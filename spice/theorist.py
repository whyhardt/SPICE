"""
theorist.py - Implementation of the RNN-SINDy theorist as a scikit-learn estimator
"""
import sys
import warnings
import time
import torch
import numpy as np
from copy import deepcopy
from sklearn.base import BaseEstimator
from typing import Dict, Optional, Tuple, Union, Iterable

from spice.resources import (
    AgentSpice,
    AgentNetwork,
    create_dataset,
    check_library_setup,
    fit_sindy,
    DatasetRNN,
    BaseRNN,
)
from spice.resources.rnn_training import fit_model as fit_rnn


warnings.filterwarnings("ignore")

class rnn_sindy_theorist(BaseEstimator):
    """
    RNN-SINDy theorist implemented as a scikit-learn estimator.
    
    This class combines an RNN for predicting behavioral choices with SINDy for discovering
    the underlying dynamical system.
    """
    
    def __init__(
        self,
        
        # Code generated by agent 3
        rnn_class: BaseRNN,
        
        # SINDy-agent configuration
        rnn_modules: Iterable[str],
        control_parameters: Iterable[str],
        sindy_library_config: Dict[str, Iterable[str]],
        sindy_filter_config: Dict[str, Iterable[Union[str, float, int, bool]]],
        
        # RNN parameters
        hidden_size: int = 8,
        dropout: float = 0.25,

        # Data/Environment parameters
        n_actions: int = 2,
        n_participants: int = 0,
        n_experiments: int = 0,
        
        # RNN training parameters
        epochs: int = 128,
        bagging: bool = False,
        sequence_length: Optional[int] = -1,  # -1 for keeping the sequence length in the data to its original length, otherwise strided windows of length sequence_length,
        n_steps_per_call: Optional[int] = 16,  # number of timesteps in one backward-call; -1 for full sequence
        batch_size: Optional[int] = -1,  # -1 for a batch-size equal to the number of participants in the data
        learning_rate: Optional[float] = 5e-3,
        convergence_threshold: Optional[float] = 1e-6,
        device: Optional[torch.device] = torch.device('cpu'),
        scheduler: Optional[bool] = False, 
        train_test_ratio: Optional[float] = 1.,
        
        # SINDy parameters
        sindy_optim_threshold: Optional[float] = 0.03,
        sindy_optim_regularization: Optional[float] = 1e-2,
        sindy_library_polynomial_degree: Optional[int] = 2,
        
        verbose: Optional[bool] = False,
    ):
        
        super(BaseEstimator, self).__init__()
        
        # Training parameters
        self.epochs = epochs
        self.bagging = bagging
        self.sequence_length = sequence_length
        self.n_steps_per_call = n_steps_per_call
        self.batch_size = batch_size
        self.learning_rate = learning_rate
        self.convergence_threshold = convergence_threshold
        self.scheduler = scheduler
        self.train_test_ratio = train_test_ratio
        self.device = device
        self.verbose = verbose
        
        # SINDy parameters
        self.sindy_optim_threshold = sindy_optim_threshold
        self.sindy_library_polynomial_degree = sindy_library_polynomial_degree
        self.sindy_optim_regularization = sindy_optim_regularization
        
        # Data parameters
        self.n_actions = n_actions
        self.n_participants = n_participants
        self.n_experiments = n_experiments
        
        # RNN parameters
        self.hidden_size = hidden_size
        self.dropout = dropout
        
        # SINDy-agent configuration
        self.rnn_modules = rnn_modules
        self.control_parameters = control_parameters
        self.sindy_feature_list = rnn_modules + control_parameters
        self.sindy_library_config = sindy_library_config
        self.sindy_filter_config = sindy_filter_config

        if not check_library_setup(self.sindy_library_config, self.sindy_feature_list, verbose=True):
            raise ValueError('\nLibrary setup does not match feature list.')
        
        self.rnn_agent = None
        self.rnn_model = None
        self.rnn_optimizer = None
        self.sindy_agent = None
        self.sindy_features = None
        
        self.rnn_model = rnn_class(
            n_actions=n_actions,
            hidden_size=hidden_size, 
            n_participants=n_participants,
            n_experiments=n_experiments,
            device=device,
        )
        
        self.optimizer_rnn = torch.optim.Adam(self.rnn_model.parameters(), lr=learning_rate)
    
    def fit(self, conditions: np.ndarray, targets: np.ndarray):
        """
        Fit the RNN-SINDy model to the data.
        
        Args:
            conditions: Array of shape (n_participants, n_trials, n_features)
            targets: Array of shape (n_participants, n_trials, n_actions)
        """
        
        dataset = DatasetRNN(conditions, targets)
        start_time = time.time()
        
        # ------------------------------------------------------------------------
        # Fit RNN
        # ------------------------------------------------------------------------
        
        if self.verbose:
            print('\nTraining the RNN...')
        
        batch_size = conditions.shape[0] if self.batch_size == -1 else self.batch_size
        
        rnn_model, rnn_optimizer, _ = fit_rnn(
            model=self.rnn_model,
            dataset_train=dataset,
            optimizer=self.optimizer_rnn,
            convergence_threshold=self.convergence_threshold,
            epochs=self.epochs,
            batch_size=batch_size,
            bagging=self.bagging,
            n_steps=self.n_steps_per_call,
            scheduler=self.scheduler,
        )

        rnn_model.eval()
        self.rnn_model = rnn_model
        self.rnn_optimizer = rnn_optimizer
        self.rnn_agent = AgentNetwork(rnn_model, self.n_actions, deterministic=True, device=self.device)
        
        if self.verbose:
            print('\nRNN training finished.')
            print(f'Training took {time.time() - start_time:.2f} seconds.')
        
        # ------------------------------------------------------------------------
        # Fit SINDy
        # ------------------------------------------------------------------------
        
        self.sindy_agent = {}
        self.sindy_features = {}
        sindy_modules = {rnn_module: {} for rnn_module in self.rnn_modules}
        
        # skip on IDs = 0 --> correspond to -1 entries in data
        participant_ids = np.unique(conditions[..., -1]).astype(int)
        experiment_ids = np.unique(conditions[..., -2]).astype(int)
        
        if min(participant_ids) == -1:
            participant_ids = participant_ids[1:]
        
        if min(experiment_ids) == -1:
            experiment_ids = experiment_ids[1:]
        
        for participant_id in participant_ids:
            self.sindy_features[participant_id] = {}
            for key in sindy_modules:
                sindy_modules[key][participant_id] = {}
                
            for experiment_id in experiment_ids:
                self.sindy_features[participant_id][experiment_id] = {}
                for key in sindy_modules:
                    sindy_modules[key][participant_id][experiment_id] = {}
                
                # get a sub-dataset for the given participant-experiment combination and only for valid 
                index_participant_experiment_combo = torch.logical_and(dataset.xs[..., -1] == participant_id, dataset.xs[..., -2] == experiment_id)
                # index_participant_experiment_combo = torch.logical_and(dataset.xs[..., 0] != -1, index_participant_experiment_combo) 
                sub_xs = dataset.xs[index_participant_experiment_combo][None]
                sub_ys = dataset.ys[index_participant_experiment_combo][None]
                
                self.rnn_agent.new_sess(participant_id=participant_id, experiment_id=experiment_id)
                
                if sub_xs.shape[1] > 0:
                    # Get SINDy-formatted data with exposed latent variables from RNN-Agent
                    x_train, control, feature_names, beta_scaling = create_dataset(
                        agent=self.rnn_agent, 
                        data=DatasetRNN(sub_xs, sub_ys),
                        n_trials=1024,
                        n_sessions=1,
                        participant_id=participant_id,
                        experiment_id=experiment_id,
                        dataprocessing=None,
                        shuffle=False,
                    )
                    
                    # Fit SINDy models -> One model per x_train feature
                    sindy_modules_id = fit_sindy(
                        variables=x_train, 
                        control=control, 
                        feature_names=feature_names, 
                        polynomial_degree=self.sindy_library_polynomial_degree, 
                        library_setup=self.sindy_library_config, 
                        filter_setup=self.sindy_filter_config, 
                        verbose=self.verbose,
                        get_loss=False, 
                        optimizer_threshold=self.sindy_optim_threshold, 
                        optimizer_alpha=self.sindy_optim_regularization,
                    )
                    
                    # Test SINDy agent and extract features
                    features_id = {}
                    # try:
                    
                    # ------------------------------------------------------------------------
                    # Save trained features of each model
                    # ------------------------------------------------------------------------
                    betas = self.rnn_agent.get_betas()
                    if betas is not None:
                        fitted_modules = {'beta_'+key: betas[key] for key in betas}
                        fitted_modules.update(sindy_modules_id)
                    else:
                        fitted_modules = sindy_modules_id
                        
                    for m in fitted_modules:
                        if m in sindy_modules:
                            sindy_modules[m][participant_id][experiment_id] = sindy_modules_id[m]
                            
                            features_m = fitted_modules[m].get_feature_names()
                            coeffs_m = fitted_modules[m].coefficients()[0]
                        
                            # Remove dummy control parameters (containing 'u')
                            index_u = ['dummy' not in feature for feature in features_m]
                            features_m = np.array(features_m)[index_u].tolist()
                            coeffs_m = np.array(coeffs_m)[index_u].tolist()
                        else:
                            features_m = ['1']
                            coeffs_m = [fitted_modules[m]]
                        
                        features_id[m] = (tuple(features_m), tuple(coeffs_m))
                        
                    self.sindy_features[participant_id][experiment_id] = deepcopy(features_id)
        
        self.sindy_agent = AgentSpice(
            model_rnn=rnn_model,
            sindy_modules=sindy_modules,
            n_actions=self.n_actions,
            deterministic=True,
        )
            # except Exception as e:
            #     # If SINDy agent setup fails, record the error
            #     for m in sindy_models:
            #         features_id[m] = (str(e), str(e))
            #     self.sindy_features[participant_id] = deepcopy(features_id)
            #     if self.verbose:
            #         print(f"Warning: SINDy agent setup failed for ID {participant_id}: {str(e)}")
    
    def predict(self, conditions: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        Make predictions using both RNN and SINDy models.
        
        Args:
            conditions: Array of shape (n_participants, n_trials, n_features)
            
        Returns:
            Tuple containing:
            - RNN predictions
            - SINDy predictions
        """
        
        # get rnn prediction about action probability
        conditions = torch.tensor(conditions, dtype=torch.float32, device=self.device)
        prediction_rnn = np.full((*conditions.shape[:-1], self.n_actions), np.nan).reshape(-1, self.n_actions)
        prediction_sindy = np.full((*conditions.shape[:-1], self.n_actions), np.nan).reshape(-1, self.n_actions)
        mask = torch.sum(conditions[..., :self.n_actions].reshape(-1, self.n_actions), dim=-1, keepdim=False) != -2
        
        # rnn predictions
        prediction = self.rnn_agent._model(conditions, batch_first=True)[0].reshape(-1, self.n_actions)
        prediction = torch.nn.functional.softmax(prediction, dim=-1).detach().cpu().numpy()
        prediction_rnn[mask.detach().cpu().numpy()] = prediction[mask]
        prediction_rnn = prediction_rnn.reshape(*conditions.shape[:-1], self.n_actions)
        
        # sindy predictions
        prediction = self.sindy_agent._model(conditions, batch_first=True)[0].reshape(-1, self.n_actions)
        prediction = torch.nn.functional.softmax(prediction, dim=-1).detach().cpu().numpy()
        prediction_sindy[mask.detach().cpu().numpy()] = prediction[mask]
        prediction_sindy = prediction_sindy.reshape(*conditions.shape[:-1], self.n_actions)
        
        return prediction_rnn, prediction_sindy

    def get_sindy_features(self) -> Dict:
        """
        Get the learned SINDy features and equations.
        
        Returns:
            Dictionary containing features and equations for each agent/model
        """
        if self.sindy_features is None:
            raise ValueError("Model hasn't been fitted yet. Call fit() first.")
        return self.sindy_features
    
    def get_sindy_agents(self) -> Dict:
        """
        Get the trained SINDy agents.
        
        Returns:
            Dictionary containing SINDy agents
        """
        if self.sindy_agent is None:
            raise ValueError("Model hasn't been fitted yet. Call fit() first.")
        return self.sindy_agent

    def get_participant_embeddings(self) -> Dict:
        if hasattr(self.rnn_model, 'participant_embedding'):
            participant_ids = torch.arange(self.n_participants, device=self.device, dtype=torch.int32).view(-1, 1)
            embeddings = self.rnn_model.participant_embedding(participant_ids)
            return {participant_id.item(): embeddings[participant_id, 0] for participant_id in participant_ids}
        else:
            print(f'RNN model has no participant_embedding module.')
            return None
        
    def get_experiment_embeddings(self) -> Dict:
        if hasattr(self.rnn_model, 'experiment_embedding'):
            experiment_ids = torch.arange(self.n_experiments, device=self.device, dtype=torch.int32).view(-1, 1)
            embeddings = self.rnn_model.experiment_embedding(experiment_ids)
            return {experiment_id.item(): embeddings[experiment_id, 0] for experiment_id in experiment_ids}
        else:
            print(f'RNN model has no experiment_embedding module.')
            return None

if __name__ == '__main__':
    # Example usage
    import argparse
    
    parser = argparse.ArgumentParser(description='Train and evaluate RNN-SINDy theorist')
    parser.add_argument('--hidden-size', type=int, default=8, help='Hidden size of the RNN')
    parser.add_argument('--epochs', type=int, default=128, help='Number of training epochs')
    parser.add_argument('--learning-rate', type=float, default=1e-2, help='Learning rate')
    parser.add_argument('--threshold', type=float, default=0.03, help='SINDy threshold')
    parser.add_argument('--verbose', action='store_true', help='Enable verbose output')
    
    args = parser.parse_args()
    
    # Generate some example data
    n_participants = 10
    n_trials = 100
    n_features = 5
    n_actions = 2
    
    conditions = np.random.rand(n_participants, n_trials, n_features)
    targets = np.random.randint(0, n_actions, size=(n_participants, n_trials, n_actions))
    
    # Create and train model
    model = rnn_sindy_theorist(
        hidden_size=args.hidden_size,
        epochs=args.epochs,
        learning_rate=args.learning_rate,
        sindy_optim_threshold=args.threshold,
        verbose=args.verbose,
        n_participants=n_participants
    )
    
    try:
        print("Fitting model...")
        model.fit(conditions, targets)
        
        print("\nMaking predictions...")
        pred_rnn, pred_sindy = model.predict(conditions)
        
        print("\nPrediction shapes:")
        print(f"RNN predictions: {pred_rnn.shape}")
        print(f"SINDy predictions: {pred_sindy.shape}")
        
        features = model.get_sindy_features()
        print("\nLearned features:")
        for id, feat in features.items():
            print(f"\nAgent {id}:")
            for model_name, (feat_names, coeffs) in feat.items():
                print(f"  {model_name}:")
                for name, coeff in zip(feat_names, coeffs):
                    print(f"    {name}: {coeff}")
                    
    except Exception as e:
        print(f"Error: {e}")
        sys.exit(1)