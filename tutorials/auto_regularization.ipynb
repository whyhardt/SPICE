{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efc9c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import manual_seed\n",
    "\n",
    "# Disable cudnn\n",
    "from torch.backends import cudnn\n",
    "cudnn.enabled = False\n",
    "\n",
    "from spice import pipeline_rnn_autoreg\n",
    "from spice.resources.old_rnn import RLRNN_dezfouli2019, RLRNN_eckstein2022 # Get predefined RNN architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2d8378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set most important arguments:\n",
    "dataset = 'eckstein2022'  # 'eckstein2022' or 'dezfouli2019'\n",
    "epochs = 2048\n",
    "metaopt_type = 'awd'\n",
    "\n",
    "# AWD\n",
    "lambda_awd = 1e-1\n",
    "\n",
    "# iMAML\n",
    "initial_reg_param = 1e-4\n",
    "outer_lr = 1e-2\n",
    "\n",
    "# Fixed model path name\n",
    "if metaopt_type == 'awd':\n",
    "    path_model = f'params/{dataset}/AWD_{dataset}_ep{epochs}_lawd-{lambda_awd}_rnn.pkl'\n",
    "elif metaopt_type == 'imaml':\n",
    "    path_model = f'params/{dataset}/iMAML_{dataset}_ep{epochs}_metalr-{outer_lr}_in-{initial_reg_param}_rnn.pkl'\n",
    "else:\n",
    "    raise ValueError('metaopt_type must be either \"awd\" or \"imaml\"')\n",
    "\n",
    "# SPICE config\n",
    "path_data = f'../data/{dataset}/{dataset}.csv'\n",
    "additional_inputs = None\n",
    "\n",
    "if dataset == 'eckstein2022':\n",
    "    train_test_ratio = 0.8\n",
    "    class_rnn = RLRNN_eckstein2022\n",
    "elif dataset == 'dezfouli2019':\n",
    "    train_test_ratio = [3, 6, 9]\n",
    "    class_rnn = RLRNN_dezfouli2019\n",
    "else:\n",
    "    raise ValueError('Dataset must be either \"eckstein2022\" or \"dezfouli2019\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51b4aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _, histories = pipeline_rnn_autoreg.main(\n",
    "    \n",
    "    dropout=0.25,\n",
    "    train_test_ratio=train_test_ratio,\n",
    "    \n",
    "    # general training parameters\n",
    "    checkpoint=False,\n",
    "    epochs=epochs, # <- 2^16\n",
    "    scheduler=True,\n",
    "    learning_rate=1e-2, # 1e-2\n",
    "\n",
    "    # Meta-optimization parameters\n",
    "    metaopt_type=metaopt_type,\n",
    "\n",
    "    lambda_awd=lambda_awd,\n",
    "\n",
    "    meta_update_interval=50,\n",
    "    inner_steps=3,\n",
    "    outer_lr=outer_lr,\n",
    "    hypergradient_steps=3,\n",
    "    initial_reg_param=initial_reg_param,\n",
    "\n",
    "    # hand-picked params\n",
    "    n_steps=-1,\n",
    "    embedding_size=32,\n",
    "    batch_size=-1,\n",
    "    sequence_length=-1,\n",
    "    bagging=True,\n",
    "    \n",
    "    class_rnn=class_rnn,\n",
    "    model=path_model,\n",
    "    data=path_data,\n",
    "    additional_inputs_data=additional_inputs,\n",
    "    \n",
    "    # synthetic dataset parameters\n",
    "    n_sessions=128,\n",
    "    n_trials=200,\n",
    "    sigma=0.2,\n",
    "    beta_reward=3.,\n",
    "    alpha_reward=0.25,\n",
    "    alpha_penalty=0.5,\n",
    "    forget_rate=0.,\n",
    "    confirmation_bias=0.,\n",
    "    beta_choice=0.,\n",
    "    alpha_choice=1.,\n",
    "    counterfactual=False,\n",
    "    alpha_counterfactual=0.,\n",
    "    \n",
    "    save_checkpoints=True,\n",
    "    analysis=False,\n",
    "    participant_id=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d6f107",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_history, val_loss_history, reg_history = histories\n",
    "plot_epochs = np.arange(1, len(train_loss_history) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot 1: Losses\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(plot_epochs, train_loss_history, label=\"Train Loss\", linewidth=2)\n",
    "plt.plot(plot_epochs, val_loss_history, label=\"Validation Loss\", linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "if metaopt_type == 'awd':\n",
    "    # Subplot 2: lambda weight decay\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, reg_history, label='λ weight decay')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('λ weight decay')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "elif metaopt_type == 'imaml':\n",
    "    # Plot 2: Regularization parameter\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(plot_epochs, reg_history, label=\"λ (Regularization)\", linewidth=2, color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Regularization Parameter')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c479892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SINDy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
