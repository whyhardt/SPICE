{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9efc9c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library setup is valid. All keys and features appear in the provided list of features.\n",
      "Library setup is valid. All keys and features appear in the provided list of features.\n",
      "Library setup is valid. All keys and features appear in the provided list of features.\n",
      "Library setup is valid. All keys and features appear in the provided list of features.\n",
      "Library setup is valid. All keys and features appear in the provided list of features.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Malte\\Desktop\\SPICE\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import manual_seed\n",
    "\n",
    "# Disable cudnn\n",
    "from torch.backends import cudnn\n",
    "cudnn.enabled = False\n",
    "\n",
    "from spice import pipeline_rnn_autoreg\n",
    "from spice.resources.old_rnn import RLRNN_dezfouli2019, RLRNN_eckstein2022 # Get predefined RNN architectures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2d8378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set most important arguments:\n",
    "dataset = 'eckstein2022'  # 'eckstein2022' or 'dezfouli2019'\n",
    "epochs = 8192\n",
    "metaopt_type = 'imaml'\n",
    "\n",
    "# AWD\n",
    "lambda_awd = 1e-1\n",
    "\n",
    "# iMAML\n",
    "initial_reg_param = 1e-4\n",
    "outer_lr = 1e-2\n",
    "\n",
    "# Fixed model path name\n",
    "if metaopt_type == 'awd':\n",
    "    path_model = f'params/{dataset}/AWD_{dataset}_ep{epochs}_lawd-{lambda_awd}_rnn.pkl'\n",
    "elif metaopt_type == 'imaml':\n",
    "    path_model = f'params/{dataset}/iMAML_{dataset}_ep{epochs}_metalr-{outer_lr}_in-{initial_reg_param}_rnn.pkl'\n",
    "else:\n",
    "    raise ValueError('metaopt_type must be either \"awd\" or \"imaml\"')\n",
    "\n",
    "# SPICE config\n",
    "path_data = f'../data/{dataset}/{dataset}.csv'\n",
    "additional_inputs = None\n",
    "\n",
    "if dataset == 'eckstein2022':\n",
    "    train_test_ratio = 0.8\n",
    "    class_rnn = RLRNN_eckstein2022\n",
    "elif dataset == 'dezfouli2019':\n",
    "    train_test_ratio = [3, 6, 9]\n",
    "    class_rnn = RLRNN_dezfouli2019\n",
    "else:\n",
    "    raise ValueError('Dataset must be either \"eckstein2022\" or \"dezfouli2019\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d51b4aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: False\n",
      "Setup of the RNN model complete.\n",
      "Training the RNN...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "metaopt_type must be either 'awd' or 'iMAML'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model, _, histories = \u001b[43mpipeline_rnn_autoreg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_test_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_test_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# general training parameters\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# <- 2^16\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# 1e-2\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Meta-optimization parameters\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetaopt_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetaopt_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlambda_awd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlambda_awd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmeta_update_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43minner_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mouter_lr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mouter_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhypergradient_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_reg_param\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial_reg_param\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# hand-picked params\u001b[39;49;00m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43msequence_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbagging\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_rnn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_rnn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43madditional_inputs_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43madditional_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# synthetic dataset parameters\u001b[39;49;00m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_sessions\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m    \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta_reward\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3.\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m    \u001b[49m\u001b[43malpha_reward\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43malpha_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforget_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfirmation_bias\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta_choice\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43malpha_choice\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcounterfactual\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43malpha_counterfactual\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_checkpoints\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43manalysis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparticipant_id\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\SPICE\\spice\\pipeline_rnn_autoreg.py:268\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(checkpoint, model, data, class_rnn, hidden_size, embedding_size, dropout, metaopt_type, lambda_awd, meta_update_interval, inner_steps, outer_lr, hypergradient_steps, initial_reg_param, epochs, train_test_ratio, l2_weight_decay, bagging, sequence_length, n_steps, batch_size, learning_rate, convergence_threshold, scheduler, additional_inputs_data, n_trials, n_sessions, beta_reward, alpha_reward, alpha_penalty, alpha_counterfactual, beta_choice, alpha_choice, forget_rate, confirmation_bias, parameter_variance, reward_prediction_error, n_actions, sigma, counterfactual, analysis, participant_id, save_checkpoints)\u001b[39m\n\u001b[32m    247\u001b[39m   model, optimizer_rnn, histories = rnn_training_imaml.fit_with_metaopt(\n\u001b[32m    248\u001b[39m     model=model,\n\u001b[32m    249\u001b[39m     model_optimizer=optimizer_rnn,\n\u001b[32m   (...)\u001b[39m\u001b[32m    264\u001b[39m     initial_reg_param=initial_reg_param,\n\u001b[32m    265\u001b[39m )\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mmetaopt_type must be either \u001b[39m\u001b[33m'\u001b[39m\u001b[33mawd\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33miMAML\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    270\u001b[39m \u001b[38;5;66;03m# save trained parameters\u001b[39;00m\n\u001b[32m    271\u001b[39m state_dict = {\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m: model.state_dict(), \u001b[33m'\u001b[39m\u001b[33moptimizer\u001b[39m\u001b[33m'\u001b[39m: optimizer_rnn.state_dict()}\n",
      "\u001b[31mValueError\u001b[39m: metaopt_type must be either 'awd' or 'iMAML'"
     ]
    }
   ],
   "source": [
    "model, _, histories = pipeline_rnn_autoreg.main(\n",
    "    \n",
    "    dropout=0.25,\n",
    "    train_test_ratio=train_test_ratio,\n",
    "    \n",
    "    # general training parameters\n",
    "    checkpoint=False,\n",
    "    epochs=epochs, # <- 2^16\n",
    "    scheduler=True,\n",
    "    learning_rate=1e-2, # 1e-2\n",
    "\n",
    "    # Meta-optimization parameters\n",
    "    metaopt_type=metaopt_type,\n",
    "\n",
    "    lambda_awd=lambda_awd,\n",
    "\n",
    "    meta_update_interval=50,\n",
    "    inner_steps=3,\n",
    "    outer_lr=outer_lr,\n",
    "    hypergradient_steps=3,\n",
    "    initial_reg_param=initial_reg_param,\n",
    "\n",
    "    # hand-picked params\n",
    "    n_steps=-1,\n",
    "    embedding_size=32,\n",
    "    batch_size=-1,\n",
    "    sequence_length=-1,\n",
    "    bagging=True,\n",
    "    \n",
    "    class_rnn=class_rnn,\n",
    "    model=path_model,\n",
    "    data=path_data,\n",
    "    additional_inputs_data=additional_inputs,\n",
    "    \n",
    "    # synthetic dataset parameters\n",
    "    n_sessions=128,\n",
    "    n_trials=200,\n",
    "    sigma=0.2,\n",
    "    beta_reward=3.,\n",
    "    alpha_reward=0.25,\n",
    "    alpha_penalty=0.5,\n",
    "    forget_rate=0.,\n",
    "    confirmation_bias=0.,\n",
    "    beta_choice=0.,\n",
    "    alpha_choice=1.,\n",
    "    counterfactual=False,\n",
    "    alpha_counterfactual=0.,\n",
    "    \n",
    "    save_checkpoints=True,\n",
    "    analysis=False,\n",
    "    participant_id=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d6f107",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_history, val_loss_history, reg_history = histories\n",
    "plot_epochs = np.arange(1, len(train_loss_history) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot 1: Losses\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(plot_epochs, train_loss_history, label=\"Train Loss\", linewidth=2)\n",
    "plt.plot(plot_epochs, val_loss_history, label=\"Validation Loss\", linewidth=2)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "if metaopt_type == 'awd':\n",
    "    # Subplot 2: lambda weight decay\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(plot_epochs, reg_history, label='λ weight decay')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('λ weight decay')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "elif metaopt_type == 'imaml':\n",
    "    # Plot 2: Regularization parameter\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(plot_epochs, reg_history, label=\"λ (Regularization)\", linewidth=2, color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Regularization Parameter')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941fa843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Configs\n",
    "from spice.resources import sindy_utils\n",
    "sindy_config = sindy_utils.SindyConfig_eckstein2022 if dataset == 'eckstein2022' else sindy_utils.SindyConfig_dezfouli2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c479892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SINDy\n",
    "from spice import pipeline_sindy\n",
    "\n",
    "agent_spice, features, sindy_loss = pipeline_sindy.main(\n",
    "    class_rnn=class_rnn,\n",
    "    model = path_model,\n",
    "    data = path_data,\n",
    "    additional_inputs_data=additional_inputs,\n",
    "    save = True,\n",
    "    \n",
    "    # general recovery parameters\n",
    "    participant_id=None,\n",
    "    filter_bad_participants=False,\n",
    "    use_optuna=True,\n",
    "    pruning=False,\n",
    "    \n",
    "    # sindy parameters\n",
    "    train_test_ratio=train_test_ratio,\n",
    "    polynomial_degree=3,\n",
    "    optimizer_alpha=0.1,\n",
    "    optimizer_threshold=0.05, # 0.05\n",
    "    n_trials_off_policy=1000,\n",
    "    n_sessions_off_policy=1,\n",
    "    n_trials_same_action_off_policy=5,\n",
    "    optuna_threshold=0.1, # 0.1\n",
    "    optuna_n_trials=50, # 50\n",
    "    optimizer_type='SR3_weighted_l1',  # 'STLSQ',  'SR3_weighted_l1'\n",
    "    # optimizer_type='SR3_L1',\n",
    "    verbose=False,\n",
    "    \n",
    "    # generated training dataset parameters\n",
    "    n_actions=2,\n",
    "    sigma=0.2,\n",
    "    beta_reward=1.,\n",
    "    alpha=0.25,\n",
    "    alpha_penalty=0.25,\n",
    "    forget_rate=0.,\n",
    "    confirmation_bias=0.,\n",
    "    beta_choice=1.,\n",
    "    alpha_choice=1.,\n",
    "    counterfactual=False,\n",
    "    alpha_counterfactual=0.,\n",
    "    \n",
    "    analysis=True,\n",
    "    get_loss=False,\n",
    "    \n",
    "    **sindy_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d75eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Model analysis\n",
    "# if dataset == 'eckstein2022':\n",
    "#     # ------------------- CONFIGURATION ECKSTEIN2022 w/o AGE --------------------\n",
    "#     study = 'eckstein2022'\n",
    "#     models_benchmark = ['ApAnBrBcfBch']#['ApBr', 'ApBrAcfpBcf', 'ApBrAcfpBcfBch', 'ApAnBrBch', 'ApAnBrAcfpAcfnBcfBch', 'ApAnBrBcfBch']\n",
    "#     train_test_ratio = 0.8\n",
    "#     sindy_config = sindy_utils.SindyConfig_eckstein2022\n",
    "#     rnn_class = rnn.RLRNN_eckstein2022\n",
    "#     additional_inputs = None\n",
    "#     setup_agent_benchmark = benchmarking_eckstein2022.setup_agent_benchmark\n",
    "#     rl_model = benchmarking_eckstein2022.rl_model\n",
    "#     benchmark_file = f'mcmc_{study}_MODEL.nc'\n",
    "#     model_config_baseline = 'ApBr'\n",
    "#     baseline_file = f'mcmc_{study}_ApBr.nc'\n",
    "\n",
    "# elif dataset == 'dezfouli2019':\n",
    "#     # ------------------------ CONFIGURATION DEZFOULI2019 -----------------------\n",
    "#     study = 'dezfouli2019'\n",
    "#     train_test_ratio = [3, 6, 9]\n",
    "#     models_benchmark = ['PhiChiBetaKappaC']\n",
    "#     sindy_config = sindy_utils.SindyConfig_dezfouli2019\n",
    "#     rnn_class = rnn.RLRNN_dezfouli2019\n",
    "#     additional_inputs = []\n",
    "#     # setup_agent_benchmark = benchmarking_dezfouli2019.setup_agent_benchmark\n",
    "#     # gql_model = benchmarking_dezfouli2019.gql_model\n",
    "#     setup_agent_benchmark = benchmarking_dezfouli2019.setup_agent_gql\n",
    "#     gql_model = benchmarking_dezfouli2019.Dezfouli2019GQL\n",
    "#     benchmark_file = f'gql_{study}_MODEL.pkl'\n",
    "#     model_config_baseline = 'PhiBeta'\n",
    "#     baseline_file = f'gql_{study}_PhiBeta.pkl'\n",
    "\n",
    "# # ------------------------- CONFIGURATION FILE PATHS ------------------------\n",
    "# use_test = True\n",
    "\n",
    "# path_data = f'data/{study}/{study}.csv'\n",
    "# path_model_rnn = path_model\n",
    "# path_model_spice = path_model.replace('_rnn.pkl', '_spice.pkl')\n",
    "# path_model_baseline = None\n",
    "# path_model_benchmark = None\n",
    "\n",
    "# dataset = convert_dataset(path_data, additional_inputs=additional_inputs)[0]\n",
    "# # use these participant_ids if not defined later\n",
    "# participant_ids = dataset.xs[:, 0, -1].unique().cpu().numpy()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
