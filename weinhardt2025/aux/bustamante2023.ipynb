{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tf7jlYw4NA0v",
    "outputId": "0969ca34-675d-422e-cbfb-7387d9bcd8ad"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/whyhardt/SPICE.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oXIbg826NS5i",
    "outputId": "3825864a-cb2d-4ad5-f2e5-79a4e81dfc3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: SPICE is not a valid editable requirement. It should either be a path to a local project or a VCS URL (beginning with bzr+http, bzr+https, bzr+ssh, bzr+sftp, bzr+ftp, bzr+lp, bzr+file, git+http, git+https, git+ssh, git+git, git+file, hg+file, hg+http, hg+https, hg+ssh, hg+static-http, svn+ssh, svn+http, svn+https, svn+svn, svn+file).\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !pip install -e SPICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "f0uVlABYznR5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/spice_env/lib/python3.11/site-packages/pysindy/__init__.py:1: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import DistributionNotFound\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from spice.estimator import SpiceEstimator\n",
    "from spice.resources.spice_utils import SpiceConfig\n",
    "from spice.utils.convert_dataset import convert_dataset\n",
    "from spice.resources.rnn import BaseRNN\n",
    "\n",
    "# For custom RNN\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data first with the `convert_dataset` method. This method returns a `SpiceDataset` object which we can use right away "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/bustamante2023/bustamante2023.csv')\n",
    "df['decision'] = df['decision'].replace({'stay': 0, 'exit': 1})\n",
    "df['decision_duration'] = df['decision'].replace({'stay': 2, 'exit': 8.333})\n",
    "df['harvest_duration'] = (df['choice_duration'] + df['harvest_duration'])/1000\n",
    "df['travel_duration'] = df['travel_duration']/1000\n",
    "df.to_csv('../data/bustamante2023/bustamante2023_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: torch.Size([4296, 112, 8])\n",
      "Number of participants: 537\n",
      "Number of actions in dataset: 2\n",
      "Number of additional inputs: 1\n"
     ]
    }
   ],
   "source": [
    "# Load your data\n",
    "dataset = convert_dataset(\n",
    "    file = '../data/bustamante2023/bustamante2023_processed.csv',\n",
    "    df_participant_id='subject_id',\n",
    "    df_choice='decision',\n",
    "    df_reward='reward',\n",
    "    df_block='overall_round',\n",
    "    additional_inputs=['decision_duration'],\n",
    "    timeshift_additional_inputs=False,\n",
    "    )\n",
    "\n",
    "# structure of dataset:\n",
    "# dataset has two main attributes: xs -> inputs; ys -> targets (next action)\n",
    "# shape: (n_participants*n_blocks*n_experiments, n_timesteps, features)\n",
    "# features are (n_actions * action, n_actions * reward, n_additional_inputs * additional_input, block_number, experiment_id, participant_id)\n",
    "\n",
    "# in order to set up the participant embedding we have to compute the number of unique participants in our data \n",
    "# to get the number of participants n_participants we do:\n",
    "n_participants = len(dataset.xs[..., -1].unique())\n",
    "\n",
    "print(f\"Shape of dataset: {dataset.xs.shape}\")\n",
    "print(f\"Number of participants: {n_participants}\")\n",
    "n_actions = dataset.ys.shape[-1]\n",
    "print(f\"Number of actions in dataset: {n_actions}\")\n",
    "print(f\"Number of additional inputs: {dataset.xs.shape[-1]-2*n_actions-3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.7286,    nan, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.6610,    nan, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 1.0000,    nan, 0.0492, 1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.7242,    nan, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.6174,    nan, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.5456,    nan, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 1.0000,    nan, 0.0492, 1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.8390,    nan, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.6964,    nan, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 1.0000,    nan, 0.0492, 1.0000, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.xs[0, :10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to define the configuration for SPICE with a `SpiceConfig` object.\n",
    "\n",
    "The `SpiceConfig` takes as arguments \n",
    "1. `library_setup (dict)`: Defining the variable names of each module.\n",
    "2. `memory_state (dict)`: Defining the memory state variables and their initial values.\n",
    "3. `states_in_logit (list)`: Defining which of the memory state variables are used later for the logit computation. This is necessary for some background processes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spice_config = SpiceConfig(\n",
    "    library_setup={\n",
    "        'value_stay': ['reward', 'decision_duration', 'value_stay'],\n",
    "        'value_exit': ['reward', 'decision_duration', 'value_exit'],\n",
    "    },\n",
    "    \n",
    "    memory_state={\n",
    "            'value': 0.5,\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we are going to define the SPICE model which is a child of the `BaseRNN` and `torch.nn.Module` class and takes as required arguments:\n",
    "1. `spice_config (SpiceConfig)`: previously defined SpiceConfig object\n",
    "2. `n_actions (int)`: number of possible actions in your dataset (including non-displayed ones if applicable).\n",
    "3. `n_participants (int)`: number of participants in your dataset.\n",
    "\n",
    "As usual for a `torch.nn.Module` we have to define at least the `__init__` method and the `forward` method.\n",
    "The `forward` method gets called when computing a forward pass through the model and takes as inputs `(inputs (SpiceDataset.xs), prev_state (dict, default: None), batch_first (bool, default: False))` and returns `(logits (torch.Tensor, shape: (n_participants*n_blocks*n_experiments, timesteps, n_actions)), updated_state (dict))`. Two necessary method calls inside the forward pass are:\n",
    "1. `self.init_forward_pass(inputs, prev_state, batch_first) -> SpiceSignals`: returns a `SpiceSignals` object which carries all relevant information already processed.\n",
    "2. `self.post_forward_pass(SpiceSignals, batch_first) -> SpiceSignals`: does some re-arranging of the logits to adhere to `batch_first`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "z0kOR2Qgz0FZ"
   },
   "outputs": [],
   "source": [
    "class SPICERNN(BaseRNN):\n",
    "    \n",
    "    def __init__(self, spice_config, n_participants, **kwargs):\n",
    "        super().__init__(n_actions=2, spice_config=spice_config, n_participants=n_participants, embedding_size=32)\n",
    "        \n",
    "        # participant embedding\n",
    "        self.participant_embedding = self.setup_embedding(num_embeddings=n_participants, embedding_size=self.embedding_size, dropout=0.)\n",
    "        \n",
    "        # scaling factor (inverse noise temperature) for each participant for the values which are handled by an hard-coded equation\n",
    "        self.betas['value'] = self.setup_constant(embedding_size=self.embedding_size)\n",
    "        \n",
    "        # set up the submodules\n",
    "        self.submodules_rnn['value_stay'] = self.setup_module(input_size=3+self.embedding_size)\n",
    "        self.submodules_rnn['value_exit'] = self.setup_module(input_size=3+self.embedding_size)\n",
    "        \n",
    "    def forward(self, inputs, prev_state, batch_first=False):\n",
    "        \n",
    "        spice_signals = self.init_forward_pass(inputs, prev_state, batch_first)\n",
    "        \n",
    "        decision_duration = spice_signals.additional_inputs[..., 0].unsqueeze(-1).repeat(1, 1, self.n_actions)\n",
    "        decision_duration = torch.where(decision_duration==0, 0.240, decision_duration)\n",
    "        rewards_chosen = (spice_signals.actions * spice_signals.rewards.nan_to_num(0)).sum(dim=-1, keepdim=True).repeat(1, 1, self.n_actions)\n",
    "        \n",
    "        # time-invariant participant features\n",
    "        participant_embeddings = self.participant_embedding(spice_signals.participant_ids)\n",
    "        beta_reward = self.betas['value'](participant_embeddings)\n",
    "        mask_stay = torch.tensor((1,0)).reshape(1, 1, self.n_actions).repeat(rewards_chosen.shape[0], rewards_chosen.shape[1], 1)\n",
    "        mask_exit = torch.tensor((0,1)).reshape(1, 1, self.n_actions).repeat(rewards_chosen.shape[0], rewards_chosen.shape[1], 1)\n",
    "        \n",
    "        for timestep in spice_signals.timesteps:\n",
    "            \n",
    "            value_stay = self.state['value'][..., 0][:, None].repeat(1, 2)\n",
    "            value_exit = self.state['value'][..., 1][:, None].repeat(1, 2)\n",
    "            \n",
    "            # update chosen value\n",
    "            self.call_module(\n",
    "                key_module='value_stay',\n",
    "                key_state='value',\n",
    "                action_mask=mask_stay[timestep],\n",
    "                inputs=(rewards_chosen[timestep], decision_duration[timestep], value_exit),\n",
    "                participant_index=spice_signals.participant_ids,\n",
    "                participant_embedding=participant_embeddings,\n",
    "                activation_rnn=torch.nn.functional.sigmoid,\n",
    "            )\n",
    "            \n",
    "            # update not chosen value\n",
    "            self.call_module(\n",
    "                key_module='value_exit',\n",
    "                key_state='value',\n",
    "                action_mask=mask_exit[timestep],\n",
    "                inputs=(rewards_chosen[timestep], decision_duration[timestep], value_stay),\n",
    "                participant_index=spice_signals.participant_ids,\n",
    "                participant_embedding=participant_embeddings,\n",
    "                activation_rnn=torch.nn.functional.sigmoid,\n",
    "            )\n",
    "            \n",
    "            # transform logits from item-space to action-space\n",
    "            spice_signals.logits[timestep] = self.state['value'] * beta_reward\n",
    "            \n",
    "        spice_signals = self.post_forward_pass(spice_signals, batch_first)\n",
    "        \n",
    "        return spice_signals.logits, self.get_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's setup now the `SpiceEstimator` object and fit it to the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "id": "3EnmDiUMWq6e",
    "outputId": "e53b1bbd-4173-4d2c-bcdc-15832bc31bd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training on cpu...\n",
      "================================================================================\n",
      "\n",
      "Training the RNN...\n",
      "Epoch 599/1000 --- L(Train): 0.3720970; Time: 2.77s; Convergence: 2.06e-03\n",
      "================================================================================\n",
      "SPICE model before 600 epochs:\n",
      "================================================================================\n",
      "value_stay[t+1] = 0.0751 1 + 0.8881 value_stay[t] + 0.0253 reward + -0.0135 decision_duration + 1.0612 value_stay[t] + -0.1852 value_stay^2 + -0.1907 value_stay*reward + -0.1897 value_stay*decision_duration + -0.0922 value_stay*value_stay + 0.2586 reward^2 + 0.0452 reward*decision_duration + 0.0211 reward*value_stay + 0.2366 decision_duration^2 + -0.0123 decision_duration*value_stay + 0.0403 value_stay^2 \n",
      "value_exit[t+1] = 0.0056 1 + 0.9997 value_exit[t] + 0.005 decision_duration + 1.0058 value_exit[t] + -0.0108 value_exit^2 + -0.0123 value_exit*reward + -0.0129 value_exit*value_exit + 0.0039 reward^2 + -0.0014 reward*decision_duration + 0.0101 reward*value_exit + -0.0038 decision_duration^2 + -0.0095 value_exit^2 \n",
      "beta(value) = 24.9759\n",
      "\n",
      "================================================================================\n",
      "SPICE model after 600 epochs:\n",
      "================================================================================\n",
      "value_stay[t+1] = 0.0751 1 + 0.8881 value_stay[t] + 0.0253 reward + -0.0135 decision_duration + 1.0612 value_stay[t] + -0.1852 value_stay^2 + -0.1907 value_stay*reward + -0.1897 value_stay*decision_duration + -0.0922 value_stay*value_stay + 0.2586 reward^2 + 0.0452 reward*decision_duration + 0.0211 reward*value_stay + 0.2366 decision_duration^2 + -0.0123 decision_duration*value_stay + 0.0403 value_stay^2 \n",
      "value_exit[t+1] = 0.0056 1 + 0.9997 value_exit[t] + 0.005 decision_duration + 1.0058 value_exit[t] + -0.0108 value_exit^2 + -0.0123 value_exit*reward + -0.0129 value_exit*value_exit + 0.0039 reward^2 + -0.0014 reward*decision_duration + 0.0101 reward*value_exit + -0.0038 decision_duration^2 + -0.0095 value_exit^2 \n",
      "beta(value) = 24.9759\n",
      "Epoch 699/1000 --- L(Train): 0.3688615; Time: 2.61s; Convergence: 9.82e-04\n",
      "================================================================================\n",
      "SPICE model after 700 epochs:\n",
      "================================================================================\n",
      "value_stay[t+1] = 0.077 1 + 0.8869 value_stay[t] + 0.0331 reward + -0.0103 decision_duration + 1.0605 value_stay[t] + -0.1841 value_stay^2 + -0.1705 value_stay*reward + -0.2182 value_stay*decision_duration + -0.0953 value_stay*value_stay + 0.2328 reward^2 + 0.0531 reward*decision_duration + 0.0249 reward*value_stay + 0.2451 decision_duration^2 + -0.0116 decision_duration*value_stay + 0.0373 value_stay^2 \n",
      "value_exit[t+1] = 0.0073 1 + 1.0 value_exit[t] + 0.0031 reward + 0.0048 decision_duration + 1.0046 value_exit[t] + -0.0115 value_exit^2 + -0.011 value_exit*reward + -0.002 value_exit*decision_duration + -0.0145 value_exit*value_exit + 0.0051 reward^2 + 0.0023 reward*decision_duration + 0.0024 reward*value_exit + -0.0029 decision_duration^2 + -0.0117 value_exit^2 \n",
      "beta(value) = 25.6079\n",
      "Epoch 799/1000 --- L(Train): 0.3629097; Time: 2.76s; Convergence: 6.52e-04\n",
      "================================================================================\n",
      "SPICE model after 800 epochs:\n",
      "================================================================================\n",
      "value_stay[t+1] = 0.0809 1 + 0.8854 value_stay[t] + 0.0406 reward + -0.0083 decision_duration + 1.0608 value_stay[t] + -0.1847 value_stay^2 + -0.1551 value_stay*reward + -0.2434 value_stay*decision_duration + -0.0994 value_stay*value_stay + 0.2076 reward^2 + 0.0607 reward*decision_duration + 0.0271 reward*value_stay + 0.2553 decision_duration^2 + -0.0127 decision_duration*value_stay + 0.0345 value_stay^2 \n",
      "value_exit[t+1] = 0.009 1 + 1.0 value_exit[t] + 0.008 reward + 0.0041 decision_duration + 1.0039 value_exit[t] + -0.0136 value_exit^2 + -0.0105 value_exit*reward + -0.0043 value_exit*decision_duration + -0.016 value_exit*value_exit + 0.0061 reward^2 + 0.0067 reward*decision_duration + -0.0063 reward*value_exit + -0.0131 value_exit^2 \n",
      "beta(value) = 26.4196\n",
      "Epoch 899/1000 --- L(Train): 0.3624975; Time: 2.81s; Convergence: 2.68e-04\n",
      "================================================================================\n",
      "SPICE model after 900 epochs:\n",
      "================================================================================\n",
      "value_stay[t+1] = 0.0845 1 + 0.8864 value_stay[t] + 0.0431 reward + -0.0095 decision_duration + 1.06 value_stay[t] + -0.1821 value_stay^2 + -0.1437 value_stay*reward + -0.2597 value_stay*decision_duration + -0.102 value_stay*value_stay + 0.1982 reward^2 + 0.0637 reward*decision_duration + 0.0234 reward*value_stay + 0.265 decision_duration^2 + -0.0177 decision_duration*value_stay + 0.0298 value_stay^2 \n",
      "value_exit[t+1] = 0.0098 1 + 1.0 value_exit[t] + 0.012 reward + 1.0045 value_exit[t] + -0.0164 value_exit^2 + -0.0109 value_exit*reward + -0.0061 value_exit*decision_duration + -0.0167 value_exit*value_exit + 0.0062 reward^2 + 0.0105 reward*decision_duration + -0.0132 reward*value_exit + -0.0126 value_exit^2 \n",
      "beta(value) = 27.3676\n",
      "Epoch 999/1000 --- L(Train): 0.3615397; Time: 2.95s; Convergence: 2.81e-03\n",
      "================================================================================\n",
      "SPICE model after 1000 epochs:\n",
      "================================================================================\n",
      "value_stay[t+1] = 0.0901 1 + 0.8848 value_stay[t] + 0.0559 reward + -0.0035 decision_duration + 1.0604 value_stay[t] + -0.185 value_stay^2 + -0.132 value_stay*reward + -0.2754 value_stay*decision_duration + -0.1075 value_stay*value_stay + 0.1673 reward^2 + 0.0756 reward*decision_duration + 0.0284 reward*value_stay + 0.2667 decision_duration^2 + -0.0166 decision_duration*value_stay + 0.0255 value_stay^2 \n",
      "value_exit[t+1] = 0.0134 1 + 1.0 value_exit[t] + 0.0194 reward + 1.0036 value_exit[t] + -0.0216 value_exit^2 + -0.013 value_exit*reward + -0.0202 value_exit*value_exit + 0.0085 reward^2 + 0.0188 reward*decision_duration + -0.0268 reward*value_exit + -0.0151 value_exit^2 \n",
      "beta(value) = 27.7513\n",
      "Epoch 1000/1000 --- L(Train): 0.3649377; Time: 2.72s; Convergence: 3.11e-03\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "================================================================================\n",
      "Starting second stage SINDy fitting (threshold=0, single model)\n",
      "================================================================================\n",
      "SINDy Stage 2 - Epoch 5000/5000 --- L(Train): 0.0000166; Time: 0.14s\n",
      "================================================================================\n",
      "Second stage SINDy fitting complete!\n",
      "================================================================================\n",
      "\n",
      "Refitted SPICE model (participant 0):\n",
      "--------------------------------------------------------------------------------\n",
      "value_stay[t+1] = 0.2411 1 + 0.7746 value_stay[t] + 0.239 reward + 0.2075 decision_duration + 1.0 value_stay[t] + -0.2934 value_stay*decision_duration + -0.4747 value_stay*value_stay + 0.241 reward*decision_duration + -0.172 reward*value_stay + 0.1384 decision_duration^2 + -0.339 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 27.7513\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "RNN training finished.\n",
      "Training took 3470.73 seconds.\n",
      "Saving SPICE model to ../params/bustamante2023/spice_bustamante2023.pkl...\n",
      "================================================================================\n",
      "\n",
      "Training complete!\n",
      "\n",
      "Example SPICE model (participant 0):\n",
      "--------------------------------------------------------------------------------\n",
      "value_stay[t+1] = 0.2411 1 + 0.7746 value_stay[t] + 0.239 reward + 0.2075 decision_duration + 1.0 value_stay[t] + -0.2934 value_stay*decision_duration + -0.4747 value_stay*value_stay + 0.241 reward*decision_duration + -0.172 reward*value_stay + 0.1384 decision_duration^2 + -0.339 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 27.7513\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "estimator = SpiceEstimator(\n",
    "        # model paramaeters\n",
    "        rnn_class=SPICERNN,\n",
    "        spice_config=spice_config,\n",
    "        n_actions=2,\n",
    "        n_participants=n_participants,\n",
    "        n_experiments=1,\n",
    "        \n",
    "        # training parameters\n",
    "        epochs=1000,\n",
    "        l2_weight_decay=0.01,\n",
    "        sindy_epochs=5000, # could also be 1000,\n",
    "        sindy_threshold=0.1,\n",
    "        sindy_threshold_frequency=100,\n",
    "        sindy_weight=0.01,\n",
    "        sindy_library_polynomial_degree=2,\n",
    "        verbose=True,\n",
    "        save_path_spice='../params/bustamante2023/spice_bustamante2023.pkl',\n",
    "    )\n",
    "\n",
    "print(f\"\\nStarting training on {estimator.device}...\")\n",
    "print(\"=\" * 80)\n",
    "estimator.fit(dataset.xs, dataset.ys)\n",
    "# estimator.load_spice(args.model)\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nTraining complete!\")\n",
    "\n",
    "# Print example SPICE model for first participant\n",
    "print(\"\\nExample SPICE model (participant 0):\")\n",
    "print(\"-\" * 80)\n",
    "estimator.print_spice_model(participant_id=0)\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     participant_id                subject_id  last_reward  relative_optimal  \\\n",
      "0                 0  08aiu2bm6t15qij5826jxz50     8.241283          1.461283   \n",
      "1                 1  09j932f828pn7h7bozp9mpnl     5.344722         -1.435278   \n",
      "2                 2  0ax9htcbhfi3ncsospqzwjx2     8.945571          2.165571   \n",
      "3                 3  0e6zivqly335lojgb4c6606t     7.554696          0.774696   \n",
      "4                 4  0fawro1pivqnh4lem4ayf4o0     3.089682         -3.690318   \n",
      "..              ...                       ...          ...               ...   \n",
      "532             532  zevrdzmkwvzsihx3hwzpudkr     9.071613          2.291613   \n",
      "533             533  zhgkeunzm8bshh2zg2kywfjv    10.476446          3.696446   \n",
      "534             534  zhyb93wwd8tvuvagdkrfh108     9.012543          2.232543   \n",
      "535             535  zn94ngriwmlw6fdmvx1onez4     5.058637         -1.721363   \n",
      "536             536  zpsyqyrcmklbww1o9f2r5hku     6.024730         -0.755270   \n",
      "\n",
      "     over_harvester  \n",
      "0                 0  \n",
      "1                 1  \n",
      "2                 0  \n",
      "3                 0  \n",
      "4                 1  \n",
      "..              ...  \n",
      "532               0  \n",
      "533               0  \n",
      "534               0  \n",
      "535               1  \n",
      "536               1  \n",
      "\n",
      "[537 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df['last_reward'] = df.groupby('subject_id')['last_reward'].fillna(method='bfill')\n",
    "df['participant_id'] = pd.factorize(df['subject_id'])[0]\n",
    "exit_df = df[df['decision'] == 1]\n",
    "mean_exit_threshold = exit_df.groupby(['participant_id', 'subject_id'])['last_reward'].mean().reset_index()\n",
    "mean_exit_threshold['relative_optimal'] = mean_exit_threshold['last_reward'] - 6.78 #from Bustamante et al. Table S7, experiment 1\n",
    "mean_exit_threshold['over_harvester'] = np.where(mean_exit_threshold['relative_optimal'] <= 0, 1, 0)\n",
    "print(mean_exit_threshold)\n",
    "overharvesters = mean_exit_threshold[mean_exit_threshold['over_harvester'] == 1]['participant_id'].unique()\n",
    "underharvesters = mean_exit_threshold[mean_exit_threshold['over_harvester'] == 0]['participant_id'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OVERHARVESTERS\n",
      "Participant number 1\n",
      "value_stay[t+1] = 0.188 1 + 0.7851 value_stay[t] + 0.3444 reward + 0.209 decision_duration + 1.0 value_stay[t] + -0.3207 value_stay*decision_duration + -0.4346 value_stay*value_stay + -0.2226 reward^2 + 0.3536 reward*decision_duration + 0.1708 decision_duration^2 + -0.331 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 46.0193\n",
      "Participant number 4\n",
      "value_stay[t+1] = 0.1576 1 + 0.8503 value_stay[t] + 0.4281 reward + 0.1835 decision_duration + 1.0 value_stay[t] + -0.2565 value_stay*reward + -0.406 value_stay*decision_duration + -0.3052 value_stay*value_stay + -0.2531 reward^2 + 0.4188 reward*decision_duration + 0.1683 decision_duration^2 + -0.2212 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 41.1108\n",
      "Participant number 7\n",
      "value_stay[t+1] = 0.1782 1 + 0.8371 value_stay[t] + 0.4067 reward + 0.19 decision_duration + 1.0 value_stay[t] + -0.1224 value_stay^2 + -0.2607 value_stay*decision_duration + -0.3784 value_stay*value_stay + -0.3138 reward^2 + 0.4092 reward*decision_duration + 0.1527 decision_duration^2 + -0.3293 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 47.9589\n",
      "Participant number 12\n",
      "value_stay[t+1] = 0.1658 1 + 0.8569 value_stay[t] + 0.4099 reward + 0.1757 decision_duration + 1.0 value_stay[t] + -0.1619 value_stay^2 + -0.2086 value_stay*decision_duration + -0.3466 value_stay*value_stay + -0.3185 reward^2 + 0.3975 reward*decision_duration + 0.1405 decision_duration^2 + -0.3169 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 57.5397\n",
      "Participant number 13\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.3405 reward + 1.0 value_stay[t] + -0.6345 value_stay*reward + 0.3302 reward*decision_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.1287 reward + 1.0 value_exit[t] + -0.1952 reward*value_exit \n",
      "beta(value) = 20.2429\n",
      "Participant number 14\n",
      "value_stay[t+1] = 0.1991 1 + 0.7895 value_stay[t] + 0.3387 reward + 0.2101 decision_duration + 1.0 value_stay[t] + -0.3081 value_stay*decision_duration + -0.4536 value_stay*value_stay + -0.2126 reward^2 + 0.3462 reward*decision_duration + 0.1654 decision_duration^2 + -0.3658 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 51.9326\n",
      "Participant number 20\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4367 reward + 0.2772 decision_duration + 1.0 value_stay[t] + -0.6073 value_stay*reward + -0.6177 value_stay*decision_duration + -0.1297 value_stay*value_stay + -0.1611 reward^2 + 0.4202 reward*decision_duration + 0.1458 reward*value_stay + 0.1535 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 24.6168\n",
      "Participant number 23\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.3918 reward + 0.2784 decision_duration + 1.0 value_stay[t] + -0.2944 value_stay^2 + -0.2694 value_stay*decision_duration + -0.3357 value_stay*value_stay + -0.2535 reward^2 + 0.3751 reward*decision_duration + 0.1057 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 35.3560\n",
      "Participant number 24\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4118 reward + 0.3605 decision_duration + 1.0 value_stay[t] + -0.182 value_stay^2 + -0.5624 value_stay*reward + -0.4612 value_stay*decision_duration + -0.1683 reward^2 + 0.393 reward*decision_duration + 0.1495 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 20.1776\n",
      "Participant number 25\n",
      "value_stay[t+1] = 0.1903 1 + 0.7915 value_stay[t] + 0.3299 reward + 0.2018 decision_duration + 1.0 value_stay[t] + -0.2678 value_stay*decision_duration + -0.4463 value_stay*value_stay + -0.1977 reward^2 + 0.339 reward*decision_duration + 0.1581 decision_duration^2 + -0.3623 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 58.7752\n",
      "Participant number 26\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.474 reward + 0.2134 decision_duration + 1.0 value_stay[t] + -0.2307 value_stay^2 + -0.5 value_stay*reward + -0.4338 value_stay*decision_duration + -0.2753 reward^2 + 0.4605 reward*decision_duration + 0.188 reward*value_stay + 0.1438 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 41.5806\n",
      "Participant number 27\n",
      "value_stay[t+1] = 0.1945 1 + 0.7793 value_stay[t] + 0.3492 reward + 0.2083 decision_duration + 1.0 value_stay[t] + -0.3172 value_stay*decision_duration + -0.4506 value_stay*value_stay + -0.2164 reward^2 + 0.3481 reward*decision_duration + 0.1762 decision_duration^2 + -0.3502 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 32.6722\n",
      "Participant number 30\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4782 reward + 0.2659 decision_duration + 1.0 value_stay[t] + -0.1905 value_stay^2 + -0.3892 value_stay*reward + -0.4008 value_stay*decision_duration + -0.1771 value_stay*value_stay + -0.3018 reward^2 + 0.465 reward*decision_duration + 0.1558 reward*value_stay + 0.1103 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 40.4281\n",
      "Participant number 32\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4879 reward + 0.2463 decision_duration + 1.0 value_stay[t] + -0.2147 value_stay^2 + -0.3745 value_stay*reward + -0.3936 value_stay*decision_duration + -0.1794 value_stay*value_stay + -0.3265 reward^2 + 0.4693 reward*decision_duration + 0.1825 reward*value_stay + 0.1317 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 25.4162\n",
      "Participant number 33\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.2754 decision_duration + 1.0 value_stay[t] + -0.7202 value_stay*reward + -0.527 value_stay*decision_duration + 2.1089 reward*decision_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.1195 reward + 1.0 value_exit[t] + -0.1826 reward*value_exit \n",
      "beta(value) = 36.9293\n",
      "Participant number 35\n",
      "value_stay[t+1] = 0.2015 1 + 0.7932 value_stay[t] + 0.3131 reward + 0.2097 decision_duration + 1.0 value_stay[t] + -0.3295 value_stay*decision_duration + -0.4348 value_stay*value_stay + -0.1959 reward^2 + 0.3219 reward*decision_duration + 0.1616 decision_duration^2 + -0.3368 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 44.1966\n",
      "Participant number 36\n",
      "value_stay[t+1] = 0.1516 1 + 0.842 value_stay[t] + 0.4424 reward + 0.1695 decision_duration + 1.0 value_stay[t] + -0.2551 value_stay*reward + -0.3725 value_stay*decision_duration + -0.3103 value_stay*value_stay + -0.2596 reward^2 + 0.4318 reward*decision_duration + 0.1741 decision_duration^2 + -0.2174 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 45.4181\n",
      "Participant number 37\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4248 reward + 0.3654 decision_duration + 1.0 value_stay[t] + -0.1231 value_stay^2 + -0.6578 value_stay*reward + -0.5024 value_stay*decision_duration + -0.1403 reward^2 + 0.4207 reward*decision_duration + 0.1385 reward*value_stay \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.1209 reward + 1.0 value_exit[t] + -0.184 reward*value_exit \n",
      "beta(value) = 27.1067\n",
      "Participant number 38\n",
      "value_stay[t+1] = 0.1217 1 + 1.0 value_stay[t] + 0.4363 reward + 0.1635 decision_duration + 1.0 value_stay[t] + -0.1448 value_stay^2 + -0.2508 value_stay*reward + -0.4223 value_stay*decision_duration + -0.2758 value_stay*value_stay + -0.2638 reward^2 + 0.4395 reward*decision_duration + 0.1966 decision_duration^2 + -0.2666 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 27.3227\n",
      "Participant number 43\n",
      "value_stay[t+1] = 0.1493 1 + 0.8721 value_stay[t] + 0.4428 reward + 0.1641 decision_duration + 1.0 value_stay[t] + -0.1116 value_stay^2 + -0.1608 value_stay*reward + -0.309 value_stay*decision_duration + -0.2913 value_stay*value_stay + -0.3018 reward^2 + 0.4343 reward*decision_duration + 0.1633 decision_duration^2 + -0.2439 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 44.1196\n",
      "Participant number 44\n",
      "value_stay[t+1] = 0.1951 1 + 0.7809 value_stay[t] + 0.3442 reward + 0.205 decision_duration + 1.0 value_stay[t] + -0.3217 value_stay*decision_duration + -0.4329 value_stay*value_stay + -0.2303 reward^2 + 0.3386 reward*decision_duration + 0.1652 decision_duration^2 + -0.312 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 43.2950\n",
      "Participant number 45\n",
      "value_stay[t+1] = 0.1997 1 + 0.7825 value_stay[t] + 0.338 reward + 0.2102 decision_duration + 1.0 value_stay[t] + -0.3161 value_stay*decision_duration + -0.4496 value_stay*value_stay + -0.2116 reward^2 + 0.3388 reward*decision_duration + 0.1663 decision_duration^2 + -0.346 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 41.9932\n",
      "Participant number 46\n",
      "value_stay[t+1] = 0.2429 1 + 0.7996 value_stay[t] + 0.1724 reward + 0.2083 decision_duration + 1.0 value_stay[t] + -0.2715 value_stay*decision_duration + -0.4929 value_stay*value_stay + 0.1828 reward*decision_duration + 0.1411 decision_duration^2 + -0.4203 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 57.9411\n",
      "Participant number 47\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.464 reward + 0.3275 decision_duration + 1.0 value_stay[t] + -0.2059 value_stay^2 + -0.4371 value_stay*reward + -0.2999 value_stay*decision_duration + -0.1764 value_stay*value_stay + -0.2914 reward^2 + 0.4643 reward*decision_duration + 0.1786 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 45.4829\n",
      "Participant number 49\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4632 reward + 0.2337 decision_duration + 1.0 value_stay[t] + -0.3039 value_stay^2 + -0.4979 value_stay*reward + -0.1689 value_stay*decision_duration + -0.287 reward^2 + 0.5053 reward*decision_duration + 0.1809 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 48.8299\n",
      "Participant number 51\n",
      "value_stay[t+1] = 0.1516 1 + 0.8737 value_stay[t] + 0.4388 reward + 0.1644 decision_duration + 1.0 value_stay[t] + -0.1215 value_stay^2 + -0.1524 value_stay*reward + -0.3313 value_stay*decision_duration + -0.2856 value_stay*value_stay + -0.3049 reward^2 + 0.4281 reward*decision_duration + 0.1704 decision_duration^2 + -0.235 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 29.0617\n",
      "Participant number 54\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4662 reward + 0.2206 decision_duration + 1.0 value_stay[t] + -0.2276 value_stay^2 + -0.2319 value_stay*reward + -0.3057 value_stay*decision_duration + -0.2659 value_stay*value_stay + -0.3257 reward^2 + 0.4625 reward*decision_duration + 0.1257 reward*value_stay + 0.1389 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 49.1557\n",
      "Participant number 59\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.3428 reward + 0.4212 decision_duration + 1.0 value_stay[t] + -0.5148 value_stay*reward + -0.4985 value_stay*decision_duration + 0.3614 reward*decision_duration + -0.2818 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 44.6834\n",
      "Participant number 66\n",
      "value_stay[t+1] = 0.2081 1 + 0.8137 value_stay[t] + 0.1649 reward + 0.2038 decision_duration + 1.0 value_stay[t] + -0.3045 value_stay*decision_duration + -0.4241 value_stay*value_stay + 0.1753 reward*decision_duration + 0.1508 decision_duration^2 + -0.3464 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 59.8518\n",
      "Participant number 68\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4279 reward + 0.3859 decision_duration + 1.0 value_stay[t] + -0.2112 value_stay^2 + -0.2308 value_stay*reward + -0.3802 value_stay*decision_duration + -0.212 value_stay*value_stay + -0.254 reward^2 + 0.4181 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 37.1216\n",
      "Participant number 70\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.3636 reward + 0.3862 decision_duration + 1.0 value_stay[t] + -0.2981 value_stay^2 + -0.2992 value_stay*decision_duration + -0.2722 value_stay*value_stay + -0.2628 reward^2 + 0.3401 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 34.5730\n",
      "Participant number 71\n",
      "value_stay[t+1] = 0.1345 1 + 0.8742 value_stay[t] + 0.4591 reward + 0.1675 decision_duration + 1.0 value_stay[t] + -0.1265 value_stay^2 + -0.1381 value_stay*reward + -0.2701 value_stay*decision_duration + -0.2929 value_stay*value_stay + -0.3166 reward^2 + 0.4609 reward*decision_duration + 0.1613 decision_duration^2 + -0.2638 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 56.3813\n",
      "Participant number 72\n",
      "value_stay[t+1] = 0.1779 1 + 0.8155 value_stay[t] + 0.3014 reward + 0.1917 decision_duration + 1.0 value_stay[t] + -0.2471 value_stay*decision_duration + -0.4252 value_stay*value_stay + -0.1667 reward^2 + 0.3094 reward*decision_duration + 0.1577 decision_duration^2 + -0.3742 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 58.8746\n",
      "Participant number 73\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4853 reward + 0.1644 decision_duration + 1.0 value_stay[t] + -0.2373 value_stay^2 + -0.5266 value_stay*reward + -0.1218 value_stay*value_stay + -0.2628 reward^2 + 0.4467 reward*decision_duration + 0.182 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 52.2883\n",
      "Participant number 74\n",
      "value_stay[t+1] = 0.2 1 + 0.8006 value_stay[t] + 0.2876 reward + 0.2149 decision_duration + 1.0 value_stay[t] + -0.3377 value_stay*decision_duration + -0.4469 value_stay*value_stay + -0.1403 reward^2 + 0.2912 reward*decision_duration + 0.1757 decision_duration^2 + -0.3762 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 35.1182\n",
      "Participant number 75\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4783 reward + 0.2307 decision_duration + 1.0 value_stay[t] + -0.1575 value_stay^2 + -0.6019 value_stay*reward + -0.5316 value_stay*decision_duration + -0.2378 reward^2 + 0.4715 reward*decision_duration + 0.1922 reward*value_stay + 0.159 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 30.6629\n",
      "Participant number 77\n",
      "value_stay[t+1] = 0.1859 1 + 0.7982 value_stay[t] + 0.285 reward + 0.2133 decision_duration + 1.0 value_stay[t] + -0.3332 value_stay*decision_duration + -0.4378 value_stay*value_stay + -0.125 reward^2 + 0.288 reward*decision_duration + 0.1829 decision_duration^2 + -0.3594 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 48.6739\n",
      "Participant number 78\n",
      "value_stay[t+1] = 0.178 1 + 0.8515 value_stay[t] + 0.4009 reward + 0.1974 decision_duration + 1.0 value_stay[t] + -0.1148 value_stay^2 + -0.2773 value_stay*decision_duration + -0.3937 value_stay*value_stay + -0.2844 reward^2 + 0.4063 reward*decision_duration + 0.17 decision_duration^2 + -0.4027 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 36.6262\n",
      "Participant number 79\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4631 reward + 0.3483 decision_duration + 1.0 value_stay[t] + -0.2078 value_stay^2 + -0.4179 value_stay*reward + -0.3371 value_stay*decision_duration + -0.1807 value_stay*value_stay + -0.3019 reward^2 + 0.4675 reward*decision_duration + 0.1771 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 39.6820\n",
      "Participant number 80\n",
      "value_stay[t+1] = 0.2476 1 + 0.8287 value_stay[t] + 0.1695 reward + 0.2074 decision_duration + 1.0 value_stay[t] + -0.2388 value_stay*decision_duration + -0.4929 value_stay*value_stay + 0.1744 reward*decision_duration + 0.1272 decision_duration^2 + -0.496 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 65.0591\n",
      "Participant number 81\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4771 reward + 0.2463 decision_duration + 1.0 value_stay[t] + -0.2245 value_stay^2 + -0.3674 value_stay*reward + -0.3848 value_stay*decision_duration + -0.1714 value_stay*value_stay + -0.3181 reward^2 + 0.4577 reward*decision_duration + 0.1868 reward*value_stay + 0.1283 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 25.7700\n",
      "Participant number 82\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4993 reward + 0.2232 decision_duration + 1.0 value_stay[t] + -0.223 value_stay^2 + -0.3332 value_stay*reward + -0.3711 value_stay*decision_duration + -0.2091 value_stay*value_stay + -0.3507 reward^2 + 0.4849 reward*decision_duration + 0.1773 reward*value_stay + 0.152 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 38.7480\n",
      "Participant number 84\n",
      "value_stay[t+1] = 0.2178 1 + 0.8305 value_stay[t] + 0.1563 reward + 0.2141 decision_duration + 1.0 value_stay[t] + -0.3569 value_stay*decision_duration + -0.4257 value_stay*value_stay + 0.1649 reward*decision_duration + 0.1569 decision_duration^2 + -0.3686 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 41.0613\n",
      "Participant number 86\n",
      "value_stay[t+1] = 0.1547 1 + 0.837 value_stay[t] + 0.4097 reward + 0.1869 decision_duration + 1.0 value_stay[t] + -0.1403 value_stay^2 + -0.2558 value_stay*decision_duration + -0.3556 value_stay*value_stay + -0.2957 reward^2 + 0.4065 reward*decision_duration + 0.168 decision_duration^2 + -0.3039 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 46.7380\n",
      "Participant number 90\n",
      "value_stay[t+1] = 0.1546 1 + 0.8418 value_stay[t] + 0.4168 reward + 0.1873 decision_duration + 1.0 value_stay[t] + -0.1402 value_stay^2 + -0.2579 value_stay*decision_duration + -0.3625 value_stay*value_stay + -0.2957 reward^2 + 0.4211 reward*decision_duration + 0.1741 decision_duration^2 + -0.3286 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 37.4791\n",
      "Participant number 92\n",
      "value_stay[t+1] = 0.217 1 + 0.817 value_stay[t] + 0.2587 reward + 0.2124 decision_duration + 1.0 value_stay[t] + -0.3214 value_stay*decision_duration + -0.4478 value_stay*value_stay + -0.1248 reward^2 + 0.2704 reward*decision_duration + 0.1552 decision_duration^2 + -0.4068 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 48.2351\n",
      "Participant number 93\n",
      "value_stay[t+1] = 0.2026 1 + 0.7942 value_stay[t] + 0.3256 reward + 0.2112 decision_duration + 1.0 value_stay[t] + -0.3215 value_stay*decision_duration + -0.4416 value_stay*value_stay + -0.2102 reward^2 + 0.3352 reward*decision_duration + 0.1597 decision_duration^2 + -0.3537 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 47.4824\n",
      "Participant number 95\n",
      "value_stay[t+1] = 0.1089 1 + 1.0 value_stay[t] + 0.4422 reward + 0.1558 decision_duration + 1.0 value_stay[t] + -0.1071 value_stay^2 + -0.4278 value_stay*reward + -0.4879 value_stay*decision_duration + -0.2237 value_stay*value_stay + -0.2567 reward^2 + 0.433 reward*decision_duration + 0.143 reward*value_stay + 0.2164 decision_duration^2 + -0.2278 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 25.8592\n",
      "Participant number 97\n",
      "value_stay[t+1] = 0.1309 1 + 0.8872 value_stay[t] + 0.469 reward + 0.1743 decision_duration + 1.0 value_stay[t] + -0.1115 value_stay^2 + -0.2416 value_stay*reward + -0.3551 value_stay*decision_duration + -0.277 value_stay*value_stay + -0.3379 reward^2 + 0.4682 reward*decision_duration + 0.1124 reward*value_stay + 0.1854 decision_duration^2 + -0.2609 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 46.8273\n",
      "Participant number 99\n",
      "value_stay[t+1] = 0.1702 1 + 0.8647 value_stay[t] + 0.3614 reward + 0.1982 decision_duration + 1.0 value_stay[t] + -0.0989 value_stay^2 + -0.3085 value_stay*decision_duration + -0.3832 value_stay*value_stay + -0.225 reward^2 + 0.3546 reward*decision_duration + 0.186 decision_duration^2 + -0.4128 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 48.3886\n",
      "Participant number 100\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.3503 reward + 1.0 value_stay[t] + 0.0142 value_stay^2 + -0.6395 value_stay*reward + -0.0334 value_stay*value_stay + 0.3489 reward*decision_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.1343 reward + 1.0 value_exit[t] + -0.2035 reward*value_exit \n",
      "beta(value) = 22.6739\n",
      "Participant number 101\n",
      "value_stay[t+1] = 0.1721 1 + 0.8293 value_stay[t] + 0.3891 reward + 0.1928 decision_duration + 1.0 value_stay[t] + -0.0989 value_stay^2 + -0.2557 value_stay*decision_duration + -0.3992 value_stay*value_stay + -0.2542 reward^2 + 0.3806 reward*decision_duration + 0.1699 decision_duration^2 + -0.3635 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 50.9289\n",
      "Participant number 103\n",
      "value_stay[t+1] = 0.1674 1 + 0.8482 value_stay[t] + 0.4238 reward + 0.171 decision_duration + 1.0 value_stay[t] + -0.1812 value_stay^2 + -0.2405 value_stay*decision_duration + -0.3291 value_stay*value_stay + -0.3511 reward^2 + 0.4141 reward*decision_duration + 0.1473 decision_duration^2 + -0.2586 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 40.8266\n",
      "Participant number 104\n",
      "value_stay[t+1] = 0.2079 1 + 0.7744 value_stay[t] + 0.3367 reward + 0.2056 decision_duration + 1.0 value_stay[t] + -0.3096 value_stay*decision_duration + -0.4426 value_stay*value_stay + -0.2352 reward^2 + 0.3426 reward*decision_duration + 0.1503 decision_duration^2 + -0.3067 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 38.5117\n",
      "Participant number 105\n",
      "value_stay[t+1] = 0.2249 1 + 0.8248 value_stay[t] + 0.2502 reward + 0.1953 decision_duration + 1.0 value_stay[t] + -0.2452 value_stay*decision_duration + -0.4469 value_stay*value_stay + 0.2513 reward*decision_duration + -0.2139 reward*value_stay + 0.1258 decision_duration^2 + -0.4028 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 60.9016\n",
      "Participant number 109\n",
      "value_stay[t+1] = 0.1696 1 + 0.8515 value_stay[t] + 0.3962 reward + 0.1933 decision_duration + 1.0 value_stay[t] + -0.1116 value_stay^2 + -0.2771 value_stay*decision_duration + -0.3792 value_stay*value_stay + -0.2847 reward^2 + 0.4021 reward*decision_duration + 0.169 decision_duration^2 + -0.3718 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 48.6836\n",
      "Participant number 110\n",
      "value_stay[t+1] = 0.1367 1 + 0.8596 value_stay[t] + 0.4507 reward + 0.1573 decision_duration + 1.0 value_stay[t] + -0.1347 value_stay^2 + -0.1087 value_stay*reward + -0.179 value_stay*decision_duration + -0.3105 value_stay*value_stay + -0.3169 reward^2 + 0.4544 reward*decision_duration + 0.1363 decision_duration^2 + -0.2649 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 55.8993\n",
      "Participant number 112\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.3801 reward + 0.3135 decision_duration + 1.0 value_stay[t] + -0.5929 value_stay*reward + -0.2957 value_stay*decision_duration + 0.3813 reward*decision_duration + -0.2743 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 52.3687\n",
      "Participant number 113\n",
      "value_stay[t+1] = 0.1524 1 + 0.8356 value_stay[t] + 0.3699 reward + 0.1918 decision_duration + 1.0 value_stay[t] + -0.1198 value_stay^2 + -0.2718 value_stay*decision_duration + -0.366 value_stay*value_stay + -0.228 reward^2 + 0.3773 reward*decision_duration + 0.1801 decision_duration^2 + -0.3224 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 38.8428\n",
      "Participant number 114\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4526 reward + 0.3299 decision_duration + 1.0 value_stay[t] + -0.2231 value_stay^2 + -0.3423 value_stay*reward + -0.2788 value_stay*decision_duration + -0.2045 value_stay*value_stay + -0.2959 reward^2 + 0.4487 reward*decision_duration + 0.1328 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 45.9770\n",
      "Participant number 115\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4537 reward + 0.3672 decision_duration + 1.0 value_stay[t] + -0.2305 value_stay^2 + -0.3251 value_stay*reward + -0.3401 value_stay*decision_duration + -0.2242 value_stay*value_stay + -0.3242 reward^2 + 0.4659 reward*decision_duration + 0.1649 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 29.2079\n",
      "Participant number 116\n",
      "value_stay[t+1] = 0.1298 1 + 0.8804 value_stay[t] + 0.4626 reward + 0.1718 decision_duration + 1.0 value_stay[t] + -0.1138 value_stay^2 + -0.1551 value_stay*reward + -0.3161 value_stay*decision_duration + -0.2844 value_stay*value_stay + -0.3138 reward^2 + 0.4669 reward*decision_duration + 0.1758 decision_duration^2 + -0.2619 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 49.7096\n",
      "Participant number 120\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4605 reward + 0.2199 decision_duration + 1.0 value_stay[t] + -0.2181 value_stay^2 + -0.2397 value_stay*reward + -0.293 value_stay*decision_duration + -0.2631 value_stay*value_stay + -0.3049 reward^2 + 0.4472 reward*decision_duration + 0.1079 reward*value_stay + 0.1312 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 51.6488\n",
      "Participant number 121\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.3422 reward + 0.2722 decision_duration + 1.0 value_stay[t] + -0.2894 value_stay^2 + -0.2754 value_stay*decision_duration + -0.315 value_stay*value_stay + -0.196 reward^2 + 0.343 reward*decision_duration + 0.1115 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 46.6395\n",
      "Participant number 122\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4522 reward + 0.2146 decision_duration + 1.0 value_stay[t] + -0.2395 value_stay^2 + -0.1494 value_stay*reward + -0.2275 value_stay*decision_duration + -0.284 value_stay*value_stay + -0.2776 reward^2 + 0.4383 reward*decision_duration + 0.1155 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 55.9762\n",
      "Participant number 123\n",
      "value_stay[t+1] = 0.1903 1 + 0.7966 value_stay[t] + 0.2826 reward + 0.2088 decision_duration + 1.0 value_stay[t] + -0.3344 value_stay*decision_duration + -0.432 value_stay*value_stay + -0.1327 reward^2 + 0.2931 reward*decision_duration + 0.1781 decision_duration^2 + -0.3425 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 46.9802\n",
      "Participant number 124\n",
      "value_stay[t+1] = 0.2015 1 + 0.8177 value_stay[t] + 0.3455 reward + 0.1932 decision_duration + 1.0 value_stay[t] + -0.3198 value_stay*decision_duration + -0.4121 value_stay*value_stay + -0.274 reward^2 + 0.3387 reward*decision_duration + 0.1543 decision_duration^2 + -0.3508 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 40.2450\n",
      "Participant number 125\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.469 reward + 0.2093 decision_duration + 1.0 value_stay[t] + -0.2447 value_stay^2 + -0.2181 value_stay*reward + -0.2515 value_stay*decision_duration + -0.2756 value_stay*value_stay + -0.3382 reward^2 + 0.4672 reward*decision_duration + 0.1324 reward*value_stay + 0.1283 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 52.2739\n",
      "Participant number 126\n",
      "value_stay[t+1] = 0.1501 1 + 1.0 value_stay[t] + 0.2309 reward + 0.2057 decision_duration + 1.0 value_stay[t] + -0.2193 value_stay*reward + -0.5584 value_stay*decision_duration + -0.3103 value_stay*value_stay + 0.2468 reward*decision_duration + 0.2302 decision_duration^2 + -0.422 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 36.0983\n",
      "Participant number 127\n",
      "value_stay[t+1] = 0.1674 1 + 1.0 value_stay[t] + 0.261 reward + 0.2163 decision_duration + 1.0 value_stay[t] + -0.2796 value_stay*reward + -0.6028 value_stay*decision_duration + -0.2177 value_stay*value_stay + 0.2653 reward*decision_duration + 0.2375 decision_duration^2 + -0.5593 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 34.8890\n",
      "Participant number 128\n",
      "value_stay[t+1] = 0.1653 1 + 0.8608 value_stay[t] + 0.4082 reward + 0.1787 decision_duration + 1.0 value_stay[t] + -0.1472 value_stay^2 + -0.2048 value_stay*decision_duration + -0.3583 value_stay*value_stay + -0.308 reward^2 + 0.3983 reward*decision_duration + 0.1434 decision_duration^2 + -0.3526 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 59.1153\n",
      "Participant number 130\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.3938 reward + 0.1304 decision_duration + 1.0 value_stay[t] + -0.6649 value_stay*reward + -0.4226 value_stay*decision_duration + 0.384 reward*decision_duration + 0.1628 decision_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.1087 reward + 1.0 value_exit[t] + -0.1664 reward*value_exit \n",
      "beta(value) = 40.8734\n",
      "Participant number 131\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 1.0 value_stay[t] + -0.7731 value_stay*reward + 2.1034 reward*decision_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.1102 reward + 1.0 value_exit[t] + -0.1688 reward*value_exit \n",
      "beta(value) = 54.2100\n",
      "Participant number 132\n",
      "value_stay[t+1] = 0.2233 1 + 0.8332 value_stay[t] + 0.1579 reward + 0.2163 decision_duration + 1.0 value_stay[t] + -0.3553 value_stay*decision_duration + -0.4341 value_stay*value_stay + 0.1655 reward*decision_duration + 0.1571 decision_duration^2 + -0.3962 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 46.3691\n",
      "Participant number 133\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4595 reward + 0.2502 decision_duration + 1.0 value_stay[t] + -0.2163 value_stay^2 + -0.3176 value_stay*reward + -0.3794 value_stay*decision_duration + -0.1974 value_stay*value_stay + -0.3087 reward^2 + 0.4561 reward*decision_duration + 0.1547 reward*value_stay + 0.127 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 29.4252\n",
      "Participant number 134\n",
      "value_stay[t+1] = 0.1741 1 + 0.8547 value_stay[t] + 0.4027 reward + 0.1893 decision_duration + 1.0 value_stay[t] + -0.1327 value_stay^2 + -0.2769 value_stay*decision_duration + -0.3572 value_stay*value_stay + -0.3151 reward^2 + 0.3941 reward*decision_duration + 0.1557 decision_duration^2 + -0.3334 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 45.4655\n",
      "Participant number 135\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.1968 reward + 0.2484 decision_duration + 1.0 value_stay[t] + -0.372 value_stay^2 + -0.2056 value_stay*value_stay + 0.1454 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 58.9214\n",
      "Participant number 139\n",
      "value_stay[t+1] = 0.1798 1 + 0.8442 value_stay[t] + 0.3897 reward + 0.1843 decision_duration + 1.0 value_stay[t] + -0.1141 value_stay^2 + -0.2232 value_stay*decision_duration + -0.3799 value_stay*value_stay + -0.2943 reward^2 + 0.3811 reward*decision_duration + 0.1387 decision_duration^2 + -0.347 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 54.9667\n",
      "Participant number 140\n",
      "value_stay[t+1] = 0.1959 1 + 0.7909 value_stay[t] + 0.3363 reward + 0.2063 decision_duration + 1.0 value_stay[t] + -0.3223 value_stay*decision_duration + -0.435 value_stay*value_stay + -0.2245 reward^2 + 0.3435 reward*decision_duration + 0.1654 decision_duration^2 + -0.3349 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 44.1109\n",
      "Participant number 142\n",
      "value_stay[t+1] = 0.1487 1 + 0.858 value_stay[t] + 0.4453 reward + 0.1739 decision_duration + 1.0 value_stay[t] + -0.1372 value_stay^2 + -0.1309 value_stay*reward + -0.2925 value_stay*decision_duration + -0.3153 value_stay*value_stay + -0.3541 reward^2 + 0.4462 reward*decision_duration + 0.1047 reward*value_stay + 0.1714 decision_duration^2 + -0.2735 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 30.6922\n",
      "Participant number 143\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4156 reward + 0.3413 decision_duration + 1.0 value_stay[t] + -0.2538 value_stay^2 + -0.4743 value_stay*reward + -0.392 value_stay*decision_duration + -0.2207 reward^2 + 0.4246 reward*decision_duration + 0.156 reward*value_stay \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.1182 reward + 1.0 value_exit[t] + -0.1799 reward*value_exit \n",
      "beta(value) = 19.9040\n",
      "Participant number 144\n",
      "value_stay[t+1] = 0.2176 1 + 0.7983 value_stay[t] + 0.3336 reward + 0.2142 decision_duration + 1.0 value_stay[t] + -0.306 value_stay*decision_duration + -0.4626 value_stay*value_stay + -0.2235 reward^2 + 0.3412 reward*decision_duration + 0.1492 decision_duration^2 + -0.3978 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 51.2161\n",
      "Participant number 146\n",
      "value_stay[t+1] = 0.1936 1 + 0.7916 value_stay[t] + 0.3645 reward + 0.2708 decision_duration + 1.0 value_stay[t] + -0.2048 value_stay^2 + 0.1977 value_stay*reward + -0.4523 value_stay*value_stay + -0.3497 reward^2 + 0.3727 reward*decision_duration + -0.3825 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 47.6367\n",
      "Participant number 148\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4288 reward + 0.3345 decision_duration + 1.0 value_stay[t] + -0.2069 value_stay^2 + -0.5623 value_stay*reward + -0.4056 value_stay*decision_duration + -0.2097 reward^2 + 0.4831 reward*decision_duration + 0.1572 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 34.2828\n",
      "Participant number 152\n",
      "value_stay[t+1] = 0.1579 1 + 0.8688 value_stay[t] + 0.4261 reward + 0.174 decision_duration + 1.0 value_stay[t] + -0.115 value_stay^2 + -0.1082 value_stay*reward + -0.3208 value_stay*decision_duration + -0.3093 value_stay*value_stay + -0.3037 reward^2 + 0.4171 reward*decision_duration + 0.1678 decision_duration^2 + -0.2734 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 43.3536\n",
      "Participant number 153\n",
      "value_stay[t+1] = 0.1281 1 + 0.8898 value_stay[t] + 0.4745 reward + 0.1722 decision_duration + 1.0 value_stay[t] + -0.1061 value_stay^2 + -0.2403 value_stay*reward + -0.3667 value_stay*decision_duration + -0.2785 value_stay*value_stay + -0.3434 reward^2 + 0.4615 reward*decision_duration + 0.1241 reward*value_stay + 0.1977 decision_duration^2 + -0.2766 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 35.6698\n",
      "Participant number 154\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.464 reward + 0.3012 decision_duration + 1.0 value_stay[t] + -0.223 value_stay^2 + -0.4465 value_stay*reward + -0.2588 value_stay*decision_duration + -0.1397 value_stay*value_stay + -0.2879 reward^2 + 0.4487 reward*decision_duration + 0.1769 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 47.5341\n",
      "Participant number 160\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4502 reward + 0.231 decision_duration + 1.0 value_stay[t] + -0.2482 value_stay^2 + -0.1622 value_stay*reward + -0.3461 value_stay*value_stay + -0.2831 reward^2 + 0.4578 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 61.4696\n",
      "Participant number 161\n",
      "value_stay[t+1] = 0.1629 1 + 0.8471 value_stay[t] + 0.4282 reward + 0.1805 decision_duration + 1.0 value_stay[t] + -0.1613 value_stay^2 + -0.247 value_stay*decision_duration + -0.3466 value_stay*value_stay + -0.3369 reward^2 + 0.4177 reward*decision_duration + 0.1558 decision_duration^2 + -0.2954 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 45.0997\n",
      "Participant number 162\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.2961 reward + 0.3528 decision_duration + 1.0 value_stay[t] + -0.2547 value_stay^2 + -0.1834 value_stay*decision_duration + -0.4002 value_stay*value_stay + -0.1451 reward^2 + 0.3166 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 47.8620\n",
      "Participant number 164\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4582 reward + 0.2096 decision_duration + 1.0 value_stay[t] + -0.2522 value_stay^2 + -0.3025 value_stay*reward + -0.2684 value_stay*value_stay + -0.2992 reward^2 + 0.451 reward*decision_duration + 0.1306 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 57.2442\n",
      "Participant number 165\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4342 reward + 0.3608 decision_duration + 1.0 value_stay[t] + -0.3315 value_stay^2 + -0.2238 value_stay*decision_duration + -0.3175 value_stay*value_stay + -0.3424 reward^2 + 0.4265 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 30.3832\n",
      "Participant number 166\n",
      "value_stay[t+1] = 0.1603 1 + 0.859 value_stay[t] + 0.429 reward + 0.1832 decision_duration + 1.0 value_stay[t] + -0.1518 value_stay^2 + -0.2531 value_stay*decision_duration + -0.3538 value_stay*value_stay + -0.3289 reward^2 + 0.4197 reward*decision_duration + 0.1644 decision_duration^2 + -0.3393 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 50.8457\n",
      "Participant number 167\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4765 reward + 0.2587 decision_duration + 1.0 value_stay[t] + -0.2385 value_stay^2 + -0.2624 value_stay*reward + -0.3471 value_stay*decision_duration + -0.232 value_stay*value_stay + -0.3373 reward^2 + 0.4598 reward*decision_duration + 0.1378 reward*value_stay + 0.1164 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 41.6767\n",
      "Participant number 168\n",
      "value_stay[t+1] = 0.1577 1 + 1.0 value_stay[t] + 0.2407 reward + 0.2039 decision_duration + 1.0 value_stay[t] + -0.2042 value_stay*reward + -0.4922 value_stay*decision_duration + -0.3995 value_stay*value_stay + 0.2458 reward*decision_duration + 0.2126 decision_duration^2 + -0.4174 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 44.8361\n",
      "Participant number 171\n",
      "value_stay[t+1] = 0.2121 1 + 0.7945 value_stay[t] + 0.3344 reward + 0.208 decision_duration + 1.0 value_stay[t] + -0.327 value_stay*decision_duration + -0.4337 value_stay*value_stay + -0.2504 reward^2 + 0.3424 reward*decision_duration + 0.1471 decision_duration^2 + -0.332 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 42.6665\n",
      "Participant number 172\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4832 reward + 0.2303 decision_duration + 1.0 value_stay[t] + -0.2181 value_stay^2 + -0.1679 value_stay*reward + -0.2964 value_stay*decision_duration + -0.3109 value_stay*value_stay + -0.3017 reward^2 + 0.4669 reward*decision_duration + 0.1352 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 54.7934\n",
      "Participant number 174\n",
      "value_stay[t+1] = 0.2293 1 + 1.0 value_stay[t] + 0.2586 reward + 0.2046 decision_duration + 1.0 value_stay[t] + -0.3633 value_stay*decision_duration + -0.5309 value_stay*value_stay + 0.2664 reward*decision_duration + -0.3261 reward*value_stay + 0.1383 decision_duration^2 + -0.5131 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 49.1704\n",
      "Participant number 176\n",
      "value_stay[t+1] = 0.1904 1 + 0.8419 value_stay[t] + 0.3891 reward + 0.196 decision_duration + 1.0 value_stay[t] + -0.1163 value_stay^2 + -0.2747 value_stay*decision_duration + -0.3809 value_stay*value_stay + -0.3097 reward^2 + 0.3932 reward*decision_duration + 0.1419 decision_duration^2 + -0.3438 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 43.5474\n",
      "Participant number 177\n",
      "value_stay[t+1] = 0.1608 1 + 0.8721 value_stay[t] + 0.4303 reward + 0.1692 decision_duration + 1.0 value_stay[t] + -0.1928 value_stay^2 + -0.2464 value_stay*decision_duration + -0.3219 value_stay*value_stay + -0.3493 reward^2 + 0.4187 reward*decision_duration + 0.1606 decision_duration^2 + -0.3074 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 30.0384\n",
      "Participant number 181\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4102 reward + 0.2593 decision_duration + 1.0 value_stay[t] + -0.5847 value_stay*reward + -0.5753 value_stay*decision_duration + -0.1127 value_stay*value_stay + -0.137 reward^2 + 0.3957 reward*decision_duration + 0.1266 reward*value_stay + 0.1421 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 24.5841\n",
      "Participant number 182\n",
      "value_stay[t+1] = 0.1991 1 + 0.7686 value_stay[t] + 0.3181 reward + 0.1986 decision_duration + 1.0 value_stay[t] + -0.2955 value_stay*decision_duration + -0.4399 value_stay*value_stay + -0.1958 reward^2 + 0.3108 reward*decision_duration + 0.1585 decision_duration^2 + -0.2906 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 29.6642\n",
      "Participant number 184\n",
      "value_stay[t+1] = 0.1661 1 + 1.0 value_stay[t] + 0.2515 reward + 1.0 value_stay[t] + -0.2573 value_stay^2 + -0.4181 value_stay*reward + -0.1666 value_stay*value_stay + 0.1387 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 19.9594\n",
      "Participant number 185\n",
      "value_stay[t+1] = 0.1945 1 + 0.8069 value_stay[t] + 0.3573 reward + 0.2028 decision_duration + 1.0 value_stay[t] + 0.0018 value_stay^2 + -0.3059 value_stay*decision_duration + -0.4279 value_stay*value_stay + -0.2671 reward^2 + 0.3632 reward*decision_duration + 0.1565 decision_duration^2 + -0.36 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 42.4942\n",
      "Participant number 186\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4088 reward + 0.2709 decision_duration + 1.0 value_stay[t] + -0.5975 value_stay*reward + -0.5519 value_stay*decision_duration + -0.1215 value_stay*value_stay + -0.1301 reward^2 + 0.39 reward*decision_duration + 0.1328 reward*value_stay + 0.1199 decision_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.1139 reward + 1.0 value_exit[t] + -0.1738 reward*value_exit \n",
      "beta(value) = 25.1444\n",
      "Participant number 188\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4561 reward + 0.2661 decision_duration + 1.0 value_stay[t] + -0.1559 value_stay^2 + -0.5916 value_stay*reward + -0.5052 value_stay*decision_duration + -0.2141 reward^2 + 0.438 reward*decision_duration + 0.1764 reward*value_stay + 0.1099 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 30.2103\n",
      "Participant number 189\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4403 reward + 0.381 decision_duration + 1.0 value_stay[t] + -0.1958 value_stay^2 + -0.4022 value_stay*reward + -0.4131 value_stay*decision_duration + -0.1552 value_stay*value_stay + -0.2695 reward^2 + 0.4399 reward*decision_duration + 0.1443 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 29.3418\n",
      "Participant number 191\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4491 reward + 0.3474 decision_duration + 1.0 value_stay[t] + -0.1634 value_stay^2 + -0.4962 value_stay*reward + -0.3764 value_stay*decision_duration + -0.1362 value_stay*value_stay + -0.2419 reward^2 + 0.444 reward*decision_duration + 0.156 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 38.9699\n",
      "Participant number 194\n",
      "value_stay[t+1] = 0.1869 1 + 0.8344 value_stay[t] + 0.3901 reward + 0.1912 decision_duration + 1.0 value_stay[t] + -0.1187 value_stay^2 + -0.2622 value_stay*decision_duration + -0.384 value_stay*value_stay + -0.2972 reward^2 + 0.3936 reward*decision_duration + 0.1489 decision_duration^2 + -0.336 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 35.5984\n",
      "Participant number 195\n",
      "value_stay[t+1] = 0.1606 1 + 0.8376 value_stay[t] + 0.4389 reward + 0.1794 decision_duration + 1.0 value_stay[t] + -0.1737 value_stay^2 + -0.229 value_stay*decision_duration + -0.3447 value_stay*value_stay + -0.3505 reward^2 + 0.441 reward*decision_duration + 0.1505 decision_duration^2 + -0.2773 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 33.5595\n",
      "Participant number 198\n",
      "value_stay[t+1] = 0.1695 1 + 0.8559 value_stay[t] + 0.4219 reward + 0.1924 decision_duration + 1.0 value_stay[t] + -0.1402 value_stay^2 + -0.2494 value_stay*decision_duration + -0.3724 value_stay*value_stay + -0.3216 reward^2 + 0.427 reward*decision_duration + 0.1559 decision_duration^2 + -0.3684 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 55.9740\n",
      "Participant number 199\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4546 reward + 0.3034 decision_duration + 1.0 value_stay[t] + -0.1996 value_stay^2 + -0.3165 value_stay*reward + -0.243 value_stay*decision_duration + -0.1931 value_stay*value_stay + -0.246 reward^2 + 0.4419 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 47.0547\n",
      "Participant number 202\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4547 reward + 0.3043 decision_duration + 1.0 value_stay[t] + -0.1908 value_stay^2 + -0.4672 value_stay*reward + -0.2705 value_stay*decision_duration + -0.1572 value_stay*value_stay + -0.257 reward^2 + 0.4496 reward*decision_duration + 0.1623 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 46.7275\n",
      "Participant number 206\n",
      "value_stay[t+1] = 0.2009 1 + 0.7725 value_stay[t] + 0.3415 reward + 0.2048 decision_duration + 1.0 value_stay[t] + -0.2792 value_stay*decision_duration + -0.4533 value_stay*value_stay + -0.219 reward^2 + 0.3354 reward*decision_duration + 0.1528 decision_duration^2 + -0.3298 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 52.7427\n",
      "Participant number 208\n",
      "value_stay[t+1] = 0.1421 1 + 0.7788 value_stay[t] + 0.2652 reward + 0.1749 decision_duration + 1.0 value_stay[t] + -0.266 value_stay*decision_duration + -0.5252 value_stay*value_stay + -0.1188 reward^2 + 0.2787 reward*decision_duration + 0.1638 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 34.9129\n",
      "Participant number 209\n",
      "value_stay[t+1] = 0.207 1 + 0.7847 value_stay[t] + 0.3285 reward + 0.2094 decision_duration + 1.0 value_stay[t] + -0.3187 value_stay*decision_duration + -0.4476 value_stay*value_stay + -0.2176 reward^2 + 0.3358 reward*decision_duration + 0.1575 decision_duration^2 + -0.3368 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 34.2665\n",
      "Participant number 211\n",
      "value_stay[t+1] = 0.1479 1 + 0.8286 value_stay[t] + 0.4158 reward + 0.251 decision_duration + 1.0 value_stay[t] + -0.1749 value_stay^2 + -0.3715 value_stay*value_stay + -0.3201 reward^2 + 0.4329 reward*decision_duration + -0.325 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 61.9575\n",
      "Participant number 214\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4042 reward + 0.1449 decision_duration + 1.0 value_stay[t] + -0.6942 value_stay*reward + -0.4111 value_stay*decision_duration + 0.3934 reward*decision_duration + 0.141 decision_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.1117 reward + 1.0 value_exit[t] + -0.1707 reward*value_exit \n",
      "beta(value) = 44.2649\n",
      "Participant number 215\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4603 reward + 0.3634 decision_duration + 1.0 value_stay[t] + -0.1764 value_stay^2 + -0.4341 value_stay*reward + -0.3704 value_stay*decision_duration + -0.2026 value_stay*value_stay + -0.2915 reward^2 + 0.4744 reward*decision_duration + 0.1748 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 38.8577\n",
      "Participant number 216\n",
      "value_stay[t+1] = 0.1939 1 + 0.8463 value_stay[t] + 0.3706 reward + 0.1807 decision_duration + 1.0 value_stay[t] + -0.1511 value_stay^2 + -0.2486 value_stay*decision_duration + -0.36 value_stay*value_stay + -0.2955 reward^2 + 0.3581 reward*decision_duration + 0.1339 decision_duration^2 + -0.3017 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 26.8505\n",
      "Participant number 218\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4612 reward + 0.3596 decision_duration + 1.0 value_stay[t] + -0.23 value_stay^2 + -0.1553 value_stay*reward + -0.266 value_stay*decision_duration + -0.3338 value_stay*value_stay + -0.3092 reward^2 + 0.4656 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 46.9437\n",
      "Participant number 219\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4596 reward + 0.241 decision_duration + 1.0 value_stay[t] + -0.1931 value_stay^2 + -0.6565 value_stay*reward + -0.2372 value_stay*decision_duration + -0.1935 reward^2 + 0.4856 reward*decision_duration + 0.1631 reward*value_stay \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.105 reward + 1.0 value_exit[t] + -0.1609 reward*value_exit \n",
      "beta(value) = 47.2754\n",
      "Participant number 220\n",
      "value_stay[t+1] = 0.1694 1 + 0.8305 value_stay[t] + 0.4112 reward + 0.1878 decision_duration + 1.0 value_stay[t] + -0.1225 value_stay^2 + -0.2631 value_stay*decision_duration + -0.3701 value_stay*value_stay + -0.3127 reward^2 + 0.4134 reward*decision_duration + 0.1599 decision_duration^2 + -0.3108 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 45.8310\n",
      "Participant number 221\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4392 reward + 0.3049 decision_duration + 1.0 value_stay[t] + -0.2688 value_stay^2 + -0.4814 value_stay*reward + -0.319 value_stay*decision_duration + -0.2496 reward^2 + 0.4606 reward*decision_duration + 0.1553 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 34.4473\n",
      "Participant number 222\n",
      "value_stay[t+1] = 0.2062 1 + 0.7718 value_stay[t] + 0.3083 reward + 0.2025 decision_duration + 1.0 value_stay[t] + -0.2889 value_stay*decision_duration + -0.4475 value_stay*value_stay + -0.1851 reward^2 + 0.3055 reward*decision_duration + 0.15 decision_duration^2 + -0.3069 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 42.2291\n",
      "Participant number 223\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.283 reward + 0.3763 decision_duration + 1.0 value_stay[t] + -0.258 value_stay^2 + -0.2369 value_stay*decision_duration + -0.3741 value_stay*value_stay + -0.1295 reward^2 + 0.2933 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 42.4288\n",
      "Participant number 225\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4524 reward + 0.249 decision_duration + 1.0 value_stay[t] + -0.252 value_stay^2 + -0.5523 value_stay*reward + -0.2213 value_stay*decision_duration + -0.2375 reward^2 + 0.4773 reward*decision_duration + 0.1689 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 44.6581\n",
      "Participant number 226\n",
      "value_stay[t+1] = 0.1426 1 + 0.8818 value_stay[t] + 0.4543 reward + 0.1659 decision_duration + 1.0 value_stay[t] + -0.0931 value_stay^2 + -0.2154 value_stay*reward + -0.3606 value_stay*decision_duration + -0.2737 value_stay*value_stay + -0.2907 reward^2 + 0.4431 reward*decision_duration + 0.1776 decision_duration^2 + -0.2352 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 38.1563\n",
      "Participant number 230\n",
      "value_stay[t+1] = 0.2211 1 + 0.8107 value_stay[t] + 0.1722 reward + 0.2153 decision_duration + 1.0 value_stay[t] + -0.3227 value_stay*decision_duration + -0.4522 value_stay*value_stay + 0.179 reward*decision_duration + 0.1564 decision_duration^2 + -0.3877 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 50.7504\n",
      "Participant number 231\n",
      "value_stay[t+1] = 0.158 1 + 0.806 value_stay[t] + 0.2854 reward + 0.1682 decision_duration + 1.0 value_stay[t] + -0.252 value_stay*decision_duration + -0.5947 value_stay*value_stay + -0.1635 reward^2 + 0.2923 reward*decision_duration + 0.1503 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 29.2361\n",
      "Participant number 233\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4828 reward + 0.2376 decision_duration + 1.0 value_stay[t] + -0.2345 value_stay^2 + -0.2369 value_stay*reward + -0.3412 value_stay*decision_duration + -0.2674 value_stay*value_stay + -0.3476 reward^2 + 0.466 reward*decision_duration + 0.1385 reward*value_stay + 0.1419 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 35.0219\n",
      "Participant number 235\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4649 reward + 0.2999 decision_duration + 1.0 value_stay[t] + -0.1992 value_stay^2 + -0.4022 value_stay*reward + -0.226 value_stay*decision_duration + -0.225 value_stay*value_stay + -0.295 reward^2 + 0.4697 reward*decision_duration + 0.1625 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 49.1598\n",
      "Participant number 236\n",
      "value_stay[t+1] = 0.1977 1 + 0.7869 value_stay[t] + 0.3189 reward + 0.2113 decision_duration + 1.0 value_stay[t] + -0.3232 value_stay*decision_duration + -0.4483 value_stay*value_stay + -0.1824 reward^2 + 0.3248 reward*decision_duration + 0.1708 decision_duration^2 + -0.3497 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 38.8433\n",
      "Participant number 238\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4664 reward + 0.2025 decision_duration + 1.0 value_stay[t] + -0.243 value_stay^2 + -0.3324 value_stay*reward + -0.2525 value_stay*value_stay + -0.2914 reward^2 + 0.4494 reward*decision_duration + 0.1209 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 54.0875\n",
      "Participant number 239\n",
      "value_stay[t+1] = 0.1755 1 + 0.8326 value_stay[t] + 0.3973 reward + 0.1919 decision_duration + 1.0 value_stay[t] + -0.1134 value_stay^2 + -0.2699 value_stay*decision_duration + -0.3812 value_stay*value_stay + -0.2943 reward^2 + 0.4026 reward*decision_duration + 0.1603 decision_duration^2 + -0.3313 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 40.2797\n",
      "Participant number 240\n",
      "value_stay[t+1] = 0.1468 1 + 0.8528 value_stay[t] + 0.4476 reward + 0.1756 decision_duration + 1.0 value_stay[t] + -0.2835 value_stay*reward + -0.3941 value_stay*decision_duration + -0.2982 value_stay*value_stay + -0.2573 reward^2 + 0.4459 reward*decision_duration + 0.1732 decision_duration^2 + -0.2135 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 38.9015\n",
      "Participant number 241\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 1.0 value_stay[t] + -0.7553 value_stay*reward + 2.0512 reward*decision_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.1089 reward + 1.0 value_exit[t] + -0.1669 reward*value_exit \n",
      "beta(value) = 48.9947\n",
      "Participant number 242\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4822 reward + 0.1901 decision_duration + 1.0 value_stay[t] + -0.2193 value_stay^2 + -0.4262 value_stay*reward + -0.2322 value_stay*value_stay + -0.2863 reward^2 + 0.4641 reward*decision_duration + 0.1539 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 54.4235\n",
      "Participant number 243\n",
      "value_stay[t+1] = 0.1728 1 + 0.8308 value_stay[t] + 0.4111 reward + 0.1763 decision_duration + 1.0 value_stay[t] + -0.1522 value_stay^2 + -0.2357 value_stay*decision_duration + -0.3545 value_stay*value_stay + -0.3205 reward^2 + 0.3974 reward*decision_duration + 0.1487 decision_duration^2 + -0.2764 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 29.1173\n",
      "Participant number 247\n",
      "value_stay[t+1] = 0.2281 1 + 0.8231 value_stay[t] + 0.1699 reward + 0.2153 decision_duration + 1.0 value_stay[t] + -0.3307 value_stay*decision_duration + -0.456 value_stay*value_stay + 0.1792 reward*decision_duration + 0.1559 decision_duration^2 + -0.4151 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 49.2132\n",
      "Participant number 249\n",
      "value_stay[t+1] = 0.1646 1 + 0.8546 value_stay[t] + 0.4159 reward + 0.177 decision_duration + 1.0 value_stay[t] + -0.17 value_stay^2 + -0.2401 value_stay*decision_duration + -0.328 value_stay*value_stay + -0.3451 reward^2 + 0.4045 reward*decision_duration + 0.1407 decision_duration^2 + -0.2688 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 50.2063\n",
      "Participant number 250\n",
      "value_stay[t+1] = 0.1431 1 + 0.832 value_stay[t] + 0.3007 reward + 0.2661 decision_duration + 1.0 value_stay[t] + -0.1418 value_stay^2 + -0.3805 value_stay*value_stay + -0.1449 reward^2 + 0.321 reward*decision_duration + -0.3506 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 64.6521\n",
      "Participant number 253\n",
      "value_stay[t+1] = 0.1826 1 + 0.8322 value_stay[t] + 0.4104 reward + 0.1928 decision_duration + 1.0 value_stay[t] + -0.115 value_stay^2 + -0.2592 value_stay*decision_duration + -0.3855 value_stay*value_stay + -0.3232 reward^2 + 0.4156 reward*decision_duration + 0.1476 decision_duration^2 + -0.3349 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 49.3546\n",
      "Participant number 254\n",
      "value_stay[t+1] = 0.1918 1 + 0.7763 value_stay[t] + 0.3328 reward + 0.2052 decision_duration + 1.0 value_stay[t] + -0.3168 value_stay*decision_duration + -0.4371 value_stay*value_stay + -0.208 reward^2 + 0.3422 reward*decision_duration + 0.169 decision_duration^2 + -0.3098 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 43.8094\n",
      "Participant number 257\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.3986 reward + 0.2735 decision_duration + 1.0 value_stay[t] + -0.2764 value_stay^2 + -0.2395 value_stay*decision_duration + -0.3776 value_stay*value_stay + -0.2609 reward^2 + 0.3982 reward*decision_duration + 0.1001 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 56.1730\n",
      "Participant number 258\n",
      "value_stay[t+1] = 0.1997 1 + 0.7978 value_stay[t] + 0.2743 reward + 0.2075 decision_duration + 1.0 value_stay[t] + -0.3366 value_stay*decision_duration + -0.4344 value_stay*value_stay + -0.1325 reward^2 + 0.271 reward*decision_duration + 0.1731 decision_duration^2 + -0.344 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 38.2474\n",
      "Participant number 260\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4779 reward + 0.2059 decision_duration + 1.0 value_stay[t] + -0.2348 value_stay^2 + -0.6352 value_stay*reward + -0.1484 value_stay*decision_duration + -0.2264 reward^2 + 0.5014 reward*decision_duration + 0.171 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 50.1467\n",
      "Participant number 262\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4217 reward + 0.3643 decision_duration + 1.0 value_stay[t] + -0.1594 value_stay^2 + -0.6058 value_stay*reward + -0.4801 value_stay*decision_duration + -0.1585 reward^2 + 0.3932 reward*decision_duration + 0.1489 reward*value_stay \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.1267 reward + 1.0 value_exit[t] + -0.1928 reward*value_exit \n",
      "beta(value) = 20.8168\n",
      "Participant number 264\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4759 reward + 0.168 decision_duration + 1.0 value_stay[t] + -0.273 value_stay^2 + -0.4318 value_stay*reward + -0.4149 value_stay*decision_duration + -0.3003 reward^2 + 0.4634 reward*decision_duration + 0.1947 reward*value_stay + 0.1888 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 26.4970\n",
      "Participant number 266\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.427 reward + 0.2547 decision_duration + 1.0 value_stay[t] + -0.2928 value_stay^2 + -0.2532 value_stay*decision_duration + -0.3398 value_stay*value_stay + -0.3077 reward^2 + 0.4283 reward*decision_duration + 0.1172 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 45.5204\n",
      "Participant number 267\n",
      "value_stay[t+1] = 0.1637 1 + 0.8294 value_stay[t] + 0.408 reward + 0.1843 decision_duration + 1.0 value_stay[t] + -0.1205 value_stay^2 + -0.2665 value_stay*decision_duration + -0.3691 value_stay*value_stay + -0.2975 reward^2 + 0.4116 reward*decision_duration + 0.1708 decision_duration^2 + -0.309 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 39.8898\n",
      "Participant number 268\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4674 reward + 0.3168 decision_duration + 1.0 value_stay[t] + -0.2081 value_stay^2 + -0.4699 value_stay*reward + -0.3002 value_stay*decision_duration + -0.1313 value_stay*value_stay + -0.2754 reward^2 + 0.4501 reward*decision_duration + 0.1632 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 43.9667\n",
      "Participant number 269\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.2722 reward + 0.2367 decision_duration + 1.0 value_stay[t] + -0.1255 value_stay^2 + -0.2193 value_stay*reward + -0.3521 value_stay*decision_duration + -0.263 value_stay*value_stay + 0.2665 reward*decision_duration + 0.14 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 58.3961\n",
      "Participant number 272\n",
      "value_stay[t+1] = 0.2192 1 + 0.8247 value_stay[t] + 0.2429 reward + 0.2073 decision_duration + 1.0 value_stay[t] + -0.3143 value_stay*decision_duration + -0.438 value_stay*value_stay + 0.2458 reward*decision_duration + -0.1888 reward*value_stay + 0.1473 decision_duration^2 + -0.3827 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 55.2780\n",
      "Participant number 273\n",
      "value_stay[t+1] = 0.1876 1 + 0.8473 value_stay[t] + 0.4 reward + 0.1804 decision_duration + 1.0 value_stay[t] + -0.1626 value_stay^2 + -0.2409 value_stay*decision_duration + -0.356 value_stay*value_stay + -0.3298 reward^2 + 0.4 reward*decision_duration + 0.135 decision_duration^2 + -0.3022 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 26.8660\n",
      "Participant number 276\n",
      "value_stay[t+1] = 0.2149 1 + 0.7852 value_stay[t] + 0.3404 reward + 0.2082 decision_duration + 1.0 value_stay[t] + -0.3193 value_stay*decision_duration + -0.4411 value_stay*value_stay + -0.2552 reward^2 + 0.3475 reward*decision_duration + 0.1453 decision_duration^2 + -0.3276 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 40.4555\n",
      "Participant number 282\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4667 reward + 0.3402 decision_duration + 1.0 value_stay[t] + -0.3256 value_stay^2 + -0.1627 value_stay*decision_duration + -0.3836 value_stay*value_stay + -0.3734 reward^2 + 0.4745 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 28.2984\n",
      "Participant number 284\n",
      "value_stay[t+1] = 0.2121 1 + 0.7962 value_stay[t] + 0.3092 reward + 0.2125 decision_duration + 1.0 value_stay[t] + -0.3159 value_stay*decision_duration + -0.4686 value_stay*value_stay + -0.1672 reward^2 + 0.3036 reward*decision_duration + 0.1674 decision_duration^2 + -0.3979 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 43.7897\n",
      "Participant number 285\n",
      "value_stay[t+1] = 0.1483 1 + 0.8615 value_stay[t] + 0.442 reward + 0.173 decision_duration + 1.0 value_stay[t] + -0.1948 value_stay^2 + -0.2267 value_stay*decision_duration + -0.3166 value_stay*value_stay + -0.3604 reward^2 + 0.4439 reward*decision_duration + 0.1528 decision_duration^2 + -0.2756 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 50.6260\n",
      "Participant number 287\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4411 reward + 0.2906 decision_duration + 1.0 value_stay[t] + -0.3397 value_stay^2 + -0.3948 value_stay*reward + -0.2594 value_stay*decision_duration + -0.3139 reward^2 + 0.4923 reward*decision_duration + 0.1816 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 38.1099\n",
      "Participant number 288\n",
      "value_stay[t+1] = 0.235 1 + 1.0 value_stay[t] + 0.24 reward + 0.2171 decision_duration + 1.0 value_stay[t] + -0.4991 value_stay*decision_duration + -0.4965 value_stay*value_stay + 0.2338 reward*decision_duration + -0.3231 reward*value_stay + 0.1681 decision_duration^2 + -0.4564 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 21.3911\n",
      "Participant number 289\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.1797 reward + 0.2105 decision_duration + 1.0 value_stay[t] + -0.7619 value_stay*reward + -0.3874 value_stay*decision_duration + 1.4199 reward*decision_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.1222 reward + 1.0 value_exit[t] + -0.1859 reward*value_exit \n",
      "beta(value) = 27.4049\n",
      "Participant number 290\n",
      "value_stay[t+1] = 0.1909 1 + 0.7892 value_stay[t] + 0.3257 reward + 0.1967 decision_duration + 1.0 value_stay[t] + -0.2766 value_stay*decision_duration + -0.4347 value_stay*value_stay + -0.2045 reward^2 + 0.335 reward*decision_duration + 0.1581 decision_duration^2 + -0.3357 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 57.2578\n",
      "Participant number 292\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4503 reward + 0.3624 decision_duration + 1.0 value_stay[t] + -0.2006 value_stay^2 + -0.3309 value_stay*reward + -0.3365 value_stay*decision_duration + -0.2378 value_stay*value_stay + -0.2964 reward^2 + 0.4617 reward*decision_duration + 0.1266 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 39.0467\n",
      "Participant number 293\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.384 reward + 0.1934 decision_duration + 1.0 value_stay[t] + -0.6563 value_stay*reward + -0.4772 value_stay*decision_duration + 0.3706 reward*decision_duration + 0.1234 decision_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.1186 reward + 1.0 value_exit[t] + -0.181 reward*value_exit \n",
      "beta(value) = 31.5090\n",
      "Participant number 295\n",
      "value_stay[t+1] = 0.1712 1 + 1.0 value_stay[t] + 0.2948 reward + 0.2218 decision_duration + 1.0 value_stay[t] + -0.3988 value_stay*reward + -0.6532 value_stay*decision_duration + 0.2928 reward*decision_duration + 0.2354 decision_duration^2 + -0.7062 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 42.7478\n",
      "Participant number 298\n",
      "value_stay[t+1] = 0.1486 1 + 0.875 value_stay[t] + 0.4462 reward + 0.1642 decision_duration + 1.0 value_stay[t] + -0.107 value_stay^2 + -0.1896 value_stay*reward + -0.3194 value_stay*decision_duration + -0.2817 value_stay*value_stay + -0.298 reward^2 + 0.4361 reward*decision_duration + 0.1603 decision_duration^2 + -0.2293 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 45.8316\n",
      "Participant number 300\n",
      "value_stay[t+1] = 0.1754 1 + 0.8313 value_stay[t] + 0.4109 reward + 0.1693 decision_duration + 1.0 value_stay[t] + -0.1681 value_stay^2 + -0.2278 value_stay*decision_duration + -0.351 value_stay*value_stay + -0.332 reward^2 + 0.3982 reward*decision_duration + 0.1418 decision_duration^2 + -0.2644 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 29.2836\n",
      "Participant number 301\n",
      "value_stay[t+1] = 0.1694 1 + 0.8219 value_stay[t] + 0.4288 reward + 0.1869 decision_duration + 1.0 value_stay[t] + -0.1315 value_stay^2 + -0.2383 value_stay*decision_duration + -0.3815 value_stay*value_stay + -0.3258 reward^2 + 0.4307 reward*decision_duration + 0.1563 decision_duration^2 + -0.3089 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 35.9255\n",
      "Participant number 302\n",
      "value_stay[t+1] = 0.1527 1 + 0.8744 value_stay[t] + 0.4351 reward + 0.1635 decision_duration + 1.0 value_stay[t] + -0.1457 value_stay^2 + -0.1302 value_stay*reward + -0.3112 value_stay*decision_duration + -0.285 value_stay*value_stay + -0.3071 reward^2 + 0.4228 reward*decision_duration + 0.1668 decision_duration^2 + -0.2383 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 23.8905\n",
      "Participant number 304\n",
      "value_stay[t+1] = 0.1572 1 + 0.858 value_stay[t] + 0.4234 reward + 0.1802 decision_duration + 1.0 value_stay[t] + -0.1565 value_stay^2 + -0.2411 value_stay*decision_duration + -0.3422 value_stay*value_stay + -0.3281 reward^2 + 0.432 reward*decision_duration + 0.16 decision_duration^2 + -0.3315 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 53.9425\n",
      "Participant number 305\n",
      "value_stay[t+1] = 0.1643 1 + 0.8422 value_stay[t] + 0.415 reward + 0.1753 decision_duration + 1.0 value_stay[t] + -0.22 value_stay*reward + -0.3348 value_stay*decision_duration + -0.3357 value_stay*value_stay + -0.2479 reward^2 + 0.4048 reward*decision_duration + 0.1521 decision_duration^2 + -0.2448 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 45.3821\n",
      "Participant number 311\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4458 reward + 0.2552 decision_duration + 1.0 value_stay[t] + -0.1856 value_stay^2 + -0.6446 value_stay*reward + -0.2666 value_stay*decision_duration + -0.1803 reward^2 + 0.4827 reward*decision_duration + 0.1547 reward*value_stay \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.1049 reward + 1.0 value_exit[t] + -0.1608 reward*value_exit \n",
      "beta(value) = 46.6313\n",
      "Participant number 312\n",
      "value_stay[t+1] = 0.1432 1 + 0.8501 value_stay[t] + 0.4352 reward + 0.1775 decision_duration + 1.0 value_stay[t] + -0.1603 value_stay^2 + -0.2523 value_stay*decision_duration + -0.3416 value_stay*value_stay + -0.3148 reward^2 + 0.4232 reward*decision_duration + 0.1826 decision_duration^2 + -0.3142 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 31.6511\n",
      "Participant number 315\n",
      "value_stay[t+1] = 0.1546 1 + 0.8616 value_stay[t] + 0.4407 reward + 0.1746 decision_duration + 1.0 value_stay[t] + -0.183 value_stay^2 + -0.2169 value_stay*decision_duration + -0.3317 value_stay*value_stay + -0.354 reward^2 + 0.4308 reward*decision_duration + 0.1494 decision_duration^2 + -0.3038 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 55.1131\n",
      "Participant number 316\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4607 reward + 0.3023 decision_duration + 1.0 value_stay[t] + -0.242 value_stay^2 + -0.3426 value_stay*reward + -0.2112 value_stay*decision_duration + -0.2213 value_stay*value_stay + -0.3206 reward^2 + 0.4626 reward*decision_duration + 0.1716 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 49.6932\n",
      "Participant number 317\n",
      "value_stay[t+1] = 0.1358 1 + 0.8771 value_stay[t] + 0.4588 reward + 0.1623 decision_duration + 1.0 value_stay[t] + -0.1056 value_stay^2 + -0.1963 value_stay*reward + -0.2737 value_stay*decision_duration + -0.2792 value_stay*value_stay + -0.2964 reward^2 + 0.4451 reward*decision_duration + 0.1523 decision_duration^2 + -0.2449 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 51.7920\n",
      "Participant number 318\n",
      "value_stay[t+1] = 0.2099 1 + 0.7941 value_stay[t] + 0.2728 reward + 0.2083 decision_duration + 1.0 value_stay[t] + -0.3217 value_stay*decision_duration + -0.4518 value_stay*value_stay + -0.1266 reward^2 + 0.2684 reward*decision_duration + 0.1657 decision_duration^2 + -0.3595 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 36.3341\n",
      "Participant number 320\n",
      "value_stay[t+1] = 0.1705 1 + 0.8456 value_stay[t] + 0.4064 reward + 0.1919 decision_duration + 1.0 value_stay[t] + -0.1171 value_stay^2 + -0.2763 value_stay*decision_duration + -0.3747 value_stay*value_stay + -0.2998 reward^2 + 0.3981 reward*decision_duration + 0.1659 decision_duration^2 + -0.3473 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 45.2100\n",
      "Participant number 321\n",
      "value_stay[t+1] = 0.1654 1 + 0.846 value_stay[t] + 0.4285 reward + 0.1779 decision_duration + 1.0 value_stay[t] + -0.1559 value_stay^2 + -0.1972 value_stay*decision_duration + -0.3594 value_stay*value_stay + -0.3392 reward^2 + 0.4328 reward*decision_duration + 0.1391 decision_duration^2 + -0.3217 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 58.3364\n",
      "Participant number 325\n",
      "value_stay[t+1] = 0.2061 1 + 0.8297 value_stay[t] + 0.1617 reward + 0.2043 decision_duration + 1.0 value_stay[t] + -0.3113 value_stay*decision_duration + -0.4174 value_stay*value_stay + 0.1698 reward*decision_duration + 0.1528 decision_duration^2 + -0.3704 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 58.1093\n",
      "Participant number 326\n",
      "value_stay[t+1] = 0.1705 1 + 0.851 value_stay[t] + 0.4131 reward + 0.1833 decision_duration + 1.0 value_stay[t] + -0.1529 value_stay^2 + -0.2549 value_stay*decision_duration + -0.3518 value_stay*value_stay + -0.3208 reward^2 + 0.4011 reward*decision_duration + 0.1548 decision_duration^2 + -0.3191 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 37.5426\n",
      "Participant number 327\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.433 reward + 0.3428 decision_duration + 1.0 value_stay[t] + -0.2209 value_stay^2 + -0.5407 value_stay*reward + -0.4147 value_stay*decision_duration + -0.2226 reward^2 + 0.477 reward*decision_duration + 0.1562 reward*value_stay \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.114 reward + 1.0 value_exit[t] + -0.174 reward*value_exit \n",
      "beta(value) = 27.1069\n",
      "Participant number 330\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4711 reward + 0.2085 decision_duration + 1.0 value_stay[t] + -0.2178 value_stay^2 + -0.5047 value_stay*reward + -0.4641 value_stay*decision_duration + -0.2631 reward^2 + 0.4537 reward*decision_duration + 0.1827 reward*value_stay + 0.1605 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 22.4487\n",
      "Participant number 331\n",
      "value_stay[t+1] = 0.1431 1 + 0.8743 value_stay[t] + 0.444 reward + 0.1642 decision_duration + 1.0 value_stay[t] + -0.1174 value_stay^2 + -0.1387 value_stay*reward + -0.2874 value_stay*decision_duration + -0.2952 value_stay*value_stay + -0.3035 reward^2 + 0.4344 reward*decision_duration + 0.1644 decision_duration^2 + -0.2622 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 53.6991\n",
      "Participant number 333\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4636 reward + 0.2846 decision_duration + 1.0 value_stay[t] + -0.2123 value_stay^2 + -0.4201 value_stay*reward + -0.2104 value_stay*decision_duration + -0.1827 value_stay*value_stay + -0.2817 reward^2 + 0.4548 reward*decision_duration + 0.1537 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 48.1594\n",
      "Participant number 335\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.3086 reward + 0.277 decision_duration + 1.0 value_stay[t] + -0.7661 value_stay*reward + -0.466 value_stay*decision_duration + 0.872 reward*decision_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.1273 reward + 1.0 value_exit[t] + -0.1932 reward*value_exit \n",
      "beta(value) = 22.8011\n",
      "Participant number 336\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4697 reward + 0.2413 decision_duration + 1.0 value_stay[t] + -0.1871 value_stay^2 + -0.5453 value_stay*reward + -0.4992 value_stay*decision_duration + -0.2478 reward^2 + 0.4522 reward*decision_duration + 0.1776 reward*value_stay + 0.1396 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 28.9916\n",
      "Participant number 337\n",
      "value_stay[t+1] = 0.1329 1 + 0.8448 value_stay[t] + 0.4135 reward + 0.2656 decision_duration + 1.0 value_stay[t] + -0.1762 value_stay^2 + -0.3658 value_stay*value_stay + -0.302 reward^2 + 0.4338 reward*decision_duration + -0.3575 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 61.0764\n",
      "Participant number 338\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4759 reward + 0.1884 decision_duration + 1.0 value_stay[t] + -0.225 value_stay^2 + -0.2396 value_stay*reward + -0.2676 value_stay*decision_duration + -0.2779 value_stay*value_stay + -0.3316 reward^2 + 0.4643 reward*decision_duration + 0.1348 reward*value_stay + 0.153 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 52.0800\n",
      "Participant number 339\n",
      "value_stay[t+1] = 0.1391 1 + 0.8472 value_stay[t] + 0.4295 reward + 0.1678 decision_duration + 1.0 value_stay[t] + -0.332 value_stay*reward + -0.3676 value_stay*decision_duration + -0.289 value_stay*value_stay + -0.2612 reward^2 + 0.4296 reward*decision_duration + 0.1072 reward*value_stay + 0.1699 decision_duration^2 + -0.1931 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 46.8896\n",
      "Participant number 340\n",
      "value_stay[t+1] = 0.154 1 + 0.8701 value_stay[t] + 0.4239 reward + 0.1629 decision_duration + 1.0 value_stay[t] + -0.1601 value_stay^2 + -0.1329 value_stay*reward + -0.2848 value_stay*decision_duration + -0.3003 value_stay*value_stay + -0.3344 reward^2 + 0.4113 reward*decision_duration + 0.0996 reward*value_stay + 0.1665 decision_duration^2 + -0.256 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 22.6819\n",
      "Participant number 341\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4179 reward + 0.3236 decision_duration + 1.0 value_stay[t] + -0.3339 value_stay^2 + -0.3697 value_stay*reward + -0.3199 value_stay*decision_duration + -0.2796 reward^2 + 0.4669 reward*decision_duration + 0.1564 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 27.0431\n",
      "Participant number 342\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.473 reward + 0.1884 decision_duration + 1.0 value_stay[t] + -0.2557 value_stay^2 + -0.3912 value_stay*reward + -0.1909 value_stay*value_stay + -0.2937 reward^2 + 0.4433 reward*decision_duration + 0.1526 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 52.8855\n",
      "Participant number 345\n",
      "value_stay[t+1] = 0.2197 1 + 0.7995 value_stay[t] + 0.3139 reward + 0.2099 decision_duration + 1.0 value_stay[t] + -0.3363 value_stay*decision_duration + -0.4318 value_stay*value_stay + -0.2304 reward^2 + 0.3191 reward*decision_duration + 0.1431 decision_duration^2 + -0.3378 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 41.1002\n",
      "Participant number 346\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4455 reward + 0.3416 decision_duration + 1.0 value_stay[t] + -0.3427 value_stay^2 + -0.1695 value_stay*decision_duration + -0.3527 value_stay*value_stay + -0.3522 reward^2 + 0.4666 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 27.7201\n",
      "Participant number 348\n",
      "value_stay[t+1] = 0.1672 1 + 1.0 value_stay[t] + 0.2917 reward + 0.1835 decision_duration + 1.0 value_stay[t] + -0.3815 value_stay*reward + -0.2993 value_stay*value_stay + 0.3012 reward*decision_duration + -0.6348 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 58.8380\n",
      "Participant number 350\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4706 reward + 0.2901 decision_duration + 1.0 value_stay[t] + -0.1655 value_stay^2 + -0.5807 value_stay*reward + -0.281 value_stay*decision_duration + -0.1105 value_stay*value_stay + -0.2363 reward^2 + 0.4554 reward*decision_duration + 0.179 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 48.0681\n",
      "Participant number 352\n",
      "value_stay[t+1] = 0.1754 1 + 0.8406 value_stay[t] + 0.3809 reward + 0.1763 decision_duration + 1.0 value_stay[t] + -0.1192 value_stay^2 + -0.1881 value_stay*decision_duration + -0.3814 value_stay*value_stay + -0.2722 reward^2 + 0.3736 reward*decision_duration + 0.1369 decision_duration^2 + -0.3451 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 62.1107\n",
      "Participant number 354\n",
      "value_stay[t+1] = 0.1448 1 + 0.8492 value_stay[t] + 0.4388 reward + 0.1693 decision_duration + 1.0 value_stay[t] + -0.2408 value_stay*reward + -0.3273 value_stay*decision_duration + -0.3106 value_stay*value_stay + -0.2658 reward^2 + 0.4398 reward*decision_duration + 0.1591 decision_duration^2 + -0.2385 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 51.1225\n",
      "Participant number 355\n",
      "value_stay[t+1] = 0.1893 1 + 0.7968 value_stay[t] + 0.3213 reward + 0.2106 decision_duration + 1.0 value_stay[t] + -0.3289 value_stay*decision_duration + -0.4354 value_stay*value_stay + -0.1846 reward^2 + 0.3308 reward*decision_duration + 0.1769 decision_duration^2 + -0.3611 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 49.4416\n",
      "Participant number 356\n",
      "value_stay[t+1] = 0.2442 1 + 0.9002 value_stay[t] + 0.1205 reward + 0.2181 decision_duration + 1.0 value_stay[t] + -0.4348 value_stay*decision_duration + -0.4035 value_stay*value_stay + 0.1198 reward*decision_duration + 0.1575 decision_duration^2 + -0.4725 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 25.3331\n",
      "Participant number 363\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4365 reward + 0.2151 decision_duration + 1.0 value_stay[t] + -0.5622 value_stay*reward + -0.5565 value_stay*decision_duration + -0.1489 value_stay*value_stay + -0.181 reward^2 + 0.424 reward*decision_duration + 0.1424 reward*value_stay + 0.1828 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 22.8437\n",
      "Participant number 364\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4553 reward + 0.2518 decision_duration + 1.0 value_stay[t] + -0.3019 value_stay^2 + -0.4785 value_stay*reward + -0.2038 value_stay*decision_duration + -0.2796 reward^2 + 0.5047 reward*decision_duration + 0.1642 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 46.4424\n",
      "Participant number 367\n",
      "value_stay[t+1] = 0.2192 1 + 0.8208 value_stay[t] + 0.1617 reward + 0.2042 decision_duration + 1.0 value_stay[t] + -0.2949 value_stay*decision_duration + -0.4385 value_stay*value_stay + 0.1633 reward*decision_duration + 0.1438 decision_duration^2 + -0.3761 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 57.5514\n",
      "Participant number 369\n",
      "value_stay[t+1] = 0.1855 1 + 0.8404 value_stay[t] + 0.3968 reward + 0.1808 decision_duration + 1.0 value_stay[t] + -0.135 value_stay^2 + -0.2585 value_stay*decision_duration + -0.3616 value_stay*value_stay + -0.3232 reward^2 + 0.387 reward*decision_duration + 0.1423 decision_duration^2 + -0.2955 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 46.0279\n",
      "Participant number 371\n",
      "value_stay[t+1] = 0.1884 1 + 1.0 value_stay[t] + 0.1576 reward + 0.1952 decision_duration + 1.0 value_stay[t] + -0.1459 value_stay^2 + -0.3261 value_stay*decision_duration + -0.408 value_stay*value_stay + 0.1684 reward*decision_duration + 0.1615 decision_duration^2 + -0.4604 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 60.9892\n",
      "Participant number 373\n",
      "value_stay[t+1] = 0.2313 1 + 0.8397 value_stay[t] + 0.2587 reward + 0.2187 decision_duration + 1.0 value_stay[t] + -0.3435 value_stay*decision_duration + -0.4561 value_stay*value_stay + -0.1385 reward^2 + 0.2685 reward*decision_duration + 0.1514 decision_duration^2 + -0.4593 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 40.3139\n",
      "Participant number 374\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4795 reward + 0.1258 decision_duration + 1.0 value_stay[t] + -0.2171 value_stay^2 + -0.6878 value_stay*reward + -0.1874 reward^2 + 0.4638 reward*decision_duration + 0.1675 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 54.4272\n",
      "Participant number 375\n",
      "value_stay[t+1] = 0.2048 1 + 0.7803 value_stay[t] + 0.3428 reward + 0.2095 decision_duration + 1.0 value_stay[t] + -0.3056 value_stay*decision_duration + -0.4582 value_stay*value_stay + -0.2164 reward^2 + 0.3366 reward*decision_duration + 0.163 decision_duration^2 + -0.3573 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 44.0131\n",
      "Participant number 376\n",
      "value_stay[t+1] = 0.1956 1 + 0.7898 value_stay[t] + 0.3375 reward + 0.207 decision_duration + 1.0 value_stay[t] + -0.3188 value_stay*decision_duration + -0.4454 value_stay*value_stay + -0.2084 reward^2 + 0.3321 reward*decision_duration + 0.1726 decision_duration^2 + -0.3543 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 41.6249\n",
      "Participant number 377\n",
      "value_stay[t+1] = 0.144 1 + 0.7954 value_stay[t] + 0.4591 reward + 0.259 decision_duration + 1.0 value_stay[t] + -0.1625 value_stay^2 + -0.3892 value_stay*value_stay + -0.3615 reward^2 + 0.472 reward*decision_duration + -0.2971 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 44.8053\n",
      "Participant number 378\n",
      "value_stay[t+1] = 0.1763 1 + 0.8554 value_stay[t] + 0.3845 reward + 0.1689 decision_duration + 1.0 value_stay[t] + -0.1733 value_stay^2 + -0.2537 value_stay*decision_duration + -0.3235 value_stay*value_stay + -0.3164 reward^2 + 0.3736 reward*decision_duration + 0.1427 decision_duration^2 + -0.2549 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 29.9597\n",
      "Participant number 379\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4555 reward + 0.3369 decision_duration + 1.0 value_stay[t] + -0.2026 value_stay^2 + -0.4105 value_stay*reward + -0.3161 value_stay*decision_duration + -0.1798 value_stay*value_stay + -0.2876 reward^2 + 0.4545 reward*decision_duration + 0.1626 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 45.7473\n",
      "Participant number 381\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4326 reward + 0.3352 decision_duration + 1.0 value_stay[t] + -0.2349 value_stay^2 + -0.5234 value_stay*reward + -0.3933 value_stay*decision_duration + -0.2348 reward^2 + 0.471 reward*decision_duration + 0.1666 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 30.4367\n",
      "Participant number 383\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.3419 reward + 0.3627 decision_duration + 1.0 value_stay[t] + -0.2734 value_stay^2 + -0.2061 value_stay*decision_duration + -0.3931 value_stay*value_stay + -0.2039 reward^2 + 0.3611 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 32.9710\n",
      "Participant number 385\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4043 reward + 0.345 decision_duration + 1.0 value_stay[t] + -0.1647 value_stay^2 + -0.5706 value_stay*reward + -0.4464 value_stay*decision_duration + -0.1492 reward^2 + 0.3785 reward*decision_duration + 0.1383 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 19.1783\n",
      "Participant number 387\n",
      "value_stay[t+1] = 0.1813 1 + 0.7866 value_stay[t] + 0.3697 reward + 0.2035 decision_duration + 1.0 value_stay[t] + -0.2996 value_stay*decision_duration + -0.4314 value_stay*value_stay + -0.2559 reward^2 + 0.3773 reward*decision_duration + 0.1681 decision_duration^2 + -0.3323 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 50.5110\n",
      "Participant number 389\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4771 reward + 0.2171 decision_duration + 1.0 value_stay[t] + -0.2511 value_stay^2 + -0.2227 value_stay*reward + -0.3252 value_stay*decision_duration + -0.2554 value_stay*value_stay + -0.3592 reward^2 + 0.4637 reward*decision_duration + 0.1621 reward*value_stay + 0.1546 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 38.9197\n",
      "Participant number 390\n",
      "value_stay[t+1] = 0.2181 1 + 0.7906 value_stay[t] + 0.3223 reward + 0.2047 decision_duration + 1.0 value_stay[t] + -0.3253 value_stay*decision_duration + -0.427 value_stay*value_stay + -0.2469 reward^2 + 0.3143 reward*decision_duration + 0.138 decision_duration^2 + -0.3053 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 41.0306\n",
      "Participant number 392\n",
      "value_stay[t+1] = 0.2194 1 + 0.8106 value_stay[t] + 0.1634 reward + 0.2102 decision_duration + 1.0 value_stay[t] + -0.3246 value_stay*decision_duration + -0.442 value_stay*value_stay + 0.1731 reward*decision_duration + 0.1546 decision_duration^2 + -0.3613 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 53.3533\n",
      "Participant number 394\n",
      "value_stay[t+1] = 0.1338 1 + 0.8676 value_stay[t] + 0.4573 reward + 0.1699 decision_duration + 1.0 value_stay[t] + -0.1163 value_stay^2 + -0.1908 value_stay*reward + -0.3155 value_stay*decision_duration + -0.2924 value_stay*value_stay + -0.3406 reward^2 + 0.4481 reward*decision_duration + 0.1132 reward*value_stay + 0.1805 decision_duration^2 + -0.2555 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 47.7848\n",
      "Participant number 396\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4615 reward + 0.208 decision_duration + 1.0 value_stay[t] + -0.2618 value_stay^2 + -0.2986 value_stay*reward + -0.2557 value_stay*value_stay + -0.3077 reward^2 + 0.4534 reward*decision_duration + 0.1298 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 56.2721\n",
      "Participant number 397\n",
      "value_stay[t+1] = 0.159 1 + 0.8531 value_stay[t] + 0.4369 reward + 0.1829 decision_duration + 1.0 value_stay[t] + -0.1601 value_stay^2 + -0.2511 value_stay*decision_duration + -0.3494 value_stay*value_stay + -0.3425 reward^2 + 0.4395 reward*decision_duration + 0.163 decision_duration^2 + -0.3227 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 41.7488\n",
      "Participant number 398\n",
      "value_stay[t+1] = 0.1895 1 + 0.7827 value_stay[t] + 0.3418 reward + 0.2091 decision_duration + 1.0 value_stay[t] + -0.3153 value_stay*decision_duration + -0.4477 value_stay*value_stay + -0.2043 reward^2 + 0.3526 reward*decision_duration + 0.1769 decision_duration^2 + -0.3503 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 43.2871\n",
      "Participant number 400\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.459 reward + 0.3416 decision_duration + 1.0 value_stay[t] + -0.1832 value_stay^2 + -0.497 value_stay*reward + -0.3581 value_stay*decision_duration + -0.1371 value_stay*value_stay + -0.2681 reward^2 + 0.4601 reward*decision_duration + 0.1844 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 41.0122\n",
      "Participant number 402\n",
      "value_stay[t+1] = 0.1466 1 + 0.8719 value_stay[t] + 0.4528 reward + 0.1718 decision_duration + 1.0 value_stay[t] + -0.1296 value_stay^2 + -0.1193 value_stay*reward + -0.3163 value_stay*decision_duration + -0.2997 value_stay*value_stay + -0.323 reward^2 + 0.4524 reward*decision_duration + 0.1749 decision_duration^2 + -0.2713 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 26.4808\n",
      "Participant number 403\n",
      "value_stay[t+1] = 0.1782 1 + 0.8469 value_stay[t] + 0.3997 reward + 0.1777 decision_duration + 1.0 value_stay[t] + -0.1552 value_stay^2 + -0.2595 value_stay*decision_duration + -0.3414 value_stay*value_stay + -0.3271 reward^2 + 0.391 reward*decision_duration + 0.1448 decision_duration^2 + -0.2795 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 40.4097\n",
      "Participant number 404\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4997 reward + 0.238 decision_duration + 1.0 value_stay[t] + -0.1876 value_stay^2 + -0.4408 value_stay*reward + -0.4227 value_stay*decision_duration + -0.1571 value_stay*value_stay + -0.3275 reward^2 + 0.4895 reward*decision_duration + 0.2 reward*value_stay + 0.1416 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 39.9446\n",
      "Participant number 405\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4733 reward + 0.2265 decision_duration + 1.0 value_stay[t] + -0.238 value_stay^2 + -0.2812 value_stay*reward + -0.3534 value_stay*decision_duration + -0.223 value_stay*value_stay + -0.3415 reward^2 + 0.47 reward*decision_duration + 0.1751 reward*value_stay + 0.1481 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 31.3526\n",
      "Participant number 406\n",
      "value_stay[t+1] = 0.2367 1 + 0.805 value_stay[t] + 0.1705 reward + 0.2118 decision_duration + 1.0 value_stay[t] + -0.2907 value_stay*decision_duration + -0.4769 value_stay*value_stay + 0.1798 reward*decision_duration + 0.1435 decision_duration^2 + -0.4085 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 56.8001\n",
      "Participant number 407\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4826 reward + 0.2325 decision_duration + 1.0 value_stay[t] + -0.2173 value_stay^2 + -0.3218 value_stay*reward + -0.3708 value_stay*decision_duration + -0.2156 value_stay*value_stay + -0.3441 reward^2 + 0.4829 reward*decision_duration + 0.1811 reward*value_stay + 0.1432 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 37.7967\n",
      "Participant number 408\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4472 reward + 0.2991 decision_duration + 1.0 value_stay[t] + -0.3059 value_stay^2 + -0.4543 value_stay*reward + -0.2914 value_stay*decision_duration + -0.2891 reward^2 + 0.5172 reward*decision_duration + 0.168 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 42.3685\n",
      "Participant number 409\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4615 reward + 0.3491 decision_duration + 1.0 value_stay[t] + -0.2246 value_stay^2 + -0.3873 value_stay*reward + -0.3261 value_stay*decision_duration + -0.189 value_stay*value_stay + -0.3148 reward^2 + 0.466 reward*decision_duration + 0.1829 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 41.1834\n",
      "Participant number 410\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.448 reward + 0.3201 decision_duration + 1.0 value_stay[t] + -0.2253 value_stay^2 + -0.32 value_stay*reward + -0.2478 value_stay*decision_duration + -0.2271 value_stay*value_stay + -0.2974 reward^2 + 0.4478 reward*decision_duration + 0.1341 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 47.5438\n",
      "Participant number 412\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.2763 decision_duration + 1.0 value_stay[t] + -0.6425 value_stay*reward + -0.5163 value_stay*decision_duration + 1.8781 reward*decision_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.1188 reward + 1.0 value_exit[t] + -0.181 reward*value_exit \n",
      "beta(value) = 31.1167\n",
      "Participant number 413\n",
      "value_stay[t+1] = 0.1219 1 + 0.846 value_stay[t] + 0.4493 reward + 0.1904 decision_duration + 1.0 value_stay[t] + -0.1761 value_stay^2 + -0.2708 value_stay*reward + -0.2675 value_stay*value_stay + -0.359 reward^2 + 0.4507 reward*decision_duration + 0.1852 reward*value_stay + -0.1711 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 46.6111\n",
      "Participant number 414\n",
      "value_stay[t+1] = 0.2044 1 + 0.796 value_stay[t] + 0.2673 reward + 0.207 decision_duration + 1.0 value_stay[t] + -0.2888 value_stay*decision_duration + -0.4579 value_stay*value_stay + -0.1104 reward^2 + 0.2694 reward*decision_duration + 0.1614 decision_duration^2 + -0.3783 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 55.7519\n",
      "Participant number 415\n",
      "value_stay[t+1] = 0.174 1 + 0.7922 value_stay[t] + 0.345 reward + 0.2111 decision_duration + 0.8348 value_stay[t] + -0.3087 value_stay*decision_duration + -0.4881 value_stay*value_stay + -0.1909 reward^2 + 0.3475 reward*decision_duration + 0.1816 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 46.5809\n",
      "Participant number 417\n",
      "value_stay[t+1] = 0.2217 1 + 0.8416 value_stay[t] + 0.1588 reward + 0.2105 decision_duration + 1.0 value_stay[t] + -0.3317 value_stay*decision_duration + -0.4352 value_stay*value_stay + 0.1688 reward*decision_duration + 0.1533 decision_duration^2 + -0.4154 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 54.9354\n",
      "Participant number 418\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.478 reward + 0.1958 decision_duration + 1.0 value_stay[t] + -0.254 value_stay^2 + -0.4502 value_stay*reward + -0.4413 value_stay*decision_duration + -0.2945 reward^2 + 0.4667 reward*decision_duration + 0.1793 reward*value_stay + 0.1706 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 31.2594\n",
      "Participant number 419\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.444 reward + 0.3128 decision_duration + 1.0 value_stay[t] + -0.2344 value_stay^2 + -0.5465 value_stay*reward + -0.3514 value_stay*decision_duration + -0.233 reward^2 + 0.4869 reward*decision_duration + 0.1609 reward*value_stay \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.1061 reward + 1.0 value_exit[t] + -0.1627 reward*value_exit \n",
      "beta(value) = 38.3010\n",
      "Participant number 420\n",
      "value_stay[t+1] = 0.1734 1 + 0.7916 value_stay[t] + 0.2237 reward + 0.1799 decision_duration + 1.0 value_stay[t] + 0.141 value_stay*reward + -0.2815 value_stay*decision_duration + -0.5431 value_stay*value_stay + 0.2265 reward*decision_duration + -0.3163 reward*value_stay + 0.1429 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 39.2607\n",
      "Participant number 421\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4587 reward + 0.2402 decision_duration + 1.0 value_stay[t] + -0.188 value_stay^2 + -0.5379 value_stay*reward + -0.5008 value_stay*decision_duration + -0.2308 reward^2 + 0.4408 reward*decision_duration + 0.1697 reward*value_stay + 0.1428 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 26.2675\n",
      "Participant number 426\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.516 reward + 0.2052 decision_duration + 1.0 value_stay[t] + -0.2003 value_stay^2 + -0.3567 value_stay*reward + -0.3787 value_stay*decision_duration + -0.2443 value_stay*value_stay + -0.3569 reward^2 + 0.5103 reward*decision_duration + 0.1872 reward*value_stay + 0.1755 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 22.1370\n",
      "Participant number 427\n",
      "value_stay[t+1] = 0.1555 1 + 1.0 value_stay[t] + 0.209 reward + 0.1844 decision_duration + 1.0 value_stay[t] + -0.138 value_stay*reward + -0.3663 value_stay*decision_duration + -0.4299 value_stay*value_stay + 0.209 reward*decision_duration + 0.1817 decision_duration^2 + -0.4285 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 54.1806\n",
      "Participant number 431\n",
      "value_stay[t+1] = 0.1744 1 + 0.8358 value_stay[t] + 0.3886 reward + 0.1903 decision_duration + 1.0 value_stay[t] + -0.1062 value_stay^2 + -0.2773 value_stay*decision_duration + -0.3871 value_stay*value_stay + -0.2681 reward^2 + 0.3787 reward*decision_duration + 0.1723 decision_duration^2 + -0.3521 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 33.4220\n",
      "Participant number 432\n",
      "value_stay[t+1] = 0.2325 1 + 0.8182 value_stay[t] + 0.1674 reward + 0.2144 decision_duration + 1.0 value_stay[t] + -0.3182 value_stay*decision_duration + -0.4649 value_stay*value_stay + 0.177 reward*decision_duration + 0.1509 decision_duration^2 + -0.4139 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 50.6252\n",
      "Participant number 434\n",
      "value_stay[t+1] = 0.1821 1 + 1.0 value_stay[t] + 0.2663 reward + 0.2411 decision_duration + 1.0 value_stay[t] + -0.3305 value_stay*reward + -0.7404 value_stay*decision_duration + 0.2793 reward*decision_duration + 0.2704 decision_duration^2 + -0.7704 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 31.0098\n",
      "Participant number 435\n",
      "value_stay[t+1] = 0.1922 1 + 0.8151 value_stay[t] + 0.3741 reward + 0.1883 decision_duration + 1.0 value_stay[t] + -0.0953 value_stay^2 + -0.2621 value_stay*decision_duration + -0.3987 value_stay*value_stay + -0.2685 reward^2 + 0.3615 reward*decision_duration + 0.1526 decision_duration^2 + -0.3223 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 26.6195\n",
      "Participant number 436\n",
      "value_stay[t+1] = 0.1481 1 + 0.8461 value_stay[t] + 0.4419 reward + 0.1773 decision_duration + 1.0 value_stay[t] + -0.1625 value_stay^2 + -0.2243 value_stay*decision_duration + -0.3437 value_stay*value_stay + -0.3362 reward^2 + 0.4331 reward*decision_duration + 0.1622 decision_duration^2 + -0.3015 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 53.1915\n",
      "Participant number 438\n",
      "value_stay[t+1] = 0.1292 1 + 1.0 value_stay[t] + 0.2303 reward + 0.2143 decision_duration + 1.0 value_stay[t] + -0.1041 value_stay^2 + -0.184 value_stay*reward + -0.381 value_stay*value_stay + 0.2451 reward*decision_duration + -0.4231 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 63.6357\n",
      "Participant number 443\n",
      "value_stay[t+1] = 0.1418 1 + 0.8451 value_stay[t] + 0.1655 reward + 0.1687 decision_duration + 1.0 value_stay[t] + -0.266 value_stay*decision_duration + -0.5718 value_stay*value_stay + 0.1684 reward*decision_duration + 0.1585 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 50.6710\n",
      "Participant number 448\n",
      "value_stay[t+1] = 0.1683 1 + 0.8552 value_stay[t] + 0.4145 reward + 0.187 decision_duration + 1.0 value_stay[t] + -0.1336 value_stay^2 + -0.2519 value_stay*decision_duration + -0.3684 value_stay*value_stay + -0.3197 reward^2 + 0.4207 reward*decision_duration + 0.1564 decision_duration^2 + -0.3496 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 51.3040\n",
      "Participant number 451\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 1.0 value_stay[t] + -0.7441 value_stay*reward + 2.0314 reward*decision_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.1105 reward + 1.0 value_exit[t] + -0.1689 reward*value_exit \n",
      "beta(value) = 51.7986\n",
      "Participant number 453\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.337 reward + 0.3449 decision_duration + 1.0 value_stay[t] + -0.4666 value_stay*reward + -0.6597 value_stay*decision_duration + 0.3346 reward*decision_duration + 0.1422 decision_duration^2 + -0.209 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 37.5733\n",
      "Participant number 454\n",
      "value_stay[t+1] = 0.2033 1 + 0.779 value_stay[t] + 0.3175 reward + 0.2051 decision_duration + 1.0 value_stay[t] + -0.3165 value_stay*decision_duration + -0.4403 value_stay*value_stay + -0.2008 reward^2 + 0.3212 reward*decision_duration + 0.1608 decision_duration^2 + -0.3167 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 28.1575\n",
      "Participant number 455\n",
      "value_stay[t+1] = 0.2098 1 + 0.8168 value_stay[t] + 0.156 reward + 0.208 decision_duration + 1.0 value_stay[t] + -0.3467 value_stay*decision_duration + -0.4136 value_stay*value_stay + 0.1654 reward*decision_duration + 0.1571 decision_duration^2 + -0.3246 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 44.2425\n",
      "Participant number 460\n",
      "value_stay[t+1] = 0.2094 1 + 0.841 value_stay[t] + 0.1552 reward + 0.2128 decision_duration + 1.0 value_stay[t] + -0.3664 value_stay*decision_duration + -0.4109 value_stay*value_stay + 0.1648 reward*decision_duration + 0.1645 decision_duration^2 + -0.3768 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 48.1158\n",
      "Participant number 461\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4843 reward + 0.2562 decision_duration + 1.0 value_stay[t] + -0.1955 value_stay^2 + -0.4358 value_stay*reward + -0.4265 value_stay*decision_duration + -0.1399 value_stay*value_stay + -0.3128 reward^2 + 0.4766 reward*decision_duration + 0.1952 reward*value_stay + 0.1237 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 32.4233\n",
      "Participant number 462\n",
      "value_stay[t+1] = 0.1672 1 + 0.8345 value_stay[t] + 0.3917 reward + 0.1924 decision_duration + 1.0 value_stay[t] + -0.097 value_stay^2 + -0.2798 value_stay*decision_duration + -0.3883 value_stay*value_stay + -0.2648 reward^2 + 0.3834 reward*decision_duration + 0.1769 decision_duration^2 + -0.3568 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 48.1975\n",
      "Participant number 463\n",
      "value_stay[t+1] = 0.1905 1 + 0.7668 value_stay[t] + 0.3672 reward + 0.2071 decision_duration + 1.0 value_stay[t] + -0.3026 value_stay*decision_duration + -0.4449 value_stay*value_stay + -0.249 reward^2 + 0.3733 reward*decision_duration + 0.1653 decision_duration^2 + -0.3105 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 43.3118\n",
      "Participant number 464\n",
      "value_stay[t+1] = 0.1527 1 + 0.8509 value_stay[t] + 0.3791 reward + 0.1957 decision_duration + 1.0 value_stay[t] + -0.123 value_stay^2 + -0.2814 value_stay*decision_duration + -0.3666 value_stay*value_stay + -0.2445 reward^2 + 0.3886 reward*decision_duration + 0.181 decision_duration^2 + -0.3537 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 43.6440\n",
      "Participant number 465\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4378 reward + 0.3018 decision_duration + 1.0 value_stay[t] + -0.1719 value_stay^2 + -0.6265 value_stay*reward + -0.3658 value_stay*decision_duration + -0.178 reward^2 + 0.465 reward*decision_duration + 0.1483 reward*value_stay \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.112 reward + 1.0 value_exit[t] + -0.1711 reward*value_exit \n",
      "beta(value) = 34.1759\n",
      "Participant number 466\n",
      "value_stay[t+1] = 0.121 1 + 0.8884 value_stay[t] + 0.4596 reward + 0.1518 decision_duration + 1.0 value_stay[t] + -0.1063 value_stay^2 + -0.3305 value_stay*reward + -0.2834 value_stay*decision_duration + -0.2478 value_stay*value_stay + -0.3169 reward^2 + 0.4601 reward*decision_duration + 0.1567 reward*value_stay + 0.1566 decision_duration^2 + -0.2088 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 54.5007\n",
      "Participant number 468\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.5105 reward + 0.2207 decision_duration + 1.0 value_stay[t] + -0.2574 value_stay^2 + -0.3008 value_stay*reward + -0.3232 value_stay*value_stay + -0.3533 reward^2 + 0.4956 reward*decision_duration + 0.1295 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 55.1760\n",
      "Participant number 469\n",
      "value_stay[t+1] = 0.2362 1 + 0.7487 value_stay[t] + 0.1587 reward + 0.2131 decision_duration + 1.0 value_stay[t] + -0.4919 value_stay*value_stay + 0.1587 reward*decision_duration + -0.3338 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 37.2742\n",
      "Participant number 470\n",
      "value_stay[t+1] = 0.1761 1 + 0.812 value_stay[t] + 0.3367 reward + 0.2035 decision_duration + 1.0 value_stay[t] + -0.3066 value_stay*decision_duration + -0.4319 value_stay*value_stay + -0.1993 reward^2 + 0.346 reward*decision_duration + 0.1826 decision_duration^2 + -0.3895 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 40.6182\n",
      "Participant number 471\n",
      "value_stay[t+1] = 0.176 1 + 0.8298 value_stay[t] + 0.4163 reward + 0.1942 decision_duration + 1.0 value_stay[t] + -0.1162 value_stay^2 + -0.2587 value_stay*decision_duration + -0.3915 value_stay*value_stay + -0.3109 reward^2 + 0.4192 reward*decision_duration + 0.159 decision_duration^2 + -0.3452 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 38.3110\n",
      "Participant number 472\n",
      "value_stay[t+1] = 0.1897 1 + 1.0 value_stay[t] + 0.1621 reward + 0.1932 decision_duration + 1.0 value_stay[t] + -0.164 value_stay^2 + -0.293 value_stay*decision_duration + -0.4142 value_stay*value_stay + 0.1694 reward*decision_duration + 0.1528 decision_duration^2 + -0.4671 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 51.2163\n",
      "Participant number 474\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.3259 reward + 0.2653 decision_duration + 1.0 value_stay[t] + -0.2992 value_stay^2 + -0.3892 value_stay*value_stay + -0.1701 reward^2 + 0.3211 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 59.2948\n",
      "Participant number 476\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4948 reward + 0.1952 decision_duration + 1.0 value_stay[t] + -0.2528 value_stay^2 + -0.26 value_stay*reward + -0.3149 value_stay*decision_duration + -0.2653 value_stay*value_stay + -0.3621 reward^2 + 0.4783 reward*decision_duration + 0.1834 reward*value_stay + 0.1728 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 23.6255\n",
      "Participant number 478\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.2784 reward + 0.2393 decision_duration + 1.0 value_stay[t] + -0.3678 value_stay^2 + -0.1834 value_stay*value_stay + 0.2109 reward*decision_duration + -0.2078 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 56.2717\n",
      "Participant number 480\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4792 reward + 0.3435 decision_duration + 1.0 value_stay[t] + -0.2086 value_stay^2 + -0.4631 value_stay*reward + -0.3377 value_stay*decision_duration + -0.1668 value_stay*value_stay + -0.3168 reward^2 + 0.4856 reward*decision_duration + 0.2029 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 42.1353\n",
      "Participant number 483\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4531 reward + 0.3111 decision_duration + 1.0 value_stay[t] + -0.2174 value_stay^2 + -0.3693 value_stay*reward + -0.2418 value_stay*decision_duration + -0.214 value_stay*value_stay + -0.2977 reward^2 + 0.4565 reward*decision_duration + 0.1645 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 49.6235\n",
      "Participant number 484\n",
      "value_stay[t+1] = 0.1824 1 + 0.8206 value_stay[t] + 0.3308 reward + 0.2137 decision_duration + 1.0 value_stay[t] + -0.3604 value_stay*decision_duration + -0.4231 value_stay*value_stay + -0.2023 reward^2 + 0.3425 reward*decision_duration + 0.1893 decision_duration^2 + -0.3929 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 44.4943\n",
      "Participant number 488\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.2932 decision_duration + 1.0 value_stay[t] + -0.7126 value_stay*reward + -0.5556 value_stay*decision_duration + 2.0818 reward*decision_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.1133 reward + 1.0 value_exit[t] + -0.1731 reward*value_exit \n",
      "beta(value) = 37.8969\n",
      "Participant number 491\n",
      "value_stay[t+1] = 0.2127 1 + 0.8104 value_stay[t] + 0.2675 reward + 0.2175 decision_duration + 1.0 value_stay[t] + -0.3418 value_stay*decision_duration + -0.4556 value_stay*value_stay + -0.12 reward^2 + 0.2758 reward*decision_duration + 0.1702 decision_duration^2 + -0.4066 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 38.6670\n",
      "Participant number 492\n",
      "value_stay[t+1] = 0.1455 1 + 0.8775 value_stay[t] + 0.4452 reward + 0.169 decision_duration + 1.0 value_stay[t] + -0.122 value_stay^2 + -0.2067 value_stay*reward + -0.337 value_stay*decision_duration + -0.2881 value_stay*value_stay + -0.3283 reward^2 + 0.4433 reward*decision_duration + 0.1062 reward*value_stay + 0.179 decision_duration^2 + -0.2609 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 25.1013\n",
      "Participant number 493\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.3723 reward + 0.3719 decision_duration + 1.0 value_stay[t] + -0.2747 value_stay^2 + -0.244 value_stay*decision_duration + -0.3572 value_stay*value_stay + -0.2606 reward^2 + 0.3758 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 44.5065\n",
      "Participant number 496\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4636 reward + 0.3487 decision_duration + 1.0 value_stay[t] + -0.2155 value_stay^2 + -0.3966 value_stay*reward + -0.3259 value_stay*decision_duration + -0.1963 value_stay*value_stay + -0.3094 reward^2 + 0.4706 reward*decision_duration + 0.1776 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 42.2817\n",
      "Participant number 497\n",
      "value_stay[t+1] = 0.1498 1 + 0.8629 value_stay[t] + 0.4527 reward + 0.1779 decision_duration + 1.0 value_stay[t] + -0.129 value_stay^2 + -0.1052 value_stay*reward + -0.3079 value_stay*decision_duration + -0.3106 value_stay*value_stay + -0.3284 reward^2 + 0.4549 reward*decision_duration + 0.1686 decision_duration^2 + -0.2709 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 35.7840\n",
      "Participant number 498\n",
      "value_stay[t+1] = 0.2075 1 + 0.8036 value_stay[t] + 0.2529 reward + 0.2056 decision_duration + 1.0 value_stay[t] + -0.3369 value_stay*decision_duration + -0.4331 value_stay*value_stay + -0.1155 reward^2 + 0.2493 reward*decision_duration + 0.1658 decision_duration^2 + -0.3436 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 35.6146\n",
      "Participant number 502\n",
      "value_stay[t+1] = 0.2338 1 + 0.7968 value_stay[t] + 0.1761 reward + 0.2142 decision_duration + 1.0 value_stay[t] + -0.3071 value_stay*decision_duration + -0.4778 value_stay*value_stay + 0.1849 reward*decision_duration + 0.1519 decision_duration^2 + -0.3925 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 55.0527\n",
      "Participant number 504\n",
      "value_stay[t+1] = 0.2204 1 + 0.8476 value_stay[t] + 0.1469 reward + 0.2103 decision_duration + 1.0 value_stay[t] + -0.3646 value_stay*decision_duration + -0.4148 value_stay*value_stay + 0.1492 reward*decision_duration + 0.1555 decision_duration^2 + -0.3838 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 39.4370\n",
      "Participant number 505\n",
      "value_stay[t+1] = 0.1595 1 + 0.8524 value_stay[t] + 0.4306 reward + 0.1656 decision_duration + 1.0 value_stay[t] + -0.1354 value_stay^2 + -0.1014 value_stay*reward + -0.2873 value_stay*decision_duration + -0.3034 value_stay*value_stay + -0.3222 reward^2 + 0.4207 reward*decision_duration + 0.1528 decision_duration^2 + -0.2174 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 35.5782\n",
      "Participant number 507\n",
      "value_stay[t+1] = 0.1686 1 + 0.839 value_stay[t] + 0.3767 reward + 0.1826 decision_duration + 1.0 value_stay[t] + -0.1081 value_stay^2 + -0.2297 value_stay*decision_duration + -0.3722 value_stay*value_stay + -0.266 reward^2 + 0.3836 reward*decision_duration + 0.1522 decision_duration^2 + -0.3394 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 56.3706\n",
      "Participant number 508\n",
      "value_stay[t+1] = 0.2217 1 + 0.811 value_stay[t] + 0.163 reward + 0.2077 decision_duration + 1.0 value_stay[t] + -0.32 value_stay*decision_duration + -0.4398 value_stay*value_stay + 0.1748 reward*decision_duration + 0.1492 decision_duration^2 + -0.3538 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 42.8764\n",
      "Participant number 509\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4834 reward + 0.1992 decision_duration + 1.0 value_stay[t] + -0.255 value_stay^2 + -0.1953 value_stay*reward + -0.2963 value_stay*decision_duration + -0.2979 value_stay*value_stay + -0.3737 reward^2 + 0.486 reward*decision_duration + 0.1658 reward*value_stay + 0.1681 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 43.6274\n",
      "Participant number 510\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4642 reward + 0.3318 decision_duration + 1.0 value_stay[t] + -0.2056 value_stay^2 + -0.3563 value_stay*reward + -0.2693 value_stay*decision_duration + -0.2541 value_stay*value_stay + -0.311 reward^2 + 0.4754 reward*decision_duration + 0.1572 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 47.0064\n",
      "Participant number 513\n",
      "value_stay[t+1] = 0.0992 1 + 1.0 value_stay[t] + 0.3636 reward + 1.0 value_stay[t] + -0.1089 value_stay^2 + -0.6261 value_stay*reward + -0.163 value_stay*value_stay + 0.2531 reward*decision_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.1311 reward + 1.0 value_exit[t] + -0.1986 reward*value_exit \n",
      "beta(value) = 24.7226\n",
      "Participant number 515\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4866 reward + 0.231 decision_duration + 1.0 value_stay[t] + -0.2281 value_stay^2 + -0.3682 value_stay*reward + -0.3819 value_stay*decision_duration + -0.1681 value_stay*value_stay + -0.3396 reward^2 + 0.4687 reward*decision_duration + 0.202 reward*value_stay + 0.1409 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 27.7845\n",
      "Participant number 516\n",
      "value_stay[t+1] = 0.2485 1 + 0.8993 value_stay[t] + 0.1322 reward + 0.2226 decision_duration + 1.0 value_stay[t] + -0.3792 value_stay*decision_duration + -0.4327 value_stay*value_stay + 0.1457 reward*decision_duration + 0.1418 decision_duration^2 + -0.5228 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 41.2897\n",
      "Participant number 517\n",
      "value_stay[t+1] = 0.1275 1 + 0.8547 value_stay[t] + 0.4466 reward + 0.1514 decision_duration + 1.0 value_stay[t] + -0.0056 value_stay^2 + -0.3348 value_stay*reward + -0.2583 value_stay*decision_duration + -0.2899 value_stay*value_stay + -0.2759 reward^2 + 0.4365 reward*decision_duration + 0.11 reward*value_stay + 0.1466 decision_duration^2 + -0.2291 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 56.6401\n",
      "Participant number 518\n",
      "value_stay[t+1] = 0.173 1 + 0.842 value_stay[t] + 0.4031 reward + 0.1812 decision_duration + 1.0 value_stay[t] + -0.1283 value_stay^2 + -0.1851 value_stay*decision_duration + -0.386 value_stay*value_stay + -0.2957 reward^2 + 0.4048 reward*decision_duration + 0.1377 decision_duration^2 + -0.3632 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 62.5990\n",
      "Participant number 523\n",
      "value_stay[t+1] = 0.2093 1 + 0.793 value_stay[t] + 0.3028 reward + 0.2037 decision_duration + 1.0 value_stay[t] + -0.3294 value_stay*decision_duration + -0.4371 value_stay*value_stay + -0.186 reward^2 + 0.2981 reward*decision_duration + 0.1626 decision_duration^2 + -0.3387 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 33.1020\n",
      "Participant number 524\n",
      "value_stay[t+1] = 0.1533 1 + 0.8645 value_stay[t] + 0.4337 reward + 0.1691 decision_duration + 1.0 value_stay[t] + -0.1172 value_stay^2 + -0.1275 value_stay*reward + -0.3157 value_stay*decision_duration + -0.2995 value_stay*value_stay + -0.3063 reward^2 + 0.4242 reward*decision_duration + 0.1651 decision_duration^2 + -0.2413 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 40.2074\n",
      "Participant number 525\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4506 reward + 0.2815 decision_duration + 1.0 value_stay[t] + -0.3041 value_stay^2 + -0.4658 value_stay*reward + -0.2601 value_stay*decision_duration + -0.2894 reward^2 + 0.5291 reward*decision_duration + 0.1669 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 46.1390\n",
      "Participant number 526\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.459 reward + 0.3323 decision_duration + 1.0 value_stay[t] + -0.224 value_stay^2 + -0.3331 value_stay*reward + -0.2721 value_stay*decision_duration + -0.2334 value_stay*value_stay + -0.3209 reward^2 + 0.465 reward*decision_duration + 0.1594 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 44.3666\n",
      "Participant number 529\n",
      "value_stay[t+1] = 0.1802 1 + 0.8356 value_stay[t] + 0.3779 reward + 0.1943 decision_duration + 1.0 value_stay[t] + -0.0961 value_stay^2 + -0.2655 value_stay*decision_duration + -0.3946 value_stay*value_stay + -0.266 reward^2 + 0.3846 reward*decision_duration + 0.1582 decision_duration^2 + -0.3606 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 53.0293\n",
      "Participant number 530\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.3591 reward + 0.223 decision_duration + 1.0 value_stay[t] + -0.5957 value_stay*reward + -0.5757 value_stay*decision_duration + 0.3479 reward*decision_duration + 0.1524 decision_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.1103 reward + 1.0 value_exit[t] + -0.1684 reward*value_exit \n",
      "beta(value) = 29.7015\n",
      "Participant number 531\n",
      "value_stay[t+1] = 0.1821 1 + 0.8153 value_stay[t] + 0.3636 reward + 0.1983 decision_duration + 1.0 value_stay[t] + -0.2829 value_stay*decision_duration + -0.4307 value_stay*value_stay + -0.2502 reward^2 + 0.3576 reward*decision_duration + 0.1665 decision_duration^2 + -0.3909 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 51.2491\n",
      "Participant number 535\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.3804 reward + 0.3549 decision_duration + 1.0 value_stay[t] + -0.2632 value_stay^2 + -0.1993 value_stay*decision_duration + -0.397 value_stay*value_stay + -0.2663 reward^2 + 0.3931 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 47.6626\n",
      "Participant number 536\n",
      "value_stay[t+1] = 0.1603 1 + 1.0 value_stay[t] + 0.1656 reward + 0.1738 decision_duration + 1.0 value_stay[t] + -0.1909 value_stay^2 + -0.237 value_stay*decision_duration + -0.3766 value_stay*value_stay + 0.1672 reward*decision_duration + 0.1461 decision_duration^2 + -0.3846 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 61.3319\n"
     ]
    }
   ],
   "source": [
    "print('OVERHARVESTERS') \n",
    "for p in overharvesters:\n",
    "    print('Participant number', p)\n",
    "    estimator.print_spice_model(participant_id=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNDERHARVESTERS\n",
      "Participant number 0\n",
      "value_stay[t+1] = 0.2411 1 + 0.7746 value_stay[t] + 0.239 reward + 0.2075 decision_duration + 1.0 value_stay[t] + -0.2934 value_stay*decision_duration + -0.4747 value_stay*value_stay + 0.241 reward*decision_duration + -0.172 reward*value_stay + 0.1384 decision_duration^2 + -0.339 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 27.7513\n",
      "Participant number 2\n",
      "value_stay[t+1] = 0.254 1 + 1.0 value_stay[t] + -0.2787 reward + 1.0 value_stay[t] + -0.2553 value_stay^2 + -0.2022 value_stay*reward + -0.1779 value_stay*value_stay + 0.6467 reward^2 + -0.4428 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 66.9040\n",
      "Participant number 3\n",
      "value_stay[t+1] = 0.1424 1 + 1.0 value_stay[t] + 0.1433 decision_duration + 1.0 value_stay[t] + -0.2246 value_stay^2 + -0.2348 value_stay*decision_duration + -0.3834 value_stay*value_stay + 0.2932 reward^2 + -0.2295 reward*value_stay + 0.1167 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 63.2399\n",
      "Participant number 5\n",
      "value_stay[t+1] = 0.238 1 + 0.8749 value_stay[t] + 0.1982 decision_duration + 1.0 value_stay[t] + -0.1023 value_stay^2 + -0.2961 value_stay*decision_duration + -0.3994 value_stay*value_stay + 0.1355 reward^2 + 0.2664 reward*decision_duration + 0.1262 decision_duration^2 + -0.3876 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 47.3926\n",
      "Participant number 6\n",
      "value_stay[t+1] = 0.2136 1 + 0.8009 value_stay[t] + 0.1731 reward + 0.2145 decision_duration + 1.0 value_stay[t] + -0.344 value_stay*decision_duration + -0.4428 value_stay*value_stay + 0.1803 reward*decision_duration + 0.1671 decision_duration^2 + -0.3482 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 43.2292\n",
      "Participant number 8\n",
      "value_stay[t+1] = 0.1286 1 + 0.8145 value_stay[t] + 0.1935 decision_duration + 1.0 value_stay[t] + -0.4118 value_stay^2 + -0.1201 value_stay*value_stay + 0.592 reward*decision_duration \n",
      "value_exit[t+1] = 0.127 1 + 0.6684 value_exit[t] + 0.1826 reward + 1.1062 value_exit[t] + -0.3937 value_exit^2 + -0.2158 value_exit*value_exit + 0.3234 reward*decision_duration + 0.1949 decision_duration*value_exit + 0.15 value_exit^2 \n",
      "beta(value) = 35.1045\n",
      "Participant number 9\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4146 reward + 0.3226 decision_duration + 1.0 value_stay[t] + -0.335 value_stay^2 + -0.3949 value_stay*reward + -0.3155 value_stay*decision_duration + -0.2659 reward^2 + 0.4139 reward*decision_duration + 0.1899 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 17.0173\n",
      "Participant number 10\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4124 reward + 0.3509 decision_duration + 1.0 value_stay[t] + -0.2435 value_stay^2 + -0.4892 value_stay*reward + -0.4112 value_stay*decision_duration + -0.2077 reward^2 + 0.398 reward*decision_duration + 0.1635 reward*value_stay \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.1186 reward + 1.0 value_exit[t] + -0.1808 reward*value_exit \n",
      "beta(value) = 17.6649\n",
      "Participant number 11\n",
      "value_stay[t+1] = 0.2217 1 + 0.8812 value_stay[t] + 0.176 decision_duration + 1.0 value_stay[t] + -0.192 value_stay^2 + -0.3376 value_stay*value_stay + 0.2522 reward^2 + -0.1605 reward*value_stay + -0.2809 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 58.6783\n",
      "Participant number 15\n",
      "value_stay[t+1] = 0.1779 1 + 0.8842 value_stay[t] + 0.157 decision_duration + 1.0 value_stay[t] + -0.2236 value_stay^2 + -0.2798 value_stay*decision_duration + -0.1363 value_stay*value_stay + 0.3003 reward^2 + -0.515 reward*value_stay + 0.1538 decision_duration*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 53.4597\n",
      "Participant number 16\n",
      "value_stay[t+1] = 0.1627 1 + 1.0 value_stay[t] + 0.1189 decision_duration + 1.0 value_stay[t] + -0.2929 value_stay^2 + -0.109 value_stay*reward + -0.2629 value_stay*value_stay + 0.4305 reward^2 + -0.203 reward*decision_duration + -0.394 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 67.4591\n",
      "Participant number 17\n",
      "value_stay[t+1] = 0.2076 1 + 0.8163 value_stay[t] + 0.1704 reward + 0.2125 decision_duration + 1.0 value_stay[t] + -0.3573 value_stay*decision_duration + -0.4318 value_stay*value_stay + 0.1849 reward*decision_duration + 0.1757 decision_duration^2 + -0.3655 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 46.3437\n",
      "Participant number 18\n",
      "value_stay[t+1] = 0.1623 1 + 1.0 value_stay[t] + 0.1399 decision_duration + 1.0 value_stay[t] + -0.2792 value_stay^2 + -0.2773 value_stay*decision_duration + -0.2954 value_stay*value_stay + 0.3567 reward^2 + -0.4039 reward*value_stay + 0.1166 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 54.8228\n",
      "Participant number 19\n",
      "value_stay[t+1] = 0.213 1 + 0.8633 value_stay[t] + 0.1858 reward + 0.2015 decision_duration + 1.0 value_stay[t] + -0.0975 value_stay^2 + -0.2481 value_stay*decision_duration + -0.4267 value_stay*value_stay + 0.1854 reward*decision_duration + 0.1454 decision_duration^2 + -0.4399 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 62.1646\n",
      "Participant number 21\n",
      "value_stay[t+1] = 0.2412 1 + 0.8666 value_stay[t] + 0.1873 decision_duration + 1.0 value_stay[t] + -0.1479 value_stay^2 + -0.2651 value_stay*decision_duration + -0.3775 value_stay*value_stay + 0.1843 reward^2 + 0.1226 decision_duration^2 + -0.3226 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 25.8384\n",
      "Participant number 22\n",
      "value_stay[t+1] = 0.1865 1 + 0.8716 value_stay[t] + -0.1164 reward + 0.2503 decision_duration + 1.0 value_stay[t] + -0.2339 value_stay^2 + -0.2451 value_stay*decision_duration + -0.2229 value_stay*value_stay + 0.3537 reward^2 + -0.2644 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 27.6478\n",
      "Participant number 28\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.3338 reward + 0.2517 decision_duration + 1.0 value_stay[t] + -0.515 value_stay^2 + -0.1536 value_stay*value_stay + -0.2246 reward^2 + 0.3253 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 26.0038\n",
      "Participant number 29\n",
      "value_stay[t+1] = 0.2074 1 + 1.0 value_stay[t] + -0.203 reward + 0.1509 decision_duration + 1.0 value_stay[t] + -0.2793 value_stay^2 + -0.2947 value_stay*decision_duration + -0.2085 value_stay*value_stay + 0.4323 reward^2 + -0.1934 reward*decision_duration + -0.3288 reward*value_stay + 0.1109 decision_duration*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 38.0383\n",
      "Participant number 31\n",
      "value_stay[t+1] = 0.2143 1 + 0.8692 value_stay[t] + 0.1305 decision_duration + 1.0 value_stay[t] + -0.1763 value_stay^2 + -0.3989 value_stay*value_stay + 0.3687 reward^2 + -0.4458 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 64.4635\n",
      "Participant number 34\n",
      "value_stay[t+1] = 0.2271 1 + 0.8136 value_stay[t] + 0.2509 reward + 0.21 decision_duration + 1.0 value_stay[t] + -0.3175 value_stay*decision_duration + -0.4558 value_stay*value_stay + 0.2522 reward*decision_duration + -0.1973 reward*value_stay + 0.1504 decision_duration^2 + -0.3887 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 46.4368\n",
      "Participant number 39\n",
      "value_stay[t+1] = 0.2962 1 + 0.8652 value_stay[t] + 0.2155 decision_duration + 1.0 value_stay[t] + -0.3324 value_stay*decision_duration + -0.4825 value_stay*value_stay + 0.1699 reward^2 + 0.1145 decision_duration^2 + -0.4995 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 41.1112\n",
      "Participant number 40\n",
      "value_stay[t+1] = 0.2072 1 + 0.8098 value_stay[t] + 0.1716 reward + 0.2153 decision_duration + 1.0 value_stay[t] + -0.3535 value_stay*decision_duration + -0.4316 value_stay*value_stay + 0.1812 reward*decision_duration + 0.1713 decision_duration^2 + -0.353 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 41.3916\n",
      "Participant number 41\n",
      "value_stay[t+1] = 0.1893 1 + 0.8607 value_stay[t] + 0.1828 decision_duration + 1.0 value_stay[t] + -0.2542 value_stay^2 + -0.222 value_stay*decision_duration + -0.2255 value_stay*value_stay + 0.3189 reward^2 + -0.1659 reward*decision_duration + -0.3377 reward*value_stay + 0.1302 decision_duration*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 15.7223\n",
      "Participant number 42\n",
      "value_stay[t+1] = 0.1991 1 + 0.8846 value_stay[t] + 0.1537 decision_duration + 1.0 value_stay[t] + -0.1447 value_stay^2 + -0.2921 value_stay*decision_duration + -0.3172 value_stay*value_stay + 0.3652 reward^2 + -0.4248 reward*value_stay + 0.1065 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 50.0365\n",
      "Participant number 48\n",
      "value_stay[t+1] = 0.1935 1 + 0.8636 value_stay[t] + 0.1503 decision_duration + 1.0 value_stay[t] + -0.1897 value_stay^2 + -0.38 value_stay*value_stay + 0.339 reward^2 + -0.3428 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 57.2150\n",
      "Participant number 50\n",
      "value_stay[t+1] = 0.2013 1 + 0.7897 value_stay[t] + 0.172 reward + 0.2046 decision_duration + 1.0 value_stay[t] + -0.3109 value_stay*decision_duration + -0.4267 value_stay*value_stay + 0.18 reward*decision_duration + 0.1617 decision_duration^2 + -0.3074 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 56.6537\n",
      "Participant number 52\n",
      "value_stay[t+1] = 0.1839 1 + 0.8856 value_stay[t] + 0.2498 decision_duration + 1.0 value_stay[t] + -0.1921 value_stay^2 + -0.2252 value_stay*decision_duration + -0.3154 value_stay*value_stay + 0.3667 reward^2 + -0.4399 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 41.9820\n",
      "Participant number 53\n",
      "value_stay[t+1] = 0.2524 1 + 0.8535 value_stay[t] + 0.21 decision_duration + 1.0 value_stay[t] + -0.3844 value_stay*decision_duration + -0.4142 value_stay*value_stay + 0.1863 reward^2 + 0.2726 reward*decision_duration + -0.1631 reward*value_stay + 0.1304 decision_duration^2 + -0.3648 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 30.0199\n",
      "Participant number 55\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.1934 reward + 0.3776 decision_duration + 1.0 value_stay[t] + -0.3194 value_stay^2 + -0.2195 value_stay*decision_duration + -0.3229 value_stay*value_stay + 0.2144 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 33.1140\n",
      "Participant number 56\n",
      "value_stay[t+1] = 0.1796 1 + 0.8818 value_stay[t] + 0.1527 decision_duration + 1.0 value_stay[t] + -0.2068 value_stay^2 + -0.3595 value_stay*value_stay + 0.3245 reward^2 + -0.3302 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 66.3362\n",
      "Participant number 57\n",
      "value_stay[t+1] = 0.2221 1 + 0.875 value_stay[t] + 0.1318 reward + 0.2148 decision_duration + 1.0 value_stay[t] + -0.4181 value_stay*decision_duration + -0.3902 value_stay*value_stay + 0.1357 reward*decision_duration + 0.1626 decision_duration^2 + -0.4032 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 26.2364\n",
      "Participant number 58\n",
      "value_stay[t+1] = 0.2276 1 + 1.0 value_stay[t] + -0.2176 reward + 0.1777 decision_duration + 1.0 value_stay[t] + -0.3102 value_stay^2 + -0.2478 value_stay*decision_duration + -0.2182 value_stay*value_stay + 0.4545 reward^2 + -0.2027 reward*decision_duration + -0.3441 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 52.6994\n",
      "Participant number 60\n",
      "value_stay[t+1] = 0.194 1 + 0.8978 value_stay[t] + 0.1986 decision_duration + 1.0 value_stay[t] + -0.2243 value_stay^2 + -0.2786 value_stay*decision_duration + -0.2333 value_stay*value_stay + 0.4131 reward^2 + -0.2392 reward*decision_duration + -0.4716 reward*value_stay + 0.12 decision_duration*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 29.7488\n",
      "Participant number 61\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.1851 reward + 0.3923 decision_duration + 1.0 value_stay[t] + -0.2507 value_stay^2 + -0.2733 value_stay*decision_duration + -0.3353 value_stay*value_stay + 0.1901 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 52.9018\n",
      "Participant number 62\n",
      "value_stay[t+1] = 0.2475 1 + 0.89 value_stay[t] + 0.1982 decision_duration + 1.0 value_stay[t] + -0.1256 value_stay^2 + -0.2963 value_stay*decision_duration + -0.3887 value_stay*value_stay + 0.1847 reward^2 + 0.1257 decision_duration^2 + -0.3883 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 44.6575\n",
      "Participant number 63\n",
      "value_stay[t+1] = 0.1828 1 + 0.8828 value_stay[t] + 0.2378 decision_duration + 1.0 value_stay[t] + -0.215 value_stay^2 + -0.2218 value_stay*decision_duration + -0.2428 value_stay*value_stay + 0.3832 reward^2 + -0.4962 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 46.5928\n",
      "Participant number 64\n",
      "value_stay[t+1] = 0.2321 1 + 1.0 value_stay[t] + -0.3293 reward + 1.1261 value_stay[t] + -0.3751 value_stay^2 + -0.2403 value_stay*value_stay + 0.5827 reward^2 + -0.4721 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 51.7819\n",
      "Participant number 65\n",
      "value_stay[t+1] = 0.3024 1 + 1.0 value_stay[t] + -0.3099 reward + 1.0 value_stay[t] + -0.3834 value_stay^2 + -0.2444 value_stay*value_stay + 0.5379 reward^2 + -0.1016 reward*decision_duration + -0.418 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 37.2279\n",
      "Participant number 67\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.3505 decision_duration + 1.0 value_stay[t] + -0.2655 value_stay^2 + -0.2219 value_stay*reward + -0.3188 value_stay*decision_duration + 0.2973 reward^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 66.0922\n",
      "Participant number 69\n",
      "value_stay[t+1] = 0.2258 1 + 1.0 value_stay[t] + 0.2018 decision_duration + 1.0 value_stay[t] + -0.1257 value_stay^2 + -0.3903 value_stay*decision_duration + -0.4067 value_stay*value_stay + 0.1749 reward^2 + 0.2995 reward*decision_duration + -0.1522 reward*value_stay + 0.1364 decision_duration^2 + -0.4134 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 36.3893\n",
      "Participant number 76\n",
      "value_stay[t+1] = 0.1662 1 + 1.0 value_stay[t] + 0.1487 decision_duration + 1.0 value_stay[t] + -0.2163 value_stay^2 + -0.3007 value_stay*decision_duration + -0.3545 value_stay*value_stay + 0.3483 reward^2 + -0.4139 reward*value_stay + 0.1157 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 55.7738\n",
      "Participant number 83\n",
      "value_stay[t+1] = 0.1775 1 + 0.8792 value_stay[t] + 0.1294 decision_duration + 1.0 value_stay[t] + -0.2 value_stay^2 + -0.2233 value_stay*reward + -0.1396 value_stay*value_stay + 0.3722 reward^2 + -0.885 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 65.5188\n",
      "Participant number 85\n",
      "value_stay[t+1] = 0.1574 1 + 1.0 value_stay[t] + 0.1411 decision_duration + 1.0 value_stay[t] + -0.2998 value_stay^2 + -0.2749 value_stay*decision_duration + -0.263 value_stay*value_stay + 0.3488 reward^2 + -0.4063 reward*value_stay + 0.1154 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 44.7968\n",
      "Participant number 87\n",
      "value_stay[t+1] = 0.2131 1 + 0.8639 value_stay[t] + 0.1783 reward + 0.1939 decision_duration + 1.0 value_stay[t] + -0.1018 value_stay^2 + -0.2377 value_stay*decision_duration + -0.421 value_stay*value_stay + 0.1874 reward*decision_duration + 0.1456 decision_duration^2 + -0.44 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 58.6324\n",
      "Participant number 88\n",
      "value_stay[t+1] = 0.1378 1 + 0.804 value_stay[t] + 0.1314 decision_duration + 1.132 value_stay[t] + -0.2703 value_stay^2 + -0.2168 value_stay*decision_duration + -0.1228 value_stay*value_stay + 0.3288 reward^2 + -0.3105 reward*decision_duration + -0.2375 reward*value_stay + 0.1098 decision_duration^2 \n",
      "value_exit[t+1] = 0.2089 1 + 1.0 value_exit[t] + 1.0 value_exit[t] + -0.34 value_exit^2 + -0.4059 value_exit*reward + -0.2556 value_exit*value_exit + 0.2956 reward^2 + -0.7181 reward*decision_duration + 0.2637 reward*value_exit \n",
      "beta(value) = 19.3111\n",
      "Participant number 89\n",
      "value_stay[t+1] = 0.1537 1 + 0.8475 value_stay[t] + 0.1692 decision_duration + 1.0 value_stay[t] + -0.1773 value_stay*reward + -0.3416 value_stay*decision_duration + -0.3736 value_stay*value_stay + 0.2743 reward^2 + 0.1492 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 51.1136\n",
      "Participant number 91\n",
      "value_stay[t+1] = 0.204 1 + 0.8927 value_stay[t] + 0.2453 decision_duration + 1.0 value_stay[t] + -0.198 value_stay^2 + -0.2578 value_stay*decision_duration + -0.269 value_stay*value_stay + 0.4361 reward^2 + -0.2377 reward*decision_duration + -0.5168 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 49.5166\n",
      "Participant number 94\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.408 decision_duration + 1.0 value_stay[t] + -0.231 value_stay^2 + -0.2669 value_stay*reward + -0.4457 value_stay*decision_duration + 0.3091 reward^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 58.8720\n",
      "Participant number 96\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.3451 decision_duration + 1.1505 value_stay[t] + -0.2038 value_stay^2 + -0.1784 value_stay*reward + -0.3204 value_stay*decision_duration + -0.3336 value_stay*value_stay + 0.2827 reward^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 38.6976\n",
      "Participant number 98\n",
      "value_stay[t+1] = 0.1938 1 + 0.8393 value_stay[t] + 0.1766 decision_duration + 1.0 value_stay[t] + -0.3265 value_stay*decision_duration + -0.4971 value_stay*value_stay + 0.2511 reward^2 + -0.1693 reward*value_stay + 0.1324 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 42.8784\n",
      "Participant number 102\n",
      "value_stay[t+1] = 0.1824 1 + 0.8824 value_stay[t] + 0.2542 decision_duration + 1.0 value_stay[t] + -0.1403 value_stay^2 + -0.2182 value_stay*decision_duration + -0.3873 value_stay*value_stay + 0.3523 reward^2 + -0.3864 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 52.5762\n",
      "Participant number 106\n",
      "value_stay[t+1] = 0.1456 1 + 0.8365 value_stay[t] + 0.1528 reward + 0.1717 decision_duration + 1.0 value_stay[t] + -0.3303 value_stay*decision_duration + -0.5012 value_stay*value_stay + 0.1591 reward*decision_duration + 0.171 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 28.0194\n",
      "Participant number 107\n",
      "value_stay[t+1] = 0.1706 1 + 0.8877 value_stay[t] + 0.2442 decision_duration + 1.0 value_stay[t] + -0.194 value_stay^2 + -0.2144 value_stay*decision_duration + -0.2688 value_stay*value_stay + 0.3629 reward^2 + -0.4353 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 60.8875\n",
      "Participant number 108\n",
      "value_stay[t+1] = 0.2231 1 + 1.0 value_stay[t] + -0.2223 reward + 0.1741 decision_duration + 1.0 value_stay[t] + -0.2683 value_stay^2 + -0.1087 value_stay*reward + -0.2719 value_stay*decision_duration + -0.1733 value_stay*value_stay + 0.5023 reward^2 + -0.2059 reward*decision_duration + -0.3277 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 65.0536\n",
      "Participant number 111\n",
      "value_stay[t+1] = 0.1458 1 + 0.872 value_stay[t] + 0.1578 decision_duration + 1.0 value_stay[t] + -0.1198 value_stay^2 + -0.2096 value_stay*decision_duration + -0.4656 value_stay*value_stay + 0.1463 reward^2 + 0.2712 reward*decision_duration + 0.1278 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 60.5029\n",
      "Participant number 117\n",
      "value_stay[t+1] = 0.3002 1 + 0.8155 value_stay[t] + 0.3024 decision_duration + 1.0 value_stay[t] + -0.1233 value_stay^2 + 0.2717 value_stay*reward + -0.1744 value_stay*decision_duration + -0.5284 value_stay*value_stay + 0.1323 reward*decision_duration + -0.4973 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 33.4586\n",
      "Participant number 118\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.3527 reward + 0.2605 decision_duration + 1.0 value_stay[t] + -0.7483 value_stay*reward + -0.4283 value_stay*decision_duration + 0.6245 reward*decision_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.1287 reward + 1.0 value_exit[t] + -0.1952 reward*value_exit \n",
      "beta(value) = 18.5798\n",
      "Participant number 119\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.3022 reward + 0.1783 decision_duration + 1.0 value_stay[t] + -0.5645 value_stay*reward + -0.2808 value_stay*decision_duration + 0.2952 reward*decision_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.1325 reward + 1.0 value_exit[t] + -0.2018 reward*value_exit \n",
      "beta(value) = 15.9893\n",
      "Participant number 129\n",
      "value_stay[t+1] = 0.2093 1 + 0.8921 value_stay[t] + -0.2738 reward + 0.1823 decision_duration + 1.1132 value_stay[t] + -0.2262 value_stay^2 + -0.2855 value_stay*decision_duration + -0.1887 value_stay*value_stay + 0.4925 reward^2 + -0.3868 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 35.7484\n",
      "Participant number 136\n",
      "value_stay[t+1] = 0.2026 1 + 1.0 value_stay[t] + 0.1884 decision_duration + 1.0 value_stay[t] + -0.2139 value_stay^2 + -0.3155 value_stay*decision_duration + -0.3746 value_stay*value_stay + 0.1889 reward^2 + 0.1438 decision_duration^2 + -0.3578 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 40.7939\n",
      "Participant number 137\n",
      "value_stay[t+1] = 0.1301 1 + 0.8329 value_stay[t] + 0.167 reward + 0.1323 decision_duration + 1.0 value_stay[t] + -0.3633 value_stay^2 + -0.2208 value_stay*value_stay + 0.1667 reward*decision_duration + 0.1304 decision_duration*value_stay \n",
      "value_exit[t+1] = 0.3379 1 + 0.8167 value_exit[t] + 1.1248 value_exit[t] + -0.3541 value_exit^2 + -0.2595 value_exit*value_exit + -0.1314 decision_duration^2 \n",
      "beta(value) = 44.2567\n",
      "Participant number 138\n",
      "value_stay[t+1] = 0.2256 1 + 0.8834 value_stay[t] + 0.149 decision_duration + 1.0 value_stay[t] + -0.2404 value_stay^2 + -0.2937 value_stay*value_stay + 0.3387 reward^2 + -0.3589 reward*value_stay + -0.1807 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 62.5717\n",
      "Participant number 141\n",
      "value_stay[t+1] = 0.2368 1 + 1.0 value_stay[t] + 1.0 value_stay[t] + -0.1723 value_stay^2 + -0.3523 value_stay*reward + -0.146 value_stay*value_stay + 0.6719 reward^2 + -0.3323 reward*decision_duration + -0.7511 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 66.3378\n",
      "Participant number 145\n",
      "value_stay[t+1] = 0.2257 1 + 0.8229 value_stay[t] + 0.1525 reward + 0.2084 decision_duration + 1.0 value_stay[t] + -0.3406 value_stay*decision_duration + -0.4315 value_stay*value_stay + 0.1543 reward*decision_duration + 0.1513 decision_duration^2 + -0.3648 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 36.4130\n",
      "Participant number 147\n",
      "value_stay[t+1] = 0.1959 1 + 0.8893 value_stay[t] + 0.1538 decision_duration + 1.0 value_stay[t] + -0.1826 value_stay^2 + -0.2447 value_stay*decision_duration + -0.3801 value_stay*value_stay + 0.2968 reward^2 + -0.2662 reward*value_stay + 0.1037 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 18.0991\n",
      "Participant number 149\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.1951 reward + 0.3516 decision_duration + 1.0 value_stay[t] + -0.315 value_stay^2 + -0.1796 value_stay*decision_duration + -0.3053 value_stay*value_stay + 0.2017 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 55.2859\n",
      "Participant number 150\n",
      "value_stay[t+1] = 0.2187 1 + 0.8215 value_stay[t] + 0.156 reward + 0.2114 decision_duration + 1.0 value_stay[t] + -0.3472 value_stay*decision_duration + -0.4324 value_stay*value_stay + 0.1662 reward*decision_duration + 0.1597 decision_duration^2 + -0.3672 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 41.8519\n",
      "Participant number 151\n",
      "value_stay[t+1] = 0.1893 1 + 0.8891 value_stay[t] + 0.2462 decision_duration + 1.0 value_stay[t] + -0.1725 value_stay^2 + -0.2288 value_stay*decision_duration + -0.3369 value_stay*value_stay + 0.3745 reward^2 + -0.4664 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 58.3973\n",
      "Participant number 155\n",
      "value_stay[t+1] = 0.1893 1 + 0.8222 value_stay[t] + 0.1753 decision_duration + 1.0 value_stay[t] + -0.258 value_stay*decision_duration + -0.564 value_stay*value_stay + 0.1892 reward^2 + 0.1259 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 56.3305\n",
      "Participant number 156\n",
      "value_stay[t+1] = 0.1893 1 + 0.8876 value_stay[t] + 0.2519 decision_duration + 1.0 value_stay[t] + -0.212 value_stay^2 + -0.2612 value_stay*decision_duration + -0.2524 value_stay*value_stay + 0.3885 reward^2 + -0.5269 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 39.4024\n",
      "Participant number 157\n",
      "value_stay[t+1] = 0.1717 1 + 0.8592 value_stay[t] + 0.1333 decision_duration + 1.0 value_stay[t] + -0.3505 value_stay^2 + -0.1049 value_stay*value_stay + 0.26 reward^2 + -0.3287 reward*value_stay \n",
      "value_exit[t+1] = 0.2046 1 + 0.8598 value_exit[t] + 0.1511 reward + 1.0 value_exit[t] + -0.465 value_exit^2 + -0.2179 value_exit*reward \n",
      "beta(value) = 37.6761\n",
      "Participant number 158\n",
      "value_stay[t+1] = 0.2018 1 + 1.0 value_stay[t] + -0.1535 reward + 0.2194 decision_duration + 1.0 value_stay[t] + -0.2931 value_stay^2 + -0.2559 value_stay*decision_duration + -0.2886 value_stay*value_stay + 0.4524 reward^2 + -0.1291 reward*decision_duration + -0.3621 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 38.1373\n",
      "Participant number 159\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.1949 decision_duration + 1.0 value_stay[t] + -0.3097 value_stay^2 + -0.1531 value_stay*reward + 0.2628 reward^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 62.4428\n",
      "Participant number 163\n",
      "value_stay[t+1] = 0.1732 1 + 1.0 value_stay[t] + 0.187 decision_duration + 1.0 value_stay[t] + -0.2431 value_stay^2 + -0.129 value_stay*reward + -0.3486 value_stay*decision_duration + -0.1933 value_stay*value_stay + 0.4755 reward^2 + -0.3451 reward*decision_duration + -0.4983 reward*value_stay + 0.1474 decision_duration*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 51.5592\n",
      "Participant number 169\n",
      "value_stay[t+1] = 0.2091 1 + 1.0 value_stay[t] + 0.1759 decision_duration + 1.0 value_stay[t] + -0.2158 value_stay^2 + -0.2975 value_stay*decision_duration + -0.3593 value_stay*value_stay + 0.2646 reward^2 + -0.1643 reward*value_stay + 0.1233 decision_duration^2 + -0.2957 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 51.5253\n",
      "Participant number 170\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.1881 reward + 0.3794 decision_duration + 1.0 value_stay[t] + -0.3305 value_stay^2 + -0.2501 value_stay*decision_duration + -0.2527 value_stay*value_stay + 0.1808 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 47.4464\n",
      "Participant number 173\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.3286 decision_duration + 1.0 value_stay[t] + -0.4322 value_stay^2 + -0.2167 value_stay*decision_duration + 0.1354 reward^2 \n",
      "value_exit[t+1] = 0.1315 1 + 1.0 value_exit[t] + 0.1634 reward + 1.0 value_exit[t] + -0.4926 value_exit^2 + -0.2144 value_exit*reward \n",
      "beta(value) = 47.8254\n",
      "Participant number 175\n",
      "value_stay[t+1] = 0.1844 1 + 1.0 value_stay[t] + 0.1873 decision_duration + 1.0 value_stay[t] + -0.2159 value_stay^2 + -0.3155 value_stay*decision_duration + -0.3578 value_stay*value_stay + 0.1492 reward^2 + 0.1941 reward*decision_duration + 0.1476 decision_duration^2 + -0.3507 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 49.8863\n",
      "Participant number 178\n",
      "value_stay[t+1] = 0.1639 1 + 0.8675 value_stay[t] + 0.1571 decision_duration + 1.0 value_stay[t] + -0.2506 value_stay^2 + -0.2098 value_stay*decision_duration + -0.2096 value_stay*value_stay + 0.1841 reward^2 + 0.138 decision_duration^2 + -0.1459 value_stay^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.3125 reward + 1.2076 value_exit[t] + -0.5444 value_exit*reward + -0.4711 value_exit*value_exit + 0.2048 reward*decision_duration \n",
      "beta(value) = 33.0863\n",
      "Participant number 179\n",
      "value_stay[t+1] = 0.1841 1 + 1.0 value_stay[t] + 0.1521 decision_duration + 1.0 value_stay[t] + -0.2525 value_stay^2 + -0.1313 value_stay*reward + -0.3239 value_stay*decision_duration + -0.1553 value_stay*value_stay + 0.4167 reward^2 + -0.4068 reward*decision_duration + -0.4729 reward*value_stay + 0.1496 decision_duration*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 50.7485\n",
      "Participant number 180\n",
      "value_stay[t+1] = 0.2838 1 + 0.8169 value_stay[t] + 0.2129 decision_duration + 1.0 value_stay[t] + -0.3311 value_stay*decision_duration + -0.4816 value_stay*value_stay + 0.1788 reward^2 + 0.1268 decision_duration^2 + -0.4038 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 33.3505\n",
      "Participant number 183\n",
      "value_stay[t+1] = 0.149 1 + 0.8635 value_stay[t] + 0.1124 decision_duration + 1.0 value_stay[t] + -0.3422 value_stay^2 + 0.1714 reward^2 + -0.2802 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 62.1033\n",
      "Participant number 187\n",
      "value_stay[t+1] = 0.2162 1 + 0.791 value_stay[t] + 0.1626 reward + 0.2065 decision_duration + 1.0 value_stay[t] + -0.3294 value_stay*decision_duration + -0.4346 value_stay*value_stay + 0.1633 reward*decision_duration + 0.1565 decision_duration^2 + -0.3038 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 35.7930\n",
      "Participant number 190\n",
      "value_stay[t+1] = 0.2275 1 + 0.8228 value_stay[t] + 0.1631 reward + 0.2178 decision_duration + 1.0 value_stay[t] + -0.3388 value_stay*decision_duration + -0.4534 value_stay*value_stay + 0.1719 reward*decision_duration + 0.155 decision_duration^2 + -0.4025 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 52.7109\n",
      "Participant number 192\n",
      "value_stay[t+1] = 0.1639 1 + 0.8628 value_stay[t] + 0.1641 decision_duration + 1.0 value_stay[t] + -0.104 value_stay^2 + -0.2298 value_stay*decision_duration + -0.4533 value_stay*value_stay + 0.1933 reward^2 + 0.1245 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 63.1017\n",
      "Participant number 193\n",
      "value_stay[t+1] = 0.1441 1 + 1.0 value_stay[t] + 0.1326 decision_duration + 1.0 value_stay[t] + -0.3847 value_stay^2 + -0.248 value_stay*decision_duration + -0.1389 value_stay*value_stay + 0.2938 reward^2 + -0.3467 reward*value_stay + 0.1114 decision_duration^2 \n",
      "value_exit[t+1] = 0.1724 1 + 0.8674 value_exit[t] + 0.1292 reward + 1.0 value_exit[t] + -0.39 value_exit^2 + -0.1555 value_exit*reward \n",
      "beta(value) = 45.8895\n",
      "Participant number 196\n",
      "value_stay[t+1] = 0.2613 1 + 0.8685 value_stay[t] + 0.2485 reward + 0.2134 decision_duration + 1.0 value_stay[t] + -0.4019 value_stay*decision_duration + -0.4315 value_stay*value_stay + 0.2432 reward*decision_duration + -0.3066 reward*value_stay + 0.1392 decision_duration^2 + -0.4403 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 20.6141\n",
      "Participant number 197\n",
      "value_stay[t+1] = 0.2851 1 + 0.8186 value_stay[t] + 0.1621 reward + 0.3032 decision_duration + 1.0 value_stay[t] + -0.1381 value_stay^2 + 0.3197 value_stay*reward + -0.1753 value_stay*decision_duration + -0.5073 value_stay*value_stay + 0.1746 reward*decision_duration + -0.3826 reward*value_stay + -0.4619 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 37.1321\n",
      "Participant number 200\n",
      "value_stay[t+1] = 0.1596 1 + 1.0 value_stay[t] + 0.1487 decision_duration + 1.0 value_stay[t] + -0.1996 value_stay^2 + -0.2253 value_stay*reward + -0.2533 value_stay*decision_duration + -0.2887 value_stay*value_stay + 0.3072 reward^2 + 0.13 decision_duration^2 + -0.2107 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 62.6765\n",
      "Participant number 201\n",
      "value_stay[t+1] = 0.1283 1 + 0.8635 value_stay[t] + 0.2054 decision_duration + 1.0 value_stay[t] + -0.3467 value_stay^2 + -0.2099 value_stay*value_stay + 0.1404 reward^2 \n",
      "value_exit[t+1] = 0.3123 1 + 0.7938 value_exit[t] + 1.1823 value_exit[t] + -0.4196 value_exit^2 + -0.196 value_exit*decision_duration + -0.2645 value_exit*value_exit + 0.1059 value_exit^2 \n",
      "beta(value) = 43.1919\n",
      "Participant number 203\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4126 reward + 0.3427 decision_duration + 1.0 value_stay[t] + -0.2932 value_stay^2 + -0.3493 value_stay*reward + -0.3097 value_stay*decision_duration + -0.1222 value_stay*value_stay + -0.2657 reward^2 + 0.4029 reward*decision_duration + 0.1852 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 15.9343\n",
      "Participant number 204\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.1812 reward + 0.391 decision_duration + 1.0 value_stay[t] + -0.291 value_stay^2 + -0.2817 value_stay*decision_duration + -0.2746 value_stay*value_stay + 0.1881 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 35.6233\n",
      "Participant number 205\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.3515 reward + 0.2825 decision_duration + 1.0 value_stay[t] + -0.794 value_stay*reward + -0.4698 value_stay*decision_duration + 0.7541 reward*decision_duration \n",
      "value_exit[t+1] = 0.2078 1 + 0.8641 value_exit[t] + 1.0 value_exit[t] + -0.3339 value_exit^2 + -0.1566 value_exit*value_exit + 0.2153 reward^2 \n",
      "beta(value) = 27.0304\n",
      "Participant number 207\n",
      "value_stay[t+1] = 0.1213 1 + 0.8613 value_stay[t] + 0.1651 decision_duration + 1.0 value_stay[t] + -0.3272 value_stay*reward + -0.3561 value_stay*value_stay + 0.3324 reward^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 68.4442\n",
      "Participant number 210\n",
      "value_stay[t+1] = 0.2367 1 + 0.8034 value_stay[t] + 0.1607 reward + 0.2113 decision_duration + 1.0 value_stay[t] + -0.3157 value_stay*decision_duration + -0.4628 value_stay*value_stay + 0.169 reward*decision_duration + 0.1451 decision_duration^2 + -0.3742 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 36.2645\n",
      "Participant number 212\n",
      "value_stay[t+1] = 0.2075 1 + 1.0 value_stay[t] + -0.1839 reward + 0.2036 decision_duration + 1.0 value_stay[t] + -0.3169 value_stay^2 + -0.2481 value_stay*decision_duration + -0.2333 value_stay*value_stay + 0.4743 reward^2 + -0.1654 reward*decision_duration + -0.358 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 44.4562\n",
      "Participant number 213\n",
      "value_stay[t+1] = 0.1142 1 + 0.8504 value_stay[t] + 0.1199 reward + 0.1467 decision_duration + 1.0 value_stay[t] + -0.3462 value_stay^2 + -0.2803 value_stay*value_stay + 0.1466 reward*decision_duration + 0.1347 decision_duration*value_stay \n",
      "value_exit[t+1] = 0.341 1 + 0.8369 value_exit[t] + 1.1467 value_exit[t] + -0.3141 value_exit^2 + -0.2439 value_exit*decision_duration + -0.296 value_exit*value_exit \n",
      "beta(value) = 42.5922\n",
      "Participant number 217\n",
      "value_stay[t+1] = 0.1348 1 + 1.0 value_stay[t] + 0.2354 decision_duration + 1.0 value_stay[t] + -0.2282 value_stay^2 + -0.1473 value_stay*reward + -0.233 value_stay*decision_duration + -0.2387 value_stay*value_stay + 0.4228 reward^2 + -0.4194 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 64.1150\n",
      "Participant number 224\n",
      "value_stay[t+1] = 0.1115 1 + 0.8641 value_stay[t] + 0.2252 decision_duration + 1.0 value_stay[t] + -0.3467 value_stay^2 + -0.2218 value_stay*value_stay + 0.1839 reward^2 \n",
      "value_exit[t+1] = 0.1925 1 + 0.6753 value_exit[t] + 1.1292 value_exit[t] + -0.3054 value_exit^2 + -0.2773 value_exit*value_exit + 0.7448 reward*decision_duration + 0.1505 value_exit^2 \n",
      "beta(value) = 34.1296\n",
      "Participant number 227\n",
      "value_stay[t+1] = 0.1673 1 + 0.8376 value_stay[t] + 0.4095 reward + 0.1751 decision_duration + 1.0 value_stay[t] + -0.1649 value_stay^2 + -0.2267 value_stay*decision_duration + -0.3531 value_stay*value_stay + -0.309 reward^2 + 0.3986 reward*decision_duration + 0.1555 decision_duration^2 + -0.296 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 22.5270\n",
      "Participant number 228\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.3238 reward + 0.3572 decision_duration + 1.0 value_stay[t] + -0.363 value_stay^2 + -0.1995 value_stay*decision_duration + -0.2844 value_stay*value_stay + -0.193 reward^2 + 0.3171 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 23.8075\n",
      "Participant number 229\n",
      "value_stay[t+1] = 0.1301 1 + 1.0 value_stay[t] + 0.2471 decision_duration + 1.0 value_stay[t] + -0.2337 value_stay^2 + -0.1287 value_stay*reward + -0.2452 value_stay*decision_duration + -0.2413 value_stay*value_stay + 0.4059 reward^2 + -0.4071 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 57.4527\n",
      "Participant number 232\n",
      "value_stay[t+1] = 0.1799 1 + 1.0 value_stay[t] + 0.2101 decision_duration + 1.0 value_stay[t] + -0.2344 value_stay^2 + -0.1705 value_stay*reward + -0.2871 value_stay*decision_duration + -0.1297 value_stay*value_stay + 0.4775 reward^2 + -0.4124 reward*decision_duration + -0.5159 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 62.4751\n",
      "Participant number 234\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.192 reward + 0.3536 decision_duration + 1.0 value_stay[t] + -0.3189 value_stay^2 + -0.1849 value_stay*decision_duration + -0.2979 value_stay*value_stay + 0.1984 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 55.2430\n",
      "Participant number 237\n",
      "value_stay[t+1] = 0.1782 1 + 0.8708 value_stay[t] + 0.1501 decision_duration + 1.0 value_stay[t] + -0.2445 value_stay^2 + -0.2839 value_stay*value_stay + 0.3364 reward^2 + -0.3538 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 69.3925\n",
      "Participant number 244\n",
      "value_stay[t+1] = 0.2216 1 + 0.8302 value_stay[t] + 0.157 reward + 0.2171 decision_duration + 1.0 value_stay[t] + -0.3778 value_stay*decision_duration + -0.4292 value_stay*value_stay + 0.1718 reward*decision_duration + 0.1662 decision_duration^2 + -0.3835 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 42.2787\n",
      "Participant number 245\n",
      "value_stay[t+1] = 0.1498 1 + 1.0 value_stay[t] + 0.185 decision_duration + 1.0 value_stay[t] + -0.2179 value_stay^2 + -0.189 value_stay*reward + -0.3103 value_stay*decision_duration + -0.2084 value_stay*value_stay + 0.4785 reward^2 + -0.5154 reward*value_stay + 0.1264 decision_duration*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 59.7700\n",
      "Participant number 246\n",
      "value_stay[t+1] = 0.1932 1 + 0.8407 value_stay[t] + 0.1749 decision_duration + 1.0 value_stay[t] + -0.3223 value_stay*decision_duration + -0.4693 value_stay*value_stay + 0.2683 reward^2 + -0.2188 reward*value_stay + 0.1252 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 45.6505\n",
      "Participant number 248\n",
      "value_stay[t+1] = 0.2646 1 + 0.8276 value_stay[t] + 0.2152 decision_duration + 1.0 value_stay[t] + -0.3488 value_stay*decision_duration + -0.4645 value_stay*value_stay + 0.1187 reward^2 + 0.2658 reward*decision_duration + 0.1304 decision_duration^2 + -0.4063 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 38.5416\n",
      "Participant number 251\n",
      "value_stay[t+1] = 0.1272 1 + 0.8668 value_stay[t] + 0.1511 reward + 0.1494 decision_duration + 1.0 value_stay[t] + -0.2438 value_stay^2 + -0.1565 value_stay*decision_duration + -0.3772 value_stay*value_stay + 0.1627 reward*decision_duration + 0.1359 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 30.7952\n",
      "Participant number 252\n",
      "value_stay[t+1] = 0.177 1 + 1.0 value_stay[t] + 0.1282 reward + 1.0 value_stay[t] + -0.4422 value_stay^2 + -0.315 value_stay*reward + 0.411 reward*decision_duration \n",
      "value_exit[t+1] = 0.3352 1 + 0.8388 value_exit[t] + 1.1265 value_exit[t] + -0.3474 value_exit^2 + -0.2872 value_exit*value_exit + -0.1302 decision_duration^2 \n",
      "beta(value) = 47.6742\n",
      "Participant number 255\n",
      "value_stay[t+1] = 0.2101 1 + 1.0 value_stay[t] + 0.1788 decision_duration + 1.0 value_stay[t] + -0.2261 value_stay^2 + -0.3203 value_stay*decision_duration + -0.3517 value_stay*value_stay + 0.2575 reward^2 + -0.1748 reward*value_stay + 0.1294 decision_duration^2 + -0.2859 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 33.3320\n",
      "Participant number 256\n",
      "value_stay[t+1] = 0.2131 1 + 0.8974 value_stay[t] + 0.1556 decision_duration + 1.0 value_stay[t] + -0.2381 value_stay^2 + -0.3089 value_stay*decision_duration + -0.1213 value_stay*value_stay + 0.4092 reward^2 + -0.4714 reward*decision_duration + -0.5358 reward*value_stay + 0.1559 decision_duration*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 51.1579\n",
      "Participant number 259\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.2875 decision_duration + 1.0 value_stay[t] + -0.1818 value_stay^2 + -0.485 value_stay*decision_duration + 0.1864 decision_duration*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 67.5269\n",
      "Participant number 261\n",
      "value_stay[t+1] = 0.1612 1 + 1.0 value_stay[t] + 0.1502 decision_duration + 1.0 value_stay[t] + -0.2093 value_stay^2 + -0.146 value_stay*reward + -0.3508 value_stay*decision_duration + -0.2456 value_stay*value_stay + 0.4292 reward^2 + -0.4356 reward*value_stay + 0.1168 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 53.2888\n",
      "Participant number 263\n",
      "value_stay[t+1] = 0.1472 1 + 0.7952 value_stay[t] + 0.1594 reward + 0.1778 decision_duration + 1.0 value_stay[t] + -0.3033 value_stay*decision_duration + -0.4717 value_stay*value_stay + 0.1696 reward*decision_duration + 0.162 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 32.0091\n",
      "Participant number 265\n",
      "value_stay[t+1] = 0.1829 1 + 1.0 value_stay[t] + -0.1214 reward + 0.2406 decision_duration + 1.0 value_stay[t] + -0.2478 value_stay^2 + -0.279 value_stay*decision_duration + -0.3206 value_stay*value_stay + 0.4395 reward^2 + -0.4125 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 41.0000\n",
      "Participant number 270\n",
      "value_stay[t+1] = 0.1537 1 + 1.0 value_stay[t] + 0.1897 decision_duration + 1.0 value_stay[t] + -0.2388 value_stay^2 + -0.1107 value_stay*reward + -0.285 value_stay*decision_duration + -0.238 value_stay*value_stay + 0.4462 reward^2 + -0.2339 reward*decision_duration + -0.4358 reward*value_stay + 0.1255 decision_duration*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 59.2214\n",
      "Participant number 271\n",
      "value_stay[t+1] = 0.1576 1 + 0.818 value_stay[t] + 0.1426 decision_duration + 1.0 value_stay[t] + -0.2782 value_stay^2 + -0.2682 value_stay*decision_duration + 0.252 reward^2 + -0.262 reward*value_stay + 0.121 decision_duration^2 \n",
      "value_exit[t+1] = 0.3024 1 + 1.0 value_exit[t] + -0.5177 reward + 1.0 value_exit[t] + -0.3469 value_exit^2 + -0.4513 value_exit*reward + -0.2331 value_exit*decision_duration + -0.1058 value_exit*value_exit + 0.6901 reward^2 + -0.5047 reward*decision_duration + 0.4077 reward*value_exit \n",
      "beta(value) = 25.8065\n",
      "Participant number 274\n",
      "value_stay[t+1] = 0.2487 1 + 0.8162 value_stay[t] + 0.1501 reward + 0.2144 decision_duration + 1.0 value_stay[t] + -0.3284 value_stay*decision_duration + -0.4638 value_stay*value_stay + 0.1639 reward*decision_duration + 0.1373 decision_duration^2 + -0.3969 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 28.9115\n",
      "Participant number 275\n",
      "value_stay[t+1] = 0.1669 1 + 1.0 value_stay[t] + 0.2181 decision_duration + 1.0 value_stay[t] + -0.2447 value_stay^2 + -0.1469 value_stay*reward + -0.2376 value_stay*decision_duration + -0.2151 value_stay*value_stay + 0.476 reward^2 + -0.2914 reward*decision_duration + -0.4621 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 61.6044\n",
      "Participant number 277\n",
      "value_stay[t+1] = 0.2335 1 + 0.8094 value_stay[t] + 0.1797 reward + 0.2221 decision_duration + 1.0 value_stay[t] + -0.3312 value_stay*decision_duration + -0.482 value_stay*value_stay + 0.1906 reward*decision_duration + 0.1639 decision_duration^2 + -0.4374 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 45.7719\n",
      "Participant number 278\n",
      "value_stay[t+1] = 0.1612 1 + 0.8854 value_stay[t] + 0.1654 decision_duration + 1.0 value_stay[t] + -0.1185 value_stay^2 + -0.2955 value_stay*decision_duration + -0.4016 value_stay*value_stay + 0.2267 reward^2 + 0.2663 reward*decision_duration + -0.2038 reward*value_stay + 0.131 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 46.0374\n",
      "Participant number 279\n",
      "value_stay[t+1] = 0.1465 1 + 0.8767 value_stay[t] + 0.1666 decision_duration + 1.0 value_stay[t] + -0.1156 value_stay^2 + -0.2844 value_stay*decision_duration + -0.4157 value_stay*value_stay + 0.1566 reward^2 + 0.175 reward*decision_duration + 0.1445 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 43.3093\n",
      "Participant number 280\n",
      "value_stay[t+1] = 0.1437 1 + 1.0 value_stay[t] + 0.222 decision_duration + 1.0 value_stay[t] + -0.2115 value_stay^2 + -0.168 value_stay*reward + -0.2351 value_stay*decision_duration + -0.2305 value_stay*value_stay + 0.4414 reward^2 + -0.4735 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 60.5672\n",
      "Participant number 281\n",
      "value_stay[t+1] = 0.1971 1 + 0.8959 value_stay[t] + -0.1062 reward + 0.2327 decision_duration + 1.0 value_stay[t] + -0.2158 value_stay^2 + -0.2345 value_stay*decision_duration + -0.2682 value_stay*value_stay + 0.4206 reward^2 + -0.3664 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 48.5628\n",
      "Participant number 283\n",
      "value_stay[t+1] = 0.1582 1 + 0.8796 value_stay[t] + 0.1382 decision_duration + 1.0 value_stay[t] + -0.3391 value_stay^2 + -0.1104 value_stay*decision_duration + -0.1723 value_stay*value_stay + 0.2006 reward^2 + 0.1282 reward*decision_duration + -0.1618 reward*value_stay + 0.1179 decision_duration*value_stay \n",
      "value_exit[t+1] = 0.3452 1 + 0.828 value_exit[t] + 1.1357 value_exit[t] + -0.3083 value_exit^2 + -0.2423 value_exit*decision_duration + -0.2795 value_exit*value_exit \n",
      "beta(value) = 49.6697\n",
      "Participant number 286\n",
      "value_stay[t+1] = 0.2096 1 + 1.0 value_stay[t] + 0.1651 decision_duration + 1.0 value_stay[t] + -0.2446 value_stay^2 + -0.2716 value_stay*decision_duration + -0.327 value_stay*value_stay + 0.2897 reward^2 + -0.25 reward*value_stay + 0.1112 decision_duration^2 + -0.2615 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 57.8453\n",
      "Participant number 291\n",
      "value_stay[t+1] = 0.1648 1 + 1.0 value_stay[t] + 0.149 decision_duration + 1.0 value_stay[t] + -0.1912 value_stay^2 + -0.2886 value_stay*decision_duration + -0.3981 value_stay*value_stay + 0.3417 reward^2 + -0.3781 reward*value_stay + 0.1151 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 57.8795\n",
      "Participant number 294\n",
      "value_stay[t+1] = 0.2547 1 + 0.8291 value_stay[t] + 0.142 reward + 0.2111 decision_duration + 1.0 value_stay[t] + -0.3602 value_stay*decision_duration + -0.4323 value_stay*value_stay + 0.1516 reward^2 + 0.1494 reward*decision_duration + -0.2882 reward*value_stay + 0.1306 decision_duration^2 + -0.3495 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 36.7489\n",
      "Participant number 296\n",
      "value_stay[t+1] = 0.1762 1 + 1.0 value_stay[t] + 0.185 decision_duration + 1.0 value_stay[t] + -0.2305 value_stay^2 + -0.1278 value_stay*reward + -0.3216 value_stay*decision_duration + -0.2251 value_stay*value_stay + 0.4749 reward^2 + -0.3092 reward*decision_duration + -0.5069 reward*value_stay + 0.1267 decision_duration*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 55.9494\n",
      "Participant number 297\n",
      "value_stay[t+1] = 0.1192 1 + 1.0 value_stay[t] + 0.1284 decision_duration + 1.0 value_stay[t] + -0.2043 value_stay^2 + -0.3187 value_stay*value_stay \n",
      "value_exit[t+1] = 0.2007 1 + 0.7324 value_exit[t] + 1.1371 value_exit[t] + -0.4185 value_exit^2 + -0.2238 value_exit*value_exit + 0.7151 reward*decision_duration + 0.1013 value_exit^2 \n",
      "beta(value) = 36.1736\n",
      "Participant number 299\n",
      "value_stay[t+1] = 0.1497 1 + 0.8584 value_stay[t] + 0.1115 decision_duration + 1.0 value_stay[t] + -0.3395 value_stay^2 + 0.1625 reward^2 + -0.2647 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 58.1305\n",
      "Participant number 303\n",
      "value_stay[t+1] = 0.1502 1 + 0.7504 value_stay[t] + 0.2629 reward + 0.1716 decision_duration + 1.0 value_stay[t] + -0.2395 value_stay*decision_duration + -0.5356 value_stay*value_stay + -0.1015 reward^2 + 0.2645 reward*decision_duration + 0.1639 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 25.7069\n",
      "Participant number 306\n",
      "value_stay[t+1] = 0.2708 1 + 1.0003 value_stay[t] + 1.0 value_stay[t] + -0.2588 value_stay^2 + -0.1955 value_stay*value_stay + 0.5687 reward^2 + -0.4792 reward*decision_duration + -0.9102 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 54.0612\n",
      "Participant number 307\n",
      "value_stay[t+1] = 0.1958 1 + 0.8163 value_stay[t] + 0.1787 decision_duration + 1.0 value_stay[t] + -0.2903 value_stay*decision_duration + -0.5393 value_stay*value_stay + 0.1834 reward^2 + 0.1291 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 33.8743\n",
      "Participant number 308\n",
      "value_stay[t+1] = 0.1678 1 + 1.0 value_stay[t] + -0.2234 reward + 0.2606 decision_duration + 1.0 value_stay[t] + -0.2238 value_stay^2 + -0.1429 value_stay*reward + -0.2908 value_stay*decision_duration + -0.3148 value_stay*value_stay + 0.4564 reward^2 + -0.1874 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 44.5853\n",
      "Participant number 309\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.1994 reward + 0.3685 decision_duration + 1.0 value_stay[t] + -0.3309 value_stay^2 + -0.1937 value_stay*decision_duration + -0.3307 value_stay*value_stay + 0.2193 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 32.2557\n",
      "Participant number 310\n",
      "value_stay[t+1] = 0.2383 1 + 0.8674 value_stay[t] + 0.1432 reward + 0.2015 decision_duration + 1.0 value_stay[t] + -0.3247 value_stay*decision_duration + -0.4162 value_stay*value_stay + 0.1606 reward^2 + 0.1491 reward*decision_duration + -0.3076 reward*value_stay + 0.1306 decision_duration^2 + -0.4086 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 52.6897\n",
      "Participant number 313\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.1818 reward + 0.4188 decision_duration + 1.0 value_stay[t] + -0.2747 value_stay^2 + -0.3473 value_stay*decision_duration + -0.2581 value_stay*value_stay + 0.1476 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 42.9777\n",
      "Participant number 314\n",
      "value_stay[t+1] = 0.1837 1 + 0.8886 value_stay[t] + 0.2423 decision_duration + 1.0 value_stay[t] + -0.1806 value_stay^2 + -0.2206 value_stay*decision_duration + -0.3114 value_stay*value_stay + 0.3715 reward^2 + -0.458 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 51.3015\n",
      "Participant number 319\n",
      "value_stay[t+1] = 0.1281 1 + 0.8488 value_stay[t] + 0.2025 decision_duration + 1.0 value_stay[t] + -0.3177 value_stay^2 + -0.2119 value_stay*value_stay + 0.14 reward^2 \n",
      "value_exit[t+1] = 0.1781 1 + 0.6669 value_exit[t] + 1.1286 value_exit[t] + -0.4421 value_exit^2 + -0.1238 value_exit*value_exit + 0.1207 reward^2 + 0.2987 value_exit^2 \n",
      "beta(value) = 28.6528\n",
      "Participant number 322\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.1963 reward + 0.358 decision_duration + 1.0 value_stay[t] + -0.3285 value_stay^2 + -0.1829 value_stay*decision_duration + -0.3083 value_stay*value_stay + 0.1954 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 53.4816\n",
      "Participant number 323\n",
      "value_stay[t+1] = 0.2034 1 + 1.0 value_stay[t] + -0.2119 reward + 0.1511 decision_duration + 1.0 value_stay[t] + -0.3161 value_stay^2 + -0.2868 value_stay*decision_duration + -0.1949 value_stay*value_stay + 0.4104 reward^2 + -0.3421 reward*value_stay + 0.1057 decision_duration*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 51.2816\n",
      "Participant number 324\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.3722 reward + 0.2471 decision_duration + 1.0 value_stay[t] + -0.2758 value_stay^2 + -0.2633 value_stay*decision_duration + -0.3806 value_stay*value_stay + -0.2054 reward^2 + 0.3592 reward*decision_duration + 0.1428 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 38.1454\n",
      "Participant number 328\n",
      "value_stay[t+1] = 0.2421 1 + 0.8139 value_stay[t] + 0.1445 reward + 0.2004 decision_duration + 1.0 value_stay[t] + -0.3137 value_stay*decision_duration + -0.4343 value_stay*value_stay + 0.1483 reward^2 + 0.1509 reward*decision_duration + -0.2682 reward*value_stay + 0.1304 decision_duration^2 + -0.3254 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 53.1323\n",
      "Participant number 329\n",
      "value_stay[t+1] = 0.1839 1 + 0.8422 value_stay[t] + 0.1935 reward + 0.1949 decision_duration + 1.0 value_stay[t] + -0.1337 value_stay^2 + -0.2529 value_stay*decision_duration + -0.3854 value_stay*value_stay + 0.2008 reward*decision_duration + 0.1628 decision_duration^2 + -0.3387 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 41.4532\n",
      "Participant number 332\n",
      "value_stay[t+1] = 0.2127 1 + 0.8414 value_stay[t] + 0.1637 reward + 0.2073 decision_duration + 1.0 value_stay[t] + -0.3121 value_stay*decision_duration + -0.4341 value_stay*value_stay + 0.1719 reward*decision_duration + 0.1554 decision_duration^2 + -0.4183 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 51.0557\n",
      "Participant number 334\n",
      "value_stay[t+1] = 0.2326 1 + 0.8914 value_stay[t] + 0.1819 decision_duration + 1.0 value_stay[t] + -0.1599 value_stay^2 + -0.2333 value_stay*decision_duration + -0.3711 value_stay*value_stay + 0.1941 reward^2 + 0.1187 decision_duration^2 + -0.3582 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 60.0612\n",
      "Participant number 343\n",
      "value_stay[t+1] = 0.1921 1 + 1.0 value_stay[t] + -0.285 reward + 0.154 decision_duration + 1.0 value_stay[t] + -0.3298 value_stay^2 + -0.2652 value_stay*decision_duration + -0.1926 value_stay*value_stay + 0.3533 reward^2 + -0.2589 reward*decision_duration + 0.114 decision_duration*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 52.6414\n",
      "Participant number 344\n",
      "value_stay[t+1] = 0.1712 1 + 0.8524 value_stay[t] + 1.0 value_stay[t] + -0.3736 value_stay^2 + -0.0975 value_stay*value_stay + 0.288 reward^2 + -0.2846 reward*value_stay + 0.2326 decision_duration*value_stay \n",
      "value_exit[t+1] = 0.2838 1 + 1.0 value_exit[t] + 1.1088 value_exit[t] + -0.3629 value_exit^2 + -0.1857 value_exit*reward + -0.3038 value_exit*decision_duration + -0.2204 value_exit*value_exit \n",
      "beta(value) = 45.0068\n",
      "Participant number 347\n",
      "value_stay[t+1] = 0.1834 1 + 1.0 value_stay[t] + 0.177 reward + 1.0 value_stay[t] + -0.4343 value_stay^2 + -0.3143 value_stay*reward + 0.1594 reward*decision_duration \n",
      "value_exit[t+1] = 0.3323 1 + 0.8518 value_exit[t] + 1.1218 value_exit[t] + -0.361 value_exit^2 + -0.2789 value_exit*value_exit + -0.1306 decision_duration^2 \n",
      "beta(value) = 34.9049\n",
      "Participant number 349\n",
      "value_stay[t+1] = 0.1636 1 + 1.0 value_stay[t] + 0.1633 reward + 0.191 decision_duration + 1.0 value_stay[t] + -0.1946 value_stay^2 + -0.3332 value_stay*decision_duration + -0.3778 value_stay*value_stay + 0.1673 reward*decision_duration + 0.1759 decision_duration^2 + -0.3812 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 41.8019\n",
      "Participant number 351\n",
      "value_stay[t+1] = 0.1822 1 + 0.8381 value_stay[t] + 0.1674 reward + 0.2052 decision_duration + 1.0 value_stay[t] + -0.3416 value_stay*decision_duration + -0.3966 value_stay*value_stay + 0.1773 reward*decision_duration + 0.1755 decision_duration^2 + -0.3528 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 50.8928\n",
      "Participant number 353\n",
      "value_stay[t+1] = 0.1868 1 + 0.8919 value_stay[t] + 0.1568 decision_duration + 1.0 value_stay[t] + -0.1364 value_stay^2 + -0.2589 value_stay*decision_duration + -0.4112 value_stay*value_stay + 0.2925 reward^2 + -0.2461 reward*value_stay + 0.1137 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 59.5593\n",
      "Participant number 357\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.1959 reward + 0.3426 decision_duration + 1.0 value_stay[t] + -0.3083 value_stay^2 + -0.2791 value_stay*decision_duration + -0.3091 value_stay*value_stay + 0.1728 reward*decision_duration + 0.1161 decision_duration*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 42.2645\n",
      "Participant number 358\n",
      "value_stay[t+1] = 0.1322 1 + 1.0 value_stay[t] + 0.1644 decision_duration + 1.0 value_stay[t] + -0.3164 value_stay^2 + -0.2639 value_stay*decision_duration + -0.1647 value_stay*value_stay + 0.2248 reward^2 + -0.3813 reward*value_stay + 0.1472 decision_duration*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 51.8321\n",
      "Participant number 359\n",
      "value_stay[t+1] = 0.1696 1 + 0.874 value_stay[t] + 0.1571 decision_duration + 1.0 value_stay[t] + -0.1802 value_stay^2 + -0.3544 value_stay*value_stay + 0.3094 reward^2 + -0.2865 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 62.4302\n",
      "Participant number 360\n",
      "value_stay[t+1] = 0.2065 1 + 1.0 value_stay[t] + -0.1914 reward + 0.1455 decision_duration + 1.0 value_stay[t] + -0.33 value_stay^2 + -0.277 value_stay*decision_duration + -0.187 value_stay*value_stay + 0.3989 reward^2 + -0.181 reward*decision_duration + -0.2973 reward*value_stay + 0.1138 decision_duration*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 42.1211\n",
      "Participant number 361\n",
      "value_stay[t+1] = 0.1782 1 + 0.9995 value_stay[t] + -0.1355 reward + 0.1851 decision_duration + 1.0 value_stay[t] + -0.2653 value_stay^2 + -0.2839 value_stay*decision_duration + -0.2668 value_stay*value_stay + 0.42 reward^2 + -0.113 reward*decision_duration + -0.3443 reward*value_stay + 0.1056 decision_duration*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 36.6366\n",
      "Participant number 362\n",
      "value_stay[t+1] = 0.1478 1 + 0.8426 value_stay[t] + 0.1728 decision_duration + 1.0 value_stay[t] + 0.0015 value_stay^2 + -0.3043 value_stay*decision_duration + -0.4996 value_stay*value_stay + 0.1351 reward^2 + 0.2334 reward*decision_duration + 0.1531 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 40.5955\n",
      "Participant number 365\n",
      "value_stay[t+1] = 0.1973 1 + 0.8756 value_stay[t] + 0.1285 decision_duration + 1.0 value_stay[t] + -0.2579 value_stay^2 + -0.2668 value_stay*value_stay + 0.3707 reward^2 + -0.4619 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 57.1551\n",
      "Participant number 366\n",
      "value_stay[t+1] = 0.2163 1 + 0.7992 value_stay[t] + 0.1789 reward + 0.2124 decision_duration + 1.0 value_stay[t] + -0.3191 value_stay*decision_duration + -0.4594 value_stay*value_stay + 0.1864 reward*decision_duration + 0.1676 decision_duration^2 + -0.3812 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 53.4180\n",
      "Participant number 368\n",
      "value_stay[t+1] = 0.1721 1 + 1.0 value_stay[t] + -0.1748 reward + 0.1487 decision_duration + 1.0 value_stay[t] + -0.2097 value_stay^2 + -0.1547 value_stay*reward + -0.3418 value_stay*decision_duration + -0.3056 value_stay*value_stay + 0.428 reward^2 + -0.1557 reward*decision_duration + 0.1248 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 44.6915\n",
      "Participant number 370\n",
      "value_stay[t+1] = 0.2043 1 + 0.8307 value_stay[t] + 0.1533 reward + 0.2134 decision_duration + 1.0 value_stay[t] + -0.3795 value_stay*decision_duration + -0.4002 value_stay*value_stay + 0.1621 reward*decision_duration + 0.1668 decision_duration^2 + -0.3355 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 34.2045\n",
      "Participant number 372\n",
      "value_stay[t+1] = 0.1907 1 + 1.0 value_stay[t] + -0.3487 reward + 0.1655 decision_duration + 1.0 value_stay[t] + -0.2537 value_stay^2 + -0.1699 value_stay*reward + -0.2406 value_stay*decision_duration + -0.1444 value_stay*value_stay + 0.4376 reward^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 69.6212\n",
      "Participant number 380\n",
      "value_stay[t+1] = 0.197 1 + 1.0 value_stay[t] + 0.2261 reward + 1.0 value_stay[t] + -0.3228 value_stay^2 + -0.3389 value_stay*reward + -0.1642 value_stay*value_stay \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.126 reward + 1.0 value_exit[t] + -0.1907 reward*value_exit \n",
      "beta(value) = 17.1230\n",
      "Participant number 382\n",
      "value_stay[t+1] = 0.1965 1 + 0.8257 value_stay[t] + 0.1726 decision_duration + 1.0 value_stay[t] + -0.3155 value_stay*decision_duration + -0.5012 value_stay*value_stay + 0.2391 reward^2 + 0.2807 reward*decision_duration + -0.2495 reward*value_stay + 0.1247 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 40.8446\n",
      "Participant number 384\n",
      "value_stay[t+1] = 0.1699 1 + 0.8799 value_stay[t] + 0.161 decision_duration + 1.0 value_stay[t] + -0.2208 value_stay^2 + -0.3423 value_stay*value_stay + 0.3133 reward^2 + -0.2821 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 58.9633\n",
      "Participant number 386\n",
      "value_stay[t+1] = 0.2055 1 + 0.7904 value_stay[t] + 0.2659 reward + 0.2039 decision_duration + 1.0 value_stay[t] + -0.328 value_stay*decision_duration + -0.4399 value_stay*value_stay + -0.122 reward^2 + 0.2606 reward*decision_duration + 0.1701 decision_duration^2 + -0.3346 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 31.1894\n",
      "Participant number 388\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.203 reward + 0.3403 decision_duration + 1.0 value_stay[t] + -0.4003 value_stay^2 + -0.1015 value_stay*decision_duration + -0.2791 value_stay*value_stay + 0.1908 reward*decision_duration \n",
      "value_exit[t+1] = 0.2958 1 + 1.0 value_exit[t] + 1.1108 value_exit[t] + -0.387 value_exit^2 + -0.1799 value_exit*reward + -0.1541 value_exit*decision_duration + -0.2069 value_exit*value_exit + -0.1001 decision_duration^2 \n",
      "beta(value) = 49.4692\n",
      "Participant number 391\n",
      "value_stay[t+1] = 0.1441 1 + 0.7657 value_stay[t] + 0.2088 decision_duration + 1.0 value_stay[t] + -0.2929 value_stay^2 + -0.1742 value_stay*value_stay + 0.1852 reward^2 \n",
      "value_exit[t+1] = 0.1381 1 + 1.0 value_exit[t] + 1.0 value_exit[t] + -0.7574 value_exit*reward + -0.4611 value_exit*value_exit + 0.3453 reward^2 + 0.355 reward*value_exit \n",
      "beta(value) = 22.9882\n",
      "Participant number 393\n",
      "value_stay[t+1] = 0.1695 1 + 1.0 value_stay[t] + 0.168 decision_duration + 1.0 value_stay[t] + -0.2445 value_stay^2 + -0.249 value_stay*decision_duration + -0.335 value_stay*value_stay + 0.1575 reward^2 + 0.1589 reward*decision_duration + 0.1317 decision_duration^2 + -0.2854 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 56.7051\n",
      "Participant number 395\n",
      "value_stay[t+1] = 0.2587 1 + 1.0 value_stay[t] + -0.267 reward + 1.0 value_stay[t] + -0.2601 value_stay^2 + -0.2212 value_stay*reward + -0.1912 value_stay*value_stay + 0.6583 reward^2 + -0.4547 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 65.9928\n",
      "Participant number 399\n",
      "value_stay[t+1] = 0.2386 1 + 0.8924 value_stay[t] + 0.1489 decision_duration + 1.0 value_stay[t] + -0.2107 value_stay^2 + -0.3171 value_stay*value_stay + 0.3268 reward^2 + -0.3534 reward*value_stay + -0.2379 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 66.4312\n",
      "Participant number 401\n",
      "value_stay[t+1] = 0.2268 1 + 1.0 value_stay[t] + -0.242 reward + 0.1809 decision_duration + 1.0 value_stay[t] + -0.2409 value_stay^2 + -0.1475 value_stay*reward + -0.316 value_stay*decision_duration + -0.1755 value_stay*value_stay + 0.5411 reward^2 + -0.4081 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 62.3277\n",
      "Participant number 411\n",
      "value_stay[t+1] = 0.1486 1 + 0.8352 value_stay[t] + 0.35 reward + 0.1972 decision_duration + 1.0 value_stay[t] + -0.1102 value_stay^2 + -0.2757 value_stay*decision_duration + -0.3776 value_stay*value_stay + -0.1797 reward^2 + 0.3561 reward*decision_duration + 0.1922 decision_duration^2 + -0.3536 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 39.4399\n",
      "Participant number 416\n",
      "value_stay[t+1] = 0.2207 1 + 0.7956 value_stay[t] + 0.181 reward + 0.2118 decision_duration + 1.0 value_stay[t] + -0.3153 value_stay*decision_duration + -0.4603 value_stay*value_stay + 0.1876 reward*decision_duration + 0.1618 decision_duration^2 + -0.3739 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 51.5786\n",
      "Participant number 422\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.2541 reward + 0.1792 decision_duration + 1.0 value_stay[t] + -0.419 value_stay^2 + -0.1639 value_stay*reward + -0.2712 value_stay*decision_duration + 0.2526 reward*decision_duration + 0.1614 decision_duration^2 \n",
      "value_exit[t+1] = 0.1574 1 + 0.8491 value_exit[t] + 1.0 value_exit[t] + -0.432 value_exit^2 + -0.1714 value_exit*reward + 0.916 reward*decision_duration \n",
      "beta(value) = 26.4984\n",
      "Participant number 423\n",
      "value_stay[t+1] = 0.1524 1 + 1.0 value_stay[t] + 0.1934 decision_duration + 1.0 value_stay[t] + -0.2345 value_stay^2 + -0.1255 value_stay*reward + -0.3858 value_stay*decision_duration + -0.1668 value_stay*value_stay + 0.4403 reward^2 + -0.5816 reward*value_stay + 0.1646 decision_duration*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 41.5492\n",
      "Participant number 424\n",
      "value_stay[t+1] = 0.2098 1 + 0.77 value_stay[t] + 0.1655 reward + 0.2013 decision_duration + 1.0 value_stay[t] + -0.3062 value_stay*decision_duration + -0.4321 value_stay*value_stay + 0.1736 reward*decision_duration + 0.1524 decision_duration^2 + -0.2579 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 40.3419\n",
      "Participant number 425\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4145 reward + 0.3239 decision_duration + 1.0 value_stay[t] + -0.3217 value_stay^2 + -0.396 value_stay*reward + -0.3257 value_stay*decision_duration + -0.2588 reward^2 + 0.4217 reward*decision_duration + 0.1702 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 17.6769\n",
      "Participant number 428\n",
      "value_stay[t+1] = 0.1694 1 + 1.0 value_stay[t] + 0.1745 decision_duration + 1.0 value_stay[t] + -0.2622 value_stay^2 + -0.1238 value_stay*reward + -0.3732 value_stay*decision_duration + -0.1112 value_stay*value_stay + 0.4453 reward^2 + -0.4232 reward*decision_duration + -0.488 reward*value_stay + 0.1717 decision_duration*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 49.0102\n",
      "Participant number 429\n",
      "value_stay[t+1] = 0.1853 1 + 0.8734 value_stay[t] + 0.2445 decision_duration + 1.0 value_stay[t] + -0.2001 value_stay^2 + -0.2226 value_stay*decision_duration + -0.2754 value_stay*value_stay + 0.3672 reward^2 + -0.4537 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 40.3227\n",
      "Participant number 430\n",
      "value_stay[t+1] = 0.2403 1 + 0.8185 value_stay[t] + 0.1604 reward + 0.2176 decision_duration + 1.0 value_stay[t] + -0.3354 value_stay*decision_duration + -0.4662 value_stay*value_stay + 0.1685 reward*decision_duration + 0.1506 decision_duration^2 + -0.4167 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 32.1716\n",
      "Participant number 433\n",
      "value_stay[t+1] = 0.2354 1 + 0.8079 value_stay[t] + 0.1524 reward + 0.2111 decision_duration + 1.0 value_stay[t] + -0.3331 value_stay*decision_duration + -0.4496 value_stay*value_stay + 0.1651 reward*decision_duration + 0.1485 decision_duration^2 + -0.3687 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 27.2253\n",
      "Participant number 437\n",
      "value_stay[t+1] = 0.2232 1 + 1.0 value_stay[t] + -0.2455 reward + 0.1935 decision_duration + 1.0 value_stay[t] + -0.2671 value_stay^2 + -0.1082 value_stay*reward + -0.3142 value_stay*decision_duration + -0.189 value_stay*value_stay + 0.5281 reward^2 + -0.3849 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 51.6870\n",
      "Participant number 439\n",
      "value_stay[t+1] = 0.1861 1 + 1.0 value_stay[t] + -0.1613 reward + 0.1773 decision_duration + 1.0 value_stay[t] + -0.3175 value_stay^2 + -0.2785 value_stay*decision_duration + -0.2337 value_stay*value_stay + 0.4507 reward^2 + -0.1457 reward*decision_duration + -0.3212 reward*value_stay + 0.1148 decision_duration*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 34.7790\n",
      "Participant number 440\n",
      "value_stay[t+1] = 0.2079 1 + 0.8728 value_stay[t] + -0.2082 reward + 0.2494 decision_duration + 1.0 value_stay[t] + -0.197 value_stay^2 + -0.2158 value_stay*decision_duration + -0.3616 value_stay*value_stay + 0.3858 reward^2 + -0.1779 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 39.2942\n",
      "Participant number 441\n",
      "value_stay[t+1] = 0.1622 1 + 1.0 value_stay[t] + 0.1699 decision_duration + 1.0 value_stay[t] + -0.1807 value_stay^2 + -0.2031 value_stay*reward + -0.3492 value_stay*decision_duration + -0.3039 value_stay*value_stay + 0.2881 reward^2 + 0.159 decision_duration^2 + -0.2278 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 47.7680\n",
      "Participant number 442\n",
      "value_stay[t+1] = 0.2624 1 + 0.8605 value_stay[t] + 0.1622 reward + 0.2149 decision_duration + 1.0 value_stay[t] + -0.383 value_stay*decision_duration + -0.429 value_stay*value_stay + 0.1308 reward^2 + 0.1624 reward*decision_duration + -0.3332 reward*value_stay + 0.1267 decision_duration^2 + -0.3981 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 25.1491\n",
      "Participant number 444\n",
      "value_stay[t+1] = 0.2162 1 + 1.0 value_stay[t] + 0.1756 decision_duration + 1.0 value_stay[t] + -0.206 value_stay^2 + -0.2835 value_stay*decision_duration + -0.3901 value_stay*value_stay + 0.2168 reward^2 + 0.2274 reward*decision_duration + -0.1842 reward*value_stay + 0.1213 decision_duration^2 + -0.3552 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 54.2089\n",
      "Participant number 445\n",
      "value_stay[t+1] = 0.1596 1 + 1.0 value_stay[t] + 0.1409 decision_duration + 1.0 value_stay[t] + -0.2291 value_stay^2 + -0.2638 value_stay*decision_duration + -0.3594 value_stay*value_stay + 0.3325 reward^2 + -0.359 reward*value_stay + 0.1143 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 55.7335\n",
      "Participant number 446\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.3879 decision_duration + 1.0 value_stay[t] + -0.1843 value_stay^2 + -0.4821 value_stay*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 59.6135\n",
      "Participant number 447\n",
      "value_stay[t+1] = 0.1209 1 + 1.0 value_stay[t] + 0.1386 decision_duration + 1.0 value_stay[t] + -0.1437 value_stay^2 + -0.3217 value_stay*reward + -0.3042 value_stay*decision_duration + -0.2946 value_stay*value_stay + 0.3045 reward^2 + 0.1362 decision_duration^2 \n",
      "value_exit[t+1] = 0.2152 1 + 0.7412 value_exit[t] + 1.0 value_exit[t] + -0.5053 value_exit^2 + -0.1125 value_exit*value_exit + 0.4256 reward*decision_duration + 0.2548 value_exit^2 \n",
      "beta(value) = 24.9871\n",
      "Participant number 449\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.3339 reward + 0.2335 decision_duration + 1.0 value_stay[t] + -0.2947 value_stay^2 + -0.2369 value_stay*decision_duration + -0.3623 value_stay*value_stay + -0.1515 reward^2 + 0.3268 reward*decision_duration + 0.1458 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 53.3919\n",
      "Participant number 450\n",
      "value_stay[t+1] = 0.1465 1 + 0.781 value_stay[t] + 0.1733 reward + 0.1766 decision_duration + 1.0 value_stay[t] + -0.2865 value_stay*decision_duration + -0.5032 value_stay*value_stay + 0.1847 reward*decision_duration + 0.17 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 41.4592\n",
      "Participant number 452\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.1427 decision_duration + 1.0 value_stay[t] + -0.2064 value_stay^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.3354 reward + 1.192 value_exit[t] + -0.5079 value_exit*reward + -0.43 value_exit*value_exit \n",
      "beta(value) = 62.6386\n",
      "Participant number 456\n",
      "value_stay[t+1] = 0.1692 1 + 1.0 value_stay[t] + 0.1649 decision_duration + 1.0 value_stay[t] + -0.1915 value_stay^2 + -0.1706 value_stay*reward + -0.3138 value_stay*decision_duration + -0.3009 value_stay*value_stay + 0.27 reward^2 + 0.1491 decision_duration^2 + -0.26 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 57.4905\n",
      "Participant number 457\n",
      "value_stay[t+1] = 0.1328 1 + 0.8375 value_stay[t] + 0.2077 decision_duration + 1.0 value_stay[t] + -0.3905 value_stay^2 + -0.2149 value_stay*value_stay + 0.5546 reward*decision_duration \n",
      "value_exit[t+1] = 0.2894 1 + 1.0 value_exit[t] + 1.0 value_exit[t] + -0.2106 value_exit^2 + -0.3034 value_exit*value_exit + -0.1778 decision_duration^2 \n",
      "beta(value) = 51.4981\n",
      "Participant number 458\n",
      "value_stay[t+1] = 0.141 1 + 1.0 value_stay[t] + 0.1505 decision_duration + 1.0 value_stay[t] + -0.1821 value_stay^2 + -0.2829 value_stay*reward + -0.3497 value_stay*decision_duration + -0.242 value_stay*value_stay + 0.4239 reward^2 + -0.5973 reward*decision_duration + 0.1489 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 58.7217\n",
      "Participant number 459\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.5266 reward + 0.1992 decision_duration + 1.0 value_stay[t] + -0.3598 value_stay^2 + -0.3219 value_stay*reward + -0.1873 value_stay*value_stay + -0.3566 reward^2 + 0.4306 reward*decision_duration + 0.163 reward*value_stay \n",
      "value_exit[t+1] = 0.1559 1 + 0.8125 value_exit[t] + 1.0 value_exit[t] + -0.2527 value_exit^2 + -0.1556 value_exit*value_exit + 0.9943 reward*decision_duration \n",
      "beta(value) = 38.3571\n",
      "Participant number 467\n",
      "value_stay[t+1] = 0.1484 1 + 0.8936 value_stay[t] + 0.1503 decision_duration + 1.0 value_stay[t] + -0.213 value_stay^2 + -0.1938 value_stay*decision_duration + -0.3921 value_stay*value_stay + 0.1409 reward^2 + 0.1335 decision_duration^2 \n",
      "value_exit[t+1] = 1.1602 value_exit[t] + 0.2284 reward + 0.1672 decision_duration + 1.1849 value_exit[t] + -0.3676 value_exit^2 + -0.4801 value_exit*reward + -0.3249 value_exit*value_exit + 0.1805 reward*decision_duration + -0.172 decision_duration^2 \n",
      "beta(value) = 43.7427\n",
      "Participant number 473\n",
      "value_stay[t+1] = 0.1799 1 + 0.8817 value_stay[t] + 0.243 decision_duration + 1.0 value_stay[t] + -0.1986 value_stay^2 + -0.2104 value_stay*decision_duration + -0.29 value_stay*value_stay + 0.3684 reward^2 + -0.4396 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 53.3606\n",
      "Participant number 475\n",
      "value_stay[t+1] = 0.2034 1 + 1.0 value_stay[t] + -0.1844 reward + 0.1652 decision_duration + 1.0 value_stay[t] + -0.2943 value_stay^2 + -0.2748 value_stay*decision_duration + -0.2507 value_stay*value_stay + 0.479 reward^2 + -0.1639 reward*decision_duration + -0.3569 reward*value_stay + 0.1031 decision_duration*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 46.8946\n",
      "Participant number 477\n",
      "value_stay[t+1] = 0.294 1 + 1.0 value_stay[t] + -0.332 reward + 1.0 value_stay[t] + -0.3512 value_stay^2 + -0.237 value_stay*value_stay + 0.6194 reward^2 + -0.5053 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 58.7010\n",
      "Participant number 479\n",
      "value_stay[t+1] = 0.1195 1 + 0.8438 value_stay[t] + 0.2119 decision_duration + 1.0 value_stay[t] + -0.3967 value_stay^2 + -0.1993 value_stay*value_stay + 0.5831 reward*decision_duration \n",
      "value_exit[t+1] = 0.3337 1 + 0.8436 value_exit[t] + 1.1348 value_exit[t] + -0.387 value_exit^2 + -0.2723 value_exit*value_exit + -0.1305 decision_duration^2 \n",
      "beta(value) = 44.8854\n",
      "Participant number 481\n",
      "value_stay[t+1] = 0.2094 1 + 1.0 value_stay[t] + -0.1803 reward + 0.2021 decision_duration + 1.0 value_stay[t] + -0.3457 value_stay^2 + -0.2385 value_stay*decision_duration + -0.2322 value_stay*value_stay + 0.4527 reward^2 + -0.1576 reward*decision_duration + -0.3346 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 29.9730\n",
      "Participant number 482\n",
      "value_stay[t+1] = 0.1976 1 + 0.8745 value_stay[t] + 0.1342 decision_duration + 1.0 value_stay[t] + -0.2567 value_stay^2 + -0.2536 value_stay*value_stay + 0.3992 reward^2 + -0.1927 reward*decision_duration + -0.4088 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 60.4706\n",
      "Participant number 485\n",
      "value_stay[t+1] = 0.2202 1 + 0.8182 value_stay[t] + 0.1758 reward + 0.2136 decision_duration + 1.0 value_stay[t] + -0.322 value_stay*decision_duration + -0.4608 value_stay*value_stay + 0.188 reward*decision_duration + 0.1682 decision_duration^2 + -0.4299 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 45.5164\n",
      "Participant number 486\n",
      "value_stay[t+1] = 0.2396 1 + 1.0 value_stay[t] + -0.3625 reward + 0.169 decision_duration + 1.0 value_stay[t] + -0.2965 value_stay^2 + -0.2139 value_stay*decision_duration + -0.2878 value_stay*value_stay + 0.4535 reward^2 + -0.3435 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 65.0595\n",
      "Participant number 487\n",
      "value_stay[t+1] = 0.1814 1 + 0.8802 value_stay[t] + 0.1932 decision_duration + 1.0 value_stay[t] + -0.2219 value_stay^2 + -0.2491 value_stay*decision_duration + -0.2468 value_stay*value_stay + 0.3613 reward^2 + -0.4491 reward*value_stay + 0.119 decision_duration*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 37.3689\n",
      "Participant number 489\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.1273 decision_duration + 1.0 value_stay[t] + -0.1951 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 75.8615\n",
      "Participant number 490\n",
      "value_stay[t+1] = 0.1599 1 + 0.8478 value_stay[t] + 0.431 reward + 0.1617 decision_duration + 1.0 value_stay[t] + -0.2119 value_stay^2 + -0.1971 value_stay*decision_duration + -0.3232 value_stay*value_stay + -0.3449 reward^2 + 0.4269 reward*decision_duration + 0.1466 decision_duration^2 + -0.2571 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 21.8377\n",
      "Participant number 494\n",
      "value_stay[t+1] = 0.2627 1 + 0.8842 value_stay[t] + 0.1232 reward + 0.2228 decision_duration + 1.0 value_stay[t] + -0.4114 value_stay*decision_duration + -0.4369 value_stay*value_stay + 0.1246 reward*decision_duration + 0.1466 decision_duration^2 + -0.4967 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 23.8713\n",
      "Participant number 495\n",
      "value_stay[t+1] = 0.2627 1 + 0.8445 value_stay[t] + 0.2055 decision_duration + 1.0 value_stay[t] + -0.3729 value_stay*decision_duration + -0.4147 value_stay*value_stay + 0.2319 reward^2 + -0.1405 reward*value_stay + 0.1251 decision_duration^2 + -0.3256 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 34.3519\n",
      "Participant number 499\n",
      "value_stay[t+1] = 0.1989 1 + 1.0 value_stay[t] + 0.2784 decision_duration + 1.0 value_stay[t] + -0.2353 value_stay^2 + -0.2292 value_stay*decision_duration + -0.3493 value_stay*value_stay + 0.2949 reward^2 + -0.2615 reward*value_stay + -0.2959 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 53.9167\n",
      "Participant number 500\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.3676 reward + 0.3062 decision_duration + 1.0 value_stay[t] + -0.1459 value_stay^2 + -0.5251 value_stay*reward + -0.3935 value_stay*decision_duration + -0.1311 reward^2 + 0.3344 reward*decision_duration + 0.1262 reward*value_stay \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.1282 reward + 1.0 value_exit[t] + -0.195 reward*value_exit \n",
      "beta(value) = 17.9000\n",
      "Participant number 501\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.1728 reward + 0.3838 decision_duration + 1.0 value_stay[t] + -0.2656 value_stay^2 + -0.2844 value_stay*decision_duration + -0.2638 value_stay*value_stay + 0.1699 reward*decision_duration \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 48.3125\n",
      "Participant number 503\n",
      "value_stay[t+1] = 0.1249 1 + 0.863 value_stay[t] + 0.1288 decision_duration + 1.0 value_stay[t] + -0.3544 value_stay^2 + -0.1138 value_stay*decision_duration + -0.1362 value_stay*value_stay + 0.1476 reward^2 + 0.1203 decision_duration^2 \n",
      "value_exit[t+1] = 0.3356 1 + 0.8157 value_exit[t] + 1.1517 value_exit[t] + -0.3607 value_exit^2 + -0.2869 value_exit*value_exit + -0.1293 decision_duration^2 \n",
      "beta(value) = 47.2977\n",
      "Participant number 506\n",
      "value_stay[t+1] = 0.136 1 + 1.0 value_stay[t] + 0.1804 decision_duration + 1.0 value_stay[t] + -0.2418 value_stay^2 + -0.165 value_stay*reward + -0.2531 value_stay*decision_duration + -0.2225 value_stay*value_stay + 0.4277 reward^2 + -0.4236 reward*value_stay + 0.1192 decision_duration*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 62.1523\n",
      "Participant number 511\n",
      "value_stay[t+1] = 0.1785 1 + 1.0 value_stay[t] + 0.1651 decision_duration + 1.0 value_stay[t] + -0.2627 value_stay^2 + -0.1488 value_stay*reward + -0.3376 value_stay*decision_duration + -0.1408 value_stay*value_stay + 0.4869 reward^2 + -0.4262 reward*decision_duration + -0.5027 reward*value_stay + 0.1577 decision_duration*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 56.4845\n",
      "Participant number 512\n",
      "value_stay[t+1] = 0.1775 1 + 0.8138 value_stay[t] + 0.1636 reward + 0.1727 decision_duration + 1.0 value_stay[t] + -0.2856 value_stay*decision_duration + -0.5052 value_stay*value_stay + 0.1758 reward^2 + 0.1704 reward*decision_duration + -0.3626 reward*value_stay + 0.1359 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 58.3973\n",
      "Participant number 514\n",
      "value_stay[t+1] = 0.133 1 + 1.0 value_stay[t] + 0.1383 decision_duration + 1.0 value_stay[t] + -0.193 value_stay^2 + -0.2653 value_stay*reward + -0.3025 value_stay*decision_duration + -0.2233 value_stay*value_stay + 0.3825 reward^2 + -0.5607 reward*decision_duration + 0.1391 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 58.4506\n",
      "Participant number 519\n",
      "value_stay[t+1] = 0.1959 1 + 0.7956 value_stay[t] + 0.2703 reward + 0.2042 decision_duration + 1.0 value_stay[t] + -0.3196 value_stay*decision_duration + -0.4397 value_stay*value_stay + -0.1175 reward^2 + 0.2662 reward*decision_duration + 0.1756 decision_duration^2 + -0.3491 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 33.8741\n",
      "Participant number 520\n",
      "value_stay[t+1] = 0.1751 1 + 1.0 value_stay[t] + 0.2011 decision_duration + 1.0 value_stay[t] + -0.2342 value_stay^2 + -0.1869 value_stay*reward + -0.2427 value_stay*decision_duration + -0.1663 value_stay*value_stay + 0.502 reward^2 + -0.3587 reward*decision_duration + -0.4987 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 69.3229\n",
      "Participant number 521\n",
      "value_stay[t+1] = 0.202 1 + 0.8911 value_stay[t] + 0.1894 decision_duration + 1.0 value_stay[t] + -0.1376 value_stay^2 + -0.3183 value_stay*decision_duration + -0.3171 value_stay*value_stay + 0.1815 reward^2 + 0.1404 decision_duration^2 + -0.271 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 50.6506\n",
      "Participant number 522\n",
      "value_stay[t+1] = 0.2329 1 + 1.0 value_stay[t] + 1.0 value_stay[t] + -0.2016 value_stay^2 + -0.3227 value_stay*reward + -0.1055 value_stay*value_stay + 0.6332 reward^2 + -0.369 reward*decision_duration + -0.7274 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 67.6170\n",
      "Participant number 527\n",
      "value_stay[t+1] = 0.1348 1 + 0.8432 value_stay[t] + 0.4524 reward + 0.1746 decision_duration + 1.0 value_stay[t] + -0.177 value_stay^2 + -0.2271 value_stay*decision_duration + -0.3352 value_stay*value_stay + -0.3309 reward^2 + 0.4538 reward*decision_duration + 0.1802 decision_duration^2 + -0.2982 value_stay^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 24.1724\n",
      "Participant number 528\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.4141 reward + 0.3068 decision_duration + 1.0 value_stay[t] + -0.2223 value_stay^2 + -0.5399 value_stay*reward + -0.3531 value_stay*decision_duration + -0.1692 reward^2 + 0.3654 reward*decision_duration + 0.1592 reward*value_stay \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.1252 reward + 1.0 value_exit[t] + -0.1905 reward*value_exit \n",
      "beta(value) = 12.6667\n",
      "Participant number 532\n",
      "value_stay[t+1] = 0.2101 1 + 0.8961 value_stay[t] + 0.1583 decision_duration + 1.0 value_stay[t] + -0.1395 value_stay^2 + -0.3052 value_stay*decision_duration + -0.3655 value_stay*value_stay + 0.3784 reward^2 + -0.4714 reward*value_stay + 0.1023 decision_duration^2 \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 44.6636\n",
      "Participant number 533\n",
      "value_stay[t+1] = 0.2124 1 + 0.8927 value_stay[t] + -0.2543 reward + 0.1698 decision_duration + 1.121 value_stay[t] + -0.2561 value_stay^2 + -0.2551 value_stay*decision_duration + -0.1849 value_stay*value_stay + 0.5309 reward^2 + -0.2309 reward*decision_duration + -0.3826 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 49.2541\n",
      "Participant number 534\n",
      "value_stay[t+1] = 0.1891 1 + 1.0 value_stay[t] + -0.1586 reward + 0.2088 decision_duration + 1.0 value_stay[t] + -0.2965 value_stay^2 + -0.2293 value_stay*decision_duration + -0.2715 value_stay*value_stay + 0.4454 reward^2 + -0.3729 reward*value_stay \n",
      "value_exit[t+1] = 0\n",
      "beta(value) = 53.2969\n"
     ]
    }
   ],
   "source": [
    "print('UNDERHARVESTERS') \n",
    "for p in underharvesters:\n",
    "    print('Participant number', p)\n",
    "    estimator.print_spice_model(participant_id=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
