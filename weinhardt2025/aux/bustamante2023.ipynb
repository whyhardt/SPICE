{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tf7jlYw4NA0v",
    "outputId": "0969ca34-675d-422e-cbfb-7387d9bcd8ad"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/whyhardt/SPICE.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oXIbg826NS5i",
    "outputId": "3825864a-cb2d-4ad5-f2e5-79a4e81dfc3e"
   },
   "outputs": [],
   "source": [
    "# !pip install -e SPICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "f0uVlABYznR5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from spice import SpiceEstimator, SpiceConfig, convert_dataset, BaseRNN\n",
    "\n",
    "# For custom RNN\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data first with the `convert_dataset` method. This method returns a `SpiceDataset` object which we can use right away "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: torch.Size([1997, 112, 9])\n",
      "Number of participants: 250\n",
      "Number of actions in dataset: 2\n",
      "Number of additional inputs: 2\n"
     ]
    }
   ],
   "source": [
    "# Load your data\n",
    "file = '../data/bustamante2023/bustamante2023_processed.csv'\n",
    "dataset = convert_dataset(\n",
    "    file = file,\n",
    "    df_participant_id='subject_id',\n",
    "    df_choice='decision',\n",
    "    df_reward='reward',\n",
    "    df_block='overall_round',\n",
    "    additional_inputs=['harvest_duration', 'travel_duration'],\n",
    "    timeshift_additional_inputs=False,\n",
    "    )\n",
    "\n",
    "# structure of dataset:\n",
    "# dataset has two main attributes: xs -> inputs; ys -> targets (next action)\n",
    "# shape: (n_participants*n_blocks*n_experiments, n_timesteps, features)\n",
    "# features are (n_actions * action, n_actions * reward, n_additional_inputs * additional_input, block_number, experiment_id, participant_id)\n",
    "\n",
    "# in order to set up the participant embedding we have to compute the number of unique participants in our data \n",
    "# to get the number of participants n_participants we do:\n",
    "n_participants = len(dataset.xs[..., -1].unique())\n",
    "\n",
    "print(f\"Shape of dataset: {dataset.xs.shape}\")\n",
    "print(f\"Number of participants: {n_participants}\")\n",
    "n_actions = dataset.ys.shape[-1]\n",
    "print(f\"Number of actions in dataset: {n_actions}\")\n",
    "print(f\"Number of additional inputs: {dataset.xs.shape[-1]-2*n_actions-3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.7561,    nan, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.6859,    nan, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 1.0000,    nan, 0.0510, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.7515,    nan, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.6407,    nan, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.5662,    nan, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 1.0000,    nan, 0.0510, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.8706,    nan, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.7226,    nan, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 1.0000,    nan, 0.0510, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect dataset\n",
    "dataset.xs[0, :10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to define the configuration for SPICE with a `SpiceConfig` object.\n",
    "\n",
    "The `SpiceConfig` takes as arguments \n",
    "1. `library_setup (dict)`: Defining the variable names of each module.\n",
    "2. `memory_state (dict)`: Defining the memory state variables and their initial values.\n",
    "3. `states_in_logit (list)`: Defining which of the memory state variables are used later for the logit computation. This is necessary for some background processes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spice_config = SpiceConfig(\n",
    "    library_setup={\n",
    "        'value_stay': ['reward', 'harvest_duration'],\n",
    "        'value_exit': ['travel_duration'],\n",
    "    },\n",
    "    \n",
    "    memory_state={\n",
    "            'value': 0.,\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we are going to define the SPICE model which is a child of the `BaseRNN` and `torch.nn.Module` class and takes as required arguments:\n",
    "1. `spice_config (SpiceConfig)`: previously defined SpiceConfig object\n",
    "2. `n_actions (int)`: number of possible actions in your dataset (including non-displayed ones if applicable).\n",
    "3. `n_participants (int)`: number of participants in your dataset.\n",
    "\n",
    "As usual for a `torch.nn.Module` we have to define at least the `__init__` method and the `forward` method.\n",
    "The `forward` method gets called when computing a forward pass through the model and takes as inputs `(inputs (SpiceDataset.xs), prev_state (dict, default: None), batch_first (bool, default: False))` and returns `(logits (torch.Tensor, shape: (n_participants*n_blocks*n_experiments, timesteps, n_actions)), updated_state (dict))`. Two necessary method calls inside the forward pass are:\n",
    "1. `self.init_forward_pass(inputs, prev_state, batch_first) -> SpiceSignals`: returns a `SpiceSignals` object which carries all relevant information already processed.\n",
    "2. `self.post_forward_pass(SpiceSignals, batch_first) -> SpiceSignals`: does some re-arranging of the logits to adhere to `batch_first`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "z0kOR2Qgz0FZ"
   },
   "outputs": [],
   "source": [
    "class SPICERNN(BaseRNN):\n",
    "    \n",
    "    def __init__(self, spice_config, **kwargs):\n",
    "        super().__init__(spice_config=spice_config, **kwargs)\n",
    "        \n",
    "        # participant embedding\n",
    "        self.participant_embedding = self.setup_embedding(num_embeddings=n_participants, embedding_size=self.embedding_size, dropout=0.)\n",
    "        \n",
    "        # set up the submodules\n",
    "        self.setup_module(key_module='value_stay', input_size=2+self.embedding_size)\n",
    "        self.setup_module(key_module='value_exit', input_size=1+self.embedding_size)\n",
    "        \n",
    "    def forward(self, inputs, prev_state, batch_first=False):\n",
    "        \n",
    "        spice_signals = self.init_forward_pass(inputs, prev_state, batch_first)\n",
    "        \n",
    "        harvest_duration = spice_signals.additional_inputs[..., 0].unsqueeze(-1).repeat(1, 1, self.n_actions)\n",
    "        travel_duration = spice_signals.additional_inputs[..., 1].unsqueeze(-1).repeat(1, 1, self.n_actions)\n",
    "        rewards_chosen = (spice_signals.actions * spice_signals.rewards).sum(dim=-1, keepdim=True).repeat(1, 1, self.n_actions)\n",
    "        \n",
    "        # time-invariant participant features\n",
    "        participant_embeddings = self.participant_embedding(spice_signals.participant_ids)\n",
    "        mask_stay = torch.tensor((1,0)).reshape(1, self.n_actions).repeat(rewards_chosen.shape[1], 1)\n",
    "        mask_exit = torch.tensor((0,1)).reshape(1, self.n_actions).repeat(rewards_chosen.shape[1], 1)\n",
    "        \n",
    "        for timestep in spice_signals.timesteps:\n",
    "            \n",
    "            # update chosen value\n",
    "            self.call_module(\n",
    "                key_module='value_stay',\n",
    "                key_state='value',\n",
    "                action_mask=mask_stay,\n",
    "                inputs=(\n",
    "                    rewards_chosen[timestep], \n",
    "                    harvest_duration[timestep], \n",
    "                    ),\n",
    "                participant_index=spice_signals.participant_ids,\n",
    "                participant_embedding=participant_embeddings,\n",
    "            )\n",
    "            \n",
    "            # update not chosen value\n",
    "            self.call_module(\n",
    "                key_module='value_exit',\n",
    "                key_state='value',\n",
    "                action_mask=mask_exit,\n",
    "                inputs=(\n",
    "                    travel_duration[timestep], \n",
    "                    ),\n",
    "                participant_index=spice_signals.participant_ids,\n",
    "                participant_embedding=participant_embeddings,\n",
    "            )\n",
    "            \n",
    "            # transform logits from item-space to action-space\n",
    "            spice_signals.logits[timestep] = self.state['value']\n",
    "            \n",
    "        spice_signals = self.post_forward_pass(spice_signals, batch_first)\n",
    "        \n",
    "        return spice_signals.logits, self.get_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's setup now the `SpiceEstimator` object and fit it to the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "id": "3EnmDiUMWq6e",
    "outputId": "e53b1bbd-4173-4d2c-bcdc-15832bc31bd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training on cpu...\n",
      "================================================================================\n",
      "\n",
      "Training the RNN...\n",
      "================================================================================\n",
      "Epoch 1/1000 --- L(Train): 0.5092973 --- L(Val, RNN): 0.3817756 --- L(Val, SINDy): 3.8043301 --- Time: 1.18s; --- Convergence: 8.09e-01; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.002 1 + 1.001 value_stay[t] + 0.002 reward + -0.0 harvest_duration + -0.0 value_stay^2 + 0.001 value_stay*reward + -0.001 value_stay*harvest_duration + 0.002 reward^2 + 0.004 reward*harvest_duration + -0.001 harvest_duration^2 \n",
      "value_exit[t+1] = 0.011 1 + 1.011 value_exit[t] + -0.01 travel_duration + 0.01 value_exit^2 + -0.009 value_exit*travel_duration + -0.009 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 2/1000 --- L(Train): 0.3793685 --- L(Val, RNN): 0.3679760 --- L(Val, SINDy): 2.1244578 --- Time: 0.84s; --- Convergence: 4.11e-01; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = -0.001 1 + 0.998 value_stay[t] + 0.005 reward + -0.004 harvest_duration + -0.001 value_stay^2 + -0.0 value_stay*reward + -0.005 value_stay*harvest_duration + 0.005 reward^2 + 0.008 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = 0.005 1 + 1.019 value_exit[t] + -0.002 travel_duration + 0.003 value_exit^2 + -0.016 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 3/1000 --- L(Train): 0.3648787 --- L(Val, RNN): 0.3639058 --- L(Val, SINDy): 2.9112027 --- Time: 0.85s; --- Convergence: 2.08e-01; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.005 1 + 1.001 value_stay[t] + 0.011 reward + 0.003 harvest_duration + -0.001 value_stay^2 + 0.002 value_stay*reward + -0.002 value_stay*harvest_duration + 0.011 reward^2 + 0.015 reward*harvest_duration + 0.001 harvest_duration^2 \n",
      "value_exit[t+1] = -0.003 1 + 1.026 value_exit[t] + -0.003 travel_duration + -0.005 value_exit^2 + -0.016 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 4/1000 --- L(Train): 0.3651667 --- L(Val, RNN): 0.3619312 --- L(Val, SINDy): 2.7944717 --- Time: 0.91s; --- Convergence: 1.05e-01; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.001 1 + 0.996 value_stay[t] + 0.009 reward + -0.001 harvest_duration + -0.006 value_stay^2 + -0.003 value_stay*reward + -0.007 value_stay*harvest_duration + 0.01 reward^2 + 0.012 reward*harvest_duration + -0.003 harvest_duration^2 \n",
      "value_exit[t+1] = -0.011 1 + 1.035 value_exit[t] + -0.005 travel_duration + -0.013 value_exit^2 + -0.014 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 5/1000 --- L(Train): 0.3651251 --- L(Val, RNN): 0.3609214 --- L(Val, SINDy): 2.1436307 --- Time: 0.90s; --- Convergence: 5.29e-02; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = -0.002 1 + 0.99 value_stay[t] + 0.009 reward + -0.004 harvest_duration + -0.011 value_stay^2 + -0.008 value_stay*reward + -0.013 value_stay*harvest_duration + 0.011 reward^2 + 0.012 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.018 1 + 1.043 value_exit[t] + -0.001 travel_duration + -0.021 value_exit^2 + -0.019 value_exit*travel_duration + 0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 6/1000 --- L(Train): 0.3547129 --- L(Val, RNN): 0.3601073 --- L(Val, SINDy): 2.4822361 --- Time: 1.04s; --- Convergence: 2.69e-02; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.0 1 + 0.989 value_stay[t] + 0.013 reward + -0.001 harvest_duration + -0.014 value_stay^2 + -0.008 value_stay*reward + -0.014 value_stay*harvest_duration + 0.016 reward^2 + 0.017 reward*harvest_duration + -0.003 harvest_duration^2 \n",
      "value_exit[t+1] = -0.022 1 + 1.046 value_exit[t] + -0.001 travel_duration + -0.025 value_exit^2 + -0.019 value_exit*travel_duration + -0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 7/1000 --- L(Train): 0.3625765 --- L(Val, RNN): 0.3593431 --- L(Val, SINDy): 2.3013320 --- Time: 0.92s; --- Convergence: 1.38e-02; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.003 1 + 0.987 value_stay[t] + 0.018 reward + 0.001 harvest_duration + -0.019 value_stay^2 + -0.009 value_stay*reward + -0.016 value_stay*harvest_duration + 0.022 reward^2 + 0.021 reward*harvest_duration + -0.001 harvest_duration^2 \n",
      "value_exit[t+1] = -0.022 1 + 1.046 value_exit[t] + -0.003 travel_duration + -0.024 value_exit^2 + -0.019 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 8/1000 --- L(Train): 0.3621267 --- L(Val, RNN): 0.3586418 --- L(Val, SINDy): 1.9201562 --- Time: 0.93s; --- Convergence: 7.26e-03; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.002 1 + 0.981 value_stay[t] + 0.019 reward + -0.0 harvest_duration + -0.024 value_stay^2 + -0.014 value_stay*reward + -0.022 value_stay*harvest_duration + 0.026 reward^2 + 0.023 reward*harvest_duration + -0.002 harvest_duration^2 \n",
      "value_exit[t+1] = -0.019 1 + 1.042 value_exit[t] + -0.003 travel_duration + -0.02 value_exit^2 + -0.02 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 9/1000 --- L(Train): 0.3643481 --- L(Val, RNN): 0.3580105 --- L(Val, SINDy): 1.7091841 --- Time: 1.04s; --- Convergence: 3.95e-03; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = -0.0 1 + 0.976 value_stay[t] + 0.021 reward + -0.002 harvest_duration + -0.031 value_stay^2 + -0.019 value_stay*reward + -0.028 value_stay*harvest_duration + 0.029 reward^2 + 0.025 reward*harvest_duration + -0.004 harvest_duration^2 \n",
      "value_exit[t+1] = -0.014 1 + 1.038 value_exit[t] + -0.003 travel_duration + -0.016 value_exit^2 + -0.022 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 10/1000 --- L(Train): 0.3589939 --- L(Val, RNN): 0.3574351 --- L(Val, SINDy): 1.7028474 --- Time: 1.20s; --- Convergence: 2.26e-03; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = -0.001 1 + 0.971 value_stay[t] + 0.023 reward + -0.003 harvest_duration + -0.036 value_stay^2 + -0.024 value_stay*reward + -0.033 value_stay*harvest_duration + 0.033 reward^2 + 0.027 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.01 1 + 1.033 value_exit[t] + -0.003 travel_duration + -0.011 value_exit^2 + -0.022 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 11/1000 --- L(Train): 0.3504592 --- L(Val, RNN): 0.3569107 --- L(Val, SINDy): 1.6265451 --- Time: 1.02s; --- Convergence: 1.39e-03; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.002 1 + 0.967 value_stay[t] + 0.028 reward + -0.0 harvest_duration + -0.042 value_stay^2 + -0.026 value_stay*reward + -0.037 value_stay*harvest_duration + 0.039 reward^2 + 0.032 reward*harvest_duration + -0.002 harvest_duration^2 \n",
      "value_exit[t+1] = -0.004 1 + 1.028 value_exit[t] + -0.006 travel_duration + -0.006 value_exit^2 + -0.022 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 12/1000 --- L(Train): 0.3554625 --- L(Val, RNN): 0.3564256 --- L(Val, SINDy): 1.4239779 --- Time: 0.95s; --- Convergence: 9.39e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.004 1 + 0.962 value_stay[t] + 0.033 reward + 0.001 harvest_duration + -0.05 value_stay^2 + -0.031 value_stay*reward + -0.042 value_stay*harvest_duration + 0.045 reward^2 + 0.036 reward*harvest_duration + -0.001 harvest_duration^2 \n",
      "value_exit[t+1] = 0.001 1 + 1.023 value_exit[t] + -0.005 travel_duration + -0.001 value_exit^2 + -0.025 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 13/1000 --- L(Train): 0.3545506 --- L(Val, RNN): 0.3559832 --- L(Val, SINDy): 1.2815711 --- Time: 0.86s; --- Convergence: 6.91e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.004 1 + 0.956 value_stay[t] + 0.035 reward + 0.001 harvest_duration + -0.057 value_stay^2 + -0.037 value_stay*reward + -0.049 value_stay*harvest_duration + 0.049 reward^2 + 0.039 reward*harvest_duration + -0.001 harvest_duration^2 \n",
      "value_exit[t+1] = 0.006 1 + 1.018 value_exit[t] + -0.004 travel_duration + 0.003 value_exit^2 + -0.027 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 14/1000 --- L(Train): 0.3567459 --- L(Val, RNN): 0.3555698 --- L(Val, SINDy): 1.2378467 --- Time: 0.87s; --- Convergence: 5.52e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.004 1 + 0.949 value_stay[t] + 0.037 reward + -0.001 harvest_duration + -0.065 value_stay^2 + -0.043 value_stay*reward + -0.056 value_stay*harvest_duration + 0.052 reward^2 + 0.041 reward*harvest_duration + -0.003 harvest_duration^2 \n",
      "value_exit[t+1] = 0.011 1 + 1.014 value_exit[t] + -0.005 travel_duration + 0.007 value_exit^2 + -0.028 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 15/1000 --- L(Train): 0.3576899 --- L(Val, RNN): 0.3551616 --- L(Val, SINDy): 1.1921587 --- Time: 0.91s; --- Convergence: 4.80e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.003 1 + 0.942 value_stay[t] + 0.038 reward + -0.002 harvest_duration + -0.074 value_stay^2 + -0.05 value_stay*reward + -0.064 value_stay*harvest_duration + 0.055 reward^2 + 0.042 reward*harvest_duration + -0.004 harvest_duration^2 \n",
      "value_exit[t+1] = 0.014 1 + 1.01 value_exit[t] + -0.007 travel_duration + 0.01 value_exit^2 + -0.027 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 16/1000 --- L(Train): 0.3524729 --- L(Val, RNN): 0.3547637 --- L(Val, SINDy): 1.1914911 --- Time: 1.22s; --- Convergence: 4.39e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.004 1 + 0.935 value_stay[t] + 0.04 reward + -0.003 harvest_duration + -0.082 value_stay^2 + -0.058 value_stay*reward + -0.072 value_stay*harvest_duration + 0.059 reward^2 + 0.044 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = 0.017 1 + 1.007 value_exit[t] + -0.008 travel_duration + 0.014 value_exit^2 + -0.029 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 17/1000 --- L(Train): 0.3564253 --- L(Val, RNN): 0.3543943 --- L(Val, SINDy): 1.0955262 --- Time: 1.08s; --- Convergence: 4.04e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.006 1 + 0.927 value_stay[t] + 0.043 reward + -0.003 harvest_duration + -0.091 value_stay^2 + -0.066 value_stay*reward + -0.08 value_stay*harvest_duration + 0.063 reward^2 + 0.047 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = 0.02 1 + 1.004 value_exit[t] + -0.006 travel_duration + 0.016 value_exit^2 + -0.032 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 18/1000 --- L(Train): 0.3524169 --- L(Val, RNN): 0.3540142 --- L(Val, SINDy): 1.0033200 --- Time: 0.85s; --- Convergence: 3.92e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.008 1 + 0.918 value_stay[t] + 0.045 reward + -0.003 harvest_duration + -0.101 value_stay^2 + -0.075 value_stay*reward + -0.089 value_stay*harvest_duration + 0.067 reward^2 + 0.049 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = 0.02 1 + 1.001 value_exit[t] + -0.009 travel_duration + 0.019 value_exit^2 + -0.031 value_exit*travel_duration + -0.007 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 19/1000 --- L(Train): 0.3635609 --- L(Val, RNN): 0.3536410 --- L(Val, SINDy): 0.8910270 --- Time: 0.87s; --- Convergence: 3.83e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.009 1 + 0.91 value_stay[t] + 0.046 reward + -0.004 harvest_duration + -0.111 value_stay^2 + -0.084 value_stay*reward + -0.098 value_stay*harvest_duration + 0.07 reward^2 + 0.05 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = 0.021 1 + 0.999 value_exit[t] + -0.009 travel_duration + 0.021 value_exit^2 + -0.033 value_exit*travel_duration + -0.008 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 20/1000 --- L(Train): 0.3525239 --- L(Val, RNN): 0.3532653 --- L(Val, SINDy): 0.7905875 --- Time: 1.28s; --- Convergence: 3.79e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.011 1 + 0.901 value_stay[t] + 0.047 reward + -0.004 harvest_duration + -0.12 value_stay^2 + -0.093 value_stay*reward + -0.107 value_stay*harvest_duration + 0.072 reward^2 + 0.051 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = 0.021 1 + 0.997 value_exit[t] + -0.009 travel_duration + 0.023 value_exit^2 + -0.035 value_exit*travel_duration + -0.008 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 21/1000 --- L(Train): 0.3500310 --- L(Val, RNN): 0.3528956 --- L(Val, SINDy): 0.6875381 --- Time: 0.89s; --- Convergence: 3.74e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.014 1 + 0.893 value_stay[t] + 0.048 reward + -0.003 harvest_duration + -0.129 value_stay^2 + -0.103 value_stay*reward + -0.116 value_stay*harvest_duration + 0.075 reward^2 + 0.052 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = 0.021 1 + 0.996 value_exit[t] + -0.008 travel_duration + 0.025 value_exit^2 + -0.038 value_exit*travel_duration + -0.007 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 22/1000 --- L(Train): 0.3568775 --- L(Val, RNN): 0.3525400 --- L(Val, SINDy): 0.7034635 --- Time: 0.93s; --- Convergence: 3.65e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.017 1 + 0.884 value_stay[t] + 0.048 reward + -0.003 harvest_duration + -0.139 value_stay^2 + -0.113 value_stay*reward + -0.125 value_stay*harvest_duration + 0.077 reward^2 + 0.052 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = 0.02 1 + 0.994 value_exit[t] + -0.009 travel_duration + 0.027 value_exit^2 + -0.038 value_exit*travel_duration + -0.008 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 23/1000 --- L(Train): 0.3557719 --- L(Val, RNN): 0.3522120 --- L(Val, SINDy): 0.6536233 --- Time: 0.87s; --- Convergence: 3.47e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.021 1 + 0.875 value_stay[t] + 0.05 reward + -0.001 harvest_duration + -0.149 value_stay^2 + -0.122 value_stay*reward + -0.135 value_stay*harvest_duration + 0.08 reward^2 + 0.054 reward*harvest_duration + -0.003 harvest_duration^2 \n",
      "value_exit[t+1] = 0.017 1 + 0.994 value_exit[t] + -0.011 travel_duration + 0.028 value_exit^2 + -0.039 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 24/1000 --- L(Train): 0.3575087 --- L(Val, RNN): 0.3519222 --- L(Val, SINDy): 0.6478154 --- Time: 1.14s; --- Convergence: 3.18e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.023 1 + 0.865 value_stay[t] + 0.05 reward + -0.001 harvest_duration + -0.159 value_stay^2 + -0.133 value_stay*reward + -0.145 value_stay*harvest_duration + 0.082 reward^2 + 0.054 reward*harvest_duration + -0.003 harvest_duration^2 \n",
      "value_exit[t+1] = 0.015 1 + 0.993 value_exit[t] + -0.009 travel_duration + 0.029 value_exit^2 + -0.042 value_exit*travel_duration + -0.008 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 25/1000 --- L(Train): 0.3548397 --- L(Val, RNN): 0.3516714 --- L(Val, SINDy): 0.5933520 --- Time: 1.02s; --- Convergence: 2.84e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.026 1 + 0.855 value_stay[t] + 0.05 reward + -0.0 harvest_duration + -0.169 value_stay^2 + -0.143 value_stay*reward + -0.155 value_stay*harvest_duration + 0.084 reward^2 + 0.054 reward*harvest_duration + -0.002 harvest_duration^2 \n",
      "value_exit[t+1] = 0.012 1 + 0.992 value_exit[t] + -0.009 travel_duration + 0.03 value_exit^2 + -0.044 value_exit*travel_duration + -0.008 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 26/1000 --- L(Train): 0.3529368 --- L(Val, RNN): 0.3514187 --- L(Val, SINDy): 0.6199722 --- Time: 1.07s; --- Convergence: 2.69e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.031 1 + 0.845 value_stay[t] + 0.053 reward + 0.003 harvest_duration + -0.18 value_stay^2 + -0.154 value_stay*reward + -0.165 value_stay*harvest_duration + 0.088 reward^2 + 0.057 reward*harvest_duration + 0.001 harvest_duration^2 \n",
      "value_exit[t+1] = 0.007 1 + 0.993 value_exit[t] + -0.013 travel_duration + 0.031 value_exit^2 + -0.042 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 27/1000 --- L(Train): 0.3510900 --- L(Val, RNN): 0.3511938 --- L(Val, SINDy): 0.6046557 --- Time: 0.97s; --- Convergence: 2.47e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.031 1 + 0.834 value_stay[t] + 0.053 reward + 0.003 harvest_duration + -0.191 value_stay^2 + -0.166 value_stay*reward + -0.176 value_stay*harvest_duration + 0.091 reward^2 + 0.057 reward*harvest_duration + 0.001 harvest_duration^2 \n",
      "value_exit[t+1] = 0.004 1 + 0.993 value_exit[t] + -0.01 travel_duration + 0.032 value_exit^2 + -0.046 value_exit*travel_duration + -0.009 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 28/1000 --- L(Train): 0.3570781 --- L(Val, RNN): 0.3509254 --- L(Val, SINDy): 0.5531638 --- Time: 1.16s; --- Convergence: 2.58e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.032 1 + 0.824 value_stay[t] + 0.055 reward + 0.003 harvest_duration + -0.202 value_stay^2 + -0.176 value_stay*reward + -0.186 value_stay*harvest_duration + 0.095 reward^2 + 0.059 reward*harvest_duration + 0.001 harvest_duration^2 \n",
      "value_exit[t+1] = 0.001 1 + 0.993 value_exit[t] + -0.009 travel_duration + 0.033 value_exit^2 + -0.049 value_exit*travel_duration + -0.007 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 29/1000 --- L(Train): 0.3575248 --- L(Val, RNN): 0.3506469 --- L(Val, SINDy): 0.5077839 --- Time: 0.94s; --- Convergence: 2.68e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.036 1 + 0.815 value_stay[t] + 0.06 reward + 0.007 harvest_duration + -0.212 value_stay^2 + -0.186 value_stay*reward + -0.196 value_stay*harvest_duration + 0.102 reward^2 + 0.064 reward*harvest_duration + 0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.003 1 + 0.993 value_exit[t] + -0.009 travel_duration + 0.033 value_exit^2 + -0.05 value_exit*travel_duration + -0.008 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 30/1000 --- L(Train): 0.3566967 --- L(Val, RNN): 0.3503599 --- L(Val, SINDy): 0.4736639 --- Time: 1.04s; --- Convergence: 2.78e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.805 value_stay[t] + 0.067 reward + 0.011 harvest_duration + -0.223 value_stay^2 + -0.196 value_stay*reward + -0.205 value_stay*harvest_duration + 0.11 reward^2 + 0.07 reward*harvest_duration + 0.009 harvest_duration^2 \n",
      "value_exit[t+1] = -0.01 1 + 0.995 value_exit[t] + -0.012 travel_duration + 0.034 value_exit^2 + -0.048 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 31/1000 --- L(Train): 0.3506030 --- L(Val, RNN): 0.3500711 --- L(Val, SINDy): 0.4739839 --- Time: 0.95s; --- Convergence: 2.83e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.795 value_stay[t] + 0.071 reward + 0.013 harvest_duration + -0.235 value_stay^2 + -0.207 value_stay*reward + -0.216 value_stay*harvest_duration + 0.116 reward^2 + 0.075 reward*harvest_duration + 0.011 harvest_duration^2 \n",
      "value_exit[t+1] = -0.015 1 + 0.996 value_exit[t] + -0.014 travel_duration + 0.034 value_exit^2 + -0.047 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 32/1000 --- L(Train): 0.3505533 --- L(Val, RNN): 0.3497564 --- L(Val, SINDy): 0.4693975 --- Time: 1.28s; --- Convergence: 2.99e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.784 value_stay[t] + 0.075 reward + 0.013 harvest_duration + -0.247 value_stay^2 + -0.217 value_stay*reward + -0.227 value_stay*harvest_duration + 0.122 reward^2 + 0.079 reward*harvest_duration + 0.011 harvest_duration^2 \n",
      "value_exit[t+1] = -0.019 1 + 0.997 value_exit[t] + -0.014 travel_duration + 0.034 value_exit^2 + -0.048 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 33/1000 --- L(Train): 0.3538852 --- L(Val, RNN): 0.3494076 --- L(Val, SINDy): 0.4455453 --- Time: 0.85s; --- Convergence: 3.24e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.773 value_stay[t] + 0.078 reward + 0.011 harvest_duration + -0.258 value_stay^2 + -0.229 value_stay*reward + -0.238 value_stay*harvest_duration + 0.128 reward^2 + 0.082 reward*harvest_duration + 0.009 harvest_duration^2 \n",
      "value_exit[t+1] = -0.02 1 + 0.997 value_exit[t] + -0.011 travel_duration + 0.035 value_exit^2 + -0.053 value_exit*travel_duration + -0.009 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 34/1000 --- L(Train): 0.3527975 --- L(Val, RNN): 0.3490729 --- L(Val, SINDy): 0.4368377 --- Time: 0.91s; --- Convergence: 3.29e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.762 value_stay[t] + 0.083 reward + 0.01 harvest_duration + -0.27 value_stay^2 + -0.239 value_stay*reward + -0.249 value_stay*harvest_duration + 0.135 reward^2 + 0.087 reward*harvest_duration + 0.008 harvest_duration^2 \n",
      "value_exit[t+1] = -0.021 1 + 0.997 value_exit[t] + -0.008 travel_duration + 0.035 value_exit^2 + -0.056 value_exit*travel_duration + -0.007 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 35/1000 --- L(Train): 0.3520170 --- L(Val, RNN): 0.3487906 --- L(Val, SINDy): 0.4361921 --- Time: 1.14s; --- Convergence: 3.06e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.752 value_stay[t] + 0.091 reward + 0.013 harvest_duration + -0.282 value_stay^2 + -0.249 value_stay*reward + -0.259 value_stay*harvest_duration + 0.145 reward^2 + 0.095 reward*harvest_duration + 0.011 harvest_duration^2 \n",
      "value_exit[t+1] = -0.027 1 + 0.999 value_exit[t] + -0.01 travel_duration + 0.035 value_exit^2 + -0.054 value_exit*travel_duration + -0.009 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 36/1000 --- L(Train): 0.3490347 --- L(Val, RNN): 0.3484930 --- L(Val, SINDy): 0.4278950 --- Time: 1.15s; --- Convergence: 3.02e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.741 value_stay[t] + 0.095 reward + 0.012 harvest_duration + -0.294 value_stay^2 + -0.26 value_stay*reward + -0.271 value_stay*harvest_duration + 0.151 reward^2 + 0.099 reward*harvest_duration + 0.01 harvest_duration^2 \n",
      "value_exit[t+1] = -0.033 1 + 1.001 value_exit[t] + -0.014 travel_duration + 0.035 value_exit^2 + -0.052 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 37/1000 --- L(Train): 0.3562283 --- L(Val, RNN): 0.3481841 --- L(Val, SINDy): 0.4156739 --- Time: 0.89s; --- Convergence: 3.05e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.729 value_stay[t] + 0.096 reward + 0.007 harvest_duration + -0.307 value_stay^2 + -0.271 value_stay*reward + -0.283 value_stay*harvest_duration + 0.155 reward^2 + 0.1 reward*harvest_duration + 0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.036 1 + 1.003 value_exit[t] + -0.014 travel_duration + 0.035 value_exit^2 + -0.052 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 38/1000 --- L(Train): 0.3536738 --- L(Val, RNN): 0.3478884 --- L(Val, SINDy): 0.4162408 --- Time: 1.08s; --- Convergence: 3.01e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.718 value_stay[t] + 0.098 reward + 0.003 harvest_duration + -0.319 value_stay^2 + -0.282 value_stay*reward + -0.294 value_stay*harvest_duration + 0.159 reward^2 + 0.102 reward*harvest_duration + 0.001 harvest_duration^2 \n",
      "value_exit[t+1] = -0.039 1 + 1.004 value_exit[t] + -0.014 travel_duration + 0.035 value_exit^2 + -0.053 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 39/1000 --- L(Train): 0.3504746 --- L(Val, RNN): 0.3475860 --- L(Val, SINDy): 0.4062343 --- Time: 1.12s; --- Convergence: 3.01e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.707 value_stay[t] + 0.101 reward + 0.002 harvest_duration + -0.331 value_stay^2 + -0.293 value_stay*reward + -0.305 value_stay*harvest_duration + 0.164 reward^2 + 0.105 reward*harvest_duration + -0.0 harvest_duration^2 \n",
      "value_exit[t+1] = -0.04 1 + 1.004 value_exit[t] + -0.012 travel_duration + 0.035 value_exit^2 + -0.056 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 40/1000 --- L(Train): 0.3540649 --- L(Val, RNN): 0.3472151 --- L(Val, SINDy): 0.4050747 --- Time: 0.86s; --- Convergence: 3.36e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.697 value_stay[t] + 0.106 reward + 0.002 harvest_duration + -0.343 value_stay^2 + -0.303 value_stay*reward + -0.315 value_stay*harvest_duration + 0.171 reward^2 + 0.11 reward*harvest_duration + 0.0 harvest_duration^2 \n",
      "value_exit[t+1] = -0.04 1 + 1.004 value_exit[t] + -0.009 travel_duration + 0.036 value_exit^2 + -0.059 value_exit*travel_duration + -0.008 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 41/1000 --- L(Train): 0.3426217 --- L(Val, RNN): 0.3468423 --- L(Val, SINDy): 0.3944792 --- Time: 0.89s; --- Convergence: 3.54e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.686 value_stay[t] + 0.109 reward + 0.002 harvest_duration + -0.355 value_stay^2 + -0.314 value_stay*reward + -0.326 value_stay*harvest_duration + 0.176 reward^2 + 0.113 reward*harvest_duration + 0.0 harvest_duration^2 \n",
      "value_exit[t+1] = -0.043 1 + 1.005 value_exit[t] + -0.009 travel_duration + 0.036 value_exit^2 + -0.06 value_exit*travel_duration + -0.008 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 42/1000 --- L(Train): 0.3422602 --- L(Val, RNN): 0.3465401 --- L(Val, SINDy): 0.3996658 --- Time: 0.86s; --- Convergence: 3.28e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.675 value_stay[t] + 0.11 reward + -0.0 harvest_duration + -0.367 value_stay^2 + -0.326 value_stay*reward + -0.337 value_stay*harvest_duration + 0.179 reward^2 + 0.114 reward*harvest_duration + -0.002 harvest_duration^2 \n",
      "value_exit[t+1] = -0.047 1 + 1.007 value_exit[t] + -0.011 travel_duration + 0.035 value_exit^2 + -0.059 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 43/1000 --- L(Train): 0.3462494 --- L(Val, RNN): 0.3460844 --- L(Val, SINDy): 0.3920983 --- Time: 0.92s; --- Convergence: 3.92e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.664 value_stay[t] + 0.11 reward + -0.002 harvest_duration + -0.379 value_stay^2 + -0.338 value_stay*reward + -0.349 value_stay*harvest_duration + 0.182 reward^2 + 0.114 reward*harvest_duration + -0.004 harvest_duration^2 \n",
      "value_exit[t+1] = -0.052 1 + 1.009 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.058 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 44/1000 --- L(Train): 0.3527253 --- L(Val, RNN): 0.3457117 --- L(Val, SINDy): 0.3909274 --- Time: 1.11s; --- Convergence: 3.82e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.653 value_stay[t] + 0.112 reward + -0.003 harvest_duration + -0.391 value_stay^2 + -0.349 value_stay*reward + -0.359 value_stay*harvest_duration + 0.185 reward^2 + 0.116 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.055 1 + 1.01 value_exit[t] + -0.014 travel_duration + 0.035 value_exit^2 + -0.057 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 45/1000 --- L(Train): 0.3512395 --- L(Val, RNN): 0.3453275 --- L(Val, SINDy): 0.3882940 --- Time: 1.22s; --- Convergence: 3.83e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.644 value_stay[t] + 0.113 reward + -0.004 harvest_duration + -0.401 value_stay^2 + -0.359 value_stay*reward + -0.369 value_stay*harvest_duration + 0.188 reward^2 + 0.117 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.058 1 + 1.012 value_exit[t] + -0.015 travel_duration + 0.035 value_exit^2 + -0.057 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 46/1000 --- L(Train): 0.3444504 --- L(Val, RNN): 0.3449175 --- L(Val, SINDy): 0.3779397 --- Time: 1.33s; --- Convergence: 3.97e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.635 value_stay[t] + 0.114 reward + -0.004 harvest_duration + -0.411 value_stay^2 + -0.368 value_stay*reward + -0.378 value_stay*harvest_duration + 0.191 reward^2 + 0.119 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.06 1 + 1.012 value_exit[t] + -0.015 travel_duration + 0.035 value_exit^2 + -0.058 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 47/1000 --- L(Train): 0.3441795 --- L(Val, RNN): 0.3444341 --- L(Val, SINDy): 0.3814792 --- Time: 1.07s; --- Convergence: 4.40e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.626 value_stay[t] + 0.115 reward + -0.005 harvest_duration + -0.42 value_stay^2 + -0.377 value_stay*reward + -0.386 value_stay*harvest_duration + 0.193 reward^2 + 0.119 reward*harvest_duration + -0.007 harvest_duration^2 \n",
      "value_exit[t+1] = -0.06 1 + 1.012 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.06 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 48/1000 --- L(Train): 0.3467800 --- L(Val, RNN): 0.3439369 --- L(Val, SINDy): 0.3791466 --- Time: 0.95s; --- Convergence: 4.69e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.617 value_stay[t] + 0.114 reward + -0.006 harvest_duration + -0.429 value_stay^2 + -0.387 value_stay*reward + -0.395 value_stay*harvest_duration + 0.194 reward^2 + 0.118 reward*harvest_duration + -0.008 harvest_duration^2 \n",
      "value_exit[t+1] = -0.06 1 + 1.012 value_exit[t] + -0.011 travel_duration + 0.035 value_exit^2 + -0.063 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 49/1000 --- L(Train): 0.3483420 --- L(Val, RNN): 0.3434385 --- L(Val, SINDy): 0.3782424 --- Time: 1.11s; --- Convergence: 4.84e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.608 value_stay[t] + 0.115 reward + -0.004 harvest_duration + -0.438 value_stay^2 + -0.396 value_stay*reward + -0.404 value_stay*harvest_duration + 0.196 reward^2 + 0.119 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.061 1 + 1.012 value_exit[t] + -0.01 travel_duration + 0.035 value_exit^2 + -0.064 value_exit*travel_duration + -0.009 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 50/1000 --- L(Train): 0.3501617 --- L(Val, RNN): 0.3428674 --- L(Val, SINDy): 0.3696032 --- Time: 1.05s; --- Convergence: 5.27e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.6 value_stay[t] + 0.117 reward + -0.002 harvest_duration + -0.447 value_stay^2 + -0.405 value_stay*reward + -0.412 value_stay*harvest_duration + 0.199 reward^2 + 0.121 reward*harvest_duration + -0.004 harvest_duration^2 \n",
      "value_exit[t+1] = -0.063 1 + 1.013 value_exit[t] + -0.011 travel_duration + 0.035 value_exit^2 + -0.065 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 51/1000 --- L(Train): 0.3495021 --- L(Val, RNN): 0.3423029 --- L(Val, SINDy): 0.3668642 --- Time: 1.15s; --- Convergence: 5.46e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.05 1 + 0.592 value_stay[t] + 0.119 reward + 0.002 harvest_duration + -0.454 value_stay^2 + -0.412 value_stay*reward + -0.418 value_stay*harvest_duration + 0.204 reward^2 + 0.123 reward*harvest_duration + -0.0 harvest_duration^2 \n",
      "value_exit[t+1] = -0.066 1 + 1.014 value_exit[t] + -0.012 travel_duration + 0.035 value_exit^2 + -0.064 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 52/1000 --- L(Train): 0.3510835 --- L(Val, RNN): 0.3417113 --- L(Val, SINDy): 0.3673845 --- Time: 0.87s; --- Convergence: 5.69e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.053 1 + 0.585 value_stay[t] + 0.122 reward + 0.005 harvest_duration + -0.46 value_stay^2 + -0.418 value_stay*reward + -0.424 value_stay*harvest_duration + 0.208 reward^2 + 0.126 reward*harvest_duration + 0.003 harvest_duration^2 \n",
      "value_exit[t+1] = -0.068 1 + 1.015 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.064 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 53/1000 --- L(Train): 0.3417630 --- L(Val, RNN): 0.3410207 --- L(Val, SINDy): 0.3655974 --- Time: 1.10s; --- Convergence: 6.30e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.056 1 + 0.579 value_stay[t] + 0.127 reward + 0.008 harvest_duration + -0.464 value_stay^2 + -0.422 value_stay*reward + -0.429 value_stay*harvest_duration + 0.215 reward^2 + 0.131 reward*harvest_duration + 0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.069 1 + 1.015 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.065 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 54/1000 --- L(Train): 0.3466619 --- L(Val, RNN): 0.3402878 --- L(Val, SINDy): 0.3620326 --- Time: 1.15s; --- Convergence: 6.81e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.06 1 + 0.575 value_stay[t] + 0.133 reward + 0.012 harvest_duration + -0.465 value_stay^2 + -0.422 value_stay*reward + -0.432 value_stay*harvest_duration + 0.224 reward^2 + 0.137 reward*harvest_duration + 0.01 harvest_duration^2 \n",
      "value_exit[t+1] = -0.07 1 + 1.015 value_exit[t] + -0.012 travel_duration + 0.035 value_exit^2 + -0.066 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 55/1000 --- L(Train): 0.3463366 --- L(Val, RNN): 0.3394898 --- L(Val, SINDy): 0.3630628 --- Time: 1.21s; --- Convergence: 7.40e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.062 1 + 0.573 value_stay[t] + 0.141 reward + 0.015 harvest_duration + -0.462 value_stay^2 + -0.419 value_stay*reward + -0.433 value_stay*harvest_duration + 0.233 reward^2 + 0.145 reward*harvest_duration + 0.013 harvest_duration^2 \n",
      "value_exit[t+1] = -0.07 1 + 1.015 value_exit[t] + -0.011 travel_duration + 0.035 value_exit^2 + -0.067 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 56/1000 --- L(Train): 0.3468562 --- L(Val, RNN): 0.3387275 --- L(Val, SINDy): 0.3614927 --- Time: 1.08s; --- Convergence: 7.51e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.061 1 + 0.572 value_stay[t] + 0.147 reward + 0.014 harvest_duration + -0.457 value_stay^2 + -0.414 value_stay*reward + -0.433 value_stay*harvest_duration + 0.243 reward^2 + 0.151 reward*harvest_duration + 0.012 harvest_duration^2 \n",
      "value_exit[t+1] = -0.071 1 + 1.016 value_exit[t] + -0.012 travel_duration + 0.035 value_exit^2 + -0.068 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 57/1000 --- L(Train): 0.3445237 --- L(Val, RNN): 0.3378399 --- L(Val, SINDy): 0.3604084 --- Time: 0.96s; --- Convergence: 8.19e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.057 1 + 0.57 value_stay[t] + 0.153 reward + 0.01 harvest_duration + -0.45 value_stay^2 + -0.407 value_stay*reward + -0.432 value_stay*harvest_duration + 0.254 reward^2 + 0.157 reward*harvest_duration + 0.008 harvest_duration^2 \n",
      "value_exit[t+1] = -0.073 1 + 1.016 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.068 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 58/1000 --- L(Train): 0.3453823 --- L(Val, RNN): 0.3368942 --- L(Val, SINDy): 0.3605940 --- Time: 0.89s; --- Convergence: 8.83e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.055 1 + 0.573 value_stay[t] + 0.162 reward + 0.009 harvest_duration + -0.44 value_stay^2 + -0.397 value_stay*reward + -0.426 value_stay*harvest_duration + 0.266 reward^2 + 0.166 reward*harvest_duration + 0.007 harvest_duration^2 \n",
      "value_exit[t+1] = -0.074 1 + 1.016 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.068 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 59/1000 --- L(Train): 0.3413489 --- L(Val, RNN): 0.3359607 --- L(Val, SINDy): 0.3616739 --- Time: 1.13s; --- Convergence: 9.08e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.06 1 + 0.581 value_stay[t] + 0.173 reward + 0.013 harvest_duration + -0.428 value_stay^2 + -0.386 value_stay*reward + -0.417 value_stay*harvest_duration + 0.279 reward^2 + 0.177 reward*harvest_duration + 0.011 harvest_duration^2 \n",
      "value_exit[t+1] = -0.075 1 + 1.016 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.069 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 60/1000 --- L(Train): 0.3419703 --- L(Val, RNN): 0.3349842 --- L(Val, SINDy): 0.3587418 --- Time: 0.88s; --- Convergence: 9.42e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.065 1 + 0.59 value_stay[t] + 0.185 reward + 0.018 harvest_duration + -0.416 value_stay^2 + -0.373 value_stay*reward + -0.406 value_stay*harvest_duration + 0.293 reward^2 + 0.189 reward*harvest_duration + 0.016 harvest_duration^2 \n",
      "value_exit[t+1] = -0.075 1 + 1.016 value_exit[t] + -0.012 travel_duration + 0.035 value_exit^2 + -0.07 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 61/1000 --- L(Train): 0.3459201 --- L(Val, RNN): 0.3339262 --- L(Val, SINDy): 0.3547858 --- Time: 1.02s; --- Convergence: 1.00e-03; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.061 1 + 0.595 value_stay[t] + 0.192 reward + 0.014 harvest_duration + -0.402 value_stay^2 + -0.359 value_stay*reward + -0.398 value_stay*harvest_duration + 0.306 reward^2 + 0.196 reward*harvest_duration + 0.012 harvest_duration^2 \n",
      "value_exit[t+1] = -0.076 1 + 1.016 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.071 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 62/1000 --- L(Train): 0.3440435 --- L(Val, RNN): 0.3328950 --- L(Val, SINDy): 0.3550497 --- Time: 0.93s; --- Convergence: 1.02e-03; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.056 1 + 0.604 value_stay[t] + 0.201 reward + 0.008 harvest_duration + -0.387 value_stay^2 + -0.345 value_stay*reward + -0.387 value_stay*harvest_duration + 0.32 reward^2 + 0.205 reward*harvest_duration + 0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 1.016 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.072 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 63/1000 --- L(Train): 0.3428254 --- L(Val, RNN): 0.3320184 --- L(Val, SINDy): 0.3563865 --- Time: 0.88s; --- Convergence: 9.46e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.055 1 + 0.614 value_stay[t] + 0.212 reward + 0.006 harvest_duration + -0.372 value_stay^2 + -0.33 value_stay*reward + -0.375 value_stay*harvest_duration + 0.334 reward^2 + 0.216 reward*harvest_duration + 0.004 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 1.015 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.073 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 64/1000 --- L(Train): 0.3454114 --- L(Val, RNN): 0.3311209 --- L(Val, SINDy): 0.3521585 --- Time: 0.85s; --- Convergence: 9.22e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.056 1 + 0.626 value_stay[t] + 0.225 reward + 0.006 harvest_duration + -0.357 value_stay^2 + -0.314 value_stay*reward + -0.361 value_stay*harvest_duration + 0.35 reward^2 + 0.229 reward*harvest_duration + 0.004 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 1.015 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.074 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 65/1000 --- L(Train): 0.3415206 --- L(Val, RNN): 0.3302599 --- L(Val, SINDy): 0.3514231 --- Time: 0.92s; --- Convergence: 8.91e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.06 1 + 0.64 value_stay[t] + 0.239 reward + 0.009 harvest_duration + -0.341 value_stay^2 + -0.298 value_stay*reward + -0.347 value_stay*harvest_duration + 0.366 reward^2 + 0.243 reward*harvest_duration + 0.007 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 1.015 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.075 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 66/1000 --- L(Train): 0.3388797 --- L(Val, RNN): 0.3296049 --- L(Val, SINDy): 0.3527990 --- Time: 1.03s; --- Convergence: 7.73e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.062 1 + 0.652 value_stay[t] + 0.251 reward + 0.009 harvest_duration + -0.325 value_stay^2 + -0.283 value_stay*reward + -0.333 value_stay*harvest_duration + 0.381 reward^2 + 0.255 reward*harvest_duration + 0.007 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 1.014 value_exit[t] + -0.014 travel_duration + 0.035 value_exit^2 + -0.076 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 67/1000 --- L(Train): 0.3406454 --- L(Val, RNN): 0.3288473 --- L(Val, SINDy): 0.3509893 --- Time: 0.95s; --- Convergence: 7.65e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.061 1 + 0.661 value_stay[t] + 0.262 reward + 0.007 harvest_duration + -0.311 value_stay^2 + -0.268 value_stay*reward + -0.323 value_stay*harvest_duration + 0.394 reward^2 + 0.266 reward*harvest_duration + 0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 1.014 value_exit[t] + -0.014 travel_duration + 0.035 value_exit^2 + -0.076 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 68/1000 --- L(Train): 0.3396269 --- L(Val, RNN): 0.3283428 --- L(Val, SINDy): 0.3483960 --- Time: 1.05s; --- Convergence: 6.35e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.057 1 + 0.666 value_stay[t] + 0.269 reward + 0.002 harvest_duration + -0.3 value_stay^2 + -0.256 value_stay*reward + -0.316 value_stay*harvest_duration + 0.405 reward^2 + 0.274 reward*harvest_duration + -0.0 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 1.013 value_exit[t] + -0.014 travel_duration + 0.036 value_exit^2 + -0.077 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 69/1000 --- L(Train): 0.3375436 --- L(Val, RNN): 0.3281747 --- L(Val, SINDy): 0.3474358 --- Time: 1.22s; --- Convergence: 4.02e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.661 value_stay[t] + 0.265 reward + -0.008 harvest_duration + -0.298 value_stay^2 + -0.254 value_stay*reward + -0.32 value_stay*harvest_duration + 0.405 reward^2 + 0.269 reward*harvest_duration + -0.01 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 1.013 value_exit[t] + -0.014 travel_duration + 0.036 value_exit^2 + -0.079 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 70/1000 --- L(Train): 0.3446465 --- L(Val, RNN): 0.3269562 --- L(Val, SINDy): 0.3474319 --- Time: 1.00s; --- Convergence: 8.10e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.656 value_stay[t] + 0.261 reward + -0.017 harvest_duration + -0.296 value_stay^2 + -0.253 value_stay*reward + -0.324 value_stay*harvest_duration + 0.404 reward^2 + 0.266 reward*harvest_duration + -0.019 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 1.012 value_exit[t] + -0.014 travel_duration + 0.036 value_exit^2 + -0.08 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 71/1000 --- L(Train): 0.3426362 --- L(Val, RNN): 0.3267430 --- L(Val, SINDy): 0.3497319 --- Time: 1.06s; --- Convergence: 5.12e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.032 1 + 0.652 value_stay[t] + 0.259 reward + -0.024 harvest_duration + -0.291 value_stay^2 + -0.249 value_stay*reward + -0.327 value_stay*harvest_duration + 0.405 reward^2 + 0.264 reward*harvest_duration + -0.026 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 1.012 value_exit[t] + -0.015 travel_duration + 0.036 value_exit^2 + -0.08 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 72/1000 --- L(Train): 0.3441774 --- L(Val, RNN): 0.3263136 --- L(Val, SINDy): 0.3490880 --- Time: 2.56s; --- Convergence: 4.71e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.027 1 + 0.65 value_stay[t] + 0.26 reward + -0.03 harvest_duration + -0.285 value_stay^2 + -0.244 value_stay*reward + -0.327 value_stay*harvest_duration + 0.409 reward^2 + 0.264 reward*harvest_duration + -0.032 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 1.011 value_exit[t] + -0.015 travel_duration + 0.036 value_exit^2 + -0.081 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 73/1000 --- L(Train): 0.3390588 --- L(Val, RNN): 0.3254374 --- L(Val, SINDy): 0.3470588 --- Time: 3.92s; --- Convergence: 6.73e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.025 1 + 0.652 value_stay[t] + 0.262 reward + -0.033 harvest_duration + -0.276 value_stay^2 + -0.236 value_stay*reward + -0.324 value_stay*harvest_duration + 0.416 reward^2 + 0.267 reward*harvest_duration + -0.035 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 1.011 value_exit[t] + -0.014 travel_duration + 0.036 value_exit^2 + -0.083 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 74/1000 --- L(Train): 0.3372434 --- L(Val, RNN): 0.3248359 --- L(Val, SINDy): 0.3453377 --- Time: 6.66s; --- Convergence: 6.37e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.025 1 + 0.654 value_stay[t] + 0.266 reward + -0.034 harvest_duration + -0.267 value_stay^2 + -0.228 value_stay*reward + -0.32 value_stay*harvest_duration + 0.423 reward^2 + 0.271 reward*harvest_duration + -0.036 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 1.01 value_exit[t] + -0.014 travel_duration + 0.036 value_exit^2 + -0.084 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 75/1000 --- L(Train): 0.3409837 --- L(Val, RNN): 0.3240981 --- L(Val, SINDy): 0.3449801 --- Time: 4.08s; --- Convergence: 6.88e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.026 1 + 0.657 value_stay[t] + 0.271 reward + -0.034 harvest_duration + -0.257 value_stay^2 + -0.219 value_stay*reward + -0.316 value_stay*harvest_duration + 0.431 reward^2 + 0.276 reward*harvest_duration + -0.036 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 1.01 value_exit[t] + -0.015 travel_duration + 0.036 value_exit^2 + -0.084 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 76/1000 --- L(Train): 0.3402959 --- L(Val, RNN): 0.3237267 --- L(Val, SINDy): 0.3450522 --- Time: 3.54s; --- Convergence: 5.29e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.028 1 + 0.661 value_stay[t] + 0.277 reward + -0.032 harvest_duration + -0.247 value_stay^2 + -0.21 value_stay*reward + -0.31 value_stay*harvest_duration + 0.44 reward^2 + 0.282 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 1.01 value_exit[t] + -0.016 travel_duration + 0.036 value_exit^2 + -0.085 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 77/1000 --- L(Train): 0.3391602 --- L(Val, RNN): 0.3231411 --- L(Val, SINDy): 0.3455248 --- Time: 1.91s; --- Convergence: 5.58e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.033 1 + 0.668 value_stay[t] + 0.286 reward + -0.028 harvest_duration + -0.234 value_stay^2 + -0.198 value_stay*reward + -0.301 value_stay*harvest_duration + 0.451 reward^2 + 0.291 reward*harvest_duration + -0.03 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 1.008 value_exit[t] + -0.013 travel_duration + 0.037 value_exit^2 + -0.088 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 78/1000 --- L(Train): 0.3365828 --- L(Val, RNN): 0.3229696 --- L(Val, SINDy): 0.3479059 --- Time: 2.94s; --- Convergence: 3.64e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.676 value_stay[t] + 0.296 reward + -0.022 harvest_duration + -0.22 value_stay^2 + -0.185 value_stay*reward + -0.292 value_stay*harvest_duration + 0.464 reward^2 + 0.3 reward*harvest_duration + -0.024 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 1.009 value_exit[t] + -0.015 travel_duration + 0.036 value_exit^2 + -0.087 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 79/1000 --- L(Train): 0.3364283 --- L(Val, RNN): 0.3219639 --- L(Val, SINDy): 0.3514905 --- Time: 2.97s; --- Convergence: 6.85e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.683 value_stay[t] + 0.305 reward + -0.018 harvest_duration + -0.207 value_stay^2 + -0.173 value_stay*reward + -0.283 value_stay*harvest_duration + 0.476 reward^2 + 0.309 reward*harvest_duration + -0.02 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 1.01 value_exit[t] + -0.017 travel_duration + 0.036 value_exit^2 + -0.086 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 80/1000 --- L(Train): 0.3407446 --- L(Val, RNN): 0.3220393 --- L(Val, SINDy): 0.3496934 --- Time: 1.61s; --- Convergence: 3.80e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.687 value_stay[t] + 0.312 reward + -0.016 harvest_duration + -0.197 value_stay^2 + -0.164 value_stay*reward + -0.278 value_stay*harvest_duration + 0.485 reward^2 + 0.316 reward*harvest_duration + -0.018 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 1.009 value_exit[t] + -0.016 travel_duration + 0.037 value_exit^2 + -0.088 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 81/1000 --- L(Train): 0.3352766 --- L(Val, RNN): 0.3208854 --- L(Val, SINDy): 0.3485561 --- Time: 2.00s; --- Convergence: 7.67e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.686 value_stay[t] + 0.314 reward + -0.018 harvest_duration + -0.19 value_stay^2 + -0.158 value_stay*reward + -0.277 value_stay*harvest_duration + 0.491 reward^2 + 0.319 reward*harvest_duration + -0.02 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 1.007 value_exit[t] + -0.014 travel_duration + 0.037 value_exit^2 + -0.091 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 82/1000 --- L(Train): 0.3329794 --- L(Val, RNN): 0.3205969 --- L(Val, SINDy): 0.3481927 --- Time: 3.66s; --- Convergence: 5.28e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.679 value_stay[t] + 0.312 reward + -0.024 harvest_duration + -0.189 value_stay^2 + -0.158 value_stay*reward + -0.281 value_stay*harvest_duration + 0.492 reward^2 + 0.316 reward*harvest_duration + -0.026 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.01 value_exit[t] + -0.018 travel_duration + 0.036 value_exit^2 + -0.088 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 83/1000 --- L(Train): 0.3393174 --- L(Val, RNN): 0.3201086 --- L(Val, SINDy): 0.3479555 --- Time: 2.93s; --- Convergence: 5.08e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.034 1 + 0.671 value_stay[t] + 0.308 reward + -0.032 harvest_duration + -0.189 value_stay^2 + -0.159 value_stay*reward + -0.287 value_stay*harvest_duration + 0.492 reward^2 + 0.312 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 1.007 value_exit[t] + -0.016 travel_duration + 0.037 value_exit^2 + -0.091 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 84/1000 --- L(Train): 0.3390567 --- L(Val, RNN): 0.3196678 --- L(Val, SINDy): 0.3459640 --- Time: 4.26s; --- Convergence: 4.74e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.029 1 + 0.663 value_stay[t] + 0.306 reward + -0.039 harvest_duration + -0.187 value_stay^2 + -0.159 value_stay*reward + -0.292 value_stay*harvest_duration + 0.494 reward^2 + 0.31 reward*harvest_duration + -0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 1.006 value_exit[t] + -0.015 travel_duration + 0.037 value_exit^2 + -0.093 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 85/1000 --- L(Train): 0.3421928 --- L(Val, RNN): 0.3199960 --- L(Val, SINDy): 0.3454741 --- Time: 2.63s; --- Convergence: 4.01e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.024 1 + 0.656 value_stay[t] + 0.304 reward + -0.044 harvest_duration + -0.184 value_stay^2 + -0.157 value_stay*reward + -0.296 value_stay*harvest_duration + 0.498 reward^2 + 0.309 reward*harvest_duration + -0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.007 value_exit[t] + -0.016 travel_duration + 0.037 value_exit^2 + -0.092 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 86/1000 --- L(Train): 0.3487736 --- L(Val, RNN): 0.3195281 --- L(Val, SINDy): 0.3464850 --- Time: 2.48s; --- Convergence: 4.35e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.02 1 + 0.649 value_stay[t] + 0.303 reward + -0.049 harvest_duration + -0.181 value_stay^2 + -0.156 value_stay*reward + -0.301 value_stay*harvest_duration + 0.501 reward^2 + 0.308 reward*harvest_duration + -0.051 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.008 value_exit[t] + -0.017 travel_duration + 0.037 value_exit^2 + -0.091 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 87/1000 --- L(Train): 0.3400750 --- L(Val, RNN): 0.3196983 --- L(Val, SINDy): 0.3495249 --- Time: 2.54s; --- Convergence: 3.02e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.017 1 + 0.642 value_stay[t] + 0.303 reward + -0.053 harvest_duration + -0.179 value_stay^2 + -0.155 value_stay*reward + -0.305 value_stay*harvest_duration + 0.505 reward^2 + 0.307 reward*harvest_duration + -0.055 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.007 value_exit[t] + -0.016 travel_duration + 0.037 value_exit^2 + -0.093 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 88/1000 --- L(Train): 0.3444048 --- L(Val, RNN): 0.3201163 --- L(Val, SINDy): 0.3482822 --- Time: 2.18s; --- Convergence: 3.60e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.018 1 + 0.637 value_stay[t] + 0.305 reward + -0.053 harvest_duration + -0.173 value_stay^2 + -0.152 value_stay*reward + -0.307 value_stay*harvest_duration + 0.512 reward^2 + 0.31 reward*harvest_duration + -0.055 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.007 value_exit[t] + -0.015 travel_duration + 0.037 value_exit^2 + -0.095 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 89/1000 --- L(Train): 0.3427295 --- L(Val, RNN): 0.3194780 --- L(Val, SINDy): 0.3461807 --- Time: 2.28s; --- Convergence: 4.99e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.021 1 + 0.635 value_stay[t] + 0.31 reward + -0.052 harvest_duration + -0.165 value_stay^2 + -0.146 value_stay*reward + -0.307 value_stay*harvest_duration + 0.52 reward^2 + 0.314 reward*harvest_duration + -0.054 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.008 value_exit[t] + -0.016 travel_duration + 0.037 value_exit^2 + -0.095 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 90/1000 --- L(Train): 0.3470559 --- L(Val, RNN): 0.3198629 --- L(Val, SINDy): 0.3443653 --- Time: 2.61s; --- Convergence: 4.42e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.024 1 + 0.631 value_stay[t] + 0.314 reward + -0.05 harvest_duration + -0.159 value_stay^2 + -0.142 value_stay*reward + -0.307 value_stay*harvest_duration + 0.528 reward^2 + 0.318 reward*harvest_duration + -0.052 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.01 value_exit[t] + -0.018 travel_duration + 0.036 value_exit^2 + -0.094 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 91/1000 --- L(Train): 0.3406839 --- L(Val, RNN): 0.3208330 --- L(Val, SINDy): 0.3436926 --- Time: 2.41s; --- Convergence: 7.06e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.026 1 + 0.627 value_stay[t] + 0.315 reward + -0.049 harvest_duration + -0.154 value_stay^2 + -0.14 value_stay*reward + -0.309 value_stay*harvest_duration + 0.534 reward^2 + 0.32 reward*harvest_duration + -0.051 harvest_duration^2 \n",
      "value_exit[t+1] = -0.092 1 + 1.011 value_exit[t] + -0.017 travel_duration + 0.036 value_exit^2 + -0.094 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 92/1000 --- L(Train): 0.3457157 --- L(Val, RNN): 0.3194764 --- L(Val, SINDy): 0.3432645 --- Time: 3.19s; --- Convergence: 1.03e-03; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.027 1 + 0.622 value_stay[t] + 0.317 reward + -0.049 harvest_duration + -0.15 value_stay^2 + -0.138 value_stay*reward + -0.311 value_stay*harvest_duration + 0.539 reward^2 + 0.321 reward*harvest_duration + -0.051 harvest_duration^2 \n",
      "value_exit[t+1] = -0.092 1 + 1.011 value_exit[t] + -0.016 travel_duration + 0.036 value_exit^2 + -0.096 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 93/1000 --- L(Train): 0.3494869 --- L(Val, RNN): 0.3189677 --- L(Val, SINDy): 0.3427914 --- Time: 1.85s; --- Convergence: 7.70e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.029 1 + 0.619 value_stay[t] + 0.319 reward + -0.048 harvest_duration + -0.146 value_stay^2 + -0.136 value_stay*reward + -0.313 value_stay*harvest_duration + 0.545 reward^2 + 0.323 reward*harvest_duration + -0.05 harvest_duration^2 \n",
      "value_exit[t+1] = -0.093 1 + 1.012 value_exit[t] + -0.016 travel_duration + 0.035 value_exit^2 + -0.096 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 94/1000 --- L(Train): 0.3455680 --- L(Val, RNN): 0.3187747 --- L(Val, SINDy): 0.3438128 --- Time: 2.07s; --- Convergence: 4.82e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.031 1 + 0.614 value_stay[t] + 0.32 reward + -0.047 harvest_duration + -0.142 value_stay^2 + -0.134 value_stay*reward + -0.315 value_stay*harvest_duration + 0.55 reward^2 + 0.324 reward*harvest_duration + -0.049 harvest_duration^2 \n",
      "value_exit[t+1] = -0.096 1 + 1.014 value_exit[t] + -0.017 travel_duration + 0.035 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 95/1000 --- L(Train): 0.3483471 --- L(Val, RNN): 0.3199693 --- L(Val, SINDy): 0.3424125 --- Time: 1.24s; --- Convergence: 8.38e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.032 1 + 0.609 value_stay[t] + 0.32 reward + -0.047 harvest_duration + -0.138 value_stay^2 + -0.133 value_stay*reward + -0.318 value_stay*harvest_duration + 0.554 reward^2 + 0.324 reward*harvest_duration + -0.049 harvest_duration^2 \n",
      "value_exit[t+1] = -0.097 1 + 1.015 value_exit[t] + -0.017 travel_duration + 0.034 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 96/1000 --- L(Train): 0.3507940 --- L(Val, RNN): 0.3188273 --- L(Val, SINDy): 0.3409331 --- Time: 1.05s; --- Convergence: 9.90e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.034 1 + 0.605 value_stay[t] + 0.321 reward + -0.046 harvest_duration + -0.133 value_stay^2 + -0.131 value_stay*reward + -0.32 value_stay*harvest_duration + 0.558 reward^2 + 0.325 reward*harvest_duration + -0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.098 1 + 1.016 value_exit[t] + -0.016 travel_duration + 0.034 value_exit^2 + -0.097 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 97/1000 --- L(Train): 0.3424662 --- L(Val, RNN): 0.3183057 --- L(Val, SINDy): 0.3427114 --- Time: 0.85s; --- Convergence: 7.56e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.604 value_stay[t] + 0.324 reward + -0.043 harvest_duration + -0.125 value_stay^2 + -0.125 value_stay*reward + -0.318 value_stay*harvest_duration + 0.565 reward^2 + 0.328 reward*harvest_duration + -0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.1 1 + 1.017 value_exit[t] + -0.016 travel_duration + 0.034 value_exit^2 + -0.097 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 98/1000 --- L(Train): 0.3504297 --- L(Val, RNN): 0.3183243 --- L(Val, SINDy): 0.3423878 --- Time: 1.03s; --- Convergence: 3.87e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.604 value_stay[t] + 0.327 reward + -0.04 harvest_duration + -0.116 value_stay^2 + -0.119 value_stay*reward + -0.315 value_stay*harvest_duration + 0.572 reward^2 + 0.331 reward*harvest_duration + -0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.101 1 + 1.018 value_exit[t] + -0.017 travel_duration + 0.033 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 99/1000 --- L(Train): 0.3496413 --- L(Val, RNN): 0.3183845 --- L(Val, SINDy): 0.3417611 --- Time: 1.16s; --- Convergence: 2.24e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.606 value_stay[t] + 0.331 reward + -0.036 harvest_duration + -0.106 value_stay^2 + -0.112 value_stay*reward + -0.312 value_stay*harvest_duration + 0.58 reward^2 + 0.335 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.102 1 + 1.019 value_exit[t] + -0.017 travel_duration + 0.033 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 100/1000 --- L(Train): 0.3490184 --- L(Val, RNN): 0.3190697 --- L(Val, SINDy): 0.3418972 --- Time: 1.02s; --- Convergence: 4.54e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.051 1 + 0.607 value_stay[t] + 0.334 reward + -0.033 harvest_duration + -0.095 value_stay^2 + -0.104 value_stay*reward + -0.308 value_stay*harvest_duration + 0.587 reward^2 + 0.338 reward*harvest_duration + -0.035 harvest_duration^2 \n",
      "value_exit[t+1] = -0.102 1 + 1.019 value_exit[t] + -0.016 travel_duration + 0.033 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 101/1000 --- L(Train): 0.3504912 --- L(Val, RNN): 0.3184176 --- L(Val, SINDy): 0.3434471 --- Time: 0.92s; --- Convergence: 5.53e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.054 1 + 0.608 value_stay[t] + 0.336 reward + -0.032 harvest_duration + -0.086 value_stay^2 + -0.097 value_stay*reward + -0.305 value_stay*harvest_duration + 0.593 reward^2 + 0.34 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.102 1 + 1.019 value_exit[t] + -0.016 travel_duration + 0.033 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 102/1000 --- L(Train): 0.3507538 --- L(Val, RNN): 0.3177734 --- L(Val, SINDy): 0.3441548 --- Time: 1.22s; --- Convergence: 5.99e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.054 1 + 0.606 value_stay[t] + 0.335 reward + -0.032 harvest_duration + -0.079 value_stay^2 + -0.093 value_stay*reward + -0.305 value_stay*harvest_duration + 0.597 reward^2 + 0.339 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.102 1 + 1.019 value_exit[t] + -0.016 travel_duration + 0.033 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 103/1000 --- L(Train): 0.3520292 --- L(Val, RNN): 0.3182232 --- L(Val, SINDy): 0.3420197 --- Time: 1.17s; --- Convergence: 5.24e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.051 1 + 0.601 value_stay[t] + 0.331 reward + -0.036 harvest_duration + -0.075 value_stay^2 + -0.092 value_stay*reward + -0.308 value_stay*harvest_duration + 0.597 reward^2 + 0.336 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.102 1 + 1.019 value_exit[t] + -0.017 travel_duration + 0.033 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 104/1000 --- L(Train): 0.3564698 --- L(Val, RNN): 0.3190125 --- L(Val, SINDy): 0.3394367 --- Time: 0.93s; --- Convergence: 6.57e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.597 value_stay[t] + 0.328 reward + -0.04 harvest_duration + -0.069 value_stay^2 + -0.089 value_stay*reward + -0.31 value_stay*harvest_duration + 0.598 reward^2 + 0.332 reward*harvest_duration + -0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.1 1 + 1.017 value_exit[t] + -0.015 travel_duration + 0.034 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 105/1000 --- L(Train): 0.3507742 --- L(Val, RNN): 0.3181209 --- L(Val, SINDy): 0.3386493 --- Time: 1.04s; --- Convergence: 7.74e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.596 value_stay[t] + 0.327 reward + -0.041 harvest_duration + -0.06 value_stay^2 + -0.083 value_stay*reward + -0.309 value_stay*harvest_duration + 0.602 reward^2 + 0.331 reward*harvest_duration + -0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.099 1 + 1.016 value_exit[t] + -0.016 travel_duration + 0.034 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 106/1000 --- L(Train): 0.3468998 --- L(Val, RNN): 0.3183652 --- L(Val, SINDy): 0.3416104 --- Time: 1.15s; --- Convergence: 5.09e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.052 1 + 0.599 value_stay[t] + 0.329 reward + -0.039 harvest_duration + -0.048 value_stay^2 + -0.074 value_stay*reward + -0.303 value_stay*harvest_duration + 0.609 reward^2 + 0.334 reward*harvest_duration + -0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.1 1 + 1.017 value_exit[t] + -0.018 travel_duration + 0.034 value_exit^2 + -0.096 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 107/1000 --- L(Train): 0.3521019 --- L(Val, RNN): 0.3184474 --- L(Val, SINDy): 0.3424486 --- Time: 1.81s; --- Convergence: 2.96e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.056 1 + 0.603 value_stay[t] + 0.333 reward + -0.037 harvest_duration + -0.036 value_stay^2 + -0.063 value_stay*reward + -0.297 value_stay*harvest_duration + 0.617 reward^2 + 0.337 reward*harvest_duration + -0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.093 1 + 1.01 value_exit[t] + -0.013 travel_duration + 0.036 value_exit^2 + -0.101 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 108/1000 --- L(Train): 0.3484773 --- L(Val, RNN): 0.3188996 --- L(Val, SINDy): 0.3421502 --- Time: 1.72s; --- Convergence: 3.74e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.058 1 + 0.604 value_stay[t] + 0.335 reward + -0.036 harvest_duration + -0.026 value_stay^2 + -0.053 value_stay*reward + -0.293 value_stay*harvest_duration + 0.623 reward^2 + 0.339 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.093 1 + 1.01 value_exit[t] + -0.014 travel_duration + 0.036 value_exit^2 + -0.1 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 109/1000 --- L(Train): 0.3570294 --- L(Val, RNN): 0.3181408 --- L(Val, SINDy): 0.3392879 --- Time: 1.30s; --- Convergence: 5.66e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.057 1 + 0.6 value_stay[t] + 0.334 reward + -0.039 harvest_duration + -0.02 value_stay^2 + -0.047 value_stay*reward + -0.294 value_stay*harvest_duration + 0.626 reward^2 + 0.338 reward*harvest_duration + -0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.098 1 + 1.015 value_exit[t] + -0.021 travel_duration + 0.034 value_exit^2 + -0.093 value_exit*travel_duration + -0.02 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 110/1000 --- L(Train): 0.3545318 --- L(Val, RNN): 0.3178687 --- L(Val, SINDy): 0.3407318 --- Time: 1.09s; --- Convergence: 4.19e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.053 1 + 0.592 value_stay[t] + 0.329 reward + -0.045 harvest_duration + -0.019 value_stay^2 + -0.046 value_stay*reward + -0.299 value_stay*harvest_duration + 0.627 reward^2 + 0.333 reward*harvest_duration + -0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.094 1 + 1.011 value_exit[t] + -0.018 travel_duration + 0.037 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 111/1000 --- L(Train): 0.3512340 --- L(Val, RNN): 0.3181413 --- L(Val, SINDy): 0.3422728 --- Time: 0.79s; --- Convergence: 3.46e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.05 1 + 0.584 value_stay[t] + 0.324 reward + -0.05 harvest_duration + -0.018 value_stay^2 + -0.044 value_stay*reward + -0.304 value_stay*harvest_duration + 0.627 reward^2 + 0.329 reward*harvest_duration + -0.052 harvest_duration^2 \n",
      "value_exit[t+1] = -0.09 1 + 1.006 value_exit[t] + -0.014 travel_duration + 0.039 value_exit^2 + -0.1 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 112/1000 --- L(Train): 0.3534231 --- L(Val, RNN): 0.3186450 --- L(Val, SINDy): 0.3405035 --- Time: 1.00s; --- Convergence: 4.25e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.051 1 + 0.581 value_stay[t] + 0.324 reward + -0.05 harvest_duration + -0.013 value_stay^2 + -0.039 value_stay*reward + -0.305 value_stay*harvest_duration + 0.631 reward^2 + 0.328 reward*harvest_duration + -0.052 harvest_duration^2 \n",
      "value_exit[t+1] = -0.092 1 + 1.008 value_exit[t] + -0.016 travel_duration + 0.038 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 113/1000 --- L(Train): 0.3610145 --- L(Val, RNN): 0.3182284 --- L(Val, SINDy): 0.3394031 --- Time: 1.05s; --- Convergence: 4.21e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.057 1 + 0.582 value_stay[t] + 0.329 reward + -0.046 harvest_duration + -0.003 value_stay^2 + -0.03 value_stay*reward + -0.301 value_stay*harvest_duration + 0.639 reward^2 + 0.333 reward*harvest_duration + -0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.094 1 + 1.01 value_exit[t] + -0.019 travel_duration + 0.037 value_exit^2 + -0.095 value_exit*travel_duration + -0.018 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 114/1000 --- L(Train): 0.3556114 --- L(Val, RNN): 0.3178515 --- L(Val, SINDy): 0.3387427 --- Time: 0.91s; --- Convergence: 3.99e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.063 1 + 0.581 value_stay[t] + 0.332 reward + -0.042 harvest_duration + 0.005 value_stay^2 + -0.022 value_stay*reward + -0.299 value_stay*harvest_duration + 0.647 reward^2 + 0.336 reward*harvest_duration + -0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.007 value_exit[t] + -0.017 travel_duration + 0.039 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 115/1000 --- L(Train): 0.3580656 --- L(Val, RNN): 0.3178938 --- L(Val, SINDy): 0.3391317 --- Time: 1.11s; --- Convergence: 2.21e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.066 1 + 0.577 value_stay[t] + 0.332 reward + -0.041 harvest_duration + 0.01 value_stay^2 + -0.017 value_stay*reward + -0.299 value_stay*harvest_duration + 0.652 reward^2 + 0.337 reward*harvest_duration + -0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.005 value_exit[t] + -0.014 travel_duration + 0.041 value_exit^2 + -0.1 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 116/1000 --- L(Train): 0.3500769 --- L(Val, RNN): 0.3184628 --- L(Val, SINDy): 0.3385895 --- Time: 1.26s; --- Convergence: 3.95e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.066 1 + 0.571 value_stay[t] + 0.329 reward + -0.043 harvest_duration + 0.011 value_stay^2 + -0.016 value_stay*reward + -0.303 value_stay*harvest_duration + 0.653 reward^2 + 0.333 reward*harvest_duration + -0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.005 value_exit[t] + -0.015 travel_duration + 0.041 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 117/1000 --- L(Train): 0.3564915 --- L(Val, RNN): 0.3185722 --- L(Val, SINDy): 0.3379352 --- Time: 1.14s; --- Convergence: 2.52e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.065 1 + 0.563 value_stay[t] + 0.325 reward + -0.046 harvest_duration + 0.012 value_stay^2 + -0.016 value_stay*reward + -0.309 value_stay*harvest_duration + 0.653 reward^2 + 0.329 reward*harvest_duration + -0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.007 value_exit[t] + -0.018 travel_duration + 0.039 value_exit^2 + -0.096 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 118/1000 --- L(Train): 0.3624997 --- L(Val, RNN): 0.3182514 --- L(Val, SINDy): 0.3376493 --- Time: 0.84s; --- Convergence: 2.86e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.065 1 + 0.557 value_stay[t] + 0.321 reward + -0.048 harvest_duration + 0.013 value_stay^2 + -0.015 value_stay*reward + -0.313 value_stay*harvest_duration + 0.654 reward^2 + 0.325 reward*harvest_duration + -0.05 harvest_duration^2 \n",
      "value_exit[t+1] = -0.092 1 + 1.008 value_exit[t] + -0.018 travel_duration + 0.039 value_exit^2 + -0.096 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 119/1000 --- L(Train): 0.3559091 --- L(Val, RNN): 0.3180479 --- L(Val, SINDy): 0.3374208 --- Time: 0.93s; --- Convergence: 2.45e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.067 1 + 0.551 value_stay[t] + 0.319 reward + -0.048 harvest_duration + 0.016 value_stay^2 + -0.013 value_stay*reward + -0.316 value_stay*harvest_duration + 0.656 reward^2 + 0.323 reward*harvest_duration + -0.05 harvest_duration^2 \n",
      "value_exit[t+1] = -0.09 1 + 1.006 value_exit[t] + -0.017 travel_duration + 0.04 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 120/1000 --- L(Train): 0.3552007 --- L(Val, RNN): 0.3182454 --- L(Val, SINDy): 0.3377611 --- Time: 1.29s; --- Convergence: 2.21e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.07 1 + 0.548 value_stay[t] + 0.319 reward + -0.047 harvest_duration + 0.02 value_stay^2 + -0.009 value_stay*reward + -0.318 value_stay*harvest_duration + 0.66 reward^2 + 0.323 reward*harvest_duration + -0.049 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.005 value_exit[t] + -0.015 travel_duration + 0.041 value_exit^2 + -0.098 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 121/1000 --- L(Train): 0.3587048 --- L(Val, RNN): 0.3185634 --- L(Val, SINDy): 0.3392268 --- Time: 1.24s; --- Convergence: 2.70e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.073 1 + 0.546 value_stay[t] + 0.319 reward + -0.045 harvest_duration + 0.026 value_stay^2 + -0.004 value_stay*reward + -0.318 value_stay*harvest_duration + 0.664 reward^2 + 0.323 reward*harvest_duration + -0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.004 value_exit[t] + -0.015 travel_duration + 0.042 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 122/1000 --- L(Train): 0.3668035 --- L(Val, RNN): 0.3187285 --- L(Val, SINDy): 0.3379600 --- Time: 0.93s; --- Convergence: 2.17e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.077 1 + 0.544 value_stay[t] + 0.32 reward + -0.043 harvest_duration + 0.031 value_stay^2 + 0.0 value_stay*reward + -0.318 value_stay*harvest_duration + 0.668 reward^2 + 0.324 reward*harvest_duration + -0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.004 value_exit[t] + -0.015 travel_duration + 0.042 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 123/1000 --- L(Train): 0.3620897 --- L(Val, RNN): 0.3187662 --- L(Val, SINDy): 0.3382119 --- Time: 1.11s; --- Convergence: 1.28e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.08 1 + 0.542 value_stay[t] + 0.319 reward + -0.042 harvest_duration + 0.035 value_stay^2 + 0.004 value_stay*reward + -0.319 value_stay*harvest_duration + 0.671 reward^2 + 0.323 reward*harvest_duration + -0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.006 value_exit[t] + -0.016 travel_duration + 0.041 value_exit^2 + -0.097 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 124/1000 --- L(Train): 0.3604553 --- L(Val, RNN): 0.3189983 --- L(Val, SINDy): 0.3383479 --- Time: 1.32s; --- Convergence: 1.80e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.08 1 + 0.537 value_stay[t] + 0.316 reward + -0.043 harvest_duration + 0.036 value_stay^2 + 0.004 value_stay*reward + -0.322 value_stay*harvest_duration + 0.672 reward^2 + 0.32 reward*harvest_duration + -0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.007 value_exit[t] + -0.018 travel_duration + 0.04 value_exit^2 + -0.096 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 125/1000 --- L(Train): 0.3586362 --- L(Val, RNN): 0.3192618 --- L(Val, SINDy): 0.3371812 --- Time: 0.86s; --- Convergence: 2.22e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.08 1 + 0.531 value_stay[t] + 0.312 reward + -0.045 harvest_duration + 0.037 value_stay^2 + 0.005 value_stay*reward + -0.326 value_stay*harvest_duration + 0.672 reward^2 + 0.317 reward*harvest_duration + -0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.007 value_exit[t] + -0.018 travel_duration + 0.04 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 126/1000 --- L(Train): 0.3613584 --- L(Val, RNN): 0.3192604 --- L(Val, SINDy): 0.3376358 --- Time: 1.09s; --- Convergence: 1.12e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.081 1 + 0.526 value_stay[t] + 0.31 reward + -0.046 harvest_duration + 0.039 value_stay^2 + 0.006 value_stay*reward + -0.329 value_stay*harvest_duration + 0.673 reward^2 + 0.314 reward*harvest_duration + -0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.005 value_exit[t] + -0.016 travel_duration + 0.041 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 127/1000 --- L(Train): 0.3645270 --- L(Val, RNN): 0.3196726 --- L(Val, SINDy): 0.3398442 --- Time: 1.13s; --- Convergence: 2.62e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.082 1 + 0.523 value_stay[t] + 0.308 reward + -0.046 harvest_duration + 0.041 value_stay^2 + 0.008 value_stay*reward + -0.332 value_stay*harvest_duration + 0.675 reward^2 + 0.312 reward*harvest_duration + -0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.004 value_exit[t] + -0.014 travel_duration + 0.042 value_exit^2 + -0.099 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 128/1000 --- L(Train): 0.3657410 --- L(Val, RNN): 0.3202441 --- L(Val, SINDy): 0.3401618 --- Time: 0.90s; --- Convergence: 4.17e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.083 1 + 0.519 value_stay[t] + 0.306 reward + -0.045 harvest_duration + 0.044 value_stay^2 + 0.011 value_stay*reward + -0.333 value_stay*harvest_duration + 0.677 reward^2 + 0.311 reward*harvest_duration + -0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.004 value_exit[t] + -0.015 travel_duration + 0.042 value_exit^2 + -0.099 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 129/1000 --- L(Train): 0.3619585 --- L(Val, RNN): 0.3202040 --- L(Val, SINDy): 0.3411242 --- Time: 0.93s; --- Convergence: 2.28e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.086 1 + 0.517 value_stay[t] + 0.306 reward + -0.044 harvest_duration + 0.048 value_stay^2 + 0.015 value_stay*reward + -0.333 value_stay*harvest_duration + 0.68 reward^2 + 0.31 reward*harvest_duration + -0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.007 value_exit[t] + -0.017 travel_duration + 0.04 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 130/1000 --- L(Train): 0.3605959 --- L(Val, RNN): 0.3202021 --- L(Val, SINDy): 0.3404817 --- Time: 0.86s; --- Convergence: 1.15e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.089 1 + 0.515 value_stay[t] + 0.306 reward + -0.042 harvest_duration + 0.051 value_stay^2 + 0.019 value_stay*reward + -0.334 value_stay*harvest_duration + 0.683 reward^2 + 0.31 reward*harvest_duration + -0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.092 1 + 1.008 value_exit[t] + -0.019 travel_duration + 0.039 value_exit^2 + -0.095 value_exit*travel_duration + -0.018 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 131/1000 --- L(Train): 0.3557698 --- L(Val, RNN): 0.3204004 --- L(Val, SINDy): 0.3389804 --- Time: 0.81s; --- Convergence: 1.57e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.091 1 + 0.512 value_stay[t] + 0.304 reward + -0.041 harvest_duration + 0.055 value_stay^2 + 0.022 value_stay*reward + -0.335 value_stay*harvest_duration + 0.686 reward^2 + 0.309 reward*harvest_duration + -0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.007 value_exit[t] + -0.018 travel_duration + 0.039 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 132/1000 --- L(Train): 0.3705032 --- L(Val, RNN): 0.3205675 --- L(Val, SINDy): 0.3382632 --- Time: 0.99s; --- Convergence: 1.62e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.093 1 + 0.51 value_stay[t] + 0.303 reward + -0.04 harvest_duration + 0.058 value_stay^2 + 0.025 value_stay*reward + -0.335 value_stay*harvest_duration + 0.688 reward^2 + 0.308 reward*harvest_duration + -0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.006 value_exit[t] + -0.016 travel_duration + 0.041 value_exit^2 + -0.097 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 133/1000 --- L(Train): 0.3702162 --- L(Val, RNN): 0.3208049 --- L(Val, SINDy): 0.3364748 --- Time: 1.03s; --- Convergence: 2.00e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.095 1 + 0.508 value_stay[t] + 0.302 reward + -0.04 harvest_duration + 0.061 value_stay^2 + 0.028 value_stay*reward + -0.336 value_stay*harvest_duration + 0.69 reward^2 + 0.306 reward*harvest_duration + -0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.005 value_exit[t] + -0.015 travel_duration + 0.041 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 134/1000 --- L(Train): 0.3584071 --- L(Val, RNN): 0.3207325 --- L(Val, SINDy): 0.3359192 --- Time: 0.91s; --- Convergence: 1.36e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.097 1 + 0.506 value_stay[t] + 0.3 reward + -0.039 harvest_duration + 0.064 value_stay^2 + 0.03 value_stay*reward + -0.337 value_stay*harvest_duration + 0.691 reward^2 + 0.304 reward*harvest_duration + -0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.005 value_exit[t] + -0.015 travel_duration + 0.041 value_exit^2 + -0.098 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 135/1000 --- L(Train): 0.3589655 --- L(Val, RNN): 0.3210141 --- L(Val, SINDy): 0.3367481 --- Time: 1.05s; --- Convergence: 2.09e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.098 1 + 0.503 value_stay[t] + 0.297 reward + -0.04 harvest_duration + 0.067 value_stay^2 + 0.033 value_stay*reward + -0.338 value_stay*harvest_duration + 0.692 reward^2 + 0.302 reward*harvest_duration + -0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.006 value_exit[t] + -0.016 travel_duration + 0.041 value_exit^2 + -0.097 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 136/1000 --- L(Train): 0.3773002 --- L(Val, RNN): 0.3214541 --- L(Val, SINDy): 0.3381172 --- Time: 1.06s; --- Convergence: 3.24e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.1 1 + 0.501 value_stay[t] + 0.295 reward + -0.039 harvest_duration + 0.07 value_stay^2 + 0.035 value_stay*reward + -0.339 value_stay*harvest_duration + 0.693 reward^2 + 0.299 reward*harvest_duration + -0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.09 1 + 1.007 value_exit[t] + -0.017 travel_duration + 0.04 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 137/1000 --- L(Train): 0.3679981 --- L(Val, RNN): 0.3217641 --- L(Val, SINDy): 0.3395804 --- Time: 0.92s; --- Convergence: 3.17e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.101 1 + 0.499 value_stay[t] + 0.294 reward + -0.039 harvest_duration + 0.072 value_stay^2 + 0.038 value_stay*reward + -0.34 value_stay*harvest_duration + 0.695 reward^2 + 0.298 reward*harvest_duration + -0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.007 value_exit[t] + -0.018 travel_duration + 0.04 value_exit^2 + -0.096 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 138/1000 --- L(Train): 0.3678401 --- L(Val, RNN): 0.3216742 --- L(Val, SINDy): 0.3400463 --- Time: 1.26s; --- Convergence: 2.04e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.103 1 + 0.498 value_stay[t] + 0.292 reward + -0.038 harvest_duration + 0.075 value_stay^2 + 0.04 value_stay*reward + -0.34 value_stay*harvest_duration + 0.697 reward^2 + 0.297 reward*harvest_duration + -0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.007 value_exit[t] + -0.018 travel_duration + 0.04 value_exit^2 + -0.096 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 139/1000 --- L(Train): 0.3676948 --- L(Val, RNN): 0.3214630 --- L(Val, SINDy): 0.3422829 --- Time: 0.93s; --- Convergence: 2.07e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.107 1 + 0.499 value_stay[t] + 0.293 reward + -0.036 harvest_duration + 0.08 value_stay^2 + 0.045 value_stay*reward + -0.339 value_stay*harvest_duration + 0.699 reward^2 + 0.297 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.005 value_exit[t] + -0.016 travel_duration + 0.041 value_exit^2 + -0.097 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 140/1000 --- L(Train): 0.3764676 --- L(Val, RNN): 0.3218382 --- L(Val, SINDy): 0.3409794 --- Time: 1.15s; --- Convergence: 2.91e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.11 1 + 0.5 value_stay[t] + 0.293 reward + -0.034 harvest_duration + 0.085 value_stay^2 + 0.049 value_stay*reward + -0.337 value_stay*harvest_duration + 0.702 reward^2 + 0.297 reward*harvest_duration + -0.036 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.004 value_exit[t] + -0.014 travel_duration + 0.042 value_exit^2 + -0.099 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 141/1000 --- L(Train): 0.3816854 --- L(Val, RNN): 0.3224647 --- L(Val, SINDy): 0.3385123 --- Time: 1.40s; --- Convergence: 4.59e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.114 1 + 0.501 value_stay[t] + 0.293 reward + -0.032 harvest_duration + 0.09 value_stay^2 + 0.053 value_stay*reward + -0.336 value_stay*harvest_duration + 0.705 reward^2 + 0.297 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.014 travel_duration + 0.042 value_exit^2 + -0.099 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 142/1000 --- L(Train): 0.3720662 --- L(Val, RNN): 0.3224407 --- L(Val, SINDy): 0.3375566 --- Time: 0.97s; --- Convergence: 2.41e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.116 1 + 0.501 value_stay[t] + 0.292 reward + -0.032 harvest_duration + 0.093 value_stay^2 + 0.056 value_stay*reward + -0.335 value_stay*harvest_duration + 0.706 reward^2 + 0.296 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.004 value_exit[t] + -0.015 travel_duration + 0.042 value_exit^2 + -0.098 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 143/1000 --- L(Train): 0.3794422 --- L(Val, RNN): 0.3222483 --- L(Val, SINDy): 0.3381962 --- Time: 0.99s; --- Convergence: 2.17e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.118 1 + 0.5 value_stay[t] + 0.289 reward + -0.032 harvest_duration + 0.096 value_stay^2 + 0.057 value_stay*reward + -0.336 value_stay*harvest_duration + 0.707 reward^2 + 0.293 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.006 value_exit[t] + -0.017 travel_duration + 0.041 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 144/1000 --- L(Train): 0.3851089 --- L(Val, RNN): 0.3225189 --- L(Val, SINDy): 0.3386226 --- Time: 1.15s; --- Convergence: 2.44e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.118 1 + 0.497 value_stay[t] + 0.286 reward + -0.034 harvest_duration + 0.096 value_stay^2 + 0.059 value_stay*reward + -0.338 value_stay*harvest_duration + 0.706 reward^2 + 0.29 reward*harvest_duration + -0.036 harvest_duration^2 \n",
      "value_exit[t+1] = -0.09 1 + 1.006 value_exit[t] + -0.018 travel_duration + 0.04 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 145/1000 --- L(Train): 0.3859713 --- L(Val, RNN): 0.3229151 --- L(Val, SINDy): 0.3385253 --- Time: 1.10s; --- Convergence: 3.20e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.118 1 + 0.494 value_stay[t] + 0.283 reward + -0.036 harvest_duration + 0.097 value_stay^2 + 0.059 value_stay*reward + -0.341 value_stay*harvest_duration + 0.706 reward^2 + 0.287 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.005 value_exit[t] + -0.017 travel_duration + 0.041 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 146/1000 --- L(Train): 0.3801723 --- L(Val, RNN): 0.3232304 --- L(Val, SINDy): 0.3396293 --- Time: 1.30s; --- Convergence: 3.18e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.119 1 + 0.493 value_stay[t] + 0.28 reward + -0.037 harvest_duration + 0.099 value_stay^2 + 0.061 value_stay*reward + -0.342 value_stay*harvest_duration + 0.706 reward^2 + 0.285 reward*harvest_duration + -0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.015 travel_duration + 0.042 value_exit^2 + -0.098 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 147/1000 --- L(Train): 0.3625561 --- L(Val, RNN): 0.3234298 --- L(Val, SINDy): 0.3399337 --- Time: 0.90s; --- Convergence: 2.59e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.121 1 + 0.492 value_stay[t] + 0.279 reward + -0.037 harvest_duration + 0.102 value_stay^2 + 0.063 value_stay*reward + -0.343 value_stay*harvest_duration + 0.707 reward^2 + 0.283 reward*harvest_duration + -0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.002 value_exit[t] + -0.014 travel_duration + 0.043 value_exit^2 + -0.099 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 148/1000 --- L(Train): 0.3800977 --- L(Val, RNN): 0.3235027 --- L(Val, SINDy): 0.3399130 --- Time: 1.21s; --- Convergence: 1.66e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.124 1 + 0.493 value_stay[t] + 0.278 reward + -0.037 harvest_duration + 0.106 value_stay^2 + 0.067 value_stay*reward + -0.342 value_stay*harvest_duration + 0.709 reward^2 + 0.282 reward*harvest_duration + -0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.003 value_exit[t] + -0.015 travel_duration + 0.043 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 149/1000 --- L(Train): 0.3868265 --- L(Val, RNN): 0.3235816 --- L(Val, SINDy): 0.3392246 --- Time: 0.93s; --- Convergence: 1.22e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.129 1 + 0.496 value_stay[t] + 0.279 reward + -0.034 harvest_duration + 0.112 value_stay^2 + 0.072 value_stay*reward + -0.34 value_stay*harvest_duration + 0.712 reward^2 + 0.283 reward*harvest_duration + -0.036 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.005 value_exit[t] + -0.017 travel_duration + 0.041 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 150/1000 --- L(Train): 0.3915248 --- L(Val, RNN): 0.3238239 --- L(Val, SINDy): 0.3383423 --- Time: 0.95s; --- Convergence: 1.82e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.133 1 + 0.498 value_stay[t] + 0.279 reward + -0.033 harvest_duration + 0.117 value_stay^2 + 0.077 value_stay*reward + -0.338 value_stay*harvest_duration + 0.715 reward^2 + 0.283 reward*harvest_duration + -0.035 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.005 value_exit[t] + -0.017 travel_duration + 0.041 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 151/1000 --- L(Train): 0.3771703 --- L(Val, RNN): 0.3239193 --- L(Val, SINDy): 0.3375174 --- Time: 0.98s; --- Convergence: 1.39e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.136 1 + 0.499 value_stay[t] + 0.277 reward + -0.032 harvest_duration + 0.12 value_stay^2 + 0.08 value_stay*reward + -0.338 value_stay*harvest_duration + 0.716 reward^2 + 0.282 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.016 travel_duration + 0.042 value_exit^2 + -0.097 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 152/1000 --- L(Train): 0.3857234 --- L(Val, RNN): 0.3241553 --- L(Val, SINDy): 0.3378377 --- Time: 0.92s; --- Convergence: 1.87e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.136 1 + 0.496 value_stay[t] + 0.274 reward + -0.035 harvest_duration + 0.121 value_stay^2 + 0.081 value_stay*reward + -0.341 value_stay*harvest_duration + 0.715 reward^2 + 0.278 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.002 value_exit[t] + -0.014 travel_duration + 0.044 value_exit^2 + -0.099 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 153/1000 --- L(Train): 0.3878178 --- L(Val, RNN): 0.3244281 --- L(Val, SINDy): 0.3390090 --- Time: 1.76s; --- Convergence: 2.30e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.136 1 + 0.493 value_stay[t] + 0.269 reward + -0.038 harvest_duration + 0.12 value_stay^2 + 0.081 value_stay*reward + -0.345 value_stay*harvest_duration + 0.714 reward^2 + 0.273 reward*harvest_duration + -0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.002 value_exit[t] + -0.015 travel_duration + 0.043 value_exit^2 + -0.098 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 154/1000 --- L(Train): 0.3906905 --- L(Val, RNN): 0.3247790 --- L(Val, SINDy): 0.3381380 --- Time: 2.35s; --- Convergence: 2.91e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.137 1 + 0.49 value_stay[t] + 0.266 reward + -0.04 harvest_duration + 0.121 value_stay^2 + 0.082 value_stay*reward + -0.348 value_stay*harvest_duration + 0.713 reward^2 + 0.27 reward*harvest_duration + -0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.016 travel_duration + 0.043 value_exit^2 + -0.097 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 155/1000 --- L(Train): 0.3895659 --- L(Val, RNN): 0.3249811 --- L(Val, SINDy): 0.3378260 --- Time: 3.64s; --- Convergence: 2.46e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.138 1 + 0.489 value_stay[t] + 0.263 reward + -0.042 harvest_duration + 0.122 value_stay^2 + 0.083 value_stay*reward + -0.35 value_stay*harvest_duration + 0.712 reward^2 + 0.267 reward*harvest_duration + -0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.004 value_exit[t] + -0.017 travel_duration + 0.042 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 156/1000 --- L(Train): 0.3780435 --- L(Val, RNN): 0.3250820 --- L(Val, SINDy): 0.3396377 --- Time: 5.51s; --- Convergence: 1.74e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.142 1 + 0.49 value_stay[t] + 0.262 reward + -0.041 harvest_duration + 0.125 value_stay^2 + 0.086 value_stay*reward + -0.35 value_stay*harvest_duration + 0.714 reward^2 + 0.266 reward*harvest_duration + -0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.017 travel_duration + 0.043 value_exit^2 + -0.097 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 157/1000 --- L(Train): 0.3843363 --- L(Val, RNN): 0.3252389 --- L(Val, SINDy): 0.3434076 --- Time: 3.79s; --- Convergence: 1.65e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.148 1 + 0.493 value_stay[t] + 0.263 reward + -0.037 harvest_duration + 0.13 value_stay^2 + 0.091 value_stay*reward + -0.347 value_stay*harvest_duration + 0.718 reward^2 + 0.268 reward*harvest_duration + -0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 1.001 value_exit[t] + -0.015 travel_duration + 0.044 value_exit^2 + -0.099 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 158/1000 --- L(Train): 0.3957593 --- L(Val, RNN): 0.3254926 --- L(Val, SINDy): 0.3415511 --- Time: 3.11s; --- Convergence: 2.09e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.153 1 + 0.496 value_stay[t] + 0.265 reward + -0.034 harvest_duration + 0.135 value_stay^2 + 0.096 value_stay*reward + -0.344 value_stay*harvest_duration + 0.721 reward^2 + 0.269 reward*harvest_duration + -0.036 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 1.0 value_exit[t] + -0.014 travel_duration + 0.045 value_exit^2 + -0.1 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 159/1000 --- L(Train): 0.3976619 --- L(Val, RNN): 0.3258745 --- L(Val, SINDy): 0.3398752 --- Time: 3.68s; --- Convergence: 2.96e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.159 1 + 0.499 value_stay[t] + 0.265 reward + -0.032 harvest_duration + 0.14 value_stay^2 + 0.1 value_stay*reward + -0.343 value_stay*harvest_duration + 0.724 reward^2 + 0.27 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 1.0 value_exit[t] + -0.014 travel_duration + 0.045 value_exit^2 + -0.1 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 160/1000 --- L(Train): 0.3910590 --- L(Val, RNN): 0.3260571 --- L(Val, SINDy): 0.3400107 --- Time: 6.47s; --- Convergence: 2.39e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.161 1 + 0.499 value_stay[t] + 0.264 reward + -0.031 harvest_duration + 0.142 value_stay^2 + 0.102 value_stay*reward + -0.343 value_stay*harvest_duration + 0.725 reward^2 + 0.268 reward*harvest_duration + -0.033 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.002 value_exit[t] + -0.016 travel_duration + 0.044 value_exit^2 + -0.098 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 161/1000 --- L(Train): 0.3898806 --- L(Val, RNN): 0.3260823 --- L(Val, SINDy): 0.3412288 --- Time: 5.19s; --- Convergence: 1.32e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.162 1 + 0.497 value_stay[t] + 0.261 reward + -0.032 harvest_duration + 0.141 value_stay^2 + 0.102 value_stay*reward + -0.346 value_stay*harvest_duration + 0.724 reward^2 + 0.265 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.017 travel_duration + 0.043 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 162/1000 --- L(Train): 0.4051255 --- L(Val, RNN): 0.3263068 --- L(Val, SINDy): 0.3408326 --- Time: 3.70s; --- Convergence: 1.78e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.161 1 + 0.493 value_stay[t] + 0.257 reward + -0.035 harvest_duration + 0.139 value_stay^2 + 0.1 value_stay*reward + -0.35 value_stay*harvest_duration + 0.721 reward^2 + 0.261 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.018 travel_duration + 0.042 value_exit^2 + -0.096 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 163/1000 --- L(Train): 0.3977874 --- L(Val, RNN): 0.3267061 --- L(Val, SINDy): 0.3388878 --- Time: 2.56s; --- Convergence: 2.89e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.159 1 + 0.487 value_stay[t] + 0.251 reward + -0.039 harvest_duration + 0.136 value_stay^2 + 0.097 value_stay*reward + -0.356 value_stay*harvest_duration + 0.718 reward^2 + 0.255 reward*harvest_duration + -0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 1.0 value_exit[t] + -0.015 travel_duration + 0.045 value_exit^2 + -0.099 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 164/1000 --- L(Train): 0.3998370 --- L(Val, RNN): 0.3270072 --- L(Val, SINDy): 0.3385317 --- Time: 2.90s; --- Convergence: 2.95e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.158 1 + 0.483 value_stay[t] + 0.246 reward + -0.042 harvest_duration + 0.134 value_stay^2 + 0.094 value_stay*reward + -0.36 value_stay*harvest_duration + 0.715 reward^2 + 0.25 reward*harvest_duration + -0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.998 value_exit[t] + -0.012 travel_duration + 0.047 value_exit^2 + -0.102 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 165/1000 --- L(Train): 0.3992549 --- L(Val, RNN): 0.3271177 --- L(Val, SINDy): 0.3396792 --- Time: 1.87s; --- Convergence: 2.03e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.162 1 + 0.485 value_stay[t] + 0.246 reward + -0.04 harvest_duration + 0.138 value_stay^2 + 0.098 value_stay*reward + -0.359 value_stay*harvest_duration + 0.717 reward^2 + 0.251 reward*harvest_duration + -0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 1.001 value_exit[t] + -0.015 travel_duration + 0.045 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 166/1000 --- L(Train): 0.3949247 --- L(Val, RNN): 0.3269964 --- L(Val, SINDy): 0.3406721 --- Time: 2.94s; --- Convergence: 1.62e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.167 1 + 0.489 value_stay[t] + 0.248 reward + -0.038 harvest_duration + 0.143 value_stay^2 + 0.102 value_stay*reward + -0.357 value_stay*harvest_duration + 0.72 reward^2 + 0.252 reward*harvest_duration + -0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.018 travel_duration + 0.042 value_exit^2 + -0.096 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 167/1000 --- L(Train): 0.3963901 --- L(Val, RNN): 0.3270382 --- L(Val, SINDy): 0.3401881 --- Time: 1.83s; --- Convergence: 1.02e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.171 1 + 0.491 value_stay[t] + 0.249 reward + -0.035 harvest_duration + 0.147 value_stay^2 + 0.107 value_stay*reward + -0.355 value_stay*harvest_duration + 0.723 reward^2 + 0.254 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.005 value_exit[t] + -0.02 travel_duration + 0.041 value_exit^2 + -0.094 value_exit*travel_duration + -0.019 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 168/1000 --- L(Train): 0.4219224 --- L(Val, RNN): 0.3273104 --- L(Val, SINDy): 0.3390715 --- Time: 1.59s; --- Convergence: 1.87e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.174 1 + 0.493 value_stay[t] + 0.25 reward + -0.033 harvest_duration + 0.15 value_stay^2 + 0.11 value_stay*reward + -0.353 value_stay*harvest_duration + 0.726 reward^2 + 0.254 reward*harvest_duration + -0.035 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.004 value_exit[t] + -0.019 travel_duration + 0.042 value_exit^2 + -0.095 value_exit*travel_duration + -0.018 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 169/1000 --- L(Train): 0.4172429 --- L(Val, RNN): 0.3276533 --- L(Val, SINDy): 0.3374776 --- Time: 0.95s; --- Convergence: 2.65e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.175 1 + 0.493 value_stay[t] + 0.249 reward + -0.034 harvest_duration + 0.152 value_stay^2 + 0.112 value_stay*reward + -0.354 value_stay*harvest_duration + 0.726 reward^2 + 0.253 reward*harvest_duration + -0.036 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.001 value_exit[t] + -0.016 travel_duration + 0.045 value_exit^2 + -0.098 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 170/1000 --- L(Train): 0.3941471 --- L(Val, RNN): 0.3277910 --- L(Val, SINDy): 0.3372464 --- Time: 1.17s; --- Convergence: 2.01e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.174 1 + 0.491 value_stay[t] + 0.246 reward + -0.036 harvest_duration + 0.151 value_stay^2 + 0.111 value_stay*reward + -0.357 value_stay*harvest_duration + 0.725 reward^2 + 0.25 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.998 value_exit[t] + -0.013 travel_duration + 0.047 value_exit^2 + -0.101 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 171/1000 --- L(Train): 0.3950651 --- L(Val, RNN): 0.3278462 --- L(Val, SINDy): 0.3382113 --- Time: 0.85s; --- Convergence: 1.28e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.173 1 + 0.487 value_stay[t] + 0.242 reward + -0.038 harvest_duration + 0.149 value_stay^2 + 0.11 value_stay*reward + -0.36 value_stay*harvest_duration + 0.723 reward^2 + 0.246 reward*harvest_duration + -0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.999 value_exit[t] + -0.013 travel_duration + 0.046 value_exit^2 + -0.101 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 172/1000 --- L(Train): 0.4054131 --- L(Val, RNN): 0.3279414 --- L(Val, SINDy): 0.3396854 --- Time: 0.90s; --- Convergence: 1.12e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.174 1 + 0.487 value_stay[t] + 0.241 reward + -0.038 harvest_duration + 0.15 value_stay^2 + 0.112 value_stay*reward + -0.361 value_stay*harvest_duration + 0.723 reward^2 + 0.245 reward*harvest_duration + -0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.018 travel_duration + 0.043 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 173/1000 --- L(Train): 0.4119178 --- L(Val, RNN): 0.3281453 --- L(Val, SINDy): 0.3396498 --- Time: 0.81s; --- Convergence: 1.58e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.177 1 + 0.487 value_stay[t] + 0.241 reward + -0.037 harvest_duration + 0.152 value_stay^2 + 0.115 value_stay*reward + -0.361 value_stay*harvest_duration + 0.725 reward^2 + 0.245 reward*harvest_duration + -0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.004 value_exit[t] + -0.019 travel_duration + 0.042 value_exit^2 + -0.095 value_exit*travel_duration + -0.018 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 174/1000 --- L(Train): 0.3892592 --- L(Val, RNN): 0.3282237 --- L(Val, SINDy): 0.3401778 --- Time: 0.84s; --- Convergence: 1.18e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.179 1 + 0.488 value_stay[t] + 0.241 reward + -0.035 harvest_duration + 0.154 value_stay^2 + 0.117 value_stay*reward + -0.36 value_stay*harvest_duration + 0.727 reward^2 + 0.246 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.002 value_exit[t] + -0.018 travel_duration + 0.043 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 175/1000 --- L(Train): 0.3996973 --- L(Val, RNN): 0.3283603 --- L(Val, SINDy): 0.3410309 --- Time: 1.06s; --- Convergence: 1.27e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.181 1 + 0.488 value_stay[t] + 0.241 reward + -0.035 harvest_duration + 0.156 value_stay^2 + 0.12 value_stay*reward + -0.36 value_stay*harvest_duration + 0.728 reward^2 + 0.246 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 1.0 value_exit[t] + -0.015 travel_duration + 0.045 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 176/1000 --- L(Train): 0.4106077 --- L(Val, RNN): 0.3285976 --- L(Val, SINDy): 0.3399905 --- Time: 1.17s; --- Convergence: 1.82e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.182 1 + 0.487 value_stay[t] + 0.24 reward + -0.035 harvest_duration + 0.155 value_stay^2 + 0.12 value_stay*reward + -0.362 value_stay*harvest_duration + 0.728 reward^2 + 0.244 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.999 value_exit[t] + -0.014 travel_duration + 0.047 value_exit^2 + -0.101 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 177/1000 --- L(Train): 0.4110871 --- L(Val, RNN): 0.3288158 --- L(Val, SINDy): 0.3373711 --- Time: 0.98s; --- Convergence: 2.00e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.182 1 + 0.484 value_stay[t] + 0.237 reward + -0.036 harvest_duration + 0.154 value_stay^2 + 0.12 value_stay*reward + -0.364 value_stay*harvest_duration + 0.728 reward^2 + 0.242 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.999 value_exit[t] + -0.014 travel_duration + 0.046 value_exit^2 + -0.1 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 178/1000 --- L(Train): 0.4193509 --- L(Val, RNN): 0.3289137 --- L(Val, SINDy): 0.3375634 --- Time: 1.17s; --- Convergence: 1.49e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.181 1 + 0.482 value_stay[t] + 0.235 reward + -0.036 harvest_duration + 0.153 value_stay^2 + 0.12 value_stay*reward + -0.367 value_stay*harvest_duration + 0.727 reward^2 + 0.239 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.001 value_exit[t] + -0.016 travel_duration + 0.044 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 179/1000 --- L(Train): 0.4000045 --- L(Val, RNN): 0.3289104 --- L(Val, SINDy): 0.3370635 --- Time: 0.99s; --- Convergence: 7.62e-05; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.181 1 + 0.479 value_stay[t] + 0.233 reward + -0.037 harvest_duration + 0.152 value_stay^2 + 0.12 value_stay*reward + -0.369 value_stay*harvest_duration + 0.726 reward^2 + 0.237 reward*harvest_duration + -0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.018 travel_duration + 0.043 value_exit^2 + -0.096 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 180/1000 --- L(Train): 0.3963223 --- L(Val, RNN): 0.3290032 --- L(Val, SINDy): 0.3376008 --- Time: 1.00s; --- Convergence: 8.45e-05; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.182 1 + 0.478 value_stay[t] + 0.232 reward + -0.037 harvest_duration + 0.151 value_stay^2 + 0.12 value_stay*reward + -0.371 value_stay*harvest_duration + 0.726 reward^2 + 0.236 reward*harvest_duration + -0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.002 value_exit[t] + -0.018 travel_duration + 0.043 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 181/1000 --- L(Train): 0.4198335 --- L(Val, RNN): 0.3292559 --- L(Val, SINDy): 0.3373412 --- Time: 1.02s; --- Convergence: 1.69e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.183 1 + 0.477 value_stay[t] + 0.231 reward + -0.036 harvest_duration + 0.151 value_stay^2 + 0.122 value_stay*reward + -0.372 value_stay*harvest_duration + 0.727 reward^2 + 0.236 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + -0.016 travel_duration + 0.045 value_exit^2 + -0.099 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 182/1000 --- L(Train): 0.4334241 --- L(Val, RNN): 0.3296250 --- L(Val, SINDy): 0.3371840 --- Time: 0.83s; --- Convergence: 2.69e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.184 1 + 0.476 value_stay[t] + 0.231 reward + -0.036 harvest_duration + 0.15 value_stay^2 + 0.124 value_stay*reward + -0.372 value_stay*harvest_duration + 0.728 reward^2 + 0.235 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.999 value_exit[t] + -0.014 travel_duration + 0.046 value_exit^2 + -0.1 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 183/1000 --- L(Train): 0.4184193 --- L(Val, RNN): 0.3299550 --- L(Val, SINDy): 0.3379574 --- Time: 0.84s; --- Convergence: 2.99e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.184 1 + 0.474 value_stay[t] + 0.23 reward + -0.035 harvest_duration + 0.15 value_stay^2 + 0.125 value_stay*reward + -0.373 value_stay*harvest_duration + 0.728 reward^2 + 0.234 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.999 value_exit[t] + -0.014 travel_duration + 0.047 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 184/1000 --- L(Train): 0.4123039 --- L(Val, RNN): 0.3300574 --- L(Val, SINDy): 0.3385688 --- Time: 0.84s; --- Convergence: 2.01e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.184 1 + 0.472 value_stay[t] + 0.228 reward + -0.035 harvest_duration + 0.149 value_stay^2 + 0.125 value_stay*reward + -0.375 value_stay*harvest_duration + 0.728 reward^2 + 0.233 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 1.0 value_exit[t] + -0.015 travel_duration + 0.046 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 185/1000 --- L(Train): 0.3994339 --- L(Val, RNN): 0.3300838 --- L(Val, SINDy): 0.3390663 --- Time: 0.88s; --- Convergence: 1.14e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.184 1 + 0.47 value_stay[t] + 0.227 reward + -0.035 harvest_duration + 0.148 value_stay^2 + 0.126 value_stay*reward + -0.376 value_stay*harvest_duration + 0.727 reward^2 + 0.231 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.001 value_exit[t] + -0.017 travel_duration + 0.045 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 186/1000 --- L(Train): 0.4804729 --- L(Val, RNN): 0.3301141 --- L(Val, SINDy): 0.3391569 --- Time: 0.89s; --- Convergence: 7.20e-05; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.185 1 + 0.469 value_stay[t] + 0.226 reward + -0.034 harvest_duration + 0.147 value_stay^2 + 0.127 value_stay*reward + -0.377 value_stay*harvest_duration + 0.728 reward^2 + 0.23 reward*harvest_duration + -0.036 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.002 value_exit[t] + -0.017 travel_duration + 0.044 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 187/1000 --- L(Train): 0.4674323 --- L(Val, RNN): 0.3303348 --- L(Val, SINDy): 0.3376388 --- Time: 0.79s; --- Convergence: 1.46e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.186 1 + 0.468 value_stay[t] + 0.225 reward + -0.033 harvest_duration + 0.147 value_stay^2 + 0.129 value_stay*reward + -0.377 value_stay*harvest_duration + 0.728 reward^2 + 0.23 reward*harvest_duration + -0.035 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.002 value_exit[t] + -0.018 travel_duration + 0.044 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 188/1000 --- L(Train): 0.4357972 --- L(Val, RNN): 0.3305675 --- L(Val, SINDy): 0.3372146 --- Time: 0.84s; --- Convergence: 1.90e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.187 1 + 0.468 value_stay[t] + 0.225 reward + -0.032 harvest_duration + 0.147 value_stay^2 + 0.13 value_stay*reward + -0.377 value_stay*harvest_duration + 0.729 reward^2 + 0.229 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.001 value_exit[t] + -0.017 travel_duration + 0.044 value_exit^2 + -0.098 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 189/1000 --- L(Train): 0.4300498 --- L(Val, RNN): 0.3307293 --- L(Val, SINDy): 0.3379092 --- Time: 1.00s; --- Convergence: 1.76e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.188 1 + 0.467 value_stay[t] + 0.224 reward + -0.031 harvest_duration + 0.147 value_stay^2 + 0.131 value_stay*reward + -0.377 value_stay*harvest_duration + 0.729 reward^2 + 0.228 reward*harvest_duration + -0.033 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + -0.016 travel_duration + 0.045 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 190/1000 --- L(Train): 0.4416681 --- L(Val, RNN): 0.3309361 --- L(Val, SINDy): 0.3381314 --- Time: 0.87s; --- Convergence: 1.91e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.189 1 + 0.466 value_stay[t] + 0.223 reward + -0.031 harvest_duration + 0.146 value_stay^2 + 0.132 value_stay*reward + -0.378 value_stay*harvest_duration + 0.729 reward^2 + 0.227 reward*harvest_duration + -0.033 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.999 value_exit[t] + -0.014 travel_duration + 0.046 value_exit^2 + -0.1 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 191/1000 --- L(Train): 0.4738328 --- L(Val, RNN): 0.3311182 --- L(Val, SINDy): 0.3381907 --- Time: 0.82s; --- Convergence: 1.87e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.189 1 + 0.465 value_stay[t] + 0.222 reward + -0.031 harvest_duration + 0.145 value_stay^2 + 0.132 value_stay*reward + -0.379 value_stay*harvest_duration + 0.728 reward^2 + 0.226 reward*harvest_duration + -0.033 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.998 value_exit[t] + -0.014 travel_duration + 0.047 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 192/1000 --- L(Train): 0.4482856 --- L(Val, RNN): 0.3313543 --- L(Val, SINDy): 0.3388438 --- Time: 1.10s; --- Convergence: 2.11e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.188 1 + 0.463 value_stay[t] + 0.219 reward + -0.031 harvest_duration + 0.144 value_stay^2 + 0.132 value_stay*reward + -0.381 value_stay*harvest_duration + 0.726 reward^2 + 0.223 reward*harvest_duration + -0.033 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 0.999 value_exit[t] + -0.015 travel_duration + 0.046 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 193/1000 --- L(Train): 0.4541990 --- L(Val, RNN): 0.3316438 --- L(Val, SINDy): 0.3387214 --- Time: 0.87s; --- Convergence: 2.50e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.189 1 + 0.462 value_stay[t] + 0.217 reward + -0.031 harvest_duration + 0.144 value_stay^2 + 0.133 value_stay*reward + -0.381 value_stay*harvest_duration + 0.725 reward^2 + 0.222 reward*harvest_duration + -0.033 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.001 value_exit[t] + -0.017 travel_duration + 0.045 value_exit^2 + -0.098 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 194/1000 --- L(Train): 0.4646768 --- L(Val, RNN): 0.3316591 --- L(Val, SINDy): 0.3386627 --- Time: 0.90s; --- Convergence: 1.33e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.191 1 + 0.463 value_stay[t] + 0.216 reward + -0.03 harvest_duration + 0.144 value_stay^2 + 0.134 value_stay*reward + -0.381 value_stay*harvest_duration + 0.725 reward^2 + 0.221 reward*harvest_duration + -0.032 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.002 value_exit[t] + -0.017 travel_duration + 0.044 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 195/1000 --- L(Train): 0.4486984 --- L(Val, RNN): 0.3317057 --- L(Val, SINDy): 0.3383778 --- Time: 1.00s; --- Convergence: 8.97e-05; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.193 1 + 0.463 value_stay[t] + 0.216 reward + -0.028 harvest_duration + 0.145 value_stay^2 + 0.135 value_stay*reward + -0.38 value_stay*harvest_duration + 0.725 reward^2 + 0.22 reward*harvest_duration + -0.03 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.001 value_exit[t] + -0.016 travel_duration + 0.045 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 196/1000 --- L(Train): 0.4498152 --- L(Val, RNN): 0.3318886 --- L(Val, SINDy): 0.3382736 --- Time: 1.30s; --- Convergence: 1.36e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.195 1 + 0.464 value_stay[t] + 0.215 reward + -0.027 harvest_duration + 0.146 value_stay^2 + 0.137 value_stay*reward + -0.38 value_stay*harvest_duration + 0.725 reward^2 + 0.219 reward*harvest_duration + -0.029 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 0.999 value_exit[t] + -0.015 travel_duration + 0.046 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 197/1000 --- L(Train): 0.4610845 --- L(Val, RNN): 0.3319443 --- L(Val, SINDy): 0.3380778 --- Time: 0.85s; --- Convergence: 9.60e-05; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.197 1 + 0.465 value_stay[t] + 0.214 reward + -0.026 harvest_duration + 0.146 value_stay^2 + 0.138 value_stay*reward + -0.38 value_stay*harvest_duration + 0.724 reward^2 + 0.218 reward*harvest_duration + -0.028 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.998 value_exit[t] + -0.014 travel_duration + 0.047 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 198/1000 --- L(Train): 0.4591763 --- L(Val, RNN): 0.3320583 --- L(Val, SINDy): 0.3380427 --- Time: 0.93s; --- Convergence: 1.05e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.198 1 + 0.464 value_stay[t] + 0.212 reward + -0.026 harvest_duration + 0.146 value_stay^2 + 0.138 value_stay*reward + -0.38 value_stay*harvest_duration + 0.723 reward^2 + 0.216 reward*harvest_duration + -0.028 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.998 value_exit[t] + -0.014 travel_duration + 0.047 value_exit^2 + -0.1 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 199/1000 --- L(Train): 0.4608829 --- L(Val, RNN): 0.3322850 --- L(Val, SINDy): 0.3381572 --- Time: 0.84s; --- Convergence: 1.66e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.198 1 + 0.463 value_stay[t] + 0.209 reward + -0.027 harvest_duration + 0.145 value_stay^2 + 0.138 value_stay*reward + -0.382 value_stay*harvest_duration + 0.721 reward^2 + 0.213 reward*harvest_duration + -0.029 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 0.999 value_exit[t] + -0.015 travel_duration + 0.046 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\n",
      ">>> Warmup complete (epoch 200). Reset optimizer state for 2 SINDy parameters (fresh start at full regularization strength).\n",
      "\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 200/1000 --- L(Train): 0.4484673 --- L(Val, RNN): 0.3324696 --- L(Val, SINDy): 0.3384752 --- Time: 0.93s; --- Convergence: 1.75e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.198 1 + 0.462 value_stay[t] + 0.206 reward + -0.028 harvest_duration + 0.144 value_stay^2 + 0.138 value_stay*reward + -0.383 value_stay*harvest_duration + 0.719 reward^2 + 0.211 reward*harvest_duration + -0.03 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + -0.016 travel_duration + 0.045 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 1, 0, 0, 0, 0, 0, 1\n",
      "value_exit: 0, 1, 1, 1, 0, 1\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 201/1000 --- L(Train): 0.4447877 --- L(Val, RNN): 0.3326565 --- L(Val, SINDy): 0.4140917 --- Time: 0.88s; --- Convergence: 1.81e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 1/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.208 1 + 0.472 value_stay[t] + 0.216 reward + -0.018 harvest_duration + 0.154 value_stay^2 + 0.148 value_stay*reward + -0.373 value_stay*harvest_duration + 0.729 reward^2 + 0.221 reward*harvest_duration + -0.02 harvest_duration^2 \n",
      "value_exit[t+1] = -0.075 1 + 0.99 value_exit[t] + -0.006 travel_duration + 0.055 value_exit^2 + -0.108 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 2, 0, 0, 0, 0, 0, 2\n",
      "value_exit: 0, 2, 2, 0, 0, 2\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 202/1000 --- L(Train): 3.1607802 --- L(Val, RNN): 0.3335262 --- L(Val, SINDy): 0.3742627 --- Time: 1.15s; --- Convergence: 5.25e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 2/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.212 1 + 0.477 value_stay[t] + 0.22 reward + -0.014 harvest_duration + 0.158 value_stay^2 + 0.153 value_stay*reward + -0.369 value_stay*harvest_duration + 0.732 reward^2 + 0.224 reward*harvest_duration + -0.016 harvest_duration^2 \n",
      "value_exit[t+1] = -0.071 1 + 0.986 value_exit[t] + -0.002 travel_duration + 0.059 value_exit^2 + -0.112 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 3, 0, 0, 0, 0, 0, 3\n",
      "value_exit: 0, 3, 3, 0, 0, 3\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 203/1000 --- L(Train): 1.9332011 --- L(Val, RNN): 0.3344940 --- L(Val, SINDy): 0.3566760 --- Time: 0.86s; --- Convergence: 7.47e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 3/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.209 1 + 0.473 value_stay[t] + 0.214 reward + -0.019 harvest_duration + 0.154 value_stay^2 + 0.15 value_stay*reward + -0.373 value_stay*harvest_duration + 0.727 reward^2 + 0.219 reward*harvest_duration + -0.021 harvest_duration^2 \n",
      "value_exit[t+1] = -0.076 1 + 0.991 value_exit[t] + -0.007 travel_duration + 0.055 value_exit^2 + -0.108 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 4, 0, 0, 0, 0, 0, 4\n",
      "value_exit: 0, 4, 4, 0, 0, 4\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 204/1000 --- L(Train): 1.4744061 --- L(Val, RNN): 0.3351893 --- L(Val, SINDy): 0.3581871 --- Time: 0.89s; --- Convergence: 7.21e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 4/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.205 1 + 0.469 value_stay[t] + 0.209 reward + -0.025 harvest_duration + 0.149 value_stay^2 + 0.147 value_stay*reward + -0.378 value_stay*harvest_duration + 0.722 reward^2 + 0.213 reward*harvest_duration + -0.027 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.996 value_exit[t] + -0.012 travel_duration + 0.05 value_exit^2 + -0.103 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 5, 0, 0, 0, 0, 0, 5\n",
      "value_exit: 0, 5, 5, 1, 0, 5\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 205/1000 --- L(Train): 1.5572056 --- L(Val, RNN): 0.3357444 --- L(Val, SINDy): 0.3562026 --- Time: 1.02s; --- Convergence: 6.38e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 5/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.201 1 + 0.465 value_stay[t] + 0.203 reward + -0.03 harvest_duration + 0.145 value_stay^2 + 0.144 value_stay*reward + -0.383 value_stay*harvest_duration + 0.717 reward^2 + 0.208 reward*harvest_duration + -0.032 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.002 value_exit[t] + -0.018 travel_duration + 0.044 value_exit^2 + -0.097 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 6, 0, 0, 0, 0, 0, 6\n",
      "value_exit: 0, 6, 6, 2, 0, 6\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 206/1000 --- L(Train): 1.4218611 --- L(Val, RNN): 0.3360967 --- L(Val, SINDy): 0.3555548 --- Time: 0.93s; --- Convergence: 4.95e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 6/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.198 1 + 0.462 value_stay[t] + 0.199 reward + -0.034 harvest_duration + 0.141 value_stay^2 + 0.142 value_stay*reward + -0.386 value_stay*harvest_duration + 0.712 reward^2 + 0.203 reward*harvest_duration + -0.036 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.006 value_exit[t] + -0.022 travel_duration + 0.04 value_exit^2 + -0.093 value_exit*travel_duration + -0.021 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 7, 0, 0, 0, 0, 0, 7\n",
      "value_exit: 0, 7, 7, 3, 0, 7\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 207/1000 --- L(Train): 1.0544778 --- L(Val, RNN): 0.3363020 --- L(Val, SINDy): 0.3596557 --- Time: 0.88s; --- Convergence: 3.50e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 7/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.197 1 + 0.461 value_stay[t] + 0.197 reward + -0.036 harvest_duration + 0.14 value_stay^2 + 0.142 value_stay*reward + -0.388 value_stay*harvest_duration + 0.711 reward^2 + 0.202 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.092 1 + 1.007 value_exit[t] + -0.024 travel_duration + 0.038 value_exit^2 + -0.091 value_exit*travel_duration + -0.023 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 8, 0, 0, 0, 0, 0, 8\n",
      "value_exit: 0, 8, 8, 4, 0, 8\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 208/1000 --- L(Train): 0.8520912 --- L(Val, RNN): 0.3365931 --- L(Val, SINDy): 0.3643555 --- Time: 0.85s; --- Convergence: 3.21e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 8/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.199 1 + 0.463 value_stay[t] + 0.198 reward + -0.035 harvest_duration + 0.142 value_stay^2 + 0.144 value_stay*reward + -0.386 value_stay*harvest_duration + 0.712 reward^2 + 0.202 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.006 value_exit[t] + -0.023 travel_duration + 0.039 value_exit^2 + -0.092 value_exit*travel_duration + -0.022 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 9, 0, 0, 0, 0, 0, 9\n",
      "value_exit: 0, 9, 9, 5, 0, 9\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 209/1000 --- L(Train): 0.9432642 --- L(Val, RNN): 0.3370097 --- L(Val, SINDy): 0.3638059 --- Time: 0.75s; --- Convergence: 3.69e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 9/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.202 1 + 0.465 value_stay[t] + 0.2 reward + -0.033 harvest_duration + 0.144 value_stay^2 + 0.147 value_stay*reward + -0.384 value_stay*harvest_duration + 0.713 reward^2 + 0.204 reward*harvest_duration + -0.035 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.004 value_exit[t] + -0.021 travel_duration + 0.041 value_exit^2 + -0.094 value_exit*travel_duration + -0.019 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 10, 0, 0, 0, 0, 0, 10\n",
      "value_exit: 0, 10, 10, 6, 0, 10\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 210/1000 --- L(Train): 0.9578822 --- L(Val, RNN): 0.3375063 --- L(Val, SINDy): 0.3599927 --- Time: 0.91s; --- Convergence: 4.33e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 10/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.205 1 + 0.468 value_stay[t] + 0.202 reward + -0.031 harvest_duration + 0.147 value_stay^2 + 0.15 value_stay*reward + -0.382 value_stay*harvest_duration + 0.715 reward^2 + 0.206 reward*harvest_duration + -0.033 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.001 value_exit[t] + -0.017 travel_duration + 0.044 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 11, 0, 0, 0, 0, 0, 11\n",
      "value_exit: 0, 11, 11, 7, 0, 11\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 211/1000 --- L(Train): 0.9274210 --- L(Val, RNN): 0.3380558 --- L(Val, SINDy): 0.3571654 --- Time: 1.01s; --- Convergence: 4.91e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 11/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.208 1 + 0.471 value_stay[t] + 0.204 reward + -0.028 harvest_duration + 0.149 value_stay^2 + 0.153 value_stay*reward + -0.379 value_stay*harvest_duration + 0.717 reward^2 + 0.208 reward*harvest_duration + -0.03 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.998 value_exit[t] + -0.014 travel_duration + 0.047 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 12, 0, 0, 0, 0, 0, 12\n",
      "value_exit: 0, 12, 12, 8, 0, 12\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 212/1000 --- L(Train): 0.8633414 --- L(Val, RNN): 0.3386598 --- L(Val, SINDy): 0.3523088 --- Time: 1.26s; --- Convergence: 5.47e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 12/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.209 1 + 0.473 value_stay[t] + 0.205 reward + -0.027 harvest_duration + 0.15 value_stay^2 + 0.155 value_stay*reward + -0.378 value_stay*harvest_duration + 0.718 reward^2 + 0.209 reward*harvest_duration + -0.029 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.995 value_exit[t] + -0.011 travel_duration + 0.05 value_exit^2 + -0.103 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 13, 0, 0, 0, 0, 0, 13\n",
      "value_exit: 0, 13, 13, 0, 0, 13\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 213/1000 --- L(Train): 0.7515696 --- L(Val, RNN): 0.3391999 --- L(Val, SINDy): 0.3476968 --- Time: 0.84s; --- Convergence: 5.44e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 13/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.209 1 + 0.471 value_stay[t] + 0.203 reward + -0.028 harvest_duration + 0.149 value_stay^2 + 0.154 value_stay*reward + -0.38 value_stay*harvest_duration + 0.716 reward^2 + 0.207 reward*harvest_duration + -0.03 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.994 value_exit[t] + -0.01 travel_duration + 0.051 value_exit^2 + -0.104 value_exit*travel_duration + -0.009 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 14, 0, 0, 0, 0, 0, 14\n",
      "value_exit: 0, 14, 14, 0, 0, 14\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 214/1000 --- L(Train): 0.6936690 --- L(Val, RNN): 0.3396359 --- L(Val, SINDy): 0.3457995 --- Time: 1.02s; --- Convergence: 4.90e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 14/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.207 1 + 0.47 value_stay[t] + 0.2 reward + -0.03 harvest_duration + 0.147 value_stay^2 + 0.152 value_stay*reward + -0.382 value_stay*harvest_duration + 0.713 reward^2 + 0.204 reward*harvest_duration + -0.032 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.994 value_exit[t] + -0.01 travel_duration + 0.051 value_exit^2 + -0.104 value_exit*travel_duration + -0.009 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 15, 0, 0, 0, 0, 0, 15\n",
      "value_exit: 0, 15, 15, 0, 0, 15\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 215/1000 --- L(Train): 0.6556407 --- L(Val, RNN): 0.3398949 --- L(Val, SINDy): 0.3463714 --- Time: 0.98s; --- Convergence: 3.74e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 15/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.206 1 + 0.467 value_stay[t] + 0.197 reward + -0.032 harvest_duration + 0.144 value_stay^2 + 0.15 value_stay*reward + -0.384 value_stay*harvest_duration + 0.71 reward^2 + 0.201 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.995 value_exit[t] + -0.012 travel_duration + 0.05 value_exit^2 + -0.103 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 16, 0, 0, 0, 0, 0, 16\n",
      "value_exit: 0, 16, 16, 0, 0, 16\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 216/1000 --- L(Train): 0.6325753 --- L(Val, RNN): 0.3400549 --- L(Val, SINDy): 0.3492553 --- Time: 1.25s; --- Convergence: 2.67e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 16/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.204 1 + 0.465 value_stay[t] + 0.194 reward + -0.033 harvest_duration + 0.142 value_stay^2 + 0.148 value_stay*reward + -0.386 value_stay*harvest_duration + 0.707 reward^2 + 0.198 reward*harvest_duration + -0.035 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.014 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 17, 0, 0, 0, 0, 0, 17\n",
      "value_exit: 0, 17, 17, 1, 0, 17\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 217/1000 --- L(Train): 0.6362990 --- L(Val, RNN): 0.3401966 --- L(Val, SINDy): 0.3540957 --- Time: 2.04s; --- Convergence: 2.04e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 17/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.204 1 + 0.464 value_stay[t] + 0.192 reward + -0.033 harvest_duration + 0.141 value_stay^2 + 0.147 value_stay*reward + -0.387 value_stay*harvest_duration + 0.706 reward^2 + 0.196 reward*harvest_duration + -0.035 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.998 value_exit[t] + -0.016 travel_duration + 0.047 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 18, 0, 0, 0, 0, 0, 18\n",
      "value_exit: 0, 18, 18, 2, 0, 18\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 218/1000 --- L(Train): 0.5982640 --- L(Val, RNN): 0.3404363 --- L(Val, SINDy): 0.3567891 --- Time: 5.11s; --- Convergence: 2.22e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 18/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.205 1 + 0.464 value_stay[t] + 0.191 reward + -0.032 harvest_duration + 0.14 value_stay^2 + 0.147 value_stay*reward + -0.387 value_stay*harvest_duration + 0.705 reward^2 + 0.196 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + -0.017 travel_duration + 0.046 value_exit^2 + -0.098 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 19, 0, 0, 0, 0, 0, 19\n",
      "value_exit: 0, 19, 19, 3, 0, 19\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 219/1000 --- L(Train): 0.5860381 --- L(Val, RNN): 0.3407426 --- L(Val, SINDy): 0.3560641 --- Time: 5.89s; --- Convergence: 2.64e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 19/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.207 1 + 0.465 value_stay[t] + 0.192 reward + -0.03 harvest_duration + 0.141 value_stay^2 + 0.148 value_stay*reward + -0.386 value_stay*harvest_duration + 0.705 reward^2 + 0.196 reward*harvest_duration + -0.032 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + -0.017 travel_duration + 0.046 value_exit^2 + -0.098 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 20, 0, 0, 0, 0, 0, 20\n",
      "value_exit: 0, 20, 20, 4, 0, 20\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 220/1000 --- L(Train): 0.5970812 --- L(Val, RNN): 0.3411337 --- L(Val, SINDy): 0.3530634 --- Time: 2.71s; --- Convergence: 3.28e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 20/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.21 1 + 0.466 value_stay[t] + 0.193 reward + -0.027 harvest_duration + 0.142 value_stay^2 + 0.149 value_stay*reward + -0.384 value_stay*harvest_duration + 0.707 reward^2 + 0.197 reward*harvest_duration + -0.029 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 0.999 value_exit[t] + -0.017 travel_duration + 0.047 value_exit^2 + -0.099 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 21, 0, 0, 0, 0, 0, 21\n",
      "value_exit: 0, 21, 21, 5, 0, 21\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 221/1000 --- L(Train): 0.5584361 --- L(Val, RNN): 0.3415103 --- L(Val, SINDy): 0.3498115 --- Time: 2.25s; --- Convergence: 3.52e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 21/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.213 1 + 0.468 value_stay[t] + 0.194 reward + -0.024 harvest_duration + 0.143 value_stay^2 + 0.151 value_stay*reward + -0.383 value_stay*harvest_duration + 0.708 reward^2 + 0.198 reward*harvest_duration + -0.026 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.998 value_exit[t] + -0.016 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 22, 0, 0, 0, 0, 0, 22\n",
      "value_exit: 0, 22, 22, 6, 0, 22\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 222/1000 --- L(Train): 0.5047039 --- L(Val, RNN): 0.3417369 --- L(Val, SINDy): 0.3491075 --- Time: 2.27s; --- Convergence: 2.89e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 22/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.215 1 + 0.469 value_stay[t] + 0.195 reward + -0.021 harvest_duration + 0.144 value_stay^2 + 0.152 value_stay*reward + -0.381 value_stay*harvest_duration + 0.709 reward^2 + 0.199 reward*harvest_duration + -0.023 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.996 value_exit[t] + -0.014 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 23, 0, 0, 0, 0, 0, 23\n",
      "value_exit: 0, 23, 23, 7, 0, 23\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 223/1000 --- L(Train): 0.5085118 --- L(Val, RNN): 0.3417372 --- L(Val, SINDy): 0.3487705 --- Time: 2.34s; --- Convergence: 1.45e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 23/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.215 1 + 0.468 value_stay[t] + 0.194 reward + -0.021 harvest_duration + 0.143 value_stay^2 + 0.151 value_stay*reward + -0.382 value_stay*harvest_duration + 0.707 reward^2 + 0.198 reward*harvest_duration + -0.023 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.995 value_exit[t] + -0.013 travel_duration + 0.051 value_exit^2 + -0.102 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 24, 0, 0, 0, 0, 0, 24\n",
      "value_exit: 0, 24, 24, 0, 0, 24\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 224/1000 --- L(Train): 0.5148552 --- L(Val, RNN): 0.3416036 --- L(Val, SINDy): 0.3485470 --- Time: 2.92s; --- Convergence: 1.39e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 24/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.214 1 + 0.466 value_stay[t] + 0.191 reward + -0.022 harvest_duration + 0.14 value_stay^2 + 0.148 value_stay*reward + -0.384 value_stay*harvest_duration + 0.704 reward^2 + 0.195 reward*harvest_duration + -0.024 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.994 value_exit[t] + -0.012 travel_duration + 0.052 value_exit^2 + -0.103 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 25, 0, 0, 0, 0, 0, 25\n",
      "value_exit: 0, 25, 25, 0, 0, 25\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 225/1000 --- L(Train): 0.5211936 --- L(Val, RNN): 0.3416046 --- L(Val, SINDy): 0.3476354 --- Time: 2.35s; --- Convergence: 7.01e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 25/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.213 1 + 0.463 value_stay[t] + 0.188 reward + -0.023 harvest_duration + 0.138 value_stay^2 + 0.146 value_stay*reward + -0.387 value_stay*harvest_duration + 0.702 reward^2 + 0.192 reward*harvest_duration + -0.025 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.993 value_exit[t] + -0.011 travel_duration + 0.052 value_exit^2 + -0.104 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 26, 0, 0, 0, 0, 0, 26\n",
      "value_exit: 0, 26, 26, 0, 0, 26\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 226/1000 --- L(Train): 0.4919272 --- L(Val, RNN): 0.3416593 --- L(Val, SINDy): 0.3483410 --- Time: 2.70s; --- Convergence: 6.24e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 26/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.213 1 + 0.463 value_stay[t] + 0.187 reward + -0.023 harvest_duration + 0.136 value_stay^2 + 0.145 value_stay*reward + -0.387 value_stay*harvest_duration + 0.701 reward^2 + 0.191 reward*harvest_duration + -0.025 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.993 value_exit[t] + -0.012 travel_duration + 0.052 value_exit^2 + -0.103 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 27, 0, 0, 0, 0, 0, 27\n",
      "value_exit: 0, 27, 27, 0, 0, 27\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 227/1000 --- L(Train): 0.4713509 --- L(Val, RNN): 0.3416198 --- L(Val, SINDy): 0.3495976 --- Time: 1.81s; --- Convergence: 5.10e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 27/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.215 1 + 0.464 value_stay[t] + 0.188 reward + -0.021 harvest_duration + 0.138 value_stay^2 + 0.147 value_stay*reward + -0.386 value_stay*harvest_duration + 0.702 reward^2 + 0.192 reward*harvest_duration + -0.023 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.995 value_exit[t] + -0.014 travel_duration + 0.05 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 28, 0, 0, 0, 0, 0, 28\n",
      "value_exit: 0, 28, 28, 0, 0, 28\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 228/1000 --- L(Train): 0.4704758 --- L(Val, RNN): 0.3414546 --- L(Val, SINDy): 0.3502482 --- Time: 2.54s; --- Convergence: 1.08e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 28/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.218 1 + 0.466 value_stay[t] + 0.189 reward + -0.019 harvest_duration + 0.139 value_stay^2 + 0.149 value_stay*reward + -0.384 value_stay*harvest_duration + 0.703 reward^2 + 0.193 reward*harvest_duration + -0.021 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.016 travel_duration + 0.049 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 29, 0, 0, 0, 0, 0, 29\n",
      "value_exit: 0, 29, 29, 1, 0, 29\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 229/1000 --- L(Train): 0.4700187 --- L(Val, RNN): 0.3414069 --- L(Val, SINDy): 0.3488831 --- Time: 2.02s; --- Convergence: 7.79e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 29/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.22 1 + 0.467 value_stay[t] + 0.189 reward + -0.018 harvest_duration + 0.14 value_stay^2 + 0.151 value_stay*reward + -0.384 value_stay*harvest_duration + 0.704 reward^2 + 0.193 reward*harvest_duration + -0.02 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.996 value_exit[t] + -0.016 travel_duration + 0.049 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 30, 0, 0, 0, 0, 0, 30\n",
      "value_exit: 0, 30, 30, 2, 0, 30\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 230/1000 --- L(Train): 0.4533333 --- L(Val, RNN): 0.3413812 --- L(Val, SINDy): 0.3468323 --- Time: 1.88s; --- Convergence: 5.18e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 30/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.219 1 + 0.465 value_stay[t] + 0.187 reward + -0.019 harvest_duration + 0.138 value_stay^2 + 0.15 value_stay*reward + -0.385 value_stay*harvest_duration + 0.702 reward^2 + 0.191 reward*harvest_duration + -0.021 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.995 value_exit[t] + -0.014 travel_duration + 0.051 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 31, 0, 0, 0, 0, 0, 31\n",
      "value_exit: 0, 31, 31, 0, 0, 31\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 231/1000 --- L(Train): 0.4477691 --- L(Val, RNN): 0.3412105 --- L(Val, SINDy): 0.3463387 --- Time: 1.85s; --- Convergence: 1.11e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 31/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.218 1 + 0.464 value_stay[t] + 0.184 reward + -0.02 harvest_duration + 0.137 value_stay^2 + 0.149 value_stay*reward + -0.387 value_stay*harvest_duration + 0.7 reward^2 + 0.189 reward*harvest_duration + -0.022 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.993 value_exit[t] + -0.013 travel_duration + 0.052 value_exit^2 + -0.103 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 32, 0, 0, 0, 0, 0, 32\n",
      "value_exit: 0, 32, 32, 0, 0, 32\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 232/1000 --- L(Train): 0.4516536 --- L(Val, RNN): 0.3410363 --- L(Val, SINDy): 0.3468645 --- Time: 2.58s; --- Convergence: 1.43e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 32/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.217 1 + 0.462 value_stay[t] + 0.182 reward + -0.022 harvest_duration + 0.135 value_stay^2 + 0.148 value_stay*reward + -0.389 value_stay*harvest_duration + 0.697 reward^2 + 0.186 reward*harvest_duration + -0.024 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 0.992 value_exit[t] + -0.012 travel_duration + 0.054 value_exit^2 + -0.104 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 33, 0, 0, 0, 0, 0, 33\n",
      "value_exit: 0, 33, 33, 0, 0, 33\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 233/1000 --- L(Train): 0.4683941 --- L(Val, RNN): 0.3409162 --- L(Val, SINDy): 0.3478959 --- Time: 1.36s; --- Convergence: 1.31e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 33/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.217 1 + 0.461 value_stay[t] + 0.18 reward + -0.023 harvest_duration + 0.134 value_stay^2 + 0.147 value_stay*reward + -0.391 value_stay*harvest_duration + 0.696 reward^2 + 0.184 reward*harvest_duration + -0.025 harvest_duration^2 \n",
      "value_exit[t+1] = -0.076 1 + 0.991 value_exit[t] + -0.011 travel_duration + 0.054 value_exit^2 + -0.104 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 34, 0, 0, 0, 0, 0, 34\n",
      "value_exit: 0, 34, 34, 0, 0, 34\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 234/1000 --- L(Train): 0.4588708 --- L(Val, RNN): 0.3408676 --- L(Val, SINDy): 0.3485125 --- Time: 0.93s; --- Convergence: 9.00e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 34/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.218 1 + 0.462 value_stay[t] + 0.18 reward + -0.022 harvest_duration + 0.134 value_stay^2 + 0.149 value_stay*reward + -0.39 value_stay*harvest_duration + 0.696 reward^2 + 0.185 reward*harvest_duration + -0.024 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 0.992 value_exit[t] + -0.012 travel_duration + 0.053 value_exit^2 + -0.103 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 35, 0, 0, 0, 0, 0, 35\n",
      "value_exit: 0, 35, 35, 0, 0, 35\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 235/1000 --- L(Train): 0.4448075 --- L(Val, RNN): 0.3408245 --- L(Val, SINDy): 0.3480214 --- Time: 1.27s; --- Convergence: 6.66e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 35/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.22 1 + 0.463 value_stay[t] + 0.181 reward + -0.02 harvest_duration + 0.136 value_stay^2 + 0.15 value_stay*reward + -0.389 value_stay*harvest_duration + 0.697 reward^2 + 0.185 reward*harvest_duration + -0.022 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.993 value_exit[t] + -0.014 travel_duration + 0.053 value_exit^2 + -0.102 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 36, 0, 0, 0, 0, 0, 36\n",
      "value_exit: 0, 36, 36, 0, 0, 36\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 236/1000 --- L(Train): 0.4349307 --- L(Val, RNN): 0.3408145 --- L(Val, SINDy): 0.3466058 --- Time: 1.18s; --- Convergence: 3.83e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 36/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.223 1 + 0.464 value_stay[t] + 0.182 reward + -0.018 harvest_duration + 0.137 value_stay^2 + 0.152 value_stay*reward + -0.388 value_stay*harvest_duration + 0.699 reward^2 + 0.186 reward*harvest_duration + -0.02 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.994 value_exit[t] + -0.015 travel_duration + 0.052 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 37, 0, 0, 0, 0, 0, 37\n",
      "value_exit: 0, 37, 37, 0, 0, 37\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 237/1000 --- L(Train): 0.4441873 --- L(Val, RNN): 0.3407576 --- L(Val, SINDy): 0.3444271 --- Time: 1.13s; --- Convergence: 4.76e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 37/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.224 1 + 0.465 value_stay[t] + 0.182 reward + -0.017 harvest_duration + 0.137 value_stay^2 + 0.153 value_stay*reward + -0.387 value_stay*harvest_duration + 0.699 reward^2 + 0.186 reward*harvest_duration + -0.019 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.994 value_exit[t] + -0.015 travel_duration + 0.052 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 38, 0, 0, 0, 0, 0, 38\n",
      "value_exit: 0, 38, 38, 0, 0, 38\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 238/1000 --- L(Train): 0.4413984 --- L(Val, RNN): 0.3405870 --- L(Val, SINDy): 0.3431724 --- Time: 1.05s; --- Convergence: 1.09e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 38/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.225 1 + 0.465 value_stay[t] + 0.181 reward + -0.017 harvest_duration + 0.137 value_stay^2 + 0.153 value_stay*reward + -0.387 value_stay*harvest_duration + 0.699 reward^2 + 0.185 reward*harvest_duration + -0.019 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.994 value_exit[t] + -0.015 travel_duration + 0.052 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 39, 0, 0, 0, 0, 0, 39\n",
      "value_exit: 0, 39, 39, 0, 0, 39\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 239/1000 --- L(Train): 0.4399113 --- L(Val, RNN): 0.3402090 --- L(Val, SINDy): 0.3435743 --- Time: 0.88s; --- Convergence: 2.44e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 39/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.224 1 + 0.463 value_stay[t] + 0.179 reward + -0.017 harvest_duration + 0.136 value_stay^2 + 0.153 value_stay*reward + -0.389 value_stay*harvest_duration + 0.698 reward^2 + 0.184 reward*harvest_duration + -0.019 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.992 value_exit[t] + -0.014 travel_duration + 0.053 value_exit^2 + -0.102 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 40, 0, 0, 0, 0, 0, 40\n",
      "value_exit: 0, 40, 40, 0, 0, 40\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 240/1000 --- L(Train): 0.4256577 --- L(Val, RNN): 0.3397526 --- L(Val, SINDy): 0.3443553 --- Time: 1.10s; --- Convergence: 3.50e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 40/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.224 1 + 0.462 value_stay[t] + 0.178 reward + -0.018 harvest_duration + 0.135 value_stay^2 + 0.152 value_stay*reward + -0.39 value_stay*harvest_duration + 0.696 reward^2 + 0.182 reward*harvest_duration + -0.02 harvest_duration^2 \n",
      "value_exit[t+1] = -0.076 1 + 0.991 value_exit[t] + -0.013 travel_duration + 0.054 value_exit^2 + -0.103 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 41, 0, 0, 0, 0, 0, 41\n",
      "value_exit: 0, 41, 41, 0, 0, 41\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 241/1000 --- L(Train): 0.4417495 --- L(Val, RNN): 0.3392924 --- L(Val, SINDy): 0.3455099 --- Time: 0.90s; --- Convergence: 4.05e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 41/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.225 1 + 0.462 value_stay[t] + 0.177 reward + -0.018 harvest_duration + 0.134 value_stay^2 + 0.151 value_stay*reward + -0.391 value_stay*harvest_duration + 0.696 reward^2 + 0.181 reward*harvest_duration + -0.02 harvest_duration^2 \n",
      "value_exit[t+1] = -0.076 1 + 0.99 value_exit[t] + -0.012 travel_duration + 0.055 value_exit^2 + -0.104 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 42, 0, 0, 0, 0, 0, 42\n",
      "value_exit: 0, 42, 42, 0, 0, 42\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 242/1000 --- L(Train): 0.4323932 --- L(Val, RNN): 0.3389630 --- L(Val, SINDy): 0.3457211 --- Time: 0.85s; --- Convergence: 3.67e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 42/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.225 1 + 0.461 value_stay[t] + 0.176 reward + -0.017 harvest_duration + 0.133 value_stay^2 + 0.151 value_stay*reward + -0.392 value_stay*harvest_duration + 0.695 reward^2 + 0.18 reward*harvest_duration + -0.019 harvest_duration^2 \n",
      "value_exit[t+1] = -0.075 1 + 0.989 value_exit[t] + -0.011 travel_duration + 0.056 value_exit^2 + -0.104 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 43, 0, 0, 0, 0, 0, 43\n",
      "value_exit: 0, 43, 43, 0, 0, 43\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 243/1000 --- L(Train): 0.4378382 --- L(Val, RNN): 0.3388860 --- L(Val, SINDy): 0.3450460 --- Time: 0.97s; --- Convergence: 2.22e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 43/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.226 1 + 0.461 value_stay[t] + 0.175 reward + -0.017 harvest_duration + 0.133 value_stay^2 + 0.151 value_stay*reward + -0.392 value_stay*harvest_duration + 0.695 reward^2 + 0.179 reward*harvest_duration + -0.019 harvest_duration^2 \n",
      "value_exit[t+1] = -0.075 1 + 0.989 value_exit[t] + -0.011 travel_duration + 0.056 value_exit^2 + -0.104 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 44, 0, 0, 0, 0, 0, 44\n",
      "value_exit: 0, 44, 44, 0, 0, 44\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 244/1000 --- L(Train): 0.4199235 --- L(Val, RNN): 0.3387924 --- L(Val, SINDy): 0.3438163 --- Time: 1.09s; --- Convergence: 1.58e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 44/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.227 1 + 0.461 value_stay[t] + 0.175 reward + -0.016 harvest_duration + 0.133 value_stay^2 + 0.152 value_stay*reward + -0.392 value_stay*harvest_duration + 0.695 reward^2 + 0.179 reward*harvest_duration + -0.018 harvest_duration^2 \n",
      "value_exit[t+1] = -0.075 1 + 0.99 value_exit[t] + -0.012 travel_duration + 0.055 value_exit^2 + -0.104 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 45, 0, 0, 0, 0, 0, 45\n",
      "value_exit: 0, 45, 45, 0, 0, 45\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 245/1000 --- L(Train): 0.4334109 --- L(Val, RNN): 0.3387683 --- L(Val, SINDy): 0.3424699 --- Time: 0.83s; --- Convergence: 9.10e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 45/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.229 1 + 0.462 value_stay[t] + 0.176 reward + -0.014 harvest_duration + 0.134 value_stay^2 + 0.153 value_stay*reward + -0.391 value_stay*harvest_duration + 0.697 reward^2 + 0.18 reward*harvest_duration + -0.016 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 0.991 value_exit[t] + -0.014 travel_duration + 0.054 value_exit^2 + -0.102 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 46, 0, 0, 0, 0, 0, 46\n",
      "value_exit: 0, 46, 46, 0, 0, 46\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 246/1000 --- L(Train): 0.4161119 --- L(Val, RNN): 0.3384843 --- L(Val, SINDy): 0.3422161 --- Time: 0.93s; --- Convergence: 1.87e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 46/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.231 1 + 0.463 value_stay[t] + 0.176 reward + -0.013 harvest_duration + 0.135 value_stay^2 + 0.154 value_stay*reward + -0.39 value_stay*harvest_duration + 0.698 reward^2 + 0.181 reward*harvest_duration + -0.015 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.993 value_exit[t] + -0.015 travel_duration + 0.052 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 47, 0, 0, 0, 0, 0, 47\n",
      "value_exit: 0, 47, 47, 0, 0, 47\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 247/1000 --- L(Train): 0.4267038 --- L(Val, RNN): 0.3383148 --- L(Val, SINDy): 0.3421980 --- Time: 1.06s; --- Convergence: 1.78e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 47/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.233 1 + 0.463 value_stay[t] + 0.176 reward + -0.012 harvest_duration + 0.135 value_stay^2 + 0.155 value_stay*reward + -0.39 value_stay*harvest_duration + 0.698 reward^2 + 0.18 reward*harvest_duration + -0.014 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.994 value_exit[t] + -0.016 travel_duration + 0.052 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 48, 0, 0, 0, 0, 0, 48\n",
      "value_exit: 0, 48, 48, 0, 0, 48\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 248/1000 --- L(Train): 0.4255576 --- L(Val, RNN): 0.3381517 --- L(Val, SINDy): 0.3419876 --- Time: 1.01s; --- Convergence: 1.71e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 48/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.233 1 + 0.463 value_stay[t] + 0.175 reward + -0.012 harvest_duration + 0.135 value_stay^2 + 0.155 value_stay*reward + -0.391 value_stay*harvest_duration + 0.697 reward^2 + 0.18 reward*harvest_duration + -0.014 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.993 value_exit[t] + -0.016 travel_duration + 0.052 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 49, 0, 0, 0, 0, 0, 49\n",
      "value_exit: 0, 49, 49, 0, 0, 49\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 249/1000 --- L(Train): 0.4095676 --- L(Val, RNN): 0.3377096 --- L(Val, SINDy): 0.3418244 --- Time: 1.08s; --- Convergence: 3.06e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 49/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.233 1 + 0.462 value_stay[t] + 0.174 reward + -0.012 harvest_duration + 0.134 value_stay^2 + 0.154 value_stay*reward + -0.392 value_stay*harvest_duration + 0.697 reward^2 + 0.179 reward*harvest_duration + -0.014 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.992 value_exit[t] + -0.015 travel_duration + 0.053 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 50, 0, 0, 0, 0, 0, 50\n",
      "value_exit: 0, 50, 50, 0, 0, 50\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 250/1000 --- L(Train): 0.4053139 --- L(Val, RNN): 0.3373820 --- L(Val, SINDy): 0.3416665 --- Time: 0.84s; --- Convergence: 3.17e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 50/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.234 1 + 0.462 value_stay[t] + 0.174 reward + -0.012 harvest_duration + 0.133 value_stay^2 + 0.154 value_stay*reward + -0.393 value_stay*harvest_duration + 0.697 reward^2 + 0.178 reward*harvest_duration + -0.014 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 0.991 value_exit[t] + -0.014 travel_duration + 0.054 value_exit^2 + -0.103 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 51, 0, 0, 0, 0, 0, 51\n",
      "value_exit: 0, 51, 51, 0, 0, 51\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 251/1000 --- L(Train): 0.4160195 --- L(Val, RNN): 0.3371405 --- L(Val, SINDy): 0.3410721 --- Time: 1.06s; --- Convergence: 2.79e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 51/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.235 1 + 0.461 value_stay[t] + 0.173 reward + -0.012 harvest_duration + 0.133 value_stay^2 + 0.154 value_stay*reward + -0.393 value_stay*harvest_duration + 0.696 reward^2 + 0.177 reward*harvest_duration + -0.014 harvest_duration^2 \n",
      "value_exit[t+1] = -0.076 1 + 0.99 value_exit[t] + -0.013 travel_duration + 0.055 value_exit^2 + -0.103 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 52, 0, 0, 0, 0, 0, 52\n",
      "value_exit: 0, 52, 52, 0, 0, 52\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 252/1000 --- L(Train): 0.4128440 --- L(Val, RNN): 0.3368619 --- L(Val, SINDy): 0.3409139 --- Time: 1.00s; --- Convergence: 2.79e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 52/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.236 1 + 0.461 value_stay[t] + 0.172 reward + -0.012 harvest_duration + 0.133 value_stay^2 + 0.154 value_stay*reward + -0.394 value_stay*harvest_duration + 0.696 reward^2 + 0.177 reward*harvest_duration + -0.014 harvest_duration^2 \n",
      "value_exit[t+1] = -0.076 1 + 0.99 value_exit[t] + -0.013 travel_duration + 0.055 value_exit^2 + -0.103 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 53, 0, 0, 0, 0, 0, 53\n",
      "value_exit: 0, 53, 53, 0, 0, 53\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 253/1000 --- L(Train): 0.4012853 --- L(Val, RNN): 0.3366408 --- L(Val, SINDy): 0.3406148 --- Time: 0.95s; --- Convergence: 2.50e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 53/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.238 1 + 0.463 value_stay[t] + 0.173 reward + -0.01 harvest_duration + 0.134 value_stay^2 + 0.156 value_stay*reward + -0.393 value_stay*harvest_duration + 0.697 reward^2 + 0.177 reward*harvest_duration + -0.012 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 0.992 value_exit[t] + -0.014 travel_duration + 0.053 value_exit^2 + -0.102 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 54, 0, 0, 0, 0, 0, 54\n",
      "value_exit: 0, 54, 54, 0, 0, 54\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 254/1000 --- L(Train): 0.3974013 --- L(Val, RNN): 0.3366806 --- L(Val, SINDy): 0.3400703 --- Time: 0.90s; --- Convergence: 1.45e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 54/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.24 1 + 0.463 value_stay[t] + 0.173 reward + -0.009 harvest_duration + 0.135 value_stay^2 + 0.157 value_stay*reward + -0.393 value_stay*harvest_duration + 0.698 reward^2 + 0.177 reward*harvest_duration + -0.011 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.993 value_exit[t] + -0.016 travel_duration + 0.052 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 55, 0, 0, 0, 0, 0, 55\n",
      "value_exit: 0, 55, 55, 0, 0, 55\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 255/1000 --- L(Train): 0.3951344 --- L(Val, RNN): 0.3366409 --- L(Val, SINDy): 0.3402516 --- Time: 0.82s; --- Convergence: 9.23e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 55/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.241 1 + 0.464 value_stay[t] + 0.172 reward + -0.009 harvest_duration + 0.135 value_stay^2 + 0.157 value_stay*reward + -0.393 value_stay*harvest_duration + 0.697 reward^2 + 0.176 reward*harvest_duration + -0.011 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.993 value_exit[t] + -0.016 travel_duration + 0.052 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 56, 0, 0, 0, 0, 0, 56\n",
      "value_exit: 0, 56, 56, 0, 0, 56\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 256/1000 --- L(Train): 0.4093504 --- L(Val, RNN): 0.3367124 --- L(Val, SINDy): 0.3402778 --- Time: 0.93s; --- Convergence: 8.20e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 56/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.242 1 + 0.464 value_stay[t] + 0.171 reward + -0.009 harvest_duration + 0.135 value_stay^2 + 0.157 value_stay*reward + -0.394 value_stay*harvest_duration + 0.697 reward^2 + 0.176 reward*harvest_duration + -0.011 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.993 value_exit[t] + -0.016 travel_duration + 0.052 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 57, 0, 0, 0, 0, 0, 57\n",
      "value_exit: 0, 57, 57, 0, 0, 57\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 257/1000 --- L(Train): 0.4095838 --- L(Val, RNN): 0.3367396 --- L(Val, SINDy): 0.3400997 --- Time: 0.88s; --- Convergence: 5.46e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 57/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.243 1 + 0.464 value_stay[t] + 0.171 reward + -0.009 harvest_duration + 0.135 value_stay^2 + 0.158 value_stay*reward + -0.394 value_stay*harvest_duration + 0.698 reward^2 + 0.175 reward*harvest_duration + -0.011 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.993 value_exit[t] + -0.015 travel_duration + 0.052 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 58, 0, 0, 0, 0, 0, 58\n",
      "value_exit: 0, 58, 58, 0, 0, 58\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 258/1000 --- L(Train): 0.3910172 --- L(Val, RNN): 0.3365801 --- L(Val, SINDy): 0.3400141 --- Time: 0.92s; --- Convergence: 1.07e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 58/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.244 1 + 0.464 value_stay[t] + 0.17 reward + -0.01 harvest_duration + 0.135 value_stay^2 + 0.158 value_stay*reward + -0.395 value_stay*harvest_duration + 0.698 reward^2 + 0.175 reward*harvest_duration + -0.012 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 0.991 value_exit[t] + -0.014 travel_duration + 0.054 value_exit^2 + -0.103 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 59, 0, 0, 0, 0, 0, 59\n",
      "value_exit: 0, 59, 59, 0, 0, 59\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 259/1000 --- L(Train): 0.3974985 --- L(Val, RNN): 0.3364162 --- L(Val, SINDy): 0.3401904 --- Time: 0.90s; --- Convergence: 1.35e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 59/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.246 1 + 0.465 value_stay[t] + 0.171 reward + -0.009 harvest_duration + 0.136 value_stay^2 + 0.161 value_stay*reward + -0.395 value_stay*harvest_duration + 0.699 reward^2 + 0.176 reward*harvest_duration + -0.011 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 0.992 value_exit[t] + -0.014 travel_duration + 0.054 value_exit^2 + -0.102 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 60, 0, 0, 0, 0, 0, 60\n",
      "value_exit: 0, 60, 60, 0, 0, 60\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 260/1000 --- L(Train): 0.4178391 --- L(Val, RNN): 0.3361446 --- L(Val, SINDy): 0.3402289 --- Time: 0.79s; --- Convergence: 2.04e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 60/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.246 1 + 0.463 value_stay[t] + 0.17 reward + -0.01 harvest_duration + 0.135 value_stay^2 + 0.161 value_stay*reward + -0.397 value_stay*harvest_duration + 0.699 reward^2 + 0.175 reward*harvest_duration + -0.012 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.993 value_exit[t] + -0.015 travel_duration + 0.052 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 61, 0, 0, 0, 0, 0, 61\n",
      "value_exit: 0, 61, 61, 0, 0, 61\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 261/1000 --- L(Train): 0.4142573 --- L(Val, RNN): 0.3359531 --- L(Val, SINDy): 0.3400510 --- Time: 1.13s; --- Convergence: 1.98e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 61/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.245 1 + 0.461 value_stay[t] + 0.169 reward + -0.011 harvest_duration + 0.133 value_stay^2 + 0.16 value_stay*reward + -0.399 value_stay*harvest_duration + 0.698 reward^2 + 0.173 reward*harvest_duration + -0.013 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.994 value_exit[t] + -0.015 travel_duration + 0.051 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 62, 0, 0, 0, 0, 0, 62\n",
      "value_exit: 0, 62, 62, 0, 0, 62\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 262/1000 --- L(Train): 0.3982800 --- L(Val, RNN): 0.3360634 --- L(Val, SINDy): 0.3401947 --- Time: 0.88s; --- Convergence: 1.54e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 62/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.246 1 + 0.46 value_stay[t] + 0.169 reward + -0.011 harvest_duration + 0.132 value_stay^2 + 0.161 value_stay*reward + -0.4 value_stay*harvest_duration + 0.699 reward^2 + 0.173 reward*harvest_duration + -0.013 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.993 value_exit[t] + -0.015 travel_duration + 0.052 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 63, 0, 0, 0, 0, 0, 63\n",
      "value_exit: 0, 63, 63, 0, 0, 63\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 263/1000 --- L(Train): 0.3953603 --- L(Val, RNN): 0.3360024 --- L(Val, SINDy): 0.3398199 --- Time: 1.09s; --- Convergence: 1.07e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 63/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.246 1 + 0.459 value_stay[t] + 0.168 reward + -0.011 harvest_duration + 0.13 value_stay^2 + 0.161 value_stay*reward + -0.402 value_stay*harvest_duration + 0.699 reward^2 + 0.172 reward*harvest_duration + -0.013 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.992 value_exit[t] + -0.014 travel_duration + 0.053 value_exit^2 + -0.102 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 64, 0, 0, 0, 0, 0, 64\n",
      "value_exit: 0, 64, 64, 0, 0, 64\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 264/1000 --- L(Train): 0.4097185 --- L(Val, RNN): 0.3359258 --- L(Val, SINDy): 0.3394373 --- Time: 0.94s; --- Convergence: 9.20e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 64/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.247 1 + 0.458 value_stay[t] + 0.168 reward + -0.01 harvest_duration + 0.13 value_stay^2 + 0.162 value_stay*reward + -0.402 value_stay*harvest_duration + 0.7 reward^2 + 0.172 reward*harvest_duration + -0.012 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.992 value_exit[t] + -0.014 travel_duration + 0.053 value_exit^2 + -0.102 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 65, 0, 0, 0, 0, 0, 65\n",
      "value_exit: 0, 65, 65, 0, 0, 65\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 265/1000 --- L(Train): 0.4087511 --- L(Val, RNN): 0.3358991 --- L(Val, SINDy): 0.3392429 --- Time: 0.84s; --- Convergence: 5.94e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 65/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.249 1 + 0.459 value_stay[t] + 0.169 reward + -0.008 harvest_duration + 0.131 value_stay^2 + 0.164 value_stay*reward + -0.401 value_stay*harvest_duration + 0.702 reward^2 + 0.174 reward*harvest_duration + -0.01 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.994 value_exit[t] + -0.015 travel_duration + 0.051 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 66, 0, 0, 0, 0, 0, 66\n",
      "value_exit: 0, 66, 66, 0, 0, 66\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 266/1000 --- L(Train): 0.4072311 --- L(Val, RNN): 0.3357196 --- L(Val, SINDy): 0.3395881 --- Time: 1.16s; --- Convergence: 1.19e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 66/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.25 1 + 0.459 value_stay[t] + 0.17 reward + -0.006 harvest_duration + 0.131 value_stay^2 + 0.165 value_stay*reward + -0.401 value_stay*harvest_duration + 0.703 reward^2 + 0.174 reward*harvest_duration + -0.008 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.995 value_exit[t] + -0.016 travel_duration + 0.05 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 67, 0, 0, 0, 0, 0, 67\n",
      "value_exit: 0, 67, 67, 1, 0, 67\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 267/1000 --- L(Train): 0.3912229 --- L(Val, RNN): 0.3357886 --- L(Val, SINDy): 0.3386891 --- Time: 0.90s; --- Convergence: 9.42e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 67/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.251 1 + 0.458 value_stay[t] + 0.17 reward + -0.005 harvest_duration + 0.13 value_stay^2 + 0.166 value_stay*reward + -0.401 value_stay*harvest_duration + 0.704 reward^2 + 0.174 reward*harvest_duration + -0.007 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.996 value_exit[t] + -0.016 travel_duration + 0.049 value_exit^2 + -0.099 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 68, 0, 0, 0, 0, 0, 68\n",
      "value_exit: 0, 68, 68, 2, 0, 68\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 268/1000 --- L(Train): 0.4034178 --- L(Val, RNN): 0.3357879 --- L(Val, SINDy): 0.3385125 --- Time: 1.03s; --- Convergence: 4.75e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 68/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.25 1 + 0.456 value_stay[t] + 0.168 reward + -0.005 harvest_duration + 0.128 value_stay^2 + 0.165 value_stay*reward + -0.403 value_stay*harvest_duration + 0.703 reward^2 + 0.172 reward*harvest_duration + -0.007 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.995 value_exit[t] + -0.015 travel_duration + 0.05 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 69, 0, 0, 0, 0, 0, 69\n",
      "value_exit: 0, 69, 69, 0, 0, 69\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 269/1000 --- L(Train): 0.3969114 --- L(Val, RNN): 0.3356634 --- L(Val, SINDy): 0.3389864 --- Time: 1.05s; --- Convergence: 8.60e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 69/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.247 1 + 0.451 value_stay[t] + 0.164 reward + -0.008 harvest_duration + 0.123 value_stay^2 + 0.162 value_stay*reward + -0.407 value_stay*harvest_duration + 0.7 reward^2 + 0.168 reward*harvest_duration + -0.01 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.993 value_exit[t] + -0.013 travel_duration + 0.052 value_exit^2 + -0.102 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 70, 0, 0, 0, 0, 0, 70\n",
      "value_exit: 0, 70, 70, 0, 0, 70\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 270/1000 --- L(Train): 0.3909675 --- L(Val, RNN): 0.3354580 --- L(Val, SINDy): 0.3395458 --- Time: 1.02s; --- Convergence: 1.46e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 70/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.248 1 + 0.451 value_stay[t] + 0.164 reward + -0.007 harvest_duration + 0.123 value_stay^2 + 0.164 value_stay*reward + -0.407 value_stay*harvest_duration + 0.701 reward^2 + 0.168 reward*harvest_duration + -0.009 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.993 value_exit[t] + -0.013 travel_duration + 0.052 value_exit^2 + -0.102 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 71, 0, 0, 0, 0, 0, 71\n",
      "value_exit: 0, 71, 71, 0, 0, 71\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 271/1000 --- L(Train): 0.3883924 --- L(Val, RNN): 0.3353890 --- L(Val, SINDy): 0.3393134 --- Time: 0.86s; --- Convergence: 1.07e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 71/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.25 1 + 0.452 value_stay[t] + 0.166 reward + -0.005 harvest_duration + 0.124 value_stay^2 + 0.167 value_stay*reward + -0.405 value_stay*harvest_duration + 0.703 reward^2 + 0.17 reward*harvest_duration + -0.007 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.995 value_exit[t] + -0.015 travel_duration + 0.05 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 72, 0, 0, 0, 0, 0, 72\n",
      "value_exit: 0, 72, 72, 0, 0, 72\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 272/1000 --- L(Train): 0.3950132 --- L(Val, RNN): 0.3353010 --- L(Val, SINDy): 0.3390819 --- Time: 1.11s; --- Convergence: 9.77e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 72/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.252 1 + 0.453 value_stay[t] + 0.166 reward + -0.003 harvest_duration + 0.125 value_stay^2 + 0.169 value_stay*reward + -0.404 value_stay*harvest_duration + 0.704 reward^2 + 0.17 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.996 value_exit[t] + -0.016 travel_duration + 0.049 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 73, 0, 0, 0, 0, 0, 73\n",
      "value_exit: 0, 73, 73, 1, 0, 73\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 273/1000 --- L(Train): 0.3924995 --- L(Val, RNN): 0.3352695 --- L(Val, SINDy): 0.3387547 --- Time: 0.98s; --- Convergence: 6.46e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 73/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.252 1 + 0.452 value_stay[t] + 0.166 reward + -0.003 harvest_duration + 0.124 value_stay^2 + 0.17 value_stay*reward + -0.404 value_stay*harvest_duration + 0.704 reward^2 + 0.17 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.016 travel_duration + 0.049 value_exit^2 + -0.099 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 74, 0, 0, 0, 0, 0, 74\n",
      "value_exit: 0, 74, 74, 2, 0, 74\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 274/1000 --- L(Train): 0.3953518 --- L(Val, RNN): 0.3350610 --- L(Val, SINDy): 0.3390274 --- Time: 0.80s; --- Convergence: 1.37e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 74/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.251 1 + 0.45 value_stay[t] + 0.164 reward + -0.004 harvest_duration + 0.123 value_stay^2 + 0.169 value_stay*reward + -0.406 value_stay*harvest_duration + 0.703 reward^2 + 0.168 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.995 value_exit[t] + -0.015 travel_duration + 0.05 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 75, 0, 0, 0, 0, 0, 75\n",
      "value_exit: 0, 75, 75, 3, 0, 75\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 275/1000 --- L(Train): 0.3966038 --- L(Val, RNN): 0.3350385 --- L(Val, SINDy): 0.3376936 --- Time: 0.89s; --- Convergence: 7.95e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 75/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.25 1 + 0.448 value_stay[t] + 0.162 reward + -0.005 harvest_duration + 0.121 value_stay^2 + 0.168 value_stay*reward + -0.408 value_stay*harvest_duration + 0.702 reward^2 + 0.166 reward*harvest_duration + -0.007 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.994 value_exit[t] + -0.014 travel_duration + 0.051 value_exit^2 + -0.102 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 76, 0, 0, 0, 0, 0, 76\n",
      "value_exit: 0, 76, 76, 0, 0, 76\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 276/1000 --- L(Train): 0.3907987 --- L(Val, RNN): 0.3348608 --- L(Val, SINDy): 0.3378172 --- Time: 1.58s; --- Convergence: 1.29e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 76/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.249 1 + 0.447 value_stay[t] + 0.16 reward + -0.006 harvest_duration + 0.12 value_stay^2 + 0.168 value_stay*reward + -0.409 value_stay*harvest_duration + 0.7 reward^2 + 0.164 reward*harvest_duration + -0.008 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.995 value_exit[t] + -0.014 travel_duration + 0.05 value_exit^2 + -0.102 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 77, 0, 0, 0, 0, 0, 77\n",
      "value_exit: 0, 77, 77, 0, 0, 77\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 277/1000 --- L(Train): 0.3966623 --- L(Val, RNN): 0.3346118 --- L(Val, SINDy): 0.3383250 --- Time: 1.58s; --- Convergence: 1.89e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 77/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.249 1 + 0.446 value_stay[t] + 0.159 reward + -0.005 harvest_duration + 0.12 value_stay^2 + 0.169 value_stay*reward + -0.409 value_stay*harvest_duration + 0.7 reward^2 + 0.163 reward*harvest_duration + -0.007 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.996 value_exit[t] + -0.015 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 78, 0, 0, 0, 0, 0, 78\n",
      "value_exit: 0, 78, 78, 1, 0, 78\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 278/1000 --- L(Train): 0.3937236 --- L(Val, RNN): 0.3346241 --- L(Val, SINDy): 0.3381226 --- Time: 4.97s; --- Convergence: 1.01e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 78/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.251 1 + 0.448 value_stay[t] + 0.16 reward + -0.004 harvest_duration + 0.122 value_stay^2 + 0.172 value_stay*reward + -0.408 value_stay*harvest_duration + 0.702 reward^2 + 0.164 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.016 travel_duration + 0.049 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 79, 0, 0, 0, 0, 0, 79\n",
      "value_exit: 0, 79, 79, 2, 0, 79\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 279/1000 --- L(Train): 0.3813202 --- L(Val, RNN): 0.3347065 --- L(Val, SINDy): 0.3381020 --- Time: 5.31s; --- Convergence: 9.15e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 79/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.252 1 + 0.448 value_stay[t] + 0.16 reward + -0.003 harvest_duration + 0.123 value_stay^2 + 0.174 value_stay*reward + -0.407 value_stay*harvest_duration + 0.702 reward^2 + 0.164 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.996 value_exit[t] + -0.015 travel_duration + 0.049 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 80, 0, 0, 0, 0, 0, 80\n",
      "value_exit: 0, 80, 80, 3, 0, 80\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 280/1000 --- L(Train): 0.3823008 --- L(Val, RNN): 0.3347776 --- L(Val, SINDy): 0.3381369 --- Time: 3.78s; --- Convergence: 8.13e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 80/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.252 1 + 0.448 value_stay[t] + 0.159 reward + -0.003 harvest_duration + 0.123 value_stay^2 + 0.175 value_stay*reward + -0.407 value_stay*harvest_duration + 0.702 reward^2 + 0.163 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.996 value_exit[t] + -0.014 travel_duration + 0.05 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 81, 0, 0, 0, 0, 0, 81\n",
      "value_exit: 0, 81, 81, 4, 0, 81\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 281/1000 --- L(Train): 0.3869972 --- L(Val, RNN): 0.3346428 --- L(Val, SINDy): 0.3377096 --- Time: 3.67s; --- Convergence: 1.08e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 81/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.251 1 + 0.447 value_stay[t] + 0.157 reward + -0.004 harvest_duration + 0.122 value_stay^2 + 0.175 value_stay*reward + -0.408 value_stay*harvest_duration + 0.701 reward^2 + 0.161 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.995 value_exit[t] + -0.014 travel_duration + 0.05 value_exit^2 + -0.102 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 82, 0, 0, 0, 0, 0, 82\n",
      "value_exit: 0, 82, 82, 0, 0, 82\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 282/1000 --- L(Train): 0.3909203 --- L(Val, RNN): 0.3345253 --- L(Val, SINDy): 0.3388458 --- Time: 2.74s; --- Convergence: 1.13e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 82/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.251 1 + 0.447 value_stay[t] + 0.156 reward + -0.004 harvest_duration + 0.122 value_stay^2 + 0.176 value_stay*reward + -0.408 value_stay*harvest_duration + 0.701 reward^2 + 0.16 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.995 value_exit[t] + -0.014 travel_duration + 0.05 value_exit^2 + -0.102 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 83, 0, 0, 0, 0, 0, 83\n",
      "value_exit: 0, 83, 83, 0, 0, 83\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 283/1000 --- L(Train): 0.3836643 --- L(Val, RNN): 0.3345347 --- L(Val, SINDy): 0.3386226 --- Time: 2.12s; --- Convergence: 6.11e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 83/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.253 1 + 0.448 value_stay[t] + 0.156 reward + -0.003 harvest_duration + 0.124 value_stay^2 + 0.178 value_stay*reward + -0.407 value_stay*harvest_duration + 0.702 reward^2 + 0.161 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.996 value_exit[t] + -0.015 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 84, 0, 0, 0, 0, 0, 84\n",
      "value_exit: 0, 84, 84, 1, 0, 84\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 284/1000 --- L(Train): 0.3834963 --- L(Val, RNN): 0.3343023 --- L(Val, SINDy): 0.3379078 --- Time: 2.45s; --- Convergence: 1.47e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 84/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.252 1 + 0.447 value_stay[t] + 0.155 reward + -0.003 harvest_duration + 0.124 value_stay^2 + 0.178 value_stay*reward + -0.408 value_stay*harvest_duration + 0.701 reward^2 + 0.159 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.997 value_exit[t] + -0.016 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 85, 0, 0, 0, 0, 0, 85\n",
      "value_exit: 0, 85, 85, 2, 0, 85\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 285/1000 --- L(Train): 0.3842850 --- L(Val, RNN): 0.3345172 --- L(Val, SINDy): 0.3382327 --- Time: 3.86s; --- Convergence: 1.81e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 85/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.252 1 + 0.447 value_stay[t] + 0.154 reward + -0.003 harvest_duration + 0.124 value_stay^2 + 0.179 value_stay*reward + -0.408 value_stay*harvest_duration + 0.7 reward^2 + 0.158 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.997 value_exit[t] + -0.016 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 86, 0, 0, 0, 0, 0, 86\n",
      "value_exit: 0, 86, 86, 3, 0, 86\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 286/1000 --- L(Train): 0.3910502 --- L(Val, RNN): 0.3346549 --- L(Val, SINDy): 0.3379798 --- Time: 3.08s; --- Convergence: 1.59e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 86/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.252 1 + 0.446 value_stay[t] + 0.153 reward + -0.003 harvest_duration + 0.123 value_stay^2 + 0.179 value_stay*reward + -0.408 value_stay*harvest_duration + 0.7 reward^2 + 0.157 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.997 value_exit[t] + -0.016 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 87, 0, 0, 0, 0, 0, 87\n",
      "value_exit: 0, 87, 87, 4, 0, 87\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 287/1000 --- L(Train): 0.3877548 --- L(Val, RNN): 0.3343971 --- L(Val, SINDy): 0.3379901 --- Time: 3.38s; --- Convergence: 2.09e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 87/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.252 1 + 0.445 value_stay[t] + 0.152 reward + -0.003 harvest_duration + 0.123 value_stay^2 + 0.179 value_stay*reward + -0.408 value_stay*harvest_duration + 0.699 reward^2 + 0.156 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.015 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 88, 0, 0, 0, 0, 0, 88\n",
      "value_exit: 0, 88, 88, 5, 0, 88\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 288/1000 --- L(Train): 0.3922175 --- L(Val, RNN): 0.3343978 --- L(Val, SINDy): 0.3375506 --- Time: 2.40s; --- Convergence: 1.05e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 88/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.254 1 + 0.446 value_stay[t] + 0.152 reward + -0.001 harvest_duration + 0.125 value_stay^2 + 0.181 value_stay*reward + -0.407 value_stay*harvest_duration + 0.7 reward^2 + 0.156 reward*harvest_duration + -0.003 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.996 value_exit[t] + -0.015 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 89, 0, 0, 0, 0, 0, 89\n",
      "value_exit: 0, 89, 89, 6, 0, 89\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 289/1000 --- L(Train): 0.3916637 --- L(Val, RNN): 0.3345414 --- L(Val, SINDy): 0.3386424 --- Time: 2.55s; --- Convergence: 1.24e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 89/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.255 1 + 0.448 value_stay[t] + 0.153 reward + 0.0 harvest_duration + 0.126 value_stay^2 + 0.183 value_stay*reward + -0.406 value_stay*harvest_duration + 0.702 reward^2 + 0.157 reward*harvest_duration + -0.002 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.996 value_exit[t] + -0.014 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 90, 0, 0, 0, 0, 0, 90\n",
      "value_exit: 0, 90, 90, 7, 0, 90\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 290/1000 --- L(Train): 0.3904198 --- L(Val, RNN): 0.3345659 --- L(Val, SINDy): 0.3376216 --- Time: 2.77s; --- Convergence: 7.43e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 90/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.256 1 + 0.448 value_stay[t] + 0.154 reward + 0.001 harvest_duration + 0.127 value_stay^2 + 0.185 value_stay*reward + -0.405 value_stay*harvest_duration + 0.703 reward^2 + 0.158 reward*harvest_duration + -0.001 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.996 value_exit[t] + -0.015 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 91, 0, 0, 0, 0, 0, 91\n",
      "value_exit: 0, 91, 91, 8, 0, 91\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 291/1000 --- L(Train): 0.3851419 --- L(Val, RNN): 0.3344281 --- L(Val, SINDy): 0.3374900 --- Time: 2.19s; --- Convergence: 1.06e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 91/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.257 1 + 0.448 value_stay[t] + 0.153 reward + 0.002 harvest_duration + 0.127 value_stay^2 + 0.186 value_stay*reward + -0.405 value_stay*harvest_duration + 0.703 reward^2 + 0.157 reward*harvest_duration + -0.0 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.015 travel_duration + 0.048 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 92, 0, 0, 0, 0, 0, 92\n",
      "value_exit: 0, 92, 92, 9, 0, 92\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 292/1000 --- L(Train): 0.3836258 --- L(Val, RNN): 0.3343716 --- L(Val, SINDy): 0.3382090 --- Time: 1.01s; --- Convergence: 8.13e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 92/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.256 1 + 0.446 value_stay[t] + 0.151 reward + 0.0 harvest_duration + 0.126 value_stay^2 + 0.185 value_stay*reward + -0.406 value_stay*harvest_duration + 0.702 reward^2 + 0.155 reward*harvest_duration + -0.002 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.015 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 93, 0, 0, 0, 0, 0, 93\n",
      "value_exit: 0, 93, 93, 10, 0, 93\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 293/1000 --- L(Train): 0.3974268 --- L(Val, RNN): 0.3342558 --- L(Val, SINDy): 0.3383515 --- Time: 1.19s; --- Convergence: 9.86e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 93/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.254 1 + 0.444 value_stay[t] + 0.149 reward + -0.001 harvest_duration + 0.124 value_stay^2 + 0.184 value_stay*reward + -0.408 value_stay*harvest_duration + 0.7 reward^2 + 0.153 reward*harvest_duration + -0.003 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.997 value_exit[t] + -0.015 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 94, 0, 0, 0, 0, 0, 94\n",
      "value_exit: 0, 94, 94, 11, 0, 94\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 294/1000 --- L(Train): 0.3940150 --- L(Val, RNN): 0.3342577 --- L(Val, SINDy): 0.3377537 --- Time: 1.11s; --- Convergence: 5.03e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 94/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.254 1 + 0.444 value_stay[t] + 0.148 reward + -0.001 harvest_duration + 0.124 value_stay^2 + 0.184 value_stay*reward + -0.409 value_stay*harvest_duration + 0.7 reward^2 + 0.152 reward*harvest_duration + -0.003 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.015 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 95, 0, 0, 0, 0, 0, 95\n",
      "value_exit: 0, 95, 95, 12, 0, 95\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 295/1000 --- L(Train): 0.3884927 --- L(Val, RNN): 0.3341983 --- L(Val, SINDy): 0.3385646 --- Time: 0.97s; --- Convergence: 5.48e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 95/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.256 1 + 0.445 value_stay[t] + 0.149 reward + 0.0 harvest_duration + 0.126 value_stay^2 + 0.187 value_stay*reward + -0.407 value_stay*harvest_duration + 0.702 reward^2 + 0.154 reward*harvest_duration + -0.002 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.015 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 96, 0, 0, 0, 0, 0, 96\n",
      "value_exit: 0, 96, 96, 13, 0, 96\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 296/1000 --- L(Train): 0.3879983 --- L(Val, RNN): 0.3341958 --- L(Val, SINDy): 0.3381571 --- Time: 1.27s; --- Convergence: 2.87e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 96/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.258 1 + 0.447 value_stay[t] + 0.151 reward + 0.002 harvest_duration + 0.128 value_stay^2 + 0.189 value_stay*reward + -0.406 value_stay*harvest_duration + 0.704 reward^2 + 0.155 reward*harvest_duration + -0.0 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.996 value_exit[t] + -0.015 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 97, 0, 0, 0, 0, 0, 97\n",
      "value_exit: 0, 97, 97, 14, 0, 97\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 297/1000 --- L(Train): 0.3982072 --- L(Val, RNN): 0.3343278 --- L(Val, SINDy): 0.3374274 --- Time: 0.99s; --- Convergence: 8.04e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 97/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.257 1 + 0.446 value_stay[t] + 0.15 reward + 0.0 harvest_duration + 0.127 value_stay^2 + 0.189 value_stay*reward + -0.407 value_stay*harvest_duration + 0.704 reward^2 + 0.154 reward*harvest_duration + -0.002 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.015 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 98, 0, 0, 0, 0, 0, 98\n",
      "value_exit: 0, 98, 98, 15, 0, 98\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 298/1000 --- L(Train): 0.4078288 --- L(Val, RNN): 0.3342167 --- L(Val, SINDy): 0.3377714 --- Time: 0.98s; --- Convergence: 9.57e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 98/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.256 1 + 0.444 value_stay[t] + 0.148 reward + -0.002 harvest_duration + 0.125 value_stay^2 + 0.189 value_stay*reward + -0.409 value_stay*harvest_duration + 0.702 reward^2 + 0.152 reward*harvest_duration + -0.004 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.015 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 99, 0, 0, 0, 0, 0, 99\n",
      "value_exit: 0, 99, 99, 16, 0, 99\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 299/1000 --- L(Train): 0.3983968 --- L(Val, RNN): 0.3341685 --- L(Val, SINDy): 0.3374518 --- Time: 1.10s; --- Convergence: 7.20e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 99/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 15):\n",
      "value_stay[t+1] = 0.256 1 + 0.444 value_stay[t] + 0.148 reward + 0.126 value_stay^2 + 0.19 value_stay*reward + -0.409 value_stay*harvest_duration + 0.703 reward^2 + 0.152 reward*harvest_duration + -0.004 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.997 value_exit[t] + -0.015 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, 100\n",
      "value_exit: 0, 100, 100, 17, 0, 100\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 300/1000 --- L(Train): 1.1520814 --- L(Val, RNN): 0.3352242 --- L(Val, SINDy): 0.3553483 --- Time: 0.83s; --- Convergence: 5.64e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 14):\n",
      "value_stay[t+1] = 0.257 1 + 0.445 value_stay[t] + 0.148 reward + 0.127 value_stay^2 + 0.192 value_stay*reward + -0.408 value_stay*harvest_duration + 0.704 reward^2 + 0.152 reward*harvest_duration + -0.003 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 1.0 value_exit[t] + -0.015 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, 101\n",
      "value_exit: 0, -, 101, 18, 0, 101\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 301/1000 --- L(Train): 2.3231125 --- L(Val, RNN): 0.3360482 --- L(Val, SINDy): 0.3984447 --- Time: 0.85s; --- Convergence: 6.94e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 1/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 13):\n",
      "value_stay[t+1] = 0.258 1 + 0.446 value_stay[t] + 0.149 reward + 0.129 value_stay^2 + 0.194 value_stay*reward + -0.407 value_stay*harvest_duration + 0.705 reward^2 + 0.153 reward*harvest_duration \n",
      "value_exit[t+1] = -0.082 1 + 1.0 value_exit[t] + -0.015 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, 102, 19, 0, 102\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 302/1000 --- L(Train): 2.6778023 --- L(Val, RNN): 0.3368646 --- L(Val, SINDy): 0.4243608 --- Time: 1.10s; --- Convergence: 7.55e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 2/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_stay[t+1] = 0.259 1 + 0.447 value_stay[t] + 0.15 reward + 0.13 value_stay^2 + 0.196 value_stay*reward + -0.406 value_stay*harvest_duration + 0.707 reward^2 + 0.154 reward*harvest_duration \n",
      "value_exit[t+1] = -0.081 1 + 1.0 value_exit[t] + -0.014 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, 103, 20, 0, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 303/1000 --- L(Train): 2.7547169 --- L(Val, RNN): 0.3375870 --- L(Val, SINDy): 0.4403746 --- Time: 0.98s; --- Convergence: 7.39e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 3/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 11):\n",
      "value_stay[t+1] = 0.26 1 + 0.447 value_stay[t] + 0.15 reward + 0.131 value_stay^2 + 0.198 value_stay*reward + -0.406 value_stay*harvest_duration + 0.708 reward^2 + 0.154 reward*harvest_duration \n",
      "value_exit[t+1] = -0.087 1 + 1.0 value_exit[t] + 0.044 value_exit^2 + -0.096 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 21, 0, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 304/1000 --- L(Train): 2.2402971 --- L(Val, RNN): 0.3383176 --- L(Val, SINDy): 0.4382166 --- Time: 0.91s; --- Convergence: 7.35e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 4/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 11):\n",
      "value_stay[t+1] = 0.261 1 + 0.448 value_stay[t] + 0.151 reward + 0.132 value_stay^2 + 0.2 value_stay*reward + -0.405 value_stay*harvest_duration + 0.709 reward^2 + 0.156 reward*harvest_duration \n",
      "value_exit[t+1] = -0.096 1 + 1.0 value_exit[t] + 0.035 value_exit^2 + -0.087 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 22, 0, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 305/1000 --- L(Train): 1.7055143 --- L(Val, RNN): 0.3392475 --- L(Val, SINDy): 0.4323960 --- Time: 1.02s; --- Convergence: 8.32e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 5/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 11):\n",
      "value_stay[t+1] = 0.262 1 + 0.449 value_stay[t] + 0.154 reward + 0.134 value_stay^2 + 0.204 value_stay*reward + -0.404 value_stay*harvest_duration + 0.712 reward^2 + 0.158 reward*harvest_duration \n",
      "value_exit[t+1] = -0.108 1 + 1.0 value_exit[t] + 0.024 value_exit^2 + -0.075 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 23, 0, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 306/1000 --- L(Train): 1.2679596 --- L(Val, RNN): 0.3406608 --- L(Val, SINDy): 0.4221447 --- Time: 0.96s; --- Convergence: 1.12e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 6/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.264 1 + 0.451 value_stay[t] + 0.156 reward + 0.137 value_stay^2 + 0.208 value_stay*reward + -0.402 value_stay*harvest_duration + 0.715 reward^2 + 0.16 reward*harvest_duration \n",
      "value_exit[t+1] = -0.122 1 + 1.0 value_exit[t] + 0.01 value_exit^2 + -0.061 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 24, 0, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 307/1000 --- L(Train): 0.9231516 --- L(Val, RNN): 0.3421144 --- L(Val, SINDy): 0.4473107 --- Time: 1.02s; --- Convergence: 1.29e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 7/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.262 1 + 0.45 value_stay[t] + 0.157 reward + 0.136 value_stay^2 + 0.211 value_stay*reward + -0.401 value_stay*harvest_duration + 0.716 reward^2 + 0.161 reward*harvest_duration \n",
      "value_exit[t+1] = -0.138 1 + 1.0 value_exit[t] + -0.004 value_exit^2 + -0.045 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 25, 1, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 308/1000 --- L(Train): 0.6688848 --- L(Val, RNN): 0.3434555 --- L(Val, SINDy): 0.5171546 --- Time: 0.99s; --- Convergence: 1.31e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 8/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.257 1 + 0.444 value_stay[t] + 0.154 reward + 0.132 value_stay^2 + 0.209 value_stay*reward + -0.405 value_stay*harvest_duration + 0.714 reward^2 + 0.158 reward*harvest_duration \n",
      "value_exit[t+1] = -0.155 1 + 1.0 value_exit[t] + -0.02 value_exit^2 + -0.028 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 26, 2, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 309/1000 --- L(Train): 0.5472672 --- L(Val, RNN): 0.3459631 --- L(Val, SINDy): 0.6779090 --- Time: 1.10s; --- Convergence: 1.91e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 9/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.254 1 + 0.443 value_stay[t] + 0.155 reward + 0.131 value_stay^2 + 0.212 value_stay*reward + -0.405 value_stay*harvest_duration + 0.715 reward^2 + 0.159 reward*harvest_duration \n",
      "value_exit[t+1] = -0.17 1 + 1.0 value_exit[t] + -0.034 value_exit^2 + -0.012 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 27, 3, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 310/1000 --- L(Train): 0.5296525 --- L(Val, RNN): 0.3457997 --- L(Val, SINDy): 0.8174689 --- Time: 0.92s; --- Convergence: 1.04e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 10/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.245 1 + 0.433 value_stay[t] + 0.146 reward + 0.122 value_stay^2 + 0.205 value_stay*reward + -0.414 value_stay*harvest_duration + 0.708 reward^2 + 0.151 reward*harvest_duration \n",
      "value_exit[t+1] = -0.176 1 + 1.0 value_exit[t] + -0.041 value_exit^2 + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 28, 4, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 311/1000 --- L(Train): 0.5662240 --- L(Val, RNN): 0.3496209 --- L(Val, SINDy): 0.9165456 --- Time: 0.87s; --- Convergence: 2.43e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 11/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.24 1 + 0.428 value_stay[t] + 0.142 reward + 0.118 value_stay^2 + 0.202 value_stay*reward + -0.418 value_stay*harvest_duration + 0.703 reward^2 + 0.147 reward*harvest_duration \n",
      "value_exit[t+1] = -0.18 1 + 1.0 value_exit[t] + -0.047 value_exit^2 + 0.009 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 29, 5, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 312/1000 --- L(Train): 0.6074606 --- L(Val, RNN): 0.3504353 --- L(Val, SINDy): 0.9122661 --- Time: 1.10s; --- Convergence: 1.62e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 12/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.242 1 + 0.43 value_stay[t] + 0.144 reward + 0.12 value_stay^2 + 0.206 value_stay*reward + -0.415 value_stay*harvest_duration + 0.705 reward^2 + 0.149 reward*harvest_duration \n",
      "value_exit[t+1] = -0.179 1 + 1.0 value_exit[t] + -0.047 value_exit^2 + 0.014 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 30, 6, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 313/1000 --- L(Train): 0.6215689 --- L(Val, RNN): 0.3504556 --- L(Val, SINDy): 0.8462824 --- Time: 0.88s; --- Convergence: 8.21e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 13/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.247 1 + 0.435 value_stay[t] + 0.149 reward + 0.125 value_stay^2 + 0.212 value_stay*reward + -0.409 value_stay*harvest_duration + 0.71 reward^2 + 0.154 reward*harvest_duration \n",
      "value_exit[t+1] = -0.171 1 + 1.0 value_exit[t] + -0.042 value_exit^2 + 0.012 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 31, 7, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 314/1000 --- L(Train): 0.6109530 --- L(Val, RNN): 0.3519282 --- L(Val, SINDy): 0.7780113 --- Time: 0.96s; --- Convergence: 1.15e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 14/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.256 1 + 0.444 value_stay[t] + 0.158 reward + 0.134 value_stay^2 + 0.221 value_stay*reward + -0.4 value_stay*harvest_duration + 0.718 reward^2 + 0.162 reward*harvest_duration \n",
      "value_exit[t+1] = -0.159 1 + 1.0 value_exit[t] + -0.034 value_exit^2 + 0.006 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 32, 8, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 315/1000 --- L(Train): 0.5885673 --- L(Val, RNN): 0.3552010 --- L(Val, SINDy): 0.7124249 --- Time: 0.84s; --- Convergence: 2.21e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 15/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.26 1 + 0.448 value_stay[t] + 0.162 reward + 0.137 value_stay^2 + 0.226 value_stay*reward + -0.395 value_stay*harvest_duration + 0.721 reward^2 + 0.166 reward*harvest_duration \n",
      "value_exit[t+1] = -0.147 1 + 1.0 value_exit[t] + -0.024 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 33, 9, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 316/1000 --- L(Train): 0.5366163 --- L(Val, RNN): 0.3575165 --- L(Val, SINDy): 0.6485744 --- Time: 0.94s; --- Convergence: 2.26e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 16/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.256 1 + 0.443 value_stay[t] + 0.156 reward + 0.132 value_stay^2 + 0.221 value_stay*reward + -0.4 value_stay*harvest_duration + 0.715 reward^2 + 0.16 reward*harvest_duration \n",
      "value_exit[t+1] = -0.133 1 + 1.0 value_exit[t] + -0.014 value_exit^2 + -0.01 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 34, 10, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 317/1000 --- L(Train): 0.5060468 --- L(Val, RNN): 0.3575545 --- L(Val, SINDy): 0.5771055 --- Time: 0.91s; --- Convergence: 1.15e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 17/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.249 1 + 0.435 value_stay[t] + 0.148 reward + 0.124 value_stay^2 + 0.213 value_stay*reward + -0.407 value_stay*harvest_duration + 0.706 reward^2 + 0.152 reward*harvest_duration \n",
      "value_exit[t+1] = -0.119 1 + 1.0 value_exit[t] + -0.003 value_exit^2 + -0.019 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 35, 11, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 318/1000 --- L(Train): 0.4826047 --- L(Val, RNN): 0.3586328 --- L(Val, SINDy): 0.5412547 --- Time: 0.91s; --- Convergence: 1.11e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 18/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.245 1 + 0.431 value_stay[t] + 0.143 reward + 0.12 value_stay^2 + 0.21 value_stay*reward + -0.411 value_stay*harvest_duration + 0.7 reward^2 + 0.147 reward*harvest_duration \n",
      "value_exit[t+1] = -0.106 1 + 1.0 value_exit[t] + 0.006 value_exit^2 + -0.027 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 36, 12, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 319/1000 --- L(Train): 0.4718719 --- L(Val, RNN): 0.3611810 --- L(Val, SINDy): 0.5337070 --- Time: 0.80s; --- Convergence: 1.83e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 19/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.245 1 + 0.432 value_stay[t] + 0.143 reward + 0.12 value_stay^2 + 0.21 value_stay*reward + -0.41 value_stay*harvest_duration + 0.699 reward^2 + 0.147 reward*harvest_duration \n",
      "value_exit[t+1] = -0.094 1 + 1.0 value_exit[t] + 0.015 value_exit^2 + -0.033 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 37, 13, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 320/1000 --- L(Train): 0.4638515 --- L(Val, RNN): 0.3635511 --- L(Val, SINDy): 0.5147980 --- Time: 0.81s; --- Convergence: 2.10e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 20/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.25 1 + 0.436 value_stay[t] + 0.146 reward + 0.125 value_stay^2 + 0.215 value_stay*reward + -0.405 value_stay*harvest_duration + 0.702 reward^2 + 0.15 reward*harvest_duration \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + 0.022 value_exit^2 + -0.037 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 38, 14, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 321/1000 --- L(Train): 0.4639621 --- L(Val, RNN): 0.3643679 --- L(Val, SINDy): 0.5056142 --- Time: 0.96s; --- Convergence: 1.46e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 21/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.253 1 + 0.44 value_stay[t] + 0.149 reward + 0.128 value_stay^2 + 0.219 value_stay*reward + -0.4 value_stay*harvest_duration + 0.704 reward^2 + 0.153 reward*harvest_duration \n",
      "value_exit[t+1] = -0.078 1 + 1.0 value_exit[t] + 0.028 value_exit^2 + -0.04 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 39, 15, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 322/1000 --- L(Train): 0.4566699 --- L(Val, RNN): 0.3649165 --- L(Val, SINDy): 0.5046097 --- Time: 1.17s; --- Convergence: 1.00e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 22/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.257 1 + 0.443 value_stay[t] + 0.152 reward + 0.132 value_stay^2 + 0.222 value_stay*reward + -0.396 value_stay*harvest_duration + 0.706 reward^2 + 0.156 reward*harvest_duration \n",
      "value_exit[t+1] = -0.072 1 + 1.0 value_exit[t] + 0.033 value_exit^2 + -0.042 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 40, 16, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 323/1000 --- L(Train): 0.4557136 --- L(Val, RNN): 0.3665542 --- L(Val, SINDy): 0.4979204 --- Time: 0.89s; --- Convergence: 1.32e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 23/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.261 1 + 0.447 value_stay[t] + 0.156 reward + 0.135 value_stay^2 + 0.226 value_stay*reward + -0.392 value_stay*harvest_duration + 0.709 reward^2 + 0.16 reward*harvest_duration \n",
      "value_exit[t+1] = -0.068 1 + 1.0 value_exit[t] + 0.037 value_exit^2 + -0.042 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 41, 17, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 324/1000 --- L(Train): 0.4534968 --- L(Val, RNN): 0.3689851 --- L(Val, SINDy): 0.4669539 --- Time: 1.13s; --- Convergence: 1.88e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 24/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.264 1 + 0.449 value_stay[t] + 0.158 reward + 0.136 value_stay^2 + 0.229 value_stay*reward + -0.389 value_stay*harvest_duration + 0.71 reward^2 + 0.162 reward*harvest_duration \n",
      "value_exit[t+1] = -0.066 1 + 1.0 value_exit[t] + 0.04 value_exit^2 + -0.041 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 42, 18, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 325/1000 --- L(Train): 0.4423286 --- L(Val, RNN): 0.3699670 --- L(Val, SINDy): 0.4570677 --- Time: 1.18s; --- Convergence: 1.43e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 25/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.263 1 + 0.448 value_stay[t] + 0.157 reward + 0.134 value_stay^2 + 0.228 value_stay*reward + -0.39 value_stay*harvest_duration + 0.708 reward^2 + 0.161 reward*harvest_duration \n",
      "value_exit[t+1] = -0.066 1 + 1.0 value_exit[t] + 0.041 value_exit^2 + -0.039 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 43, 19, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 326/1000 --- L(Train): 0.4407564 --- L(Val, RNN): 0.3698279 --- L(Val, SINDy): 0.4570597 --- Time: 1.29s; --- Convergence: 7.84e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 26/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.261 1 + 0.444 value_stay[t] + 0.154 reward + 0.13 value_stay^2 + 0.224 value_stay*reward + -0.392 value_stay*harvest_duration + 0.704 reward^2 + 0.158 reward*harvest_duration \n",
      "value_exit[t+1] = -0.067 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.035 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 44, 20, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 327/1000 --- L(Train): 0.4419249 --- L(Val, RNN): 0.3706358 --- L(Val, SINDy): 0.4636413 --- Time: 0.87s; --- Convergence: 7.96e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 27/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.258 1 + 0.44 value_stay[t] + 0.15 reward + 0.126 value_stay^2 + 0.22 value_stay*reward + -0.395 value_stay*harvest_duration + 0.7 reward^2 + 0.154 reward*harvest_duration \n",
      "value_exit[t+1] = -0.068 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.032 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 45, 21, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 328/1000 --- L(Train): 0.4299424 --- L(Val, RNN): 0.3725477 --- L(Val, SINDy): 0.4653551 --- Time: 0.90s; --- Convergence: 1.35e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 28/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.256 1 + 0.437 value_stay[t] + 0.148 reward + 0.122 value_stay^2 + 0.217 value_stay*reward + -0.398 value_stay*harvest_duration + 0.697 reward^2 + 0.152 reward*harvest_duration \n",
      "value_exit[t+1] = -0.071 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.028 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 46, 22, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 329/1000 --- L(Train): 0.4351868 --- L(Val, RNN): 0.3738073 --- L(Val, SINDy): 0.4677475 --- Time: 0.96s; --- Convergence: 1.31e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 29/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.256 1 + 0.436 value_stay[t] + 0.147 reward + 0.12 value_stay^2 + 0.216 value_stay*reward + -0.398 value_stay*harvest_duration + 0.695 reward^2 + 0.151 reward*harvest_duration \n",
      "value_exit[t+1] = -0.074 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.023 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 47, 23, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 330/1000 --- L(Train): 0.4309554 --- L(Val, RNN): 0.3739759 --- L(Val, SINDy): 0.4691229 --- Time: 1.00s; --- Convergence: 7.38e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 30/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.258 1 + 0.436 value_stay[t] + 0.148 reward + 0.119 value_stay^2 + 0.216 value_stay*reward + -0.397 value_stay*harvest_duration + 0.695 reward^2 + 0.152 reward*harvest_duration \n",
      "value_exit[t+1] = -0.077 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.018 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 48, 24, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 331/1000 --- L(Train): 0.4220161 --- L(Val, RNN): 0.3743378 --- L(Val, SINDy): 0.4666590 --- Time: 1.00s; --- Convergence: 5.50e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 31/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.261 1 + 0.438 value_stay[t] + 0.151 reward + 0.119 value_stay^2 + 0.218 value_stay*reward + -0.394 value_stay*harvest_duration + 0.697 reward^2 + 0.155 reward*harvest_duration \n",
      "value_exit[t+1] = -0.08 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.014 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 49, 25, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 332/1000 --- L(Train): 0.4227268 --- L(Val, RNN): 0.3750714 --- L(Val, SINDy): 0.4695570 --- Time: 0.98s; --- Convergence: 6.42e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 32/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.265 1 + 0.44 value_stay[t] + 0.154 reward + 0.121 value_stay^2 + 0.22 value_stay*reward + -0.391 value_stay*harvest_duration + 0.699 reward^2 + 0.158 reward*harvest_duration \n",
      "value_exit[t+1] = -0.082 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.01 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 50, 26, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 333/1000 --- L(Train): 0.4213771 --- L(Val, RNN): 0.3757006 --- L(Val, SINDy): 0.4769077 --- Time: 1.30s; --- Convergence: 6.35e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 33/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.27 1 + 0.444 value_stay[t] + 0.158 reward + 0.124 value_stay^2 + 0.224 value_stay*reward + -0.387 value_stay*harvest_duration + 0.703 reward^2 + 0.162 reward*harvest_duration \n",
      "value_exit[t+1] = -0.084 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.007 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 51, 27, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 334/1000 --- L(Train): 0.4166925 --- L(Val, RNN): 0.3759897 --- L(Val, SINDy): 0.4919677 --- Time: 0.96s; --- Convergence: 4.62e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 34/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.275 1 + 0.447 value_stay[t] + 0.162 reward + 0.125 value_stay^2 + 0.226 value_stay*reward + -0.383 value_stay*harvest_duration + 0.706 reward^2 + 0.166 reward*harvest_duration \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 52, 28, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 335/1000 --- L(Train): 0.4182623 --- L(Val, RNN): 0.3756913 --- L(Val, SINDy): 0.4963505 --- Time: 0.97s; --- Convergence: 3.80e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 35/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.279 1 + 0.45 value_stay[t] + 0.166 reward + 0.127 value_stay^2 + 0.229 value_stay*reward + -0.38 value_stay*harvest_duration + 0.709 reward^2 + 0.17 reward*harvest_duration \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 53, 29, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 336/1000 --- L(Train): 0.4148588 --- L(Val, RNN): 0.3756020 --- L(Val, SINDy): 0.4960997 --- Time: 1.08s; --- Convergence: 2.35e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 36/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.282 1 + 0.451 value_stay[t] + 0.167 reward + 0.127 value_stay^2 + 0.229 value_stay*reward + -0.378 value_stay*harvest_duration + 0.709 reward^2 + 0.171 reward*harvest_duration \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 54, 30, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 337/1000 --- L(Train): 0.4138311 --- L(Val, RNN): 0.3757301 --- L(Val, SINDy): 0.4933369 --- Time: 0.96s; --- Convergence: 1.81e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 37/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.282 1 + 0.45 value_stay[t] + 0.167 reward + 0.125 value_stay^2 + 0.228 value_stay*reward + -0.378 value_stay*harvest_duration + 0.709 reward^2 + 0.171 reward*harvest_duration \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + 0.044 value_exit^2 + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 55, 31, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 338/1000 --- L(Train): 0.4087628 --- L(Val, RNN): 0.3757549 --- L(Val, SINDy): 0.4896396 --- Time: 0.92s; --- Convergence: 1.03e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 38/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.283 1 + 0.448 value_stay[t] + 0.167 reward + 0.122 value_stay^2 + 0.226 value_stay*reward + -0.379 value_stay*harvest_duration + 0.707 reward^2 + 0.171 reward*harvest_duration \n",
      "value_exit[t+1] = -0.083 1 + 1.0 value_exit[t] + 0.045 value_exit^2 + 0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 56, 32, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 339/1000 --- L(Train): 0.4105177 --- L(Val, RNN): 0.3754927 --- L(Val, SINDy): 0.4892283 --- Time: 1.11s; --- Convergence: 1.83e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 39/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.283 1 + 0.447 value_stay[t] + 0.167 reward + 0.12 value_stay^2 + 0.225 value_stay*reward + -0.38 value_stay*harvest_duration + 0.707 reward^2 + 0.171 reward*harvest_duration \n",
      "value_exit[t+1] = -0.082 1 + 1.0 value_exit[t] + 0.046 value_exit^2 + 0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 57, 33, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 340/1000 --- L(Train): 0.4113697 --- L(Val, RNN): 0.3750161 --- L(Val, SINDy): 0.4873317 --- Time: 2.24s; --- Convergence: 3.30e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 40/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.284 1 + 0.446 value_stay[t] + 0.168 reward + 0.118 value_stay^2 + 0.225 value_stay*reward + -0.38 value_stay*harvest_duration + 0.707 reward^2 + 0.172 reward*harvest_duration \n",
      "value_exit[t+1] = -0.078 1 + 1.0 value_exit[t] + 0.047 value_exit^2 + 0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 58, 34, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 341/1000 --- L(Train): 0.4055852 --- L(Val, RNN): 0.3744906 --- L(Val, SINDy): 0.4837913 --- Time: 4.67s; --- Convergence: 4.28e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 41/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.285 1 + 0.445 value_stay[t] + 0.168 reward + 0.115 value_stay^2 + 0.224 value_stay*reward + -0.381 value_stay*harvest_duration + 0.708 reward^2 + 0.173 reward*harvest_duration \n",
      "value_exit[t+1] = -0.075 1 + 1.0 value_exit[t] + 0.048 value_exit^2 + 0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 59, 35, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 342/1000 --- L(Train): 0.4025204 --- L(Val, RNN): 0.3738575 --- L(Val, SINDy): 0.4817400 --- Time: 4.44s; --- Convergence: 5.30e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 42/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.285 1 + 0.443 value_stay[t] + 0.168 reward + 0.112 value_stay^2 + 0.222 value_stay*reward + -0.382 value_stay*harvest_duration + 0.707 reward^2 + 0.173 reward*harvest_duration \n",
      "value_exit[t+1] = -0.071 1 + 1.0 value_exit[t] + 0.05 value_exit^2 + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 60, 36, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 343/1000 --- L(Train): 0.4058847 --- L(Val, RNN): 0.3733142 --- L(Val, SINDy): 0.4795115 --- Time: 3.44s; --- Convergence: 5.37e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 43/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.285 1 + 0.441 value_stay[t] + 0.169 reward + 0.108 value_stay^2 + 0.221 value_stay*reward + -0.384 value_stay*harvest_duration + 0.706 reward^2 + 0.173 reward*harvest_duration \n",
      "value_exit[t+1] = -0.066 1 + 1.0 value_exit[t] + 0.051 value_exit^2 + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 0, 37, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 344/1000 --- L(Train): 0.4047338 --- L(Val, RNN): 0.3728246 --- L(Val, SINDy): 0.4785167 --- Time: 3.67s; --- Convergence: 5.13e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 44/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.286 1 + 0.44 value_stay[t] + 0.17 reward + 0.106 value_stay^2 + 0.221 value_stay*reward + -0.384 value_stay*harvest_duration + 0.707 reward^2 + 0.174 reward*harvest_duration \n",
      "value_exit[t+1] = -0.061 1 + 1.0 value_exit[t] + 0.053 value_exit^2 + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 0, 38, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 345/1000 --- L(Train): 0.4064340 --- L(Val, RNN): 0.3721532 --- L(Val, SINDy): 0.4783028 --- Time: 5.11s; --- Convergence: 5.92e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 45/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.287 1 + 0.439 value_stay[t] + 0.171 reward + 0.104 value_stay^2 + 0.222 value_stay*reward + -0.384 value_stay*harvest_duration + 0.708 reward^2 + 0.176 reward*harvest_duration \n",
      "value_exit[t+1] = -0.056 1 + 1.0 value_exit[t] + 0.055 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 0, 39, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 346/1000 --- L(Train): 0.3986992 --- L(Val, RNN): 0.3713073 --- L(Val, SINDy): 0.4767755 --- Time: 2.63s; --- Convergence: 7.19e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 46/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.289 1 + 0.439 value_stay[t] + 0.173 reward + 0.103 value_stay^2 + 0.222 value_stay*reward + -0.383 value_stay*harvest_duration + 0.709 reward^2 + 0.178 reward*harvest_duration \n",
      "value_exit[t+1] = -0.051 1 + 1.0 value_exit[t] + 0.056 value_exit^2 + -0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 0, 40, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 347/1000 --- L(Train): 0.3984274 --- L(Val, RNN): 0.3705930 --- L(Val, SINDy): 0.4751840 --- Time: 1.80s; --- Convergence: 7.17e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 47/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.292 1 + 0.44 value_stay[t] + 0.175 reward + 0.102 value_stay^2 + 0.224 value_stay*reward + -0.382 value_stay*harvest_duration + 0.71 reward^2 + 0.18 reward*harvest_duration \n",
      "value_exit[t+1] = -0.046 1 + 1.0 value_exit[t] + 0.058 value_exit^2 + -0.005 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 1, -, -, 0, 41, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 348/1000 --- L(Train): 0.3987691 --- L(Val, RNN): 0.3698566 --- L(Val, SINDy): 0.4734010 --- Time: 2.40s; --- Convergence: 7.27e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 48/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.293 1 + 0.44 value_stay[t] + 0.177 reward + 0.1 value_stay^2 + 0.224 value_stay*reward + -0.382 value_stay*harvest_duration + 0.711 reward^2 + 0.181 reward*harvest_duration \n",
      "value_exit[t+1] = -0.042 1 + 1.0 value_exit[t] + 0.06 value_exit^2 + -0.007 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 2, -, -, 0, 42, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 349/1000 --- L(Train): 0.3988968 --- L(Val, RNN): 0.3693002 --- L(Val, SINDy): 0.4722442 --- Time: 3.77s; --- Convergence: 6.41e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 49/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.295 1 + 0.44 value_stay[t] + 0.178 reward + 0.099 value_stay^2 + 0.225 value_stay*reward + -0.381 value_stay*harvest_duration + 0.712 reward^2 + 0.183 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.061 value_exit^2 + -0.008 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 3, -, -, 0, 43, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 350/1000 --- L(Train): 0.3948970 --- L(Val, RNN): 0.3690347 --- L(Val, SINDy): 0.4713446 --- Time: 2.87s; --- Convergence: 4.54e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 50/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.297 1 + 0.44 value_stay[t] + 0.18 reward + 0.098 value_stay^2 + 0.225 value_stay*reward + -0.381 value_stay*harvest_duration + 0.712 reward^2 + 0.184 reward*harvest_duration \n",
      "value_exit[t+1] = -0.034 1 + 1.0 value_exit[t] + 0.062 value_exit^2 + -0.009 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 4, -, -, 0, 44, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 351/1000 --- L(Train): 0.3972763 --- L(Val, RNN): 0.3685449 --- L(Val, SINDy): 0.4713044 --- Time: 1.62s; --- Convergence: 4.72e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 51/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.297 1 + 0.439 value_stay[t] + 0.18 reward + 0.095 value_stay^2 + 0.224 value_stay*reward + -0.382 value_stay*harvest_duration + 0.712 reward^2 + 0.184 reward*harvest_duration \n",
      "value_exit[t+1] = -0.031 1 + 1.0 value_exit[t] + 0.063 value_exit^2 + -0.01 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 5, -, -, 0, 45, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 352/1000 --- L(Train): 0.3957275 --- L(Val, RNN): 0.3677547 --- L(Val, SINDy): 0.4699499 --- Time: 2.61s; --- Convergence: 6.31e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 52/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.297 1 + 0.437 value_stay[t] + 0.179 reward + 0.092 value_stay^2 + 0.223 value_stay*reward + -0.383 value_stay*harvest_duration + 0.711 reward^2 + 0.183 reward*harvest_duration \n",
      "value_exit[t+1] = -0.028 1 + 1.0 value_exit[t] + 0.064 value_exit^2 + -0.011 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 6, -, -, 0, 46, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 353/1000 --- L(Train): 0.3956258 --- L(Val, RNN): 0.3669232 --- L(Val, SINDy): 0.4677081 --- Time: 2.21s; --- Convergence: 7.31e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 53/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.299 1 + 0.437 value_stay[t] + 0.18 reward + 0.09 value_stay^2 + 0.222 value_stay*reward + -0.383 value_stay*harvest_duration + 0.71 reward^2 + 0.184 reward*harvest_duration \n",
      "value_exit[t+1] = -0.027 1 + 1.0 value_exit[t] + 0.065 value_exit^2 + -0.011 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 7, -, -, 0, 47, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 354/1000 --- L(Train): 0.3940746 --- L(Val, RNN): 0.3665599 --- L(Val, SINDy): 0.4646212 --- Time: 2.25s; --- Convergence: 5.47e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 54/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.302 1 + 0.439 value_stay[t] + 0.181 reward + 0.091 value_stay^2 + 0.224 value_stay*reward + -0.381 value_stay*harvest_duration + 0.711 reward^2 + 0.186 reward*harvest_duration \n",
      "value_exit[t+1] = -0.025 1 + 1.0 value_exit[t] + 0.066 value_exit^2 + -0.011 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 8, -, -, 0, 48, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 355/1000 --- L(Train): 0.3960564 --- L(Val, RNN): 0.3660711 --- L(Val, SINDy): 0.4619758 --- Time: 2.08s; --- Convergence: 5.18e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 55/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.305 1 + 0.441 value_stay[t] + 0.183 reward + 0.091 value_stay^2 + 0.225 value_stay*reward + -0.379 value_stay*harvest_duration + 0.712 reward^2 + 0.188 reward*harvest_duration \n",
      "value_exit[t+1] = -0.025 1 + 1.0 value_exit[t] + 0.066 value_exit^2 + -0.011 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 9, -, -, 0, 49, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 356/1000 --- L(Train): 0.3917784 --- L(Val, RNN): 0.3654449 --- L(Val, SINDy): 0.4591423 --- Time: 1.07s; --- Convergence: 5.72e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 56/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.308 1 + 0.442 value_stay[t] + 0.184 reward + 0.09 value_stay^2 + 0.225 value_stay*reward + -0.378 value_stay*harvest_duration + 0.712 reward^2 + 0.188 reward*harvest_duration \n",
      "value_exit[t+1] = -0.025 1 + 1.0 value_exit[t] + 0.066 value_exit^2 + -0.01 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 10, -, -, 0, 50, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 357/1000 --- L(Train): 0.3914028 --- L(Val, RNN): 0.3644816 --- L(Val, SINDy): 0.4567034 --- Time: 0.91s; --- Convergence: 7.68e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 57/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.31 1 + 0.441 value_stay[t] + 0.184 reward + 0.088 value_stay^2 + 0.224 value_stay*reward + -0.379 value_stay*harvest_duration + 0.71 reward^2 + 0.188 reward*harvest_duration \n",
      "value_exit[t+1] = -0.026 1 + 1.0 value_exit[t] + 0.066 value_exit^2 + -0.009 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 11, -, -, 0, 51, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 358/1000 --- L(Train): 0.3884457 --- L(Val, RNN): 0.3638746 --- L(Val, SINDy): 0.4540978 --- Time: 0.91s; --- Convergence: 6.87e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 58/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.312 1 + 0.441 value_stay[t] + 0.183 reward + 0.086 value_stay^2 + 0.223 value_stay*reward + -0.378 value_stay*harvest_duration + 0.709 reward^2 + 0.188 reward*harvest_duration \n",
      "value_exit[t+1] = -0.027 1 + 1.0 value_exit[t] + 0.066 value_exit^2 + -0.008 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 12, -, -, 0, 52, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 359/1000 --- L(Train): 0.3890775 --- L(Val, RNN): 0.3636337 --- L(Val, SINDy): 0.4525570 --- Time: 0.86s; --- Convergence: 4.64e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 59/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.313 1 + 0.441 value_stay[t] + 0.183 reward + 0.084 value_stay^2 + 0.222 value_stay*reward + -0.379 value_stay*harvest_duration + 0.708 reward^2 + 0.188 reward*harvest_duration \n",
      "value_exit[t+1] = -0.028 1 + 1.0 value_exit[t] + 0.065 value_exit^2 + -0.006 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 13, -, -, 0, 53, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 360/1000 --- L(Train): 0.3886282 --- L(Val, RNN): 0.3628688 --- L(Val, SINDy): 0.4511923 --- Time: 0.99s; --- Convergence: 6.15e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 60/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.315 1 + 0.442 value_stay[t] + 0.184 reward + 0.083 value_stay^2 + 0.222 value_stay*reward + -0.378 value_stay*harvest_duration + 0.707 reward^2 + 0.188 reward*harvest_duration \n",
      "value_exit[t+1] = -0.029 1 + 1.0 value_exit[t] + 0.065 value_exit^2 + -0.005 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 14, -, -, 0, 54, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 361/1000 --- L(Train): 0.3918735 --- L(Val, RNN): 0.3619251 --- L(Val, SINDy): 0.4510588 --- Time: 1.01s; --- Convergence: 7.79e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 61/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.318 1 + 0.442 value_stay[t] + 0.184 reward + 0.082 value_stay^2 + 0.222 value_stay*reward + -0.378 value_stay*harvest_duration + 0.707 reward^2 + 0.189 reward*harvest_duration \n",
      "value_exit[t+1] = -0.03 1 + 1.0 value_exit[t] + 0.065 value_exit^2 + -0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 15, -, -, 0, 55, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 362/1000 --- L(Train): 0.3881640 --- L(Val, RNN): 0.3614249 --- L(Val, SINDy): 0.4519139 --- Time: 1.18s; --- Convergence: 6.40e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 62/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.321 1 + 0.444 value_stay[t] + 0.186 reward + 0.083 value_stay^2 + 0.224 value_stay*reward + -0.375 value_stay*harvest_duration + 0.708 reward^2 + 0.19 reward*harvest_duration \n",
      "value_exit[t+1] = -0.031 1 + 1.0 value_exit[t] + 0.065 value_exit^2 + -0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 16, -, -, 0, 56, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 363/1000 --- L(Train): 0.3891884 --- L(Val, RNN): 0.3612573 --- L(Val, SINDy): 0.4510693 --- Time: 0.88s; --- Convergence: 4.04e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 63/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.325 1 + 0.446 value_stay[t] + 0.188 reward + 0.083 value_stay^2 + 0.225 value_stay*reward + -0.373 value_stay*harvest_duration + 0.709 reward^2 + 0.192 reward*harvest_duration \n",
      "value_exit[t+1] = -0.032 1 + 1.0 value_exit[t] + 0.064 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 17, -, -, 0, 57, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 364/1000 --- L(Train): 0.3833376 --- L(Val, RNN): 0.3607487 --- L(Val, SINDy): 0.4489166 --- Time: 1.02s; --- Convergence: 4.56e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 64/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.327 1 + 0.448 value_stay[t] + 0.189 reward + 0.083 value_stay^2 + 0.226 value_stay*reward + -0.372 value_stay*harvest_duration + 0.709 reward^2 + 0.193 reward*harvest_duration \n",
      "value_exit[t+1] = -0.033 1 + 1.0 value_exit[t] + 0.064 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 18, -, -, 0, 58, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 365/1000 --- L(Train): 0.3844191 --- L(Val, RNN): 0.3599393 --- L(Val, SINDy): 0.4468477 --- Time: 0.96s; --- Convergence: 6.33e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 65/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.329 1 + 0.448 value_stay[t] + 0.189 reward + 0.081 value_stay^2 + 0.226 value_stay*reward + -0.371 value_stay*harvest_duration + 0.708 reward^2 + 0.193 reward*harvest_duration \n",
      "value_exit[t+1] = -0.034 1 + 1.0 value_exit[t] + 0.064 value_exit^2 + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 19, -, -, 0, 59, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 366/1000 --- L(Train): 0.3863412 --- L(Val, RNN): 0.3594700 --- L(Val, SINDy): 0.4461243 --- Time: 1.04s; --- Convergence: 5.51e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 66/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.33 1 + 0.447 value_stay[t] + 0.188 reward + 0.079 value_stay^2 + 0.224 value_stay*reward + -0.372 value_stay*harvest_duration + 0.707 reward^2 + 0.193 reward*harvest_duration \n",
      "value_exit[t+1] = -0.035 1 + 1.0 value_exit[t] + 0.064 value_exit^2 + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 20, -, -, 0, 60, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 367/1000 --- L(Train): 0.3815255 --- L(Val, RNN): 0.3592374 --- L(Val, SINDy): 0.4449315 --- Time: 0.87s; --- Convergence: 3.92e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 67/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.332 1 + 0.447 value_stay[t] + 0.188 reward + 0.077 value_stay^2 + 0.223 value_stay*reward + -0.371 value_stay*harvest_duration + 0.705 reward^2 + 0.193 reward*harvest_duration \n",
      "value_exit[t+1] = -0.035 1 + 1.0 value_exit[t] + 0.064 value_exit^2 + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 21, -, -, 0, 61, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 368/1000 --- L(Train): 0.3855280 --- L(Val, RNN): 0.3589957 --- L(Val, SINDy): 0.4448040 --- Time: 0.84s; --- Convergence: 3.17e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 68/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.334 1 + 0.447 value_stay[t] + 0.189 reward + 0.076 value_stay^2 + 0.223 value_stay*reward + -0.37 value_stay*harvest_duration + 0.705 reward^2 + 0.193 reward*harvest_duration \n",
      "value_exit[t+1] = -0.035 1 + 1.0 value_exit[t] + 0.064 value_exit^2 + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 22, -, -, 0, 62, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 369/1000 --- L(Train): 0.3839014 --- L(Val, RNN): 0.3582517 --- L(Val, SINDy): 0.4438934 --- Time: 1.11s; --- Convergence: 5.30e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 69/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.336 1 + 0.448 value_stay[t] + 0.189 reward + 0.075 value_stay^2 + 0.223 value_stay*reward + -0.37 value_stay*harvest_duration + 0.704 reward^2 + 0.193 reward*harvest_duration \n",
      "value_exit[t+1] = -0.035 1 + 1.0 value_exit[t] + 0.065 value_exit^2 + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 23, -, -, 0, 63, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 370/1000 --- L(Train): 0.3810094 --- L(Val, RNN): 0.3576827 --- L(Val, SINDy): 0.4435016 --- Time: 1.34s; --- Convergence: 5.50e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 70/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.338 1 + 0.448 value_stay[t] + 0.189 reward + 0.074 value_stay^2 + 0.223 value_stay*reward + -0.368 value_stay*harvest_duration + 0.704 reward^2 + 0.194 reward*harvest_duration \n",
      "value_exit[t+1] = -0.035 1 + 1.0 value_exit[t] + 0.065 value_exit^2 + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 24, -, -, 0, 64, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 371/1000 --- L(Train): 0.3850397 --- L(Val, RNN): 0.3574932 --- L(Val, SINDy): 0.4433270 --- Time: 1.47s; --- Convergence: 3.70e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 71/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.34 1 + 0.449 value_stay[t] + 0.19 reward + 0.073 value_stay^2 + 0.224 value_stay*reward + -0.367 value_stay*harvest_duration + 0.704 reward^2 + 0.195 reward*harvest_duration \n",
      "value_exit[t+1] = -0.035 1 + 1.0 value_exit[t] + 0.065 value_exit^2 + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 25, -, -, 0, 65, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 372/1000 --- L(Train): 0.3804282 --- L(Val, RNN): 0.3571743 --- L(Val, SINDy): 0.4429793 --- Time: 0.89s; --- Convergence: 3.44e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 72/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.343 1 + 0.451 value_stay[t] + 0.192 reward + 0.074 value_stay^2 + 0.225 value_stay*reward + -0.365 value_stay*harvest_duration + 0.705 reward^2 + 0.196 reward*harvest_duration \n",
      "value_exit[t+1] = -0.035 1 + 1.0 value_exit[t] + 0.066 value_exit^2 + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 26, -, -, 0, 66, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 373/1000 --- L(Train): 0.3835864 --- L(Val, RNN): 0.3565357 --- L(Val, SINDy): 0.4418430 --- Time: 1.25s; --- Convergence: 4.91e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 73/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.345 1 + 0.452 value_stay[t] + 0.193 reward + 0.073 value_stay^2 + 0.226 value_stay*reward + -0.364 value_stay*harvest_duration + 0.705 reward^2 + 0.197 reward*harvest_duration \n",
      "value_exit[t+1] = -0.034 1 + 1.0 value_exit[t] + 0.066 value_exit^2 + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 27, -, -, 0, 67, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 374/1000 --- L(Train): 0.3826292 --- L(Val, RNN): 0.3560379 --- L(Val, SINDy): 0.4409771 --- Time: 0.93s; --- Convergence: 4.95e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 74/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.346 1 + 0.451 value_stay[t] + 0.193 reward + 0.071 value_stay^2 + 0.225 value_stay*reward + -0.364 value_stay*harvest_duration + 0.704 reward^2 + 0.197 reward*harvest_duration \n",
      "value_exit[t+1] = -0.034 1 + 1.0 value_exit[t] + 0.067 value_exit^2 + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 28, -, -, 0, 68, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 375/1000 --- L(Train): 0.3822999 --- L(Val, RNN): 0.3558404 --- L(Val, SINDy): 0.4399580 --- Time: 0.87s; --- Convergence: 3.46e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 75/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.346 1 + 0.448 value_stay[t] + 0.192 reward + 0.066 value_stay^2 + 0.223 value_stay*reward + -0.366 value_stay*harvest_duration + 0.702 reward^2 + 0.196 reward*harvest_duration \n",
      "value_exit[t+1] = -0.033 1 + 1.0 value_exit[t] + 0.067 value_exit^2 + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 29, -, -, 0, 69, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 376/1000 --- L(Train): 0.3795273 --- L(Val, RNN): 0.3555544 --- L(Val, SINDy): 0.4386193 --- Time: 0.92s; --- Convergence: 3.16e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 76/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.345 1 + 0.446 value_stay[t] + 0.191 reward + 0.061 value_stay^2 + 0.222 value_stay*reward + -0.367 value_stay*harvest_duration + 0.7 reward^2 + 0.195 reward*harvest_duration \n",
      "value_exit[t+1] = -0.032 1 + 1.0 value_exit[t] + 0.068 value_exit^2 + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 30, -, -, 0, 70, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 377/1000 --- L(Train): 0.3778847 --- L(Val, RNN): 0.3550833 --- L(Val, SINDy): 0.4380585 --- Time: 0.98s; --- Convergence: 3.94e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 77/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.346 1 + 0.445 value_stay[t] + 0.191 reward + 0.059 value_stay^2 + 0.222 value_stay*reward + -0.368 value_stay*harvest_duration + 0.7 reward^2 + 0.195 reward*harvest_duration \n",
      "value_exit[t+1] = -0.031 1 + 1.0 value_exit[t] + 0.068 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 31, -, -, 0, 71, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 378/1000 --- L(Train): 0.3823486 --- L(Val, RNN): 0.3546937 --- L(Val, SINDy): 0.4376440 --- Time: 0.97s; --- Convergence: 3.92e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 78/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.348 1 + 0.446 value_stay[t] + 0.193 reward + 0.059 value_stay^2 + 0.223 value_stay*reward + -0.366 value_stay*harvest_duration + 0.7 reward^2 + 0.197 reward*harvest_duration \n",
      "value_exit[t+1] = -0.031 1 + 1.0 value_exit[t] + 0.069 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 32, -, -, 0, 72, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 379/1000 --- L(Train): 0.3809029 --- L(Val, RNN): 0.3544349 --- L(Val, SINDy): 0.4372691 --- Time: 1.12s; --- Convergence: 3.25e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 79/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.352 1 + 0.448 value_stay[t] + 0.195 reward + 0.06 value_stay^2 + 0.226 value_stay*reward + -0.363 value_stay*harvest_duration + 0.702 reward^2 + 0.199 reward*harvest_duration \n",
      "value_exit[t+1] = -0.03 1 + 1.0 value_exit[t] + 0.069 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 33, -, -, 0, 73, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 380/1000 --- L(Train): 0.3829245 --- L(Val, RNN): 0.3541735 --- L(Val, SINDy): 0.4363851 --- Time: 1.15s; --- Convergence: 2.93e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 80/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.354 1 + 0.45 value_stay[t] + 0.197 reward + 0.06 value_stay^2 + 0.228 value_stay*reward + -0.361 value_stay*harvest_duration + 0.703 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.03 1 + 1.0 value_exit[t] + 0.07 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 34, -, -, 0, 74, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 381/1000 --- L(Train): 0.3823634 --- L(Val, RNN): 0.3538725 --- L(Val, SINDy): 0.4355955 --- Time: 1.15s; --- Convergence: 2.97e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 81/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.356 1 + 0.45 value_stay[t] + 0.197 reward + 0.059 value_stay^2 + 0.227 value_stay*reward + -0.361 value_stay*harvest_duration + 0.702 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.03 1 + 1.0 value_exit[t] + 0.07 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 35, -, -, 0, 75, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 382/1000 --- L(Train): 0.3882413 --- L(Val, RNN): 0.3535313 --- L(Val, SINDy): 0.4349793 --- Time: 1.04s; --- Convergence: 3.19e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 82/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.357 1 + 0.45 value_stay[t] + 0.197 reward + 0.057 value_stay^2 + 0.227 value_stay*reward + -0.36 value_stay*harvest_duration + 0.701 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.03 1 + 1.0 value_exit[t] + 0.07 value_exit^2 + -0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 36, -, -, 0, 76, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 383/1000 --- L(Train): 0.3758229 --- L(Val, RNN): 0.3532594 --- L(Val, SINDy): 0.4342207 --- Time: 0.82s; --- Convergence: 2.96e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 83/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.359 1 + 0.45 value_stay[t] + 0.197 reward + 0.056 value_stay^2 + 0.227 value_stay*reward + -0.36 value_stay*harvest_duration + 0.7 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.03 1 + 1.0 value_exit[t] + 0.07 value_exit^2 + -0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 37, -, -, 0, 77, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 384/1000 --- L(Train): 0.3778823 --- L(Val, RNN): 0.3530051 --- L(Val, SINDy): 0.4334933 --- Time: 1.02s; --- Convergence: 2.75e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 84/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.36 1 + 0.45 value_stay[t] + 0.196 reward + 0.055 value_stay^2 + 0.226 value_stay*reward + -0.359 value_stay*harvest_duration + 0.699 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.03 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 38, -, -, 0, 78, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 385/1000 --- L(Train): 0.3807187 --- L(Val, RNN): 0.3527064 --- L(Val, SINDy): 0.4328265 --- Time: 1.24s; --- Convergence: 2.87e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 85/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.361 1 + 0.449 value_stay[t] + 0.195 reward + 0.052 value_stay^2 + 0.225 value_stay*reward + -0.36 value_stay*harvest_duration + 0.697 reward^2 + 0.2 reward*harvest_duration \n",
      "value_exit[t+1] = -0.03 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 39, -, -, 0, 79, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 386/1000 --- L(Train): 0.3775881 --- L(Val, RNN): 0.3525140 --- L(Val, SINDy): 0.4320050 --- Time: 1.20s; --- Convergence: 2.40e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 86/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.361 1 + 0.448 value_stay[t] + 0.194 reward + 0.05 value_stay^2 + 0.223 value_stay*reward + -0.36 value_stay*harvest_duration + 0.694 reward^2 + 0.198 reward*harvest_duration \n",
      "value_exit[t+1] = -0.031 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 1, 0, 0, 0, 0, -\n",
      "value_exit: 40, -, -, 0, 80, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 387/1000 --- L(Train): 0.3784277 --- L(Val, RNN): 0.3523140 --- L(Val, SINDy): 0.4312381 --- Time: 0.90s; --- Convergence: 2.20e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 87/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.363 1 + 0.449 value_stay[t] + 0.194 reward + 0.049 value_stay^2 + 0.222 value_stay*reward + -0.359 value_stay*harvest_duration + 0.693 reward^2 + 0.198 reward*harvest_duration \n",
      "value_exit[t+1] = -0.032 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 2, 0, 0, 0, 0, -\n",
      "value_exit: 41, -, -, 0, 81, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 388/1000 --- L(Train): 0.3793118 --- L(Val, RNN): 0.3519314 --- L(Val, SINDy): 0.4306388 --- Time: 1.03s; --- Convergence: 3.01e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 88/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.368 1 + 0.453 value_stay[t] + 0.196 reward + 0.052 value_stay^2 + 0.225 value_stay*reward + -0.356 value_stay*harvest_duration + 0.694 reward^2 + 0.2 reward*harvest_duration \n",
      "value_exit[t+1] = -0.032 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 42, -, -, 0, 82, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 389/1000 --- L(Train): 0.3796552 --- L(Val, RNN): 0.3517359 --- L(Val, SINDy): 0.4299800 --- Time: 0.88s; --- Convergence: 2.48e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 89/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.372 1 + 0.457 value_stay[t] + 0.198 reward + 0.055 value_stay^2 + 0.227 value_stay*reward + -0.351 value_stay*harvest_duration + 0.695 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.033 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 43, -, -, 0, 83, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 390/1000 --- L(Train): 0.3796007 --- L(Val, RNN): 0.3516094 --- L(Val, SINDy): 0.4292380 --- Time: 1.06s; --- Convergence: 1.87e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 90/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.376 1 + 0.459 value_stay[t] + 0.199 reward + 0.056 value_stay^2 + 0.228 value_stay*reward + -0.349 value_stay*harvest_duration + 0.695 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.034 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 44, -, -, 0, 84, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 391/1000 --- L(Train): 0.3745319 --- L(Val, RNN): 0.3512953 --- L(Val, SINDy): 0.4286235 --- Time: 0.83s; --- Convergence: 2.51e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 91/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.376 1 + 0.459 value_stay[t] + 0.197 reward + 0.054 value_stay^2 + 0.226 value_stay*reward + -0.349 value_stay*harvest_duration + 0.693 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.035 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 45, -, -, 0, 85, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 392/1000 --- L(Train): 0.3777174 --- L(Val, RNN): 0.3509279 --- L(Val, SINDy): 0.4280448 --- Time: 1.07s; --- Convergence: 3.09e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 92/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.376 1 + 0.457 value_stay[t] + 0.195 reward + 0.051 value_stay^2 + 0.224 value_stay*reward + -0.351 value_stay*harvest_duration + 0.69 reward^2 + 0.199 reward*harvest_duration \n",
      "value_exit[t+1] = -0.036 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 46, -, -, 0, 86, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 393/1000 --- L(Train): 0.3787279 --- L(Val, RNN): 0.3508641 --- L(Val, SINDy): 0.4273395 --- Time: 0.88s; --- Convergence: 1.86e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 93/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.377 1 + 0.456 value_stay[t] + 0.194 reward + 0.048 value_stay^2 + 0.221 value_stay*reward + -0.352 value_stay*harvest_duration + 0.687 reward^2 + 0.198 reward*harvest_duration \n",
      "value_exit[t+1] = -0.036 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 1, 0, 0, 0, 0, -\n",
      "value_exit: 47, -, -, 0, 87, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 394/1000 --- L(Train): 0.3797129 --- L(Val, RNN): 0.3507236 --- L(Val, SINDy): 0.4266005 --- Time: 0.88s; --- Convergence: 1.63e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 94/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.378 1 + 0.456 value_stay[t] + 0.193 reward + 0.047 value_stay^2 + 0.221 value_stay*reward + -0.351 value_stay*harvest_duration + 0.686 reward^2 + 0.197 reward*harvest_duration \n",
      "value_exit[t+1] = -0.037 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 2, 0, 0, 0, 0, -\n",
      "value_exit: 48, -, -, 0, 88, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 395/1000 --- L(Train): 0.3840516 --- L(Val, RNN): 0.3504306 --- L(Val, SINDy): 0.4259879 --- Time: 1.03s; --- Convergence: 2.28e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 95/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.38 1 + 0.457 value_stay[t] + 0.193 reward + 0.047 value_stay^2 + 0.22 value_stay*reward + -0.35 value_stay*harvest_duration + 0.685 reward^2 + 0.197 reward*harvest_duration \n",
      "value_exit[t+1] = -0.037 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 3, 0, 0, 0, 0, -\n",
      "value_exit: 49, -, -, 0, 89, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 396/1000 --- L(Train): 0.3815412 --- L(Val, RNN): 0.3501771 --- L(Val, SINDy): 0.4254302 --- Time: 0.95s; --- Convergence: 2.41e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 96/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.382 1 + 0.458 value_stay[t] + 0.193 reward + 0.047 value_stay^2 + 0.22 value_stay*reward + -0.349 value_stay*harvest_duration + 0.685 reward^2 + 0.198 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 4, 0, 0, 0, 0, -\n",
      "value_exit: 50, -, -, 0, 90, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 397/1000 --- L(Train): 0.3798553 --- L(Val, RNN): 0.3500863 --- L(Val, SINDy): 0.4249040 --- Time: 0.90s; --- Convergence: 1.66e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 97/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.384 1 + 0.459 value_stay[t] + 0.194 reward + 0.047 value_stay^2 + 0.221 value_stay*reward + -0.348 value_stay*harvest_duration + 0.685 reward^2 + 0.199 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 5, 0, 0, 0, 0, -\n",
      "value_exit: 51, -, -, 0, 91, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 398/1000 --- L(Train): 0.3771397 --- L(Val, RNN): 0.3499930 --- L(Val, SINDy): 0.4244349 --- Time: 0.91s; --- Convergence: 1.30e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 98/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.385 1 + 0.46 value_stay[t] + 0.195 reward + 0.047 value_stay^2 + 0.222 value_stay*reward + -0.347 value_stay*harvest_duration + 0.685 reward^2 + 0.199 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 6, 0, 0, 0, 0, -\n",
      "value_exit: 52, -, -, 0, 92, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 399/1000 --- L(Train): 0.3795062 --- L(Val, RNN): 0.3498028 --- L(Val, SINDy): 0.4239236 --- Time: 1.01s; --- Convergence: 1.60e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 99/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.387 1 + 0.461 value_stay[t] + 0.197 reward + 0.047 value_stay^2 + 0.223 value_stay*reward + -0.345 value_stay*harvest_duration + 0.686 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.072 value_exit^2 + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 7, 0, 0, 0, 0, -\n",
      "value_exit: 53, -, -, 0, 93, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 400/1000 --- L(Train): 0.3763884 --- L(Val, RNN): 0.3495343 --- L(Val, SINDy): 0.4233840 --- Time: 1.02s; --- Convergence: 2.14e-04; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.389 1 + 0.461 value_stay[t] + 0.198 reward + 0.047 value_stay^2 + 0.225 value_stay*reward + -0.345 value_stay*harvest_duration + 0.687 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.072 value_exit^2 + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 8, 0, 0, 0, 0, -\n",
      "value_exit: 54, -, -, 0, 94, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 401/1000 --- L(Train): 0.3817411 --- L(Val, RNN): 0.3494411 --- L(Val, SINDy): 0.4225146 --- Time: 1.62s; --- Convergence: 1.54e-04; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 1/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.388 1 + 0.459 value_stay[t] + 0.198 reward + 0.043 value_stay^2 + 0.224 value_stay*reward + -0.347 value_stay*harvest_duration + 0.686 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.072 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 9, 0, 0, 0, 0, -\n",
      "value_exit: 55, -, -, 0, 95, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 402/1000 --- L(Train): 0.3813535 --- L(Val, RNN): 0.3494253 --- L(Val, SINDy): 0.4219857 --- Time: 3.27s; --- Convergence: 8.48e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 2/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.387 1 + 0.456 value_stay[t] + 0.197 reward + 0.038 value_stay^2 + 0.222 value_stay*reward + -0.349 value_stay*harvest_duration + 0.685 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.073 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 10, 0, 0, 0, 0, -\n",
      "value_exit: 56, -, -, 0, 96, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 403/1000 --- L(Train): 0.3774808 --- L(Val, RNN): 0.3493804 --- L(Val, SINDy): 0.4215022 --- Time: 3.88s; --- Convergence: 6.48e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 3/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.386 1 + 0.453 value_stay[t] + 0.196 reward + 0.034 value_stay^2 + 0.221 value_stay*reward + -0.351 value_stay*harvest_duration + 0.684 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.073 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 11, 0, 0, 0, 0, -\n",
      "value_exit: 57, -, -, 0, 97, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 404/1000 --- L(Train): 0.3795100 --- L(Val, RNN): 0.3492528 --- L(Val, SINDy): 0.4208545 --- Time: 3.69s; --- Convergence: 9.62e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 4/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.386 1 + 0.452 value_stay[t] + 0.197 reward + 0.031 value_stay^2 + 0.221 value_stay*reward + -0.352 value_stay*harvest_duration + 0.684 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.074 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 12, 0, 0, 0, 0, -\n",
      "value_exit: 58, -, -, 0, 98, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 405/1000 --- L(Train): 0.3786492 --- L(Val, RNN): 0.3490922 --- L(Val, SINDy): 0.4197773 --- Time: 5.24s; --- Convergence: 1.28e-04; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 5/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.387 1 + 0.451 value_stay[t] + 0.197 reward + 0.029 value_stay^2 + 0.221 value_stay*reward + -0.352 value_stay*harvest_duration + 0.684 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.074 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 13, 0, 0, 0, 0, -\n",
      "value_exit: 59, -, -, 0, 99, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 406/1000 --- L(Train): 0.3789916 --- L(Val, RNN): 0.3489975 --- L(Val, SINDy): 0.4183827 --- Time: 4.61s; --- Convergence: 1.12e-04; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 6/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.389 1 + 0.452 value_stay[t] + 0.199 reward + 0.03 value_stay^2 + 0.223 value_stay*reward + -0.351 value_stay*harvest_duration + 0.685 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.074 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 14, 0, 0, 0, 0, -\n",
      "value_exit: 60, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 407/1000 --- L(Train): 0.3735381 --- L(Val, RNN): 0.3489585 --- L(Val, SINDy): 0.4167441 --- Time: 8.08s; --- Convergence: 7.53e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 7/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.392 1 + 0.454 value_stay[t] + 0.202 reward + 0.032 value_stay^2 + 0.227 value_stay*reward + -0.348 value_stay*harvest_duration + 0.687 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.075 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 15, 0, 0, 0, 0, -\n",
      "value_exit: 61, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 408/1000 --- L(Train): 0.3734650 --- L(Val, RNN): 0.3489278 --- L(Val, SINDy): 0.4159847 --- Time: 3.56s; --- Convergence: 5.30e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 8/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.394 1 + 0.456 value_stay[t] + 0.204 reward + 0.033 value_stay^2 + 0.23 value_stay*reward + -0.345 value_stay*harvest_duration + 0.689 reward^2 + 0.208 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.075 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 16, 0, 0, 0, 0, -\n",
      "value_exit: 62, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 409/1000 --- L(Train): 0.3800357 --- L(Val, RNN): 0.3488278 --- L(Val, SINDy): 0.4160467 --- Time: 3.57s; --- Convergence: 7.65e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 9/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.396 1 + 0.458 value_stay[t] + 0.206 reward + 0.034 value_stay^2 + 0.232 value_stay*reward + -0.343 value_stay*harvest_duration + 0.69 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.076 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 17, 0, 0, 0, 0, -\n",
      "value_exit: 63, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 410/1000 --- L(Train): 0.3746231 --- L(Val, RNN): 0.3487060 --- L(Val, SINDy): 0.4159558 --- Time: 5.91s; --- Convergence: 9.91e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 10/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.397 1 + 0.457 value_stay[t] + 0.206 reward + 0.033 value_stay^2 + 0.232 value_stay*reward + -0.343 value_stay*harvest_duration + 0.69 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.076 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 18, 0, 0, 0, 0, -\n",
      "value_exit: 64, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 411/1000 --- L(Train): 0.3746335 --- L(Val, RNN): 0.3485884 --- L(Val, SINDy): 0.4161132 --- Time: 4.71s; --- Convergence: 1.08e-04; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 11/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.397 1 + 0.456 value_stay[t] + 0.205 reward + 0.03 value_stay^2 + 0.231 value_stay*reward + -0.344 value_stay*harvest_duration + 0.688 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.076 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 19, 0, 0, 0, 0, -\n",
      "value_exit: 65, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 412/1000 --- L(Train): 0.3717536 --- L(Val, RNN): 0.3485264 --- L(Val, SINDy): 0.4164698 --- Time: 1.12s; --- Convergence: 8.52e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 12/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.397 1 + 0.454 value_stay[t] + 0.203 reward + 0.027 value_stay^2 + 0.23 value_stay*reward + -0.345 value_stay*harvest_duration + 0.686 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.077 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 20, 0, 0, 0, 0, -\n",
      "value_exit: 66, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 413/1000 --- L(Train): 0.3695362 --- L(Val, RNN): 0.3484888 --- L(Val, SINDy): 0.4178076 --- Time: 0.98s; --- Convergence: 6.14e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 13/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.396 1 + 0.453 value_stay[t] + 0.202 reward + 0.025 value_stay^2 + 0.228 value_stay*reward + -0.347 value_stay*harvest_duration + 0.684 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.077 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 21, 0, 0, 0, 0, -\n",
      "value_exit: 67, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 414/1000 --- L(Train): 0.3773001 --- L(Val, RNN): 0.3484398 --- L(Val, SINDy): 0.4186694 --- Time: 0.86s; --- Convergence: 5.52e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 14/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.397 1 + 0.452 value_stay[t] + 0.201 reward + 0.023 value_stay^2 + 0.227 value_stay*reward + -0.347 value_stay*harvest_duration + 0.683 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.078 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 22, 0, 0, 0, 0, -\n",
      "value_exit: 68, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 415/1000 --- L(Train): 0.3719016 --- L(Val, RNN): 0.3483388 --- L(Val, SINDy): 0.4200667 --- Time: 0.96s; --- Convergence: 7.81e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 15/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.398 1 + 0.453 value_stay[t] + 0.201 reward + 0.024 value_stay^2 + 0.228 value_stay*reward + -0.346 value_stay*harvest_duration + 0.682 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.078 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 23, 0, 0, 0, 0, -\n",
      "value_exit: 69, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 416/1000 --- L(Train): 0.3790147 --- L(Val, RNN): 0.3482241 --- L(Val, SINDy): 0.4214403 --- Time: 1.38s; --- Convergence: 9.64e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 16/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.401 1 + 0.456 value_stay[t] + 0.201 reward + 0.026 value_stay^2 + 0.23 value_stay*reward + -0.344 value_stay*harvest_duration + 0.682 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.079 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 24, 0, 0, 0, 0, -\n",
      "value_exit: 70, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 417/1000 --- L(Train): 0.3715467 --- L(Val, RNN): 0.3481454 --- L(Val, SINDy): 0.4228951 --- Time: 1.03s; --- Convergence: 8.75e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 17/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.403 1 + 0.458 value_stay[t] + 0.202 reward + 0.027 value_stay^2 + 0.231 value_stay*reward + -0.342 value_stay*harvest_duration + 0.682 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.079 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 25, 0, 0, 0, 0, -\n",
      "value_exit: 71, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 418/1000 --- L(Train): 0.3738428 --- L(Val, RNN): 0.3481345 --- L(Val, SINDy): 0.4245373 --- Time: 1.13s; --- Convergence: 4.92e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 18/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.405 1 + 0.459 value_stay[t] + 0.202 reward + 0.028 value_stay^2 + 0.232 value_stay*reward + -0.341 value_stay*harvest_duration + 0.682 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.08 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 26, 0, 0, 0, 0, -\n",
      "value_exit: 72, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 419/1000 --- L(Train): 0.3770886 --- L(Val, RNN): 0.3480780 --- L(Val, SINDy): 0.4259552 --- Time: 0.87s; --- Convergence: 5.29e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 19/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.406 1 + 0.459 value_stay[t] + 0.202 reward + 0.027 value_stay^2 + 0.232 value_stay*reward + -0.342 value_stay*harvest_duration + 0.68 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = -0.037 1 + 1.0 value_exit[t] + 0.08 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 27, 0, 0, 0, 0, -\n",
      "value_exit: 73, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 420/1000 --- L(Train): 0.3669173 --- L(Val, RNN): 0.3479397 --- L(Val, SINDy): 0.4122423 --- Time: 0.86s; --- Convergence: 9.56e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 20/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.406 1 + 0.458 value_stay[t] + 0.201 reward + 0.025 value_stay^2 + 0.232 value_stay*reward + -0.343 value_stay*harvest_duration + 0.679 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = -0.037 1 + 1.0 value_exit[t] + 0.081 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 28, 0, 0, 0, 0, -\n",
      "value_exit: 74, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 421/1000 --- L(Train): 0.3759782 --- L(Val, RNN): 0.3478089 --- L(Val, SINDy): 0.4139423 --- Time: 0.90s; --- Convergence: 1.13e-04; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 21/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.407 1 + 0.458 value_stay[t] + 0.2 reward + 0.024 value_stay^2 + 0.231 value_stay*reward + -0.343 value_stay*harvest_duration + 0.677 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = -0.037 1 + 1.0 value_exit[t] + 0.081 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 29, 0, 0, 0, 0, -\n",
      "value_exit: 75, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 422/1000 --- L(Train): 0.3750668 --- L(Val, RNN): 0.3477551 --- L(Val, SINDy): 0.4154533 --- Time: 1.11s; --- Convergence: 8.35e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 22/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.408 1 + 0.458 value_stay[t] + 0.2 reward + 0.023 value_stay^2 + 0.231 value_stay*reward + -0.343 value_stay*harvest_duration + 0.676 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.081 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 30, 0, 0, 0, 0, -\n",
      "value_exit: 76, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 423/1000 --- L(Train): 0.3744653 --- L(Val, RNN): 0.3477734 --- L(Val, SINDy): 0.4163147 --- Time: 0.94s; --- Convergence: 5.09e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 23/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.409 1 + 0.458 value_stay[t] + 0.199 reward + 0.021 value_stay^2 + 0.231 value_stay*reward + -0.344 value_stay*harvest_duration + 0.675 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.082 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 31, 0, 0, 0, 0, -\n",
      "value_exit: 77, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 424/1000 --- L(Train): 0.3799876 --- L(Val, RNN): 0.3477749 --- L(Val, SINDy): 0.4165060 --- Time: 1.13s; --- Convergence: 2.62e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 24/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.409 1 + 0.457 value_stay[t] + 0.198 reward + 0.02 value_stay^2 + 0.231 value_stay*reward + -0.344 value_stay*harvest_duration + 0.673 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.082 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 32, 0, 0, 0, 0, -\n",
      "value_exit: 78, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 425/1000 --- L(Train): 0.3717726 --- L(Val, RNN): 0.3476925 --- L(Val, SINDy): 0.4166583 --- Time: 1.01s; --- Convergence: 5.43e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 25/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.41 1 + 0.457 value_stay[t] + 0.197 reward + 0.018 value_stay^2 + 0.23 value_stay*reward + -0.344 value_stay*harvest_duration + 0.672 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.083 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 33, 0, 0, 0, 0, -\n",
      "value_exit: 79, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 426/1000 --- L(Train): 0.3751509 --- L(Val, RNN): 0.3475934 --- L(Val, SINDy): 0.4165919 --- Time: 1.19s; --- Convergence: 7.67e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 26/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.41 1 + 0.457 value_stay[t] + 0.197 reward + 0.018 value_stay^2 + 0.23 value_stay*reward + -0.345 value_stay*harvest_duration + 0.671 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.083 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 34, 0, 0, 0, 0, -\n",
      "value_exit: 80, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 427/1000 --- L(Train): 0.3819354 --- L(Val, RNN): 0.3475345 --- L(Val, SINDy): 0.4167605 --- Time: 0.89s; --- Convergence: 6.78e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 27/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.412 1 + 0.458 value_stay[t] + 0.198 reward + 0.018 value_stay^2 + 0.232 value_stay*reward + -0.343 value_stay*harvest_duration + 0.671 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.084 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 35, 0, 0, 0, 0, -\n",
      "value_exit: 81, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 428/1000 --- L(Train): 0.3729434 --- L(Val, RNN): 0.3475198 --- L(Val, SINDy): 0.4163536 --- Time: 1.17s; --- Convergence: 4.13e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 28/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.414 1 + 0.459 value_stay[t] + 0.199 reward + 0.019 value_stay^2 + 0.235 value_stay*reward + -0.341 value_stay*harvest_duration + 0.672 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.084 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 36, 0, 0, 0, 0, -\n",
      "value_exit: 82, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 429/1000 --- L(Train): 0.3692357 --- L(Val, RNN): 0.3474933 --- L(Val, SINDy): 0.4155027 --- Time: 0.88s; --- Convergence: 3.39e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 29/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.414 1 + 0.458 value_stay[t] + 0.199 reward + 0.017 value_stay^2 + 0.236 value_stay*reward + -0.342 value_stay*harvest_duration + 0.672 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = -0.039 1 + 1.0 value_exit[t] + 0.085 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 37, 0, 0, 0, 0, -\n",
      "value_exit: 83, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 430/1000 --- L(Train): 0.3698045 --- L(Val, RNN): 0.3474045 --- L(Val, SINDy): 0.4151246 --- Time: 1.05s; --- Convergence: 6.13e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 30/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.414 1 + 0.457 value_stay[t] + 0.199 reward + 0.015 value_stay^2 + 0.236 value_stay*reward + -0.342 value_stay*harvest_duration + 0.671 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.039 1 + 1.0 value_exit[t] + 0.085 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 38, 0, 0, 0, 0, -\n",
      "value_exit: 84, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 431/1000 --- L(Train): 0.3730584 --- L(Val, RNN): 0.3473240 --- L(Val, SINDy): 0.4144312 --- Time: 0.92s; --- Convergence: 7.09e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 31/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.414 1 + 0.456 value_stay[t] + 0.199 reward + 0.014 value_stay^2 + 0.236 value_stay*reward + -0.343 value_stay*harvest_duration + 0.67 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.039 1 + 1.0 value_exit[t] + 0.085 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 39, 0, 0, 0, 0, -\n",
      "value_exit: 85, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 432/1000 --- L(Train): 0.3748904 --- L(Val, RNN): 0.3472565 --- L(Val, SINDy): 0.4136215 --- Time: 1.12s; --- Convergence: 6.92e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 32/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.415 1 + 0.455 value_stay[t] + 0.198 reward + 0.013 value_stay^2 + 0.237 value_stay*reward + -0.343 value_stay*harvest_duration + 0.669 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.039 1 + 1.0 value_exit[t] + 0.086 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 40, 0, 0, 0, 0, -\n",
      "value_exit: 86, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 433/1000 --- L(Train): 0.3776133 --- L(Val, RNN): 0.3472238 --- L(Val, SINDy): 0.4130865 --- Time: 1.01s; --- Convergence: 5.10e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 33/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.415 1 + 0.455 value_stay[t] + 0.198 reward + 0.012 value_stay^2 + 0.238 value_stay*reward + -0.342 value_stay*harvest_duration + 0.669 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.04 1 + 1.0 value_exit[t] + 0.086 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 41, 0, 0, 0, 0, -\n",
      "value_exit: 87, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 434/1000 --- L(Train): 0.3719390 --- L(Val, RNN): 0.3471946 --- L(Val, SINDy): 0.4121572 --- Time: 0.95s; --- Convergence: 4.01e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 34/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.416 1 + 0.455 value_stay[t] + 0.198 reward + 0.012 value_stay^2 + 0.239 value_stay*reward + -0.342 value_stay*harvest_duration + 0.668 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.04 1 + 1.0 value_exit[t] + 0.087 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 42, 0, 0, 0, 0, -\n",
      "value_exit: 88, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 435/1000 --- L(Train): 0.3706002 --- L(Val, RNN): 0.3471297 --- L(Val, SINDy): 0.4115404 --- Time: 0.97s; --- Convergence: 5.25e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 35/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.416 1 + 0.455 value_stay[t] + 0.198 reward + 0.011 value_stay^2 + 0.239 value_stay*reward + -0.342 value_stay*harvest_duration + 0.667 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.04 1 + 1.0 value_exit[t] + 0.087 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 43, 0, 0, 0, 0, -\n",
      "value_exit: 89, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 436/1000 --- L(Train): 0.3758097 --- L(Val, RNN): 0.3470839 --- L(Val, SINDy): 0.4106090 --- Time: 1.14s; --- Convergence: 4.91e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 36/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.417 1 + 0.456 value_stay[t] + 0.198 reward + 0.011 value_stay^2 + 0.24 value_stay*reward + -0.341 value_stay*harvest_duration + 0.667 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.04 1 + 1.0 value_exit[t] + 0.087 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 44, 0, 0, 0, 0, -\n",
      "value_exit: 90, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 437/1000 --- L(Train): 0.3773444 --- L(Val, RNN): 0.3470285 --- L(Val, SINDy): 0.4102717 --- Time: 1.33s; --- Convergence: 5.23e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 37/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.418 1 + 0.456 value_stay[t] + 0.198 reward + 0.01 value_stay^2 + 0.24 value_stay*reward + -0.341 value_stay*harvest_duration + 0.666 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.041 1 + 1.0 value_exit[t] + 0.088 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 45, 0, 0, 0, 0, -\n",
      "value_exit: 91, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 438/1000 --- L(Train): 0.3740463 --- L(Val, RNN): 0.3469730 --- L(Val, SINDy): 0.4099302 --- Time: 0.92s; --- Convergence: 5.39e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 38/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.42 1 + 0.456 value_stay[t] + 0.198 reward + 0.01 value_stay^2 + 0.242 value_stay*reward + -0.34 value_stay*harvest_duration + 0.666 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.041 1 + 1.0 value_exit[t] + 0.088 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 46, 0, 0, 0, 0, -\n",
      "value_exit: 92, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 439/1000 --- L(Train): 0.3798763 --- L(Val, RNN): 0.3469125 --- L(Val, SINDy): 0.4101532 --- Time: 0.86s; --- Convergence: 5.72e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 39/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.421 1 + 0.457 value_stay[t] + 0.199 reward + 0.011 value_stay^2 + 0.243 value_stay*reward + -0.339 value_stay*harvest_duration + 0.667 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = -0.041 1 + 1.0 value_exit[t] + 0.089 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 47, 0, 0, 0, 0, -\n",
      "value_exit: 93, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 440/1000 --- L(Train): 0.3744872 --- L(Val, RNN): 0.3468626 --- L(Val, SINDy): 0.4101725 --- Time: 1.08s; --- Convergence: 5.36e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 40/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.423 1 + 0.458 value_stay[t] + 0.2 reward + 0.011 value_stay^2 + 0.245 value_stay*reward + -0.338 value_stay*harvest_duration + 0.667 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = -0.041 1 + 1.0 value_exit[t] + 0.089 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 48, 0, 0, 0, 0, -\n",
      "value_exit: 94, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 441/1000 --- L(Train): 0.3768109 --- L(Val, RNN): 0.3468042 --- L(Val, SINDy): 0.4102109 --- Time: 0.90s; --- Convergence: 5.60e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 41/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.424 1 + 0.459 value_stay[t] + 0.2 reward + 0.011 value_stay^2 + 0.245 value_stay*reward + -0.338 value_stay*harvest_duration + 0.666 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = -0.041 1 + 1.0 value_exit[t] + 0.089 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 49, 0, 0, 0, 0, -\n",
      "value_exit: 95, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 442/1000 --- L(Train): 0.3769868 --- L(Val, RNN): 0.3467458 --- L(Val, SINDy): 0.4104244 --- Time: 0.87s; --- Convergence: 5.72e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 42/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.425 1 + 0.458 value_stay[t] + 0.199 reward + 0.01 value_stay^2 + 0.245 value_stay*reward + -0.338 value_stay*harvest_duration + 0.665 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = -0.041 1 + 1.0 value_exit[t] + 0.09 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 50, 0, 0, 0, 0, -\n",
      "value_exit: 96, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 443/1000 --- L(Train): 0.3713870 --- L(Val, RNN): 0.3467261 --- L(Val, SINDy): 0.4104598 --- Time: 0.95s; --- Convergence: 3.85e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 43/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.426 1 + 0.458 value_stay[t] + 0.199 reward + 0.009 value_stay^2 + 0.245 value_stay*reward + -0.339 value_stay*harvest_duration + 0.664 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.042 1 + 1.0 value_exit[t] + 0.09 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 51, 0, 0, 0, 0, -\n",
      "value_exit: 97, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 444/1000 --- L(Train): 0.3732224 --- L(Val, RNN): 0.3466872 --- L(Val, SINDy): 0.4107773 --- Time: 1.02s; --- Convergence: 3.87e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 44/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.427 1 + 0.458 value_stay[t] + 0.198 reward + 0.008 value_stay^2 + 0.245 value_stay*reward + -0.339 value_stay*harvest_duration + 0.663 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.042 1 + 1.0 value_exit[t] + 0.09 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 52, 0, 0, 0, 0, -\n",
      "value_exit: 98, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 445/1000 --- L(Train): 0.3741748 --- L(Val, RNN): 0.3466274 --- L(Val, SINDy): 0.4110738 --- Time: 0.93s; --- Convergence: 4.92e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 45/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.428 1 + 0.458 value_stay[t] + 0.198 reward + 0.008 value_stay^2 + 0.245 value_stay*reward + -0.339 value_stay*harvest_duration + 0.663 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.042 1 + 1.0 value_exit[t] + 0.091 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 53, 0, 0, 0, 0, -\n",
      "value_exit: 99, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 446/1000 --- L(Train): 0.3735318 --- L(Val, RNN): 0.3465526 --- L(Val, SINDy): 0.4113401 --- Time: 1.45s; --- Convergence: 6.20e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 46/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.429 1 + 0.458 value_stay[t] + 0.198 reward + 0.008 value_stay^2 + 0.244 value_stay*reward + -0.339 value_stay*harvest_duration + 0.662 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.091 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 54, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 447/1000 --- L(Train): 0.3735065 --- L(Val, RNN): 0.3464987 --- L(Val, SINDy): 0.4119343 --- Time: 1.01s; --- Convergence: 5.80e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 47/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.429 1 + 0.458 value_stay[t] + 0.197 reward + 0.007 value_stay^2 + 0.244 value_stay*reward + -0.339 value_stay*harvest_duration + 0.661 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.091 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 55, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 448/1000 --- L(Train): 0.3695376 --- L(Val, RNN): 0.3464519 --- L(Val, SINDy): 0.4121370 --- Time: 1.00s; --- Convergence: 5.24e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 48/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.43 1 + 0.458 value_stay[t] + 0.197 reward + 0.006 value_stay^2 + 0.245 value_stay*reward + -0.338 value_stay*harvest_duration + 0.661 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.091 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 56, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 449/1000 --- L(Train): 0.3709962 --- L(Val, RNN): 0.3464325 --- L(Val, SINDy): 0.4122249 --- Time: 0.92s; --- Convergence: 3.59e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 49/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.432 1 + 0.459 value_stay[t] + 0.198 reward + 0.007 value_stay^2 + 0.246 value_stay*reward + -0.337 value_stay*harvest_duration + 0.661 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.09 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 57, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 450/1000 --- L(Train): 0.3655441 --- L(Val, RNN): 0.3463890 --- L(Val, SINDy): 0.4122800 --- Time: 0.93s; --- Convergence: 3.97e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 50/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.434 1 + 0.461 value_stay[t] + 0.199 reward + 0.008 value_stay^2 + 0.248 value_stay*reward + -0.336 value_stay*harvest_duration + 0.662 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.089 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 58, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 451/1000 --- L(Train): 0.3739131 --- L(Val, RNN): 0.3463371 --- L(Val, SINDy): 0.4122140 --- Time: 0.88s; --- Convergence: 4.58e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 51/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.436 1 + 0.462 value_stay[t] + 0.2 reward + 0.009 value_stay^2 + 0.25 value_stay*reward + -0.334 value_stay*harvest_duration + 0.663 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.088 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 59, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 452/1000 --- L(Train): 0.3746315 --- L(Val, RNN): 0.3462571 --- L(Val, SINDy): 0.4120743 --- Time: 0.86s; --- Convergence: 6.29e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 52/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.437 1 + 0.462 value_stay[t] + 0.2 reward + 0.008 value_stay^2 + 0.25 value_stay*reward + -0.334 value_stay*harvest_duration + 0.663 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.086 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 60, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 453/1000 --- L(Train): 0.3678398 --- L(Val, RNN): 0.3461992 --- L(Val, SINDy): 0.4118743 --- Time: 1.08s; --- Convergence: 6.04e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 53/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.436 1 + 0.46 value_stay[t] + 0.199 reward + 0.006 value_stay^2 + 0.249 value_stay*reward + -0.335 value_stay*harvest_duration + 0.661 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.085 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 61, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 454/1000 --- L(Train): 0.3705787 --- L(Val, RNN): 0.3462073 --- L(Val, SINDy): 0.4114251 --- Time: 0.92s; --- Convergence: 3.42e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 54/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.436 1 + 0.458 value_stay[t] + 0.197 reward + 0.003 value_stay^2 + 0.247 value_stay*reward + -0.337 value_stay*harvest_duration + 0.659 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.083 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 62, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 455/1000 --- L(Train): 0.3716637 --- L(Val, RNN): 0.3461912 --- L(Val, SINDy): 0.4112168 --- Time: 1.17s; --- Convergence: 2.52e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 55/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.436 1 + 0.457 value_stay[t] + 0.196 reward + 0.001 value_stay^2 + 0.247 value_stay*reward + -0.337 value_stay*harvest_duration + 0.658 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.081 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 63, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 456/1000 --- L(Train): 0.3712626 --- L(Val, RNN): 0.3461170 --- L(Val, SINDy): 0.4110893 --- Time: 1.20s; --- Convergence: 4.97e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 56/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.437 1 + 0.457 value_stay[t] + 0.197 reward + 0.001 value_stay^2 + 0.247 value_stay*reward + -0.337 value_stay*harvest_duration + 0.657 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.079 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 64, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 457/1000 --- L(Train): 0.3713816 --- L(Val, RNN): 0.3460170 --- L(Val, SINDy): 0.4110021 --- Time: 0.85s; --- Convergence: 7.48e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 57/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.439 1 + 0.459 value_stay[t] + 0.198 reward + 0.002 value_stay^2 + 0.249 value_stay*reward + -0.335 value_stay*harvest_duration + 0.658 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.077 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 65, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 458/1000 --- L(Train): 0.3679925 --- L(Val, RNN): 0.3459736 --- L(Val, SINDy): 0.4107817 --- Time: 1.14s; --- Convergence: 5.91e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 58/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.442 1 + 0.461 value_stay[t] + 0.2 reward + 0.005 value_stay^2 + 0.252 value_stay*reward + -0.332 value_stay*harvest_duration + 0.66 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.075 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 66, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 459/1000 --- L(Train): 0.3718669 --- L(Val, RNN): 0.3459518 --- L(Val, SINDy): 0.4103137 --- Time: 1.14s; --- Convergence: 4.05e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 59/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.444 1 + 0.462 value_stay[t] + 0.201 reward + 0.006 value_stay^2 + 0.254 value_stay*reward + -0.33 value_stay*harvest_duration + 0.661 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.073 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 67, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 460/1000 --- L(Train): 0.3742196 --- L(Val, RNN): 0.3459013 --- L(Val, SINDy): 0.4101378 --- Time: 0.89s; --- Convergence: 4.55e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 60/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.444 1 + 0.462 value_stay[t] + 0.201 reward + 0.005 value_stay^2 + 0.254 value_stay*reward + -0.33 value_stay*harvest_duration + 0.661 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.071 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 68, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 461/1000 --- L(Train): 0.3711054 --- L(Val, RNN): 0.3458448 --- L(Val, SINDy): 0.4098079 --- Time: 0.91s; --- Convergence: 5.10e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 61/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.444 1 + 0.461 value_stay[t] + 0.2 reward + 0.003 value_stay^2 + 0.253 value_stay*reward + -0.332 value_stay*harvest_duration + 0.66 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.068 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 69, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 462/1000 --- L(Train): 0.3689216 --- L(Val, RNN): 0.3457913 --- L(Val, SINDy): 0.4096112 --- Time: 1.01s; --- Convergence: 5.23e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 62/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.444 1 + 0.459 value_stay[t] + 0.199 reward + 0.001 value_stay^2 + 0.252 value_stay*reward + -0.333 value_stay*harvest_duration + 0.659 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.066 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 70, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 463/1000 --- L(Train): 0.3662840 --- L(Val, RNN): 0.3457596 --- L(Val, SINDy): 0.4090571 --- Time: 0.98s; --- Convergence: 4.20e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 63/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.445 1 + 0.459 value_stay[t] + 0.199 reward + 0.0 value_stay^2 + 0.253 value_stay*reward + -0.333 value_stay*harvest_duration + 0.658 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.064 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 71, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 464/1000 --- L(Train): 0.3730666 --- L(Val, RNN): 0.3457141 --- L(Val, SINDy): 0.4087892 --- Time: 0.96s; --- Convergence: 4.37e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 64/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.446 1 + 0.459 value_stay[t] + 0.2 reward + 0.0 value_stay^2 + 0.253 value_stay*reward + -0.332 value_stay*harvest_duration + 0.659 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.062 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 72, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 465/1000 --- L(Train): 0.3707382 --- L(Val, RNN): 0.3456525 --- L(Val, SINDy): 0.4084393 --- Time: 1.18s; --- Convergence: 5.27e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 65/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.448 1 + 0.46 value_stay[t] + 0.2 reward + 0.0 value_stay^2 + 0.255 value_stay*reward + -0.331 value_stay*harvest_duration + 0.659 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.059 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 73, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 466/1000 --- L(Train): 0.3750858 --- L(Val, RNN): 0.3456040 --- L(Val, SINDy): 0.4079603 --- Time: 2.18s; --- Convergence: 5.06e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 66/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.449 1 + 0.46 value_stay[t] + 0.201 reward + 0.0 value_stay^2 + 0.256 value_stay*reward + -0.331 value_stay*harvest_duration + 0.66 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.057 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 74, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 467/1000 --- L(Train): 0.3737274 --- L(Val, RNN): 0.3455559 --- L(Val, SINDy): 0.4073479 --- Time: 3.63s; --- Convergence: 4.93e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 67/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.45 1 + 0.46 value_stay[t] + 0.201 reward + -0.001 value_stay^2 + 0.256 value_stay*reward + -0.331 value_stay*harvest_duration + 0.66 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.054 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 75, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 468/1000 --- L(Train): 0.3654805 --- L(Val, RNN): 0.3455361 --- L(Val, SINDy): 0.4066587 --- Time: 4.42s; --- Convergence: 3.46e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 68/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.451 1 + 0.459 value_stay[t] + 0.202 reward + -0.002 value_stay^2 + 0.257 value_stay*reward + -0.331 value_stay*harvest_duration + 0.66 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.052 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 76, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 469/1000 --- L(Train): 0.3705725 --- L(Val, RNN): 0.3454995 --- L(Val, SINDy): 0.4059586 --- Time: 3.83s; --- Convergence: 3.56e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 69/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.452 1 + 0.459 value_stay[t] + 0.202 reward + -0.002 value_stay^2 + 0.258 value_stay*reward + -0.331 value_stay*harvest_duration + 0.66 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.05 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 77, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 1, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 470/1000 --- L(Train): 0.3657854 --- L(Val, RNN): 0.3454361 --- L(Val, SINDy): 0.4051760 --- Time: 3.93s; --- Convergence: 4.95e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 70/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.452 1 + 0.459 value_stay[t] + 0.203 reward + -0.003 value_stay^2 + 0.259 value_stay*reward + -0.331 value_stay*harvest_duration + 0.66 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.047 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 78, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 2, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 471/1000 --- L(Train): 0.3681871 --- L(Val, RNN): 0.3453911 --- L(Val, SINDy): 0.4043032 --- Time: 3.93s; --- Convergence: 4.72e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 71/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.453 1 + 0.458 value_stay[t] + 0.203 reward + -0.005 value_stay^2 + 0.259 value_stay*reward + -0.331 value_stay*harvest_duration + 0.66 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.045 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 79, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 3, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 472/1000 --- L(Train): 0.3692430 --- L(Val, RNN): 0.3453498 --- L(Val, SINDy): 0.4033465 --- Time: 2.96s; --- Convergence: 4.43e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 72/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.453 1 + 0.457 value_stay[t] + 0.202 reward + -0.006 value_stay^2 + 0.259 value_stay*reward + -0.332 value_stay*harvest_duration + 0.66 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.043 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 80, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 4, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 473/1000 --- L(Train): 0.3734902 --- L(Val, RNN): 0.3453241 --- L(Val, SINDy): 0.4025129 --- Time: 4.54s; --- Convergence: 3.50e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 73/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.454 1 + 0.457 value_stay[t] + 0.202 reward + -0.007 value_stay^2 + 0.259 value_stay*reward + -0.333 value_stay*harvest_duration + 0.659 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.041 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 81, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 5, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 474/1000 --- L(Train): 0.3730217 --- L(Val, RNN): 0.3452972 --- L(Val, SINDy): 0.4016408 --- Time: 3.14s; --- Convergence: 3.10e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 74/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.455 1 + 0.457 value_stay[t] + 0.202 reward + -0.007 value_stay^2 + 0.26 value_stay*reward + -0.332 value_stay*harvest_duration + 0.659 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.039 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 82, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 6, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 475/1000 --- L(Train): 0.3726875 --- L(Val, RNN): 0.3452435 --- L(Val, SINDy): 0.4008093 --- Time: 3.91s; --- Convergence: 4.23e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 75/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.457 1 + 0.458 value_stay[t] + 0.202 reward + -0.007 value_stay^2 + 0.261 value_stay*reward + -0.331 value_stay*harvest_duration + 0.659 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.037 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 83, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 7, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 476/1000 --- L(Train): 0.3737390 --- L(Val, RNN): 0.3451929 --- L(Val, SINDy): 0.3998232 --- Time: 4.82s; --- Convergence: 4.64e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 76/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.458 1 + 0.458 value_stay[t] + 0.203 reward + -0.007 value_stay^2 + 0.262 value_stay*reward + -0.331 value_stay*harvest_duration + 0.659 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.035 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 84, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 8, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 477/1000 --- L(Train): 0.3669684 --- L(Val, RNN): 0.3451518 --- L(Val, SINDy): 0.3987162 --- Time: 1.92s; --- Convergence: 4.38e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 77/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.459 1 + 0.459 value_stay[t] + 0.203 reward + -0.007 value_stay^2 + 0.262 value_stay*reward + -0.331 value_stay*harvest_duration + 0.659 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.033 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 85, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 9, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 478/1000 --- L(Train): 0.3701122 --- L(Val, RNN): 0.3450897 --- L(Val, SINDy): 0.3974814 --- Time: 1.85s; --- Convergence: 5.30e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 78/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.46 1 + 0.459 value_stay[t] + 0.203 reward + -0.006 value_stay^2 + 0.263 value_stay*reward + -0.331 value_stay*harvest_duration + 0.659 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.032 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 86, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 10, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 479/1000 --- L(Train): 0.3705098 --- L(Val, RNN): 0.3450239 --- L(Val, SINDy): 0.3902108 --- Time: 1.92s; --- Convergence: 5.94e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 79/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.461 1 + 0.46 value_stay[t] + 0.203 reward + -0.006 value_stay^2 + 0.264 value_stay*reward + -0.331 value_stay*harvest_duration + 0.658 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.03 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 87, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 11, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 480/1000 --- L(Train): 0.3678575 --- L(Val, RNN): 0.3449965 --- L(Val, SINDy): 0.3899887 --- Time: 1.51s; --- Convergence: 4.34e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 80/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.462 1 + 0.46 value_stay[t] + 0.203 reward + -0.006 value_stay^2 + 0.264 value_stay*reward + -0.331 value_stay*harvest_duration + 0.658 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.028 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 88, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 12, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 481/1000 --- L(Train): 0.3726833 --- L(Val, RNN): 0.3449732 --- L(Val, SINDy): 0.3896952 --- Time: 1.38s; --- Convergence: 3.33e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 81/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.463 1 + 0.461 value_stay[t] + 0.203 reward + -0.006 value_stay^2 + 0.265 value_stay*reward + -0.33 value_stay*harvest_duration + 0.658 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.027 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 89, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 13, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 482/1000 --- L(Train): 0.3689084 --- L(Val, RNN): 0.3449326 --- L(Val, SINDy): 0.3895976 --- Time: 1.09s; --- Convergence: 3.70e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 82/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.464 1 + 0.461 value_stay[t] + 0.202 reward + -0.006 value_stay^2 + 0.265 value_stay*reward + -0.331 value_stay*harvest_duration + 0.657 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.026 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 90, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 14, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 483/1000 --- L(Train): 0.3714116 --- L(Val, RNN): 0.3448871 --- L(Val, SINDy): 0.3893574 --- Time: 0.85s; --- Convergence: 4.12e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 83/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.465 1 + 0.46 value_stay[t] + 0.202 reward + -0.007 value_stay^2 + 0.264 value_stay*reward + -0.331 value_stay*harvest_duration + 0.656 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.024 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 91, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 15, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 484/1000 --- L(Train): 0.3697670 --- L(Val, RNN): 0.3448431 --- L(Val, SINDy): 0.3892559 --- Time: 1.06s; --- Convergence: 4.26e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 84/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.465 1 + 0.46 value_stay[t] + 0.201 reward + -0.008 value_stay^2 + 0.264 value_stay*reward + -0.332 value_stay*harvest_duration + 0.655 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.023 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 92, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 16, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 485/1000 --- L(Train): 0.3691989 --- L(Val, RNN): 0.3448027 --- L(Val, SINDy): 0.3893646 --- Time: 0.88s; --- Convergence: 4.15e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 85/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.466 1 + 0.46 value_stay[t] + 0.2 reward + -0.009 value_stay^2 + 0.263 value_stay*reward + -0.332 value_stay*harvest_duration + 0.654 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.022 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 93, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 17, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 486/1000 --- L(Train): 0.3722007 --- L(Val, RNN): 0.3448082 --- L(Val, SINDy): 0.3890905 --- Time: 1.00s; --- Convergence: 2.35e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 86/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.467 1 + 0.46 value_stay[t] + 0.2 reward + -0.009 value_stay^2 + 0.264 value_stay*reward + -0.332 value_stay*harvest_duration + 0.654 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.021 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 94, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 18, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 487/1000 --- L(Train): 0.3701658 --- L(Val, RNN): 0.3447977 --- L(Val, SINDy): 0.3887752 --- Time: 1.04s; --- Convergence: 1.70e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 87/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.468 1 + 0.461 value_stay[t] + 0.2 reward + -0.008 value_stay^2 + 0.265 value_stay*reward + -0.331 value_stay*harvest_duration + 0.654 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.02 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 95, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 19, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 488/1000 --- L(Train): 0.3726661 --- L(Val, RNN): 0.3447084 --- L(Val, SINDy): 0.3885655 --- Time: 0.83s; --- Convergence: 5.32e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 88/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.469 1 + 0.462 value_stay[t] + 0.2 reward + -0.007 value_stay^2 + 0.265 value_stay*reward + -0.329 value_stay*harvest_duration + 0.653 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.019 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 96, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 20, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 489/1000 --- L(Train): 0.3666119 --- L(Val, RNN): 0.3446021 --- L(Val, SINDy): 0.3884603 --- Time: 0.89s; --- Convergence: 7.97e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 89/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.47 1 + 0.463 value_stay[t] + 0.2 reward + -0.006 value_stay^2 + 0.266 value_stay*reward + -0.328 value_stay*harvest_duration + 0.653 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.018 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 97, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 21, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 490/1000 --- L(Train): 0.3691347 --- L(Val, RNN): 0.3445840 --- L(Val, SINDy): 0.3881683 --- Time: 0.99s; --- Convergence: 4.89e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 90/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.471 1 + 0.463 value_stay[t] + 0.2 reward + -0.006 value_stay^2 + 0.266 value_stay*reward + -0.328 value_stay*harvest_duration + 0.653 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.017 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 98, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 22, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 491/1000 --- L(Train): 0.3701485 --- L(Val, RNN): 0.3446094 --- L(Val, SINDy): 0.3878242 --- Time: 0.89s; --- Convergence: 3.71e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 91/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.471 1 + 0.463 value_stay[t] + 0.199 reward + -0.006 value_stay^2 + 0.267 value_stay*reward + -0.327 value_stay*harvest_duration + 0.652 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.016 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 99, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 23, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 492/1000 --- L(Train): 0.3743506 --- L(Val, RNN): 0.3445883 --- L(Val, SINDy): 0.3876110 --- Time: 1.05s; --- Convergence: 2.91e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 92/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.472 1 + 0.462 value_stay[t] + 0.199 reward + 0.267 value_stay*reward + -0.327 value_stay*harvest_duration + 0.652 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.015 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 24, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 493/1000 --- L(Train): 0.3665832 --- L(Val, RNN): 0.3444941 --- L(Val, SINDy): 0.3875657 --- Time: 0.88s; --- Convergence: 6.17e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 93/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.472 1 + 0.462 value_stay[t] + 0.199 reward + 0.267 value_stay*reward + -0.327 value_stay*harvest_duration + 0.651 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.014 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 25, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 494/1000 --- L(Train): 0.3660432 --- L(Val, RNN): 0.3444289 --- L(Val, SINDy): 0.3874678 --- Time: 1.16s; --- Convergence: 6.34e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 94/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.472 1 + 0.461 value_stay[t] + 0.198 reward + 0.267 value_stay*reward + -0.327 value_stay*harvest_duration + 0.651 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.013 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 26, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 495/1000 --- L(Train): 0.3665302 --- L(Val, RNN): 0.3444220 --- L(Val, SINDy): 0.3872454 --- Time: 0.91s; --- Convergence: 3.52e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 95/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.472 1 + 0.461 value_stay[t] + 0.198 reward + 0.267 value_stay*reward + -0.327 value_stay*harvest_duration + 0.65 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.013 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 27, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 496/1000 --- L(Train): 0.3711646 --- L(Val, RNN): 0.3444180 --- L(Val, SINDy): 0.3870362 --- Time: 0.85s; --- Convergence: 1.95e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 96/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.473 1 + 0.46 value_stay[t] + 0.198 reward + 0.267 value_stay*reward + -0.327 value_stay*harvest_duration + 0.65 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.012 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 28, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 497/1000 --- L(Train): 0.3633914 --- L(Val, RNN): 0.3443672 --- L(Val, SINDy): 0.3869735 --- Time: 0.85s; --- Convergence: 3.52e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 97/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.473 1 + 0.459 value_stay[t] + 0.197 reward + 0.266 value_stay*reward + -0.327 value_stay*harvest_duration + 0.649 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.011 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 29, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 498/1000 --- L(Train): 0.3652858 --- L(Val, RNN): 0.3442998 --- L(Val, SINDy): 0.3869306 --- Time: 0.99s; --- Convergence: 5.13e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 98/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.474 1 + 0.46 value_stay[t] + 0.199 reward + 0.268 value_stay*reward + -0.325 value_stay*harvest_duration + 0.65 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.011 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 30, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 499/1000 --- L(Train): 0.3694041 --- L(Val, RNN): 0.3442630 --- L(Val, SINDy): 0.3867461 --- Time: 1.01s; --- Convergence: 4.41e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 99/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.477 1 + 0.462 value_stay[t] + 0.201 reward + 0.271 value_stay*reward + -0.322 value_stay*harvest_duration + 0.653 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.01 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 31, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 500/1000 --- L(Train): 0.3692845 --- L(Val, RNN): 0.3442353 --- L(Val, SINDy): 0.3866070 --- Time: 1.10s; --- Convergence: 3.58e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.479 1 + 0.464 value_stay[t] + 0.203 reward + 0.273 value_stay*reward + -0.32 value_stay*harvest_duration + 0.654 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.009 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 32, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 501/1000 --- L(Train): 0.3647441 --- L(Val, RNN): 0.3441973 --- L(Val, SINDy): 0.3864539 --- Time: 0.92s; --- Convergence: 3.69e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 1/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.481 1 + 0.465 value_stay[t] + 0.204 reward + 0.274 value_stay*reward + -0.319 value_stay*harvest_duration + 0.655 reward^2 + 0.208 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.009 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 33, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 502/1000 --- L(Train): 0.3705634 --- L(Val, RNN): 0.3441466 --- L(Val, SINDy): 0.3869449 --- Time: 0.92s; --- Convergence: 4.38e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 2/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.482 1 + 0.464 value_stay[t] + 0.204 reward + 0.274 value_stay*reward + -0.319 value_stay*harvest_duration + 0.655 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.008 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 34, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 503/1000 --- L(Train): 0.3646459 --- L(Val, RNN): 0.3441068 --- L(Val, SINDy): 0.3867967 --- Time: 0.85s; --- Convergence: 4.18e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 3/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.48 1 + 0.461 value_stay[t] + 0.202 reward + 0.271 value_stay*reward + -0.322 value_stay*harvest_duration + 0.653 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.008 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 35, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 504/1000 --- L(Train): 0.3636296 --- L(Val, RNN): 0.3440905 --- L(Val, SINDy): 0.3864077 --- Time: 0.78s; --- Convergence: 2.91e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 4/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.478 1 + 0.457 value_stay[t] + 0.2 reward + 0.268 value_stay*reward + -0.326 value_stay*harvest_duration + 0.65 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.007 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 36, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 505/1000 --- L(Train): 0.3610073 --- L(Val, RNN): 0.3440702 --- L(Val, SINDy): 0.3860923 --- Time: 0.88s; --- Convergence: 2.47e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 5/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.477 1 + 0.454 value_stay[t] + 0.199 reward + 0.266 value_stay*reward + -0.328 value_stay*harvest_duration + 0.649 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.007 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 37, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 506/1000 --- L(Train): 0.3718454 --- L(Val, RNN): 0.3440401 --- L(Val, SINDy): 0.3859821 --- Time: 1.01s; --- Convergence: 2.74e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 6/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.479 1 + 0.455 value_stay[t] + 0.2 reward + 0.267 value_stay*reward + -0.328 value_stay*harvest_duration + 0.65 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.007 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 38, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 507/1000 --- L(Train): 0.3618016 --- L(Val, RNN): 0.3439894 --- L(Val, SINDy): 0.3860320 --- Time: 0.92s; --- Convergence: 3.90e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 7/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.48 1 + 0.456 value_stay[t] + 0.201 reward + 0.268 value_stay*reward + -0.327 value_stay*harvest_duration + 0.651 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.006 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 39, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 508/1000 --- L(Train): 0.3642789 --- L(Val, RNN): 0.3439571 --- L(Val, SINDy): 0.3861868 --- Time: 0.99s; --- Convergence: 3.57e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 8/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.482 1 + 0.456 value_stay[t] + 0.203 reward + 0.269 value_stay*reward + -0.326 value_stay*harvest_duration + 0.652 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.006 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 40, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 509/1000 --- L(Train): 0.3629949 --- L(Val, RNN): 0.3439481 --- L(Val, SINDy): 0.3861590 --- Time: 0.77s; --- Convergence: 2.24e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 9/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.483 1 + 0.457 value_stay[t] + 0.204 reward + 0.271 value_stay*reward + -0.325 value_stay*harvest_duration + 0.653 reward^2 + 0.208 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.005 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 41, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 510/1000 --- L(Train): 0.3639279 --- L(Val, RNN): 0.3439304 --- L(Val, SINDy): 0.3861838 --- Time: 0.83s; --- Convergence: 2.00e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 10/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.485 1 + 0.457 value_stay[t] + 0.205 reward + 0.272 value_stay*reward + -0.325 value_stay*harvest_duration + 0.653 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.005 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 42, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 511/1000 --- L(Train): 0.3659389 --- L(Val, RNN): 0.3438947 --- L(Val, SINDy): 0.3862823 --- Time: 0.87s; --- Convergence: 2.78e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 11/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.486 1 + 0.457 value_stay[t] + 0.205 reward + 0.272 value_stay*reward + -0.324 value_stay*harvest_duration + 0.654 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.005 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 43, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 512/1000 --- L(Train): 0.3694316 --- L(Val, RNN): 0.3438468 --- L(Val, SINDy): 0.3865724 --- Time: 0.85s; --- Convergence: 3.79e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 12/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.486 1 + 0.457 value_stay[t] + 0.205 reward + 0.272 value_stay*reward + -0.324 value_stay*harvest_duration + 0.654 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.005 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 44, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 513/1000 --- L(Train): 0.3613293 --- L(Val, RNN): 0.3438208 --- L(Val, SINDy): 0.3865302 --- Time: 1.18s; --- Convergence: 3.19e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 13/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.487 1 + 0.456 value_stay[t] + 0.205 reward + 0.271 value_stay*reward + -0.325 value_stay*harvest_duration + 0.653 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.004 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 45, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 514/1000 --- L(Train): 0.3642024 --- L(Val, RNN): 0.3438081 --- L(Val, SINDy): 0.3864008 --- Time: 0.94s; --- Convergence: 2.24e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 14/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.487 1 + 0.455 value_stay[t] + 0.205 reward + 0.271 value_stay*reward + -0.325 value_stay*harvest_duration + 0.653 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.004 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 46, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 515/1000 --- L(Train): 0.3647425 --- L(Val, RNN): 0.3437966 --- L(Val, SINDy): 0.3863511 --- Time: 0.99s; --- Convergence: 1.69e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 15/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.487 1 + 0.454 value_stay[t] + 0.204 reward + 0.27 value_stay*reward + -0.326 value_stay*harvest_duration + 0.652 reward^2 + 0.208 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.004 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 47, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 516/1000 --- L(Train): 0.3695446 --- L(Val, RNN): 0.3437771 --- L(Val, SINDy): 0.3863072 --- Time: 1.26s; --- Convergence: 1.82e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 16/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.487 1 + 0.454 value_stay[t] + 0.204 reward + 0.269 value_stay*reward + -0.327 value_stay*harvest_duration + 0.651 reward^2 + 0.208 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.004 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 48, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 517/1000 --- L(Train): 0.3653282 --- L(Val, RNN): 0.3437473 --- L(Val, SINDy): 0.3862334 --- Time: 1.70s; --- Convergence: 2.40e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 17/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.489 1 + 0.454 value_stay[t] + 0.205 reward + 0.27 value_stay*reward + -0.326 value_stay*harvest_duration + 0.652 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.003 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 49, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 518/1000 --- L(Train): 0.3693472 --- L(Val, RNN): 0.3437114 --- L(Val, SINDy): 0.3861579 --- Time: 1.15s; --- Convergence: 2.99e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 18/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.491 1 + 0.456 value_stay[t] + 0.206 reward + 0.272 value_stay*reward + -0.324 value_stay*harvest_duration + 0.653 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.003 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 50, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 519/1000 --- L(Train): 0.3669060 --- L(Val, RNN): 0.3436812 --- L(Val, SINDy): 0.3857056 --- Time: 0.91s; --- Convergence: 3.01e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 19/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.493 1 + 0.458 value_stay[t] + 0.207 reward + 0.274 value_stay*reward + -0.322 value_stay*harvest_duration + 0.654 reward^2 + 0.211 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.003 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 51, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 520/1000 --- L(Train): 0.3634162 --- L(Val, RNN): 0.3436606 --- L(Val, SINDy): 0.3854290 --- Time: 1.11s; --- Convergence: 2.53e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 20/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.495 1 + 0.459 value_stay[t] + 0.208 reward + 0.275 value_stay*reward + -0.321 value_stay*harvest_duration + 0.654 reward^2 + 0.212 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.003 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 52, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 521/1000 --- L(Train): 0.3652404 --- L(Val, RNN): 0.3436430 --- L(Val, SINDy): 0.3852577 --- Time: 0.99s; --- Convergence: 2.15e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 21/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.495 1 + 0.458 value_stay[t] + 0.208 reward + 0.274 value_stay*reward + -0.321 value_stay*harvest_duration + 0.653 reward^2 + 0.212 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.003 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 53, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 522/1000 --- L(Train): 0.3649713 --- L(Val, RNN): 0.3436220 --- L(Val, SINDy): 0.3852593 --- Time: 0.95s; --- Convergence: 2.12e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 22/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.495 1 + 0.456 value_stay[t] + 0.206 reward + 0.272 value_stay*reward + -0.323 value_stay*harvest_duration + 0.651 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 54, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 523/1000 --- L(Train): 0.3637085 --- L(Val, RNN): 0.3436047 --- L(Val, SINDy): 0.3852507 --- Time: 1.17s; --- Convergence: 1.93e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 23/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.494 1 + 0.455 value_stay[t] + 0.205 reward + 0.27 value_stay*reward + -0.325 value_stay*harvest_duration + 0.65 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 55, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 524/1000 --- L(Train): 0.3690872 --- L(Val, RNN): 0.3435935 --- L(Val, SINDy): 0.3852004 --- Time: 0.83s; --- Convergence: 1.52e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 24/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.494 1 + 0.453 value_stay[t] + 0.203 reward + 0.269 value_stay*reward + -0.326 value_stay*harvest_duration + 0.648 reward^2 + 0.208 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 56, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 525/1000 --- L(Train): 0.3629631 --- L(Val, RNN): 0.3435710 --- L(Val, SINDy): 0.3851233 --- Time: 0.81s; --- Convergence: 1.89e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 25/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.494 1 + 0.452 value_stay[t] + 0.203 reward + 0.268 value_stay*reward + -0.327 value_stay*harvest_duration + 0.647 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 57, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 526/1000 --- L(Train): 0.3687652 --- L(Val, RNN): 0.3435443 --- L(Val, SINDy): 0.3850049 --- Time: 1.14s; --- Convergence: 2.28e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 26/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.496 1 + 0.453 value_stay[t] + 0.203 reward + 0.269 value_stay*reward + -0.326 value_stay*harvest_duration + 0.647 reward^2 + 0.208 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 58, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 527/1000 --- L(Train): 0.3659714 --- L(Val, RNN): 0.3435265 --- L(Val, SINDy): 0.3849169 --- Time: 1.15s; --- Convergence: 2.03e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 27/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.498 1 + 0.455 value_stay[t] + 0.205 reward + 0.271 value_stay*reward + -0.324 value_stay*harvest_duration + 0.648 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 59, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 528/1000 --- L(Train): 0.3661322 --- L(Val, RNN): 0.3435068 --- L(Val, SINDy): 0.3848862 --- Time: 0.90s; --- Convergence: 2.00e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 28/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.5 1 + 0.457 value_stay[t] + 0.206 reward + 0.273 value_stay*reward + -0.322 value_stay*harvest_duration + 0.649 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 60, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 529/1000 --- L(Train): 0.3642037 --- L(Val, RNN): 0.3434909 --- L(Val, SINDy): 0.3848641 --- Time: 1.02s; --- Convergence: 1.79e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 29/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.501 1 + 0.458 value_stay[t] + 0.207 reward + 0.274 value_stay*reward + -0.321 value_stay*harvest_duration + 0.65 reward^2 + 0.211 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 61, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 530/1000 --- L(Train): 0.3683787 --- L(Val, RNN): 0.3434753 --- L(Val, SINDy): 0.3847640 --- Time: 1.19s; --- Convergence: 1.68e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 30/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.502 1 + 0.458 value_stay[t] + 0.208 reward + 0.275 value_stay*reward + -0.321 value_stay*harvest_duration + 0.65 reward^2 + 0.212 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 62, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 531/1000 --- L(Train): 0.3622389 --- L(Val, RNN): 0.3434475 --- L(Val, SINDy): 0.3846807 --- Time: 1.28s; --- Convergence: 2.23e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 31/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.503 1 + 0.458 value_stay[t] + 0.208 reward + 0.276 value_stay*reward + -0.32 value_stay*harvest_duration + 0.651 reward^2 + 0.212 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 63, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 532/1000 --- L(Train): 0.3625254 --- L(Val, RNN): 0.3434214 --- L(Val, SINDy): 0.3845554 --- Time: 1.12s; --- Convergence: 2.42e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 32/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.503 1 + 0.457 value_stay[t] + 0.208 reward + 0.276 value_stay*reward + -0.321 value_stay*harvest_duration + 0.65 reward^2 + 0.212 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 64, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 533/1000 --- L(Train): 0.3665890 --- L(Val, RNN): 0.3433937 --- L(Val, SINDy): 0.3844197 --- Time: 1.20s; --- Convergence: 2.60e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 33/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.502 1 + 0.456 value_stay[t] + 0.207 reward + 0.275 value_stay*reward + -0.322 value_stay*harvest_duration + 0.649 reward^2 + 0.211 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 65, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 534/1000 --- L(Train): 0.3659846 --- L(Val, RNN): 0.3433613 --- L(Val, SINDy): 0.3843498 --- Time: 1.25s; --- Convergence: 2.92e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 34/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.501 1 + 0.454 value_stay[t] + 0.206 reward + 0.273 value_stay*reward + -0.324 value_stay*harvest_duration + 0.647 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 66, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 535/1000 --- L(Train): 0.3679020 --- L(Val, RNN): 0.3433402 --- L(Val, SINDy): 0.3842421 --- Time: 1.36s; --- Convergence: 2.51e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 35/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.501 1 + 0.452 value_stay[t] + 0.205 reward + 0.272 value_stay*reward + -0.325 value_stay*harvest_duration + 0.646 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 67, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 536/1000 --- L(Train): 0.3651432 --- L(Val, RNN): 0.3433251 --- L(Val, SINDy): 0.3840971 --- Time: 1.59s; --- Convergence: 2.01e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 36/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.501 1 + 0.452 value_stay[t] + 0.205 reward + 0.273 value_stay*reward + -0.324 value_stay*harvest_duration + 0.645 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 68, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 537/1000 --- L(Train): 0.3637676 --- L(Val, RNN): 0.3432965 --- L(Val, SINDy): 0.3840265 --- Time: 1.12s; --- Convergence: 2.44e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 37/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.502 1 + 0.453 value_stay[t] + 0.205 reward + 0.274 value_stay*reward + -0.323 value_stay*harvest_duration + 0.646 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 69, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 538/1000 --- L(Train): 0.3680082 --- L(Val, RNN): 0.3432626 --- L(Val, SINDy): 0.3839793 --- Time: 1.28s; --- Convergence: 2.91e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 38/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.504 1 + 0.455 value_stay[t] + 0.207 reward + 0.276 value_stay*reward + -0.32 value_stay*harvest_duration + 0.646 reward^2 + 0.211 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 70, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 539/1000 --- L(Train): 0.3681235 --- L(Val, RNN): 0.3432288 --- L(Val, SINDy): 0.3839189 --- Time: 1.42s; --- Convergence: 3.14e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 39/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.506 1 + 0.456 value_stay[t] + 0.207 reward + 0.277 value_stay*reward + -0.318 value_stay*harvest_duration + 0.647 reward^2 + 0.212 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 71, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 540/1000 --- L(Train): 0.3663154 --- L(Val, RNN): 0.3431999 --- L(Val, SINDy): 0.3838030 --- Time: 1.98s; --- Convergence: 3.02e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 40/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.507 1 + 0.457 value_stay[t] + 0.208 reward + 0.278 value_stay*reward + -0.317 value_stay*harvest_duration + 0.647 reward^2 + 0.212 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 72, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 541/1000 --- L(Train): 0.3654511 --- L(Val, RNN): 0.3431812 --- L(Val, SINDy): 0.3836257 --- Time: 2.58s; --- Convergence: 2.44e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 41/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.508 1 + 0.457 value_stay[t] + 0.208 reward + 0.278 value_stay*reward + -0.317 value_stay*harvest_duration + 0.646 reward^2 + 0.212 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 73, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 542/1000 --- L(Train): 0.3617485 --- L(Val, RNN): 0.3431684 --- L(Val, SINDy): 0.3834546 --- Time: 3.88s; --- Convergence: 1.86e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 42/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.507 1 + 0.456 value_stay[t] + 0.207 reward + 0.277 value_stay*reward + -0.317 value_stay*harvest_duration + 0.645 reward^2 + 0.211 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 74, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 543/1000 --- L(Train): 0.3657504 --- L(Val, RNN): 0.3431467 --- L(Val, SINDy): 0.3833325 --- Time: 4.12s; --- Convergence: 2.02e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 43/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.506 1 + 0.453 value_stay[t] + 0.206 reward + 0.276 value_stay*reward + -0.319 value_stay*harvest_duration + 0.644 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 75, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 544/1000 --- L(Train): 0.3663920 --- L(Val, RNN): 0.3431181 --- L(Val, SINDy): 0.3832791 --- Time: 2.55s; --- Convergence: 2.44e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 44/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.506 1 + 0.451 value_stay[t] + 0.205 reward + 0.275 value_stay*reward + -0.321 value_stay*harvest_duration + 0.643 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 76, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 545/1000 --- L(Train): 0.3630203 --- L(Val, RNN): 0.3430866 --- L(Val, SINDy): 0.3832024 --- Time: 2.45s; --- Convergence: 2.80e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 45/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.506 1 + 0.451 value_stay[t] + 0.205 reward + 0.275 value_stay*reward + -0.321 value_stay*harvest_duration + 0.642 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 77, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 546/1000 --- L(Train): 0.3658516 --- L(Val, RNN): 0.3430578 --- L(Val, SINDy): 0.3831146 --- Time: 2.43s; --- Convergence: 2.84e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 46/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.507 1 + 0.451 value_stay[t] + 0.206 reward + 0.276 value_stay*reward + -0.321 value_stay*harvest_duration + 0.642 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 78, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 547/1000 --- L(Train): 0.3640478 --- L(Val, RNN): 0.3430391 --- L(Val, SINDy): 0.3830053 --- Time: 2.30s; --- Convergence: 2.36e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 47/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.507 1 + 0.45 value_stay[t] + 0.206 reward + 0.276 value_stay*reward + -0.321 value_stay*harvest_duration + 0.642 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 79, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 548/1000 --- L(Train): 0.3640516 --- L(Val, RNN): 0.3430222 --- L(Val, SINDy): 0.3829255 --- Time: 3.09s; --- Convergence: 2.02e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 48/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.509 1 + 0.451 value_stay[t] + 0.207 reward + 0.277 value_stay*reward + -0.32 value_stay*harvest_duration + 0.643 reward^2 + 0.211 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 80, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 549/1000 --- L(Train): 0.3586763 --- L(Val, RNN): 0.3430047 --- L(Val, SINDy): 0.3828850 --- Time: 2.86s; --- Convergence: 1.88e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 49/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.51 1 + 0.451 value_stay[t] + 0.208 reward + 0.278 value_stay*reward + -0.319 value_stay*harvest_duration + 0.643 reward^2 + 0.212 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 81, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 550/1000 --- L(Train): 0.3705635 --- L(Val, RNN): 0.3429877 --- L(Val, SINDy): 0.3828650 --- Time: 1.94s; --- Convergence: 1.79e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 50/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.511 1 + 0.452 value_stay[t] + 0.209 reward + 0.279 value_stay*reward + -0.318 value_stay*harvest_duration + 0.644 reward^2 + 0.213 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 82, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 551/1000 --- L(Train): 0.3663258 --- L(Val, RNN): 0.3429645 --- L(Val, SINDy): 0.3828220 --- Time: 1.66s; --- Convergence: 2.06e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 51/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.511 1 + 0.451 value_stay[t] + 0.209 reward + 0.28 value_stay*reward + -0.319 value_stay*harvest_duration + 0.643 reward^2 + 0.213 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 83, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 552/1000 --- L(Train): 0.3666076 --- L(Val, RNN): 0.3429381 --- L(Val, SINDy): 0.3827398 --- Time: 2.88s; --- Convergence: 2.35e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 52/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.512 1 + 0.45 value_stay[t] + 0.209 reward + 0.279 value_stay*reward + -0.319 value_stay*harvest_duration + 0.643 reward^2 + 0.213 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 84, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 553/1000 --- L(Train): 0.3660104 --- L(Val, RNN): 0.3429167 --- L(Val, SINDy): 0.3826372 --- Time: 4.12s; --- Convergence: 2.24e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 53/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.512 1 + 0.449 value_stay[t] + 0.209 reward + 0.279 value_stay*reward + -0.32 value_stay*harvest_duration + 0.643 reward^2 + 0.213 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 85, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 554/1000 --- L(Train): 0.3609335 --- L(Val, RNN): 0.3429018 --- L(Val, SINDy): 0.3824848 --- Time: 5.14s; --- Convergence: 1.87e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 54/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.512 1 + 0.448 value_stay[t] + 0.209 reward + 0.279 value_stay*reward + -0.321 value_stay*harvest_duration + 0.642 reward^2 + 0.213 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 86, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 555/1000 --- L(Train): 0.3621766 --- L(Val, RNN): 0.3428927 --- L(Val, SINDy): 0.3824051 --- Time: 5.45s; --- Convergence: 1.39e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 55/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.512 1 + 0.448 value_stay[t] + 0.209 reward + 0.279 value_stay*reward + -0.321 value_stay*harvest_duration + 0.642 reward^2 + 0.213 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 87, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 556/1000 --- L(Train): 0.3623827 --- L(Val, RNN): 0.3428798 --- L(Val, SINDy): 0.3823571 --- Time: 2.13s; --- Convergence: 1.34e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 56/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.512 1 + 0.447 value_stay[t] + 0.209 reward + 0.279 value_stay*reward + -0.322 value_stay*harvest_duration + 0.642 reward^2 + 0.213 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 88, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 557/1000 --- L(Train): 0.3650373 --- L(Val, RNN): 0.3428560 --- L(Val, SINDy): 0.3823522 --- Time: 1.23s; --- Convergence: 1.86e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 57/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.513 1 + 0.447 value_stay[t] + 0.21 reward + 0.28 value_stay*reward + -0.322 value_stay*harvest_duration + 0.642 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 89, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 558/1000 --- L(Train): 0.3576426 --- L(Val, RNN): 0.3428297 --- L(Val, SINDy): 0.3823220 --- Time: 1.12s; --- Convergence: 2.25e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 58/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.514 1 + 0.447 value_stay[t] + 0.21 reward + 0.281 value_stay*reward + -0.322 value_stay*harvest_duration + 0.643 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 90, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 559/1000 --- L(Train): 0.3609682 --- L(Val, RNN): 0.3428059 --- L(Val, SINDy): 0.3822565 --- Time: 1.17s; --- Convergence: 2.31e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 59/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.515 1 + 0.447 value_stay[t] + 0.211 reward + 0.282 value_stay*reward + -0.321 value_stay*harvest_duration + 0.643 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 91, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 560/1000 --- L(Train): 0.3640748 --- L(Val, RNN): 0.3427873 --- L(Val, SINDy): 0.3821236 --- Time: 1.00s; --- Convergence: 2.09e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 60/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.516 1 + 0.448 value_stay[t] + 0.212 reward + 0.283 value_stay*reward + -0.321 value_stay*harvest_duration + 0.643 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 92, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 561/1000 --- L(Train): 0.3621508 --- L(Val, RNN): 0.3427744 --- L(Val, SINDy): 0.3819216 --- Time: 0.95s; --- Convergence: 1.69e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 61/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.517 1 + 0.448 value_stay[t] + 0.212 reward + 0.283 value_stay*reward + -0.32 value_stay*harvest_duration + 0.643 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 93, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 562/1000 --- L(Train): 0.3636276 --- L(Val, RNN): 0.3427622 --- L(Val, SINDy): 0.3817240 --- Time: 0.93s; --- Convergence: 1.45e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 62/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.517 1 + 0.447 value_stay[t] + 0.211 reward + 0.283 value_stay*reward + -0.321 value_stay*harvest_duration + 0.642 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 94, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 563/1000 --- L(Train): 0.3613627 --- L(Val, RNN): 0.3427342 --- L(Val, SINDy): 0.3816149 --- Time: 0.97s; --- Convergence: 2.13e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 63/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.517 1 + 0.446 value_stay[t] + 0.21 reward + 0.283 value_stay*reward + -0.322 value_stay*harvest_duration + 0.641 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 95, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 564/1000 --- L(Train): 0.3626023 --- L(Val, RNN): 0.3427013 --- L(Val, SINDy): 0.3815654 --- Time: 1.16s; --- Convergence: 2.71e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 64/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.517 1 + 0.446 value_stay[t] + 0.21 reward + 0.283 value_stay*reward + -0.322 value_stay*harvest_duration + 0.64 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 96, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 565/1000 --- L(Train): 0.3620121 --- L(Val, RNN): 0.3426766 --- L(Val, SINDy): 0.3815646 --- Time: 1.37s; --- Convergence: 2.59e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 65/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.518 1 + 0.446 value_stay[t] + 0.211 reward + 0.284 value_stay*reward + -0.322 value_stay*harvest_duration + 0.64 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 97, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 566/1000 --- L(Train): 0.3628227 --- L(Val, RNN): 0.3426652 --- L(Val, SINDy): 0.3814716 --- Time: 1.04s; --- Convergence: 1.86e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 66/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.519 1 + 0.447 value_stay[t] + 0.211 reward + 0.285 value_stay*reward + -0.321 value_stay*harvest_duration + 0.64 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 98, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 567/1000 --- L(Train): 0.3608483 --- L(Val, RNN): 0.3426556 --- L(Val, SINDy): 0.3812990 --- Time: 1.03s; --- Convergence: 1.41e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 67/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.521 1 + 0.448 value_stay[t] + 0.212 reward + 0.287 value_stay*reward + -0.32 value_stay*harvest_duration + 0.64 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 99, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 568/1000 --- L(Train): 0.3623815 --- L(Val, RNN): 0.3426216 --- L(Val, SINDy): 0.3811940 --- Time: 1.11s; --- Convergence: 2.41e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 68/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.522 1 + 0.449 value_stay[t] + 0.213 reward + 0.288 value_stay*reward + -0.32 value_stay*harvest_duration + 0.64 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 569/1000 --- L(Train): 0.3661499 --- L(Val, RNN): 0.3425831 --- L(Val, SINDy): 0.3811698 --- Time: 0.92s; --- Convergence: 3.12e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 69/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.521 1 + 0.447 value_stay[t] + 0.212 reward + 0.286 value_stay*reward + -0.321 value_stay*harvest_duration + 0.639 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 570/1000 --- L(Train): 0.3606897 --- L(Val, RNN): 0.3425637 --- L(Val, SINDy): 0.3811240 --- Time: 1.05s; --- Convergence: 2.54e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 70/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.521 1 + 0.446 value_stay[t] + 0.21 reward + 0.285 value_stay*reward + -0.323 value_stay*harvest_duration + 0.637 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 571/1000 --- L(Train): 0.3633547 --- L(Val, RNN): 0.3425567 --- L(Val, SINDy): 0.3810612 --- Time: 0.94s; --- Convergence: 1.62e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 71/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.521 1 + 0.444 value_stay[t] + 0.21 reward + 0.285 value_stay*reward + -0.324 value_stay*harvest_duration + 0.636 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 572/1000 --- L(Train): 0.3672169 --- L(Val, RNN): 0.3425515 --- L(Val, SINDy): 0.3809696 --- Time: 0.92s; --- Convergence: 1.07e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 72/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.522 1 + 0.445 value_stay[t] + 0.21 reward + 0.286 value_stay*reward + -0.323 value_stay*harvest_duration + 0.636 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 573/1000 --- L(Train): 0.3642777 --- L(Val, RNN): 0.3425333 --- L(Val, SINDy): 0.3808821 --- Time: 0.84s; --- Convergence: 1.44e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 73/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.524 1 + 0.446 value_stay[t] + 0.211 reward + 0.288 value_stay*reward + -0.321 value_stay*harvest_duration + 0.636 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 574/1000 --- L(Train): 0.3642775 --- L(Val, RNN): 0.3425005 --- L(Val, SINDy): 0.3808663 --- Time: 0.93s; --- Convergence: 2.36e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 74/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.525 1 + 0.446 value_stay[t] + 0.211 reward + 0.288 value_stay*reward + -0.321 value_stay*harvest_duration + 0.636 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 575/1000 --- L(Train): 0.3624990 --- L(Val, RNN): 0.3424727 --- L(Val, SINDy): 0.3808321 --- Time: 0.95s; --- Convergence: 2.57e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 75/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.525 1 + 0.446 value_stay[t] + 0.211 reward + 0.289 value_stay*reward + -0.321 value_stay*harvest_duration + 0.635 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 576/1000 --- L(Train): 0.3577339 --- L(Val, RNN): 0.3424709 --- L(Val, SINDy): 0.3806777 --- Time: 1.17s; --- Convergence: 1.38e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 76/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.526 1 + 0.445 value_stay[t] + 0.211 reward + 0.289 value_stay*reward + -0.321 value_stay*harvest_duration + 0.634 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 577/1000 --- L(Train): 0.3622602 --- L(Val, RNN): 0.3424700 --- L(Val, SINDy): 0.3805240 --- Time: 0.89s; --- Convergence: 7.31e-06; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 77/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.526 1 + 0.444 value_stay[t] + 0.21 reward + 0.288 value_stay*reward + -0.322 value_stay*harvest_duration + 0.633 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 578/1000 --- L(Train): 0.3660682 --- L(Val, RNN): 0.3424579 --- L(Val, SINDy): 0.3804989 --- Time: 0.89s; --- Convergence: 9.75e-06; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 78/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.526 1 + 0.443 value_stay[t] + 0.21 reward + 0.288 value_stay*reward + -0.322 value_stay*harvest_duration + 0.631 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 579/1000 --- L(Train): 0.3619913 --- L(Val, RNN): 0.3424436 --- L(Val, SINDy): 0.3805393 --- Time: 1.24s; --- Convergence: 1.20e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 79/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.526 1 + 0.442 value_stay[t] + 0.21 reward + 0.288 value_stay*reward + -0.322 value_stay*harvest_duration + 0.63 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 580/1000 --- L(Train): 0.3619173 --- L(Val, RNN): 0.3424174 --- L(Val, SINDy): 0.3805666 --- Time: 1.18s; --- Convergence: 1.91e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 80/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.527 1 + 0.442 value_stay[t] + 0.21 reward + 0.289 value_stay*reward + -0.322 value_stay*harvest_duration + 0.63 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 581/1000 --- L(Train): 0.3659081 --- L(Val, RNN): 0.3423817 --- L(Val, SINDy): 0.3805253 --- Time: 1.13s; --- Convergence: 2.74e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 81/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.527 1 + 0.442 value_stay[t] + 0.21 reward + 0.29 value_stay*reward + -0.322 value_stay*harvest_duration + 0.63 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 582/1000 --- L(Train): 0.3644541 --- L(Val, RNN): 0.3423732 --- L(Val, SINDy): 0.3803266 --- Time: 1.20s; --- Convergence: 1.80e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 82/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.528 1 + 0.442 value_stay[t] + 0.211 reward + 0.291 value_stay*reward + -0.322 value_stay*harvest_duration + 0.63 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 583/1000 --- L(Train): 0.3615425 --- L(Val, RNN): 0.3423684 --- L(Val, SINDy): 0.3801395 --- Time: 1.23s; --- Convergence: 1.14e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 83/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.529 1 + 0.442 value_stay[t] + 0.211 reward + 0.292 value_stay*reward + -0.322 value_stay*harvest_duration + 0.63 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 584/1000 --- L(Train): 0.3658529 --- L(Val, RNN): 0.3423447 --- L(Val, SINDy): 0.3800513 --- Time: 0.87s; --- Convergence: 1.75e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 84/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.529 1 + 0.441 value_stay[t] + 0.211 reward + 0.292 value_stay*reward + -0.323 value_stay*harvest_duration + 0.629 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 585/1000 --- L(Train): 0.3599625 --- L(Val, RNN): 0.3423179 --- L(Val, SINDy): 0.3800439 --- Time: 0.87s; --- Convergence: 2.22e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 85/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.529 1 + 0.44 value_stay[t] + 0.211 reward + 0.293 value_stay*reward + -0.323 value_stay*harvest_duration + 0.628 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 586/1000 --- L(Train): 0.3605773 --- L(Val, RNN): 0.3423015 --- L(Val, SINDy): 0.3799653 --- Time: 0.90s; --- Convergence: 1.93e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 86/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.53 1 + 0.439 value_stay[t] + 0.211 reward + 0.293 value_stay*reward + -0.323 value_stay*harvest_duration + 0.628 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 587/1000 --- L(Train): 0.3604962 --- L(Val, RNN): 0.3422893 --- L(Val, SINDy): 0.3798243 --- Time: 0.98s; --- Convergence: 1.58e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 87/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.531 1 + 0.439 value_stay[t] + 0.212 reward + 0.294 value_stay*reward + -0.323 value_stay*harvest_duration + 0.627 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 588/1000 --- L(Train): 0.3681714 --- L(Val, RNN): 0.3422758 --- L(Val, SINDy): 0.3796985 --- Time: 0.92s; --- Convergence: 1.46e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 88/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.531 1 + 0.438 value_stay[t] + 0.212 reward + 0.295 value_stay*reward + -0.323 value_stay*harvest_duration + 0.627 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 589/1000 --- L(Train): 0.3643793 --- L(Val, RNN): 0.3422542 --- L(Val, SINDy): 0.3796640 --- Time: 0.97s; --- Convergence: 1.81e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 89/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.532 1 + 0.438 value_stay[t] + 0.212 reward + 0.295 value_stay*reward + -0.323 value_stay*harvest_duration + 0.627 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 590/1000 --- L(Train): 0.3615069 --- L(Val, RNN): 0.3422268 --- L(Val, SINDy): 0.3796621 --- Time: 1.06s; --- Convergence: 2.28e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 90/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.533 1 + 0.438 value_stay[t] + 0.212 reward + 0.296 value_stay*reward + -0.323 value_stay*harvest_duration + 0.627 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 591/1000 --- L(Train): 0.3656744 --- L(Val, RNN): 0.3422016 --- L(Val, SINDy): 0.3795224 --- Time: 0.90s; --- Convergence: 2.40e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 91/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.533 1 + 0.437 value_stay[t] + 0.212 reward + 0.296 value_stay*reward + -0.323 value_stay*harvest_duration + 0.626 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 592/1000 --- L(Train): 0.3643988 --- L(Val, RNN): 0.3421845 --- L(Val, SINDy): 0.3795120 --- Time: 1.02s; --- Convergence: 2.05e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 92/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.533 1 + 0.437 value_stay[t] + 0.212 reward + 0.296 value_stay*reward + -0.323 value_stay*harvest_duration + 0.625 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 593/1000 --- L(Train): 0.3698106 --- L(Val, RNN): 0.3421700 --- L(Val, SINDy): 0.3794172 --- Time: 1.04s; --- Convergence: 1.75e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 93/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.534 1 + 0.436 value_stay[t] + 0.211 reward + 0.295 value_stay*reward + -0.323 value_stay*harvest_duration + 0.624 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 594/1000 --- L(Train): 0.3619542 --- L(Val, RNN): 0.3421596 --- L(Val, SINDy): 0.3793224 --- Time: 1.09s; --- Convergence: 1.39e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 94/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.534 1 + 0.435 value_stay[t] + 0.211 reward + 0.295 value_stay*reward + -0.324 value_stay*harvest_duration + 0.623 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 595/1000 --- L(Train): 0.3608983 --- L(Val, RNN): 0.3421503 --- L(Val, SINDy): 0.3792485 --- Time: 1.22s; --- Convergence: 1.16e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 95/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.534 1 + 0.435 value_stay[t] + 0.21 reward + 0.295 value_stay*reward + -0.324 value_stay*harvest_duration + 0.622 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 596/1000 --- L(Train): 0.3583156 --- L(Val, RNN): 0.3421380 --- L(Val, SINDy): 0.3792336 --- Time: 1.02s; --- Convergence: 1.20e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 96/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.535 1 + 0.435 value_stay[t] + 0.21 reward + 0.295 value_stay*reward + -0.323 value_stay*harvest_duration + 0.621 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 597/1000 --- L(Train): 0.3661791 --- L(Val, RNN): 0.3421132 --- L(Val, SINDy): 0.3792148 --- Time: 0.91s; --- Convergence: 1.84e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 97/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.535 1 + 0.435 value_stay[t] + 0.21 reward + 0.295 value_stay*reward + -0.322 value_stay*harvest_duration + 0.62 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 598/1000 --- L(Train): 0.3616232 --- L(Val, RNN): 0.3420779 --- L(Val, SINDy): 0.3791458 --- Time: 0.95s; --- Convergence: 2.68e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 98/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.536 1 + 0.436 value_stay[t] + 0.21 reward + 0.296 value_stay*reward + -0.321 value_stay*harvest_duration + 0.62 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 599/1000 --- L(Train): 0.3621583 --- L(Val, RNN): 0.3420607 --- L(Val, SINDy): 0.3789503 --- Time: 0.86s; --- Convergence: 2.20e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 99/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.537 1 + 0.436 value_stay[t] + 0.211 reward + 0.297 value_stay*reward + -0.32 value_stay*harvest_duration + 0.62 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 600/1000 --- L(Train): 0.3589615 --- L(Val, RNN): 0.3420403 --- L(Val, SINDy): 0.3787663 --- Time: 1.04s; --- Convergence: 2.12e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.538 1 + 0.437 value_stay[t] + 0.211 reward + 0.298 value_stay*reward + -0.319 value_stay*harvest_duration + 0.62 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 601/1000 --- L(Train): 0.3620219 --- L(Val, RNN): 0.3420265 --- L(Val, SINDy): 0.3787298 --- Time: 0.94s; --- Convergence: 1.75e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 1/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.539 1 + 0.437 value_stay[t] + 0.211 reward + 0.298 value_stay*reward + -0.319 value_stay*harvest_duration + 0.62 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 602/1000 --- L(Train): 0.3634082 --- L(Val, RNN): 0.3420174 --- L(Val, SINDy): 0.3786880 --- Time: 0.95s; --- Convergence: 1.33e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 2/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.54 1 + 0.436 value_stay[t] + 0.211 reward + 0.299 value_stay*reward + -0.319 value_stay*harvest_duration + 0.619 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 603/1000 --- L(Train): 0.3645284 --- L(Val, RNN): 0.3420129 --- L(Val, SINDy): 0.3786290 --- Time: 1.00s; --- Convergence: 8.93e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 3/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.54 1 + 0.436 value_stay[t] + 0.211 reward + 0.298 value_stay*reward + -0.319 value_stay*harvest_duration + 0.618 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 604/1000 --- L(Train): 0.3642260 --- L(Val, RNN): 0.3420009 --- L(Val, SINDy): 0.3786610 --- Time: 1.09s; --- Convergence: 1.04e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 4/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.541 1 + 0.435 value_stay[t] + 0.211 reward + 0.298 value_stay*reward + -0.319 value_stay*harvest_duration + 0.618 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 605/1000 --- L(Train): 0.3574764 --- L(Val, RNN): 0.3419888 --- L(Val, SINDy): 0.3786747 --- Time: 1.03s; --- Convergence: 1.13e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 5/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.541 1 + 0.435 value_stay[t] + 0.211 reward + 0.298 value_stay*reward + -0.319 value_stay*harvest_duration + 0.617 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 606/1000 --- L(Train): 0.3643435 --- L(Val, RNN): 0.3419784 --- L(Val, SINDy): 0.3786298 --- Time: 1.14s; --- Convergence: 1.09e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 6/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.542 1 + 0.434 value_stay[t] + 0.211 reward + 0.298 value_stay*reward + -0.32 value_stay*harvest_duration + 0.616 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 607/1000 --- L(Train): 0.3567380 --- L(Val, RNN): 0.3419709 --- L(Val, SINDy): 0.3785442 --- Time: 0.80s; --- Convergence: 9.19e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 7/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.542 1 + 0.434 value_stay[t] + 0.211 reward + 0.299 value_stay*reward + -0.319 value_stay*harvest_duration + 0.616 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 608/1000 --- L(Train): 0.3588273 --- L(Val, RNN): 0.3419652 --- L(Val, SINDy): 0.3784112 --- Time: 0.83s; --- Convergence: 7.41e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 8/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.543 1 + 0.434 value_stay[t] + 0.212 reward + 0.3 value_stay*reward + -0.319 value_stay*harvest_duration + 0.617 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 609/1000 --- L(Train): 0.3619881 --- L(Val, RNN): 0.3419586 --- L(Val, SINDy): 0.3783429 --- Time: 0.97s; --- Convergence: 7.03e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 9/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.544 1 + 0.434 value_stay[t] + 0.212 reward + 0.3 value_stay*reward + -0.319 value_stay*harvest_duration + 0.617 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 610/1000 --- L(Train): 0.3657564 --- L(Val, RNN): 0.3419466 --- L(Val, SINDy): 0.3783420 --- Time: 0.88s; --- Convergence: 9.52e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 10/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.545 1 + 0.434 value_stay[t] + 0.213 reward + 0.301 value_stay*reward + -0.319 value_stay*harvest_duration + 0.617 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 611/1000 --- L(Train): 0.3663440 --- L(Val, RNN): 0.3419330 --- L(Val, SINDy): 0.3783582 --- Time: 0.92s; --- Convergence: 1.15e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 11/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.545 1 + 0.433 value_stay[t] + 0.213 reward + 0.301 value_stay*reward + -0.319 value_stay*harvest_duration + 0.617 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 612/1000 --- L(Train): 0.3650921 --- L(Val, RNN): 0.3419230 --- L(Val, SINDy): 0.3783421 --- Time: 0.86s; --- Convergence: 1.08e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 12/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.545 1 + 0.433 value_stay[t] + 0.213 reward + 0.301 value_stay*reward + -0.32 value_stay*harvest_duration + 0.616 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 613/1000 --- L(Train): 0.3624527 --- L(Val, RNN): 0.3419205 --- L(Val, SINDy): 0.3782842 --- Time: 0.82s; --- Convergence: 6.65e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 13/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.545 1 + 0.432 value_stay[t] + 0.213 reward + 0.302 value_stay*reward + -0.32 value_stay*harvest_duration + 0.616 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 614/1000 --- L(Train): 0.3618668 --- L(Val, RNN): 0.3419220 --- L(Val, SINDy): 0.3782052 --- Time: 1.02s; --- Convergence: 4.10e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 14/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.546 1 + 0.431 value_stay[t] + 0.213 reward + 0.302 value_stay*reward + -0.321 value_stay*harvest_duration + 0.616 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 615/1000 --- L(Train): 0.3629475 --- L(Val, RNN): 0.3419182 --- L(Val, SINDy): 0.3781466 --- Time: 0.84s; --- Convergence: 3.94e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 15/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.546 1 + 0.43 value_stay[t] + 0.213 reward + 0.302 value_stay*reward + -0.322 value_stay*harvest_duration + 0.615 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 616/1000 --- L(Train): 0.3676503 --- L(Val, RNN): 0.3419096 --- L(Val, SINDy): 0.3780737 --- Time: 0.99s; --- Convergence: 6.31e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 16/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.546 1 + 0.43 value_stay[t] + 0.213 reward + 0.302 value_stay*reward + -0.322 value_stay*harvest_duration + 0.615 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 617/1000 --- L(Train): 0.3621689 --- L(Val, RNN): 0.3418997 --- L(Val, SINDy): 0.3780175 --- Time: 1.19s; --- Convergence: 8.09e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 17/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.547 1 + 0.43 value_stay[t] + 0.214 reward + 0.303 value_stay*reward + -0.322 value_stay*harvest_duration + 0.615 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 618/1000 --- L(Train): 0.3588872 --- L(Val, RNN): 0.3418910 --- L(Val, SINDy): 0.3780015 --- Time: 1.12s; --- Convergence: 8.38e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 18/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.548 1 + 0.43 value_stay[t] + 0.214 reward + 0.304 value_stay*reward + -0.321 value_stay*harvest_duration + 0.615 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 619/1000 --- L(Train): 0.3660077 --- L(Val, RNN): 0.3418856 --- L(Val, SINDy): 0.3780595 --- Time: 1.33s; --- Convergence: 6.89e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 19/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.549 1 + 0.431 value_stay[t] + 0.214 reward + 0.304 value_stay*reward + -0.32 value_stay*harvest_duration + 0.614 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 620/1000 --- L(Train): 0.3615175 --- L(Val, RNN): 0.3418836 --- L(Val, SINDy): 0.3780865 --- Time: 3.26s; --- Convergence: 4.46e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 20/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.55 1 + 0.431 value_stay[t] + 0.214 reward + 0.304 value_stay*reward + -0.319 value_stay*harvest_duration + 0.613 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 621/1000 --- L(Train): 0.3642443 --- L(Val, RNN): 0.3418860 --- L(Val, SINDy): 0.3780331 --- Time: 1.99s; --- Convergence: 3.44e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 21/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.55 1 + 0.43 value_stay[t] + 0.213 reward + 0.303 value_stay*reward + -0.32 value_stay*harvest_duration + 0.612 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 622/1000 --- L(Train): 0.3612081 --- L(Val, RNN): 0.3418823 --- L(Val, SINDy): 0.3779435 --- Time: 4.06s; --- Convergence: 3.57e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 22/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.55 1 + 0.429 value_stay[t] + 0.212 reward + 0.302 value_stay*reward + -0.321 value_stay*harvest_duration + 0.61 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 623/1000 --- L(Train): 0.3656524 --- L(Val, RNN): 0.3418749 --- L(Val, SINDy): 0.3778699 --- Time: 3.32s; --- Convergence: 5.51e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 23/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.55 1 + 0.428 value_stay[t] + 0.212 reward + 0.302 value_stay*reward + -0.321 value_stay*harvest_duration + 0.609 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 624/1000 --- L(Train): 0.3598296 --- L(Val, RNN): 0.3418649 --- L(Val, SINDy): 0.3778403 --- Time: 2.09s; --- Convergence: 7.75e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 24/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.551 1 + 0.427 value_stay[t] + 0.212 reward + 0.303 value_stay*reward + -0.321 value_stay*harvest_duration + 0.609 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 625/1000 --- L(Train): 0.3591668 --- L(Val, RNN): 0.3418538 --- L(Val, SINDy): 0.3778292 --- Time: 2.29s; --- Convergence: 9.43e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 25/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.551 1 + 0.427 value_stay[t] + 0.212 reward + 0.304 value_stay*reward + -0.321 value_stay*harvest_duration + 0.609 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 626/1000 --- L(Train): 0.3616627 --- L(Val, RNN): 0.3418486 --- L(Val, SINDy): 0.3777905 --- Time: 3.55s; --- Convergence: 7.29e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 26/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.552 1 + 0.428 value_stay[t] + 0.213 reward + 0.305 value_stay*reward + -0.32 value_stay*harvest_duration + 0.609 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 627/1000 --- L(Train): 0.3562533 --- L(Val, RNN): 0.3418441 --- L(Val, SINDy): 0.3777660 --- Time: 1.87s; --- Convergence: 5.90e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 27/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.554 1 + 0.428 value_stay[t] + 0.214 reward + 0.307 value_stay*reward + -0.318 value_stay*harvest_duration + 0.609 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 628/1000 --- L(Train): 0.3664028 --- L(Val, RNN): 0.3418393 --- L(Val, SINDy): 0.3777508 --- Time: 2.75s; --- Convergence: 5.38e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 28/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.554 1 + 0.428 value_stay[t] + 0.214 reward + 0.307 value_stay*reward + -0.318 value_stay*harvest_duration + 0.608 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 629/1000 --- L(Train): 0.3591440 --- L(Val, RNN): 0.3418280 --- L(Val, SINDy): 0.3777277 --- Time: 2.46s; --- Convergence: 8.31e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 29/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.555 1 + 0.428 value_stay[t] + 0.213 reward + 0.308 value_stay*reward + -0.318 value_stay*harvest_duration + 0.607 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 630/1000 --- L(Train): 0.3659040 --- L(Val, RNN): 0.3418100 --- L(Val, SINDy): 0.3776730 --- Time: 2.92s; --- Convergence: 1.32e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 30/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.555 1 + 0.426 value_stay[t] + 0.213 reward + 0.307 value_stay*reward + -0.319 value_stay*harvest_duration + 0.606 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 631/1000 --- L(Train): 0.3611558 --- L(Val, RNN): 0.3417903 --- L(Val, SINDy): 0.3776374 --- Time: 2.68s; --- Convergence: 1.64e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 31/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.555 1 + 0.425 value_stay[t] + 0.212 reward + 0.307 value_stay*reward + -0.319 value_stay*harvest_duration + 0.605 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 632/1000 --- L(Train): 0.3613176 --- L(Val, RNN): 0.3417744 --- L(Val, SINDy): 0.3775899 --- Time: 2.49s; --- Convergence: 1.61e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 32/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.555 1 + 0.424 value_stay[t] + 0.212 reward + 0.307 value_stay*reward + -0.32 value_stay*harvest_duration + 0.604 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 633/1000 --- L(Train): 0.3632334 --- L(Val, RNN): 0.3417686 --- L(Val, SINDy): 0.3774695 --- Time: 2.16s; --- Convergence: 1.10e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 33/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.555 1 + 0.423 value_stay[t] + 0.212 reward + 0.307 value_stay*reward + -0.32 value_stay*harvest_duration + 0.603 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 634/1000 --- L(Train): 0.3653057 --- L(Val, RNN): 0.3417658 --- L(Val, SINDy): 0.3773617 --- Time: 2.85s; --- Convergence: 6.91e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 34/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.556 1 + 0.423 value_stay[t] + 0.212 reward + 0.308 value_stay*reward + -0.32 value_stay*harvest_duration + 0.603 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 635/1000 --- L(Train): 0.3574790 --- L(Val, RNN): 0.3417650 --- L(Val, SINDy): 0.3772391 --- Time: 3.38s; --- Convergence: 3.83e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 35/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.557 1 + 0.424 value_stay[t] + 0.213 reward + 0.31 value_stay*reward + -0.319 value_stay*harvest_duration + 0.604 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 636/1000 --- L(Train): 0.3648139 --- L(Val, RNN): 0.3417566 --- L(Val, SINDy): 0.3772228 --- Time: 3.39s; --- Convergence: 6.14e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 36/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.559 1 + 0.425 value_stay[t] + 0.214 reward + 0.312 value_stay*reward + -0.317 value_stay*harvest_duration + 0.604 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 637/1000 --- L(Train): 0.3590020 --- L(Val, RNN): 0.3417400 --- L(Val, SINDy): 0.3772922 --- Time: 1.77s; --- Convergence: 1.14e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 37/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.56 1 + 0.425 value_stay[t] + 0.215 reward + 0.312 value_stay*reward + -0.317 value_stay*harvest_duration + 0.604 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 638/1000 --- L(Train): 0.3648155 --- L(Val, RNN): 0.3417270 --- L(Val, SINDy): 0.3772949 --- Time: 2.30s; --- Convergence: 1.22e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 38/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.561 1 + 0.425 value_stay[t] + 0.215 reward + 0.313 value_stay*reward + -0.317 value_stay*harvest_duration + 0.603 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 639/1000 --- L(Train): 0.3640892 --- L(Val, RNN): 0.3417230 --- L(Val, SINDy): 0.3771772 --- Time: 2.10s; --- Convergence: 8.09e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 39/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.56 1 + 0.423 value_stay[t] + 0.214 reward + 0.312 value_stay*reward + -0.318 value_stay*harvest_duration + 0.601 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 640/1000 --- L(Train): 0.3602675 --- L(Val, RNN): 0.3417216 --- L(Val, SINDy): 0.3770520 --- Time: 1.91s; --- Convergence: 4.76e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 40/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.56 1 + 0.421 value_stay[t] + 0.212 reward + 0.31 value_stay*reward + -0.32 value_stay*harvest_duration + 0.6 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 641/1000 --- L(Train): 0.3576217 --- L(Val, RNN): 0.3417166 --- L(Val, SINDy): 0.3769947 --- Time: 0.88s; --- Convergence: 4.85e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 41/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.56 1 + 0.421 value_stay[t] + 0.212 reward + 0.31 value_stay*reward + -0.321 value_stay*harvest_duration + 0.599 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 642/1000 --- L(Train): 0.3660133 --- L(Val, RNN): 0.3417084 --- L(Val, SINDy): 0.3770321 --- Time: 0.90s; --- Convergence: 6.52e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 42/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.561 1 + 0.42 value_stay[t] + 0.212 reward + 0.311 value_stay*reward + -0.321 value_stay*harvest_duration + 0.598 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 643/1000 --- L(Train): 0.3546817 --- L(Val, RNN): 0.3417006 --- L(Val, SINDy): 0.3771248 --- Time: 1.20s; --- Convergence: 7.20e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 43/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.562 1 + 0.421 value_stay[t] + 0.213 reward + 0.313 value_stay*reward + -0.319 value_stay*harvest_duration + 0.598 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 644/1000 --- L(Train): 0.3588096 --- L(Val, RNN): 0.3416958 --- L(Val, SINDy): 0.3770957 --- Time: 1.14s; --- Convergence: 5.95e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 44/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.564 1 + 0.423 value_stay[t] + 0.214 reward + 0.314 value_stay*reward + -0.318 value_stay*harvest_duration + 0.598 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 645/1000 --- L(Train): 0.3636984 --- L(Val, RNN): 0.3416950 --- L(Val, SINDy): 0.3770362 --- Time: 1.03s; --- Convergence: 3.39e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 45/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.565 1 + 0.423 value_stay[t] + 0.215 reward + 0.316 value_stay*reward + -0.317 value_stay*harvest_duration + 0.598 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 646/1000 --- L(Train): 0.3630505 --- L(Val, RNN): 0.3416893 --- L(Val, SINDy): 0.3768636 --- Time: 1.22s; --- Convergence: 4.53e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 46/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.566 1 + 0.423 value_stay[t] + 0.214 reward + 0.316 value_stay*reward + -0.316 value_stay*harvest_duration + 0.597 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 647/1000 --- L(Train): 0.3605965 --- L(Val, RNN): 0.3416797 --- L(Val, SINDy): 0.3768050 --- Time: 0.90s; --- Convergence: 7.11e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 47/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.566 1 + 0.422 value_stay[t] + 0.213 reward + 0.314 value_stay*reward + -0.318 value_stay*harvest_duration + 0.595 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 648/1000 --- L(Train): 0.3639513 --- L(Val, RNN): 0.3416632 --- L(Val, SINDy): 0.3768978 --- Time: 0.90s; --- Convergence: 1.18e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 48/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.565 1 + 0.42 value_stay[t] + 0.211 reward + 0.313 value_stay*reward + -0.319 value_stay*harvest_duration + 0.593 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 649/1000 --- L(Train): 0.3573262 --- L(Val, RNN): 0.3416502 --- L(Val, SINDy): 0.3770624 --- Time: 0.90s; --- Convergence: 1.24e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 49/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.565 1 + 0.419 value_stay[t] + 0.21 reward + 0.311 value_stay*reward + -0.32 value_stay*harvest_duration + 0.591 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 650/1000 --- L(Train): 0.3599604 --- L(Val, RNN): 0.3416466 --- L(Val, SINDy): 0.3770877 --- Time: 0.92s; --- Convergence: 8.01e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 50/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.566 1 + 0.419 value_stay[t] + 0.21 reward + 0.312 value_stay*reward + -0.319 value_stay*harvest_duration + 0.591 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 651/1000 --- L(Train): 0.3624707 --- L(Val, RNN): 0.3416475 --- L(Val, SINDy): 0.3769781 --- Time: 1.17s; --- Convergence: 4.45e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 51/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.567 1 + 0.42 value_stay[t] + 0.211 reward + 0.313 value_stay*reward + -0.317 value_stay*harvest_duration + 0.591 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 652/1000 --- L(Train): 0.3636895 --- L(Val, RNN): 0.3416509 --- L(Val, SINDy): 0.3767871 --- Time: 1.03s; --- Convergence: 3.92e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 52/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.568 1 + 0.421 value_stay[t] + 0.211 reward + 0.314 value_stay*reward + -0.316 value_stay*harvest_duration + 0.591 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 653/1000 --- L(Train): 0.3607150 --- L(Val, RNN): 0.3416485 --- L(Val, SINDy): 0.3766414 --- Time: 0.88s; --- Convergence: 3.17e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 53/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.569 1 + 0.421 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.315 value_stay*harvest_duration + 0.59 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 654/1000 --- L(Train): 0.3557492 --- L(Val, RNN): 0.3416319 --- L(Val, SINDy): 0.3766315 --- Time: 1.29s; --- Convergence: 9.88e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 54/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.57 1 + 0.421 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.315 value_stay*harvest_duration + 0.59 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 655/1000 --- L(Train): 0.3625109 --- L(Val, RNN): 0.3416095 --- L(Val, SINDy): 0.3767032 --- Time: 1.44s; --- Convergence: 1.61e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 55/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.57 1 + 0.42 value_stay[t] + 0.212 reward + 0.316 value_stay*reward + -0.315 value_stay*harvest_duration + 0.59 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 656/1000 --- L(Train): 0.3608837 --- L(Val, RNN): 0.3415927 --- L(Val, SINDy): 0.3767112 --- Time: 1.62s; --- Convergence: 1.65e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 56/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.571 1 + 0.42 value_stay[t] + 0.212 reward + 0.316 value_stay*reward + -0.314 value_stay*harvest_duration + 0.59 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 657/1000 --- L(Train): 0.3625047 --- L(Val, RNN): 0.3415880 --- L(Val, SINDy): 0.3766240 --- Time: 1.19s; --- Convergence: 1.06e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 57/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.571 1 + 0.419 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.315 value_stay*harvest_duration + 0.589 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 658/1000 --- L(Train): 0.3610261 --- L(Val, RNN): 0.3415899 --- L(Val, SINDy): 0.3765411 --- Time: 1.14s; --- Convergence: 6.21e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 58/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.571 1 + 0.417 value_stay[t] + 0.211 reward + 0.314 value_stay*reward + -0.316 value_stay*harvest_duration + 0.588 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 659/1000 --- L(Train): 0.3572452 --- L(Val, RNN): 0.3415890 --- L(Val, SINDy): 0.3764585 --- Time: 1.04s; --- Convergence: 3.52e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 59/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.57 1 + 0.416 value_stay[t] + 0.21 reward + 0.313 value_stay*reward + -0.317 value_stay*harvest_duration + 0.587 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 660/1000 --- L(Train): 0.3606377 --- L(Val, RNN): 0.3415786 --- L(Val, SINDy): 0.3764251 --- Time: 0.94s; --- Convergence: 6.98e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 60/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.571 1 + 0.416 value_stay[t] + 0.21 reward + 0.314 value_stay*reward + -0.316 value_stay*harvest_duration + 0.586 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 661/1000 --- L(Train): 0.3598684 --- L(Val, RNN): 0.3415594 --- L(Val, SINDy): 0.3763767 --- Time: 1.07s; --- Convergence: 1.31e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 61/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.573 1 + 0.416 value_stay[t] + 0.211 reward + 0.314 value_stay*reward + -0.316 value_stay*harvest_duration + 0.587 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 662/1000 --- L(Train): 0.3643670 --- L(Val, RNN): 0.3415404 --- L(Val, SINDy): 0.3764144 --- Time: 1.29s; --- Convergence: 1.60e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 62/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.574 1 + 0.417 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.314 value_stay*harvest_duration + 0.587 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 663/1000 --- L(Train): 0.3637523 --- L(Val, RNN): 0.3415310 --- L(Val, SINDy): 0.3763593 --- Time: 1.01s; --- Convergence: 1.27e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 63/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.575 1 + 0.418 value_stay[t] + 0.212 reward + 0.316 value_stay*reward + -0.313 value_stay*harvest_duration + 0.587 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 664/1000 --- L(Train): 0.3600869 --- L(Val, RNN): 0.3415297 --- L(Val, SINDy): 0.3762352 --- Time: 0.97s; --- Convergence: 7.04e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 64/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.576 1 + 0.418 value_stay[t] + 0.212 reward + 0.316 value_stay*reward + -0.313 value_stay*harvest_duration + 0.587 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 665/1000 --- L(Train): 0.3585068 --- L(Val, RNN): 0.3415238 --- L(Val, SINDy): 0.3761833 --- Time: 1.16s; --- Convergence: 6.47e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 65/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.576 1 + 0.417 value_stay[t] + 0.212 reward + 0.316 value_stay*reward + -0.313 value_stay*harvest_duration + 0.586 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 666/1000 --- L(Train): 0.3579481 --- L(Val, RNN): 0.3415175 --- L(Val, SINDy): 0.3761733 --- Time: 1.24s; --- Convergence: 6.38e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 66/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.576 1 + 0.416 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.314 value_stay*harvest_duration + 0.586 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 667/1000 --- L(Train): 0.3649154 --- L(Val, RNN): 0.3415122 --- L(Val, SINDy): 0.3761111 --- Time: 1.18s; --- Convergence: 5.81e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 67/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.577 1 + 0.415 value_stay[t] + 0.211 reward + 0.314 value_stay*reward + -0.314 value_stay*harvest_duration + 0.585 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 668/1000 --- L(Train): 0.3626155 --- L(Val, RNN): 0.3415118 --- L(Val, SINDy): 0.3760544 --- Time: 1.24s; --- Convergence: 3.13e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 68/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.577 1 + 0.415 value_stay[t] + 0.211 reward + 0.314 value_stay*reward + -0.314 value_stay*harvest_duration + 0.585 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 669/1000 --- L(Train): 0.3628088 --- L(Val, RNN): 0.3415109 --- L(Val, SINDy): 0.3760453 --- Time: 1.01s; --- Convergence: 2.01e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 69/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.578 1 + 0.414 value_stay[t] + 0.211 reward + 0.314 value_stay*reward + -0.314 value_stay*harvest_duration + 0.584 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 670/1000 --- L(Train): 0.3598355 --- L(Val, RNN): 0.3415110 --- L(Val, SINDy): 0.3760951 --- Time: 1.02s; --- Convergence: 1.04e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 70/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.579 1 + 0.415 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.313 value_stay*harvest_duration + 0.585 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 671/1000 --- L(Train): 0.3649501 --- L(Val, RNN): 0.3415113 --- L(Val, SINDy): 0.3761322 --- Time: 1.16s; --- Convergence: 7.12e-07; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 71/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.58 1 + 0.415 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.312 value_stay*harvest_duration + 0.585 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 672/1000 --- L(Train): 0.3583632 --- L(Val, RNN): 0.3415067 --- L(Val, SINDy): 0.3761136 --- Time: 1.13s; --- Convergence: 2.68e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 72/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.581 1 + 0.415 value_stay[t] + 0.212 reward + 0.316 value_stay*reward + -0.311 value_stay*harvest_duration + 0.585 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 673/1000 --- L(Train): 0.3589538 --- L(Val, RNN): 0.3414986 --- L(Val, SINDy): 0.3760851 --- Time: 0.98s; --- Convergence: 5.39e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 73/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.582 1 + 0.415 value_stay[t] + 0.212 reward + 0.316 value_stay*reward + -0.311 value_stay*harvest_duration + 0.585 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 674/1000 --- L(Train): 0.3595826 --- L(Val, RNN): 0.3414883 --- L(Val, SINDy): 0.3760397 --- Time: 0.93s; --- Convergence: 7.82e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 74/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.582 1 + 0.415 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.311 value_stay*harvest_duration + 0.584 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 675/1000 --- L(Train): 0.3609232 --- L(Val, RNN): 0.3414819 --- L(Val, SINDy): 0.3759878 --- Time: 0.98s; --- Convergence: 7.13e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 75/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.583 1 + 0.415 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.311 value_stay*harvest_duration + 0.584 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 676/1000 --- L(Train): 0.3568865 --- L(Val, RNN): 0.3414816 --- L(Val, SINDy): 0.3759101 --- Time: 1.19s; --- Convergence: 3.71e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 76/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.583 1 + 0.414 value_stay[t] + 0.212 reward + 0.314 value_stay*reward + -0.311 value_stay*harvest_duration + 0.583 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 677/1000 --- L(Train): 0.3592932 --- L(Val, RNN): 0.3414803 --- L(Val, SINDy): 0.3758247 --- Time: 0.95s; --- Convergence: 2.53e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 77/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.583 1 + 0.413 value_stay[t] + 0.212 reward + 0.314 value_stay*reward + -0.312 value_stay*harvest_duration + 0.583 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 678/1000 --- L(Train): 0.3604621 --- L(Val, RNN): 0.3414704 --- L(Val, SINDy): 0.3757730 --- Time: 1.13s; --- Convergence: 6.20e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 78/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.584 1 + 0.413 value_stay[t] + 0.212 reward + 0.314 value_stay*reward + -0.312 value_stay*harvest_duration + 0.583 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 679/1000 --- L(Train): 0.3585027 --- L(Val, RNN): 0.3414547 --- L(Val, SINDy): 0.3757894 --- Time: 0.97s; --- Convergence: 1.09e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 79/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.584 1 + 0.413 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.312 value_stay*harvest_duration + 0.583 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 680/1000 --- L(Train): 0.3581427 --- L(Val, RNN): 0.3414408 --- L(Val, SINDy): 0.3757972 --- Time: 0.96s; --- Convergence: 1.24e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 80/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.585 1 + 0.413 value_stay[t] + 0.213 reward + 0.316 value_stay*reward + -0.312 value_stay*harvest_duration + 0.584 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 681/1000 --- L(Train): 0.3588038 --- L(Val, RNN): 0.3414340 --- L(Val, SINDy): 0.3757443 --- Time: 1.09s; --- Convergence: 9.60e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 81/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.586 1 + 0.413 value_stay[t] + 0.214 reward + 0.317 value_stay*reward + -0.312 value_stay*harvest_duration + 0.585 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 682/1000 --- L(Train): 0.3685688 --- L(Val, RNN): 0.3414296 --- L(Val, SINDy): 0.3756595 --- Time: 0.91s; --- Convergence: 7.01e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 82/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.586 1 + 0.412 value_stay[t] + 0.214 reward + 0.317 value_stay*reward + -0.312 value_stay*harvest_duration + 0.585 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 683/1000 --- L(Train): 0.3618478 --- L(Val, RNN): 0.3414228 --- L(Val, SINDy): 0.3755871 --- Time: 1.26s; --- Convergence: 6.90e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 83/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.586 1 + 0.412 value_stay[t] + 0.214 reward + 0.318 value_stay*reward + -0.312 value_stay*harvest_duration + 0.585 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 684/1000 --- L(Train): 0.3588219 --- L(Val, RNN): 0.3414117 --- L(Val, SINDy): 0.3755218 --- Time: 0.96s; --- Convergence: 9.01e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 84/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.587 1 + 0.412 value_stay[t] + 0.215 reward + 0.318 value_stay*reward + -0.312 value_stay*harvest_duration + 0.585 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 685/1000 --- L(Train): 0.3667223 --- L(Val, RNN): 0.3413967 --- L(Val, SINDy): 0.3755517 --- Time: 0.89s; --- Convergence: 1.20e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 85/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.587 1 + 0.411 value_stay[t] + 0.215 reward + 0.319 value_stay*reward + -0.313 value_stay*harvest_duration + 0.585 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 686/1000 --- L(Train): 0.3570832 --- L(Val, RNN): 0.3413818 --- L(Val, SINDy): 0.3755606 --- Time: 0.98s; --- Convergence: 1.35e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 86/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.588 1 + 0.411 value_stay[t] + 0.215 reward + 0.32 value_stay*reward + -0.314 value_stay*harvest_duration + 0.585 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 687/1000 --- L(Train): 0.3603348 --- L(Val, RNN): 0.3413779 --- L(Val, SINDy): 0.3754926 --- Time: 1.15s; --- Convergence: 8.71e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 87/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.588 1 + 0.41 value_stay[t] + 0.216 reward + 0.32 value_stay*reward + -0.314 value_stay*harvest_duration + 0.585 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 688/1000 --- L(Train): 0.3593707 --- L(Val, RNN): 0.3413732 --- L(Val, SINDy): 0.3753872 --- Time: 0.93s; --- Convergence: 6.69e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 88/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.589 1 + 0.41 value_stay[t] + 0.216 reward + 0.321 value_stay*reward + -0.314 value_stay*harvest_duration + 0.584 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 689/1000 --- L(Train): 0.3586486 --- L(Val, RNN): 0.3413670 --- L(Val, SINDy): 0.3753463 --- Time: 0.85s; --- Convergence: 6.45e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 89/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.589 1 + 0.41 value_stay[t] + 0.216 reward + 0.321 value_stay*reward + -0.314 value_stay*harvest_duration + 0.584 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 690/1000 --- L(Train): 0.3627514 --- L(Val, RNN): 0.3413566 --- L(Val, SINDy): 0.3753290 --- Time: 1.05s; --- Convergence: 8.41e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 90/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.59 1 + 0.41 value_stay[t] + 0.216 reward + 0.322 value_stay*reward + -0.315 value_stay*harvest_duration + 0.583 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 691/1000 --- L(Train): 0.3606988 --- L(Val, RNN): 0.3413469 --- L(Val, SINDy): 0.3752808 --- Time: 1.04s; --- Convergence: 9.03e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 91/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.59 1 + 0.409 value_stay[t] + 0.216 reward + 0.322 value_stay*reward + -0.315 value_stay*harvest_duration + 0.583 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 692/1000 --- L(Train): 0.3638946 --- L(Val, RNN): 0.3413372 --- L(Val, SINDy): 0.3752518 --- Time: 0.85s; --- Convergence: 9.40e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 92/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.591 1 + 0.409 value_stay[t] + 0.216 reward + 0.323 value_stay*reward + -0.315 value_stay*harvest_duration + 0.582 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 693/1000 --- L(Train): 0.3663177 --- L(Val, RNN): 0.3413325 --- L(Val, SINDy): 0.3751965 --- Time: 0.96s; --- Convergence: 7.03e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 93/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.591 1 + 0.409 value_stay[t] + 0.216 reward + 0.323 value_stay*reward + -0.315 value_stay*harvest_duration + 0.581 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 694/1000 --- L(Train): 0.3607577 --- L(Val, RNN): 0.3413276 --- L(Val, SINDy): 0.3751430 --- Time: 0.94s; --- Convergence: 5.97e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 94/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.592 1 + 0.409 value_stay[t] + 0.215 reward + 0.323 value_stay*reward + -0.315 value_stay*harvest_duration + 0.581 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 695/1000 --- L(Train): 0.3553823 --- L(Val, RNN): 0.3413230 --- L(Val, SINDy): 0.3751180 --- Time: 0.86s; --- Convergence: 5.28e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 95/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.592 1 + 0.409 value_stay[t] + 0.215 reward + 0.323 value_stay*reward + -0.315 value_stay*harvest_duration + 0.58 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 696/1000 --- L(Train): 0.3597292 --- L(Val, RNN): 0.3413173 --- L(Val, SINDy): 0.3751266 --- Time: 1.03s; --- Convergence: 5.50e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 96/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.593 1 + 0.409 value_stay[t] + 0.215 reward + 0.324 value_stay*reward + -0.315 value_stay*harvest_duration + 0.58 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 697/1000 --- L(Train): 0.3615157 --- L(Val, RNN): 0.3413113 --- L(Val, SINDy): 0.3751179 --- Time: 0.96s; --- Convergence: 5.76e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 97/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.593 1 + 0.408 value_stay[t] + 0.216 reward + 0.325 value_stay*reward + -0.315 value_stay*harvest_duration + 0.579 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 698/1000 --- L(Train): 0.3601859 --- L(Val, RNN): 0.3412984 --- L(Val, SINDy): 0.3751273 --- Time: 0.86s; --- Convergence: 9.32e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 98/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.593 1 + 0.408 value_stay[t] + 0.216 reward + 0.326 value_stay*reward + -0.315 value_stay*harvest_duration + 0.579 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 699/1000 --- L(Train): 0.3565252 --- L(Val, RNN): 0.3412854 --- L(Val, SINDy): 0.3750554 --- Time: 0.96s; --- Convergence: 1.12e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 99/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.593 1 + 0.407 value_stay[t] + 0.216 reward + 0.327 value_stay*reward + -0.315 value_stay*harvest_duration + 0.579 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 700/1000 --- L(Train): 0.3655179 --- L(Val, RNN): 0.3412765 --- L(Val, SINDy): 0.3749119 --- Time: 1.13s; --- Convergence: 1.00e-05; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.594 1 + 0.407 value_stay[t] + 0.216 reward + 0.327 value_stay*reward + -0.316 value_stay*harvest_duration + 0.578 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 701/1000 --- L(Train): 0.3644591 --- L(Val, RNN): 0.3412745 --- L(Val, SINDy): 0.3747798 --- Time: 1.44s; --- Convergence: 6.02e-06; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 1/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.594 1 + 0.406 value_stay[t] + 0.216 reward + 0.328 value_stay*reward + -0.316 value_stay*harvest_duration + 0.578 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 702/1000 --- L(Train): 0.3581049 --- L(Val, RNN): 0.3412731 --- L(Val, SINDy): 0.3747279 --- Time: 1.57s; --- Convergence: 3.69e-06; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 2/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.594 1 + 0.406 value_stay[t] + 0.216 reward + 0.329 value_stay*reward + -0.316 value_stay*harvest_duration + 0.577 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 703/1000 --- L(Train): 0.3628161 --- L(Val, RNN): 0.3412689 --- L(Val, SINDy): 0.3748184 --- Time: 1.87s; --- Convergence: 3.98e-06; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 3/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.594 1 + 0.405 value_stay[t] + 0.216 reward + 0.329 value_stay*reward + -0.316 value_stay*harvest_duration + 0.577 reward^2 + 0.221 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 704/1000 --- L(Train): 0.3592226 --- L(Val, RNN): 0.3412651 --- L(Val, SINDy): 0.3748671 --- Time: 4.17s; --- Convergence: 3.87e-06; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 4/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.594 1 + 0.405 value_stay[t] + 0.216 reward + 0.33 value_stay*reward + -0.317 value_stay*harvest_duration + 0.576 reward^2 + 0.221 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 705/1000 --- L(Train): 0.3589009 --- L(Val, RNN): 0.3412605 --- L(Val, SINDy): 0.3748213 --- Time: 5.31s; --- Convergence: 4.23e-06; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 5/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.594 1 + 0.404 value_stay[t] + 0.216 reward + 0.331 value_stay*reward + -0.317 value_stay*harvest_duration + 0.576 reward^2 + 0.221 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 706/1000 --- L(Train): 0.3600669 --- L(Val, RNN): 0.3412542 --- L(Val, SINDy): 0.3747756 --- Time: 5.91s; --- Convergence: 5.27e-06; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 6/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.594 1 + 0.403 value_stay[t] + 0.217 reward + 0.332 value_stay*reward + -0.318 value_stay*harvest_duration + 0.576 reward^2 + 0.221 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 707/1000 --- L(Train): 0.3615042 --- L(Val, RNN): 0.3412496 --- L(Val, SINDy): 0.3747495 --- Time: 5.94s; --- Convergence: 4.93e-06; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 7/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.595 1 + 0.403 value_stay[t] + 0.217 reward + 0.334 value_stay*reward + -0.318 value_stay*harvest_duration + 0.575 reward^2 + 0.221 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 708/1000 --- L(Train): 0.3549580 --- L(Val, RNN): 0.3412451 --- L(Val, SINDy): 0.3747332 --- Time: 2.09s; --- Convergence: 4.75e-06; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 8/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.596 1 + 0.404 value_stay[t] + 0.218 reward + 0.336 value_stay*reward + -0.317 value_stay*harvest_duration + 0.575 reward^2 + 0.222 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 709/1000 --- L(Train): 0.3633988 --- L(Val, RNN): 0.3412420 --- L(Val, SINDy): 0.3747146 --- Time: 3.94s; --- Convergence: 3.88e-06; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 9/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.596 1 + 0.404 value_stay[t] + 0.218 reward + 0.337 value_stay*reward + -0.317 value_stay*harvest_duration + 0.575 reward^2 + 0.222 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\n",
      "Training interrupted. Continuing with further operations...\n",
      "\n",
      "================================================================================\n",
      "Starting second stage SINDy fitting (threshold=0.05, single model)\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 1/1000 --- L(Train): 0.0679438 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.01 1 + 0.991 value_stay[t] + 0.009 reward + 0.01 harvest_duration + -0.011 value_stay^2 + -0.009 value_stay*reward + -0.01 value_stay*harvest_duration + 0.011 reward^2 + 0.009 reward*harvest_duration + 0.01 harvest_duration^2 \n",
      "value_exit[t+1] = 0.009 1 + 0.991 value_exit[t] + 0.01 travel_duration + 0.01 value_exit^2 + -0.011 value_exit*travel_duration + 0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 2/1000 --- L(Train): 0.3698150 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.008 1 + 0.981 value_stay[t] + 0.019 reward + 0.009 harvest_duration + -0.021 value_stay^2 + -0.019 value_stay*reward + -0.02 value_stay*harvest_duration + 0.021 reward^2 + 0.019 reward*harvest_duration + 0.009 harvest_duration^2 \n",
      "value_exit[t+1] = 0.001 1 + 0.998 value_exit[t] + 0.002 travel_duration + 0.003 value_exit^2 + -0.004 value_exit*travel_duration + 0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 3/1000 --- L(Train): 0.0769846 --- L(Val, SINDy): 0.0000000 --- Time: 0.27s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.011 1 + 0.971 value_stay[t] + 0.028 reward + 0.011 harvest_duration + -0.031 value_stay^2 + -0.026 value_stay*reward + -0.03 value_stay*harvest_duration + 0.031 reward^2 + 0.029 reward*harvest_duration + 0.012 harvest_duration^2 \n",
      "value_exit[t+1] = -0.006 1 + 1.006 value_exit[t] + -0.005 travel_duration + -0.004 value_exit^2 + 0.003 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 4/1000 --- L(Train): 0.1222406 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.017 1 + 0.961 value_stay[t] + 0.038 reward + 0.017 harvest_duration + -0.041 value_stay^2 + -0.03 value_stay*reward + -0.04 value_stay*harvest_duration + 0.041 reward^2 + 0.039 reward*harvest_duration + 0.017 harvest_duration^2 \n",
      "value_exit[t+1] = -0.009 1 + 1.008 value_exit[t] + -0.008 travel_duration + -0.007 value_exit^2 + 0.006 value_exit*travel_duration + -0.008 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 5/1000 --- L(Train): 0.2250931 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.023 1 + 0.952 value_stay[t] + 0.048 reward + 0.023 harvest_duration + -0.05 value_stay^2 + -0.031 value_stay*reward + -0.049 value_stay*harvest_duration + 0.051 reward^2 + 0.049 reward*harvest_duration + 0.023 harvest_duration^2 \n",
      "value_exit[t+1] = -0.008 1 + 1.007 value_exit[t] + -0.007 travel_duration + -0.006 value_exit^2 + 0.005 value_exit*travel_duration + -0.007 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 6/1000 --- L(Train): 0.1682639 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.028 1 + 0.943 value_stay[t] + 0.058 reward + 0.028 harvest_duration + -0.06 value_stay^2 + -0.032 value_stay*reward + -0.059 value_stay*harvest_duration + 0.061 reward^2 + 0.058 reward*harvest_duration + 0.028 harvest_duration^2 \n",
      "value_exit[t+1] = -0.005 1 + 1.004 value_exit[t] + -0.004 travel_duration + -0.003 value_exit^2 + 0.002 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 7/1000 --- L(Train): 0.0702509 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.031 1 + 0.933 value_stay[t] + 0.068 reward + 0.031 harvest_duration + -0.07 value_stay^2 + -0.033 value_stay*reward + -0.068 value_stay*harvest_duration + 0.071 reward^2 + 0.068 reward*harvest_duration + 0.031 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 1.0 value_exit[t] + -0.0 travel_duration + 0.001 value_exit^2 + -0.002 value_exit*travel_duration + 0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 8/1000 --- L(Train): 0.0426422 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.033 1 + 0.923 value_stay[t] + 0.078 reward + 0.033 harvest_duration + -0.079 value_stay^2 + -0.034 value_stay*reward + -0.078 value_stay*harvest_duration + 0.08 reward^2 + 0.078 reward*harvest_duration + 0.033 harvest_duration^2 \n",
      "value_exit[t+1] = 0.002 1 + 0.997 value_exit[t] + 0.003 travel_duration + 0.004 value_exit^2 + -0.005 value_exit*travel_duration + 0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 9/1000 --- L(Train): 0.0864310 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.035 1 + 0.914 value_stay[t] + 0.087 reward + 0.035 harvest_duration + -0.088 value_stay^2 + -0.032 value_stay*reward + -0.087 value_stay*harvest_duration + 0.09 reward^2 + 0.087 reward*harvest_duration + 0.035 harvest_duration^2 \n",
      "value_exit[t+1] = 0.004 1 + 0.995 value_exit[t] + 0.005 travel_duration + 0.006 value_exit^2 + -0.007 value_exit*travel_duration + 0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 10/1000 --- L(Train): 0.1216199 --- L(Val, SINDy): 0.0000000 --- Time: 0.28s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.905 value_stay[t] + 0.097 reward + 0.038 harvest_duration + -0.097 value_stay^2 + -0.029 value_stay*reward + -0.096 value_stay*harvest_duration + 0.1 reward^2 + 0.097 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = 0.004 1 + 0.995 value_exit[t] + 0.005 travel_duration + 0.006 value_exit^2 + -0.007 value_exit*travel_duration + 0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 11/1000 --- L(Train): 0.1028378 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.896 value_stay[t] + 0.106 reward + 0.042 harvest_duration + -0.106 value_stay^2 + -0.023 value_stay*reward + -0.105 value_stay*harvest_duration + 0.109 reward^2 + 0.107 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.002 1 + 0.996 value_exit[t] + 0.003 travel_duration + 0.005 value_exit^2 + -0.006 value_exit*travel_duration + 0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 12/1000 --- L(Train): 0.0567309 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.887 value_stay[t] + 0.116 reward + 0.045 harvest_duration + -0.114 value_stay^2 + -0.017 value_stay*reward + -0.114 value_stay*harvest_duration + 0.119 reward^2 + 0.116 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.998 value_exit[t] + 0.001 travel_duration + 0.003 value_exit^2 + -0.004 value_exit*travel_duration + 0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 13/1000 --- L(Train): 0.0295713 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.879 value_stay[t] + 0.126 reward + 0.048 harvest_duration + -0.123 value_stay^2 + -0.01 value_stay*reward + -0.122 value_stay*harvest_duration + 0.129 reward^2 + 0.126 reward*harvest_duration + 0.049 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 1.0 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.002 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 14/1000 --- L(Train): 0.0386319 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.05 1 + 0.87 value_stay[t] + 0.135 reward + 0.05 harvest_duration + -0.131 value_stay^2 + -0.003 value_stay*reward + -0.131 value_stay*harvest_duration + 0.138 reward^2 + 0.135 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = -0.004 1 + 1.002 value_exit[t] + -0.003 travel_duration + -0.001 value_exit^2 + -0.0 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 15/1000 --- L(Train): 0.0618805 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.051 1 + 0.862 value_stay[t] + 0.144 reward + 0.051 harvest_duration + -0.139 value_stay^2 + 0.005 value_stay*reward + -0.139 value_stay*harvest_duration + 0.147 reward^2 + 0.144 reward*harvest_duration + 0.051 harvest_duration^2 \n",
      "value_exit[t+1] = -0.005 1 + 1.003 value_exit[t] + -0.004 travel_duration + -0.002 value_exit^2 + 0.001 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 16/1000 --- L(Train): 0.0681846 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.052 1 + 0.854 value_stay[t] + 0.153 reward + 0.052 harvest_duration + -0.146 value_stay^2 + 0.013 value_stay*reward + -0.147 value_stay*harvest_duration + 0.156 reward^2 + 0.154 reward*harvest_duration + 0.052 harvest_duration^2 \n",
      "value_exit[t+1] = -0.005 1 + 1.003 value_exit[t] + -0.004 travel_duration + -0.002 value_exit^2 + 0.0 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 17/1000 --- L(Train): 0.0511231 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.054 1 + 0.846 value_stay[t] + 0.162 reward + 0.054 harvest_duration + -0.153 value_stay^2 + 0.021 value_stay*reward + -0.155 value_stay*harvest_duration + 0.165 reward^2 + 0.163 reward*harvest_duration + 0.054 harvest_duration^2 \n",
      "value_exit[t+1] = -0.004 1 + 1.001 value_exit[t] + -0.003 travel_duration + -0.001 value_exit^2 + -0.001 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 18/1000 --- L(Train): 0.0289331 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.056 1 + 0.839 value_stay[t] + 0.171 reward + 0.056 harvest_duration + -0.16 value_stay^2 + 0.03 value_stay*reward + -0.162 value_stay*harvest_duration + 0.174 reward^2 + 0.172 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.999 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.003 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 19/1000 --- L(Train): 0.0210141 --- L(Val, SINDy): 0.0000000 --- Time: 0.29s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.058 1 + 0.832 value_stay[t] + 0.18 reward + 0.058 harvest_duration + -0.166 value_stay^2 + 0.039 value_stay*reward + -0.169 value_stay*harvest_duration + 0.183 reward^2 + 0.18 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.997 value_exit[t] + 0.001 travel_duration + 0.003 value_exit^2 + -0.005 value_exit*travel_duration + 0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 20/1000 --- L(Train): 0.0292556 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.06 1 + 0.825 value_stay[t] + 0.189 reward + 0.06 harvest_duration + -0.172 value_stay^2 + 0.049 value_stay*reward + -0.176 value_stay*harvest_duration + 0.192 reward^2 + 0.189 reward*harvest_duration + 0.06 harvest_duration^2 \n",
      "value_exit[t+1] = 0.001 1 + 0.996 value_exit[t] + 0.002 travel_duration + 0.005 value_exit^2 + -0.006 value_exit*travel_duration + 0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 21/1000 --- L(Train): 0.0395570 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.06 1 + 0.819 value_stay[t] + 0.197 reward + 0.06 harvest_duration + -0.178 value_stay^2 + 0.058 value_stay*reward + -0.183 value_stay*harvest_duration + 0.2 reward^2 + 0.198 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = 0.002 1 + 0.995 value_exit[t] + 0.002 travel_duration + 0.005 value_exit^2 + -0.007 value_exit*travel_duration + 0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 22/1000 --- L(Train): 0.0389137 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.06 1 + 0.812 value_stay[t] + 0.206 reward + 0.06 harvest_duration + -0.183 value_stay^2 + 0.067 value_stay*reward + -0.189 value_stay*harvest_duration + 0.208 reward^2 + 0.206 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = 0.001 1 + 0.995 value_exit[t] + 0.002 travel_duration + 0.005 value_exit^2 + -0.007 value_exit*travel_duration + 0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 23/1000 --- L(Train): 0.0281515 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.06 1 + 0.806 value_stay[t] + 0.214 reward + 0.06 harvest_duration + -0.188 value_stay^2 + 0.077 value_stay*reward + -0.195 value_stay*harvest_duration + 0.217 reward^2 + 0.214 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.996 value_exit[t] + 0.001 travel_duration + 0.004 value_exit^2 + -0.006 value_exit*travel_duration + 0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 24/1000 --- L(Train): 0.0180971 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.061 1 + 0.801 value_stay[t] + 0.222 reward + 0.061 harvest_duration + -0.193 value_stay^2 + 0.086 value_stay*reward + -0.201 value_stay*harvest_duration + 0.224 reward^2 + 0.222 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.997 value_exit[t] + 0.0 travel_duration + 0.003 value_exit^2 + -0.005 value_exit*travel_duration + 0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 25/1000 --- L(Train): 0.0168013 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.061 1 + 0.796 value_stay[t] + 0.23 reward + 0.061 harvest_duration + -0.197 value_stay^2 + 0.096 value_stay*reward + -0.206 value_stay*harvest_duration + 0.232 reward^2 + 0.23 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.998 value_exit[t] + -0.001 travel_duration + 0.002 value_exit^2 + -0.004 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 26/1000 --- L(Train): 0.0221422 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.062 1 + 0.791 value_stay[t] + 0.237 reward + 0.062 harvest_duration + -0.2 value_stay^2 + 0.107 value_stay*reward + -0.21 value_stay*harvest_duration + 0.24 reward^2 + 0.238 reward*harvest_duration + 0.062 harvest_duration^2 \n",
      "value_exit[t+1] = -0.003 1 + 0.999 value_exit[t] + -0.002 travel_duration + 0.001 value_exit^2 + -0.003 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 27/1000 --- L(Train): 0.0259015 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.062 1 + 0.786 value_stay[t] + 0.245 reward + 0.062 harvest_duration + -0.203 value_stay^2 + 0.117 value_stay*reward + -0.215 value_stay*harvest_duration + 0.247 reward^2 + 0.245 reward*harvest_duration + 0.062 harvest_duration^2 \n",
      "value_exit[t+1] = -0.004 1 + 0.999 value_exit[t] + -0.003 travel_duration + 0.0 value_exit^2 + -0.003 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 28/1000 --- L(Train): 0.0232896 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.061 1 + 0.782 value_stay[t] + 0.252 reward + 0.062 harvest_duration + -0.206 value_stay^2 + 0.126 value_stay*reward + -0.219 value_stay*harvest_duration + 0.254 reward^2 + 0.252 reward*harvest_duration + 0.062 harvest_duration^2 \n",
      "value_exit[t+1] = -0.003 1 + 0.999 value_exit[t] + -0.002 travel_duration + 0.001 value_exit^2 + -0.004 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 29/1000 --- L(Train): 0.0171324 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.06 1 + 0.778 value_stay[t] + 0.259 reward + 0.06 harvest_duration + -0.209 value_stay^2 + 0.136 value_stay*reward + -0.223 value_stay*harvest_duration + 0.261 reward^2 + 0.259 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.998 value_exit[t] + -0.002 travel_duration + 0.001 value_exit^2 + -0.005 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 30/1000 --- L(Train): 0.0134005 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.059 1 + 0.774 value_stay[t] + 0.266 reward + 0.06 harvest_duration + -0.211 value_stay^2 + 0.146 value_stay*reward + -0.227 value_stay*harvest_duration + 0.268 reward^2 + 0.266 reward*harvest_duration + 0.06 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.997 value_exit[t] + -0.001 travel_duration + 0.002 value_exit^2 + -0.006 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 31/1000 --- L(Train): 0.0144461 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.059 1 + 0.771 value_stay[t] + 0.272 reward + 0.059 harvest_duration + -0.213 value_stay^2 + 0.155 value_stay*reward + -0.231 value_stay*harvest_duration + 0.274 reward^2 + 0.273 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.995 value_exit[t] + 0.0 travel_duration + 0.003 value_exit^2 + -0.007 value_exit*travel_duration + 0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 32/1000 --- L(Train): 0.0172947 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.058 1 + 0.768 value_stay[t] + 0.278 reward + 0.058 harvest_duration + -0.214 value_stay^2 + 0.165 value_stay*reward + -0.234 value_stay*harvest_duration + 0.28 reward^2 + 0.279 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.995 value_exit[t] + 0.001 travel_duration + 0.004 value_exit^2 + -0.008 value_exit*travel_duration + 0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 33/1000 --- L(Train): 0.0177888 --- L(Val, SINDy): 0.0000000 --- Time: 0.28s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.058 1 + 0.765 value_stay[t] + 0.284 reward + 0.058 harvest_duration + -0.215 value_stay^2 + 0.175 value_stay*reward + -0.236 value_stay*harvest_duration + 0.286 reward^2 + 0.285 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.995 value_exit[t] + 0.001 travel_duration + 0.003 value_exit^2 + -0.008 value_exit*travel_duration + 0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 34/1000 --- L(Train): 0.0151986 --- L(Val, SINDy): 0.0000000 --- Time: 0.27s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.057 1 + 0.763 value_stay[t] + 0.29 reward + 0.057 harvest_duration + -0.216 value_stay^2 + 0.184 value_stay*reward + -0.239 value_stay*harvest_duration + 0.291 reward^2 + 0.291 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.995 value_exit[t] + 0.001 travel_duration + 0.003 value_exit^2 + -0.008 value_exit*travel_duration + 0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 35/1000 --- L(Train): 0.0122926 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.055 1 + 0.76 value_stay[t] + 0.296 reward + 0.056 harvest_duration + -0.217 value_stay^2 + 0.192 value_stay*reward + -0.241 value_stay*harvest_duration + 0.297 reward^2 + 0.296 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.995 value_exit[t] + -0.0 travel_duration + 0.002 value_exit^2 + -0.007 value_exit*travel_duration + -0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 36/1000 --- L(Train): 0.0116654 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.054 1 + 0.758 value_stay[t] + 0.301 reward + 0.054 harvest_duration + -0.217 value_stay^2 + 0.201 value_stay*reward + -0.243 value_stay*harvest_duration + 0.301 reward^2 + 0.301 reward*harvest_duration + 0.054 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.996 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.007 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 37/1000 --- L(Train): 0.0129875 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.053 1 + 0.756 value_stay[t] + 0.306 reward + 0.053 harvest_duration + -0.218 value_stay^2 + 0.209 value_stay*reward + -0.245 value_stay*harvest_duration + 0.306 reward^2 + 0.306 reward*harvest_duration + 0.053 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.997 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.006 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 38/1000 --- L(Train): 0.0139412 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.052 1 + 0.755 value_stay[t] + 0.31 reward + 0.052 harvest_duration + -0.218 value_stay^2 + 0.217 value_stay*reward + -0.247 value_stay*harvest_duration + 0.311 reward^2 + 0.311 reward*harvest_duration + 0.052 harvest_duration^2 \n",
      "value_exit[t+1] = -0.003 1 + 0.997 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.006 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 39/1000 --- L(Train): 0.0131458 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.051 1 + 0.753 value_stay[t] + 0.315 reward + 0.051 harvest_duration + -0.218 value_stay^2 + 0.224 value_stay*reward + -0.249 value_stay*harvest_duration + 0.315 reward^2 + 0.315 reward*harvest_duration + 0.051 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.996 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.007 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 40/1000 --- L(Train): 0.0114825 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.05 1 + 0.752 value_stay[t] + 0.319 reward + 0.05 harvest_duration + -0.218 value_stay^2 + 0.231 value_stay*reward + -0.25 value_stay*harvest_duration + 0.319 reward^2 + 0.319 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.996 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.007 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 41/1000 --- L(Train): 0.0106504 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.75 value_stay[t] + 0.323 reward + 0.049 harvest_duration + -0.217 value_stay^2 + 0.237 value_stay*reward + -0.251 value_stay*harvest_duration + 0.322 reward^2 + 0.323 reward*harvest_duration + 0.049 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.995 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.008 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 42/1000 --- L(Train): 0.0111004 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.749 value_stay[t] + 0.326 reward + 0.048 harvest_duration + -0.217 value_stay^2 + 0.243 value_stay*reward + -0.252 value_stay*harvest_duration + 0.325 reward^2 + 0.326 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.994 value_exit[t] + -0.0 travel_duration + 0.001 value_exit^2 + -0.009 value_exit*travel_duration + -0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 43/1000 --- L(Train): 0.0117764 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.748 value_stay[t] + 0.329 reward + 0.047 harvest_duration + -0.217 value_stay^2 + 0.248 value_stay*reward + -0.254 value_stay*harvest_duration + 0.328 reward^2 + 0.33 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.994 value_exit[t] + 0.0 travel_duration + 0.002 value_exit^2 + -0.009 value_exit*travel_duration + 0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 44/1000 --- L(Train): 0.0116133 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.747 value_stay[t] + 0.332 reward + 0.046 harvest_duration + -0.216 value_stay^2 + 0.252 value_stay*reward + -0.254 value_stay*harvest_duration + 0.331 reward^2 + 0.333 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.994 value_exit[t] + 0.0 travel_duration + 0.002 value_exit^2 + -0.01 value_exit*travel_duration + 0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 45/1000 --- L(Train): 0.0107543 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.746 value_stay[t] + 0.335 reward + 0.045 harvest_duration + -0.216 value_stay^2 + 0.256 value_stay*reward + -0.255 value_stay*harvest_duration + 0.333 reward^2 + 0.335 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.994 value_exit[t] + -0.0 travel_duration + 0.001 value_exit^2 + -0.01 value_exit*travel_duration + -0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 46/1000 --- L(Train): 0.0101362 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.746 value_stay[t] + 0.337 reward + 0.045 harvest_duration + -0.215 value_stay^2 + 0.26 value_stay*reward + -0.256 value_stay*harvest_duration + 0.336 reward^2 + 0.338 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.994 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.009 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 47/1000 --- L(Train): 0.0102401 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.34 reward + 0.044 harvest_duration + -0.215 value_stay^2 + 0.263 value_stay*reward + -0.257 value_stay*harvest_duration + 0.338 reward^2 + 0.34 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.995 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.009 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 48/1000 --- L(Train): 0.0106155 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.744 value_stay[t] + 0.342 reward + 0.043 harvest_duration + -0.214 value_stay^2 + 0.265 value_stay*reward + -0.257 value_stay*harvest_duration + 0.339 reward^2 + 0.342 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.995 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.009 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 49/1000 --- L(Train): 0.0105971 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.744 value_stay[t] + 0.343 reward + 0.043 harvest_duration + -0.214 value_stay^2 + 0.266 value_stay*reward + -0.258 value_stay*harvest_duration + 0.341 reward^2 + 0.344 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.995 value_exit[t] + -0.001 travel_duration + -0.001 value_exit^2 + -0.009 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 50/1000 --- L(Train): 0.0101414 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.743 value_stay[t] + 0.345 reward + 0.042 harvest_duration + -0.213 value_stay^2 + 0.267 value_stay*reward + -0.259 value_stay*harvest_duration + 0.342 reward^2 + 0.345 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.995 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.01 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 51/1000 --- L(Train): 0.0097495 --- L(Val, SINDy): 0.0000000 --- Time: 0.28s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.743 value_stay[t] + 0.346 reward + 0.042 harvest_duration + -0.212 value_stay^2 + 0.268 value_stay*reward + -0.259 value_stay*harvest_duration + 0.343 reward^2 + 0.346 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.994 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.01 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 52/1000 --- L(Train): 0.0097491 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.742 value_stay[t] + 0.347 reward + 0.042 harvest_duration + -0.212 value_stay^2 + 0.268 value_stay*reward + -0.259 value_stay*harvest_duration + 0.344 reward^2 + 0.348 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.994 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.011 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 53/1000 --- L(Train): 0.0099314 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.742 value_stay[t] + 0.348 reward + 0.042 harvest_duration + -0.211 value_stay^2 + 0.267 value_stay*reward + -0.26 value_stay*harvest_duration + 0.344 reward^2 + 0.348 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.993 value_exit[t] + -0.0 travel_duration + 0.001 value_exit^2 + -0.011 value_exit*travel_duration + -0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 54/1000 --- L(Train): 0.0099134 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.741 value_stay[t] + 0.349 reward + 0.042 harvest_duration + -0.211 value_stay^2 + 0.266 value_stay*reward + -0.26 value_stay*harvest_duration + 0.345 reward^2 + 0.349 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.993 value_exit[t] + -0.0 travel_duration + 0.001 value_exit^2 + -0.012 value_exit*travel_duration + -0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 55/1000 --- L(Train): 0.0096457 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.741 value_stay[t] + 0.349 reward + 0.042 harvest_duration + -0.211 value_stay^2 + 0.264 value_stay*reward + -0.261 value_stay*harvest_duration + 0.345 reward^2 + 0.35 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.993 value_exit[t] + -0.0 travel_duration + 0.001 value_exit^2 + -0.012 value_exit*travel_duration + -0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 56/1000 --- L(Train): 0.0094074 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.741 value_stay[t] + 0.35 reward + 0.042 harvest_duration + -0.21 value_stay^2 + 0.263 value_stay*reward + -0.261 value_stay*harvest_duration + 0.345 reward^2 + 0.35 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.993 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.012 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 57/1000 --- L(Train): 0.0093887 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.74 value_stay[t] + 0.35 reward + 0.042 harvest_duration + -0.209 value_stay^2 + 0.261 value_stay*reward + -0.261 value_stay*harvest_duration + 0.345 reward^2 + 0.35 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.993 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.012 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 58/1000 --- L(Train): 0.0094670 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.74 value_stay[t] + 0.35 reward + 0.043 harvest_duration + -0.209 value_stay^2 + 0.258 value_stay*reward + -0.261 value_stay*harvest_duration + 0.345 reward^2 + 0.351 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.993 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.012 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 59/1000 --- L(Train): 0.0094267 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.74 value_stay[t] + 0.35 reward + 0.043 harvest_duration + -0.208 value_stay^2 + 0.255 value_stay*reward + -0.262 value_stay*harvest_duration + 0.345 reward^2 + 0.351 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.993 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.012 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 60/1000 --- L(Train): 0.0092531 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.74 value_stay[t] + 0.35 reward + 0.043 harvest_duration + -0.208 value_stay^2 + 0.252 value_stay*reward + -0.262 value_stay*harvest_duration + 0.345 reward^2 + 0.351 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.993 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.012 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 61/1000 --- L(Train): 0.0091118 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.74 value_stay[t] + 0.35 reward + 0.043 harvest_duration + -0.207 value_stay^2 + 0.249 value_stay*reward + -0.262 value_stay*harvest_duration + 0.344 reward^2 + 0.35 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.993 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.013 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 62/1000 --- L(Train): 0.0090960 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.74 value_stay[t] + 0.35 reward + 0.043 harvest_duration + -0.207 value_stay^2 + 0.246 value_stay*reward + -0.262 value_stay*harvest_duration + 0.344 reward^2 + 0.35 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.013 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 63/1000 --- L(Train): 0.0091191 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.74 value_stay[t] + 0.35 reward + 0.044 harvest_duration + -0.206 value_stay^2 + 0.243 value_stay*reward + -0.262 value_stay*harvest_duration + 0.343 reward^2 + 0.35 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.014 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 64/1000 --- L(Train): 0.0090649 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.74 value_stay[t] + 0.349 reward + 0.044 harvest_duration + -0.205 value_stay^2 + 0.24 value_stay*reward + -0.262 value_stay*harvest_duration + 0.342 reward^2 + 0.35 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.014 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 65/1000 --- L(Train): 0.0089476 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.74 value_stay[t] + 0.349 reward + 0.044 harvest_duration + -0.205 value_stay^2 + 0.236 value_stay*reward + -0.262 value_stay*harvest_duration + 0.342 reward^2 + 0.349 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.014 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 66/1000 --- L(Train): 0.0088654 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.74 value_stay[t] + 0.349 reward + 0.044 harvest_duration + -0.204 value_stay^2 + 0.233 value_stay*reward + -0.262 value_stay*harvest_duration + 0.341 reward^2 + 0.349 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.014 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 67/1000 --- L(Train): 0.0088527 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.74 value_stay[t] + 0.348 reward + 0.045 harvest_duration + -0.203 value_stay^2 + 0.229 value_stay*reward + -0.262 value_stay*harvest_duration + 0.34 reward^2 + 0.348 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.014 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 68/1000 --- L(Train): 0.0088459 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.74 value_stay[t] + 0.348 reward + 0.045 harvest_duration + -0.202 value_stay^2 + 0.226 value_stay*reward + -0.262 value_stay*harvest_duration + 0.339 reward^2 + 0.348 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.014 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 69/1000 --- L(Train): 0.0087893 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.74 value_stay[t] + 0.347 reward + 0.045 harvest_duration + -0.201 value_stay^2 + 0.223 value_stay*reward + -0.261 value_stay*harvest_duration + 0.339 reward^2 + 0.348 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.015 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 70/1000 --- L(Train): 0.0087093 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.74 value_stay[t] + 0.347 reward + 0.045 harvest_duration + -0.2 value_stay^2 + 0.22 value_stay*reward + -0.261 value_stay*harvest_duration + 0.338 reward^2 + 0.347 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.015 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 71/1000 --- L(Train): 0.0086626 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.741 value_stay[t] + 0.346 reward + 0.045 harvest_duration + -0.199 value_stay^2 + 0.216 value_stay*reward + -0.261 value_stay*harvest_duration + 0.337 reward^2 + 0.347 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.015 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 72/1000 --- L(Train): 0.0086504 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.741 value_stay[t] + 0.346 reward + 0.045 harvest_duration + -0.198 value_stay^2 + 0.213 value_stay*reward + -0.261 value_stay*harvest_duration + 0.336 reward^2 + 0.346 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.016 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 73/1000 --- L(Train): 0.0086275 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.741 value_stay[t] + 0.345 reward + 0.045 harvest_duration + -0.197 value_stay^2 + 0.211 value_stay*reward + -0.26 value_stay*harvest_duration + 0.336 reward^2 + 0.346 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.016 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 74/1000 --- L(Train): 0.0085758 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.741 value_stay[t] + 0.345 reward + 0.046 harvest_duration + -0.196 value_stay^2 + 0.208 value_stay*reward + -0.26 value_stay*harvest_duration + 0.335 reward^2 + 0.345 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.016 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 75/1000 --- L(Train): 0.0085237 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.742 value_stay[t] + 0.345 reward + 0.045 harvest_duration + -0.195 value_stay^2 + 0.205 value_stay*reward + -0.26 value_stay*harvest_duration + 0.334 reward^2 + 0.345 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.016 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 76/1000 --- L(Train): 0.0084957 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.742 value_stay[t] + 0.344 reward + 0.045 harvest_duration + -0.193 value_stay^2 + 0.202 value_stay*reward + -0.26 value_stay*harvest_duration + 0.333 reward^2 + 0.345 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.991 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.017 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 77/1000 --- L(Train): 0.0084790 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.742 value_stay[t] + 0.344 reward + 0.045 harvest_duration + -0.192 value_stay^2 + 0.2 value_stay*reward + -0.259 value_stay*harvest_duration + 0.333 reward^2 + 0.344 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.991 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.017 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 78/1000 --- L(Train): 0.0084492 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.743 value_stay[t] + 0.344 reward + 0.045 harvest_duration + -0.191 value_stay^2 + 0.197 value_stay*reward + -0.259 value_stay*harvest_duration + 0.332 reward^2 + 0.344 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.991 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.017 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 79/1000 --- L(Train): 0.0084070 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.743 value_stay[t] + 0.344 reward + 0.045 harvest_duration + -0.19 value_stay^2 + 0.195 value_stay*reward + -0.259 value_stay*harvest_duration + 0.332 reward^2 + 0.344 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.017 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 80/1000 --- L(Train): 0.0083719 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.743 value_stay[t] + 0.343 reward + 0.045 harvest_duration + -0.189 value_stay^2 + 0.192 value_stay*reward + -0.258 value_stay*harvest_duration + 0.331 reward^2 + 0.344 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.018 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 81/1000 --- L(Train): 0.0083509 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.744 value_stay[t] + 0.343 reward + 0.045 harvest_duration + -0.187 value_stay^2 + 0.19 value_stay*reward + -0.258 value_stay*harvest_duration + 0.33 reward^2 + 0.344 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.018 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 82/1000 --- L(Train): 0.0083299 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.744 value_stay[t] + 0.343 reward + 0.045 harvest_duration + -0.186 value_stay^2 + 0.188 value_stay*reward + -0.258 value_stay*harvest_duration + 0.33 reward^2 + 0.344 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.018 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 83/1000 --- L(Train): 0.0082983 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.744 value_stay[t] + 0.343 reward + 0.045 harvest_duration + -0.185 value_stay^2 + 0.186 value_stay*reward + -0.257 value_stay*harvest_duration + 0.329 reward^2 + 0.343 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.019 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 84/1000 --- L(Train): 0.0082640 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.744 value_stay[t] + 0.343 reward + 0.045 harvest_duration + -0.184 value_stay^2 + 0.184 value_stay*reward + -0.257 value_stay*harvest_duration + 0.329 reward^2 + 0.343 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.019 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 85/1000 --- L(Train): 0.0082392 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.343 reward + 0.044 harvest_duration + -0.182 value_stay^2 + 0.181 value_stay*reward + -0.257 value_stay*harvest_duration + 0.329 reward^2 + 0.343 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.019 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 86/1000 --- L(Train): 0.0082196 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.343 reward + 0.044 harvest_duration + -0.181 value_stay^2 + 0.179 value_stay*reward + -0.257 value_stay*harvest_duration + 0.328 reward^2 + 0.344 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.019 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 87/1000 --- L(Train): 0.0081944 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.343 reward + 0.044 harvest_duration + -0.18 value_stay^2 + 0.177 value_stay*reward + -0.257 value_stay*harvest_duration + 0.328 reward^2 + 0.344 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.02 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 88/1000 --- L(Train): 0.0081642 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.343 reward + 0.044 harvest_duration + -0.179 value_stay^2 + 0.175 value_stay*reward + -0.257 value_stay*harvest_duration + 0.328 reward^2 + 0.344 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.02 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 89/1000 --- L(Train): 0.0081379 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.344 reward + 0.044 harvest_duration + -0.178 value_stay^2 + 0.173 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.344 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.02 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 90/1000 --- L(Train): 0.0081171 --- L(Val, SINDy): 0.0000000 --- Time: 0.28s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.344 reward + 0.044 harvest_duration + -0.177 value_stay^2 + 0.171 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.344 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.021 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 91/1000 --- L(Train): 0.0080955 --- L(Val, SINDy): 0.0000000 --- Time: 0.27s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.344 reward + 0.044 harvest_duration + -0.176 value_stay^2 + 0.169 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.344 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.021 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 92/1000 --- L(Train): 0.0080700 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.344 reward + 0.044 harvest_duration + -0.175 value_stay^2 + 0.167 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.345 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.021 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 93/1000 --- L(Train): 0.0080443 --- L(Val, SINDy): 0.0000000 --- Time: 0.28s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.345 reward + 0.044 harvest_duration + -0.174 value_stay^2 + 0.165 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.345 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.021 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 94/1000 --- L(Train): 0.0080229 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.345 reward + 0.044 harvest_duration + -0.173 value_stay^2 + 0.163 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.345 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.022 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 95/1000 --- L(Train): 0.0080031 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.345 reward + 0.044 harvest_duration + -0.172 value_stay^2 + 0.161 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.346 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.022 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 96/1000 --- L(Train): 0.0079800 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.346 reward + 0.044 harvest_duration + -0.171 value_stay^2 + 0.159 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.346 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.022 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 97/1000 --- L(Train): 0.0079553 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.745 value_stay[t] + 0.346 reward + 0.044 harvest_duration + -0.17 value_stay^2 + 0.157 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.346 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.022 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 98/1000 --- L(Train): 0.0079336 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.744 value_stay[t] + 0.347 reward + 0.044 harvest_duration + -0.169 value_stay^2 + 0.155 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.347 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.023 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 99/1000 --- L(Train): 0.0079138 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.744 value_stay[t] + 0.347 reward + 0.044 harvest_duration + -0.169 value_stay^2 + 0.154 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.347 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.023 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 100/1000 --- L(Train): 0.0078920 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.744 value_stay[t] + 0.347 reward + 0.044 harvest_duration + -0.168 value_stay^2 + 0.152 value_stay*reward + -0.258 value_stay*harvest_duration + 0.327 reward^2 + 0.348 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.023 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 101/1000 --- L(Train): 0.0078692 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.744 value_stay[t] + 0.348 reward + 0.043 harvest_duration + -0.167 value_stay^2 + 0.15 value_stay*reward + -0.258 value_stay*harvest_duration + 0.327 reward^2 + 0.348 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.024 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 102/1000 --- L(Train): 0.0078481 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.744 value_stay[t] + 0.348 reward + 0.043 harvest_duration + -0.166 value_stay^2 + 0.148 value_stay*reward + -0.258 value_stay*harvest_duration + 0.327 reward^2 + 0.349 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.024 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 103/1000 --- L(Train): 0.0078283 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.744 value_stay[t] + 0.349 reward + 0.043 harvest_duration + -0.165 value_stay^2 + 0.146 value_stay*reward + -0.258 value_stay*harvest_duration + 0.327 reward^2 + 0.349 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.024 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 104/1000 --- L(Train): 0.0078079 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.743 value_stay[t] + 0.35 reward + 0.043 harvest_duration + -0.164 value_stay^2 + 0.144 value_stay*reward + -0.258 value_stay*harvest_duration + 0.327 reward^2 + 0.35 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.024 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 105/1000 --- L(Train): 0.0077873 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.743 value_stay[t] + 0.35 reward + 0.043 harvest_duration + -0.164 value_stay^2 + 0.142 value_stay*reward + -0.259 value_stay*harvest_duration + 0.327 reward^2 + 0.35 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.025 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 106/1000 --- L(Train): 0.0077673 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.743 value_stay[t] + 0.351 reward + 0.043 harvest_duration + -0.163 value_stay^2 + 0.14 value_stay*reward + -0.259 value_stay*harvest_duration + 0.327 reward^2 + 0.351 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.025 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 107/1000 --- L(Train): 0.0077475 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.743 value_stay[t] + 0.351 reward + 0.043 harvest_duration + -0.162 value_stay^2 + 0.139 value_stay*reward + -0.259 value_stay*harvest_duration + 0.327 reward^2 + 0.352 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.025 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 108/1000 --- L(Train): 0.0077274 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.742 value_stay[t] + 0.352 reward + 0.043 harvest_duration + -0.161 value_stay^2 + 0.137 value_stay*reward + -0.259 value_stay*harvest_duration + 0.327 reward^2 + 0.352 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.026 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 109/1000 --- L(Train): 0.0077075 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.742 value_stay[t] + 0.352 reward + 0.043 harvest_duration + -0.16 value_stay^2 + 0.135 value_stay*reward + -0.259 value_stay*harvest_duration + 0.327 reward^2 + 0.353 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.026 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 110/1000 --- L(Train): 0.0076875 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.742 value_stay[t] + 0.353 reward + 0.043 harvest_duration + -0.159 value_stay^2 + 0.133 value_stay*reward + -0.26 value_stay*harvest_duration + 0.327 reward^2 + 0.353 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.026 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 111/1000 --- L(Train): 0.0076684 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.742 value_stay[t] + 0.353 reward + 0.043 harvest_duration + -0.158 value_stay^2 + 0.132 value_stay*reward + -0.26 value_stay*harvest_duration + 0.328 reward^2 + 0.354 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.026 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 112/1000 --- L(Train): 0.0076495 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.742 value_stay[t] + 0.354 reward + 0.043 harvest_duration + -0.158 value_stay^2 + 0.13 value_stay*reward + -0.26 value_stay*harvest_duration + 0.328 reward^2 + 0.354 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.027 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 113/1000 --- L(Train): 0.0076303 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.741 value_stay[t] + 0.355 reward + 0.043 harvest_duration + -0.157 value_stay^2 + 0.128 value_stay*reward + -0.26 value_stay*harvest_duration + 0.328 reward^2 + 0.355 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.027 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 114/1000 --- L(Train): 0.0076111 --- L(Val, SINDy): 0.0000000 --- Time: 0.27s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.741 value_stay[t] + 0.355 reward + 0.043 harvest_duration + -0.156 value_stay^2 + 0.126 value_stay*reward + -0.26 value_stay*harvest_duration + 0.328 reward^2 + 0.356 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.027 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 115/1000 --- L(Train): 0.0075930 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.741 value_stay[t] + 0.356 reward + 0.043 harvest_duration + -0.155 value_stay^2 + 0.125 value_stay*reward + -0.261 value_stay*harvest_duration + 0.328 reward^2 + 0.356 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.028 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 116/1000 --- L(Train): 0.0075748 --- L(Val, SINDy): 0.0000000 --- Time: 0.27s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.741 value_stay[t] + 0.356 reward + 0.043 harvest_duration + -0.154 value_stay^2 + 0.123 value_stay*reward + -0.261 value_stay*harvest_duration + 0.328 reward^2 + 0.357 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.028 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 117/1000 --- L(Train): 0.0075561 --- L(Val, SINDy): 0.0000000 --- Time: 0.14s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.741 value_stay[t] + 0.357 reward + 0.043 harvest_duration + -0.153 value_stay^2 + 0.121 value_stay*reward + -0.261 value_stay*harvest_duration + 0.328 reward^2 + 0.357 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.028 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 118/1000 --- L(Train): 0.0075383 --- L(Val, SINDy): 0.0000000 --- Time: 0.09s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.741 value_stay[t] + 0.358 reward + 0.043 harvest_duration + -0.152 value_stay^2 + 0.119 value_stay*reward + -0.261 value_stay*harvest_duration + 0.328 reward^2 + 0.358 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.028 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 119/1000 --- L(Train): 0.0075211 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.74 value_stay[t] + 0.358 reward + 0.042 harvest_duration + -0.151 value_stay^2 + 0.118 value_stay*reward + -0.261 value_stay*harvest_duration + 0.328 reward^2 + 0.358 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.029 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 120/1000 --- L(Train): 0.0075035 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.74 value_stay[t] + 0.359 reward + 0.042 harvest_duration + -0.15 value_stay^2 + 0.116 value_stay*reward + -0.261 value_stay*harvest_duration + 0.328 reward^2 + 0.359 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.029 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 121/1000 --- L(Train): 0.0074857 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.74 value_stay[t] + 0.359 reward + 0.042 harvest_duration + -0.149 value_stay^2 + 0.114 value_stay*reward + -0.262 value_stay*harvest_duration + 0.328 reward^2 + 0.36 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.029 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 122/1000 --- L(Train): 0.0074682 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.74 value_stay[t] + 0.36 reward + 0.042 harvest_duration + -0.148 value_stay^2 + 0.112 value_stay*reward + -0.262 value_stay*harvest_duration + 0.328 reward^2 + 0.36 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.03 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 123/1000 --- L(Train): 0.0074510 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.74 value_stay[t] + 0.36 reward + 0.042 harvest_duration + -0.147 value_stay^2 + 0.111 value_stay*reward + -0.262 value_stay*harvest_duration + 0.328 reward^2 + 0.361 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.03 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 124/1000 --- L(Train): 0.0074348 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.74 value_stay[t] + 0.361 reward + 0.042 harvest_duration + -0.146 value_stay^2 + 0.109 value_stay*reward + -0.262 value_stay*harvest_duration + 0.328 reward^2 + 0.361 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.03 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 125/1000 --- L(Train): 0.0074179 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.739 value_stay[t] + 0.361 reward + 0.042 harvest_duration + -0.145 value_stay^2 + 0.107 value_stay*reward + -0.262 value_stay*harvest_duration + 0.328 reward^2 + 0.362 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.03 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 126/1000 --- L(Train): 0.0074011 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.739 value_stay[t] + 0.362 reward + 0.042 harvest_duration + -0.145 value_stay^2 + 0.105 value_stay*reward + -0.262 value_stay*harvest_duration + 0.328 reward^2 + 0.362 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.031 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 127/1000 --- L(Train): 0.0073850 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.739 value_stay[t] + 0.362 reward + 0.042 harvest_duration + -0.144 value_stay^2 + 0.103 value_stay*reward + -0.263 value_stay*harvest_duration + 0.328 reward^2 + 0.363 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.031 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 128/1000 --- L(Train): 0.0073692 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.739 value_stay[t] + 0.363 reward + 0.042 harvest_duration + -0.143 value_stay^2 + 0.101 value_stay*reward + -0.263 value_stay*harvest_duration + 0.328 reward^2 + 0.363 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.031 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 129/1000 --- L(Train): 0.0073533 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.739 value_stay[t] + 0.363 reward + 0.042 harvest_duration + -0.142 value_stay^2 + 0.099 value_stay*reward + -0.263 value_stay*harvest_duration + 0.328 reward^2 + 0.364 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.032 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 130/1000 --- L(Train): 0.0073370 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.739 value_stay[t] + 0.364 reward + 0.042 harvest_duration + -0.141 value_stay^2 + 0.097 value_stay*reward + -0.263 value_stay*harvest_duration + 0.328 reward^2 + 0.364 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.032 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 131/1000 --- L(Train): 0.0073214 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.739 value_stay[t] + 0.364 reward + 0.042 harvest_duration + -0.14 value_stay^2 + 0.095 value_stay*reward + -0.263 value_stay*harvest_duration + 0.328 reward^2 + 0.365 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.032 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 132/1000 --- L(Train): 0.0073062 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.738 value_stay[t] + 0.365 reward + 0.042 harvest_duration + -0.139 value_stay^2 + 0.094 value_stay*reward + -0.263 value_stay*harvest_duration + 0.328 reward^2 + 0.365 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.033 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 133/1000 --- L(Train): 0.0072915 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.738 value_stay[t] + 0.365 reward + 0.041 harvest_duration + -0.138 value_stay^2 + 0.092 value_stay*reward + -0.263 value_stay*harvest_duration + 0.328 reward^2 + 0.366 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.033 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 134/1000 --- L(Train): 0.0072772 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.738 value_stay[t] + 0.366 reward + 0.041 harvest_duration + -0.137 value_stay^2 + 0.09 value_stay*reward + -0.264 value_stay*harvest_duration + 0.328 reward^2 + 0.366 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.033 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 135/1000 --- L(Train): 0.0072631 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.738 value_stay[t] + 0.366 reward + 0.041 harvest_duration + -0.136 value_stay^2 + 0.088 value_stay*reward + -0.264 value_stay*harvest_duration + 0.328 reward^2 + 0.367 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.033 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 136/1000 --- L(Train): 0.0072486 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.738 value_stay[t] + 0.367 reward + 0.041 harvest_duration + -0.135 value_stay^2 + 0.086 value_stay*reward + -0.264 value_stay*harvest_duration + 0.328 reward^2 + 0.367 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.034 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 137/1000 --- L(Train): 0.0072335 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.738 value_stay[t] + 0.367 reward + 0.041 harvest_duration + -0.134 value_stay^2 + 0.084 value_stay*reward + -0.264 value_stay*harvest_duration + 0.328 reward^2 + 0.368 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.034 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 138/1000 --- L(Train): 0.0072190 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.738 value_stay[t] + 0.368 reward + 0.041 harvest_duration + -0.133 value_stay^2 + 0.082 value_stay*reward + -0.264 value_stay*harvest_duration + 0.327 reward^2 + 0.368 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.034 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 139/1000 --- L(Train): 0.0072052 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.737 value_stay[t] + 0.368 reward + 0.041 harvest_duration + -0.132 value_stay^2 + 0.08 value_stay*reward + -0.264 value_stay*harvest_duration + 0.327 reward^2 + 0.369 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.035 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 140/1000 --- L(Train): 0.0071906 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.737 value_stay[t] + 0.369 reward + 0.041 harvest_duration + -0.131 value_stay^2 + 0.078 value_stay*reward + -0.264 value_stay*harvest_duration + 0.327 reward^2 + 0.369 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.035 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 141/1000 --- L(Train): 0.0071763 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.737 value_stay[t] + 0.369 reward + 0.041 harvest_duration + -0.13 value_stay^2 + 0.076 value_stay*reward + -0.264 value_stay*harvest_duration + 0.327 reward^2 + 0.37 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.035 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 142/1000 --- L(Train): 0.0071629 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.737 value_stay[t] + 0.37 reward + 0.041 harvest_duration + -0.129 value_stay^2 + 0.074 value_stay*reward + -0.265 value_stay*harvest_duration + 0.327 reward^2 + 0.37 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.035 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 143/1000 --- L(Train): 0.0071491 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.737 value_stay[t] + 0.37 reward + 0.041 harvest_duration + -0.128 value_stay^2 + 0.072 value_stay*reward + -0.265 value_stay*harvest_duration + 0.327 reward^2 + 0.371 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.036 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 144/1000 --- L(Train): 0.0071357 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.737 value_stay[t] + 0.371 reward + 0.041 harvest_duration + -0.127 value_stay^2 + 0.07 value_stay*reward + -0.265 value_stay*harvest_duration + 0.327 reward^2 + 0.371 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.036 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 145/1000 --- L(Train): 0.0071231 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.737 value_stay[t] + 0.371 reward + 0.041 harvest_duration + -0.126 value_stay^2 + 0.067 value_stay*reward + -0.265 value_stay*harvest_duration + 0.327 reward^2 + 0.372 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.036 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\u001b[H\u001b[2J\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 146/1000 --- L(Train): 0.0071100 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.737 value_stay[t] + 0.372 reward + 0.041 harvest_duration + -0.125 value_stay^2 + 0.065 value_stay*reward + -0.265 value_stay*harvest_duration + 0.327 reward^2 + 0.372 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.037 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 147/1000 --- L(Train): 0.0070968 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.736 value_stay[t] + 0.372 reward + 0.041 harvest_duration + -0.124 value_stay^2 + 0.063 value_stay*reward + -0.265 value_stay*harvest_duration + 0.326 reward^2 + 0.373 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.037 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 148/1000 --- L(Train): 0.0070842 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.736 value_stay[t] + 0.373 reward + 0.041 harvest_duration + -0.123 value_stay^2 + 0.061 value_stay*reward + -0.265 value_stay*harvest_duration + 0.326 reward^2 + 0.373 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.037 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 149/1000 --- L(Train): 0.0070712 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.736 value_stay[t] + 0.373 reward + 0.041 harvest_duration + -0.122 value_stay^2 + 0.059 value_stay*reward + -0.265 value_stay*harvest_duration + 0.326 reward^2 + 0.373 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.037 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 150/1000 --- L(Train): 0.0070591 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.736 value_stay[t] + 0.374 reward + 0.04 harvest_duration + -0.121 value_stay^2 + 0.057 value_stay*reward + -0.266 value_stay*harvest_duration + 0.326 reward^2 + 0.374 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.038 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 151/1000 --- L(Train): 0.0070471 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.736 value_stay[t] + 0.374 reward + 0.04 harvest_duration + -0.12 value_stay^2 + 0.055 value_stay*reward + -0.266 value_stay*harvest_duration + 0.326 reward^2 + 0.374 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.038 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 152/1000 --- L(Train): 0.0070345 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.736 value_stay[t] + 0.375 reward + 0.04 harvest_duration + -0.119 value_stay^2 + 0.053 value_stay*reward + -0.266 value_stay*harvest_duration + 0.326 reward^2 + 0.375 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.038 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 153/1000 --- L(Train): 0.0070222 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.736 value_stay[t] + 0.375 reward + 0.04 harvest_duration + -0.118 value_stay^2 + 0.051 value_stay*reward + -0.266 value_stay*harvest_duration + 0.326 reward^2 + 0.375 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.039 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 154/1000 --- L(Train): 0.0070103 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.736 value_stay[t] + 0.376 reward + 0.04 harvest_duration + -0.117 value_stay^2 + 0.049 value_stay*reward + -0.266 value_stay*harvest_duration + 0.325 reward^2 + 0.376 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.039 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 155/1000 --- L(Train): 0.0069985 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.735 value_stay[t] + 0.376 reward + 0.04 harvest_duration + -0.116 value_stay^2 + 0.048 value_stay*reward + -0.266 value_stay*harvest_duration + 0.325 reward^2 + 0.376 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.039 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 156/1000 --- L(Train): 0.0069870 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.735 value_stay[t] + 0.377 reward + 0.04 harvest_duration + -0.115 value_stay^2 + 0.046 value_stay*reward + -0.266 value_stay*harvest_duration + 0.325 reward^2 + 0.377 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.039 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 157/1000 --- L(Train): 0.0069757 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.735 value_stay[t] + 0.377 reward + 0.04 harvest_duration + -0.114 value_stay^2 + 0.044 value_stay*reward + -0.266 value_stay*harvest_duration + 0.325 reward^2 + 0.377 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.04 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 158/1000 --- L(Train): 0.0069645 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.735 value_stay[t] + 0.378 reward + 0.04 harvest_duration + -0.113 value_stay^2 + 0.042 value_stay*reward + -0.267 value_stay*harvest_duration + 0.325 reward^2 + 0.378 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.04 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 159/1000 --- L(Train): 0.0069533 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.735 value_stay[t] + 0.378 reward + 0.04 harvest_duration + -0.113 value_stay^2 + 0.04 value_stay*reward + -0.267 value_stay*harvest_duration + 0.325 reward^2 + 0.378 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.04 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 160/1000 --- L(Train): 0.0069427 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.735 value_stay[t] + 0.379 reward + 0.04 harvest_duration + -0.112 value_stay^2 + 0.038 value_stay*reward + -0.267 value_stay*harvest_duration + 0.325 reward^2 + 0.379 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.041 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 161/1000 --- L(Train): 0.0069316 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.735 value_stay[t] + 0.379 reward + 0.04 harvest_duration + -0.111 value_stay^2 + 0.036 value_stay*reward + -0.267 value_stay*harvest_duration + 0.324 reward^2 + 0.379 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.041 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 162/1000 --- L(Train): 0.0069205 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.735 value_stay[t] + 0.38 reward + 0.04 harvest_duration + -0.11 value_stay^2 + 0.034 value_stay*reward + -0.267 value_stay*harvest_duration + 0.324 reward^2 + 0.38 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.041 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 163/1000 --- L(Train): 0.0069095 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.734 value_stay[t] + 0.38 reward + 0.04 harvest_duration + -0.109 value_stay^2 + 0.032 value_stay*reward + -0.267 value_stay*harvest_duration + 0.324 reward^2 + 0.381 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.041 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 164/1000 --- L(Train): 0.0068990 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.734 value_stay[t] + 0.381 reward + 0.04 harvest_duration + -0.108 value_stay^2 + 0.03 value_stay*reward + -0.267 value_stay*harvest_duration + 0.324 reward^2 + 0.381 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.042 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 165/1000 --- L(Train): 0.0068888 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.734 value_stay[t] + 0.381 reward + 0.039 harvest_duration + -0.107 value_stay^2 + 0.028 value_stay*reward + -0.268 value_stay*harvest_duration + 0.324 reward^2 + 0.382 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.042 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 166/1000 --- L(Train): 0.0068784 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.734 value_stay[t] + 0.382 reward + 0.039 harvest_duration + -0.106 value_stay^2 + 0.026 value_stay*reward + -0.268 value_stay*harvest_duration + 0.324 reward^2 + 0.382 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.042 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 167/1000 --- L(Train): 0.0068684 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.734 value_stay[t] + 0.382 reward + 0.039 harvest_duration + -0.105 value_stay^2 + 0.024 value_stay*reward + -0.268 value_stay*harvest_duration + 0.323 reward^2 + 0.383 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.043 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 168/1000 --- L(Train): 0.0068587 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.734 value_stay[t] + 0.383 reward + 0.039 harvest_duration + -0.104 value_stay^2 + 0.022 value_stay*reward + -0.268 value_stay*harvest_duration + 0.323 reward^2 + 0.383 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.043 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 169/1000 --- L(Train): 0.0068495 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.734 value_stay[t] + 0.383 reward + 0.039 harvest_duration + -0.103 value_stay^2 + 0.02 value_stay*reward + -0.268 value_stay*harvest_duration + 0.323 reward^2 + 0.384 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.043 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 170/1000 --- L(Train): 0.0068402 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.733 value_stay[t] + 0.384 reward + 0.039 harvest_duration + -0.102 value_stay^2 + 0.018 value_stay*reward + -0.268 value_stay*harvest_duration + 0.323 reward^2 + 0.384 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.043 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 171/1000 --- L(Train): 0.0068310 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.733 value_stay[t] + 0.384 reward + 0.039 harvest_duration + -0.101 value_stay^2 + 0.016 value_stay*reward + -0.268 value_stay*harvest_duration + 0.323 reward^2 + 0.385 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.044 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 172/1000 --- L(Train): 0.0068214 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.733 value_stay[t] + 0.385 reward + 0.039 harvest_duration + -0.1 value_stay^2 + 0.014 value_stay*reward + -0.269 value_stay*harvest_duration + 0.323 reward^2 + 0.385 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.044 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 173/1000 --- L(Train): 0.0068115 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.733 value_stay[t] + 0.385 reward + 0.039 harvest_duration + -0.099 value_stay^2 + 0.012 value_stay*reward + -0.269 value_stay*harvest_duration + 0.322 reward^2 + 0.386 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.044 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 174/1000 --- L(Train): 0.0068023 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.733 value_stay[t] + 0.386 reward + 0.039 harvest_duration + -0.098 value_stay^2 + 0.01 value_stay*reward + -0.269 value_stay*harvest_duration + 0.322 reward^2 + 0.386 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.044 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 175/1000 --- L(Train): 0.0067934 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.733 value_stay[t] + 0.387 reward + 0.039 harvest_duration + -0.097 value_stay^2 + 0.008 value_stay*reward + -0.269 value_stay*harvest_duration + 0.322 reward^2 + 0.387 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.045 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 176/1000 --- L(Train): 0.0067844 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.733 value_stay[t] + 0.387 reward + 0.039 harvest_duration + -0.096 value_stay^2 + 0.006 value_stay*reward + -0.269 value_stay*harvest_duration + 0.322 reward^2 + 0.387 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.045 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 177/1000 --- L(Train): 0.0067757 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.732 value_stay[t] + 0.388 reward + 0.039 harvest_duration + -0.095 value_stay^2 + 0.004 value_stay*reward + -0.269 value_stay*harvest_duration + 0.322 reward^2 + 0.388 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.045 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 178/1000 --- L(Train): 0.0067670 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.732 value_stay[t] + 0.388 reward + 0.039 harvest_duration + -0.094 value_stay^2 + 0.002 value_stay*reward + -0.269 value_stay*harvest_duration + 0.321 reward^2 + 0.388 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.046 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 179/1000 --- L(Train): 0.0067582 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.732 value_stay[t] + 0.389 reward + 0.039 harvest_duration + -0.093 value_stay^2 + 0.0 value_stay*reward + -0.27 value_stay*harvest_duration + 0.321 reward^2 + 0.389 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.046 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 180/1000 --- L(Train): 0.0067494 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.732 value_stay[t] + 0.389 reward + 0.039 harvest_duration + -0.092 value_stay^2 + -0.002 value_stay*reward + -0.27 value_stay*harvest_duration + 0.321 reward^2 + 0.389 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.046 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 181/1000 --- L(Train): 0.0067407 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.732 value_stay[t] + 0.39 reward + 0.038 harvest_duration + -0.091 value_stay^2 + -0.003 value_stay*reward + -0.27 value_stay*harvest_duration + 0.321 reward^2 + 0.39 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.046 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 182/1000 --- L(Train): 0.0067320 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.732 value_stay[t] + 0.39 reward + 0.038 harvest_duration + -0.09 value_stay^2 + -0.003 value_stay*reward + -0.27 value_stay*harvest_duration + 0.321 reward^2 + 0.391 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.047 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 183/1000 --- L(Train): 0.0067237 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.732 value_stay[t] + 0.391 reward + 0.038 harvest_duration + -0.089 value_stay^2 + -0.002 value_stay*reward + -0.27 value_stay*harvest_duration + 0.32 reward^2 + 0.391 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.047 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 184/1000 --- L(Train): 0.0067160 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.731 value_stay[t] + 0.391 reward + 0.038 harvest_duration + -0.089 value_stay^2 + -0.0 value_stay*reward + -0.27 value_stay*harvest_duration + 0.32 reward^2 + 0.392 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.047 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 185/1000 --- L(Train): 0.0067082 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.037 1 + 0.731 value_stay[t] + 0.392 reward + 0.037 harvest_duration + -0.088 value_stay^2 + 0.002 value_stay*reward + -0.271 value_stay*harvest_duration + 0.32 reward^2 + 0.392 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.047 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 186/1000 --- L(Train): 0.0067001 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.037 1 + 0.731 value_stay[t] + 0.392 reward + 0.037 harvest_duration + -0.087 value_stay^2 + 0.003 value_stay*reward + -0.271 value_stay*harvest_duration + 0.32 reward^2 + 0.392 reward*harvest_duration + 0.037 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.048 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 187/1000 --- L(Train): 0.0066923 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.037 1 + 0.73 value_stay[t] + 0.393 reward + 0.037 harvest_duration + -0.086 value_stay^2 + 0.004 value_stay*reward + -0.271 value_stay*harvest_duration + 0.319 reward^2 + 0.393 reward*harvest_duration + 0.037 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.048 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 188/1000 --- L(Train): 0.0066845 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.037 1 + 0.73 value_stay[t] + 0.393 reward + 0.037 harvest_duration + -0.086 value_stay^2 + 0.005 value_stay*reward + -0.272 value_stay*harvest_duration + 0.319 reward^2 + 0.393 reward*harvest_duration + 0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.048 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 189/1000 --- L(Train): 0.0066767 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.037 1 + 0.73 value_stay[t] + 0.393 reward + 0.037 harvest_duration + -0.085 value_stay^2 + 0.005 value_stay*reward + -0.272 value_stay*harvest_duration + 0.318 reward^2 + 0.394 reward*harvest_duration + 0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.049 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 190/1000 --- L(Train): 0.0066687 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.037 1 + 0.729 value_stay[t] + 0.394 reward + 0.037 harvest_duration + -0.085 value_stay^2 + 0.004 value_stay*reward + -0.272 value_stay*harvest_duration + 0.318 reward^2 + 0.394 reward*harvest_duration + 0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.049 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 191/1000 --- L(Train): 0.0066605 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.037 1 + 0.729 value_stay[t] + 0.394 reward + 0.037 harvest_duration + -0.084 value_stay^2 + 0.003 value_stay*reward + -0.273 value_stay*harvest_duration + 0.318 reward^2 + 0.394 reward*harvest_duration + 0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.049 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 192/1000 --- L(Train): 0.0066534 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.037 1 + 0.728 value_stay[t] + 0.394 reward + 0.037 harvest_duration + -0.084 value_stay^2 + 0.002 value_stay*reward + -0.273 value_stay*harvest_duration + 0.317 reward^2 + 0.395 reward*harvest_duration + 0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.049 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 193/1000 --- L(Train): 0.0066464 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.728 value_stay[t] + 0.394 reward + 0.038 harvest_duration + -0.083 value_stay^2 + 0.0 value_stay*reward + -0.274 value_stay*harvest_duration + 0.317 reward^2 + 0.395 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.05 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 194/1000 --- L(Train): 0.0066392 --- L(Val, SINDy): 0.0000000 --- Time: 0.11s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.727 value_stay[t] + 0.395 reward + 0.038 harvest_duration + -0.083 value_stay^2 + -0.001 value_stay*reward + -0.274 value_stay*harvest_duration + 0.316 reward^2 + 0.395 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.05 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 195/1000 --- L(Train): 0.0066317 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.727 value_stay[t] + 0.395 reward + 0.038 harvest_duration + -0.082 value_stay^2 + -0.002 value_stay*reward + -0.275 value_stay*harvest_duration + 0.316 reward^2 + 0.395 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.05 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 196/1000 --- L(Train): 0.0066241 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.726 value_stay[t] + 0.395 reward + 0.038 harvest_duration + -0.082 value_stay^2 + -0.002 value_stay*reward + -0.275 value_stay*harvest_duration + 0.315 reward^2 + 0.395 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.05 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 197/1000 --- L(Train): 0.0066166 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.726 value_stay[t] + 0.395 reward + 0.038 harvest_duration + -0.082 value_stay^2 + -0.002 value_stay*reward + -0.276 value_stay*harvest_duration + 0.314 reward^2 + 0.396 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.051 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 198/1000 --- L(Train): 0.0066099 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.726 value_stay[t] + 0.396 reward + 0.038 harvest_duration + -0.081 value_stay^2 + -0.0 value_stay*reward + -0.276 value_stay*harvest_duration + 0.314 reward^2 + 0.396 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.051 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 199/1000 --- L(Train): 0.0066029 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.725 value_stay[t] + 0.396 reward + 0.038 harvest_duration + -0.081 value_stay^2 + 0.001 value_stay*reward + -0.277 value_stay*harvest_duration + 0.313 reward^2 + 0.396 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.051 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 200/1000 --- L(Train): 0.0065958 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.725 value_stay[t] + 0.396 reward + 0.038 harvest_duration + -0.08 value_stay^2 + 0.003 value_stay*reward + -0.277 value_stay*harvest_duration + 0.313 reward^2 + 0.396 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.051 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 201/1000 --- L(Train): 0.0065888 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.724 value_stay[t] + 0.396 reward + 0.038 harvest_duration + -0.08 value_stay^2 + 0.004 value_stay*reward + -0.278 value_stay*harvest_duration + 0.312 reward^2 + 0.396 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.052 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 202/1000 --- L(Train): 0.0065817 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.724 value_stay[t] + 0.396 reward + 0.038 harvest_duration + -0.079 value_stay^2 + 0.004 value_stay*reward + -0.278 value_stay*harvest_duration + 0.311 reward^2 + 0.396 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.052 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 203/1000 --- L(Train): 0.0065753 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.723 value_stay[t] + 0.396 reward + 0.039 harvest_duration + -0.079 value_stay^2 + 0.004 value_stay*reward + -0.278 value_stay*harvest_duration + 0.311 reward^2 + 0.396 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.052 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 204/1000 --- L(Train): 0.0065690 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.723 value_stay[t] + 0.396 reward + 0.039 harvest_duration + -0.078 value_stay^2 + 0.003 value_stay*reward + -0.279 value_stay*harvest_duration + 0.31 reward^2 + 0.397 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.053 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 205/1000 --- L(Train): 0.0065626 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.723 value_stay[t] + 0.396 reward + 0.039 harvest_duration + -0.078 value_stay^2 + 0.002 value_stay*reward + -0.279 value_stay*harvest_duration + 0.309 reward^2 + 0.397 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.053 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 206/1000 --- L(Train): 0.0065561 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.722 value_stay[t] + 0.396 reward + 0.039 harvest_duration + -0.078 value_stay^2 + 0.001 value_stay*reward + -0.28 value_stay*harvest_duration + 0.308 reward^2 + 0.397 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.053 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 207/1000 --- L(Train): 0.0065496 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.722 value_stay[t] + 0.396 reward + 0.039 harvest_duration + -0.077 value_stay^2 + -0.0 value_stay*reward + -0.28 value_stay*harvest_duration + 0.308 reward^2 + 0.397 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.053 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 208/1000 --- L(Train): 0.0065430 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.721 value_stay[t] + 0.397 reward + 0.039 harvest_duration + -0.076 value_stay^2 + -0.001 value_stay*reward + -0.28 value_stay*harvest_duration + 0.307 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.054 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 209/1000 --- L(Train): 0.0065367 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.721 value_stay[t] + 0.397 reward + 0.039 harvest_duration + -0.076 value_stay^2 + -0.0 value_stay*reward + -0.281 value_stay*harvest_duration + 0.306 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.054 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 210/1000 --- L(Train): 0.0065304 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.721 value_stay[t] + 0.397 reward + 0.039 harvest_duration + -0.075 value_stay^2 + 0.001 value_stay*reward + -0.281 value_stay*harvest_duration + 0.305 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.054 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 211/1000 --- L(Train): 0.0065240 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.72 value_stay[t] + 0.397 reward + 0.039 harvest_duration + -0.075 value_stay^2 + 0.002 value_stay*reward + -0.281 value_stay*harvest_duration + 0.305 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.054 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 212/1000 --- L(Train): 0.0065175 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.72 value_stay[t] + 0.397 reward + 0.039 harvest_duration + -0.074 value_stay^2 + 0.002 value_stay*reward + -0.282 value_stay*harvest_duration + 0.304 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.055 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 213/1000 --- L(Train): 0.0065112 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.72 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.074 value_stay^2 + 0.002 value_stay*reward + -0.282 value_stay*harvest_duration + 0.303 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.055 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 214/1000 --- L(Train): 0.0065052 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.72 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.073 value_stay^2 + 0.001 value_stay*reward + -0.282 value_stay*harvest_duration + 0.302 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.055 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 215/1000 --- L(Train): 0.0064995 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.719 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.072 value_stay^2 + 0.0 value_stay*reward + -0.282 value_stay*harvest_duration + 0.302 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.055 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 216/1000 --- L(Train): 0.0064937 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.719 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.072 value_stay^2 + -0.001 value_stay*reward + -0.283 value_stay*harvest_duration + 0.301 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.056 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 217/1000 --- L(Train): 0.0064880 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.719 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.071 value_stay^2 + -0.001 value_stay*reward + -0.283 value_stay*harvest_duration + 0.3 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.056 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 218/1000 --- L(Train): 0.0064820 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.718 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.07 value_stay^2 + -0.0 value_stay*reward + -0.283 value_stay*harvest_duration + 0.299 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.056 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 219/1000 --- L(Train): 0.0064758 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.718 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.07 value_stay^2 + 0.001 value_stay*reward + -0.284 value_stay*harvest_duration + 0.299 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.056 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 220/1000 --- L(Train): 0.0064699 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.718 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.069 value_stay^2 + 0.002 value_stay*reward + -0.284 value_stay*harvest_duration + 0.298 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.057 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 221/1000 --- L(Train): 0.0064639 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.717 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.069 value_stay^2 + 0.003 value_stay*reward + -0.284 value_stay*harvest_duration + 0.297 reward^2 + 0.398 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.057 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 222/1000 --- L(Train): 0.0064582 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.717 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.068 value_stay^2 + 0.002 value_stay*reward + -0.285 value_stay*harvest_duration + 0.296 reward^2 + 0.398 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.057 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 223/1000 --- L(Train): 0.0064530 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.717 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.067 value_stay^2 + 0.002 value_stay*reward + -0.285 value_stay*harvest_duration + 0.296 reward^2 + 0.398 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.057 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 224/1000 --- L(Train): 0.0064477 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.716 value_stay[t] + 0.398 reward + 0.04 harvest_duration + -0.067 value_stay^2 + 0.001 value_stay*reward + -0.285 value_stay*harvest_duration + 0.295 reward^2 + 0.398 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.058 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 225/1000 --- L(Train): 0.0064424 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.716 value_stay[t] + 0.398 reward + 0.04 harvest_duration + -0.066 value_stay^2 + 0.0 value_stay*reward + -0.286 value_stay*harvest_duration + 0.294 reward^2 + 0.398 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.058 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 226/1000 --- L(Train): 0.0064365 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.716 value_stay[t] + 0.398 reward + 0.04 harvest_duration + -0.066 value_stay^2 + -0.001 value_stay*reward + -0.286 value_stay*harvest_duration + 0.294 reward^2 + 0.398 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.058 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 227/1000 --- L(Train): 0.0064308 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.715 value_stay[t] + 0.398 reward + 0.041 harvest_duration + -0.065 value_stay^2 + -0.002 value_stay*reward + -0.286 value_stay*harvest_duration + 0.293 reward^2 + 0.398 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.058 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 228/1000 --- L(Train): 0.0064249 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.715 value_stay[t] + 0.398 reward + 0.041 harvest_duration + -0.065 value_stay^2 + -0.001 value_stay*reward + -0.287 value_stay*harvest_duration + 0.292 reward^2 + 0.398 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.059 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 229/1000 --- L(Train): 0.0064195 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.715 value_stay[t] + 0.398 reward + 0.041 harvest_duration + -0.064 value_stay^2 + 0.0 value_stay*reward + -0.287 value_stay*harvest_duration + 0.291 reward^2 + 0.398 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.059 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 230/1000 --- L(Train): 0.0064139 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.714 value_stay[t] + 0.398 reward + 0.041 harvest_duration + -0.064 value_stay^2 + 0.001 value_stay*reward + -0.287 value_stay*harvest_duration + 0.291 reward^2 + 0.398 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.059 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 231/1000 --- L(Train): 0.0064087 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.714 value_stay[t] + 0.398 reward + 0.041 harvest_duration + -0.063 value_stay^2 + 0.001 value_stay*reward + -0.288 value_stay*harvest_duration + 0.29 reward^2 + 0.399 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.059 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 232/1000 --- L(Train): 0.0064035 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.714 value_stay[t] + 0.398 reward + 0.041 harvest_duration + -0.062 value_stay^2 + 0.001 value_stay*reward + -0.288 value_stay*harvest_duration + 0.289 reward^2 + 0.399 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.059 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 233/1000 --- L(Train): 0.0063982 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.713 value_stay[t] + 0.399 reward + 0.041 harvest_duration + -0.062 value_stay^2 + 0.0 value_stay*reward + -0.289 value_stay*harvest_duration + 0.288 reward^2 + 0.399 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.06 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 234/1000 --- L(Train): 0.0063925 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.713 value_stay[t] + 0.399 reward + 0.041 harvest_duration + -0.061 value_stay^2 + -0.0 value_stay*reward + -0.289 value_stay*harvest_duration + 0.288 reward^2 + 0.399 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.06 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 235/1000 --- L(Train): 0.0063876 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.712 value_stay[t] + 0.399 reward + 0.041 harvest_duration + -0.061 value_stay^2 + -0.0 value_stay*reward + -0.289 value_stay*harvest_duration + 0.287 reward^2 + 0.399 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.06 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 236/1000 --- L(Train): 0.0063828 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.712 value_stay[t] + 0.399 reward + 0.041 harvest_duration + -0.06 value_stay^2 + 0.001 value_stay*reward + -0.29 value_stay*harvest_duration + 0.286 reward^2 + 0.399 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.06 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 237/1000 --- L(Train): 0.0063779 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.712 value_stay[t] + 0.399 reward + 0.041 harvest_duration + -0.06 value_stay^2 + 0.001 value_stay*reward + -0.29 value_stay*harvest_duration + 0.286 reward^2 + 0.399 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.061 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 238/1000 --- L(Train): 0.0063726 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.711 value_stay[t] + 0.399 reward + 0.041 harvest_duration + -0.059 value_stay^2 + 0.001 value_stay*reward + -0.29 value_stay*harvest_duration + 0.285 reward^2 + 0.4 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.061 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 239/1000 --- L(Train): 0.0063673 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.711 value_stay[t] + 0.399 reward + 0.041 harvest_duration + -0.059 value_stay^2 + 0.001 value_stay*reward + -0.291 value_stay*harvest_duration + 0.284 reward^2 + 0.4 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.061 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 240/1000 --- L(Train): 0.0063624 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.711 value_stay[t] + 0.4 reward + 0.041 harvest_duration + -0.058 value_stay^2 + -0.0 value_stay*reward + -0.291 value_stay*harvest_duration + 0.284 reward^2 + 0.4 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.061 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 241/1000 --- L(Train): 0.0063573 --- L(Val, SINDy): 0.0000000 --- Time: 0.09s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.71 value_stay[t] + 0.4 reward + 0.041 harvest_duration + -0.057 value_stay^2 + 0.0 value_stay*reward + -0.292 value_stay*harvest_duration + 0.283 reward^2 + 0.4 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.062 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 242/1000 --- L(Train): 0.0063527 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.71 value_stay[t] + 0.4 reward + 0.042 harvest_duration + -0.057 value_stay^2 + -0.0 value_stay*reward + -0.292 value_stay*harvest_duration + 0.282 reward^2 + 0.4 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.062 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 243/1000 --- L(Train): 0.0063482 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.709 value_stay[t] + 0.4 reward + 0.042 harvest_duration + -0.056 value_stay^2 + 0.001 value_stay*reward + -0.292 value_stay*harvest_duration + 0.281 reward^2 + 0.4 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.062 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 244/1000 --- L(Train): 0.0063435 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.709 value_stay[t] + 0.4 reward + 0.042 harvest_duration + -0.056 value_stay^2 + 0.001 value_stay*reward + -0.293 value_stay*harvest_duration + 0.281 reward^2 + 0.4 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.062 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 245/1000 --- L(Train): 0.0063387 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.709 value_stay[t] + 0.4 reward + 0.042 harvest_duration + -0.055 value_stay^2 + 0.001 value_stay*reward + -0.293 value_stay*harvest_duration + 0.28 reward^2 + 0.401 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.063 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 246/1000 --- L(Train): 0.0063340 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.708 value_stay[t] + 0.4 reward + 0.042 harvest_duration + -0.055 value_stay^2 + 0.0 value_stay*reward + -0.293 value_stay*harvest_duration + 0.279 reward^2 + 0.401 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.063 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 247/1000 --- L(Train): 0.0063299 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.708 value_stay[t] + 0.401 reward + 0.042 harvest_duration + -0.054 value_stay^2 + -0.001 value_stay*reward + -0.294 value_stay*harvest_duration + 0.279 reward^2 + 0.401 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.063 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 248/1000 --- L(Train): 0.0063253 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.708 value_stay[t] + 0.401 reward + 0.042 harvest_duration + -0.054 value_stay^2 + -0.001 value_stay*reward + -0.294 value_stay*harvest_duration + 0.278 reward^2 + 0.401 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.063 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 249/1000 --- L(Train): 0.0063206 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.707 value_stay[t] + 0.401 reward + 0.042 harvest_duration + -0.053 value_stay^2 + 0.0 value_stay*reward + -0.295 value_stay*harvest_duration + 0.277 reward^2 + 0.401 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.063 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 250/1000 --- L(Train): 0.0063160 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.707 value_stay[t] + 0.401 reward + 0.042 harvest_duration + -0.052 value_stay^2 + 0.001 value_stay*reward + -0.295 value_stay*harvest_duration + 0.276 reward^2 + 0.401 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.064 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 251/1000 --- L(Train): 0.0063117 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.706 value_stay[t] + 0.401 reward + 0.042 harvest_duration + -0.052 value_stay^2 + 0.001 value_stay*reward + -0.295 value_stay*harvest_duration + 0.276 reward^2 + 0.401 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.064 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 1, 0, 0, 1, 0, 1, 0, 0, 0, 1\n",
      "value_exit: 1, 1, 1, 1, 0, 1\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 252/1000 --- L(Train): 0.0063072 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.706 value_stay[t] + 0.401 reward + 0.042 harvest_duration + -0.051 value_stay^2 + 0.0 value_stay*reward + -0.296 value_stay*harvest_duration + 0.275 reward^2 + 0.402 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.064 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 2, 0, 0, 2, 0, 2, 0, 0, 0, 2\n",
      "value_exit: 2, 2, 2, 2, 0, 2\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 253/1000 --- L(Train): 0.0063029 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.706 value_stay[t] + 0.401 reward + 0.042 harvest_duration + -0.051 value_stay^2 + -0.0 value_stay*reward + -0.296 value_stay*harvest_duration + 0.274 reward^2 + 0.402 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.064 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 3, 0, 0, 3, 0, 3, 0, 0, 0, 3\n",
      "value_exit: 3, 3, 3, 3, 0, 3\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 254/1000 --- L(Train): 0.0062984 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.705 value_stay[t] + 0.402 reward + 0.042 harvest_duration + -0.05 value_stay^2 + -0.0 value_stay*reward + -0.296 value_stay*harvest_duration + 0.273 reward^2 + 0.402 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.065 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 4, 0, 0, 4, 0, 4, 0, 0, 0, 4\n",
      "value_exit: 4, 4, 4, 4, 0, 4\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 255/1000 --- L(Train): 0.0062942 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.705 value_stay[t] + 0.402 reward + 0.042 harvest_duration + -0.049 value_stay^2 + 0.001 value_stay*reward + -0.297 value_stay*harvest_duration + 0.273 reward^2 + 0.402 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.065 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 5, 0, 0, 5, 1, 5, 0, 0, 0, 5\n",
      "value_exit: 5, 5, 5, 5, 0, 5\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 256/1000 --- L(Train): 0.0062898 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.705 value_stay[t] + 0.402 reward + 0.042 harvest_duration + -0.049 value_stay^2 + 0.001 value_stay*reward + -0.297 value_stay*harvest_duration + 0.272 reward^2 + 0.402 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.065 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 6, 0, 0, 6, 2, 6, 0, 0, 0, 6\n",
      "value_exit: 6, 6, 6, 6, 0, 6\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 257/1000 --- L(Train): 0.0062852 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.704 value_stay[t] + 0.402 reward + 0.042 harvest_duration + -0.048 value_stay^2 + 0.001 value_stay*reward + -0.298 value_stay*harvest_duration + 0.271 reward^2 + 0.402 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.065 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 7, 0, 0, 7, 3, 7, 0, 0, 0, 7\n",
      "value_exit: 7, 7, 7, 7, 0, 7\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 258/1000 --- L(Train): 0.0062809 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.704 value_stay[t] + 0.402 reward + 0.043 harvest_duration + -0.048 value_stay^2 + 0.001 value_stay*reward + -0.298 value_stay*harvest_duration + 0.27 reward^2 + 0.402 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.065 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 8, 0, 0, 8, 4, 8, 0, 0, 0, 8\n",
      "value_exit: 8, 8, 8, 8, 0, 8\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 259/1000 --- L(Train): 0.0062765 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.704 value_stay[t] + 0.402 reward + 0.043 harvest_duration + -0.047 value_stay^2 + 0.0 value_stay*reward + -0.298 value_stay*harvest_duration + 0.27 reward^2 + 0.403 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.066 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 9, 0, 0, 9, 5, 9, 0, 0, 0, 9\n",
      "value_exit: 9, 9, 9, 9, 0, 9\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 260/1000 --- L(Train): 0.0062723 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.703 value_stay[t] + 0.402 reward + 0.043 harvest_duration + -0.047 value_stay^2 + -0.001 value_stay*reward + -0.299 value_stay*harvest_duration + 0.269 reward^2 + 0.403 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.066 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 10, 0, 0, 10, 6, 10, 0, 0, 0, 10\n",
      "value_exit: 10, 10, 10, 10, 0, 10\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 261/1000 --- L(Train): 0.0062683 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.703 value_stay[t] + 0.403 reward + 0.043 harvest_duration + -0.046 value_stay^2 + -0.001 value_stay*reward + -0.299 value_stay*harvest_duration + 0.268 reward^2 + 0.403 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.066 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 11, 0, 0, 11, 7, 11, 0, 0, 0, 11\n",
      "value_exit: 11, 11, 11, 11, 0, 11\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 262/1000 --- L(Train): 0.0062642 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.702 value_stay[t] + 0.403 reward + 0.043 harvest_duration + -0.045 value_stay^2 + 0.0 value_stay*reward + -0.299 value_stay*harvest_duration + 0.267 reward^2 + 0.403 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.066 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 12, 0, 0, 12, 8, 12, 0, 0, 0, 12\n",
      "value_exit: 12, 12, 12, 12, 0, 12\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 263/1000 --- L(Train): 0.0062599 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.702 value_stay[t] + 0.403 reward + 0.043 harvest_duration + -0.045 value_stay^2 + 0.0 value_stay*reward + -0.3 value_stay*harvest_duration + 0.267 reward^2 + 0.403 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.001 value_exit^2 + -0.067 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 13, 0, 0, 13, 9, 13, 0, 0, 0, 13\n",
      "value_exit: 13, 13, 13, 13, 0, 13\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 264/1000 --- L(Train): 0.0062558 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.702 value_stay[t] + 0.403 reward + 0.043 harvest_duration + -0.044 value_stay^2 + 0.0 value_stay*reward + -0.3 value_stay*harvest_duration + 0.266 reward^2 + 0.403 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.067 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 14, 0, 0, 14, 10, 14, 0, 0, 0, 14\n",
      "value_exit: 14, 14, 14, 14, 0, 14\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 265/1000 --- L(Train): 0.0062515 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.701 value_stay[t] + 0.403 reward + 0.043 harvest_duration + -0.044 value_stay^2 + -0.0 value_stay*reward + -0.3 value_stay*harvest_duration + 0.265 reward^2 + 0.403 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.067 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 15, 0, 0, 15, 11, 15, 0, 0, 0, 15\n",
      "value_exit: 15, 15, 15, 15, 0, 15\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 266/1000 --- L(Train): 0.0062476 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.701 value_stay[t] + 0.403 reward + 0.043 harvest_duration + -0.043 value_stay^2 + 0.0 value_stay*reward + -0.301 value_stay*harvest_duration + 0.264 reward^2 + 0.404 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.067 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 16, 0, 0, 16, 12, 16, 0, 0, 0, 16\n",
      "value_exit: 16, 16, 16, 16, 0, 16\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 267/1000 --- L(Train): 0.0062437 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.701 value_stay[t] + 0.403 reward + 0.043 harvest_duration + -0.043 value_stay^2 + 0.0 value_stay*reward + -0.301 value_stay*harvest_duration + 0.264 reward^2 + 0.404 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.067 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 17, 0, 0, 17, 13, 17, 0, 0, 0, 17\n",
      "value_exit: 17, 17, 17, 17, 0, 17\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 268/1000 --- L(Train): 0.0062395 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.7 value_stay[t] + 0.404 reward + 0.043 harvest_duration + -0.042 value_stay^2 + 0.0 value_stay*reward + -0.302 value_stay*harvest_duration + 0.263 reward^2 + 0.404 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.068 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 18, 0, 0, 18, 14, 18, 0, 0, 0, 18\n",
      "value_exit: 18, 18, 18, 18, 0, 18\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 269/1000 --- L(Train): 0.0062354 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.7 value_stay[t] + 0.404 reward + 0.044 harvest_duration + -0.041 value_stay^2 + -0.001 value_stay*reward + -0.302 value_stay*harvest_duration + 0.262 reward^2 + 0.404 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.068 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 19, 0, 0, 19, 15, 19, 0, 0, 0, 19\n",
      "value_exit: 19, 19, 19, 19, 0, 19\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 270/1000 --- L(Train): 0.0062318 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.699 value_stay[t] + 0.404 reward + 0.044 harvest_duration + -0.041 value_stay^2 + -0.001 value_stay*reward + -0.302 value_stay*harvest_duration + 0.261 reward^2 + 0.404 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.068 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 20, 0, 0, 20, 16, 20, 0, 0, 0, 20\n",
      "value_exit: 20, 20, 20, 20, 0, 20\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 271/1000 --- L(Train): 0.0062279 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.699 value_stay[t] + 0.404 reward + 0.043 harvest_duration + -0.04 value_stay^2 + 0.001 value_stay*reward + -0.303 value_stay*harvest_duration + 0.261 reward^2 + 0.404 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.068 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 21, 0, 0, 21, 17, 21, 0, 0, 0, 21\n",
      "value_exit: 21, 21, 21, 21, 0, 21\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 272/1000 --- L(Train): 0.0062241 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.699 value_stay[t] + 0.404 reward + 0.044 harvest_duration + -0.04 value_stay^2 + 0.001 value_stay*reward + -0.303 value_stay*harvest_duration + 0.26 reward^2 + 0.404 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.068 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 22, 0, 0, 22, 18, 22, 0, 0, 0, 22\n",
      "value_exit: 22, 22, 22, 22, 0, 22\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 273/1000 --- L(Train): 0.0062204 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.698 value_stay[t] + 0.404 reward + 0.044 harvest_duration + -0.039 value_stay^2 + 0.001 value_stay*reward + -0.303 value_stay*harvest_duration + 0.259 reward^2 + 0.405 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.069 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 23, 0, 0, 23, 19, 23, 0, 0, 0, 23\n",
      "value_exit: 23, 23, 23, 23, 0, 23\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 274/1000 --- L(Train): 0.0062167 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.698 value_stay[t] + 0.404 reward + 0.044 harvest_duration + -0.039 value_stay^2 + 0.001 value_stay*reward + -0.304 value_stay*harvest_duration + 0.258 reward^2 + 0.405 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.069 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 24, 0, 0, 24, 20, 24, 0, 0, 0, 24\n",
      "value_exit: 24, 24, 24, 24, 0, 24\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 275/1000 --- L(Train): 0.0062132 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.698 value_stay[t] + 0.404 reward + 0.044 harvest_duration + -0.038 value_stay^2 + 0.0 value_stay*reward + -0.304 value_stay*harvest_duration + 0.257 reward^2 + 0.405 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.069 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 25, 0, 0, 25, 21, 25, 0, 0, 0, 25\n",
      "value_exit: 25, 25, 25, 25, 0, 25\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 276/1000 --- L(Train): 0.0062099 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.697 value_stay[t] + 0.405 reward + 0.044 harvest_duration + -0.037 value_stay^2 + -0.001 value_stay*reward + -0.305 value_stay*harvest_duration + 0.257 reward^2 + 0.405 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.069 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 26, 0, 0, 26, 22, 26, 0, 0, 0, 26\n",
      "value_exit: 26, 26, 26, 26, 0, 26\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 277/1000 --- L(Train): 0.0062065 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.697 value_stay[t] + 0.405 reward + 0.044 harvest_duration + -0.037 value_stay^2 + -0.001 value_stay*reward + -0.305 value_stay*harvest_duration + 0.256 reward^2 + 0.405 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.069 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 27, 0, 0, 27, 23, 27, 0, 0, 0, 27\n",
      "value_exit: 27, 27, 27, 27, 0, 27\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 278/1000 --- L(Train): 0.0062030 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.697 value_stay[t] + 0.405 reward + 0.044 harvest_duration + -0.036 value_stay^2 + 0.0 value_stay*reward + -0.305 value_stay*harvest_duration + 0.255 reward^2 + 0.405 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.07 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 28, 0, 0, 28, 24, 28, 0, 0, 0, 28\n",
      "value_exit: 28, 28, 28, 28, 0, 28\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 279/1000 --- L(Train): 0.0061994 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.696 value_stay[t] + 0.405 reward + 0.044 harvest_duration + -0.036 value_stay^2 + 0.0 value_stay*reward + -0.306 value_stay*harvest_duration + 0.254 reward^2 + 0.405 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.07 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 29, 0, 0, 29, 25, 29, 0, 0, 0, 29\n",
      "value_exit: 29, 29, 29, 29, 0, 29\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 280/1000 --- L(Train): 0.0061952 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.696 value_stay[t] + 0.405 reward + 0.044 harvest_duration + -0.035 value_stay^2 + 0.0 value_stay*reward + -0.306 value_stay*harvest_duration + 0.254 reward^2 + 0.406 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.07 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 30, 0, 0, 30, 26, 30, 0, 0, 0, 30\n",
      "value_exit: 30, 30, 30, 30, 0, 30\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 281/1000 --- L(Train): 0.0061915 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.695 value_stay[t] + 0.405 reward + 0.044 harvest_duration + -0.035 value_stay^2 + -0.0 value_stay*reward + -0.306 value_stay*harvest_duration + 0.253 reward^2 + 0.406 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.07 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 31, 0, 0, 31, 27, 31, 0, 0, 0, 31\n",
      "value_exit: 31, 31, 31, 31, 0, 31\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 282/1000 --- L(Train): 0.0061883 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.695 value_stay[t] + 0.405 reward + 0.044 harvest_duration + -0.034 value_stay^2 + 0.0 value_stay*reward + -0.307 value_stay*harvest_duration + 0.252 reward^2 + 0.406 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.07 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 32, 0, 0, 32, 28, 32, 0, 0, 0, 32\n",
      "value_exit: 32, 32, 32, 32, 0, 32\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 283/1000 --- L(Train): 0.0061851 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.695 value_stay[t] + 0.406 reward + 0.044 harvest_duration + -0.034 value_stay^2 + 0.0 value_stay*reward + -0.307 value_stay*harvest_duration + 0.251 reward^2 + 0.406 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.071 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 33, 0, 0, 33, 29, 33, 0, 0, 0, 33\n",
      "value_exit: 33, 33, 33, 33, 0, 33\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 284/1000 --- L(Train): 0.0061820 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.694 value_stay[t] + 0.406 reward + 0.044 harvest_duration + -0.033 value_stay^2 + 0.0 value_stay*reward + -0.308 value_stay*harvest_duration + 0.25 reward^2 + 0.406 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.071 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 34, 0, 0, 34, 30, 34, 0, 0, 0, 34\n",
      "value_exit: 34, 34, 34, 34, 0, 34\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 285/1000 --- L(Train): 0.0061785 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.694 value_stay[t] + 0.406 reward + 0.045 harvest_duration + -0.032 value_stay^2 + -0.001 value_stay*reward + -0.308 value_stay*harvest_duration + 0.25 reward^2 + 0.406 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.071 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 35, 0, 0, 35, 31, 35, 0, 0, 0, 35\n",
      "value_exit: 35, 35, 35, 35, 0, 35\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 286/1000 --- L(Train): 0.0061749 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.694 value_stay[t] + 0.406 reward + 0.045 harvest_duration + -0.032 value_stay^2 + -0.0 value_stay*reward + -0.308 value_stay*harvest_duration + 0.249 reward^2 + 0.406 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.071 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 36, 0, 0, 36, 32, 36, 0, 0, 0, 36\n",
      "value_exit: 36, 36, 36, 36, 0, 36\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 287/1000 --- L(Train): 0.0061717 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.693 value_stay[t] + 0.406 reward + 0.045 harvest_duration + -0.031 value_stay^2 + 0.001 value_stay*reward + -0.309 value_stay*harvest_duration + 0.248 reward^2 + 0.407 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.071 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 37, 0, 0, 37, 33, 37, 0, 0, 0, 37\n",
      "value_exit: 37, 37, 37, 37, 0, 37\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 288/1000 --- L(Train): 0.0061686 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.693 value_stay[t] + 0.406 reward + 0.045 harvest_duration + -0.031 value_stay^2 + 0.001 value_stay*reward + -0.309 value_stay*harvest_duration + 0.247 reward^2 + 0.407 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.072 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 38, 0, 0, 38, 34, 38, 0, 0, 0, 38\n",
      "value_exit: 38, 38, 38, 38, 0, 38\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 289/1000 --- L(Train): 0.0061654 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.692 value_stay[t] + 0.407 reward + 0.045 harvest_duration + -0.03 value_stay^2 + 0.001 value_stay*reward + -0.309 value_stay*harvest_duration + 0.246 reward^2 + 0.407 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.072 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 39, 0, 0, 39, 35, 39, 0, 0, 0, 39\n",
      "value_exit: 39, 39, 39, 39, 0, 39\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 290/1000 --- L(Train): 0.0061621 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.692 value_stay[t] + 0.407 reward + 0.045 harvest_duration + -0.03 value_stay^2 + 0.001 value_stay*reward + -0.31 value_stay*harvest_duration + 0.246 reward^2 + 0.407 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.072 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 40, 0, 0, 40, 36, 40, 0, 0, 0, 40\n",
      "value_exit: 40, 40, 40, 40, 0, 40\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 291/1000 --- L(Train): 0.0061587 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.692 value_stay[t] + 0.407 reward + 0.045 harvest_duration + -0.029 value_stay^2 + 0.0 value_stay*reward + -0.31 value_stay*harvest_duration + 0.245 reward^2 + 0.407 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.072 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 41, 0, 0, 41, 37, 41, 0, 0, 0, 41\n",
      "value_exit: 41, 41, 41, 41, 0, 41\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 292/1000 --- L(Train): 0.0061552 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.691 value_stay[t] + 0.407 reward + 0.045 harvest_duration + -0.028 value_stay^2 + -0.001 value_stay*reward + -0.311 value_stay*harvest_duration + 0.244 reward^2 + 0.407 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.072 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 42, 0, 0, 42, 38, 42, 0, 0, 0, 42\n",
      "value_exit: 42, 42, 42, 42, 0, 42\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 293/1000 --- L(Train): 0.0061518 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.691 value_stay[t] + 0.407 reward + 0.045 harvest_duration + -0.028 value_stay^2 + -0.001 value_stay*reward + -0.311 value_stay*harvest_duration + 0.243 reward^2 + 0.407 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.073 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 43, 0, 0, 43, 39, 43, 0, 0, 0, 43\n",
      "value_exit: 43, 43, 43, 43, 0, 43\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 294/1000 --- L(Train): 0.0061481 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.691 value_stay[t] + 0.407 reward + 0.045 harvest_duration + -0.027 value_stay^2 + 0.0 value_stay*reward + -0.311 value_stay*harvest_duration + 0.242 reward^2 + 0.408 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.073 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 44, 0, 0, 44, 40, 44, 0, 0, 0, 44\n",
      "value_exit: 44, 44, 44, 44, 0, 44\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 295/1000 --- L(Train): 0.0061451 --- L(Val, SINDy): 0.0000000 --- Time: 0.09s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.69 value_stay[t] + 0.407 reward + 0.045 harvest_duration + -0.027 value_stay^2 + 0.001 value_stay*reward + -0.312 value_stay*harvest_duration + 0.242 reward^2 + 0.408 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.073 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 45, 0, 0, 45, 41, 45, 0, 0, 0, 45\n",
      "value_exit: 45, 45, 45, 45, 0, 45\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 296/1000 --- L(Train): 0.0061426 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.69 value_stay[t] + 0.408 reward + 0.045 harvest_duration + -0.026 value_stay^2 + 0.001 value_stay*reward + -0.312 value_stay*harvest_duration + 0.241 reward^2 + 0.408 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.073 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 46, 0, 0, 46, 42, 46, 0, 0, 0, 46\n",
      "value_exit: 46, 46, 46, 46, 0, 46\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 297/1000 --- L(Train): 0.0061397 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.689 value_stay[t] + 0.408 reward + 0.045 harvest_duration + -0.026 value_stay^2 + 0.0 value_stay*reward + -0.312 value_stay*harvest_duration + 0.24 reward^2 + 0.408 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.073 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 47, 0, 0, 47, 43, 47, 0, 0, 0, 47\n",
      "value_exit: 47, 47, 47, 47, 0, 47\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 298/1000 --- L(Train): 0.0061365 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.689 value_stay[t] + 0.408 reward + 0.045 harvest_duration + -0.025 value_stay^2 + -0.001 value_stay*reward + -0.313 value_stay*harvest_duration + 0.239 reward^2 + 0.408 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.074 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 48, 0, 0, 48, 44, 48, 0, 0, 0, 48\n",
      "value_exit: 48, 48, 48, 48, 0, 48\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 299/1000 --- L(Train): 0.0061331 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.689 value_stay[t] + 0.408 reward + 0.046 harvest_duration + -0.024 value_stay^2 + -0.0 value_stay*reward + -0.313 value_stay*harvest_duration + 0.239 reward^2 + 0.408 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.074 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 49, 0, 0, 49, 45, 49, 0, 0, 0, 49\n",
      "value_exit: 49, 49, 49, 49, 0, 49\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 300/1000 --- L(Train): 0.0061301 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.688 value_stay[t] + 0.408 reward + 0.046 harvest_duration + -0.024 value_stay^2 + 0.001 value_stay*reward + -0.313 value_stay*harvest_duration + 0.238 reward^2 + 0.408 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.074 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 50, 0, 0, 50, 46, 50, 0, 0, 0, 50\n",
      "value_exit: 50, 50, 50, 50, 0, 50\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 301/1000 --- L(Train): 0.0061274 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.688 value_stay[t] + 0.408 reward + 0.045 harvest_duration + -0.023 value_stay^2 + 0.001 value_stay*reward + -0.314 value_stay*harvest_duration + 0.237 reward^2 + 0.409 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.074 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 51, 0, 0, 51, 47, 51, 0, 0, 0, 51\n",
      "value_exit: 51, 51, 51, 51, 0, 51\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 302/1000 --- L(Train): 0.0061248 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.688 value_stay[t] + 0.408 reward + 0.046 harvest_duration + -0.023 value_stay^2 + 0.001 value_stay*reward + -0.314 value_stay*harvest_duration + 0.236 reward^2 + 0.409 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.074 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 52, 0, 0, 52, 48, 52, 0, 0, 0, 52\n",
      "value_exit: 52, 52, 52, 52, 0, 52\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 303/1000 --- L(Train): 0.0061214 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.687 value_stay[t] + 0.409 reward + 0.046 harvest_duration + -0.022 value_stay^2 + 0.001 value_stay*reward + -0.315 value_stay*harvest_duration + 0.235 reward^2 + 0.409 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.074 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 53, 0, 0, 53, 49, 53, 0, 0, 0, 53\n",
      "value_exit: 53, 53, 53, 53, 0, 53\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 304/1000 --- L(Train): 0.0061183 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.687 value_stay[t] + 0.409 reward + 0.046 harvest_duration + -0.022 value_stay^2 + 0.0 value_stay*reward + -0.315 value_stay*harvest_duration + 0.234 reward^2 + 0.409 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.075 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 54, 0, 0, 54, 50, 54, 0, 0, 0, 54\n",
      "value_exit: 54, 54, 54, 54, 0, 54\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 305/1000 --- L(Train): 0.0061156 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.686 value_stay[t] + 0.409 reward + 0.046 harvest_duration + -0.021 value_stay^2 + -0.001 value_stay*reward + -0.315 value_stay*harvest_duration + 0.234 reward^2 + 0.409 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.075 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 55, 0, 0, 55, 51, 55, 0, 0, 0, 55\n",
      "value_exit: 55, 55, 55, 55, 0, 55\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 306/1000 --- L(Train): 0.0061129 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.686 value_stay[t] + 0.409 reward + 0.046 harvest_duration + -0.02 value_stay^2 + -0.001 value_stay*reward + -0.316 value_stay*harvest_duration + 0.233 reward^2 + 0.409 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.075 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 56, 0, 0, 56, 52, 56, 0, 0, 0, 56\n",
      "value_exit: 56, 56, 56, 56, 0, 56\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 307/1000 --- L(Train): 0.0061098 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.686 value_stay[t] + 0.409 reward + 0.046 harvest_duration + -0.02 value_stay^2 + 0.0 value_stay*reward + -0.316 value_stay*harvest_duration + 0.232 reward^2 + 0.409 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.075 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 57, 0, 0, 57, 53, 57, 0, 0, 0, 57\n",
      "value_exit: 57, 57, 57, 57, 0, 57\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 308/1000 --- L(Train): 0.0061070 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.685 value_stay[t] + 0.409 reward + 0.046 harvest_duration + -0.019 value_stay^2 + 0.001 value_stay*reward + -0.317 value_stay*harvest_duration + 0.231 reward^2 + 0.41 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.075 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 58, 0, 0, 58, 54, 58, 0, 0, 0, 58\n",
      "value_exit: 58, 58, 58, 58, 0, 58\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 309/1000 --- L(Train): 0.0061045 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.685 value_stay[t] + 0.41 reward + 0.046 harvest_duration + -0.019 value_stay^2 + 0.001 value_stay*reward + -0.317 value_stay*harvest_duration + 0.23 reward^2 + 0.41 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.076 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 59, 0, 0, 59, 55, 59, 0, 0, 0, 59\n",
      "value_exit: 59, 59, 59, 59, 0, 59\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 310/1000 --- L(Train): 0.0061018 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.685 value_stay[t] + 0.41 reward + 0.046 harvest_duration + -0.018 value_stay^2 + 0.0 value_stay*reward + -0.317 value_stay*harvest_duration + 0.23 reward^2 + 0.41 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.076 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 60, 0, 0, 60, 56, 60, 0, 0, 0, 60\n",
      "value_exit: 60, 60, 60, 60, 0, 60\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 311/1000 --- L(Train): 0.0060994 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.684 value_stay[t] + 0.41 reward + 0.046 harvest_duration + -0.018 value_stay^2 + -0.001 value_stay*reward + -0.318 value_stay*harvest_duration + 0.229 reward^2 + 0.41 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.076 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 61, 0, 0, 61, 57, 61, 0, 0, 0, 61\n",
      "value_exit: 61, 61, 61, 61, 0, 61\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 312/1000 --- L(Train): 0.0060969 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.684 value_stay[t] + 0.41 reward + 0.047 harvest_duration + -0.017 value_stay^2 + -0.0 value_stay*reward + -0.318 value_stay*harvest_duration + 0.228 reward^2 + 0.41 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.076 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 62, 0, 0, 62, 58, 62, 0, 0, 0, 62\n",
      "value_exit: 62, 62, 62, 62, 0, 62\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 313/1000 --- L(Train): 0.0060944 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.684 value_stay[t] + 0.41 reward + 0.047 harvest_duration + -0.016 value_stay^2 + 0.001 value_stay*reward + -0.318 value_stay*harvest_duration + 0.227 reward^2 + 0.41 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.076 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 63, 0, 0, 63, 59, 63, 0, 0, 0, 63\n",
      "value_exit: 63, 63, 63, 63, 0, 63\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 314/1000 --- L(Train): 0.0060920 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.683 value_stay[t] + 0.41 reward + 0.046 harvest_duration + -0.016 value_stay^2 + 0.001 value_stay*reward + -0.319 value_stay*harvest_duration + 0.226 reward^2 + 0.411 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.076 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 64, 0, 0, 64, 60, 64, 0, 0, 0, 64\n",
      "value_exit: 64, 64, 64, 64, 0, 64\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 315/1000 --- L(Train): 0.0060899 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.683 value_stay[t] + 0.41 reward + 0.047 harvest_duration + -0.015 value_stay^2 + 0.001 value_stay*reward + -0.319 value_stay*harvest_duration + 0.226 reward^2 + 0.411 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.077 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 65, 0, 0, 65, 61, 65, 0, 0, 0, 65\n",
      "value_exit: 65, 65, 65, 65, 0, 65\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 316/1000 --- L(Train): 0.0060870 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.682 value_stay[t] + 0.411 reward + 0.047 harvest_duration + -0.015 value_stay^2 + 0.001 value_stay*reward + -0.319 value_stay*harvest_duration + 0.225 reward^2 + 0.411 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.077 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 66, 0, 0, 66, 62, 66, 0, 0, 0, 66\n",
      "value_exit: 66, 66, 66, 66, 0, 66\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 317/1000 --- L(Train): 0.0060840 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.682 value_stay[t] + 0.411 reward + 0.047 harvest_duration + -0.014 value_stay^2 + 0.0 value_stay*reward + -0.32 value_stay*harvest_duration + 0.224 reward^2 + 0.411 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.077 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 67, 0, 0, 67, 63, 67, 0, 0, 0, 67\n",
      "value_exit: 67, 67, 67, 67, 0, 67\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 318/1000 --- L(Train): 0.0060813 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.682 value_stay[t] + 0.411 reward + 0.047 harvest_duration + -0.014 value_stay^2 + -0.001 value_stay*reward + -0.32 value_stay*harvest_duration + 0.223 reward^2 + 0.411 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.077 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 68, 0, 0, 68, 64, 68, 0, 0, 0, 68\n",
      "value_exit: 68, 68, 68, 68, 0, 68\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 319/1000 --- L(Train): 0.0060791 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.681 value_stay[t] + 0.411 reward + 0.047 harvest_duration + -0.013 value_stay^2 + -0.001 value_stay*reward + -0.32 value_stay*harvest_duration + 0.222 reward^2 + 0.411 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.077 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 69, 0, 0, 69, 65, 69, 0, 0, 0, 69\n",
      "value_exit: 69, 69, 69, 69, 0, 69\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 320/1000 --- L(Train): 0.0060773 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.681 value_stay[t] + 0.411 reward + 0.047 harvest_duration + -0.012 value_stay^2 + 0.0 value_stay*reward + -0.321 value_stay*harvest_duration + 0.221 reward^2 + 0.412 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.077 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 70, 0, 0, 70, 66, 70, 0, 0, 0, 70\n",
      "value_exit: 70, 70, 70, 70, 0, 70\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 321/1000 --- L(Train): 0.0060753 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.681 value_stay[t] + 0.411 reward + 0.047 harvest_duration + -0.012 value_stay^2 + 0.001 value_stay*reward + -0.321 value_stay*harvest_duration + 0.221 reward^2 + 0.412 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.078 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 71, 0, 0, 71, 67, 71, 0, 0, 0, 71\n",
      "value_exit: 71, 71, 71, 71, 0, 71\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 322/1000 --- L(Train): 0.0060729 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.68 value_stay[t] + 0.412 reward + 0.047 harvest_duration + -0.011 value_stay^2 + 0.001 value_stay*reward + -0.322 value_stay*harvest_duration + 0.22 reward^2 + 0.412 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.078 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 72, 0, 0, 72, 68, 72, 0, 0, 0, 72\n",
      "value_exit: 72, 72, 72, 72, 0, 72\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 323/1000 --- L(Train): 0.0060701 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.68 value_stay[t] + 0.412 reward + 0.047 harvest_duration + -0.011 value_stay^2 + 0.0 value_stay*reward + -0.322 value_stay*harvest_duration + 0.219 reward^2 + 0.412 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.078 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 73, 0, 0, 73, 69, 73, 0, 0, 0, 73\n",
      "value_exit: 73, 73, 73, 73, 0, 73\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 324/1000 --- L(Train): 0.0060674 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.679 value_stay[t] + 0.412 reward + 0.047 harvest_duration + -0.01 value_stay^2 + -0.001 value_stay*reward + -0.322 value_stay*harvest_duration + 0.218 reward^2 + 0.412 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.078 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 74, 0, 0, 74, 70, 74, 0, 0, 0, 74\n",
      "value_exit: 74, 74, 74, 74, 0, 74\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 325/1000 --- L(Train): 0.0060650 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.679 value_stay[t] + 0.412 reward + 0.048 harvest_duration + -0.01 value_stay^2 + -0.0 value_stay*reward + -0.323 value_stay*harvest_duration + 0.217 reward^2 + 0.412 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.078 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 75, 0, 0, 75, 71, 75, 0, 0, 0, 75\n",
      "value_exit: 75, 75, 75, 75, 0, 75\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 326/1000 --- L(Train): 0.0060629 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.679 value_stay[t] + 0.412 reward + 0.048 harvest_duration + -0.009 value_stay^2 + 0.001 value_stay*reward + -0.323 value_stay*harvest_duration + 0.216 reward^2 + 0.412 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.078 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 76, 0, 0, 76, 72, 76, 0, 0, 0, 76\n",
      "value_exit: 76, 76, 76, 76, 0, 76\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 327/1000 --- L(Train): 0.0060612 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.678 value_stay[t] + 0.412 reward + 0.047 harvest_duration + -0.009 value_stay^2 + 0.001 value_stay*reward + -0.324 value_stay*harvest_duration + 0.216 reward^2 + 0.413 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.079 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 77, 0, 0, 77, 73, 77, 0, 0, 0, 77\n",
      "value_exit: 77, 77, 77, 77, 0, 77\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 328/1000 --- L(Train): 0.0060593 --- L(Val, SINDy): 0.0000000 --- Time: 0.09s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.678 value_stay[t] + 0.412 reward + 0.048 harvest_duration + -0.008 value_stay^2 + 0.002 value_stay*reward + -0.324 value_stay*harvest_duration + 0.215 reward^2 + 0.413 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.079 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 78, 0, 0, 78, 74, 78, 0, 0, 0, 78\n",
      "value_exit: 78, 78, 78, 78, 0, 78\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 329/1000 --- L(Train): 0.0060574 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.678 value_stay[t] + 0.413 reward + 0.048 harvest_duration + -0.007 value_stay^2 + 0.001 value_stay*reward + -0.324 value_stay*harvest_duration + 0.214 reward^2 + 0.413 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.079 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 79, 0, 0, 79, 75, 79, 0, 0, 0, 79\n",
      "value_exit: 79, 79, 79, 79, 0, 79\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 330/1000 --- L(Train): 0.0060554 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.677 value_stay[t] + 0.413 reward + 0.047 harvest_duration + -0.007 value_stay^2 + 0.0 value_stay*reward + -0.325 value_stay*harvest_duration + 0.213 reward^2 + 0.413 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.079 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 80, 0, 0, 80, 76, 80, 0, 0, 0, 80\n",
      "value_exit: 80, 80, 80, 80, 0, 80\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 331/1000 --- L(Train): 0.0060533 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.677 value_stay[t] + 0.413 reward + 0.048 harvest_duration + -0.006 value_stay^2 + -0.001 value_stay*reward + -0.325 value_stay*harvest_duration + 0.212 reward^2 + 0.413 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.079 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 81, 0, 0, 81, 77, 81, 0, 0, 0, 81\n",
      "value_exit: 81, 81, 81, 81, 0, 81\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 332/1000 --- L(Train): 0.0060503 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.677 value_stay[t] + 0.413 reward + 0.048 harvest_duration + -0.006 value_stay^2 + -0.0 value_stay*reward + -0.325 value_stay*harvest_duration + 0.211 reward^2 + 0.413 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.079 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 82, 0, 0, 82, 78, 82, 0, 0, 0, 82\n",
      "value_exit: 82, 82, 82, 82, 0, 82\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 333/1000 --- L(Train): 0.0060475 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.676 value_stay[t] + 0.413 reward + 0.048 harvest_duration + -0.005 value_stay^2 + 0.0 value_stay*reward + -0.326 value_stay*harvest_duration + 0.211 reward^2 + 0.414 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.08 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 83, 0, 0, 83, 79, 83, 0, 0, 0, 83\n",
      "value_exit: 83, 83, 83, 83, 0, 83\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 334/1000 --- L(Train): 0.0060458 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.676 value_stay[t] + 0.413 reward + 0.048 harvest_duration + -0.005 value_stay^2 + 0.001 value_stay*reward + -0.326 value_stay*harvest_duration + 0.21 reward^2 + 0.414 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.08 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 84, 0, 0, 84, 80, 84, 0, 0, 0, 84\n",
      "value_exit: 84, 84, 84, 84, 0, 84\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 335/1000 --- L(Train): 0.0060443 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.675 value_stay[t] + 0.414 reward + 0.048 harvest_duration + -0.004 value_stay^2 + 0.001 value_stay*reward + -0.326 value_stay*harvest_duration + 0.209 reward^2 + 0.414 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.08 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 85, 0, 0, 85, 81, 85, 0, 0, 0, 85\n",
      "value_exit: 85, 85, 85, 85, 0, 85\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 336/1000 --- L(Train): 0.0060426 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.675 value_stay[t] + 0.414 reward + 0.048 harvest_duration + -0.003 value_stay^2 + 0.0 value_stay*reward + -0.327 value_stay*harvest_duration + 0.208 reward^2 + 0.414 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.08 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 86, 0, 0, 86, 82, 86, 0, 0, 0, 86\n",
      "value_exit: 86, 86, 86, 86, 0, 86\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 337/1000 --- L(Train): 0.0060406 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.675 value_stay[t] + 0.414 reward + 0.048 harvest_duration + -0.003 value_stay^2 + -0.0 value_stay*reward + -0.327 value_stay*harvest_duration + 0.207 reward^2 + 0.414 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.08 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 87, 0, 0, 87, 83, 87, 0, 0, 0, 87\n",
      "value_exit: 87, 87, 87, 87, 0, 87\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 338/1000 --- L(Train): 0.0060383 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.674 value_stay[t] + 0.414 reward + 0.049 harvest_duration + -0.002 value_stay^2 + -0.0 value_stay*reward + -0.328 value_stay*harvest_duration + 0.206 reward^2 + 0.414 reward*harvest_duration + 0.049 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.08 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 88, 0, 0, 88, 84, 88, 0, 0, 0, 88\n",
      "value_exit: 88, 88, 88, 88, 0, 88\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 339/1000 --- L(Train): 0.0060362 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.674 value_stay[t] + 0.414 reward + 0.048 harvest_duration + -0.002 value_stay^2 + 0.001 value_stay*reward + -0.328 value_stay*harvest_duration + 0.206 reward^2 + 0.415 reward*harvest_duration + 0.049 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.992 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.081 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 89, 0, 0, 89, 85, 89, 0, 0, 0, 89\n",
      "value_exit: 89, 89, 89, 89, 0, 89\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 340/1000 --- L(Train): 0.0060346 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.673 value_stay[t] + 0.414 reward + 0.048 harvest_duration + -0.001 value_stay^2 + 0.002 value_stay*reward + -0.328 value_stay*harvest_duration + 0.205 reward^2 + 0.415 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.992 value_exit[t] + -0.001 travel_duration + -0.001 value_exit^2 + -0.081 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 90, 0, 0, 90, 86, 90, 0, 0, 0, 90\n",
      "value_exit: 90, 90, 90, 90, 0, 90\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 341/1000 --- L(Train): 0.0060329 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.673 value_stay[t] + 0.415 reward + 0.049 harvest_duration + -0.001 value_stay^2 + 0.002 value_stay*reward + -0.329 value_stay*harvest_duration + 0.204 reward^2 + 0.415 reward*harvest_duration + 0.049 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.992 value_exit[t] + -0.001 travel_duration + -0.001 value_exit^2 + -0.081 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 91, 0, 0, 91, 87, 91, 0, 0, 0, 91\n",
      "value_exit: 91, 91, 91, 91, 0, 91\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 342/1000 --- L(Train): 0.0060309 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.673 value_stay[t] + 0.415 reward + 0.049 harvest_duration + 0.0 value_stay^2 + 0.002 value_stay*reward + -0.329 value_stay*harvest_duration + 0.203 reward^2 + 0.415 reward*harvest_duration + 0.049 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.992 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.081 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 92, 0, 0, 92, 88, 92, 0, 0, 0, 92\n",
      "value_exit: 92, 92, 92, 92, 0, 92\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 343/1000 --- L(Train): 0.0060287 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.672 value_stay[t] + 0.415 reward + 0.048 harvest_duration + 0.0 value_stay^2 + 0.001 value_stay*reward + -0.33 value_stay*harvest_duration + 0.202 reward^2 + 0.415 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.081 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 93, 0, 0, 93, 89, 93, 0, 0, 0, 93\n",
      "value_exit: 93, 93, 93, 93, 0, 93\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 344/1000 --- L(Train): 0.0060271 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.672 value_stay[t] + 0.415 reward + 0.049 harvest_duration + 0.0 value_stay^2 + -0.0 value_stay*reward + -0.33 value_stay*harvest_duration + 0.201 reward^2 + 0.415 reward*harvest_duration + 0.049 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.081 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 94, 0, 0, 94, 90, 94, 0, 0, 0, 94\n",
      "value_exit: 94, 94, 94, 94, 0, 94\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 345/1000 --- L(Train): 0.0060251 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.672 value_stay[t] + 0.415 reward + 0.049 harvest_duration + -0.0 value_stay^2 + -0.0 value_stay*reward + -0.33 value_stay*harvest_duration + 0.2 reward^2 + 0.416 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.993 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.081 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 95, 0, 0, 95, 91, 95, 0, 0, 0, 95\n",
      "value_exit: 95, 95, 95, 95, 0, 95\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 346/1000 --- L(Train): 0.0060231 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.671 value_stay[t] + 0.415 reward + 0.049 harvest_duration + -0.0 value_stay^2 + 0.001 value_stay*reward + -0.331 value_stay*harvest_duration + 0.2 reward^2 + 0.416 reward*harvest_duration + 0.049 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.993 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.082 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 96, 0, 0, 96, 92, 96, 0, 0, 0, 96\n",
      "value_exit: 96, 96, 96, 96, 0, 96\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 347/1000 --- L(Train): 0.0060214 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.671 value_stay[t] + 0.416 reward + 0.049 harvest_duration + -0.001 value_stay^2 + 0.002 value_stay*reward + -0.331 value_stay*harvest_duration + 0.199 reward^2 + 0.416 reward*harvest_duration + 0.049 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.993 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.082 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 97, 0, 0, 97, 93, 97, 0, 0, 0, 97\n",
      "value_exit: 97, 97, 97, 97, 0, 97\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 348/1000 --- L(Train): 0.0060200 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.05 1 + 0.671 value_stay[t] + 0.416 reward + 0.05 harvest_duration + -0.0 value_stay^2 + 0.002 value_stay*reward + -0.331 value_stay*harvest_duration + 0.198 reward^2 + 0.416 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.993 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.082 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 98, 0, 0, 98, 94, 98, 0, 0, 0, 98\n",
      "value_exit: 98, 98, 98, 98, 0, 98\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 349/1000 --- L(Train): 0.0060184 --- L(Val, SINDy): 0.0000000 --- Time: 0.09s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.671 value_stay[t] + 0.416 reward + 0.049 harvest_duration + -0.0 value_stay^2 + 0.002 value_stay*reward + -0.331 value_stay*harvest_duration + 0.197 reward^2 + 0.416 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.993 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.082 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 99, 0, 0, 99, 95, 99, 0, 0, 0, 99\n",
      "value_exit: 99, 99, 99, 99, 0, 99\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 350/1000 --- L(Train): 0.0060170 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 15):\n",
      "value_stay[t+1] = 0.049 1 + 0.67 value_stay[t] + 0.416 reward + 0.049 harvest_duration + -0.0 value_stay^2 + 0.001 value_stay*reward + -0.331 value_stay*harvest_duration + 0.196 reward^2 + 0.416 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = 0.994 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.082 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 100, 0, 0, 100, 96, 100, 0, 0, 0, 100\n",
      "value_exit: -, 100, 100, 100, 0, 100\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 351/1000 --- L(Train): 0.0060162 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 14):\n",
      "value_stay[t+1] = 0.05 1 + 0.67 value_stay[t] + 0.416 reward + 0.05 harvest_duration + 0.0 value_stay^2 + 0.001 value_stay*reward + -0.332 value_stay*harvest_duration + 0.195 reward^2 + 0.417 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = 0.994 value_exit[t] + -0.001 travel_duration + -0.082 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 101, 0, 0, 101, 97, 101, 0, 0, 0, 0\n",
      "value_exit: -, 101, 101, -, 0, 101\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 352/1000 --- L(Train): 0.0060145 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 13):\n",
      "value_stay[t+1] = 0.05 1 + 0.67 value_stay[t] + 0.416 reward + 0.05 harvest_duration + 0.0 value_stay^2 + -0.332 value_stay*harvest_duration + 0.195 reward^2 + 0.417 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = 0.994 value_exit[t] + -0.001 travel_duration + -0.083 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 102, 0, 0, 102, 98, -, 0, 0, 0, 1\n",
      "value_exit: -, 102, 102, -, 0, 102\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 353/1000 --- L(Train): 0.0060143 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_stay[t+1] = 0.05 1 + 0.67 value_stay[t] + 0.417 reward + 0.05 harvest_duration + 0.0 value_stay^2 + -0.332 value_stay*harvest_duration + 0.194 reward^2 + 0.417 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = 0.994 value_exit[t] + -0.083 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 103, 0, 0, 103, 99, -, 0, 0, 0, 2\n",
      "value_exit: -, 103, -, -, 0, 103\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 354/1000 --- L(Train): 0.0063723 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 11):\n",
      "value_stay[t+1] = 0.05 1 + 0.67 value_stay[t] + 0.417 reward + 0.05 harvest_duration + -0.332 value_stay*harvest_duration + 0.193 reward^2 + 0.417 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = 0.994 value_exit[t] + -0.083 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 104, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, 104, -, -, 0, 104\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 355/1000 --- L(Train): 0.0171811 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.05 1 + 0.67 value_stay[t] + 0.417 reward + 0.05 harvest_duration + -0.332 value_stay*harvest_duration + 0.192 reward^2 + 0.417 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.083 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 105, 0, 0, 1, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 0, 105\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 356/1000 --- L(Train): 0.0415292 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.05 1 + 0.67 value_stay[t] + 0.417 reward + 0.05 harvest_duration + -0.332 value_stay*harvest_duration + 0.191 reward^2 + 0.418 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.083 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 106, 0, 0, 2, -, -, 0, 0, 0, 1\n",
      "value_exit: -, -, -, -, 0, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 357/1000 --- L(Train): 0.0638916 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.418 reward + 0.05 harvest_duration + -0.332 value_stay*harvest_duration + 0.19 reward^2 + 0.418 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.079 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 3, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 0, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 358/1000 --- L(Train): 0.0622400 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.673 value_stay[t] + 0.42 reward + 0.062 harvest_duration + -0.328 value_stay*harvest_duration + 0.191 reward^2 + 0.42 reward*harvest_duration + 0.062 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.071 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 0, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 359/1000 --- L(Train): 0.0535363 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.674 value_stay[t] + 0.42 reward + 0.064 harvest_duration + -0.328 value_stay*harvest_duration + 0.19 reward^2 + 0.42 reward*harvest_duration + 0.064 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.06 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 0, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 360/1000 --- L(Train): 0.0413205 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.419 reward + 0.056 harvest_duration + -0.331 value_stay*harvest_duration + 0.188 reward^2 + 0.419 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.048 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 1, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 361/1000 --- L(Train): 0.0284234 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.418 reward + 0.051 harvest_duration + -0.333 value_stay*harvest_duration + 0.187 reward^2 + 0.418 reward*harvest_duration + 0.051 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.034 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 2, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 362/1000 --- L(Train): 0.0190179 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.419 reward + 0.054 harvest_duration + -0.331 value_stay*harvest_duration + 0.187 reward^2 + 0.419 reward*harvest_duration + 0.054 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.02 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 3, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 363/1000 --- L(Train): 0.0134318 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.673 value_stay[t] + 0.421 reward + 0.061 harvest_duration + -0.329 value_stay*harvest_duration + 0.187 reward^2 + 0.421 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.007 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 4, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 364/1000 --- L(Train): 0.0114087 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.674 value_stay[t] + 0.421 reward + 0.062 harvest_duration + -0.328 value_stay*harvest_duration + 0.186 reward^2 + 0.421 reward*harvest_duration + 0.062 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.006 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 5, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 365/1000 --- L(Train): 0.0125463 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.672 value_stay[t] + 0.42 reward + 0.057 harvest_duration + -0.33 value_stay*harvest_duration + 0.185 reward^2 + 0.42 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.017 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 6, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 366/1000 --- L(Train): 0.0156896 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.419 reward + 0.053 harvest_duration + -0.332 value_stay*harvest_duration + 0.183 reward^2 + 0.42 reward*harvest_duration + 0.053 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.026 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 7, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 367/1000 --- L(Train): 0.0195231 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.42 reward + 0.054 harvest_duration + -0.332 value_stay*harvest_duration + 0.182 reward^2 + 0.42 reward*harvest_duration + 0.054 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.033 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 8, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 368/1000 --- L(Train): 0.0227669 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.672 value_stay[t] + 0.421 reward + 0.058 harvest_duration + -0.33 value_stay*harvest_duration + 0.182 reward^2 + 0.421 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.037 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 9, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 369/1000 --- L(Train): 0.0246113 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.673 value_stay[t] + 0.422 reward + 0.061 harvest_duration + -0.329 value_stay*harvest_duration + 0.182 reward^2 + 0.422 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.039 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 10, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 370/1000 --- L(Train): 0.0247713 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.672 value_stay[t] + 0.422 reward + 0.059 harvest_duration + -0.33 value_stay*harvest_duration + 0.181 reward^2 + 0.422 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.039 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 11, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 371/1000 --- L(Train): 0.0233353 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.421 reward + 0.055 harvest_duration + -0.332 value_stay*harvest_duration + 0.179 reward^2 + 0.421 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.037 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 12, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 372/1000 --- L(Train): 0.0207042 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.421 reward + 0.054 harvest_duration + -0.332 value_stay*harvest_duration + 0.178 reward^2 + 0.421 reward*harvest_duration + 0.054 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.034 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 13, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 373/1000 --- L(Train): 0.0174912 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.421 reward + 0.056 harvest_duration + -0.331 value_stay*harvest_duration + 0.178 reward^2 + 0.422 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.029 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 14, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 374/1000 --- L(Train): 0.0143616 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.672 value_stay[t] + 0.423 reward + 0.059 harvest_duration + -0.33 value_stay*harvest_duration + 0.178 reward^2 + 0.423 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.023 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 15, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 375/1000 --- L(Train): 0.0116628 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.672 value_stay[t] + 0.423 reward + 0.06 harvest_duration + -0.33 value_stay*harvest_duration + 0.177 reward^2 + 0.423 reward*harvest_duration + 0.06 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.016 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 16, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 376/1000 --- L(Train): 0.0097927 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.423 reward + 0.058 harvest_duration + -0.331 value_stay*harvest_duration + 0.176 reward^2 + 0.423 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.01 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 17, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 377/1000 --- L(Train): 0.0088213 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.422 reward + 0.055 harvest_duration + -0.332 value_stay*harvest_duration + 0.174 reward^2 + 0.422 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 18, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 378/1000 --- L(Train): 0.0086743 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.422 reward + 0.055 harvest_duration + -0.332 value_stay*harvest_duration + 0.174 reward^2 + 0.423 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 19, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 379/1000 --- L(Train): 0.0091661 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.423 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.173 reward^2 + 0.423 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.008 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 20, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 380/1000 --- L(Train): 0.0099707 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.672 value_stay[t] + 0.424 reward + 0.059 harvest_duration + -0.33 value_stay*harvest_duration + 0.173 reward^2 + 0.424 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.012 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 21, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 381/1000 --- L(Train): 0.0108111 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.672 value_stay[t] + 0.424 reward + 0.059 harvest_duration + -0.33 value_stay*harvest_duration + 0.172 reward^2 + 0.424 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.015 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 22, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 382/1000 --- L(Train): 0.0114317 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.424 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.171 reward^2 + 0.424 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.018 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 23, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 383/1000 --- L(Train): 0.0117198 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.423 reward + 0.055 harvest_duration + -0.332 value_stay*harvest_duration + 0.17 reward^2 + 0.424 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.019 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 24, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 384/1000 --- L(Train): 0.0115927 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.424 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.169 reward^2 + 0.424 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.019 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 25, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 385/1000 --- L(Train): 0.0111641 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.425 reward + 0.058 harvest_duration + -0.331 value_stay*harvest_duration + 0.169 reward^2 + 0.425 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.018 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 26, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 386/1000 --- L(Train): 0.0104887 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.672 value_stay[t] + 0.425 reward + 0.059 harvest_duration + -0.33 value_stay*harvest_duration + 0.168 reward^2 + 0.425 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.016 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 27, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 387/1000 --- L(Train): 0.0097370 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.425 reward + 0.058 harvest_duration + -0.331 value_stay*harvest_duration + 0.167 reward^2 + 0.426 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.014 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 28, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 388/1000 --- L(Train): 0.0090256 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.425 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.166 reward^2 + 0.425 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.011 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 29, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 389/1000 --- L(Train): 0.0084572 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.425 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.165 reward^2 + 0.425 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.008 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 30, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 390/1000 --- L(Train): 0.0080986 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.425 reward + 0.056 harvest_duration + -0.331 value_stay*harvest_duration + 0.165 reward^2 + 0.426 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.005 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 31, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 391/1000 --- L(Train): 0.0079419 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.426 reward + 0.058 harvest_duration + -0.331 value_stay*harvest_duration + 0.164 reward^2 + 0.426 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 32, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 392/1000 --- L(Train): 0.0079673 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.426 reward + 0.058 harvest_duration + -0.331 value_stay*harvest_duration + 0.163 reward^2 + 0.427 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 33, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 393/1000 --- L(Train): 0.0081084 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.426 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.162 reward^2 + 0.427 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 34, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 394/1000 --- L(Train): 0.0083080 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.426 reward + 0.056 harvest_duration + -0.331 value_stay*harvest_duration + 0.161 reward^2 + 0.427 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.006 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 35, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 395/1000 --- L(Train): 0.0084794 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.427 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.161 reward^2 + 0.427 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.007 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 36, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 396/1000 --- L(Train): 0.0085767 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.427 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.16 reward^2 + 0.427 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.008 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 37, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 397/1000 --- L(Train): 0.0086012 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.427 reward + 0.058 harvest_duration + -0.331 value_stay*harvest_duration + 0.159 reward^2 + 0.428 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.009 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 38, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 398/1000 --- L(Train): 0.0085266 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.428 reward + 0.058 harvest_duration + -0.331 value_stay*harvest_duration + 0.159 reward^2 + 0.428 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.009 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 39, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 399/1000 --- L(Train): 0.0083880 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.428 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.158 reward^2 + 0.428 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.008 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 40, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 400/1000 --- L(Train): 0.0082139 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.428 reward + 0.056 harvest_duration + -0.331 value_stay*harvest_duration + 0.157 reward^2 + 0.428 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.008 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 41, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 401/1000 --- L(Train): 0.0080382 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.428 reward + 0.056 harvest_duration + -0.331 value_stay*harvest_duration + 0.156 reward^2 + 0.428 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.006 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 42, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 402/1000 --- L(Train): 0.0078863 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.428 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.156 reward^2 + 0.429 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.005 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 43, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 403/1000 --- L(Train): 0.0077706 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.429 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.155 reward^2 + 0.429 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 44, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 404/1000 --- L(Train): 0.0077111 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.429 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.154 reward^2 + 0.429 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 45, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 405/1000 --- L(Train): 0.0076962 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.429 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.153 reward^2 + 0.429 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 46, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 406/1000 --- L(Train): 0.0077245 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.429 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.152 reward^2 + 0.43 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 47, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 407/1000 --- L(Train): 0.0077634 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.43 reward + 0.056 harvest_duration + -0.331 value_stay*harvest_duration + 0.152 reward^2 + 0.43 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 48, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 408/1000 --- L(Train): 0.0078075 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.43 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.151 reward^2 + 0.43 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 49, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 409/1000 --- L(Train): 0.0078412 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.43 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.15 reward^2 + 0.431 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 50, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 410/1000 --- L(Train): 0.0078392 --- L(Val, SINDy): 0.0000000 --- Time: 0.09s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.43 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.149 reward^2 + 0.431 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 51, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 411/1000 --- L(Train): 0.0078330 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.431 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.149 reward^2 + 0.431 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 52, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 412/1000 --- L(Train): 0.0078023 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.431 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.148 reward^2 + 0.431 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 53, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 413/1000 --- L(Train): 0.0077585 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.431 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.147 reward^2 + 0.431 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 54, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 414/1000 --- L(Train): 0.0077174 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.431 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.146 reward^2 + 0.432 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 55, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 415/1000 --- L(Train): 0.0076680 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.432 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.146 reward^2 + 0.432 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 56, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 416/1000 --- L(Train): 0.0076519 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.432 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.145 reward^2 + 0.432 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 57, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 417/1000 --- L(Train): 0.0076305 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.432 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.144 reward^2 + 0.432 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 58, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 418/1000 --- L(Train): 0.0076204 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.432 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.143 reward^2 + 0.432 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 59, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 419/1000 --- L(Train): 0.0076278 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.432 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.143 reward^2 + 0.433 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 60, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 420/1000 --- L(Train): 0.0076287 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.433 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.142 reward^2 + 0.433 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 61, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 421/1000 --- L(Train): 0.0076387 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.433 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.141 reward^2 + 0.433 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 62, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 422/1000 --- L(Train): 0.0076439 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.433 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.14 reward^2 + 0.433 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 63, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 423/1000 --- L(Train): 0.0076415 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.433 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.139 reward^2 + 0.434 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 64, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 424/1000 --- L(Train): 0.0076497 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.434 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.139 reward^2 + 0.434 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 65, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 425/1000 --- L(Train): 0.0076399 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.434 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.138 reward^2 + 0.434 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 66, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 426/1000 --- L(Train): 0.0076214 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.434 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.137 reward^2 + 0.434 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 67, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 427/1000 --- L(Train): 0.0076113 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.434 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.136 reward^2 + 0.435 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 68, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 428/1000 --- L(Train): 0.0075970 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.434 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.136 reward^2 + 0.435 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 69, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 429/1000 --- L(Train): 0.0075857 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.435 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.135 reward^2 + 0.435 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 70, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 430/1000 --- L(Train): 0.0075990 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.435 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.134 reward^2 + 0.435 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 71, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 431/1000 --- L(Train): 0.0075902 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.435 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.133 reward^2 + 0.435 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 72, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 432/1000 --- L(Train): 0.0076027 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.435 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.133 reward^2 + 0.436 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 73, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 433/1000 --- L(Train): 0.0076170 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.436 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.132 reward^2 + 0.436 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 74, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 434/1000 --- L(Train): 0.0076208 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.436 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.131 reward^2 + 0.436 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 75, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 435/1000 --- L(Train): 0.0076091 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.436 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.13 reward^2 + 0.436 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 76, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 436/1000 --- L(Train): 0.0075985 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.436 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.13 reward^2 + 0.437 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 77, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 437/1000 --- L(Train): 0.0076064 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.437 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.129 reward^2 + 0.437 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 78, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 438/1000 --- L(Train): 0.0075865 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.437 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.128 reward^2 + 0.437 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 79, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 439/1000 --- L(Train): 0.0075840 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.437 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.127 reward^2 + 0.437 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 80, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 440/1000 --- L(Train): 0.0075829 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.437 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.127 reward^2 + 0.437 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 81, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 441/1000 --- L(Train): 0.0075801 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.437 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.126 reward^2 + 0.438 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 82, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 442/1000 --- L(Train): 0.0075799 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.438 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.125 reward^2 + 0.438 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 83, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 443/1000 --- L(Train): 0.0075768 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.438 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.124 reward^2 + 0.438 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 84, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 444/1000 --- L(Train): 0.0075894 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.438 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.124 reward^2 + 0.438 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 85, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 445/1000 --- L(Train): 0.0075787 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.438 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.123 reward^2 + 0.439 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 86, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 446/1000 --- L(Train): 0.0075897 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.438 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.122 reward^2 + 0.439 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 87, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 447/1000 --- L(Train): 0.0075664 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.439 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.121 reward^2 + 0.439 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 88, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 448/1000 --- L(Train): 0.0075742 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.439 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.121 reward^2 + 0.439 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 89, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 449/1000 --- L(Train): 0.0075742 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.439 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.12 reward^2 + 0.44 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 90, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 450/1000 --- L(Train): 0.0075570 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.439 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.119 reward^2 + 0.44 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 91, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 451/1000 --- L(Train): 0.0075621 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.44 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.118 reward^2 + 0.44 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 92, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 452/1000 --- L(Train): 0.0075764 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.44 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.118 reward^2 + 0.44 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 93, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 453/1000 --- L(Train): 0.0075608 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.44 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.117 reward^2 + 0.44 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 94, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 454/1000 --- L(Train): 0.0075641 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.44 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.116 reward^2 + 0.441 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 95, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 455/1000 --- L(Train): 0.0075598 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.441 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.115 reward^2 + 0.441 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 96, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 456/1000 --- L(Train): 0.0075713 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.441 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.115 reward^2 + 0.441 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 97, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 457/1000 --- L(Train): 0.0075682 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.441 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.114 reward^2 + 0.441 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 98, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 458/1000 --- L(Train): 0.0075665 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.441 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.113 reward^2 + 0.442 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 99, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 459/1000 --- L(Train): 0.0075568 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.441 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.112 reward^2 + 0.442 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 460/1000 --- L(Train): 0.0075530 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.442 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.112 reward^2 + 0.442 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 461/1000 --- L(Train): 0.0075524 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.442 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.111 reward^2 + 0.442 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 462/1000 --- L(Train): 0.0075515 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.442 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.11 reward^2 + 0.442 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 463/1000 --- L(Train): 0.0075651 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.442 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.109 reward^2 + 0.443 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 464/1000 --- L(Train): 0.0075614 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.443 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.109 reward^2 + 0.443 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 465/1000 --- L(Train): 0.0075630 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.443 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.108 reward^2 + 0.443 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 466/1000 --- L(Train): 0.0077042 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.443 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.107 reward^2 + 0.443 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 467/1000 --- L(Train): 0.0076024 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.443 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.106 reward^2 + 0.444 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 468/1000 --- L(Train): 0.0075518 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.443 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.106 reward^2 + 0.444 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 469/1000 --- L(Train): 0.0076344 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.444 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.105 reward^2 + 0.444 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 470/1000 --- L(Train): 0.0076420 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.444 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.104 reward^2 + 0.444 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 471/1000 --- L(Train): 0.0076508 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.444 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.104 reward^2 + 0.444 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 472/1000 --- L(Train): 0.0075902 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.444 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.103 reward^2 + 0.445 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 473/1000 --- L(Train): 0.0075512 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.445 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.102 reward^2 + 0.445 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 474/1000 --- L(Train): 0.0075909 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.445 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.101 reward^2 + 0.445 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 475/1000 --- L(Train): 0.0076384 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.445 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.101 reward^2 + 0.445 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 476/1000 --- L(Train): 0.0076803 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.445 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.1 reward^2 + 0.445 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 477/1000 --- L(Train): 0.0076141 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.445 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.099 reward^2 + 0.446 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 478/1000 --- L(Train): 0.0076397 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.446 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.098 reward^2 + 0.446 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 479/1000 --- L(Train): 0.0075851 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.446 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.098 reward^2 + 0.446 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 480/1000 --- L(Train): 0.0076137 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.446 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.097 reward^2 + 0.446 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 481/1000 --- L(Train): 0.0076335 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.446 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.096 reward^2 + 0.447 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 482/1000 --- L(Train): 0.0076221 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.446 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.095 reward^2 + 0.447 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 483/1000 --- L(Train): 0.0076201 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.447 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.095 reward^2 + 0.447 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 484/1000 --- L(Train): 0.0075723 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.447 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.094 reward^2 + 0.447 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 485/1000 --- L(Train): 0.0075909 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.447 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.093 reward^2 + 0.447 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 486/1000 --- L(Train): 0.0075790 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.447 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.093 reward^2 + 0.448 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 487/1000 --- L(Train): 0.0075936 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.448 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.092 reward^2 + 0.448 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 488/1000 --- L(Train): 0.0075974 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.448 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.091 reward^2 + 0.448 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 489/1000 --- L(Train): 0.0075956 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.448 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.09 reward^2 + 0.448 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 490/1000 --- L(Train): 0.0075825 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.448 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.09 reward^2 + 0.449 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 491/1000 --- L(Train): 0.0076044 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.448 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.089 reward^2 + 0.449 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 492/1000 --- L(Train): 0.0075802 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.449 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.088 reward^2 + 0.449 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 493/1000 --- L(Train): 0.0075647 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.449 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.088 reward^2 + 0.449 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 494/1000 --- L(Train): 0.0075829 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.449 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.087 reward^2 + 0.449 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 495/1000 --- L(Train): 0.0075532 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.449 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.086 reward^2 + 0.45 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 496/1000 --- L(Train): 0.0075604 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.45 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.085 reward^2 + 0.45 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 497/1000 --- L(Train): 0.0075594 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.45 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.085 reward^2 + 0.45 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 498/1000 --- L(Train): 0.0075484 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.45 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.084 reward^2 + 0.45 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 499/1000 --- L(Train): 0.0075602 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.45 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.083 reward^2 + 0.45 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 500/1000 --- L(Train): 0.0075491 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.45 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.082 reward^2 + 0.451 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 501/1000 --- L(Train): 0.0075389 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.451 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.082 reward^2 + 0.451 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 502/1000 --- L(Train): 0.0075481 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.451 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.081 reward^2 + 0.451 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 503/1000 --- L(Train): 0.0075567 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.451 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.08 reward^2 + 0.451 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 504/1000 --- L(Train): 0.0075358 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.451 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.08 reward^2 + 0.452 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 505/1000 --- L(Train): 0.0075567 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.451 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.079 reward^2 + 0.452 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 506/1000 --- L(Train): 0.0075542 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.452 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.078 reward^2 + 0.452 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 507/1000 --- L(Train): 0.0075357 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.452 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.077 reward^2 + 0.452 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 508/1000 --- L(Train): 0.0075413 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.452 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.077 reward^2 + 0.452 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 509/1000 --- L(Train): 0.0075461 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.452 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.076 reward^2 + 0.453 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 510/1000 --- L(Train): 0.0075356 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.453 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.075 reward^2 + 0.453 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 511/1000 --- L(Train): 0.0075352 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.453 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.075 reward^2 + 0.453 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 512/1000 --- L(Train): 0.0075384 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.453 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.074 reward^2 + 0.453 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 513/1000 --- L(Train): 0.0075360 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.453 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.073 reward^2 + 0.453 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 514/1000 --- L(Train): 0.0075348 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.453 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.073 reward^2 + 0.454 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 515/1000 --- L(Train): 0.0075562 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.454 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.072 reward^2 + 0.454 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 516/1000 --- L(Train): 0.0075515 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.454 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.071 reward^2 + 0.454 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 517/1000 --- L(Train): 0.0075562 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.454 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.07 reward^2 + 0.454 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 518/1000 --- L(Train): 0.0075326 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.454 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.07 reward^2 + 0.455 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 519/1000 --- L(Train): 0.0075506 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.454 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.069 reward^2 + 0.455 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 520/1000 --- L(Train): 0.0075366 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.455 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.068 reward^2 + 0.455 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 521/1000 --- L(Train): 0.0075376 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.455 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.068 reward^2 + 0.455 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 522/1000 --- L(Train): 0.0075589 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.455 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.067 reward^2 + 0.455 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 523/1000 --- L(Train): 0.0075474 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.455 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.066 reward^2 + 0.456 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 524/1000 --- L(Train): 0.0075497 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.455 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.066 reward^2 + 0.456 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 525/1000 --- L(Train): 0.0075405 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.456 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.065 reward^2 + 0.456 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 526/1000 --- L(Train): 0.0075417 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.456 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.064 reward^2 + 0.456 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 527/1000 --- L(Train): 0.0075335 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.456 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.063 reward^2 + 0.456 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 528/1000 --- L(Train): 0.0075424 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.456 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.063 reward^2 + 0.457 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 529/1000 --- L(Train): 0.0075324 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.457 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.062 reward^2 + 0.457 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 530/1000 --- L(Train): 0.0075298 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.457 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.061 reward^2 + 0.457 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 531/1000 --- L(Train): 0.0075375 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.457 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.061 reward^2 + 0.457 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 532/1000 --- L(Train): 0.0075269 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.457 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.06 reward^2 + 0.457 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 533/1000 --- L(Train): 0.0075275 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.457 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.059 reward^2 + 0.458 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 534/1000 --- L(Train): 0.0075318 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.458 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.059 reward^2 + 0.458 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 535/1000 --- L(Train): 0.0075240 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.458 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.058 reward^2 + 0.458 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 536/1000 --- L(Train): 0.0075270 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.458 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.057 reward^2 + 0.458 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 537/1000 --- L(Train): 0.0075294 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.458 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.057 reward^2 + 0.458 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 538/1000 --- L(Train): 0.0075230 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.458 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.056 reward^2 + 0.459 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 539/1000 --- L(Train): 0.0075260 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.459 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.055 reward^2 + 0.459 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 540/1000 --- L(Train): 0.0075277 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.459 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.054 reward^2 + 0.459 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 541/1000 --- L(Train): 0.0075226 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.459 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.054 reward^2 + 0.459 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 542/1000 --- L(Train): 0.0075248 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.459 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.053 reward^2 + 0.46 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 543/1000 --- L(Train): 0.0075258 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.459 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.052 reward^2 + 0.46 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 544/1000 --- L(Train): 0.0075224 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.46 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.052 reward^2 + 0.46 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 545/1000 --- L(Train): 0.0075237 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.46 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.051 reward^2 + 0.46 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 546/1000 --- L(Train): 0.0075246 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.46 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.05 reward^2 + 0.46 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 547/1000 --- L(Train): 0.0075222 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.46 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.05 reward^2 + 0.461 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 1, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 548/1000 --- L(Train): 0.0075228 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.46 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.049 reward^2 + 0.461 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 2, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 549/1000 --- L(Train): 0.0075230 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.461 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.048 reward^2 + 0.461 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 3, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 550/1000 --- L(Train): 0.0075213 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.461 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.048 reward^2 + 0.461 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 4, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 551/1000 --- L(Train): 0.0075220 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.461 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.047 reward^2 + 0.461 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 5, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 552/1000 --- L(Train): 0.0075222 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.461 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.046 reward^2 + 0.462 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 6, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 553/1000 --- L(Train): 0.0075209 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.461 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.046 reward^2 + 0.462 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 7, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 554/1000 --- L(Train): 0.0075584 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.462 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.045 reward^2 + 0.462 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 8, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 555/1000 --- L(Train): 0.0075276 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.462 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.044 reward^2 + 0.462 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 9, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 556/1000 --- L(Train): 0.0075633 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.462 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.044 reward^2 + 0.462 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 10, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 557/1000 --- L(Train): 0.0075263 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.462 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.043 reward^2 + 0.463 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 11, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 558/1000 --- L(Train): 0.0075379 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.462 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.042 reward^2 + 0.463 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 12, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 559/1000 --- L(Train): 0.0075475 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.463 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.042 reward^2 + 0.463 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 13, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 560/1000 --- L(Train): 0.0075222 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.463 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.041 reward^2 + 0.463 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 14, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 561/1000 --- L(Train): 0.0075346 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.463 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.04 reward^2 + 0.463 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 15, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 562/1000 --- L(Train): 0.0075390 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.463 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.04 reward^2 + 0.464 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 16, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 563/1000 --- L(Train): 0.0075217 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.463 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.039 reward^2 + 0.464 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 17, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 564/1000 --- L(Train): 0.0075290 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.464 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.038 reward^2 + 0.464 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 18, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 565/1000 --- L(Train): 0.0075342 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.464 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.038 reward^2 + 0.464 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 19, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 566/1000 --- L(Train): 0.0075264 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.464 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.037 reward^2 + 0.464 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 20, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 567/1000 --- L(Train): 0.0075306 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.464 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.036 reward^2 + 0.465 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 21, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 568/1000 --- L(Train): 0.0075328 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.464 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.036 reward^2 + 0.465 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 22, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 569/1000 --- L(Train): 0.0075254 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.465 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.035 reward^2 + 0.465 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 23, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 570/1000 --- L(Train): 0.0075245 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.465 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.034 reward^2 + 0.465 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 24, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 571/1000 --- L(Train): 0.0075275 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.465 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.034 reward^2 + 0.465 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 25, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 572/1000 --- L(Train): 0.0075265 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.465 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.033 reward^2 + 0.466 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 26, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 573/1000 --- L(Train): 0.0075192 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.465 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.032 reward^2 + 0.466 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 27, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 574/1000 --- L(Train): 0.0075265 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.466 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.032 reward^2 + 0.466 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 28, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 575/1000 --- L(Train): 0.0075241 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.466 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.031 reward^2 + 0.466 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 29, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 576/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.466 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.03 reward^2 + 0.466 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 30, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 577/1000 --- L(Train): 0.0075239 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.466 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.03 reward^2 + 0.467 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 31, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 578/1000 --- L(Train): 0.0075228 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.466 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.029 reward^2 + 0.467 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 32, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 579/1000 --- L(Train): 0.0075215 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.467 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.028 reward^2 + 0.467 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 33, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 580/1000 --- L(Train): 0.0075224 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.467 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.028 reward^2 + 0.467 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 34, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 581/1000 --- L(Train): 0.0075231 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.467 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.027 reward^2 + 0.467 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 35, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 582/1000 --- L(Train): 0.0075219 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.467 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.026 reward^2 + 0.468 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 36, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 583/1000 --- L(Train): 0.0075199 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.467 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.026 reward^2 + 0.468 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 37, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 584/1000 --- L(Train): 0.0075218 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.468 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.025 reward^2 + 0.468 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 38, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 585/1000 --- L(Train): 0.0075213 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.468 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.024 reward^2 + 0.468 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 39, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 586/1000 --- L(Train): 0.0075191 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.468 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.024 reward^2 + 0.468 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 40, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 587/1000 --- L(Train): 0.0075207 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.468 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.023 reward^2 + 0.469 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 41, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 588/1000 --- L(Train): 0.0075325 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.468 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.022 reward^2 + 0.469 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 42, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 589/1000 --- L(Train): 0.0075196 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.469 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.022 reward^2 + 0.469 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 43, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 590/1000 --- L(Train): 0.0075315 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.469 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.021 reward^2 + 0.469 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 44, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 591/1000 --- L(Train): 0.0075246 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.469 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.021 reward^2 + 0.469 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 45, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 592/1000 --- L(Train): 0.0075201 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.469 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.02 reward^2 + 0.469 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 46, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 593/1000 --- L(Train): 0.0075280 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.469 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.019 reward^2 + 0.47 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 47, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 594/1000 --- L(Train): 0.0075212 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.47 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.019 reward^2 + 0.47 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 48, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 595/1000 --- L(Train): 0.0075202 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.47 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.018 reward^2 + 0.47 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 49, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 596/1000 --- L(Train): 0.0075246 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.47 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.017 reward^2 + 0.47 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 50, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 597/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.47 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.017 reward^2 + 0.47 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 51, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 598/1000 --- L(Train): 0.0075206 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.47 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.016 reward^2 + 0.471 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 52, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 599/1000 --- L(Train): 0.0075235 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.47 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.015 reward^2 + 0.471 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 53, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 600/1000 --- L(Train): 0.0075202 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.471 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.015 reward^2 + 0.471 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 54, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 601/1000 --- L(Train): 0.0075217 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.471 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.014 reward^2 + 0.471 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 55, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 602/1000 --- L(Train): 0.0075230 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.471 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.014 reward^2 + 0.471 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 56, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 603/1000 --- L(Train): 0.0075191 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.471 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.013 reward^2 + 0.472 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 57, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 604/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.471 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.012 reward^2 + 0.472 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 58, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 605/1000 --- L(Train): 0.0075205 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.472 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.012 reward^2 + 0.472 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 59, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 606/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.472 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.011 reward^2 + 0.472 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 60, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 607/1000 --- L(Train): 0.0075201 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.472 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.01 reward^2 + 0.472 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 61, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 608/1000 --- L(Train): 0.0075208 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.472 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.01 reward^2 + 0.473 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 62, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 609/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.472 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.009 reward^2 + 0.473 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 63, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 610/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.473 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.008 reward^2 + 0.473 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 64, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 611/1000 --- L(Train): 0.0075192 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.473 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.008 reward^2 + 0.473 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 65, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 612/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.473 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.007 reward^2 + 0.473 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 66, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 613/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.473 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.007 reward^2 + 0.473 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 67, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 614/1000 --- L(Train): 0.0075208 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.473 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.006 reward^2 + 0.474 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 68, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 615/1000 --- L(Train): 0.0075201 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.474 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.005 reward^2 + 0.474 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 69, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 616/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.474 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.005 reward^2 + 0.474 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 70, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 617/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.474 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.004 reward^2 + 0.474 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 71, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 618/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.474 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.004 reward^2 + 0.474 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 72, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 619/1000 --- L(Train): 0.0075191 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.474 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.003 reward^2 + 0.475 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 73, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 620/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.474 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.002 reward^2 + 0.475 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 74, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 621/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.475 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.002 reward^2 + 0.475 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 75, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 622/1000 --- L(Train): 0.0075178 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.475 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.001 reward^2 + 0.475 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 76, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 623/1000 --- L(Train): 0.0075177 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.475 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.475 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 77, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 624/1000 --- L(Train): 0.0075179 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.475 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + -0.0 reward^2 + 0.475 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 78, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 625/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.475 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 79, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 626/1000 --- L(Train): 0.0075941 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 80, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 627/1000 --- L(Train): 0.0075545 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 81, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 628/1000 --- L(Train): 0.0075262 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 82, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 629/1000 --- L(Train): 0.0075319 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 83, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 630/1000 --- L(Train): 0.0075547 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 84, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 631/1000 --- L(Train): 0.0075630 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + -0.0 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 85, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 632/1000 --- L(Train): 0.0075499 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 86, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 633/1000 --- L(Train): 0.0075303 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.001 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 87, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 634/1000 --- L(Train): 0.0075219 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.001 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 88, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 635/1000 --- L(Train): 0.0075288 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.001 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 89, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 636/1000 --- L(Train): 0.0075397 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.002 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 90, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 637/1000 --- L(Train): 0.0075427 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.002 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 91, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 638/1000 --- L(Train): 0.0075363 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.001 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 92, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 639/1000 --- L(Train): 0.0075280 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.001 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 93, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 640/1000 --- L(Train): 0.0075240 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.001 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 94, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 641/1000 --- L(Train): 0.0075258 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.001 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 95, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 642/1000 --- L(Train): 0.0075306 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 96, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 643/1000 --- L(Train): 0.0075338 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + -0.0 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 97, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 644/1000 --- L(Train): 0.0075323 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 98, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 645/1000 --- L(Train): 0.0075272 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.001 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 99, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 646/1000 --- L(Train): 0.0075234 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 647/1000 --- L(Train): 0.0075241 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 648/1000 --- L(Train): 0.0075280 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 649/1000 --- L(Train): 0.0075295 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 650/1000 --- L(Train): 0.0075275 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 651/1000 --- L(Train): 0.0075251 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 652/1000 --- L(Train): 0.0075243 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 653/1000 --- L(Train): 0.0075231 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 654/1000 --- L(Train): 0.0075224 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 655/1000 --- L(Train): 0.0075233 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 656/1000 --- L(Train): 0.0075242 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 657/1000 --- L(Train): 0.0075233 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 658/1000 --- L(Train): 0.0075214 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 659/1000 --- L(Train): 0.0075209 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 660/1000 --- L(Train): 0.0075217 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 661/1000 --- L(Train): 0.0075221 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 662/1000 --- L(Train): 0.0075220 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 663/1000 --- L(Train): 0.0075214 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 664/1000 --- L(Train): 0.0075209 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 665/1000 --- L(Train): 0.0075205 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 666/1000 --- L(Train): 0.0075206 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 667/1000 --- L(Train): 0.0075211 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 668/1000 --- L(Train): 0.0075216 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 669/1000 --- L(Train): 0.0075217 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 670/1000 --- L(Train): 0.0075214 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 671/1000 --- L(Train): 0.0075214 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 672/1000 --- L(Train): 0.0075219 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 673/1000 --- L(Train): 0.0075219 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 674/1000 --- L(Train): 0.0075219 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 675/1000 --- L(Train): 0.0075219 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 676/1000 --- L(Train): 0.0075217 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 677/1000 --- L(Train): 0.0075217 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 678/1000 --- L(Train): 0.0075218 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 679/1000 --- L(Train): 0.0075210 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 680/1000 --- L(Train): 0.0075206 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 681/1000 --- L(Train): 0.0075208 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 682/1000 --- L(Train): 0.0075213 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 683/1000 --- L(Train): 0.0075211 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 684/1000 --- L(Train): 0.0075203 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 685/1000 --- L(Train): 0.0075199 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 686/1000 --- L(Train): 0.0075204 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 687/1000 --- L(Train): 0.0075205 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 688/1000 --- L(Train): 0.0075202 --- L(Val, SINDy): 0.0000000 --- Time: 0.09s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 689/1000 --- L(Train): 0.0075199 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 690/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 691/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 692/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 693/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 694/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 695/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 696/1000 --- L(Train): 0.0075199 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 697/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 698/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 699/1000 --- L(Train): 0.0075202 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 700/1000 --- L(Train): 0.0075204 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 701/1000 --- L(Train): 0.0075203 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 702/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 703/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 704/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 705/1000 --- L(Train): 0.0075203 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 706/1000 --- L(Train): 0.0075402 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 707/1000 --- L(Train): 0.0075210 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 708/1000 --- L(Train): 0.0075423 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 709/1000 --- L(Train): 0.0075250 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 710/1000 --- L(Train): 0.0075255 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 711/1000 --- L(Train): 0.0075349 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 712/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 713/1000 --- L(Train): 0.0075259 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 714/1000 --- L(Train): 0.0075288 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 715/1000 --- L(Train): 0.0075191 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 716/1000 --- L(Train): 0.0075257 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 717/1000 --- L(Train): 0.0075251 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 718/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 719/1000 --- L(Train): 0.0075243 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 720/1000 --- L(Train): 0.0075234 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 721/1000 --- L(Train): 0.0075191 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 722/1000 --- L(Train): 0.0075231 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 723/1000 --- L(Train): 0.0075220 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 724/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 725/1000 --- L(Train): 0.0075222 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 726/1000 --- L(Train): 0.0075209 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 727/1000 --- L(Train): 0.0075192 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 728/1000 --- L(Train): 0.0075214 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 729/1000 --- L(Train): 0.0075205 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 730/1000 --- L(Train): 0.0075192 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 731/1000 --- L(Train): 0.0075207 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 732/1000 --- L(Train): 0.0075198 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 733/1000 --- L(Train): 0.0075190 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 734/1000 --- L(Train): 0.0075203 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 735/1000 --- L(Train): 0.0075196 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 736/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 737/1000 --- L(Train): 0.0075202 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 738/1000 --- L(Train): 0.0075198 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 739/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 740/1000 --- L(Train): 0.0075199 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 741/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 742/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 743/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 744/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 745/1000 --- L(Train): 0.0075188 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 746/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 747/1000 --- L(Train): 0.0075190 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 748/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 749/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 750/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 751/1000 --- L(Train): 0.0075180 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 752/1000 --- L(Train): 0.0075185 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 753/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 754/1000 --- L(Train): 0.0075470 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 755/1000 --- L(Train): 0.0075202 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 756/1000 --- L(Train): 0.0075503 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 757/1000 --- L(Train): 0.0075287 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 758/1000 --- L(Train): 0.0075255 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 759/1000 --- L(Train): 0.0075418 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 760/1000 --- L(Train): 0.0075227 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 761/1000 --- L(Train): 0.0075262 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 762/1000 --- L(Train): 0.0075350 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\u001b[H\u001b[2J\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 763/1000 --- L(Train): 0.0075206 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 764/1000 --- L(Train): 0.0075243 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 765/1000 --- L(Train): 0.0075303 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 766/1000 --- L(Train): 0.0075204 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 767/1000 --- L(Train): 0.0075229 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 768/1000 --- L(Train): 0.0075276 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 769/1000 --- L(Train): 0.0075206 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 770/1000 --- L(Train): 0.0075216 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 771/1000 --- L(Train): 0.0075249 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 772/1000 --- L(Train): 0.0075196 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 773/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 774/1000 --- L(Train): 0.0075225 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 775/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 776/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 777/1000 --- L(Train): 0.0075213 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 778/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.09s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 779/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 780/1000 --- L(Train): 0.0075211 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 781/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 782/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 783/1000 --- L(Train): 0.0075202 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 784/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 785/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 786/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 787/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 788/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 789/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 790/1000 --- L(Train): 0.0075190 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 791/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 792/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 793/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 794/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 795/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 796/1000 --- L(Train): 0.0075188 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 797/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 798/1000 --- L(Train): 0.0075185 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 799/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 800/1000 --- L(Train): 0.0075179 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 801/1000 --- L(Train): 0.0075181 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 802/1000 --- L(Train): 0.0075181 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 803/1000 --- L(Train): 0.0075179 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 804/1000 --- L(Train): 0.0075178 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 805/1000 --- L(Train): 0.0075180 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 806/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 807/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 808/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 809/1000 --- L(Train): 0.0075185 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 810/1000 --- L(Train): 0.0075188 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 811/1000 --- L(Train): 0.0075185 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 812/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 813/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 814/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 815/1000 --- L(Train): 0.0075181 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 816/1000 --- L(Train): 0.0075181 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 817/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 818/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 819/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 820/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 821/1000 --- L(Train): 0.0075181 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 822/1000 --- L(Train): 0.0075180 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 823/1000 --- L(Train): 0.0075181 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 824/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 825/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 826/1000 --- L(Train): 0.0075190 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 827/1000 --- L(Train): 0.0075196 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 828/1000 --- L(Train): 0.0075201 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 829/1000 --- L(Train): 0.0075199 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 830/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 831/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 832/1000 --- L(Train): 0.0075185 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 833/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 834/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 835/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.12s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 836/1000 --- L(Train): 0.0075192 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 837/1000 --- L(Train): 0.0075185 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 838/1000 --- L(Train): 0.0075180 --- L(Val, SINDy): 0.0000000 --- Time: 0.09s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 839/1000 --- L(Train): 0.0075181 --- L(Val, SINDy): 0.0000000 --- Time: 0.10s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 840/1000 --- L(Train): 0.0075190 --- L(Val, SINDy): 0.0000000 --- Time: 0.12s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 841/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.12s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 842/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.15s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 843/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.13s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 844/1000 --- L(Train): 0.0075188 --- L(Val, SINDy): 0.0000000 --- Time: 0.14s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 845/1000 --- L(Train): 0.0075190 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 846/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.15s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 847/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 848/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 849/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 850/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 851/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 852/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 853/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 854/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 855/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 856/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 857/1000 --- L(Train): 0.0075179 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 858/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 859/1000 --- L(Train): 0.0075177 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 860/1000 --- L(Train): 0.0075188 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 861/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 862/1000 --- L(Train): 0.0075191 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 863/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 864/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 865/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 866/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 867/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 868/1000 --- L(Train): 0.0075192 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 869/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 870/1000 --- L(Train): 0.0075191 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 871/1000 --- L(Train): 0.0075191 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 872/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 873/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 874/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 875/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 876/1000 --- L(Train): 0.0075199 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 877/1000 --- L(Train): 0.0075205 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 878/1000 --- L(Train): 0.0075208 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 879/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 880/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 881/1000 --- L(Train): 0.0075209 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 882/1000 --- L(Train): 0.0075224 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 883/1000 --- L(Train): 0.0075220 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 884/1000 --- L(Train): 0.0075201 --- L(Val, SINDy): 0.0000000 --- Time: 0.15s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 885/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 886/1000 --- L(Train): 0.0075190 --- L(Val, SINDy): 0.0000000 --- Time: 0.16s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 887/1000 --- L(Train): 0.0075201 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 888/1000 --- L(Train): 0.0075207 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 889/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.14s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 890/1000 --- L(Train): 0.0075190 --- L(Val, SINDy): 0.0000000 --- Time: 0.14s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 891/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 892/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 893/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 894/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 895/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 896/1000 --- L(Train): 0.0075188 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 897/1000 --- L(Train): 0.0075192 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 898/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 899/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 900/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 901/1000 --- L(Train): 0.0075185 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 902/1000 --- L(Train): 0.0075190 --- L(Val, SINDy): 0.0000000 --- Time: 0.16s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 903/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 904/1000 --- L(Train): 0.0075201 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 905/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 906/1000 --- L(Train): 0.0075196 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 907/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 908/1000 --- L(Train): 0.0075201 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 909/1000 --- L(Train): 0.0075198 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 910/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 911/1000 --- L(Train): 0.0075506 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 912/1000 --- L(Train): 0.0075235 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 913/1000 --- L(Train): 0.0075580 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 914/1000 --- L(Train): 0.0075246 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 915/1000 --- L(Train): 0.0075359 --- L(Val, SINDy): 0.0000000 --- Time: 0.28s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 916/1000 --- L(Train): 0.0075412 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 917/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 918/1000 --- L(Train): 0.0075364 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 919/1000 --- L(Train): 0.0075308 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 920/1000 --- L(Train): 0.0075188 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 921/1000 --- L(Train): 0.0075324 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 922/1000 --- L(Train): 0.0075258 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 923/1000 --- L(Train): 0.0075196 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 924/1000 --- L(Train): 0.0075287 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 925/1000 --- L(Train): 0.0075223 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 926/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 927/1000 --- L(Train): 0.0075267 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 928/1000 --- L(Train): 0.0075221 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 929/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 930/1000 --- L(Train): 0.0075247 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 931/1000 --- L(Train): 0.0075209 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 932/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 933/1000 --- L(Train): 0.0075223 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 934/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 935/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 936/1000 --- L(Train): 0.0075211 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 937/1000 --- L(Train): 0.0075196 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 938/1000 --- L(Train): 0.0075188 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 939/1000 --- L(Train): 0.0075206 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 940/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.27s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 941/1000 --- L(Train): 0.0075185 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 942/1000 --- L(Train): 0.0075196 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 943/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 944/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 945/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 946/1000 --- L(Train): 0.0075198 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 947/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 948/1000 --- L(Train): 0.0075206 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 949/1000 --- L(Train): 0.0075196 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 950/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 951/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 952/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 953/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 954/1000 --- L(Train): 0.0075185 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 955/1000 --- L(Train): 0.0075178 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 956/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 957/1000 --- L(Train): 0.0075181 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 958/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 959/1000 --- L(Train): 0.0075180 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 960/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 961/1000 --- L(Train): 0.0075179 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 962/1000 --- L(Train): 0.0075178 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 963/1000 --- L(Train): 0.0075181 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 964/1000 --- L(Train): 0.0075176 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 965/1000 --- L(Train): 0.0075171 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 966/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 967/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 968/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 969/1000 --- L(Train): 0.0075176 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 970/1000 --- L(Train): 0.0075171 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 971/1000 --- L(Train): 0.0075173 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 972/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 973/1000 --- L(Train): 0.0075170 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 974/1000 --- L(Train): 0.0075170 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 975/1000 --- L(Train): 0.0075171 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 976/1000 --- L(Train): 0.0075173 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 977/1000 --- L(Train): 0.0075174 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 978/1000 --- L(Train): 0.0075173 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 979/1000 --- L(Train): 0.0075173 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 980/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 981/1000 --- L(Train): 0.0075177 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 982/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 983/1000 --- L(Train): 0.0075173 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 984/1000 --- L(Train): 0.0075173 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 985/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 986/1000 --- L(Train): 0.0075180 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 987/1000 --- L(Train): 0.0075180 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 988/1000 --- L(Train): 0.0075178 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 989/1000 --- L(Train): 0.0075178 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 990/1000 --- L(Train): 0.0075178 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 991/1000 --- L(Train): 0.0075171 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 992/1000 --- L(Train): 0.0075168 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 993/1000 --- L(Train): 0.0075173 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 994/1000 --- L(Train): 0.0075177 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 995/1000 --- L(Train): 0.0075177 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 996/1000 --- L(Train): 0.0075179 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 997/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 998/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 999/1000 --- L(Train): 0.0075177 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 1000/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 1001/1000 --- L(Train): 0.0075180 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\n",
      "Training result:\n",
      "L(Train): 0.0000000 --- L(Val, RNN): 0.3412420 --- L(Val, SINDy): 0.3886036 --- LR: 3.1250000e-04\n",
      "\n",
      "RNN training finished.\n",
      "Training took 1158.69 seconds.\n",
      "Saving SPICE model to ../params/bustamante2023/spice_bustamante2023.pkl...\n",
      "================================================================================\n",
      "\n",
      "Training complete!\n",
      "\n",
      "Example SPICE model (participant 0):\n",
      "--------------------------------------------------------------------------------\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "estimator = SpiceEstimator(\n",
    "        # model paramaeters\n",
    "        rnn_class=SPICERNN,\n",
    "        spice_config=spice_config,\n",
    "        n_actions=2,\n",
    "        n_participants=n_participants,\n",
    "        n_experiments=1,\n",
    "        \n",
    "        # rnn training parameters\n",
    "        epochs=1000,\n",
    "        warmup_steps=200,\n",
    "        learning_rate=0.01,\n",
    "        \n",
    "        # sindy fitting parameters\n",
    "        sindy_weight=0.1,\n",
    "        sindy_threshold=0.05,\n",
    "        sindy_threshold_frequency=1,\n",
    "        sindy_threshold_terms=1,\n",
    "        sindy_cutoff_patience=100,\n",
    "        sindy_epochs=1000,\n",
    "        sindy_alpha=0.0001,\n",
    "        sindy_library_polynomial_degree=2,\n",
    "        sindy_ensemble_size=1,\n",
    "        \n",
    "        # additional generalization parameters\n",
    "        batch_size=1024,\n",
    "        bagging=True,\n",
    "        scheduler=True,\n",
    "        \n",
    "        verbose=True,\n",
    "        save_path_spice='../params/bustamante2023/spice_bustamante2023.pkl',\n",
    "    )\n",
    "\n",
    "print(f\"\\nStarting training on {estimator.device}...\")\n",
    "print(\"=\" * 80)\n",
    "estimator.fit(dataset.xs, dataset.ys, dataset.xs, dataset.ys)\n",
    "# estimator.load_spice(args.model)\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nTraining complete!\")\n",
    "\n",
    "# Print example SPICE model for first participant\n",
    "print(\"\\nExample SPICE model (participant 0):\")\n",
    "print(\"-\" * 80)\n",
    "estimator.print_spice_model(participant_id=0)\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     participant_id                subject_id  last_reward  relative_optimal  \\\n",
      "0                 0  08aiu2bm6t15qij5826jxz50     8.241283          1.461283   \n",
      "1                 1  09j932f828pn7h7bozp9mpnl     5.344722         -1.435278   \n",
      "2                 2  0ax9htcbhfi3ncsospqzwjx2     8.945571          2.165571   \n",
      "3                 3  0e6zivqly335lojgb4c6606t     7.554696          0.774696   \n",
      "4                 4  0fawro1pivqnh4lem4ayf4o0     3.089682         -3.690318   \n",
      "..              ...                       ...          ...               ...   \n",
      "245             245  fzllq0yp08zefacpmy7dqq0u     9.041866          2.261866   \n",
      "246             246  g2n23l2w8uf3brbllm4sbrcx     8.106489          1.326489   \n",
      "247             247  g9wqksieqbldodjoyuci048q     6.765186         -0.014814   \n",
      "248             248  garkh3hmuozi9loxpee54z20     7.720383          0.940383   \n",
      "249             249  gd6af6pqeo2d0x2dcumwirmy     3.908357         -2.871643   \n",
      "\n",
      "     over_harvester  \n",
      "0                 0  \n",
      "1                 1  \n",
      "2                 0  \n",
      "3                 0  \n",
      "4                 1  \n",
      "..              ...  \n",
      "245               0  \n",
      "246               0  \n",
      "247               1  \n",
      "248               0  \n",
      "249               1  \n",
      "\n",
      "[250 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file)\n",
    "df['last_reward'] = df.groupby('subject_id')['last_reward'].fillna(method='bfill')\n",
    "df['participant_id'] = pd.factorize(df['subject_id'])[0]\n",
    "exit_df = df[df['decision'] == 1]\n",
    "mean_exit_threshold = exit_df.groupby(['participant_id', 'subject_id'])['last_reward'].mean().reset_index()\n",
    "mean_exit_threshold['relative_optimal'] = mean_exit_threshold['last_reward'] - 6.78 #from Bustamante et al. Table S7, experiment 1\n",
    "mean_exit_threshold['over_harvester'] = np.where(mean_exit_threshold['relative_optimal'] <= 0, 1, 0)\n",
    "print(mean_exit_threshold)\n",
    "overharvesters = mean_exit_threshold[mean_exit_threshold['over_harvester'] == 1]['participant_id'].unique()\n",
    "underharvesters = mean_exit_threshold[mean_exit_threshold['over_harvester'] == 0]['participant_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OVERHARVESTERS\n",
      "Participant number 1\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 4\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 7\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 12\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 13\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 14\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 20\n",
      "value_stay[t+1] = 0.875 value_stay[t] + -0.062 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 23\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 24\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 25\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 26\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 27\n",
      "value_stay[t+1] = -0.168 1 + 0.445 value_stay[t] + -0.168 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 30\n",
      "value_stay[t+1] = -0.154 1 + 0.561 value_stay[t] + -0.154 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 32\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 33\n",
      "value_stay[t+1] = 0.123 1 + 0.646 value_stay[t] + 0.123 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 35\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 36\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 37\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 38\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 43\n",
      "value_stay[t+1] = -0.115 1 + 0.95 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 44\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 45\n",
      "value_stay[t+1] = 0.113 1 + 0.645 value_stay[t] + 0.112 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 46\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 47\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 49\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 51\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 54\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 59\n",
      "value_stay[t+1] = -0.065 1 + 0.752 value_stay[t] + -0.066 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 66\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 68\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 70\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 71\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 72\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 73\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 74\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 75\n",
      "value_stay[t+1] = -0.055 1 + 0.788 value_stay[t] + -0.055 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 77\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 78\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 79\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 80\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 81\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 82\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 84\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 86\n",
      "value_stay[t+1] = -0.115 1 + 0.448 value_stay[t] + -0.115 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 90\n",
      "value_stay[t+1] = -0.125 1 + 0.564 value_stay[t] + -0.125 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 92\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 93\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 95\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 97\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 99\n",
      "value_stay[t+1] = 0.1 1 + 0.561 value_stay[t] + 0.1 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 100\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 101\n",
      "value_stay[t+1] = 0.165 1 + 0.503 value_stay[t] + 0.166 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 103\n",
      "value_stay[t+1] = 0.825 value_stay[t] + -0.066 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 104\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 105\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 109\n",
      "value_stay[t+1] = 0.793 value_stay[t] + -0.068 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 110\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 112\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 113\n",
      "value_stay[t+1] = -0.064 1 + 0.455 value_stay[t] + -0.065 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 114\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 115\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 116\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 120\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 121\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 122\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 123\n",
      "value_stay[t+1] = -0.052 1 + 0.787 value_stay[t] + -0.051 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 124\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 125\n",
      "value_stay[t+1] = -0.066 1 + 0.585 value_stay[t] + -0.067 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 126\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 127\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 128\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 130\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 131\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 132\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 133\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 134\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 135\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 139\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 140\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 142\n",
      "value_stay[t+1] = 0.151 1 + -0.56 value_stay[t] + 0.15 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 143\n",
      "value_stay[t+1] = -0.121 1 + 0.579 value_stay[t] + -0.122 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 144\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 146\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 148\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 152\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 153\n",
      "value_stay[t+1] = 0.16 1 + 0.46 value_stay[t] + 0.16 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 154\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 160\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 161\n",
      "value_stay[t+1] = 0.149 1 + 0.81 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 162\n",
      "value_stay[t+1] = -0.078 1 + 0.262 value_stay[t] + -0.079 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 164\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 165\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 166\n",
      "value_stay[t+1] = -0.109 1 + -0.052 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 167\n",
      "value_stay[t+1] = 0.086 1 + 0.601 value_stay[t] + 0.086 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 168\n",
      "value_stay[t+1] = 0.937 value_stay[t] + 0.066 reward \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 171\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 172\n",
      "value_stay[t+1] = -0.218 1 + 0.272 value_stay[t] + -0.219 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 174\n",
      "value_stay[t+1] = 1.069 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 176\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 177\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 181\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 182\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 184\n",
      "value_stay[t+1] = -0.066 1 + 0.705 value_stay[t] + -0.066 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 185\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 186\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 188\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 189\n",
      "value_stay[t+1] = 0.169 1 + 0.492 value_stay[t] + 0.169 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 191\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 194\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 195\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 198\n",
      "value_stay[t+1] = 0.065 1 + 0.835 value_stay[t] + 0.066 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 199\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 202\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 206\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 208\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 209\n",
      "value_stay[t+1] = -0.094 1 + 0.728 value_stay[t] + -0.094 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 211\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 214\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 215\n",
      "value_stay[t+1] = 0.084 1 + 0.784 value_stay[t] + 0.085 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 216\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 218\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 219\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 220\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 221\n",
      "value_stay[t+1] = 0.118 1 + 0.511 value_stay[t] + 0.118 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 222\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 223\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 225\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 226\n",
      "value_stay[t+1] = -0.218 1 + 0.106 value_stay[t] + -0.217 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 230\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 231\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 233\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 235\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 236\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 238\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 239\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 240\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 241\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 242\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 243\n",
      "value_stay[t+1] = -0.221 1 + 0.281 value_stay[t] + -0.221 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 247\n",
      "value_stay[t+1] = 0.127 1 + 0.911 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 249\n",
      "value_stay[t+1] = -0.138 1 + 0.868 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n"
     ]
    }
   ],
   "source": [
    "print('OVERHARVESTERS') \n",
    "for p in overharvesters:\n",
    "    print('Participant number', p)\n",
    "    estimator.print_spice_model(participant_id=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNDERHARVESTERS\n",
      "Participant number 0\n",
      "value_stay[t+1] = -0.16 1 + 0.379 value_stay[t] + -0.16 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 2\n",
      "value_stay[t+1] = 0.239 1 + 0.273 value_stay[t] + 0.24 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 3\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 5\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 6\n",
      "value_stay[t+1] = -0.237 1 + 0.042 value_stay[t] + -0.237 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 8\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 9\n",
      "value_stay[t+1] = -0.13 1 + 0.628 value_stay[t] + -0.129 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 10\n",
      "value_stay[t+1] = 0.137 1 + 0.569 value_stay[t] + 0.138 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 11\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 15\n",
      "value_stay[t+1] = 0.143 1 + 0.902 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 16\n",
      "value_stay[t+1] = -0.076 1 + 0.821 value_stay[t] + -0.076 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 17\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 18\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 19\n",
      "value_stay[t+1] = -0.098 1 + 0.654 value_stay[t] + -0.097 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 21\n",
      "value_stay[t+1] = -0.058 1 + 0.768 value_stay[t] + -0.058 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 22\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 28\n",
      "value_stay[t+1] = 1.076 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 29\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 31\n",
      "value_stay[t+1] = -0.177 1 + 0.405 value_stay[t] + -0.18 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 34\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 39\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 40\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 41\n",
      "value_stay[t+1] = 0.206 1 + 0.372 value_stay[t] + 0.204 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 42\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 48\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 50\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 52\n",
      "value_stay[t+1] = 0.075 1 + 0.825 value_stay[t] + 0.074 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 53\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 55\n",
      "value_stay[t+1] = 0.091 1 + 0.158 value_stay[t] + 0.063 reward \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 56\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 57\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 58\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 60\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 61\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 62\n",
      "value_stay[t+1] = 0.805 value_stay[t] + -0.072 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 63\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 64\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 65\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 67\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 69\n",
      "value_stay[t+1] = -0.091 1 + 0.701 value_stay[t] + -0.091 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 76\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 83\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 85\n",
      "value_stay[t+1] = -0.096 1 + 0.76 value_stay[t] + -0.096 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 87\n",
      "value_stay[t+1] = -0.137 1 + 0.482 value_stay[t] + -0.137 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 88\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 89\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 91\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 94\n",
      "value_stay[t+1] = 0.131 1 + 0.515 value_stay[t] + 0.131 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 96\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 98\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 102\n",
      "value_stay[t+1] = -0.114 1 + 0.257 value_stay[t] + -0.111 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 106\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 107\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 108\n",
      "value_stay[t+1] = 1.057 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 111\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 117\n",
      "value_stay[t+1] = -0.097 1 + 0.607 value_stay[t] + -0.097 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 118\n",
      "value_stay[t+1] = 0.055 1 + 0.872 value_stay[t] + 0.055 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 119\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 129\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 136\n",
      "value_stay[t+1] = 1.057 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 137\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 138\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 141\n",
      "value_stay[t+1] = 0.066 1 + 0.798 value_stay[t] + 0.065 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 145\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 147\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 149\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 150\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 151\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 155\n",
      "value_stay[t+1] = 0.117 1 + 0.566 value_stay[t] + 0.117 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 156\n",
      "value_stay[t+1] = 0.108 1 + 0.547 value_stay[t] + 0.108 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 157\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 158\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 159\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 163\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 169\n",
      "value_stay[t+1] = -0.062 1 + 0.778 value_stay[t] + -0.061 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 170\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 173\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 175\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 178\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 179\n",
      "value_stay[t+1] = 0.88 value_stay[t] + -0.064 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 180\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 183\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 187\n",
      "value_stay[t+1] = 0.098 1 + 0.654 value_stay[t] + 0.098 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 190\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 192\n",
      "value_stay[t+1] = 0.077 1 + 0.803 value_stay[t] + 0.078 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 193\n",
      "value_stay[t+1] = 0.121 1 + 0.715 value_stay[t] + 0.072 reward \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 196\n",
      "value_stay[t+1] = -0.096 1 + 0.679 value_stay[t] + -0.096 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 197\n",
      "value_stay[t+1] = 0.218 1 + 0.396 value_stay[t] + 0.219 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 200\n",
      "value_stay[t+1] = 0.12 1 + 0.593 value_stay[t] + 0.12 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 201\n",
      "value_stay[t+1] = -0.055 1 + 0.876 value_stay[t] + -0.054 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 203\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 204\n",
      "value_stay[t+1] = -0.224 1 + 0.288 value_stay[t] + -0.224 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 205\n",
      "value_stay[t+1] = -0.122 1 + 0.636 value_stay[t] + -0.122 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 207\n",
      "value_stay[t+1] = 0.145 1 + 0.812 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 210\n",
      "value_stay[t+1] = 1.067 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 212\n",
      "value_stay[t+1] = -0.079 1 + 0.694 value_stay[t] + -0.079 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 213\n",
      "value_stay[t+1] = 1.0 value_stay[t] + 0.061 reward \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 217\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 224\n",
      "value_stay[t+1] = -0.098 1 + 0.647 value_stay[t] + -0.098 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 227\n",
      "value_stay[t+1] = -0.149 1 + 0.819 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 228\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 229\n",
      "value_stay[t+1] = -0.078 1 + 0.82 value_stay[t] + -0.077 harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 232\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 234\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 237\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 244\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 245\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 246\n",
      "value_stay[t+1] = 1.071 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 248\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n"
     ]
    }
   ],
   "source": [
    "print('UNDERHARVESTERS') \n",
    "for p in underharvesters:\n",
    "    print('Participant number', p)\n",
    "    estimator.print_spice_model(participant_id=p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MVT Model by Constantino et al. (2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "from weinhardt2025.benchmarking.benchmarking_bustamante2023 import MarginalValueTheoremModel\n",
    "\n",
    "mvt = MarginalValueTheoremModel(\n",
    "    n_participants=n_participants,\n",
    "    depletion=None,  # if None: learn value; else: fix to given value;\n",
    "    baseline_gain=None,  # if None: learn value; else: fix to given value;\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000 --- Loss: 0.72331\n",
      "Epoch 2/1000 --- Loss: 0.71865\n",
      "Epoch 3/1000 --- Loss: 0.71365\n",
      "Epoch 4/1000 --- Loss: 0.70874\n",
      "Epoch 5/1000 --- Loss: 0.70381\n",
      "Epoch 6/1000 --- Loss: 0.69908\n",
      "Epoch 7/1000 --- Loss: 0.69476\n",
      "Epoch 8/1000 --- Loss: 0.69014\n",
      "Epoch 9/1000 --- Loss: 0.68553\n",
      "Epoch 10/1000 --- Loss: 0.68091\n",
      "Epoch 11/1000 --- Loss: 0.67673\n",
      "Epoch 12/1000 --- Loss: 0.67237\n",
      "Epoch 13/1000 --- Loss: 0.66785\n",
      "Epoch 14/1000 --- Loss: 0.66333\n",
      "Epoch 15/1000 --- Loss: 0.65945\n",
      "Epoch 16/1000 --- Loss: 0.65527\n",
      "Epoch 17/1000 --- Loss: 0.65087\n",
      "Epoch 18/1000 --- Loss: 0.64707\n",
      "Epoch 19/1000 --- Loss: 0.64334\n",
      "Epoch 20/1000 --- Loss: 0.63907\n",
      "Epoch 21/1000 --- Loss: 0.63501\n",
      "Epoch 22/1000 --- Loss: 0.63115\n",
      "Epoch 23/1000 --- Loss: 0.62727\n",
      "Epoch 24/1000 --- Loss: 0.62378\n",
      "Epoch 25/1000 --- Loss: 0.61989\n",
      "Epoch 26/1000 --- Loss: 0.61617\n",
      "Epoch 27/1000 --- Loss: 0.61258\n",
      "Epoch 28/1000 --- Loss: 0.60865\n",
      "Epoch 29/1000 --- Loss: 0.60535\n",
      "Epoch 30/1000 --- Loss: 0.60167\n",
      "Epoch 31/1000 --- Loss: 0.59840\n",
      "Epoch 32/1000 --- Loss: 0.59489\n",
      "Epoch 33/1000 --- Loss: 0.59157\n",
      "Epoch 34/1000 --- Loss: 0.58793\n",
      "Epoch 35/1000 --- Loss: 0.58457\n",
      "Epoch 36/1000 --- Loss: 0.58169\n",
      "Epoch 37/1000 --- Loss: 0.57852\n",
      "Epoch 38/1000 --- Loss: 0.57485\n",
      "Epoch 39/1000 --- Loss: 0.57187\n",
      "Epoch 40/1000 --- Loss: 0.56895\n",
      "Epoch 41/1000 --- Loss: 0.56558\n",
      "Epoch 42/1000 --- Loss: 0.56259\n",
      "Epoch 43/1000 --- Loss: 0.56003\n",
      "Epoch 44/1000 --- Loss: 0.55692\n",
      "Epoch 45/1000 --- Loss: 0.55397\n",
      "Epoch 46/1000 --- Loss: 0.55098\n",
      "Epoch 47/1000 --- Loss: 0.54825\n",
      "Epoch 48/1000 --- Loss: 0.54512\n",
      "Epoch 49/1000 --- Loss: 0.54283\n",
      "Epoch 50/1000 --- Loss: 0.53966\n",
      "Epoch 51/1000 --- Loss: 0.53694\n",
      "Epoch 52/1000 --- Loss: 0.53446\n",
      "Epoch 53/1000 --- Loss: 0.53176\n",
      "Epoch 54/1000 --- Loss: 0.52888\n",
      "Epoch 55/1000 --- Loss: 0.52611\n",
      "Epoch 56/1000 --- Loss: 0.52411\n",
      "Epoch 57/1000 --- Loss: 0.52176\n",
      "Epoch 58/1000 --- Loss: 0.51919\n",
      "Epoch 59/1000 --- Loss: 0.51693\n",
      "Epoch 60/1000 --- Loss: 0.51430\n",
      "Epoch 61/1000 --- Loss: 0.51184\n",
      "Epoch 62/1000 --- Loss: 0.50948\n",
      "Epoch 63/1000 --- Loss: 0.50719\n",
      "Epoch 64/1000 --- Loss: 0.50498\n",
      "Epoch 65/1000 --- Loss: 0.50330\n",
      "Epoch 66/1000 --- Loss: 0.50115\n",
      "Epoch 67/1000 --- Loss: 0.49918\n",
      "Epoch 68/1000 --- Loss: 0.49713\n",
      "Epoch 69/1000 --- Loss: 0.49556\n",
      "Epoch 70/1000 --- Loss: 0.49344\n",
      "Epoch 71/1000 --- Loss: 0.49177\n",
      "Epoch 72/1000 --- Loss: 0.48976\n",
      "Epoch 73/1000 --- Loss: 0.48865\n",
      "Epoch 74/1000 --- Loss: 0.48674\n",
      "Epoch 75/1000 --- Loss: 0.48484\n",
      "Epoch 76/1000 --- Loss: 0.48296\n",
      "Epoch 77/1000 --- Loss: 0.48115\n",
      "Epoch 78/1000 --- Loss: 0.47952\n",
      "Epoch 79/1000 --- Loss: 0.47796\n",
      "Epoch 80/1000 --- Loss: 0.47638\n",
      "Epoch 81/1000 --- Loss: 0.47483\n",
      "Epoch 82/1000 --- Loss: 0.47305\n",
      "Epoch 83/1000 --- Loss: 0.47189\n",
      "Epoch 84/1000 --- Loss: 0.47014\n",
      "Epoch 85/1000 --- Loss: 0.46810\n",
      "Epoch 86/1000 --- Loss: 0.46698\n",
      "Epoch 87/1000 --- Loss: 0.46540\n",
      "Epoch 88/1000 --- Loss: 0.46387\n",
      "Epoch 89/1000 --- Loss: 0.46241\n",
      "Epoch 90/1000 --- Loss: 0.46097\n",
      "Epoch 91/1000 --- Loss: 0.45935\n",
      "Epoch 92/1000 --- Loss: 0.45783\n",
      "Epoch 93/1000 --- Loss: 0.45633\n",
      "Epoch 94/1000 --- Loss: 0.45526\n",
      "Epoch 95/1000 --- Loss: 0.45396\n",
      "Epoch 96/1000 --- Loss: 0.45257\n",
      "Epoch 97/1000 --- Loss: 0.45118\n",
      "Epoch 98/1000 --- Loss: 0.44933\n",
      "Epoch 99/1000 --- Loss: 0.44853\n",
      "Epoch 100/1000 --- Loss: 0.44714\n",
      "Epoch 101/1000 --- Loss: 0.44572\n",
      "Epoch 102/1000 --- Loss: 0.44470\n",
      "Epoch 103/1000 --- Loss: 0.44322\n",
      "Epoch 104/1000 --- Loss: 0.44168\n",
      "Epoch 105/1000 --- Loss: 0.44054\n",
      "Epoch 106/1000 --- Loss: 0.43935\n",
      "Epoch 107/1000 --- Loss: 0.43839\n",
      "Epoch 108/1000 --- Loss: 0.43730\n",
      "Epoch 109/1000 --- Loss: 0.43628\n",
      "Epoch 110/1000 --- Loss: 0.43484\n",
      "Epoch 111/1000 --- Loss: 0.43330\n",
      "Epoch 112/1000 --- Loss: 0.43256\n",
      "Epoch 113/1000 --- Loss: 0.43154\n",
      "Epoch 114/1000 --- Loss: 0.43039\n",
      "Epoch 115/1000 --- Loss: 0.42929\n",
      "Epoch 116/1000 --- Loss: 0.42848\n",
      "Epoch 117/1000 --- Loss: 0.42720\n",
      "Epoch 118/1000 --- Loss: 0.42636\n",
      "Epoch 119/1000 --- Loss: 0.42478\n",
      "Epoch 120/1000 --- Loss: 0.42347\n",
      "Epoch 121/1000 --- Loss: 0.42323\n",
      "Epoch 122/1000 --- Loss: 0.42181\n",
      "Epoch 123/1000 --- Loss: 0.42071\n",
      "Epoch 124/1000 --- Loss: 0.42016\n",
      "Epoch 125/1000 --- Loss: 0.41926\n",
      "Epoch 126/1000 --- Loss: 0.41804\n",
      "Epoch 127/1000 --- Loss: 0.41680\n",
      "Epoch 128/1000 --- Loss: 0.41607\n",
      "Epoch 129/1000 --- Loss: 0.41523\n",
      "Epoch 130/1000 --- Loss: 0.41413\n",
      "Epoch 131/1000 --- Loss: 0.41329\n",
      "Epoch 132/1000 --- Loss: 0.41213\n",
      "Epoch 133/1000 --- Loss: 0.41169\n",
      "Epoch 134/1000 --- Loss: 0.41084\n",
      "Epoch 135/1000 --- Loss: 0.40988\n",
      "Epoch 136/1000 --- Loss: 0.40887\n",
      "Epoch 137/1000 --- Loss: 0.40824\n",
      "Epoch 138/1000 --- Loss: 0.40723\n",
      "Epoch 139/1000 --- Loss: 0.40682\n",
      "Epoch 140/1000 --- Loss: 0.40569\n",
      "Epoch 141/1000 --- Loss: 0.40545\n",
      "Epoch 142/1000 --- Loss: 0.40432\n",
      "Epoch 143/1000 --- Loss: 0.40318\n",
      "Epoch 144/1000 --- Loss: 0.40248\n",
      "Epoch 145/1000 --- Loss: 0.40223\n",
      "Epoch 146/1000 --- Loss: 0.40157\n",
      "Epoch 147/1000 --- Loss: 0.40092\n",
      "Epoch 148/1000 --- Loss: 0.40008\n",
      "Epoch 149/1000 --- Loss: 0.39936\n",
      "Epoch 150/1000 --- Loss: 0.39844\n",
      "Epoch 151/1000 --- Loss: 0.39783\n",
      "Epoch 152/1000 --- Loss: 0.39649\n",
      "Epoch 153/1000 --- Loss: 0.39624\n",
      "Epoch 154/1000 --- Loss: 0.39551\n",
      "Epoch 155/1000 --- Loss: 0.39487\n",
      "Epoch 156/1000 --- Loss: 0.39415\n",
      "Epoch 157/1000 --- Loss: 0.39371\n",
      "Epoch 158/1000 --- Loss: 0.39297\n",
      "Epoch 159/1000 --- Loss: 0.39189\n",
      "Epoch 160/1000 --- Loss: 0.39179\n",
      "Epoch 161/1000 --- Loss: 0.39068\n",
      "Epoch 162/1000 --- Loss: 0.39046\n",
      "Epoch 163/1000 --- Loss: 0.39023\n",
      "Epoch 164/1000 --- Loss: 0.38896\n",
      "Epoch 165/1000 --- Loss: 0.38889\n",
      "Epoch 166/1000 --- Loss: 0.38741\n",
      "Epoch 167/1000 --- Loss: 0.38742\n",
      "Epoch 168/1000 --- Loss: 0.38716\n",
      "Epoch 169/1000 --- Loss: 0.38651\n",
      "Epoch 170/1000 --- Loss: 0.38565\n",
      "Epoch 171/1000 --- Loss: 0.38507\n",
      "Epoch 172/1000 --- Loss: 0.38503\n",
      "Epoch 173/1000 --- Loss: 0.38423\n",
      "Epoch 174/1000 --- Loss: 0.38402\n",
      "Epoch 175/1000 --- Loss: 0.38330\n",
      "Epoch 176/1000 --- Loss: 0.38257\n",
      "Epoch 177/1000 --- Loss: 0.38272\n",
      "Epoch 178/1000 --- Loss: 0.38244\n",
      "Epoch 179/1000 --- Loss: 0.38130\n",
      "Epoch 180/1000 --- Loss: 0.38085\n",
      "Epoch 181/1000 --- Loss: 0.38001\n",
      "Epoch 182/1000 --- Loss: 0.38018\n",
      "Epoch 183/1000 --- Loss: 0.37939\n",
      "Epoch 184/1000 --- Loss: 0.37903\n",
      "Epoch 185/1000 --- Loss: 0.37833\n",
      "Epoch 186/1000 --- Loss: 0.37777\n",
      "Epoch 187/1000 --- Loss: 0.37731\n",
      "Epoch 188/1000 --- Loss: 0.37749\n",
      "Epoch 189/1000 --- Loss: 0.37660\n",
      "Epoch 190/1000 --- Loss: 0.37681\n",
      "Epoch 191/1000 --- Loss: 0.37578\n",
      "Epoch 192/1000 --- Loss: 0.37579\n",
      "Epoch 193/1000 --- Loss: 0.37490\n",
      "Epoch 194/1000 --- Loss: 0.37424\n",
      "Epoch 195/1000 --- Loss: 0.37420\n",
      "Epoch 196/1000 --- Loss: 0.37382\n",
      "Epoch 197/1000 --- Loss: 0.37325\n",
      "Epoch 198/1000 --- Loss: 0.37283\n",
      "Epoch 199/1000 --- Loss: 0.37202\n",
      "Epoch 200/1000 --- Loss: 0.37240\n",
      "Epoch 201/1000 --- Loss: 0.37171\n",
      "Epoch 202/1000 --- Loss: 0.37182\n",
      "Epoch 203/1000 --- Loss: 0.37156\n",
      "Epoch 204/1000 --- Loss: 0.37113\n",
      "Epoch 205/1000 --- Loss: 0.37122\n",
      "Epoch 206/1000 --- Loss: 0.37045\n",
      "Epoch 207/1000 --- Loss: 0.37000\n",
      "Epoch 208/1000 --- Loss: 0.36913\n",
      "Epoch 209/1000 --- Loss: 0.36904\n",
      "Epoch 210/1000 --- Loss: 0.36923\n",
      "Epoch 211/1000 --- Loss: 0.36896\n",
      "Epoch 212/1000 --- Loss: 0.36845\n",
      "Epoch 213/1000 --- Loss: 0.36778\n",
      "Epoch 214/1000 --- Loss: 0.36820\n",
      "Epoch 215/1000 --- Loss: 0.36737\n",
      "Epoch 216/1000 --- Loss: 0.36670\n",
      "Epoch 217/1000 --- Loss: 0.36629\n",
      "Epoch 218/1000 --- Loss: 0.36661\n",
      "Epoch 219/1000 --- Loss: 0.36615\n",
      "Epoch 220/1000 --- Loss: 0.36618\n",
      "Epoch 221/1000 --- Loss: 0.36567\n",
      "Epoch 222/1000 --- Loss: 0.36553\n",
      "Epoch 223/1000 --- Loss: 0.36489\n",
      "Epoch 224/1000 --- Loss: 0.36453\n",
      "Epoch 225/1000 --- Loss: 0.36438\n",
      "Epoch 226/1000 --- Loss: 0.36388\n",
      "Epoch 227/1000 --- Loss: 0.36460\n",
      "Epoch 228/1000 --- Loss: 0.36334\n",
      "Epoch 229/1000 --- Loss: 0.36307\n",
      "Epoch 230/1000 --- Loss: 0.36343\n",
      "Epoch 231/1000 --- Loss: 0.36307\n",
      "Epoch 232/1000 --- Loss: 0.36280\n",
      "Epoch 233/1000 --- Loss: 0.36307\n",
      "Epoch 234/1000 --- Loss: 0.36264\n",
      "Epoch 235/1000 --- Loss: 0.36227\n",
      "Epoch 236/1000 --- Loss: 0.36123\n",
      "Epoch 237/1000 --- Loss: 0.36102\n",
      "Epoch 238/1000 --- Loss: 0.36149\n",
      "Epoch 239/1000 --- Loss: 0.36186\n",
      "Epoch 240/1000 --- Loss: 0.36057\n",
      "Epoch 241/1000 --- Loss: 0.36054\n",
      "Epoch 242/1000 --- Loss: 0.36096\n",
      "Epoch 243/1000 --- Loss: 0.36085\n",
      "Epoch 244/1000 --- Loss: 0.35974\n",
      "Epoch 245/1000 --- Loss: 0.35939\n",
      "Epoch 246/1000 --- Loss: 0.36009\n",
      "Epoch 247/1000 --- Loss: 0.35939\n",
      "Epoch 248/1000 --- Loss: 0.35975\n",
      "Epoch 249/1000 --- Loss: 0.35981\n",
      "Epoch 250/1000 --- Loss: 0.35879\n",
      "Epoch 251/1000 --- Loss: 0.35875\n",
      "Epoch 252/1000 --- Loss: 0.35819\n",
      "Epoch 253/1000 --- Loss: 0.35792\n",
      "Epoch 254/1000 --- Loss: 0.35827\n",
      "Epoch 255/1000 --- Loss: 0.35812\n",
      "Epoch 256/1000 --- Loss: 0.35833\n",
      "Epoch 257/1000 --- Loss: 0.35748\n",
      "Epoch 258/1000 --- Loss: 0.35736\n",
      "Epoch 259/1000 --- Loss: 0.35691\n",
      "Epoch 260/1000 --- Loss: 0.35664\n",
      "Epoch 261/1000 --- Loss: 0.35724\n",
      "Epoch 262/1000 --- Loss: 0.35618\n",
      "Epoch 263/1000 --- Loss: 0.35689\n",
      "Epoch 264/1000 --- Loss: 0.35652\n",
      "Epoch 265/1000 --- Loss: 0.35583\n",
      "Epoch 266/1000 --- Loss: 0.35627\n",
      "Epoch 267/1000 --- Loss: 0.35585\n",
      "Epoch 268/1000 --- Loss: 0.35513\n",
      "Epoch 269/1000 --- Loss: 0.35555\n",
      "Epoch 270/1000 --- Loss: 0.35622\n",
      "Epoch 271/1000 --- Loss: 0.35499\n",
      "Epoch 272/1000 --- Loss: 0.35566\n",
      "Epoch 273/1000 --- Loss: 0.35451\n",
      "Epoch 274/1000 --- Loss: 0.35475\n",
      "Epoch 275/1000 --- Loss: 0.35481\n",
      "Epoch 276/1000 --- Loss: 0.35501\n",
      "Epoch 277/1000 --- Loss: 0.35474\n",
      "Epoch 278/1000 --- Loss: 0.35506\n",
      "Epoch 279/1000 --- Loss: 0.35391\n",
      "Epoch 280/1000 --- Loss: 0.35449\n",
      "Epoch 281/1000 --- Loss: 0.35430\n",
      "Epoch 282/1000 --- Loss: 0.35370\n",
      "Epoch 283/1000 --- Loss: 0.35400\n",
      "Epoch 284/1000 --- Loss: 0.35446\n",
      "Epoch 285/1000 --- Loss: 0.35375\n",
      "Epoch 286/1000 --- Loss: 0.35396\n",
      "Epoch 287/1000 --- Loss: 0.35297\n",
      "Epoch 288/1000 --- Loss: 0.35323\n",
      "Epoch 289/1000 --- Loss: 0.35380\n",
      "Epoch 290/1000 --- Loss: 0.35255\n",
      "Epoch 291/1000 --- Loss: 0.35292\n",
      "Epoch 292/1000 --- Loss: 0.35285\n",
      "Epoch 293/1000 --- Loss: 0.35174\n",
      "Epoch 294/1000 --- Loss: 0.35279\n",
      "Epoch 295/1000 --- Loss: 0.35218\n",
      "Epoch 296/1000 --- Loss: 0.35268\n",
      "Epoch 297/1000 --- Loss: 0.35277\n",
      "Epoch 298/1000 --- Loss: 0.35219\n",
      "Epoch 299/1000 --- Loss: 0.35182\n",
      "Epoch 300/1000 --- Loss: 0.35213\n",
      "Epoch 301/1000 --- Loss: 0.35192\n",
      "Epoch 302/1000 --- Loss: 0.35150\n",
      "Epoch 303/1000 --- Loss: 0.35161\n",
      "Epoch 304/1000 --- Loss: 0.35246\n",
      "Epoch 305/1000 --- Loss: 0.35171\n",
      "Epoch 306/1000 --- Loss: 0.35078\n",
      "Epoch 307/1000 --- Loss: 0.35120\n",
      "Epoch 308/1000 --- Loss: 0.35195\n",
      "Epoch 309/1000 --- Loss: 0.35098\n",
      "Epoch 310/1000 --- Loss: 0.35066\n",
      "Epoch 311/1000 --- Loss: 0.35078\n",
      "Epoch 312/1000 --- Loss: 0.35090\n",
      "Epoch 313/1000 --- Loss: 0.35093\n",
      "Epoch 314/1000 --- Loss: 0.35159\n",
      "Epoch 315/1000 --- Loss: 0.35067\n",
      "Epoch 316/1000 --- Loss: 0.35125\n",
      "Epoch 317/1000 --- Loss: 0.35122\n",
      "Epoch 318/1000 --- Loss: 0.35086\n",
      "Epoch 319/1000 --- Loss: 0.34926\n",
      "Epoch 320/1000 --- Loss: 0.34965\n",
      "Epoch 321/1000 --- Loss: 0.34976\n",
      "Epoch 322/1000 --- Loss: 0.35075\n",
      "Epoch 323/1000 --- Loss: 0.34980\n",
      "Epoch 324/1000 --- Loss: 0.34951\n",
      "Epoch 325/1000 --- Loss: 0.34940\n",
      "Epoch 326/1000 --- Loss: 0.34972\n",
      "Epoch 327/1000 --- Loss: 0.34885\n",
      "Epoch 328/1000 --- Loss: 0.34880\n",
      "Epoch 329/1000 --- Loss: 0.34997\n",
      "Epoch 330/1000 --- Loss: 0.34939\n",
      "Epoch 331/1000 --- Loss: 0.34894\n",
      "Epoch 332/1000 --- Loss: 0.34912\n",
      "Epoch 333/1000 --- Loss: 0.35006\n",
      "Epoch 334/1000 --- Loss: 0.34922\n",
      "Epoch 335/1000 --- Loss: 0.34893\n",
      "Epoch 336/1000 --- Loss: 0.34910\n",
      "Epoch 337/1000 --- Loss: 0.34900\n",
      "Epoch 338/1000 --- Loss: 0.34897\n",
      "Epoch 339/1000 --- Loss: 0.34896\n",
      "Epoch 340/1000 --- Loss: 0.34839\n",
      "Epoch 341/1000 --- Loss: 0.34896\n",
      "Epoch 342/1000 --- Loss: 0.34970\n",
      "Epoch 343/1000 --- Loss: 0.34814\n",
      "Epoch 344/1000 --- Loss: 0.34845\n",
      "Epoch 345/1000 --- Loss: 0.34894\n",
      "Epoch 346/1000 --- Loss: 0.34828\n",
      "Epoch 347/1000 --- Loss: 0.34830\n",
      "Epoch 348/1000 --- Loss: 0.34836\n",
      "Epoch 349/1000 --- Loss: 0.34886\n",
      "Epoch 350/1000 --- Loss: 0.34768\n",
      "Epoch 351/1000 --- Loss: 0.34838\n",
      "Epoch 352/1000 --- Loss: 0.34835\n",
      "Epoch 353/1000 --- Loss: 0.34828\n",
      "Epoch 354/1000 --- Loss: 0.34782\n",
      "Epoch 355/1000 --- Loss: 0.34839\n",
      "Epoch 356/1000 --- Loss: 0.34827\n",
      "Epoch 357/1000 --- Loss: 0.34850\n",
      "Epoch 358/1000 --- Loss: 0.34790\n",
      "Epoch 359/1000 --- Loss: 0.34822\n",
      "Epoch 360/1000 --- Loss: 0.34795\n",
      "Epoch 361/1000 --- Loss: 0.34749\n",
      "Epoch 362/1000 --- Loss: 0.34733\n",
      "Epoch 363/1000 --- Loss: 0.34766\n",
      "Epoch 364/1000 --- Loss: 0.34669\n",
      "Epoch 365/1000 --- Loss: 0.34790\n",
      "Epoch 366/1000 --- Loss: 0.34680\n",
      "Epoch 367/1000 --- Loss: 0.34774\n",
      "Epoch 368/1000 --- Loss: 0.34746\n",
      "Epoch 369/1000 --- Loss: 0.34715\n",
      "Epoch 370/1000 --- Loss: 0.34742\n",
      "Epoch 371/1000 --- Loss: 0.34720\n",
      "Epoch 372/1000 --- Loss: 0.34692\n",
      "Epoch 373/1000 --- Loss: 0.34797\n",
      "Epoch 374/1000 --- Loss: 0.34771\n",
      "Epoch 375/1000 --- Loss: 0.34768\n",
      "Epoch 376/1000 --- Loss: 0.34700\n",
      "Epoch 377/1000 --- Loss: 0.34668\n",
      "Epoch 378/1000 --- Loss: 0.34722\n",
      "Epoch 379/1000 --- Loss: 0.34624\n",
      "Epoch 380/1000 --- Loss: 0.34685\n",
      "Epoch 381/1000 --- Loss: 0.34696\n",
      "Epoch 382/1000 --- Loss: 0.34667\n",
      "Epoch 383/1000 --- Loss: 0.34718\n",
      "Epoch 384/1000 --- Loss: 0.34648\n",
      "Epoch 385/1000 --- Loss: 0.34607\n",
      "Epoch 386/1000 --- Loss: 0.34555\n",
      "Epoch 387/1000 --- Loss: 0.34682\n",
      "Epoch 388/1000 --- Loss: 0.34684\n",
      "Epoch 389/1000 --- Loss: 0.34619\n",
      "Epoch 390/1000 --- Loss: 0.34746\n",
      "Epoch 391/1000 --- Loss: 0.34728\n",
      "Epoch 392/1000 --- Loss: 0.34675\n",
      "Epoch 393/1000 --- Loss: 0.34639\n",
      "Epoch 394/1000 --- Loss: 0.34643\n",
      "Epoch 395/1000 --- Loss: 0.34624\n",
      "Epoch 396/1000 --- Loss: 0.34656\n",
      "Epoch 397/1000 --- Loss: 0.34607\n",
      "Epoch 398/1000 --- Loss: 0.34684\n",
      "Epoch 399/1000 --- Loss: 0.34579\n",
      "Epoch 400/1000 --- Loss: 0.34677\n",
      "Epoch 401/1000 --- Loss: 0.34536\n",
      "Epoch 402/1000 --- Loss: 0.34555\n",
      "Epoch 403/1000 --- Loss: 0.34696\n",
      "Epoch 404/1000 --- Loss: 0.34587\n",
      "Epoch 405/1000 --- Loss: 0.34603\n",
      "Epoch 406/1000 --- Loss: 0.34629\n",
      "Epoch 407/1000 --- Loss: 0.34585\n",
      "Epoch 408/1000 --- Loss: 0.34595\n",
      "Epoch 409/1000 --- Loss: 0.34578\n",
      "Epoch 410/1000 --- Loss: 0.34606\n",
      "Epoch 411/1000 --- Loss: 0.34636\n",
      "Epoch 412/1000 --- Loss: 0.34551\n",
      "Epoch 413/1000 --- Loss: 0.34624\n",
      "Epoch 414/1000 --- Loss: 0.34606\n",
      "Epoch 415/1000 --- Loss: 0.34594\n",
      "Epoch 416/1000 --- Loss: 0.34559\n",
      "Epoch 417/1000 --- Loss: 0.34530\n",
      "Epoch 418/1000 --- Loss: 0.34628\n",
      "Epoch 419/1000 --- Loss: 0.34663\n",
      "Epoch 420/1000 --- Loss: 0.34570\n",
      "Epoch 421/1000 --- Loss: 0.34567\n",
      "Epoch 422/1000 --- Loss: 0.34555\n",
      "Epoch 423/1000 --- Loss: 0.34554\n",
      "Epoch 424/1000 --- Loss: 0.34631\n",
      "Epoch 425/1000 --- Loss: 0.34485\n",
      "Epoch 426/1000 --- Loss: 0.34538\n",
      "Epoch 427/1000 --- Loss: 0.34527\n",
      "Epoch 428/1000 --- Loss: 0.34504\n",
      "Epoch 429/1000 --- Loss: 0.34544\n",
      "Epoch 430/1000 --- Loss: 0.34429\n",
      "Epoch 431/1000 --- Loss: 0.34554\n",
      "Epoch 432/1000 --- Loss: 0.34517\n",
      "Epoch 433/1000 --- Loss: 0.34490\n",
      "Epoch 434/1000 --- Loss: 0.34571\n",
      "Epoch 435/1000 --- Loss: 0.34506\n",
      "Epoch 436/1000 --- Loss: 0.34484\n",
      "Epoch 437/1000 --- Loss: 0.34597\n",
      "Epoch 438/1000 --- Loss: 0.34483\n",
      "Epoch 439/1000 --- Loss: 0.34521\n",
      "Epoch 440/1000 --- Loss: 0.34439\n",
      "Epoch 441/1000 --- Loss: 0.34577\n",
      "Epoch 442/1000 --- Loss: 0.34411\n",
      "Epoch 443/1000 --- Loss: 0.34539\n",
      "Epoch 444/1000 --- Loss: 0.34542\n",
      "Epoch 445/1000 --- Loss: 0.34441\n",
      "Epoch 446/1000 --- Loss: 0.34582\n",
      "Epoch 447/1000 --- Loss: 0.34587\n",
      "Epoch 448/1000 --- Loss: 0.34515\n",
      "Epoch 449/1000 --- Loss: 0.34496\n",
      "Epoch 450/1000 --- Loss: 0.34490\n",
      "Epoch 451/1000 --- Loss: 0.34516\n",
      "Epoch 452/1000 --- Loss: 0.34527\n",
      "Epoch 453/1000 --- Loss: 0.34509\n",
      "Epoch 454/1000 --- Loss: 0.34496\n",
      "Epoch 455/1000 --- Loss: 0.34508\n",
      "Epoch 456/1000 --- Loss: 0.34443\n",
      "Epoch 457/1000 --- Loss: 0.34458\n",
      "Epoch 458/1000 --- Loss: 0.34441\n",
      "Epoch 459/1000 --- Loss: 0.34595\n",
      "Epoch 460/1000 --- Loss: 0.34392\n",
      "Epoch 461/1000 --- Loss: 0.34505\n",
      "Epoch 462/1000 --- Loss: 0.34515\n",
      "Epoch 463/1000 --- Loss: 0.34519\n",
      "Epoch 464/1000 --- Loss: 0.34545\n",
      "Epoch 465/1000 --- Loss: 0.34513\n",
      "Epoch 466/1000 --- Loss: 0.34468\n",
      "Epoch 467/1000 --- Loss: 0.34486\n",
      "Epoch 468/1000 --- Loss: 0.34530\n",
      "Epoch 469/1000 --- Loss: 0.34464\n",
      "Epoch 470/1000 --- Loss: 0.34483\n",
      "Epoch 471/1000 --- Loss: 0.34357\n",
      "Epoch 472/1000 --- Loss: 0.34442\n",
      "Epoch 473/1000 --- Loss: 0.34481\n",
      "Epoch 474/1000 --- Loss: 0.34502\n",
      "Epoch 475/1000 --- Loss: 0.34485\n",
      "Epoch 476/1000 --- Loss: 0.34398\n",
      "Epoch 477/1000 --- Loss: 0.34428\n",
      "Epoch 478/1000 --- Loss: 0.34437\n",
      "Epoch 479/1000 --- Loss: 0.34470\n",
      "Epoch 480/1000 --- Loss: 0.34298\n",
      "Epoch 481/1000 --- Loss: 0.34487\n",
      "Epoch 482/1000 --- Loss: 0.34479\n",
      "Epoch 483/1000 --- Loss: 0.34429\n",
      "Epoch 484/1000 --- Loss: 0.34508\n",
      "Epoch 485/1000 --- Loss: 0.34382\n",
      "Epoch 486/1000 --- Loss: 0.34442\n",
      "Epoch 487/1000 --- Loss: 0.34377\n",
      "Epoch 488/1000 --- Loss: 0.34468\n",
      "Epoch 489/1000 --- Loss: 0.34495\n",
      "Epoch 490/1000 --- Loss: 0.34484\n",
      "Epoch 491/1000 --- Loss: 0.34445\n",
      "Epoch 492/1000 --- Loss: 0.34423\n",
      "Epoch 493/1000 --- Loss: 0.34458\n",
      "Epoch 494/1000 --- Loss: 0.34445\n",
      "Epoch 495/1000 --- Loss: 0.34556\n",
      "Epoch 496/1000 --- Loss: 0.34440\n",
      "Epoch 497/1000 --- Loss: 0.34385\n",
      "Epoch 498/1000 --- Loss: 0.34433\n",
      "Epoch 499/1000 --- Loss: 0.34459\n",
      "Epoch 500/1000 --- Loss: 0.34435\n",
      "Epoch 501/1000 --- Loss: 0.34366\n",
      "Epoch 502/1000 --- Loss: 0.34364\n",
      "Epoch 503/1000 --- Loss: 0.34481\n",
      "Epoch 504/1000 --- Loss: 0.34395\n",
      "Epoch 505/1000 --- Loss: 0.34390\n",
      "Epoch 506/1000 --- Loss: 0.34476\n",
      "Epoch 507/1000 --- Loss: 0.34480\n",
      "Epoch 508/1000 --- Loss: 0.34422\n",
      "Epoch 509/1000 --- Loss: 0.34444\n",
      "Epoch 510/1000 --- Loss: 0.34471\n",
      "Epoch 511/1000 --- Loss: 0.34428\n",
      "Epoch 512/1000 --- Loss: 0.34428\n",
      "Epoch 513/1000 --- Loss: 0.34397\n",
      "Epoch 514/1000 --- Loss: 0.34440\n",
      "Epoch 515/1000 --- Loss: 0.34466\n",
      "Epoch 516/1000 --- Loss: 0.34359\n",
      "Epoch 517/1000 --- Loss: 0.34460\n",
      "Epoch 518/1000 --- Loss: 0.34415\n",
      "Epoch 519/1000 --- Loss: 0.34375\n",
      "Epoch 520/1000 --- Loss: 0.34438\n",
      "Epoch 521/1000 --- Loss: 0.34297\n",
      "Epoch 522/1000 --- Loss: 0.34390\n",
      "Epoch 523/1000 --- Loss: 0.34483\n",
      "Epoch 524/1000 --- Loss: 0.34396\n",
      "Epoch 525/1000 --- Loss: 0.34468\n",
      "Epoch 526/1000 --- Loss: 0.34452\n",
      "Epoch 527/1000 --- Loss: 0.34391\n",
      "Epoch 528/1000 --- Loss: 0.34422\n",
      "Epoch 529/1000 --- Loss: 0.34420\n",
      "Epoch 530/1000 --- Loss: 0.34399\n",
      "Epoch 531/1000 --- Loss: 0.34334\n",
      "Epoch 532/1000 --- Loss: 0.34472\n",
      "Epoch 533/1000 --- Loss: 0.34400\n",
      "Epoch 534/1000 --- Loss: 0.34322\n",
      "Epoch 535/1000 --- Loss: 0.34388\n",
      "Epoch 536/1000 --- Loss: 0.34447\n",
      "Epoch 537/1000 --- Loss: 0.34388\n",
      "Epoch 538/1000 --- Loss: 0.34415\n",
      "Epoch 539/1000 --- Loss: 0.34428\n",
      "Epoch 540/1000 --- Loss: 0.34328\n",
      "Epoch 541/1000 --- Loss: 0.34544\n",
      "Epoch 542/1000 --- Loss: 0.34373\n",
      "Epoch 543/1000 --- Loss: 0.34370\n",
      "Epoch 544/1000 --- Loss: 0.34419\n",
      "Epoch 545/1000 --- Loss: 0.34491\n",
      "Epoch 546/1000 --- Loss: 0.34372\n",
      "Epoch 547/1000 --- Loss: 0.34371\n",
      "Epoch 548/1000 --- Loss: 0.34447\n",
      "Epoch 549/1000 --- Loss: 0.34374\n",
      "Epoch 550/1000 --- Loss: 0.34383\n",
      "Epoch 551/1000 --- Loss: 0.34371\n",
      "Epoch 552/1000 --- Loss: 0.34351\n",
      "Epoch 553/1000 --- Loss: 0.34422\n",
      "Epoch 554/1000 --- Loss: 0.34404\n",
      "Epoch 555/1000 --- Loss: 0.34451\n",
      "Epoch 556/1000 --- Loss: 0.34355\n",
      "Epoch 557/1000 --- Loss: 0.34384\n",
      "Epoch 558/1000 --- Loss: 0.34443\n",
      "Epoch 559/1000 --- Loss: 0.34369\n",
      "Epoch 560/1000 --- Loss: 0.34287\n",
      "Epoch 561/1000 --- Loss: 0.34380\n",
      "Epoch 562/1000 --- Loss: 0.34420\n",
      "Epoch 563/1000 --- Loss: 0.34358\n",
      "Epoch 564/1000 --- Loss: 0.34397\n",
      "Epoch 565/1000 --- Loss: 0.34393\n",
      "Epoch 566/1000 --- Loss: 0.34432\n",
      "Epoch 567/1000 --- Loss: 0.34406\n",
      "Epoch 568/1000 --- Loss: 0.34367\n",
      "Epoch 569/1000 --- Loss: 0.34368\n",
      "Epoch 570/1000 --- Loss: 0.34409\n",
      "Epoch 571/1000 --- Loss: 0.34438\n",
      "Epoch 572/1000 --- Loss: 0.34427\n",
      "Epoch 573/1000 --- Loss: 0.34411\n",
      "Epoch 574/1000 --- Loss: 0.34455\n",
      "Epoch 575/1000 --- Loss: 0.34383\n",
      "Epoch 576/1000 --- Loss: 0.34372\n",
      "Epoch 577/1000 --- Loss: 0.34399\n",
      "Epoch 578/1000 --- Loss: 0.34339\n",
      "Epoch 579/1000 --- Loss: 0.34399\n",
      "Epoch 580/1000 --- Loss: 0.34312\n",
      "Epoch 581/1000 --- Loss: 0.34377\n",
      "Epoch 582/1000 --- Loss: 0.34362\n",
      "Epoch 583/1000 --- Loss: 0.34409\n",
      "Epoch 584/1000 --- Loss: 0.34391\n",
      "Epoch 585/1000 --- Loss: 0.34410\n",
      "Epoch 586/1000 --- Loss: 0.34499\n",
      "Epoch 587/1000 --- Loss: 0.34358\n",
      "Epoch 588/1000 --- Loss: 0.34284\n",
      "Epoch 589/1000 --- Loss: 0.34373\n",
      "Epoch 590/1000 --- Loss: 0.34403\n",
      "Epoch 591/1000 --- Loss: 0.34305\n",
      "Epoch 592/1000 --- Loss: 0.34336\n",
      "Epoch 593/1000 --- Loss: 0.34282\n",
      "Epoch 594/1000 --- Loss: 0.34373\n",
      "Epoch 595/1000 --- Loss: 0.34408\n",
      "Epoch 596/1000 --- Loss: 0.34353\n",
      "Epoch 597/1000 --- Loss: 0.34381\n",
      "Epoch 598/1000 --- Loss: 0.34385\n",
      "Epoch 599/1000 --- Loss: 0.34340\n",
      "Epoch 600/1000 --- Loss: 0.34348\n",
      "Epoch 601/1000 --- Loss: 0.34419\n",
      "Epoch 602/1000 --- Loss: 0.34348\n",
      "Epoch 603/1000 --- Loss: 0.34359\n",
      "Epoch 604/1000 --- Loss: 0.34385\n",
      "Epoch 605/1000 --- Loss: 0.34391\n",
      "Epoch 606/1000 --- Loss: 0.34325\n",
      "Epoch 607/1000 --- Loss: 0.34328\n",
      "Epoch 608/1000 --- Loss: 0.34340\n",
      "Epoch 609/1000 --- Loss: 0.34390\n",
      "Epoch 610/1000 --- Loss: 0.34366\n",
      "Epoch 611/1000 --- Loss: 0.34321\n",
      "Epoch 612/1000 --- Loss: 0.34304\n",
      "Epoch 613/1000 --- Loss: 0.34398\n",
      "Epoch 614/1000 --- Loss: 0.34377\n",
      "Epoch 615/1000 --- Loss: 0.34321\n",
      "Epoch 616/1000 --- Loss: 0.34327\n",
      "Epoch 617/1000 --- Loss: 0.34280\n",
      "Epoch 618/1000 --- Loss: 0.34425\n",
      "Epoch 619/1000 --- Loss: 0.34324\n",
      "Epoch 620/1000 --- Loss: 0.34427\n",
      "Epoch 621/1000 --- Loss: 0.34342\n",
      "Epoch 622/1000 --- Loss: 0.34322\n",
      "Epoch 623/1000 --- Loss: 0.34348\n",
      "Epoch 624/1000 --- Loss: 0.34408\n",
      "Epoch 625/1000 --- Loss: 0.34282\n",
      "Epoch 626/1000 --- Loss: 0.34374\n",
      "Epoch 627/1000 --- Loss: 0.34349\n",
      "Epoch 628/1000 --- Loss: 0.34365\n",
      "Epoch 629/1000 --- Loss: 0.34373\n",
      "Epoch 630/1000 --- Loss: 0.34347\n",
      "Epoch 631/1000 --- Loss: 0.34359\n",
      "Epoch 632/1000 --- Loss: 0.34246\n",
      "Epoch 633/1000 --- Loss: 0.34348\n",
      "Epoch 634/1000 --- Loss: 0.34357\n",
      "Epoch 635/1000 --- Loss: 0.34387\n",
      "Epoch 636/1000 --- Loss: 0.34332\n",
      "Epoch 637/1000 --- Loss: 0.34286\n",
      "Epoch 638/1000 --- Loss: 0.34331\n",
      "Epoch 639/1000 --- Loss: 0.34316\n",
      "Epoch 640/1000 --- Loss: 0.34379\n",
      "Epoch 641/1000 --- Loss: 0.34370\n",
      "Epoch 642/1000 --- Loss: 0.34331\n",
      "Epoch 643/1000 --- Loss: 0.34356\n",
      "Epoch 644/1000 --- Loss: 0.34359\n",
      "Epoch 645/1000 --- Loss: 0.34328\n",
      "Epoch 646/1000 --- Loss: 0.34276\n",
      "Epoch 647/1000 --- Loss: 0.34294\n",
      "Epoch 648/1000 --- Loss: 0.34351\n",
      "Epoch 649/1000 --- Loss: 0.34309\n",
      "Epoch 650/1000 --- Loss: 0.34268\n",
      "Epoch 651/1000 --- Loss: 0.34344\n",
      "Epoch 652/1000 --- Loss: 0.34310\n",
      "Epoch 653/1000 --- Loss: 0.34309\n",
      "Epoch 654/1000 --- Loss: 0.34312\n",
      "Epoch 655/1000 --- Loss: 0.34313\n",
      "Epoch 656/1000 --- Loss: 0.34339\n",
      "Epoch 657/1000 --- Loss: 0.34350\n",
      "Epoch 658/1000 --- Loss: 0.34287\n",
      "Epoch 659/1000 --- Loss: 0.34330\n",
      "Epoch 660/1000 --- Loss: 0.34318\n",
      "Epoch 661/1000 --- Loss: 0.34376\n",
      "Epoch 662/1000 --- Loss: 0.34402\n",
      "Epoch 663/1000 --- Loss: 0.34356\n",
      "Epoch 664/1000 --- Loss: 0.34337\n",
      "Epoch 665/1000 --- Loss: 0.34411\n",
      "Epoch 666/1000 --- Loss: 0.34357\n",
      "Epoch 667/1000 --- Loss: 0.34360\n",
      "Epoch 668/1000 --- Loss: 0.34266\n",
      "Epoch 669/1000 --- Loss: 0.34358\n",
      "Epoch 670/1000 --- Loss: 0.34310\n",
      "Epoch 671/1000 --- Loss: 0.34359\n",
      "Epoch 672/1000 --- Loss: 0.34356\n",
      "Epoch 673/1000 --- Loss: 0.34295\n",
      "Epoch 674/1000 --- Loss: 0.34296\n",
      "Epoch 675/1000 --- Loss: 0.34275\n",
      "Epoch 676/1000 --- Loss: 0.34292\n",
      "Epoch 677/1000 --- Loss: 0.34265\n",
      "Epoch 678/1000 --- Loss: 0.34349\n",
      "Epoch 679/1000 --- Loss: 0.34301\n",
      "Epoch 680/1000 --- Loss: 0.34318\n",
      "Epoch 681/1000 --- Loss: 0.34380\n",
      "Epoch 682/1000 --- Loss: 0.34232\n",
      "Epoch 683/1000 --- Loss: 0.34382\n",
      "Epoch 684/1000 --- Loss: 0.34289\n",
      "Epoch 685/1000 --- Loss: 0.34339\n",
      "Epoch 686/1000 --- Loss: 0.34289\n",
      "Epoch 687/1000 --- Loss: 0.34384\n",
      "Epoch 688/1000 --- Loss: 0.34352\n",
      "Epoch 689/1000 --- Loss: 0.34345\n",
      "Epoch 690/1000 --- Loss: 0.34299\n",
      "Epoch 691/1000 --- Loss: 0.34282\n",
      "Epoch 692/1000 --- Loss: 0.34342\n",
      "Epoch 693/1000 --- Loss: 0.34371\n",
      "Epoch 694/1000 --- Loss: 0.34367\n",
      "Epoch 695/1000 --- Loss: 0.34359\n",
      "Epoch 696/1000 --- Loss: 0.34366\n",
      "Epoch 697/1000 --- Loss: 0.34262\n",
      "Epoch 698/1000 --- Loss: 0.34247\n",
      "Epoch 699/1000 --- Loss: 0.34265\n",
      "Epoch 700/1000 --- Loss: 0.34252\n",
      "Epoch 701/1000 --- Loss: 0.34297\n",
      "Epoch 702/1000 --- Loss: 0.34350\n",
      "Epoch 703/1000 --- Loss: 0.34285\n",
      "Epoch 704/1000 --- Loss: 0.34344\n",
      "Epoch 705/1000 --- Loss: 0.34347\n",
      "Epoch 706/1000 --- Loss: 0.34257\n",
      "Epoch 707/1000 --- Loss: 0.34320\n",
      "Epoch 708/1000 --- Loss: 0.34359\n",
      "Epoch 709/1000 --- Loss: 0.34263\n",
      "Epoch 710/1000 --- Loss: 0.34364\n",
      "Epoch 711/1000 --- Loss: 0.34323\n",
      "Epoch 712/1000 --- Loss: 0.34330\n",
      "Epoch 713/1000 --- Loss: 0.34287\n",
      "Epoch 714/1000 --- Loss: 0.34318\n",
      "Epoch 715/1000 --- Loss: 0.34334\n",
      "Epoch 716/1000 --- Loss: 0.34374\n",
      "Epoch 717/1000 --- Loss: 0.34387\n",
      "Epoch 718/1000 --- Loss: 0.34319\n",
      "Epoch 719/1000 --- Loss: 0.34290\n",
      "Epoch 720/1000 --- Loss: 0.34278\n",
      "Epoch 721/1000 --- Loss: 0.34276\n",
      "Epoch 722/1000 --- Loss: 0.34287\n",
      "Epoch 723/1000 --- Loss: 0.34245\n",
      "Epoch 724/1000 --- Loss: 0.34236\n",
      "Epoch 725/1000 --- Loss: 0.34387\n",
      "Epoch 726/1000 --- Loss: 0.34318\n",
      "Epoch 727/1000 --- Loss: 0.34351\n",
      "Epoch 728/1000 --- Loss: 0.34368\n",
      "Epoch 729/1000 --- Loss: 0.34385\n",
      "Epoch 730/1000 --- Loss: 0.34315\n",
      "Epoch 731/1000 --- Loss: 0.34331\n",
      "Epoch 732/1000 --- Loss: 0.34256\n",
      "Epoch 733/1000 --- Loss: 0.34288\n",
      "Epoch 734/1000 --- Loss: 0.34318\n",
      "Epoch 735/1000 --- Loss: 0.34249\n",
      "Epoch 736/1000 --- Loss: 0.34320\n",
      "Epoch 737/1000 --- Loss: 0.34327\n",
      "Epoch 738/1000 --- Loss: 0.34302\n",
      "Epoch 739/1000 --- Loss: 0.34382\n",
      "Epoch 740/1000 --- Loss: 0.34328\n",
      "Epoch 741/1000 --- Loss: 0.34312\n",
      "Epoch 742/1000 --- Loss: 0.34199\n",
      "Epoch 743/1000 --- Loss: 0.34234\n",
      "Epoch 744/1000 --- Loss: 0.34319\n",
      "Epoch 745/1000 --- Loss: 0.34335\n",
      "Epoch 746/1000 --- Loss: 0.34365\n",
      "Epoch 747/1000 --- Loss: 0.34329\n",
      "Epoch 748/1000 --- Loss: 0.34273\n",
      "Epoch 749/1000 --- Loss: 0.34265\n",
      "Epoch 750/1000 --- Loss: 0.34351\n",
      "Epoch 751/1000 --- Loss: 0.34273\n",
      "Epoch 752/1000 --- Loss: 0.34409\n",
      "Epoch 753/1000 --- Loss: 0.34385\n",
      "Epoch 754/1000 --- Loss: 0.34342\n",
      "Epoch 755/1000 --- Loss: 0.34291\n",
      "Epoch 756/1000 --- Loss: 0.34314\n",
      "Epoch 757/1000 --- Loss: 0.34359\n",
      "Epoch 758/1000 --- Loss: 0.34325\n",
      "Epoch 759/1000 --- Loss: 0.34261\n",
      "Epoch 760/1000 --- Loss: 0.34298\n",
      "Epoch 761/1000 --- Loss: 0.34336\n",
      "Epoch 762/1000 --- Loss: 0.34301\n",
      "Epoch 763/1000 --- Loss: 0.34338\n",
      "Epoch 764/1000 --- Loss: 0.34283\n",
      "Epoch 765/1000 --- Loss: 0.34364\n",
      "Epoch 766/1000 --- Loss: 0.34276\n",
      "Epoch 767/1000 --- Loss: 0.34268\n",
      "Epoch 768/1000 --- Loss: 0.34336\n",
      "Epoch 769/1000 --- Loss: 0.34303\n",
      "Epoch 770/1000 --- Loss: 0.34262\n",
      "Epoch 771/1000 --- Loss: 0.34398\n",
      "Epoch 772/1000 --- Loss: 0.34360\n",
      "Epoch 773/1000 --- Loss: 0.34254\n",
      "Epoch 774/1000 --- Loss: 0.34409\n",
      "Epoch 775/1000 --- Loss: 0.34352\n",
      "Epoch 776/1000 --- Loss: 0.34312\n",
      "Epoch 777/1000 --- Loss: 0.34331\n",
      "Epoch 778/1000 --- Loss: 0.34327\n",
      "Epoch 779/1000 --- Loss: 0.34356\n",
      "Epoch 780/1000 --- Loss: 0.34374\n",
      "Epoch 781/1000 --- Loss: 0.34328\n",
      "Epoch 782/1000 --- Loss: 0.34315\n",
      "Epoch 783/1000 --- Loss: 0.34360\n",
      "Epoch 784/1000 --- Loss: 0.34285\n",
      "Epoch 785/1000 --- Loss: 0.34307\n",
      "Epoch 786/1000 --- Loss: 0.34257\n",
      "Epoch 787/1000 --- Loss: 0.34322\n",
      "Epoch 788/1000 --- Loss: 0.34255\n",
      "Epoch 789/1000 --- Loss: 0.34290\n",
      "Epoch 790/1000 --- Loss: 0.34283\n",
      "Epoch 791/1000 --- Loss: 0.34281\n",
      "Epoch 792/1000 --- Loss: 0.34410\n",
      "Epoch 793/1000 --- Loss: 0.34297\n",
      "Epoch 794/1000 --- Loss: 0.34261\n",
      "Epoch 795/1000 --- Loss: 0.34357\n",
      "Epoch 796/1000 --- Loss: 0.34238\n",
      "Epoch 797/1000 --- Loss: 0.34346\n",
      "Epoch 798/1000 --- Loss: 0.34326\n",
      "Epoch 799/1000 --- Loss: 0.34270\n",
      "Epoch 800/1000 --- Loss: 0.34220\n",
      "Epoch 801/1000 --- Loss: 0.34269\n",
      "Epoch 802/1000 --- Loss: 0.34283\n",
      "Epoch 803/1000 --- Loss: 0.34349\n",
      "Epoch 804/1000 --- Loss: 0.34295\n",
      "Epoch 805/1000 --- Loss: 0.34378\n",
      "Epoch 806/1000 --- Loss: 0.34330\n",
      "Epoch 807/1000 --- Loss: 0.34298\n",
      "Epoch 808/1000 --- Loss: 0.34269\n",
      "Epoch 809/1000 --- Loss: 0.34285\n",
      "Epoch 810/1000 --- Loss: 0.34279\n",
      "Epoch 811/1000 --- Loss: 0.34435\n",
      "Epoch 812/1000 --- Loss: 0.34365\n",
      "Epoch 813/1000 --- Loss: 0.34303\n",
      "Epoch 814/1000 --- Loss: 0.34297\n",
      "Epoch 815/1000 --- Loss: 0.34351\n",
      "Epoch 816/1000 --- Loss: 0.34327\n",
      "Epoch 817/1000 --- Loss: 0.34287\n",
      "Epoch 818/1000 --- Loss: 0.34323\n",
      "Epoch 819/1000 --- Loss: 0.34313\n",
      "Epoch 820/1000 --- Loss: 0.34248\n",
      "Epoch 821/1000 --- Loss: 0.34270\n",
      "Epoch 822/1000 --- Loss: 0.34258\n",
      "Epoch 823/1000 --- Loss: 0.34255\n",
      "Epoch 824/1000 --- Loss: 0.34250\n",
      "Epoch 825/1000 --- Loss: 0.34310\n",
      "Epoch 826/1000 --- Loss: 0.34301\n",
      "Epoch 827/1000 --- Loss: 0.34332\n",
      "Epoch 828/1000 --- Loss: 0.34344\n",
      "Epoch 829/1000 --- Loss: 0.34327\n",
      "Epoch 830/1000 --- Loss: 0.34351\n",
      "Epoch 831/1000 --- Loss: 0.34301\n",
      "Epoch 832/1000 --- Loss: 0.34289\n",
      "Epoch 833/1000 --- Loss: 0.34359\n",
      "Epoch 834/1000 --- Loss: 0.34308\n",
      "Epoch 835/1000 --- Loss: 0.34305\n",
      "Epoch 836/1000 --- Loss: 0.34361\n",
      "Epoch 837/1000 --- Loss: 0.34268\n",
      "Epoch 838/1000 --- Loss: 0.34248\n",
      "Epoch 839/1000 --- Loss: 0.34335\n",
      "Epoch 840/1000 --- Loss: 0.34374\n",
      "Epoch 841/1000 --- Loss: 0.34284\n",
      "Epoch 842/1000 --- Loss: 0.34387\n",
      "Epoch 843/1000 --- Loss: 0.34301\n",
      "Epoch 844/1000 --- Loss: 0.34357\n",
      "Epoch 845/1000 --- Loss: 0.34356\n",
      "Epoch 846/1000 --- Loss: 0.34224\n",
      "Epoch 847/1000 --- Loss: 0.34269\n",
      "Epoch 848/1000 --- Loss: 0.34315\n",
      "Epoch 849/1000 --- Loss: 0.34301\n",
      "Epoch 850/1000 --- Loss: 0.34291\n",
      "Epoch 851/1000 --- Loss: 0.34317\n",
      "Epoch 852/1000 --- Loss: 0.34220\n",
      "Epoch 853/1000 --- Loss: 0.34278\n",
      "Epoch 854/1000 --- Loss: 0.34234\n",
      "Epoch 855/1000 --- Loss: 0.34336\n",
      "Epoch 856/1000 --- Loss: 0.34322\n",
      "Epoch 857/1000 --- Loss: 0.34286\n",
      "Epoch 858/1000 --- Loss: 0.34268\n",
      "Epoch 859/1000 --- Loss: 0.34296\n",
      "Epoch 860/1000 --- Loss: 0.34293\n",
      "Epoch 861/1000 --- Loss: 0.34295\n",
      "Epoch 862/1000 --- Loss: 0.34358\n",
      "Epoch 863/1000 --- Loss: 0.34318\n",
      "Epoch 864/1000 --- Loss: 0.34391\n",
      "Epoch 865/1000 --- Loss: 0.34382\n",
      "Epoch 866/1000 --- Loss: 0.34312\n",
      "Epoch 867/1000 --- Loss: 0.34266\n",
      "Epoch 868/1000 --- Loss: 0.34325\n",
      "Epoch 869/1000 --- Loss: 0.34313\n",
      "Epoch 870/1000 --- Loss: 0.34335\n",
      "Epoch 871/1000 --- Loss: 0.34284\n",
      "Epoch 872/1000 --- Loss: 0.34206\n",
      "Epoch 873/1000 --- Loss: 0.34322\n",
      "Epoch 874/1000 --- Loss: 0.34257\n",
      "Epoch 875/1000 --- Loss: 0.34281\n",
      "Epoch 876/1000 --- Loss: 0.34313\n",
      "Epoch 877/1000 --- Loss: 0.34273\n",
      "Epoch 878/1000 --- Loss: 0.34297\n",
      "Epoch 879/1000 --- Loss: 0.34327\n",
      "Epoch 880/1000 --- Loss: 0.34361\n",
      "Epoch 881/1000 --- Loss: 0.34293\n",
      "Epoch 882/1000 --- Loss: 0.34250\n",
      "Epoch 883/1000 --- Loss: 0.34295\n",
      "Epoch 884/1000 --- Loss: 0.34295\n",
      "Epoch 885/1000 --- Loss: 0.34278\n",
      "Epoch 886/1000 --- Loss: 0.34246\n",
      "Epoch 887/1000 --- Loss: 0.34320\n",
      "Epoch 888/1000 --- Loss: 0.34348\n",
      "Epoch 889/1000 --- Loss: 0.34356\n",
      "Epoch 890/1000 --- Loss: 0.34350\n",
      "Epoch 891/1000 --- Loss: 0.34250\n",
      "Epoch 892/1000 --- Loss: 0.34371\n",
      "Epoch 893/1000 --- Loss: 0.34345\n",
      "Epoch 894/1000 --- Loss: 0.34282\n",
      "Epoch 895/1000 --- Loss: 0.34329\n",
      "Epoch 896/1000 --- Loss: 0.34371\n",
      "Epoch 897/1000 --- Loss: 0.34234\n",
      "Epoch 898/1000 --- Loss: 0.34341\n",
      "Epoch 899/1000 --- Loss: 0.34331\n",
      "Epoch 900/1000 --- Loss: 0.34270\n",
      "Epoch 901/1000 --- Loss: 0.34334\n",
      "Epoch 902/1000 --- Loss: 0.34268\n",
      "Epoch 903/1000 --- Loss: 0.34355\n",
      "Epoch 904/1000 --- Loss: 0.34263\n",
      "Epoch 905/1000 --- Loss: 0.34389\n",
      "Epoch 906/1000 --- Loss: 0.34270\n",
      "Epoch 907/1000 --- Loss: 0.34233\n",
      "Epoch 908/1000 --- Loss: 0.34324\n",
      "Epoch 909/1000 --- Loss: 0.34372\n",
      "Epoch 910/1000 --- Loss: 0.34206\n",
      "Epoch 911/1000 --- Loss: 0.34330\n",
      "Epoch 912/1000 --- Loss: 0.34392\n",
      "Epoch 913/1000 --- Loss: 0.34323\n",
      "Epoch 914/1000 --- Loss: 0.34274\n",
      "Epoch 915/1000 --- Loss: 0.34264\n",
      "Epoch 916/1000 --- Loss: 0.34322\n",
      "Epoch 917/1000 --- Loss: 0.34366\n",
      "Epoch 918/1000 --- Loss: 0.34235\n",
      "Epoch 919/1000 --- Loss: 0.34242\n",
      "Epoch 920/1000 --- Loss: 0.34232\n",
      "Epoch 921/1000 --- Loss: 0.34285\n",
      "Epoch 922/1000 --- Loss: 0.34355\n",
      "Epoch 923/1000 --- Loss: 0.34279\n",
      "Epoch 924/1000 --- Loss: 0.34282\n",
      "Epoch 925/1000 --- Loss: 0.34247\n",
      "Epoch 926/1000 --- Loss: 0.34285\n",
      "Epoch 927/1000 --- Loss: 0.34289\n",
      "Epoch 928/1000 --- Loss: 0.34348\n",
      "Epoch 929/1000 --- Loss: 0.34400\n",
      "Epoch 930/1000 --- Loss: 0.34419\n",
      "Epoch 931/1000 --- Loss: 0.34305\n",
      "Epoch 932/1000 --- Loss: 0.34213\n",
      "Epoch 933/1000 --- Loss: 0.34320\n",
      "Epoch 934/1000 --- Loss: 0.34331\n",
      "Epoch 935/1000 --- Loss: 0.34239\n",
      "Epoch 936/1000 --- Loss: 0.34287\n",
      "Epoch 937/1000 --- Loss: 0.34297\n",
      "Epoch 938/1000 --- Loss: 0.34345\n",
      "Epoch 939/1000 --- Loss: 0.34248\n",
      "Epoch 940/1000 --- Loss: 0.34308\n",
      "Epoch 941/1000 --- Loss: 0.34320\n",
      "Epoch 942/1000 --- Loss: 0.34322\n",
      "Epoch 943/1000 --- Loss: 0.34332\n",
      "Epoch 944/1000 --- Loss: 0.34239\n",
      "Epoch 945/1000 --- Loss: 0.34273\n",
      "Epoch 946/1000 --- Loss: 0.34240\n",
      "Epoch 947/1000 --- Loss: 0.34342\n",
      "Epoch 948/1000 --- Loss: 0.34318\n",
      "Epoch 949/1000 --- Loss: 0.34225\n",
      "Epoch 950/1000 --- Loss: 0.34365\n",
      "Epoch 951/1000 --- Loss: 0.34286\n",
      "Epoch 952/1000 --- Loss: 0.34287\n",
      "Epoch 953/1000 --- Loss: 0.34251\n",
      "Epoch 954/1000 --- Loss: 0.34290\n",
      "Epoch 955/1000 --- Loss: 0.34292\n",
      "Epoch 956/1000 --- Loss: 0.34325\n",
      "Epoch 957/1000 --- Loss: 0.34273\n",
      "Epoch 958/1000 --- Loss: 0.34272\n",
      "Epoch 959/1000 --- Loss: 0.34344\n",
      "Epoch 960/1000 --- Loss: 0.34339\n",
      "Epoch 961/1000 --- Loss: 0.34274\n",
      "Epoch 962/1000 --- Loss: 0.34350\n",
      "Epoch 963/1000 --- Loss: 0.34316\n",
      "Epoch 964/1000 --- Loss: 0.34371\n",
      "Epoch 965/1000 --- Loss: 0.34361\n",
      "Epoch 966/1000 --- Loss: 0.34278\n",
      "Epoch 967/1000 --- Loss: 0.34311\n",
      "Epoch 968/1000 --- Loss: 0.34302\n",
      "Epoch 969/1000 --- Loss: 0.34272\n",
      "Epoch 970/1000 --- Loss: 0.34370\n",
      "Epoch 971/1000 --- Loss: 0.34222\n",
      "Epoch 972/1000 --- Loss: 0.34302\n",
      "Epoch 973/1000 --- Loss: 0.34298\n",
      "Epoch 974/1000 --- Loss: 0.34280\n",
      "Epoch 975/1000 --- Loss: 0.34366\n",
      "Epoch 976/1000 --- Loss: 0.34247\n",
      "Epoch 977/1000 --- Loss: 0.34327\n",
      "Epoch 978/1000 --- Loss: 0.34295\n",
      "Epoch 979/1000 --- Loss: 0.34283\n",
      "Epoch 980/1000 --- Loss: 0.34314\n",
      "Epoch 981/1000 --- Loss: 0.34264\n",
      "Epoch 982/1000 --- Loss: 0.34324\n",
      "Epoch 983/1000 --- Loss: 0.34315\n",
      "Epoch 984/1000 --- Loss: 0.34248\n",
      "Epoch 985/1000 --- Loss: 0.34315\n",
      "Epoch 986/1000 --- Loss: 0.34302\n",
      "Epoch 987/1000 --- Loss: 0.34244\n",
      "Epoch 988/1000 --- Loss: 0.34249\n",
      "Epoch 989/1000 --- Loss: 0.34304\n",
      "Epoch 990/1000 --- Loss: 0.34305\n",
      "Epoch 991/1000 --- Loss: 0.34275\n",
      "Epoch 992/1000 --- Loss: 0.34261\n",
      "Epoch 993/1000 --- Loss: 0.34251\n",
      "Epoch 994/1000 --- Loss: 0.34312\n",
      "Epoch 995/1000 --- Loss: 0.34281\n",
      "Epoch 996/1000 --- Loss: 0.34318\n",
      "Epoch 997/1000 --- Loss: 0.34285\n",
      "Epoch 998/1000 --- Loss: 0.34233\n",
      "Epoch 999/1000 --- Loss: 0.34272\n",
      "Epoch 1000/1000 --- Loss: 0.34282\n"
     ]
    }
   ],
   "source": [
    "# benchmark training\n",
    "epochs = 1000\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=mvt.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    random_index = torch.randint(len(dataset.xs), (len(dataset.xs), 1))[:, 0]\n",
    "    \n",
    "    mask = ~torch.isnan(dataset.xs[random_index, :, 0]).reshape(-1)\n",
    "    \n",
    "    logits, state = mvt(inputs=dataset.xs[random_index], batch_first=True)\n",
    "    \n",
    "    # compute loss\n",
    "    loss = criterion(\n",
    "        logits.reshape(-1, mvt.n_actions)[mask],\n",
    "        dataset.ys.argmax(dim=-1, keepdim=True).long().reshape(-1)[mask], \n",
    "        )\n",
    "    \n",
    "    # backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs} --- Loss: {loss.item():.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted parameters:\n",
      "\n",
      "Alpha\n",
      "tensor([0.1216, 0.0686, 0.1614, 0.0934, 0.0554, 0.0959, 0.0936, 0.0669, 0.5242,\n",
      "        0.1769, 0.2570, 0.1074, 0.0808, 0.2032, 0.0811, 0.2943, 0.1229, 0.0838,\n",
      "        0.1248, 0.0769, 0.1100, 0.1705, 0.2785, 0.0743, 0.0964, 0.0763, 0.0746,\n",
      "        0.0816, 0.1129, 0.2516, 0.1096, 0.1177, 0.0824, 0.5659, 0.0924, 0.0818,\n",
      "        0.0265, 0.1639, 0.1019, 0.1195, 0.0851, 0.4803, 0.1283, 0.1025, 0.0625,\n",
      "        0.0579, 0.0807, 0.4586, 0.1150, 0.4680, 0.0829, 0.0659, 0.1560, 0.1225,\n",
      "        0.0914, 0.1224, 0.1121, 0.1102, 0.2327, 0.0417, 0.1890, 0.0930, 0.0874,\n",
      "        0.1368, 0.1928, 0.2621, 0.0763, 0.1173, 0.0676, 0.0788, 0.1362, 0.0498,\n",
      "        0.0698, 0.4696, 0.0845, 0.5709, 0.1174, 0.0819, 0.0799, 0.5079, 0.0850,\n",
      "        0.0955, 0.0629, 0.2425, 0.0798, 0.1497, 0.0971, 0.0971, 0.3654, 0.0969,\n",
      "        0.0742, 0.1245, 0.0737, 0.0723, 0.1288, 0.0846, 0.1343, 0.0518, 0.0962,\n",
      "        0.0699, 0.2615, 0.0785, 0.1222, 0.0757, 0.0676, 0.0836, 0.1100, 0.1044,\n",
      "        0.2302, 0.0634, 0.0574, 0.0974, 0.2663, 0.0912, 0.3013, 0.0834, 0.0505,\n",
      "        0.1133, 0.1603, 0.1837, 0.0909, 0.0734, 0.0566, 0.0765, 0.1036, 0.0469,\n",
      "        0.0718, 0.0707, 0.0529, 0.2536, 0.5219, 0.3966, 0.0726, 0.0799, 0.0742,\n",
      "        0.0762, 0.0999, 0.5463, 0.1146, 0.0784, 0.0819, 0.1714, 0.0680, 0.1921,\n",
      "        0.0813, 0.0720, 0.0687, 0.2539, 0.4922, 0.0790, 0.0866, 0.1306, 0.0681,\n",
      "        0.0601, 0.3632, 0.0944, 0.1933, 0.4545, 0.2093, 0.1178, 0.0547, 0.0441,\n",
      "        0.0731, 0.1620, 0.1775, 0.0694, 0.0643, 0.0547, 0.0777, 0.1068, 0.0904,\n",
      "        0.0498, 0.0496, 0.4690, 0.0679, 0.1038, 0.0455, 0.0773, 0.2794, 0.2584,\n",
      "        0.1117, 0.1555, 0.0699, 0.3433, 0.0272, 0.0863, 0.2238, 0.0776, 0.4668,\n",
      "        0.0595, 0.0846, 0.5488, 0.0835, 0.3344, 0.0850, 0.0864, 0.1222, 0.1002,\n",
      "        0.0598, 0.2090, 0.1120, 0.5719, 0.5499, 0.1670, 0.0889, 0.6263, 0.0665,\n",
      "        0.1402, 0.0779, 0.0783, 0.0943, 0.0779, 0.1965, 0.5505, 0.5996, 0.2432,\n",
      "        0.0638, 0.1214, 0.0398, 0.4516, 0.0686, 0.3173, 0.0835, 0.0813, 0.5281,\n",
      "        0.5558, 0.0708, 0.0904, 0.1456, 0.1325, 0.0625, 0.0691, 0.2230, 0.0636,\n",
      "        0.0921, 0.4914, 0.0815, 0.1148, 0.0155, 0.0812, 0.0248, 0.6153, 0.1115,\n",
      "        0.0730, 0.0774, 0.1257, 0.1062, 0.0811, 0.1034, 0.0525],\n",
      "       grad_fn=<ClampBackward1>)\n",
      "\n",
      "Beta\n",
      "tensor([0.3360, 0.3600, 0.4500, 0.4389, 0.3578, 0.4158, 0.4051, 0.3670, 1.3729,\n",
      "        0.3134, 0.3228, 0.4153, 0.3864, 0.3257, 0.3583, 0.6188, 0.4361, 0.4022,\n",
      "        0.4415, 0.4218, 0.3465, 0.4199, 0.4882, 0.3501, 0.3100, 0.3415, 0.3670,\n",
      "        0.3634, 0.4104, 0.5600, 0.3325, 0.4291, 0.2920, 0.4757, 0.4000, 0.3919,\n",
      "        0.3048, 0.3916, 0.2920, 0.3738, 0.4151, 0.5913, 0.4569, 0.3256, 0.4191,\n",
      "        0.3650, 0.4199, 0.5249, 0.4440, 0.5037, 0.3956, 0.3635, 0.4516, 0.3771,\n",
      "        0.3733, 0.3700, 0.4467, 0.3542, 0.5394, 0.3550, 0.4484, 0.3765, 0.3697,\n",
      "        0.4653, 0.5179, 0.6212, 0.4199, 0.4266, 0.3782, 0.3873, 0.2751, 0.3686,\n",
      "        0.4059, 0.5077, 0.3692, 0.4704, 0.4469, 0.3867, 0.3454, 0.4798, 0.3890,\n",
      "        0.3154, 0.3366, 0.5750, 0.4111, 0.4686, 0.3601, 0.4672, 0.5179, 0.4085,\n",
      "        0.3873, 0.4419, 0.4013, 0.3657, 0.4390, 0.3110, 0.4262, 0.3219, 0.4027,\n",
      "        0.3622, 0.3749, 0.3625, 0.4037, 0.3555, 0.3593, 0.3748, 0.3656, 0.4409,\n",
      "        0.5653, 0.3634, 0.3348, 0.4293, 0.3992, 0.3780, 0.4335, 0.4079, 0.3724,\n",
      "        0.3282, 0.3676, 0.3543, 0.3845, 0.3804, 0.3497, 0.3666, 0.3175, 0.3337,\n",
      "        0.3872, 0.3315, 0.4156, 0.5482, 0.5005, 0.5096, 0.3912, 0.3755, 0.3230,\n",
      "        0.3915, 0.4241, 1.2980, 0.4407, 0.3209, 0.4005, 0.5028, 0.2981, 0.3075,\n",
      "        0.3224, 0.3529, 0.3451, 0.4417, 0.4766, 0.4163, 0.3500, 0.4528, 0.3532,\n",
      "        0.3380, 0.5209, 0.3769, 0.4994, 0.8077, 0.4585, 0.4464, 0.3880, 0.3261,\n",
      "        0.3983, 0.4853, 0.3227, 0.3312, 0.3855, 0.3456, 0.3506, 0.3981, 0.3915,\n",
      "        0.3617, 0.3469, 0.9464, 0.4084, 0.4600, 0.3840, 0.3189, 0.5683, 0.5951,\n",
      "        0.4221, 0.3092, 0.3639, 0.7613, 0.3280, 0.3588, 0.3959, 0.3712, 0.4702,\n",
      "        0.3520, 0.3783, 0.5054, 0.4096, 0.7112, 0.3432, 0.3445, 0.3946, 0.3656,\n",
      "        0.3456, 0.3506, 0.4280, 1.3414, 0.5125, 0.3961, 0.3878, 0.9821, 0.3899,\n",
      "        0.4428, 0.4389, 0.3213, 0.3875, 0.3668, 0.5050, 1.4000, 0.4665, 0.4133,\n",
      "        0.3422, 0.4418, 0.3778, 0.4920, 0.3525, 0.4810, 0.3359, 0.3757, 1.3151,\n",
      "        0.5192, 0.3317, 0.3482, 0.3848, 0.4756, 0.3671, 0.3521, 0.5531, 0.3513,\n",
      "        0.4573, 0.5056, 0.3587, 0.4719, 0.4278, 0.3644, 0.3526, 0.4679, 0.3475,\n",
      "        0.3619, 0.3555, 0.4514, 0.3956, 0.4006, 0.3868, 0.3365],\n",
      "       grad_fn=<ClampBackward1>)\n",
      "\n",
      "C\n",
      "tensor([1.9899, 2.0762, 1.9394, 1.9710, 2.1662, 1.9860, 2.0050, 2.0832, 1.7928,\n",
      "        2.0052, 2.1136, 1.9549, 2.1172, 2.1528, 2.0746, 1.8804, 1.9441, 2.0022,\n",
      "        1.9583, 2.0114, 2.1322, 1.9759, 1.9147, 2.0705, 2.0841, 2.0756, 2.2004,\n",
      "        2.0671, 2.0077, 1.9226, 2.1492, 1.9644, 2.0924, 2.2434, 2.0089, 2.0742,\n",
      "        2.1792, 2.1934, 2.1152, 2.0204, 1.9869, 1.9877, 1.9423, 2.1826, 2.0836,\n",
      "        2.0532, 2.0031, 2.2086, 1.9334, 2.2260, 2.0263, 2.0899, 1.9426, 1.9921,\n",
      "        2.1471, 1.9724, 1.9512, 1.9894, 1.9031, 2.1782, 1.9270, 2.0352, 1.9951,\n",
      "        1.9300, 1.9082, 1.8935, 2.0340, 1.9515, 2.1708, 1.9788, 2.1217, 2.1531,\n",
      "        2.0602, 2.2373, 2.0026, 2.1338, 1.9521, 2.0362, 2.0716, 2.1598, 2.0547,\n",
      "        2.1042, 2.1293, 1.8935, 2.0412, 1.9376, 2.0820, 2.0050, 1.9291, 1.9786,\n",
      "        2.0805, 1.9193, 2.0713, 2.0549, 1.9454, 2.1435, 1.9849, 2.1439, 1.9905,\n",
      "        2.0569, 2.2095, 2.0633, 1.9611, 2.1105, 2.1002, 2.0394, 2.0510, 1.9528,\n",
      "        1.8913, 2.0837, 2.1505, 1.9741, 2.2043, 2.0215, 2.2054, 2.1311, 2.1354,\n",
      "        2.0403, 2.0972, 2.0780, 2.1304, 2.0502, 2.1260, 2.0462, 2.1562, 2.1433,\n",
      "        2.0661, 2.0547, 2.1192, 1.9041, 2.2367, 2.3301, 2.0214, 2.1015, 2.1104,\n",
      "        2.0306, 1.9525, 1.8336, 1.9723, 2.1246, 2.0965, 1.9152, 2.1151, 2.0870,\n",
      "        2.1163, 2.0226, 2.0842, 1.9165, 2.2308, 2.0307, 2.0001, 1.9298, 2.1450,\n",
      "        2.1294, 2.2187, 1.9782, 1.9241, 1.8776, 1.9063, 1.9869, 2.1578, 2.0997,\n",
      "        2.0230, 1.9284, 2.1757, 2.0700, 2.0975, 2.1254, 2.0647, 1.9548, 2.0152,\n",
      "        2.1195, 2.1269, 1.8657, 2.0929, 1.9587, 2.1171, 2.0650, 1.8815, 1.8808,\n",
      "        1.9553, 2.1679, 2.0420, 1.8722, 2.1646, 2.0773, 2.1717, 2.0209, 2.1933,\n",
      "        2.1504, 2.0316, 2.2384, 1.9691, 1.8612, 2.0377, 2.0603, 2.0013, 2.0340,\n",
      "        2.0896, 2.2072, 1.9734, 1.7873, 2.2314, 2.0066, 1.9993, 1.9160, 2.0739,\n",
      "        1.9634, 2.0315, 2.0790, 2.0133, 2.1241, 1.9291, 1.7773, 2.2558, 2.1872,\n",
      "        2.0836, 1.9493, 2.1520, 2.2873, 2.1064, 2.1795, 2.0897, 2.0551, 1.7993,\n",
      "        2.2799, 2.0911, 2.0391, 1.9760, 1.9394, 2.0149, 2.0354, 1.8929, 2.1167,\n",
      "        2.0007, 2.2148, 2.0518, 1.9454, 2.1741, 2.1048, 2.1751, 2.2447, 2.2197,\n",
      "        2.0691, 2.0159, 1.9264, 1.9482, 2.0352, 1.9861, 2.1117],\n",
      "       grad_fn=<ClampBackward1>)\n",
      "\n",
      "Baseline Gain\n",
      "tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1798, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1140, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1645,\n",
      "        0.1000, 0.1000, 0.1000, 0.1234, 0.1000, 0.1000, 0.1223, 0.1000, 0.1000,\n",
      "        0.2853, 0.1066, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1205, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1156, 0.1000, 0.1080, 0.1000, 0.1000,\n",
      "        0.1044, 0.1000, 0.1000, 0.1000, 0.1000, 0.2195, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1515, 0.1000, 0.1000, 0.1763,\n",
      "        0.1000, 0.1083, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1476, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1213, 0.1000, 0.1524, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1165, 0.1049, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1575, 0.1000, 0.1000, 0.1000, 0.1000, 0.1088, 0.1923,\n",
      "        0.1000, 0.1000, 0.1000, 0.1237, 0.1000, 0.1474, 0.1000, 0.1009, 0.1728,\n",
      "        0.1000, 0.1000, 0.1628, 0.1000, 0.1114, 0.1206, 0.1000, 0.1094, 0.1261,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1153, 0.1000, 0.1000, 0.1064, 0.1000,\n",
      "        0.1006, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1429,\n",
      "        0.1358, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1519, 0.1474,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1238, 0.1459, 0.1000, 0.1000, 0.1000,\n",
      "        0.1476, 0.1749, 0.1000, 0.1000, 0.1000, 0.1664, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.2252, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1417, 0.1000, 0.1041, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1141, 0.1013, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1103, 0.1000, 0.1000, 0.1310, 0.1022,\n",
      "        0.1000, 0.1000, 0.2181, 0.1151, 0.1128, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1095, 0.1147, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1168,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.4732, 0.1000, 0.2940, 0.1228, 0.1424,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1423],\n",
      "       grad_fn=<ClampBackward1>)\n",
      "\n",
      "Depletion\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       grad_fn=<ClampBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitted parameters:\")\n",
    "print(\"\\nAlpha\")\n",
    "print(mvt.alpha_env)\n",
    "print(\"\\nBeta\")\n",
    "print(mvt.beta)\n",
    "print(\"\\nC\")\n",
    "print(mvt.c)\n",
    "print(\"\\nBaseline Gain\")\n",
    "print(mvt.baseline_gain)\n",
    "print(\"\\nDepletion\")\n",
    "print(mvt.depletion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, n_actions):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.gru_features = 32\n",
    "        self.n_actions = n_actions\n",
    "        \n",
    "        self.linear_in = torch.nn.Linear(in_features=input_size, out_features=self.gru_features)\n",
    "        self.gru = torch.nn.GRU(input_size=self.gru_features,hidden_size=n_actions, batch_first=True)\n",
    "        self.linear_out = torch.nn.Linear(in_features=n_actions, out_features=n_actions)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        y = self.linear_in(inputs.nan_to_num(0))\n",
    "        y, _ = self.gru(y)\n",
    "        logits = self.linear_out(y)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000 --- Loss: 0.34180\n",
      "Epoch 2/1000 --- Loss: 0.34218\n",
      "Epoch 3/1000 --- Loss: 0.34284\n",
      "Epoch 4/1000 --- Loss: 0.34271\n",
      "Epoch 5/1000 --- Loss: 0.34323\n",
      "Epoch 6/1000 --- Loss: 0.34310\n",
      "Epoch 7/1000 --- Loss: 0.34271\n",
      "Epoch 8/1000 --- Loss: 0.34328\n",
      "Epoch 9/1000 --- Loss: 0.34264\n",
      "Epoch 10/1000 --- Loss: 0.34249\n",
      "Epoch 11/1000 --- Loss: 0.34319\n",
      "Epoch 12/1000 --- Loss: 0.34258\n",
      "Epoch 13/1000 --- Loss: 0.34264\n",
      "Epoch 14/1000 --- Loss: 0.34278\n",
      "Epoch 15/1000 --- Loss: 0.34253\n",
      "Epoch 16/1000 --- Loss: 0.34292\n",
      "Epoch 17/1000 --- Loss: 0.34200\n",
      "Epoch 18/1000 --- Loss: 0.34345\n",
      "Epoch 19/1000 --- Loss: 0.34315\n",
      "Epoch 20/1000 --- Loss: 0.34302\n",
      "Epoch 21/1000 --- Loss: 0.34299\n",
      "Epoch 22/1000 --- Loss: 0.34327\n",
      "Epoch 23/1000 --- Loss: 0.34208\n",
      "Epoch 24/1000 --- Loss: 0.34224\n",
      "Epoch 25/1000 --- Loss: 0.34330\n",
      "Epoch 26/1000 --- Loss: 0.34241\n",
      "Epoch 27/1000 --- Loss: 0.34289\n",
      "Epoch 28/1000 --- Loss: 0.34309\n",
      "Epoch 29/1000 --- Loss: 0.34224\n",
      "Epoch 30/1000 --- Loss: 0.34246\n",
      "Epoch 31/1000 --- Loss: 0.34273\n",
      "Epoch 32/1000 --- Loss: 0.34325\n",
      "Epoch 33/1000 --- Loss: 0.34281\n",
      "Epoch 34/1000 --- Loss: 0.34208\n",
      "Epoch 35/1000 --- Loss: 0.34247\n",
      "Epoch 36/1000 --- Loss: 0.34325\n",
      "Epoch 37/1000 --- Loss: 0.34326\n",
      "Epoch 38/1000 --- Loss: 0.34321\n",
      "Epoch 39/1000 --- Loss: 0.34298\n",
      "Epoch 40/1000 --- Loss: 0.34261\n",
      "Epoch 41/1000 --- Loss: 0.34296\n",
      "Epoch 42/1000 --- Loss: 0.34318\n",
      "Epoch 43/1000 --- Loss: 0.34303\n",
      "Epoch 44/1000 --- Loss: 0.34356\n",
      "Epoch 45/1000 --- Loss: 0.34227\n",
      "Epoch 46/1000 --- Loss: 0.34299\n",
      "Epoch 47/1000 --- Loss: 0.34331\n",
      "Epoch 48/1000 --- Loss: 0.34315\n",
      "Epoch 49/1000 --- Loss: 0.34345\n",
      "Epoch 50/1000 --- Loss: 0.34275\n",
      "Epoch 51/1000 --- Loss: 0.34268\n",
      "Epoch 52/1000 --- Loss: 0.34340\n",
      "Epoch 53/1000 --- Loss: 0.34150\n",
      "Epoch 54/1000 --- Loss: 0.34274\n",
      "Epoch 55/1000 --- Loss: 0.34329\n",
      "Epoch 56/1000 --- Loss: 0.34258\n",
      "Epoch 57/1000 --- Loss: 0.34305\n",
      "Epoch 58/1000 --- Loss: 0.34313\n",
      "Epoch 59/1000 --- Loss: 0.34380\n",
      "Epoch 60/1000 --- Loss: 0.34235\n",
      "Epoch 61/1000 --- Loss: 0.34316\n",
      "Epoch 62/1000 --- Loss: 0.34290\n",
      "Epoch 63/1000 --- Loss: 0.34258\n",
      "Epoch 64/1000 --- Loss: 0.34282\n",
      "Epoch 65/1000 --- Loss: 0.34262\n",
      "Epoch 66/1000 --- Loss: 0.34315\n",
      "Epoch 67/1000 --- Loss: 0.34345\n",
      "Epoch 68/1000 --- Loss: 0.34284\n",
      "Epoch 69/1000 --- Loss: 0.34275\n",
      "Epoch 70/1000 --- Loss: 0.34256\n",
      "Epoch 71/1000 --- Loss: 0.34323\n",
      "Epoch 72/1000 --- Loss: 0.34211\n",
      "Epoch 73/1000 --- Loss: 0.34280\n",
      "Epoch 74/1000 --- Loss: 0.34366\n",
      "Epoch 75/1000 --- Loss: 0.34308\n",
      "Epoch 76/1000 --- Loss: 0.34346\n",
      "Epoch 77/1000 --- Loss: 0.34317\n",
      "Epoch 78/1000 --- Loss: 0.34242\n",
      "Epoch 79/1000 --- Loss: 0.34316\n",
      "Epoch 80/1000 --- Loss: 0.34303\n",
      "Epoch 81/1000 --- Loss: 0.34278\n",
      "Epoch 82/1000 --- Loss: 0.34230\n",
      "Epoch 83/1000 --- Loss: 0.34173\n",
      "Epoch 84/1000 --- Loss: 0.34324\n",
      "Epoch 85/1000 --- Loss: 0.34247\n",
      "Epoch 86/1000 --- Loss: 0.34229\n",
      "Epoch 87/1000 --- Loss: 0.34347\n",
      "Epoch 88/1000 --- Loss: 0.34418\n",
      "Epoch 89/1000 --- Loss: 0.34332\n",
      "Epoch 90/1000 --- Loss: 0.34333\n",
      "Epoch 91/1000 --- Loss: 0.34274\n",
      "Epoch 92/1000 --- Loss: 0.34324\n",
      "Epoch 93/1000 --- Loss: 0.34322\n",
      "Epoch 94/1000 --- Loss: 0.34197\n",
      "Epoch 95/1000 --- Loss: 0.34305\n",
      "Epoch 96/1000 --- Loss: 0.34290\n",
      "Epoch 97/1000 --- Loss: 0.34296\n",
      "Epoch 98/1000 --- Loss: 0.34243\n",
      "Epoch 99/1000 --- Loss: 0.34333\n",
      "Epoch 100/1000 --- Loss: 0.34274\n",
      "Epoch 101/1000 --- Loss: 0.34296\n",
      "Epoch 102/1000 --- Loss: 0.34365\n",
      "Epoch 103/1000 --- Loss: 0.34372\n",
      "Epoch 104/1000 --- Loss: 0.34315\n",
      "Epoch 105/1000 --- Loss: 0.34302\n",
      "Epoch 106/1000 --- Loss: 0.34250\n",
      "Epoch 107/1000 --- Loss: 0.34307\n",
      "Epoch 108/1000 --- Loss: 0.34261\n",
      "Epoch 109/1000 --- Loss: 0.34328\n",
      "Epoch 110/1000 --- Loss: 0.34315\n",
      "Epoch 111/1000 --- Loss: 0.34236\n",
      "Epoch 112/1000 --- Loss: 0.34266\n",
      "Epoch 113/1000 --- Loss: 0.34293\n",
      "Epoch 114/1000 --- Loss: 0.34266\n",
      "Epoch 115/1000 --- Loss: 0.34263\n",
      "Epoch 116/1000 --- Loss: 0.34316\n",
      "Epoch 117/1000 --- Loss: 0.34269\n",
      "Epoch 118/1000 --- Loss: 0.34159\n",
      "Epoch 119/1000 --- Loss: 0.34265\n",
      "Epoch 120/1000 --- Loss: 0.34226\n",
      "Epoch 121/1000 --- Loss: 0.34317\n",
      "Epoch 122/1000 --- Loss: 0.34283\n",
      "Epoch 123/1000 --- Loss: 0.34300\n",
      "Epoch 124/1000 --- Loss: 0.34352\n",
      "Epoch 125/1000 --- Loss: 0.34271\n",
      "Epoch 126/1000 --- Loss: 0.34211\n",
      "Epoch 127/1000 --- Loss: 0.34159\n",
      "Epoch 128/1000 --- Loss: 0.34232\n",
      "Epoch 129/1000 --- Loss: 0.34212\n",
      "Epoch 130/1000 --- Loss: 0.34325\n",
      "Epoch 131/1000 --- Loss: 0.34258\n",
      "Epoch 132/1000 --- Loss: 0.34241\n",
      "Epoch 133/1000 --- Loss: 0.34320\n",
      "Epoch 134/1000 --- Loss: 0.34264\n",
      "Epoch 135/1000 --- Loss: 0.34300\n",
      "Epoch 136/1000 --- Loss: 0.34237\n",
      "Epoch 137/1000 --- Loss: 0.34319\n",
      "Epoch 138/1000 --- Loss: 0.34344\n",
      "Epoch 139/1000 --- Loss: 0.34338\n",
      "Epoch 140/1000 --- Loss: 0.34275\n",
      "Epoch 141/1000 --- Loss: 0.34290\n",
      "Epoch 142/1000 --- Loss: 0.34309\n",
      "Epoch 143/1000 --- Loss: 0.34351\n",
      "Epoch 144/1000 --- Loss: 0.34349\n",
      "Epoch 145/1000 --- Loss: 0.34302\n",
      "Epoch 146/1000 --- Loss: 0.34281\n",
      "Epoch 147/1000 --- Loss: 0.34258\n",
      "Epoch 148/1000 --- Loss: 0.34207\n",
      "Epoch 149/1000 --- Loss: 0.34321\n",
      "Epoch 150/1000 --- Loss: 0.34282\n",
      "Epoch 151/1000 --- Loss: 0.34302\n",
      "Epoch 152/1000 --- Loss: 0.34313\n",
      "Epoch 153/1000 --- Loss: 0.34233\n",
      "Epoch 154/1000 --- Loss: 0.34303\n",
      "Epoch 155/1000 --- Loss: 0.34196\n",
      "Epoch 156/1000 --- Loss: 0.34221\n",
      "Epoch 157/1000 --- Loss: 0.34403\n",
      "Epoch 158/1000 --- Loss: 0.34216\n",
      "Epoch 159/1000 --- Loss: 0.34327\n",
      "Epoch 160/1000 --- Loss: 0.34286\n",
      "Epoch 161/1000 --- Loss: 0.34261\n",
      "Epoch 162/1000 --- Loss: 0.34274\n",
      "Epoch 163/1000 --- Loss: 0.34282\n",
      "Epoch 164/1000 --- Loss: 0.34266\n",
      "Epoch 165/1000 --- Loss: 0.34320\n",
      "Epoch 166/1000 --- Loss: 0.34205\n",
      "Epoch 167/1000 --- Loss: 0.34328\n",
      "Epoch 168/1000 --- Loss: 0.34281\n",
      "Epoch 169/1000 --- Loss: 0.34257\n",
      "Epoch 170/1000 --- Loss: 0.34335\n",
      "Epoch 171/1000 --- Loss: 0.34359\n",
      "Epoch 172/1000 --- Loss: 0.34254\n",
      "Epoch 173/1000 --- Loss: 0.34337\n",
      "Epoch 174/1000 --- Loss: 0.34248\n",
      "Epoch 175/1000 --- Loss: 0.34245\n",
      "Epoch 176/1000 --- Loss: 0.34288\n",
      "Epoch 177/1000 --- Loss: 0.34244\n",
      "Epoch 178/1000 --- Loss: 0.34334\n",
      "Epoch 179/1000 --- Loss: 0.34298\n",
      "Epoch 180/1000 --- Loss: 0.34312\n",
      "Epoch 181/1000 --- Loss: 0.34334\n",
      "Epoch 182/1000 --- Loss: 0.34267\n",
      "Epoch 183/1000 --- Loss: 0.34317\n",
      "Epoch 184/1000 --- Loss: 0.34282\n",
      "Epoch 185/1000 --- Loss: 0.34251\n",
      "Epoch 186/1000 --- Loss: 0.34286\n",
      "Epoch 187/1000 --- Loss: 0.34289\n",
      "Epoch 188/1000 --- Loss: 0.34324\n",
      "Epoch 189/1000 --- Loss: 0.34259\n",
      "Epoch 190/1000 --- Loss: 0.34308\n",
      "Epoch 191/1000 --- Loss: 0.34275\n",
      "Epoch 192/1000 --- Loss: 0.34290\n",
      "Epoch 193/1000 --- Loss: 0.34287\n",
      "Epoch 194/1000 --- Loss: 0.34298\n",
      "Epoch 195/1000 --- Loss: 0.34260\n",
      "Epoch 196/1000 --- Loss: 0.34297\n",
      "Epoch 197/1000 --- Loss: 0.34247\n",
      "Epoch 198/1000 --- Loss: 0.34377\n",
      "Epoch 199/1000 --- Loss: 0.34287\n",
      "Epoch 200/1000 --- Loss: 0.34259\n",
      "Epoch 201/1000 --- Loss: 0.34356\n",
      "Epoch 202/1000 --- Loss: 0.34296\n",
      "Epoch 203/1000 --- Loss: 0.34396\n",
      "Epoch 204/1000 --- Loss: 0.34319\n",
      "Epoch 205/1000 --- Loss: 0.34275\n",
      "Epoch 206/1000 --- Loss: 0.34292\n",
      "Epoch 207/1000 --- Loss: 0.34216\n",
      "Epoch 208/1000 --- Loss: 0.34358\n",
      "Epoch 209/1000 --- Loss: 0.34269\n",
      "Epoch 210/1000 --- Loss: 0.34299\n",
      "Epoch 211/1000 --- Loss: 0.34320\n",
      "Epoch 212/1000 --- Loss: 0.34226\n",
      "Epoch 213/1000 --- Loss: 0.34285\n",
      "Epoch 214/1000 --- Loss: 0.34279\n",
      "Epoch 215/1000 --- Loss: 0.34283\n",
      "Epoch 216/1000 --- Loss: 0.34248\n",
      "Epoch 217/1000 --- Loss: 0.34303\n",
      "Epoch 218/1000 --- Loss: 0.34327\n",
      "Epoch 219/1000 --- Loss: 0.34286\n",
      "Epoch 220/1000 --- Loss: 0.34297\n",
      "Epoch 221/1000 --- Loss: 0.34273\n",
      "Epoch 222/1000 --- Loss: 0.34324\n",
      "Epoch 223/1000 --- Loss: 0.34322\n",
      "Epoch 224/1000 --- Loss: 0.34297\n",
      "Epoch 225/1000 --- Loss: 0.34268\n",
      "Epoch 226/1000 --- Loss: 0.34298\n",
      "Epoch 227/1000 --- Loss: 0.34346\n",
      "Epoch 228/1000 --- Loss: 0.34292\n",
      "Epoch 229/1000 --- Loss: 0.34347\n",
      "Epoch 230/1000 --- Loss: 0.34289\n",
      "Epoch 231/1000 --- Loss: 0.34220\n",
      "Epoch 232/1000 --- Loss: 0.34312\n",
      "Epoch 233/1000 --- Loss: 0.34319\n",
      "Epoch 234/1000 --- Loss: 0.34277\n",
      "Epoch 235/1000 --- Loss: 0.34338\n",
      "Epoch 236/1000 --- Loss: 0.34308\n",
      "Epoch 237/1000 --- Loss: 0.34316\n",
      "Epoch 238/1000 --- Loss: 0.34260\n",
      "Epoch 239/1000 --- Loss: 0.34282\n",
      "Epoch 240/1000 --- Loss: 0.34299\n",
      "Epoch 241/1000 --- Loss: 0.34271\n",
      "Epoch 242/1000 --- Loss: 0.34286\n",
      "Epoch 243/1000 --- Loss: 0.34209\n",
      "Epoch 244/1000 --- Loss: 0.34314\n",
      "Epoch 245/1000 --- Loss: 0.34359\n",
      "Epoch 246/1000 --- Loss: 0.34209\n",
      "Epoch 247/1000 --- Loss: 0.34288\n",
      "Epoch 248/1000 --- Loss: 0.34233\n",
      "Epoch 249/1000 --- Loss: 0.34219\n",
      "Epoch 250/1000 --- Loss: 0.34287\n",
      "Epoch 251/1000 --- Loss: 0.34224\n",
      "Epoch 252/1000 --- Loss: 0.34327\n",
      "Epoch 253/1000 --- Loss: 0.34256\n",
      "Epoch 254/1000 --- Loss: 0.34289\n",
      "Epoch 255/1000 --- Loss: 0.34227\n",
      "Epoch 256/1000 --- Loss: 0.34282\n",
      "Epoch 257/1000 --- Loss: 0.34247\n",
      "Epoch 258/1000 --- Loss: 0.34226\n",
      "Epoch 259/1000 --- Loss: 0.34405\n",
      "Epoch 260/1000 --- Loss: 0.34303\n",
      "Epoch 261/1000 --- Loss: 0.34301\n",
      "Epoch 262/1000 --- Loss: 0.34188\n",
      "Epoch 263/1000 --- Loss: 0.34247\n",
      "Epoch 264/1000 --- Loss: 0.34241\n",
      "Epoch 265/1000 --- Loss: 0.34303\n",
      "Epoch 266/1000 --- Loss: 0.34263\n",
      "Epoch 267/1000 --- Loss: 0.34297\n",
      "Epoch 268/1000 --- Loss: 0.34298\n",
      "Epoch 269/1000 --- Loss: 0.34313\n",
      "Epoch 270/1000 --- Loss: 0.34305\n",
      "Epoch 271/1000 --- Loss: 0.34285\n",
      "Epoch 272/1000 --- Loss: 0.34281\n",
      "Epoch 273/1000 --- Loss: 0.34357\n",
      "Epoch 274/1000 --- Loss: 0.34314\n",
      "Epoch 275/1000 --- Loss: 0.34214\n",
      "Epoch 276/1000 --- Loss: 0.34292\n",
      "Epoch 277/1000 --- Loss: 0.34255\n",
      "Epoch 278/1000 --- Loss: 0.34189\n",
      "Epoch 279/1000 --- Loss: 0.34345\n",
      "Epoch 280/1000 --- Loss: 0.34311\n",
      "Epoch 281/1000 --- Loss: 0.34306\n",
      "Epoch 282/1000 --- Loss: 0.34328\n",
      "Epoch 283/1000 --- Loss: 0.34283\n",
      "Epoch 284/1000 --- Loss: 0.34318\n",
      "Epoch 285/1000 --- Loss: 0.34290\n",
      "Epoch 286/1000 --- Loss: 0.34296\n",
      "Epoch 287/1000 --- Loss: 0.34247\n",
      "Epoch 288/1000 --- Loss: 0.34334\n",
      "Epoch 289/1000 --- Loss: 0.34286\n",
      "Epoch 290/1000 --- Loss: 0.34205\n",
      "Epoch 291/1000 --- Loss: 0.34288\n",
      "Epoch 292/1000 --- Loss: 0.34278\n",
      "Epoch 293/1000 --- Loss: 0.34244\n",
      "Epoch 294/1000 --- Loss: 0.34288\n",
      "Epoch 295/1000 --- Loss: 0.34301\n",
      "Epoch 296/1000 --- Loss: 0.34192\n",
      "Epoch 297/1000 --- Loss: 0.34317\n",
      "Epoch 298/1000 --- Loss: 0.34306\n",
      "Epoch 299/1000 --- Loss: 0.34277\n",
      "Epoch 300/1000 --- Loss: 0.34216\n",
      "Epoch 301/1000 --- Loss: 0.34301\n",
      "Epoch 302/1000 --- Loss: 0.34253\n",
      "Epoch 303/1000 --- Loss: 0.34336\n",
      "Epoch 304/1000 --- Loss: 0.34239\n",
      "Epoch 305/1000 --- Loss: 0.34231\n",
      "Epoch 306/1000 --- Loss: 0.34308\n",
      "Epoch 307/1000 --- Loss: 0.34371\n",
      "Epoch 308/1000 --- Loss: 0.34300\n",
      "Epoch 309/1000 --- Loss: 0.34304\n",
      "Epoch 310/1000 --- Loss: 0.34294\n",
      "Epoch 311/1000 --- Loss: 0.34278\n",
      "Epoch 312/1000 --- Loss: 0.34342\n",
      "Epoch 313/1000 --- Loss: 0.34294\n",
      "Epoch 314/1000 --- Loss: 0.34274\n",
      "Epoch 315/1000 --- Loss: 0.34223\n",
      "Epoch 316/1000 --- Loss: 0.34286\n",
      "Epoch 317/1000 --- Loss: 0.34301\n",
      "Epoch 318/1000 --- Loss: 0.34298\n",
      "Epoch 319/1000 --- Loss: 0.34280\n",
      "Epoch 320/1000 --- Loss: 0.34267\n",
      "Epoch 321/1000 --- Loss: 0.34349\n",
      "Epoch 322/1000 --- Loss: 0.34346\n",
      "Epoch 323/1000 --- Loss: 0.34322\n",
      "Epoch 324/1000 --- Loss: 0.34334\n",
      "Epoch 325/1000 --- Loss: 0.34223\n",
      "Epoch 326/1000 --- Loss: 0.34287\n",
      "Epoch 327/1000 --- Loss: 0.34327\n",
      "Epoch 328/1000 --- Loss: 0.34216\n",
      "Epoch 329/1000 --- Loss: 0.34241\n",
      "Epoch 330/1000 --- Loss: 0.34345\n",
      "Epoch 331/1000 --- Loss: 0.34282\n",
      "Epoch 332/1000 --- Loss: 0.34316\n",
      "Epoch 333/1000 --- Loss: 0.34241\n",
      "Epoch 334/1000 --- Loss: 0.34278\n",
      "Epoch 335/1000 --- Loss: 0.34285\n",
      "Epoch 336/1000 --- Loss: 0.34254\n",
      "Epoch 337/1000 --- Loss: 0.34264\n",
      "Epoch 338/1000 --- Loss: 0.34324\n",
      "Epoch 339/1000 --- Loss: 0.34365\n",
      "Epoch 340/1000 --- Loss: 0.34267\n",
      "Epoch 341/1000 --- Loss: 0.34316\n",
      "Epoch 342/1000 --- Loss: 0.34308\n",
      "Epoch 343/1000 --- Loss: 0.34282\n",
      "Epoch 344/1000 --- Loss: 0.34252\n",
      "Epoch 345/1000 --- Loss: 0.34323\n",
      "Epoch 346/1000 --- Loss: 0.34289\n",
      "Epoch 347/1000 --- Loss: 0.34311\n",
      "Epoch 348/1000 --- Loss: 0.34188\n",
      "Epoch 349/1000 --- Loss: 0.34321\n",
      "Epoch 350/1000 --- Loss: 0.34265\n",
      "Epoch 351/1000 --- Loss: 0.34237\n",
      "Epoch 352/1000 --- Loss: 0.34341\n",
      "Epoch 353/1000 --- Loss: 0.34249\n",
      "Epoch 354/1000 --- Loss: 0.34327\n",
      "Epoch 355/1000 --- Loss: 0.34278\n",
      "Epoch 356/1000 --- Loss: 0.34261\n",
      "Epoch 357/1000 --- Loss: 0.34331\n",
      "Epoch 358/1000 --- Loss: 0.34238\n",
      "Epoch 359/1000 --- Loss: 0.34341\n",
      "Epoch 360/1000 --- Loss: 0.34357\n",
      "Epoch 361/1000 --- Loss: 0.34293\n",
      "Epoch 362/1000 --- Loss: 0.34235\n",
      "Epoch 363/1000 --- Loss: 0.34364\n",
      "Epoch 364/1000 --- Loss: 0.34267\n",
      "Epoch 365/1000 --- Loss: 0.34302\n",
      "Epoch 366/1000 --- Loss: 0.34251\n",
      "Epoch 367/1000 --- Loss: 0.34239\n",
      "Epoch 368/1000 --- Loss: 0.34376\n",
      "Epoch 369/1000 --- Loss: 0.34354\n",
      "Epoch 370/1000 --- Loss: 0.34247\n",
      "Epoch 371/1000 --- Loss: 0.34294\n",
      "Epoch 372/1000 --- Loss: 0.34322\n",
      "Epoch 373/1000 --- Loss: 0.34238\n",
      "Epoch 374/1000 --- Loss: 0.34270\n",
      "Epoch 375/1000 --- Loss: 0.34349\n",
      "Epoch 376/1000 --- Loss: 0.34194\n",
      "Epoch 377/1000 --- Loss: 0.34296\n",
      "Epoch 378/1000 --- Loss: 0.34336\n",
      "Epoch 379/1000 --- Loss: 0.34247\n",
      "Epoch 380/1000 --- Loss: 0.34228\n",
      "Epoch 381/1000 --- Loss: 0.34325\n",
      "Epoch 382/1000 --- Loss: 0.34293\n",
      "Epoch 383/1000 --- Loss: 0.34268\n",
      "Epoch 384/1000 --- Loss: 0.34311\n",
      "Epoch 385/1000 --- Loss: 0.34296\n",
      "Epoch 386/1000 --- Loss: 0.34280\n",
      "Epoch 387/1000 --- Loss: 0.34270\n",
      "Epoch 388/1000 --- Loss: 0.34283\n",
      "Epoch 389/1000 --- Loss: 0.34241\n",
      "Epoch 390/1000 --- Loss: 0.34301\n",
      "Epoch 391/1000 --- Loss: 0.34336\n",
      "Epoch 392/1000 --- Loss: 0.34265\n",
      "Epoch 393/1000 --- Loss: 0.34278\n",
      "Epoch 394/1000 --- Loss: 0.34304\n",
      "Epoch 395/1000 --- Loss: 0.34361\n",
      "Epoch 396/1000 --- Loss: 0.34283\n",
      "Epoch 397/1000 --- Loss: 0.34271\n",
      "Epoch 398/1000 --- Loss: 0.34271\n",
      "Epoch 399/1000 --- Loss: 0.34274\n",
      "Epoch 400/1000 --- Loss: 0.34259\n",
      "Epoch 401/1000 --- Loss: 0.34283\n",
      "Epoch 402/1000 --- Loss: 0.34266\n",
      "Epoch 403/1000 --- Loss: 0.34263\n",
      "Epoch 404/1000 --- Loss: 0.34384\n",
      "Epoch 405/1000 --- Loss: 0.34329\n",
      "Epoch 406/1000 --- Loss: 0.34270\n",
      "Epoch 407/1000 --- Loss: 0.34179\n",
      "Epoch 408/1000 --- Loss: 0.34341\n",
      "Epoch 409/1000 --- Loss: 0.34351\n",
      "Epoch 410/1000 --- Loss: 0.34288\n",
      "Epoch 411/1000 --- Loss: 0.34232\n",
      "Epoch 412/1000 --- Loss: 0.34292\n",
      "Epoch 413/1000 --- Loss: 0.34291\n",
      "Epoch 414/1000 --- Loss: 0.34216\n",
      "Epoch 415/1000 --- Loss: 0.34366\n",
      "Epoch 416/1000 --- Loss: 0.34375\n",
      "Epoch 417/1000 --- Loss: 0.34362\n",
      "Epoch 418/1000 --- Loss: 0.34332\n",
      "Epoch 419/1000 --- Loss: 0.34336\n",
      "Epoch 420/1000 --- Loss: 0.34207\n",
      "Epoch 421/1000 --- Loss: 0.34292\n",
      "Epoch 422/1000 --- Loss: 0.34334\n",
      "Epoch 423/1000 --- Loss: 0.34217\n",
      "Epoch 424/1000 --- Loss: 0.34264\n",
      "Epoch 425/1000 --- Loss: 0.34274\n",
      "Epoch 426/1000 --- Loss: 0.34293\n",
      "Epoch 427/1000 --- Loss: 0.34304\n",
      "Epoch 428/1000 --- Loss: 0.34281\n",
      "Epoch 429/1000 --- Loss: 0.34337\n",
      "Epoch 430/1000 --- Loss: 0.34336\n",
      "Epoch 431/1000 --- Loss: 0.34226\n",
      "Epoch 432/1000 --- Loss: 0.34201\n",
      "Epoch 433/1000 --- Loss: 0.34213\n",
      "Epoch 434/1000 --- Loss: 0.34212\n",
      "Epoch 435/1000 --- Loss: 0.34220\n",
      "Epoch 436/1000 --- Loss: 0.34343\n",
      "Epoch 437/1000 --- Loss: 0.34218\n",
      "Epoch 438/1000 --- Loss: 0.34358\n",
      "Epoch 439/1000 --- Loss: 0.34223\n",
      "Epoch 440/1000 --- Loss: 0.34284\n",
      "Epoch 441/1000 --- Loss: 0.34295\n",
      "Epoch 442/1000 --- Loss: 0.34227\n",
      "Epoch 443/1000 --- Loss: 0.34242\n",
      "Epoch 444/1000 --- Loss: 0.34226\n",
      "Epoch 445/1000 --- Loss: 0.34231\n",
      "Epoch 446/1000 --- Loss: 0.34307\n",
      "Epoch 447/1000 --- Loss: 0.34239\n",
      "Epoch 448/1000 --- Loss: 0.34295\n",
      "Epoch 449/1000 --- Loss: 0.34278\n",
      "Epoch 450/1000 --- Loss: 0.34385\n",
      "Epoch 451/1000 --- Loss: 0.34152\n",
      "Epoch 452/1000 --- Loss: 0.34209\n",
      "Epoch 453/1000 --- Loss: 0.34281\n",
      "Epoch 454/1000 --- Loss: 0.34313\n",
      "Epoch 455/1000 --- Loss: 0.34244\n",
      "Epoch 456/1000 --- Loss: 0.34287\n",
      "Epoch 457/1000 --- Loss: 0.34339\n",
      "Epoch 458/1000 --- Loss: 0.34358\n",
      "Epoch 459/1000 --- Loss: 0.34279\n",
      "Epoch 460/1000 --- Loss: 0.34356\n",
      "Epoch 461/1000 --- Loss: 0.34253\n",
      "Epoch 462/1000 --- Loss: 0.34294\n",
      "Epoch 463/1000 --- Loss: 0.34229\n",
      "Epoch 464/1000 --- Loss: 0.34287\n",
      "Epoch 465/1000 --- Loss: 0.34205\n",
      "Epoch 466/1000 --- Loss: 0.34251\n",
      "Epoch 467/1000 --- Loss: 0.34201\n",
      "Epoch 468/1000 --- Loss: 0.34348\n",
      "Epoch 469/1000 --- Loss: 0.34287\n",
      "Epoch 470/1000 --- Loss: 0.34230\n",
      "Epoch 471/1000 --- Loss: 0.34256\n",
      "Epoch 472/1000 --- Loss: 0.34264\n",
      "Epoch 473/1000 --- Loss: 0.34288\n",
      "Epoch 474/1000 --- Loss: 0.34278\n",
      "Epoch 475/1000 --- Loss: 0.34307\n",
      "Epoch 476/1000 --- Loss: 0.34238\n",
      "Epoch 477/1000 --- Loss: 0.34276\n",
      "Epoch 478/1000 --- Loss: 0.34310\n",
      "Epoch 479/1000 --- Loss: 0.34317\n",
      "Epoch 480/1000 --- Loss: 0.34310\n",
      "Epoch 481/1000 --- Loss: 0.34316\n",
      "Epoch 482/1000 --- Loss: 0.34329\n",
      "Epoch 483/1000 --- Loss: 0.34306\n",
      "Epoch 484/1000 --- Loss: 0.34281\n",
      "Epoch 485/1000 --- Loss: 0.34285\n",
      "Epoch 486/1000 --- Loss: 0.34329\n",
      "Epoch 487/1000 --- Loss: 0.34193\n",
      "Epoch 488/1000 --- Loss: 0.34227\n",
      "Epoch 489/1000 --- Loss: 0.34275\n",
      "Epoch 490/1000 --- Loss: 0.34294\n",
      "Epoch 491/1000 --- Loss: 0.34331\n",
      "Epoch 492/1000 --- Loss: 0.34298\n",
      "Epoch 493/1000 --- Loss: 0.34264\n",
      "Epoch 494/1000 --- Loss: 0.34316\n",
      "Epoch 495/1000 --- Loss: 0.34243\n",
      "Epoch 496/1000 --- Loss: 0.34280\n",
      "Epoch 497/1000 --- Loss: 0.34299\n",
      "Epoch 498/1000 --- Loss: 0.34345\n",
      "Epoch 499/1000 --- Loss: 0.34270\n",
      "Epoch 500/1000 --- Loss: 0.34315\n",
      "Epoch 501/1000 --- Loss: 0.34278\n",
      "Epoch 502/1000 --- Loss: 0.34220\n",
      "Epoch 503/1000 --- Loss: 0.34222\n",
      "Epoch 504/1000 --- Loss: 0.34282\n",
      "Epoch 505/1000 --- Loss: 0.34297\n",
      "Epoch 506/1000 --- Loss: 0.34315\n",
      "Epoch 507/1000 --- Loss: 0.34266\n",
      "Epoch 508/1000 --- Loss: 0.34279\n",
      "Epoch 509/1000 --- Loss: 0.34308\n",
      "Epoch 510/1000 --- Loss: 0.34276\n",
      "Epoch 511/1000 --- Loss: 0.34311\n",
      "Epoch 512/1000 --- Loss: 0.34219\n",
      "Epoch 513/1000 --- Loss: 0.34287\n",
      "Epoch 514/1000 --- Loss: 0.34334\n",
      "Epoch 515/1000 --- Loss: 0.34252\n",
      "Epoch 516/1000 --- Loss: 0.34289\n",
      "Epoch 517/1000 --- Loss: 0.34310\n",
      "Epoch 518/1000 --- Loss: 0.34322\n",
      "Epoch 519/1000 --- Loss: 0.34257\n",
      "Epoch 520/1000 --- Loss: 0.34296\n",
      "Epoch 521/1000 --- Loss: 0.34226\n",
      "Epoch 522/1000 --- Loss: 0.34361\n",
      "Epoch 523/1000 --- Loss: 0.34390\n",
      "Epoch 524/1000 --- Loss: 0.34294\n",
      "Epoch 525/1000 --- Loss: 0.34341\n",
      "Epoch 526/1000 --- Loss: 0.34286\n",
      "Epoch 527/1000 --- Loss: 0.34246\n",
      "Epoch 528/1000 --- Loss: 0.34315\n",
      "Epoch 529/1000 --- Loss: 0.34302\n",
      "Epoch 530/1000 --- Loss: 0.34238\n",
      "Epoch 531/1000 --- Loss: 0.34258\n",
      "Epoch 532/1000 --- Loss: 0.34288\n",
      "Epoch 533/1000 --- Loss: 0.34323\n",
      "Epoch 534/1000 --- Loss: 0.34313\n",
      "Epoch 535/1000 --- Loss: 0.34240\n",
      "Epoch 536/1000 --- Loss: 0.34285\n",
      "Epoch 537/1000 --- Loss: 0.34277\n",
      "Epoch 538/1000 --- Loss: 0.34243\n",
      "Epoch 539/1000 --- Loss: 0.34331\n",
      "Epoch 540/1000 --- Loss: 0.34304\n",
      "Epoch 541/1000 --- Loss: 0.34298\n",
      "Epoch 542/1000 --- Loss: 0.34302\n",
      "Epoch 543/1000 --- Loss: 0.34189\n",
      "Epoch 544/1000 --- Loss: 0.34290\n",
      "Epoch 545/1000 --- Loss: 0.34214\n",
      "Epoch 546/1000 --- Loss: 0.34321\n",
      "Epoch 547/1000 --- Loss: 0.34364\n",
      "Epoch 548/1000 --- Loss: 0.34207\n",
      "Epoch 549/1000 --- Loss: 0.34289\n",
      "Epoch 550/1000 --- Loss: 0.34246\n",
      "Epoch 551/1000 --- Loss: 0.34352\n",
      "Epoch 552/1000 --- Loss: 0.34259\n",
      "Epoch 553/1000 --- Loss: 0.34297\n",
      "Epoch 554/1000 --- Loss: 0.34252\n",
      "Epoch 555/1000 --- Loss: 0.34255\n",
      "Epoch 556/1000 --- Loss: 0.34225\n",
      "Epoch 557/1000 --- Loss: 0.34236\n",
      "Epoch 558/1000 --- Loss: 0.34348\n",
      "Epoch 559/1000 --- Loss: 0.34340\n",
      "Epoch 560/1000 --- Loss: 0.34214\n",
      "Epoch 561/1000 --- Loss: 0.34196\n",
      "Epoch 562/1000 --- Loss: 0.34301\n",
      "Epoch 563/1000 --- Loss: 0.34267\n",
      "Epoch 564/1000 --- Loss: 0.34272\n",
      "Epoch 565/1000 --- Loss: 0.34306\n",
      "Epoch 566/1000 --- Loss: 0.34302\n",
      "Epoch 567/1000 --- Loss: 0.34287\n",
      "Epoch 568/1000 --- Loss: 0.34265\n",
      "Epoch 569/1000 --- Loss: 0.34278\n",
      "Epoch 570/1000 --- Loss: 0.34317\n",
      "Epoch 571/1000 --- Loss: 0.34360\n",
      "Epoch 572/1000 --- Loss: 0.34329\n",
      "Epoch 573/1000 --- Loss: 0.34290\n",
      "Epoch 574/1000 --- Loss: 0.34309\n",
      "Epoch 575/1000 --- Loss: 0.34257\n",
      "Epoch 576/1000 --- Loss: 0.34342\n",
      "Epoch 577/1000 --- Loss: 0.34365\n",
      "Epoch 578/1000 --- Loss: 0.34290\n",
      "Epoch 579/1000 --- Loss: 0.34330\n",
      "Epoch 580/1000 --- Loss: 0.34316\n",
      "Epoch 581/1000 --- Loss: 0.34219\n",
      "Epoch 582/1000 --- Loss: 0.34280\n",
      "Epoch 583/1000 --- Loss: 0.34371\n",
      "Epoch 584/1000 --- Loss: 0.34322\n",
      "Epoch 585/1000 --- Loss: 0.34269\n",
      "Epoch 586/1000 --- Loss: 0.34260\n",
      "Epoch 587/1000 --- Loss: 0.34227\n",
      "Epoch 588/1000 --- Loss: 0.34291\n",
      "Epoch 589/1000 --- Loss: 0.34338\n",
      "Epoch 590/1000 --- Loss: 0.34310\n",
      "Epoch 591/1000 --- Loss: 0.34278\n",
      "Epoch 592/1000 --- Loss: 0.34259\n",
      "Epoch 593/1000 --- Loss: 0.34395\n",
      "Epoch 594/1000 --- Loss: 0.34330\n",
      "Epoch 595/1000 --- Loss: 0.34260\n",
      "Epoch 596/1000 --- Loss: 0.34212\n",
      "Epoch 597/1000 --- Loss: 0.34224\n",
      "Epoch 598/1000 --- Loss: 0.34297\n",
      "Epoch 599/1000 --- Loss: 0.34259\n",
      "Epoch 600/1000 --- Loss: 0.34268\n",
      "Epoch 601/1000 --- Loss: 0.34282\n",
      "Epoch 602/1000 --- Loss: 0.34387\n",
      "Epoch 603/1000 --- Loss: 0.34288\n",
      "Epoch 604/1000 --- Loss: 0.34257\n",
      "Epoch 605/1000 --- Loss: 0.34296\n",
      "Epoch 606/1000 --- Loss: 0.34237\n",
      "Epoch 607/1000 --- Loss: 0.34266\n",
      "Epoch 608/1000 --- Loss: 0.34303\n",
      "Epoch 609/1000 --- Loss: 0.34180\n",
      "Epoch 610/1000 --- Loss: 0.34241\n",
      "Epoch 611/1000 --- Loss: 0.34398\n",
      "Epoch 612/1000 --- Loss: 0.34334\n",
      "Epoch 613/1000 --- Loss: 0.34293\n",
      "Epoch 614/1000 --- Loss: 0.34241\n",
      "Epoch 615/1000 --- Loss: 0.34280\n",
      "Epoch 616/1000 --- Loss: 0.34238\n",
      "Epoch 617/1000 --- Loss: 0.34309\n",
      "Epoch 618/1000 --- Loss: 0.34232\n",
      "Epoch 619/1000 --- Loss: 0.34331\n",
      "Epoch 620/1000 --- Loss: 0.34275\n",
      "Epoch 621/1000 --- Loss: 0.34290\n",
      "Epoch 622/1000 --- Loss: 0.34330\n",
      "Epoch 623/1000 --- Loss: 0.34227\n",
      "Epoch 624/1000 --- Loss: 0.34356\n",
      "Epoch 625/1000 --- Loss: 0.34417\n",
      "Epoch 626/1000 --- Loss: 0.34313\n",
      "Epoch 627/1000 --- Loss: 0.34285\n",
      "Epoch 628/1000 --- Loss: 0.34282\n",
      "Epoch 629/1000 --- Loss: 0.34231\n",
      "Epoch 630/1000 --- Loss: 0.34283\n",
      "Epoch 631/1000 --- Loss: 0.34312\n",
      "Epoch 632/1000 --- Loss: 0.34261\n",
      "Epoch 633/1000 --- Loss: 0.34312\n",
      "Epoch 634/1000 --- Loss: 0.34243\n",
      "Epoch 635/1000 --- Loss: 0.34284\n",
      "Epoch 636/1000 --- Loss: 0.34294\n",
      "Epoch 637/1000 --- Loss: 0.34238\n",
      "Epoch 638/1000 --- Loss: 0.34242\n",
      "Epoch 639/1000 --- Loss: 0.34261\n",
      "Epoch 640/1000 --- Loss: 0.34315\n",
      "Epoch 641/1000 --- Loss: 0.34298\n",
      "Epoch 642/1000 --- Loss: 0.34281\n",
      "Epoch 643/1000 --- Loss: 0.34318\n",
      "Epoch 644/1000 --- Loss: 0.34225\n",
      "Epoch 645/1000 --- Loss: 0.34305\n",
      "Epoch 646/1000 --- Loss: 0.34338\n",
      "Epoch 647/1000 --- Loss: 0.34346\n",
      "Epoch 648/1000 --- Loss: 0.34240\n",
      "Epoch 649/1000 --- Loss: 0.34303\n",
      "Epoch 650/1000 --- Loss: 0.34240\n",
      "Epoch 651/1000 --- Loss: 0.34326\n",
      "Epoch 652/1000 --- Loss: 0.34281\n",
      "Epoch 653/1000 --- Loss: 0.34292\n",
      "Epoch 654/1000 --- Loss: 0.34315\n",
      "Epoch 655/1000 --- Loss: 0.34225\n",
      "Epoch 656/1000 --- Loss: 0.34244\n",
      "Epoch 657/1000 --- Loss: 0.34328\n",
      "Epoch 658/1000 --- Loss: 0.34301\n",
      "Epoch 659/1000 --- Loss: 0.34298\n",
      "Epoch 660/1000 --- Loss: 0.34335\n",
      "Epoch 661/1000 --- Loss: 0.34317\n",
      "Epoch 662/1000 --- Loss: 0.34335\n",
      "Epoch 663/1000 --- Loss: 0.34336\n",
      "Epoch 664/1000 --- Loss: 0.34357\n",
      "Epoch 665/1000 --- Loss: 0.34296\n",
      "Epoch 666/1000 --- Loss: 0.34268\n",
      "Epoch 667/1000 --- Loss: 0.34263\n",
      "Epoch 668/1000 --- Loss: 0.34320\n",
      "Epoch 669/1000 --- Loss: 0.34250\n",
      "Epoch 670/1000 --- Loss: 0.34365\n",
      "Epoch 671/1000 --- Loss: 0.34300\n",
      "Epoch 672/1000 --- Loss: 0.34242\n",
      "Epoch 673/1000 --- Loss: 0.34261\n",
      "Epoch 674/1000 --- Loss: 0.34238\n",
      "Epoch 675/1000 --- Loss: 0.34324\n",
      "Epoch 676/1000 --- Loss: 0.34310\n",
      "Epoch 677/1000 --- Loss: 0.34279\n",
      "Epoch 678/1000 --- Loss: 0.34223\n",
      "Epoch 679/1000 --- Loss: 0.34309\n",
      "Epoch 680/1000 --- Loss: 0.34338\n",
      "Epoch 681/1000 --- Loss: 0.34236\n",
      "Epoch 682/1000 --- Loss: 0.34240\n",
      "Epoch 683/1000 --- Loss: 0.34288\n",
      "Epoch 684/1000 --- Loss: 0.34282\n",
      "Epoch 685/1000 --- Loss: 0.34260\n",
      "Epoch 686/1000 --- Loss: 0.34288\n",
      "Epoch 687/1000 --- Loss: 0.34384\n",
      "Epoch 688/1000 --- Loss: 0.34209\n",
      "Epoch 689/1000 --- Loss: 0.34258\n",
      "Epoch 690/1000 --- Loss: 0.34285\n",
      "Epoch 691/1000 --- Loss: 0.34252\n",
      "Epoch 692/1000 --- Loss: 0.34314\n",
      "Epoch 693/1000 --- Loss: 0.34284\n",
      "Epoch 694/1000 --- Loss: 0.34317\n",
      "Epoch 695/1000 --- Loss: 0.34284\n",
      "Epoch 696/1000 --- Loss: 0.34260\n",
      "Epoch 697/1000 --- Loss: 0.34239\n",
      "Epoch 698/1000 --- Loss: 0.34257\n",
      "Epoch 699/1000 --- Loss: 0.34320\n",
      "Epoch 700/1000 --- Loss: 0.34243\n",
      "Epoch 701/1000 --- Loss: 0.34286\n",
      "Epoch 702/1000 --- Loss: 0.34337\n",
      "Epoch 703/1000 --- Loss: 0.34277\n",
      "Epoch 704/1000 --- Loss: 0.34276\n",
      "Epoch 705/1000 --- Loss: 0.34284\n",
      "Epoch 706/1000 --- Loss: 0.34304\n",
      "Epoch 707/1000 --- Loss: 0.34233\n",
      "Epoch 708/1000 --- Loss: 0.34303\n",
      "Epoch 709/1000 --- Loss: 0.34350\n",
      "Epoch 710/1000 --- Loss: 0.34304\n",
      "Epoch 711/1000 --- Loss: 0.34315\n",
      "Epoch 712/1000 --- Loss: 0.34315\n",
      "Epoch 713/1000 --- Loss: 0.34267\n",
      "Epoch 714/1000 --- Loss: 0.34292\n",
      "Epoch 715/1000 --- Loss: 0.34340\n",
      "Epoch 716/1000 --- Loss: 0.34277\n",
      "Epoch 717/1000 --- Loss: 0.34326\n",
      "Epoch 718/1000 --- Loss: 0.34186\n",
      "Epoch 719/1000 --- Loss: 0.34329\n",
      "Epoch 720/1000 --- Loss: 0.34328\n",
      "Epoch 721/1000 --- Loss: 0.34290\n",
      "Epoch 722/1000 --- Loss: 0.34367\n",
      "Epoch 723/1000 --- Loss: 0.34254\n",
      "Epoch 724/1000 --- Loss: 0.34264\n",
      "Epoch 725/1000 --- Loss: 0.34239\n",
      "Epoch 726/1000 --- Loss: 0.34317\n",
      "Epoch 727/1000 --- Loss: 0.34236\n",
      "Epoch 728/1000 --- Loss: 0.34223\n",
      "Epoch 729/1000 --- Loss: 0.34228\n",
      "Epoch 730/1000 --- Loss: 0.34280\n",
      "Epoch 731/1000 --- Loss: 0.34244\n",
      "Epoch 732/1000 --- Loss: 0.34179\n",
      "Epoch 733/1000 --- Loss: 0.34289\n",
      "Epoch 734/1000 --- Loss: 0.34303\n",
      "Epoch 735/1000 --- Loss: 0.34230\n",
      "Epoch 736/1000 --- Loss: 0.34303\n",
      "Epoch 737/1000 --- Loss: 0.34296\n",
      "Epoch 738/1000 --- Loss: 0.34242\n",
      "Epoch 739/1000 --- Loss: 0.34291\n",
      "Epoch 740/1000 --- Loss: 0.34293\n",
      "Epoch 741/1000 --- Loss: 0.34321\n",
      "Epoch 742/1000 --- Loss: 0.34168\n",
      "Epoch 743/1000 --- Loss: 0.34280\n",
      "Epoch 744/1000 --- Loss: 0.34222\n",
      "Epoch 745/1000 --- Loss: 0.34342\n",
      "Epoch 746/1000 --- Loss: 0.34241\n",
      "Epoch 747/1000 --- Loss: 0.34346\n",
      "Epoch 748/1000 --- Loss: 0.34247\n",
      "Epoch 749/1000 --- Loss: 0.34353\n",
      "Epoch 750/1000 --- Loss: 0.34337\n",
      "Epoch 751/1000 --- Loss: 0.34321\n",
      "Epoch 752/1000 --- Loss: 0.34286\n",
      "Epoch 753/1000 --- Loss: 0.34263\n",
      "Epoch 754/1000 --- Loss: 0.34227\n",
      "Epoch 755/1000 --- Loss: 0.34282\n",
      "Epoch 756/1000 --- Loss: 0.34274\n",
      "Epoch 757/1000 --- Loss: 0.34263\n",
      "Epoch 758/1000 --- Loss: 0.34285\n",
      "Epoch 759/1000 --- Loss: 0.34331\n",
      "Epoch 760/1000 --- Loss: 0.34217\n",
      "Epoch 761/1000 --- Loss: 0.34294\n",
      "Epoch 762/1000 --- Loss: 0.34306\n",
      "Epoch 763/1000 --- Loss: 0.34338\n",
      "Epoch 764/1000 --- Loss: 0.34332\n",
      "Epoch 765/1000 --- Loss: 0.34332\n",
      "Epoch 766/1000 --- Loss: 0.34295\n",
      "Epoch 767/1000 --- Loss: 0.34304\n",
      "Epoch 768/1000 --- Loss: 0.34311\n",
      "Epoch 769/1000 --- Loss: 0.34221\n",
      "Epoch 770/1000 --- Loss: 0.34220\n",
      "Epoch 771/1000 --- Loss: 0.34340\n",
      "Epoch 772/1000 --- Loss: 0.34263\n",
      "Epoch 773/1000 --- Loss: 0.34217\n",
      "Epoch 774/1000 --- Loss: 0.34310\n",
      "Epoch 775/1000 --- Loss: 0.34304\n",
      "Epoch 776/1000 --- Loss: 0.34349\n",
      "Epoch 777/1000 --- Loss: 0.34319\n",
      "Epoch 778/1000 --- Loss: 0.34269\n",
      "Epoch 779/1000 --- Loss: 0.34269\n",
      "Epoch 780/1000 --- Loss: 0.34282\n",
      "Epoch 781/1000 --- Loss: 0.34270\n",
      "Epoch 782/1000 --- Loss: 0.34310\n",
      "Epoch 783/1000 --- Loss: 0.34310\n",
      "Epoch 784/1000 --- Loss: 0.34287\n",
      "Epoch 785/1000 --- Loss: 0.34231\n",
      "Epoch 786/1000 --- Loss: 0.34271\n",
      "Epoch 787/1000 --- Loss: 0.34280\n",
      "Epoch 788/1000 --- Loss: 0.34222\n",
      "Epoch 789/1000 --- Loss: 0.34320\n",
      "Epoch 790/1000 --- Loss: 0.34304\n",
      "Epoch 791/1000 --- Loss: 0.34216\n",
      "Epoch 792/1000 --- Loss: 0.34255\n",
      "Epoch 793/1000 --- Loss: 0.34373\n",
      "Epoch 794/1000 --- Loss: 0.34289\n",
      "Epoch 795/1000 --- Loss: 0.34272\n",
      "Epoch 796/1000 --- Loss: 0.34256\n",
      "Epoch 797/1000 --- Loss: 0.34343\n",
      "Epoch 798/1000 --- Loss: 0.34265\n",
      "Epoch 799/1000 --- Loss: 0.34266\n",
      "Epoch 800/1000 --- Loss: 0.34289\n",
      "Epoch 801/1000 --- Loss: 0.34381\n",
      "Epoch 802/1000 --- Loss: 0.34243\n",
      "Epoch 803/1000 --- Loss: 0.34265\n",
      "Epoch 804/1000 --- Loss: 0.34201\n",
      "Epoch 805/1000 --- Loss: 0.34211\n",
      "Epoch 806/1000 --- Loss: 0.34290\n",
      "Epoch 807/1000 --- Loss: 0.34420\n",
      "Epoch 808/1000 --- Loss: 0.34333\n",
      "Epoch 809/1000 --- Loss: 0.34408\n",
      "Epoch 810/1000 --- Loss: 0.34272\n",
      "Epoch 811/1000 --- Loss: 0.34244\n",
      "Epoch 812/1000 --- Loss: 0.34268\n",
      "Epoch 813/1000 --- Loss: 0.34291\n",
      "Epoch 814/1000 --- Loss: 0.34252\n",
      "Epoch 815/1000 --- Loss: 0.34248\n",
      "Epoch 816/1000 --- Loss: 0.34307\n",
      "Epoch 817/1000 --- Loss: 0.34285\n",
      "Epoch 818/1000 --- Loss: 0.34380\n",
      "Epoch 819/1000 --- Loss: 0.34304\n",
      "Epoch 820/1000 --- Loss: 0.34326\n",
      "Epoch 821/1000 --- Loss: 0.34283\n",
      "Epoch 822/1000 --- Loss: 0.34404\n",
      "Epoch 823/1000 --- Loss: 0.34236\n",
      "Epoch 824/1000 --- Loss: 0.34289\n",
      "Epoch 825/1000 --- Loss: 0.34340\n",
      "Epoch 826/1000 --- Loss: 0.34270\n",
      "Epoch 827/1000 --- Loss: 0.34281\n",
      "Epoch 828/1000 --- Loss: 0.34242\n",
      "Epoch 829/1000 --- Loss: 0.34348\n",
      "Epoch 830/1000 --- Loss: 0.34314\n",
      "Epoch 831/1000 --- Loss: 0.34269\n",
      "Epoch 832/1000 --- Loss: 0.34310\n",
      "Epoch 833/1000 --- Loss: 0.34193\n",
      "Epoch 834/1000 --- Loss: 0.34337\n",
      "Epoch 835/1000 --- Loss: 0.34254\n",
      "Epoch 836/1000 --- Loss: 0.34234\n",
      "Epoch 837/1000 --- Loss: 0.34266\n",
      "Epoch 838/1000 --- Loss: 0.34199\n",
      "Epoch 839/1000 --- Loss: 0.34308\n",
      "Epoch 840/1000 --- Loss: 0.34228\n",
      "Epoch 841/1000 --- Loss: 0.34249\n",
      "Epoch 842/1000 --- Loss: 0.34339\n",
      "Epoch 843/1000 --- Loss: 0.34292\n",
      "Epoch 844/1000 --- Loss: 0.34262\n",
      "Epoch 845/1000 --- Loss: 0.34226\n",
      "Epoch 846/1000 --- Loss: 0.34306\n",
      "Epoch 847/1000 --- Loss: 0.34317\n",
      "Epoch 848/1000 --- Loss: 0.34213\n",
      "Epoch 849/1000 --- Loss: 0.34336\n",
      "Epoch 850/1000 --- Loss: 0.34248\n",
      "Epoch 851/1000 --- Loss: 0.34351\n",
      "Epoch 852/1000 --- Loss: 0.34338\n",
      "Epoch 853/1000 --- Loss: 0.34335\n",
      "Epoch 854/1000 --- Loss: 0.34299\n",
      "Epoch 855/1000 --- Loss: 0.34243\n",
      "Epoch 856/1000 --- Loss: 0.34228\n",
      "Epoch 857/1000 --- Loss: 0.34322\n",
      "Epoch 858/1000 --- Loss: 0.34339\n",
      "Epoch 859/1000 --- Loss: 0.34214\n",
      "Epoch 860/1000 --- Loss: 0.34230\n",
      "Epoch 861/1000 --- Loss: 0.34264\n",
      "Epoch 862/1000 --- Loss: 0.34323\n",
      "Epoch 863/1000 --- Loss: 0.34286\n",
      "Epoch 864/1000 --- Loss: 0.34280\n",
      "Epoch 865/1000 --- Loss: 0.34269\n",
      "Epoch 866/1000 --- Loss: 0.34357\n",
      "Epoch 867/1000 --- Loss: 0.34231\n",
      "Epoch 868/1000 --- Loss: 0.34218\n",
      "Epoch 869/1000 --- Loss: 0.34244\n",
      "Epoch 870/1000 --- Loss: 0.34279\n",
      "Epoch 871/1000 --- Loss: 0.34283\n",
      "Epoch 872/1000 --- Loss: 0.34298\n",
      "Epoch 873/1000 --- Loss: 0.34276\n",
      "Epoch 874/1000 --- Loss: 0.34256\n",
      "Epoch 875/1000 --- Loss: 0.34249\n",
      "Epoch 876/1000 --- Loss: 0.34144\n",
      "Epoch 877/1000 --- Loss: 0.34289\n",
      "Epoch 878/1000 --- Loss: 0.34289\n",
      "Epoch 879/1000 --- Loss: 0.34254\n",
      "Epoch 880/1000 --- Loss: 0.34348\n",
      "Epoch 881/1000 --- Loss: 0.34264\n",
      "Epoch 882/1000 --- Loss: 0.34240\n",
      "Epoch 883/1000 --- Loss: 0.34278\n",
      "Epoch 884/1000 --- Loss: 0.34344\n",
      "Epoch 885/1000 --- Loss: 0.34212\n",
      "Epoch 886/1000 --- Loss: 0.34183\n",
      "Epoch 887/1000 --- Loss: 0.34301\n",
      "Epoch 888/1000 --- Loss: 0.34289\n",
      "Epoch 889/1000 --- Loss: 0.34277\n",
      "Epoch 890/1000 --- Loss: 0.34221\n",
      "Epoch 891/1000 --- Loss: 0.34276\n",
      "Epoch 892/1000 --- Loss: 0.34234\n",
      "Epoch 893/1000 --- Loss: 0.34304\n",
      "Epoch 894/1000 --- Loss: 0.34278\n",
      "Epoch 895/1000 --- Loss: 0.34282\n",
      "Epoch 896/1000 --- Loss: 0.34256\n",
      "Epoch 897/1000 --- Loss: 0.34360\n",
      "Epoch 898/1000 --- Loss: 0.34336\n",
      "Epoch 899/1000 --- Loss: 0.34324\n",
      "Epoch 900/1000 --- Loss: 0.34342\n",
      "Epoch 901/1000 --- Loss: 0.34319\n",
      "Epoch 902/1000 --- Loss: 0.34381\n",
      "Epoch 903/1000 --- Loss: 0.34335\n",
      "Epoch 904/1000 --- Loss: 0.34303\n",
      "Epoch 905/1000 --- Loss: 0.34297\n",
      "Epoch 906/1000 --- Loss: 0.34224\n",
      "Epoch 907/1000 --- Loss: 0.34314\n",
      "Epoch 908/1000 --- Loss: 0.34326\n",
      "Epoch 909/1000 --- Loss: 0.34270\n",
      "Epoch 910/1000 --- Loss: 0.34325\n",
      "Epoch 911/1000 --- Loss: 0.34226\n",
      "Epoch 912/1000 --- Loss: 0.34268\n",
      "Epoch 913/1000 --- Loss: 0.34317\n",
      "Epoch 914/1000 --- Loss: 0.34275\n",
      "Epoch 915/1000 --- Loss: 0.34280\n",
      "Epoch 916/1000 --- Loss: 0.34229\n",
      "Epoch 917/1000 --- Loss: 0.34386\n",
      "Epoch 918/1000 --- Loss: 0.34329\n",
      "Epoch 919/1000 --- Loss: 0.34258\n",
      "Epoch 920/1000 --- Loss: 0.34341\n",
      "Epoch 921/1000 --- Loss: 0.34260\n",
      "Epoch 922/1000 --- Loss: 0.34257\n",
      "Epoch 923/1000 --- Loss: 0.34370\n",
      "Epoch 924/1000 --- Loss: 0.34322\n",
      "Epoch 925/1000 --- Loss: 0.34249\n",
      "Epoch 926/1000 --- Loss: 0.34306\n",
      "Epoch 927/1000 --- Loss: 0.34372\n",
      "Epoch 928/1000 --- Loss: 0.34276\n",
      "Epoch 929/1000 --- Loss: 0.34244\n",
      "Epoch 930/1000 --- Loss: 0.34272\n",
      "Epoch 931/1000 --- Loss: 0.34208\n",
      "Epoch 932/1000 --- Loss: 0.34344\n",
      "Epoch 933/1000 --- Loss: 0.34246\n",
      "Epoch 934/1000 --- Loss: 0.34322\n",
      "Epoch 935/1000 --- Loss: 0.34284\n",
      "Epoch 936/1000 --- Loss: 0.34292\n",
      "Epoch 937/1000 --- Loss: 0.34329\n",
      "Epoch 938/1000 --- Loss: 0.34336\n",
      "Epoch 939/1000 --- Loss: 0.34301\n",
      "Epoch 940/1000 --- Loss: 0.34214\n",
      "Epoch 941/1000 --- Loss: 0.34225\n",
      "Epoch 942/1000 --- Loss: 0.34371\n",
      "Epoch 943/1000 --- Loss: 0.34337\n",
      "Epoch 944/1000 --- Loss: 0.34275\n",
      "Epoch 945/1000 --- Loss: 0.34228\n",
      "Epoch 946/1000 --- Loss: 0.34178\n",
      "Epoch 947/1000 --- Loss: 0.34273\n",
      "Epoch 948/1000 --- Loss: 0.34266\n",
      "Epoch 949/1000 --- Loss: 0.34305\n",
      "Epoch 950/1000 --- Loss: 0.34287\n",
      "Epoch 951/1000 --- Loss: 0.34325\n",
      "Epoch 952/1000 --- Loss: 0.34332\n",
      "Epoch 953/1000 --- Loss: 0.34272\n",
      "Epoch 954/1000 --- Loss: 0.34348\n",
      "Epoch 955/1000 --- Loss: 0.34281\n",
      "Epoch 956/1000 --- Loss: 0.34324\n",
      "Epoch 957/1000 --- Loss: 0.34266\n",
      "Epoch 958/1000 --- Loss: 0.34311\n",
      "Epoch 959/1000 --- Loss: 0.34338\n",
      "Epoch 960/1000 --- Loss: 0.34390\n",
      "Epoch 961/1000 --- Loss: 0.34189\n",
      "Epoch 962/1000 --- Loss: 0.34370\n",
      "Epoch 963/1000 --- Loss: 0.34290\n",
      "Epoch 964/1000 --- Loss: 0.34288\n",
      "Epoch 965/1000 --- Loss: 0.34331\n",
      "Epoch 966/1000 --- Loss: 0.34312\n",
      "Epoch 967/1000 --- Loss: 0.34291\n",
      "Epoch 968/1000 --- Loss: 0.34373\n",
      "Epoch 969/1000 --- Loss: 0.34363\n",
      "Epoch 970/1000 --- Loss: 0.34288\n",
      "Epoch 971/1000 --- Loss: 0.34329\n",
      "Epoch 972/1000 --- Loss: 0.34281\n",
      "Epoch 973/1000 --- Loss: 0.34248\n",
      "Epoch 974/1000 --- Loss: 0.34322\n",
      "Epoch 975/1000 --- Loss: 0.34283\n",
      "Epoch 976/1000 --- Loss: 0.34287\n",
      "Epoch 977/1000 --- Loss: 0.34269\n",
      "Epoch 978/1000 --- Loss: 0.34280\n",
      "Epoch 979/1000 --- Loss: 0.34337\n",
      "Epoch 980/1000 --- Loss: 0.34291\n",
      "Epoch 981/1000 --- Loss: 0.34311\n",
      "Epoch 982/1000 --- Loss: 0.34287\n",
      "Epoch 983/1000 --- Loss: 0.34189\n",
      "Epoch 984/1000 --- Loss: 0.34261\n",
      "Epoch 985/1000 --- Loss: 0.34274\n",
      "Epoch 986/1000 --- Loss: 0.34206\n",
      "Epoch 987/1000 --- Loss: 0.34308\n",
      "Epoch 988/1000 --- Loss: 0.34287\n",
      "Epoch 989/1000 --- Loss: 0.34278\n",
      "Epoch 990/1000 --- Loss: 0.34246\n",
      "Epoch 991/1000 --- Loss: 0.34274\n",
      "Epoch 992/1000 --- Loss: 0.34297\n",
      "Epoch 993/1000 --- Loss: 0.34339\n",
      "Epoch 994/1000 --- Loss: 0.34260\n",
      "Epoch 995/1000 --- Loss: 0.34311\n",
      "Epoch 996/1000 --- Loss: 0.34382\n",
      "Epoch 997/1000 --- Loss: 0.34314\n",
      "Epoch 998/1000 --- Loss: 0.34248\n",
      "Epoch 999/1000 --- Loss: 0.34314\n",
      "Epoch 1000/1000 --- Loss: 0.34360\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "gru = GRU(dataset.xs.shape[-1], 2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(gru.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    random_index = torch.randint(len(dataset.xs), (len(dataset.xs), 1))[:, 0]\n",
    "    logits, state = mvt(inputs=dataset.xs[random_index], batch_first=True)\n",
    "    \n",
    "    mask = ~torch.isnan(dataset.xs[random_index, :, 0]).reshape(-1)\n",
    "    \n",
    "    # compute loss\n",
    "    loss = criterion(\n",
    "        logits.reshape(-1, mvt.n_actions)[mask],\n",
    "        dataset.ys.argmax(dim=-1, keepdim=True).long().reshape(-1)[mask], \n",
    "        )\n",
    "    \n",
    "    # backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs} --- Loss: {loss.item():.5f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "spice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
