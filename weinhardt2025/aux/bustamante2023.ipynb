{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tf7jlYw4NA0v",
    "outputId": "0969ca34-675d-422e-cbfb-7387d9bcd8ad"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/whyhardt/SPICE.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oXIbg826NS5i",
    "outputId": "3825864a-cb2d-4ad5-f2e5-79a4e81dfc3e"
   },
   "outputs": [],
   "source": [
    "# !pip install -e SPICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "f0uVlABYznR5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from spice import SpiceEstimator, SpiceConfig, convert_dataset, BaseRNN, plot_session\n",
    "\n",
    "# For custom RNN\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data first with the `convert_dataset` method. This method returns a `SpiceDataset` object which we can use right away "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: torch.Size([1997, 112, 9])\n",
      "Number of participants: 250\n",
      "Number of actions in dataset: 2\n",
      "Number of additional inputs: 2\n"
     ]
    }
   ],
   "source": [
    "# Load your data\n",
    "file = '../data/bustamante2023/bustamante2023_processed.csv'\n",
    "dataset = convert_dataset(\n",
    "    file = file,\n",
    "    df_participant_id='subject_id',\n",
    "    df_choice='decision',\n",
    "    df_reward='reward',\n",
    "    df_block='overall_round',\n",
    "    additional_inputs=['harvest_duration', 'travel_duration'],\n",
    "    timeshift_additional_inputs=False,\n",
    "    )\n",
    "\n",
    "# structure of dataset:\n",
    "# dataset has two main attributes: xs -> inputs; ys -> targets (next action)\n",
    "# shape: (n_participants*n_blocks*n_experiments, n_timesteps, features)\n",
    "# features are (n_actions * action, n_actions * reward, n_additional_inputs * additional_input, block_number, experiment_id, participant_id)\n",
    "\n",
    "# in order to set up the participant embedding we have to compute the number of unique participants in our data \n",
    "# to get the number of participants n_participants we do:\n",
    "n_participants = len(dataset.xs[..., -1].unique())\n",
    "\n",
    "print(f\"Shape of dataset: {dataset.xs.shape}\")\n",
    "print(f\"Number of participants: {n_participants}\")\n",
    "n_actions = dataset.ys.shape[-1]\n",
    "print(f\"Number of actions in dataset: {n_actions}\")\n",
    "print(f\"Number of additional inputs: {dataset.xs.shape[-1]-2*n_actions-3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.7561,    nan, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.6859,    nan, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 1.0000,    nan, 0.0510, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.7515,    nan, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.6407,    nan, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.5662,    nan, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 1.0000,    nan, 0.0510, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.8706,    nan, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.7226,    nan, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 1.0000,    nan, 0.0510, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect dataset\n",
    "dataset.xs[0, :10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPICE Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to define the configuration for SPICE with a `SpiceConfig` object.\n",
    "\n",
    "The `SpiceConfig` takes as arguments \n",
    "1. `library_setup (dict)`: Defining the variable names of each module.\n",
    "2. `memory_state (dict)`: Defining the memory state variables and their initial values.\n",
    "3. `states_in_logit (list)`: Defining which of the memory state variables are used later for the logit computation. This is necessary for some background processes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spice_config = SpiceConfig(\n",
    "    library_setup={\n",
    "        'value_stay': ['reward', 'harvest_duration'],\n",
    "        'value_exit': ['travel_duration'],\n",
    "    },\n",
    "    \n",
    "    memory_state={\n",
    "            'value': 0.,\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we are going to define the SPICE model which is a child of the `BaseRNN` and `torch.nn.Module` class and takes as required arguments:\n",
    "1. `spice_config (SpiceConfig)`: previously defined SpiceConfig object\n",
    "2. `n_actions (int)`: number of possible actions in your dataset (including non-displayed ones if applicable).\n",
    "3. `n_participants (int)`: number of participants in your dataset.\n",
    "\n",
    "As usual for a `torch.nn.Module` we have to define at least the `__init__` method and the `forward` method.\n",
    "The `forward` method gets called when computing a forward pass through the model and takes as inputs `(inputs (SpiceDataset.xs), prev_state (dict, default: None), batch_first (bool, default: False))` and returns `(logits (torch.Tensor, shape: (n_participants*n_blocks*n_experiments, timesteps, n_actions)), updated_state (dict))`. Two necessary method calls inside the forward pass are:\n",
    "1. `self.init_forward_pass(inputs, prev_state, batch_first) -> SpiceSignals`: returns a `SpiceSignals` object which carries all relevant information already processed.\n",
    "2. `self.post_forward_pass(SpiceSignals, batch_first) -> SpiceSignals`: does some re-arranging of the logits to adhere to `batch_first`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "z0kOR2Qgz0FZ"
   },
   "outputs": [],
   "source": [
    "class SPICERNN(BaseRNN):\n",
    "    \n",
    "    def __init__(self, spice_config, **kwargs):\n",
    "        super().__init__(spice_config=spice_config, **kwargs)\n",
    "        \n",
    "        # participant embedding\n",
    "        self.participant_embedding = self.setup_embedding(num_embeddings=n_participants, embedding_size=self.embedding_size, dropout=0.)\n",
    "        \n",
    "        # set up the submodules\n",
    "        self.setup_module(key_module='value_stay', input_size=2+self.embedding_size)\n",
    "        self.setup_module(key_module='value_exit', input_size=1+self.embedding_size)\n",
    "        \n",
    "    def forward(self, inputs, prev_state, batch_first=False):\n",
    "        \n",
    "        spice_signals = self.init_forward_pass(inputs, prev_state, batch_first)\n",
    "        \n",
    "        harvest_duration = spice_signals.additional_inputs[..., 0].unsqueeze(-1).repeat(1, 1, self.n_actions)\n",
    "        travel_duration = spice_signals.additional_inputs[..., 1].unsqueeze(-1).repeat(1, 1, self.n_actions)\n",
    "        rewards_chosen = (spice_signals.actions * spice_signals.rewards).sum(dim=-1, keepdim=True).repeat(1, 1, self.n_actions)\n",
    "        \n",
    "        # time-invariant participant features\n",
    "        participant_embeddings = self.participant_embedding(spice_signals.participant_ids)\n",
    "        mask_stay = torch.tensor((1,0)).reshape(1, self.n_actions).repeat(rewards_chosen.shape[1], 1)\n",
    "        mask_exit = torch.tensor((0,1)).reshape(1, self.n_actions).repeat(rewards_chosen.shape[1], 1)\n",
    "        \n",
    "        for timestep in spice_signals.timesteps:\n",
    "            \n",
    "            # update chosen value\n",
    "            self.call_module(\n",
    "                key_module='value_stay',\n",
    "                key_state='value',\n",
    "                action_mask=mask_stay,\n",
    "                inputs=(\n",
    "                    rewards_chosen[timestep], \n",
    "                    harvest_duration[timestep], \n",
    "                    ),\n",
    "                participant_index=spice_signals.participant_ids,\n",
    "                participant_embedding=participant_embeddings,\n",
    "            )\n",
    "            \n",
    "            # update not chosen value\n",
    "            self.call_module(\n",
    "                key_module='value_exit',\n",
    "                key_state='value',\n",
    "                action_mask=mask_exit,\n",
    "                inputs=(\n",
    "                    travel_duration[timestep], \n",
    "                    ),\n",
    "                participant_index=spice_signals.participant_ids,\n",
    "                participant_embedding=participant_embeddings,\n",
    "            )\n",
    "            \n",
    "            # transform logits from item-space to action-space\n",
    "            spice_signals.logits[timestep] = self.state['value']\n",
    "            \n",
    "        spice_signals = self.post_forward_pass(spice_signals, batch_first)\n",
    "        \n",
    "        return spice_signals.logits, self.get_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's setup now the `SpiceEstimator` object and fit it to the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_spice = '../params/bustamante2023/spice_bustamante2023.pkl'\n",
    "estimator = SpiceEstimator(\n",
    "        # model paramaeters\n",
    "        rnn_class=SPICERNN,\n",
    "        spice_config=spice_config,\n",
    "        n_actions=2,\n",
    "        n_participants=n_participants,\n",
    "        n_experiments=1,\n",
    "        \n",
    "        # rnn training parameters\n",
    "        epochs=1000,\n",
    "        warmup_steps=200,\n",
    "        learning_rate=0.01,\n",
    "        \n",
    "        # sindy fitting parameters\n",
    "        sindy_weight=0.1,\n",
    "        sindy_threshold=0.05,\n",
    "        sindy_threshold_frequency=1,\n",
    "        sindy_threshold_terms=1,\n",
    "        sindy_cutoff_patience=100,\n",
    "        sindy_epochs=1000,\n",
    "        sindy_alpha=0.0001,\n",
    "        sindy_library_polynomial_degree=2,\n",
    "        sindy_ensemble_size=1,\n",
    "        \n",
    "        # additional generalization parameters\n",
    "        batch_size=1024,\n",
    "        bagging=True,\n",
    "        scheduler=True,\n",
    "        \n",
    "        verbose=True,\n",
    "        save_path_spice=path_spice,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "id": "3EnmDiUMWq6e",
    "outputId": "e53b1bbd-4173-4d2c-bcdc-15832bc31bd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training on cpu...\n",
      "================================================================================\n",
      "\n",
      "Training the RNN...\n",
      "================================================================================\n",
      "Epoch 1/1000 --- L(Train): 0.5092973 --- L(Val, RNN): 0.3817756 --- L(Val, SINDy): 3.8043301 --- Time: 1.18s; --- Convergence: 8.09e-01; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.002 1 + 1.001 value_stay[t] + 0.002 reward + -0.0 harvest_duration + -0.0 value_stay^2 + 0.001 value_stay*reward + -0.001 value_stay*harvest_duration + 0.002 reward^2 + 0.004 reward*harvest_duration + -0.001 harvest_duration^2 \n",
      "value_exit[t+1] = 0.011 1 + 1.011 value_exit[t] + -0.01 travel_duration + 0.01 value_exit^2 + -0.009 value_exit*travel_duration + -0.009 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 2/1000 --- L(Train): 0.3793685 --- L(Val, RNN): 0.3679760 --- L(Val, SINDy): 2.1244578 --- Time: 0.84s; --- Convergence: 4.11e-01; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = -0.001 1 + 0.998 value_stay[t] + 0.005 reward + -0.004 harvest_duration + -0.001 value_stay^2 + -0.0 value_stay*reward + -0.005 value_stay*harvest_duration + 0.005 reward^2 + 0.008 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = 0.005 1 + 1.019 value_exit[t] + -0.002 travel_duration + 0.003 value_exit^2 + -0.016 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 3/1000 --- L(Train): 0.3648787 --- L(Val, RNN): 0.3639058 --- L(Val, SINDy): 2.9112027 --- Time: 0.85s; --- Convergence: 2.08e-01; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.005 1 + 1.001 value_stay[t] + 0.011 reward + 0.003 harvest_duration + -0.001 value_stay^2 + 0.002 value_stay*reward + -0.002 value_stay*harvest_duration + 0.011 reward^2 + 0.015 reward*harvest_duration + 0.001 harvest_duration^2 \n",
      "value_exit[t+1] = -0.003 1 + 1.026 value_exit[t] + -0.003 travel_duration + -0.005 value_exit^2 + -0.016 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 4/1000 --- L(Train): 0.3651667 --- L(Val, RNN): 0.3619312 --- L(Val, SINDy): 2.7944717 --- Time: 0.91s; --- Convergence: 1.05e-01; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.001 1 + 0.996 value_stay[t] + 0.009 reward + -0.001 harvest_duration + -0.006 value_stay^2 + -0.003 value_stay*reward + -0.007 value_stay*harvest_duration + 0.01 reward^2 + 0.012 reward*harvest_duration + -0.003 harvest_duration^2 \n",
      "value_exit[t+1] = -0.011 1 + 1.035 value_exit[t] + -0.005 travel_duration + -0.013 value_exit^2 + -0.014 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 5/1000 --- L(Train): 0.3651251 --- L(Val, RNN): 0.3609214 --- L(Val, SINDy): 2.1436307 --- Time: 0.90s; --- Convergence: 5.29e-02; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = -0.002 1 + 0.99 value_stay[t] + 0.009 reward + -0.004 harvest_duration + -0.011 value_stay^2 + -0.008 value_stay*reward + -0.013 value_stay*harvest_duration + 0.011 reward^2 + 0.012 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.018 1 + 1.043 value_exit[t] + -0.001 travel_duration + -0.021 value_exit^2 + -0.019 value_exit*travel_duration + 0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 6/1000 --- L(Train): 0.3547129 --- L(Val, RNN): 0.3601073 --- L(Val, SINDy): 2.4822361 --- Time: 1.04s; --- Convergence: 2.69e-02; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.0 1 + 0.989 value_stay[t] + 0.013 reward + -0.001 harvest_duration + -0.014 value_stay^2 + -0.008 value_stay*reward + -0.014 value_stay*harvest_duration + 0.016 reward^2 + 0.017 reward*harvest_duration + -0.003 harvest_duration^2 \n",
      "value_exit[t+1] = -0.022 1 + 1.046 value_exit[t] + -0.001 travel_duration + -0.025 value_exit^2 + -0.019 value_exit*travel_duration + -0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 7/1000 --- L(Train): 0.3625765 --- L(Val, RNN): 0.3593431 --- L(Val, SINDy): 2.3013320 --- Time: 0.92s; --- Convergence: 1.38e-02; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.003 1 + 0.987 value_stay[t] + 0.018 reward + 0.001 harvest_duration + -0.019 value_stay^2 + -0.009 value_stay*reward + -0.016 value_stay*harvest_duration + 0.022 reward^2 + 0.021 reward*harvest_duration + -0.001 harvest_duration^2 \n",
      "value_exit[t+1] = -0.022 1 + 1.046 value_exit[t] + -0.003 travel_duration + -0.024 value_exit^2 + -0.019 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 8/1000 --- L(Train): 0.3621267 --- L(Val, RNN): 0.3586418 --- L(Val, SINDy): 1.9201562 --- Time: 0.93s; --- Convergence: 7.26e-03; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.002 1 + 0.981 value_stay[t] + 0.019 reward + -0.0 harvest_duration + -0.024 value_stay^2 + -0.014 value_stay*reward + -0.022 value_stay*harvest_duration + 0.026 reward^2 + 0.023 reward*harvest_duration + -0.002 harvest_duration^2 \n",
      "value_exit[t+1] = -0.019 1 + 1.042 value_exit[t] + -0.003 travel_duration + -0.02 value_exit^2 + -0.02 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 9/1000 --- L(Train): 0.3643481 --- L(Val, RNN): 0.3580105 --- L(Val, SINDy): 1.7091841 --- Time: 1.04s; --- Convergence: 3.95e-03; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = -0.0 1 + 0.976 value_stay[t] + 0.021 reward + -0.002 harvest_duration + -0.031 value_stay^2 + -0.019 value_stay*reward + -0.028 value_stay*harvest_duration + 0.029 reward^2 + 0.025 reward*harvest_duration + -0.004 harvest_duration^2 \n",
      "value_exit[t+1] = -0.014 1 + 1.038 value_exit[t] + -0.003 travel_duration + -0.016 value_exit^2 + -0.022 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 10/1000 --- L(Train): 0.3589939 --- L(Val, RNN): 0.3574351 --- L(Val, SINDy): 1.7028474 --- Time: 1.20s; --- Convergence: 2.26e-03; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = -0.001 1 + 0.971 value_stay[t] + 0.023 reward + -0.003 harvest_duration + -0.036 value_stay^2 + -0.024 value_stay*reward + -0.033 value_stay*harvest_duration + 0.033 reward^2 + 0.027 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.01 1 + 1.033 value_exit[t] + -0.003 travel_duration + -0.011 value_exit^2 + -0.022 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 11/1000 --- L(Train): 0.3504592 --- L(Val, RNN): 0.3569107 --- L(Val, SINDy): 1.6265451 --- Time: 1.02s; --- Convergence: 1.39e-03; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.002 1 + 0.967 value_stay[t] + 0.028 reward + -0.0 harvest_duration + -0.042 value_stay^2 + -0.026 value_stay*reward + -0.037 value_stay*harvest_duration + 0.039 reward^2 + 0.032 reward*harvest_duration + -0.002 harvest_duration^2 \n",
      "value_exit[t+1] = -0.004 1 + 1.028 value_exit[t] + -0.006 travel_duration + -0.006 value_exit^2 + -0.022 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 12/1000 --- L(Train): 0.3554625 --- L(Val, RNN): 0.3564256 --- L(Val, SINDy): 1.4239779 --- Time: 0.95s; --- Convergence: 9.39e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.004 1 + 0.962 value_stay[t] + 0.033 reward + 0.001 harvest_duration + -0.05 value_stay^2 + -0.031 value_stay*reward + -0.042 value_stay*harvest_duration + 0.045 reward^2 + 0.036 reward*harvest_duration + -0.001 harvest_duration^2 \n",
      "value_exit[t+1] = 0.001 1 + 1.023 value_exit[t] + -0.005 travel_duration + -0.001 value_exit^2 + -0.025 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 13/1000 --- L(Train): 0.3545506 --- L(Val, RNN): 0.3559832 --- L(Val, SINDy): 1.2815711 --- Time: 0.86s; --- Convergence: 6.91e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.004 1 + 0.956 value_stay[t] + 0.035 reward + 0.001 harvest_duration + -0.057 value_stay^2 + -0.037 value_stay*reward + -0.049 value_stay*harvest_duration + 0.049 reward^2 + 0.039 reward*harvest_duration + -0.001 harvest_duration^2 \n",
      "value_exit[t+1] = 0.006 1 + 1.018 value_exit[t] + -0.004 travel_duration + 0.003 value_exit^2 + -0.027 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 14/1000 --- L(Train): 0.3567459 --- L(Val, RNN): 0.3555698 --- L(Val, SINDy): 1.2378467 --- Time: 0.87s; --- Convergence: 5.52e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.004 1 + 0.949 value_stay[t] + 0.037 reward + -0.001 harvest_duration + -0.065 value_stay^2 + -0.043 value_stay*reward + -0.056 value_stay*harvest_duration + 0.052 reward^2 + 0.041 reward*harvest_duration + -0.003 harvest_duration^2 \n",
      "value_exit[t+1] = 0.011 1 + 1.014 value_exit[t] + -0.005 travel_duration + 0.007 value_exit^2 + -0.028 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 15/1000 --- L(Train): 0.3576899 --- L(Val, RNN): 0.3551616 --- L(Val, SINDy): 1.1921587 --- Time: 0.91s; --- Convergence: 4.80e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.003 1 + 0.942 value_stay[t] + 0.038 reward + -0.002 harvest_duration + -0.074 value_stay^2 + -0.05 value_stay*reward + -0.064 value_stay*harvest_duration + 0.055 reward^2 + 0.042 reward*harvest_duration + -0.004 harvest_duration^2 \n",
      "value_exit[t+1] = 0.014 1 + 1.01 value_exit[t] + -0.007 travel_duration + 0.01 value_exit^2 + -0.027 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 16/1000 --- L(Train): 0.3524729 --- L(Val, RNN): 0.3547637 --- L(Val, SINDy): 1.1914911 --- Time: 1.22s; --- Convergence: 4.39e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.004 1 + 0.935 value_stay[t] + 0.04 reward + -0.003 harvest_duration + -0.082 value_stay^2 + -0.058 value_stay*reward + -0.072 value_stay*harvest_duration + 0.059 reward^2 + 0.044 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = 0.017 1 + 1.007 value_exit[t] + -0.008 travel_duration + 0.014 value_exit^2 + -0.029 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 17/1000 --- L(Train): 0.3564253 --- L(Val, RNN): 0.3543943 --- L(Val, SINDy): 1.0955262 --- Time: 1.08s; --- Convergence: 4.04e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.006 1 + 0.927 value_stay[t] + 0.043 reward + -0.003 harvest_duration + -0.091 value_stay^2 + -0.066 value_stay*reward + -0.08 value_stay*harvest_duration + 0.063 reward^2 + 0.047 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = 0.02 1 + 1.004 value_exit[t] + -0.006 travel_duration + 0.016 value_exit^2 + -0.032 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 18/1000 --- L(Train): 0.3524169 --- L(Val, RNN): 0.3540142 --- L(Val, SINDy): 1.0033200 --- Time: 0.85s; --- Convergence: 3.92e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.008 1 + 0.918 value_stay[t] + 0.045 reward + -0.003 harvest_duration + -0.101 value_stay^2 + -0.075 value_stay*reward + -0.089 value_stay*harvest_duration + 0.067 reward^2 + 0.049 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = 0.02 1 + 1.001 value_exit[t] + -0.009 travel_duration + 0.019 value_exit^2 + -0.031 value_exit*travel_duration + -0.007 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 19/1000 --- L(Train): 0.3635609 --- L(Val, RNN): 0.3536410 --- L(Val, SINDy): 0.8910270 --- Time: 0.87s; --- Convergence: 3.83e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.009 1 + 0.91 value_stay[t] + 0.046 reward + -0.004 harvest_duration + -0.111 value_stay^2 + -0.084 value_stay*reward + -0.098 value_stay*harvest_duration + 0.07 reward^2 + 0.05 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = 0.021 1 + 0.999 value_exit[t] + -0.009 travel_duration + 0.021 value_exit^2 + -0.033 value_exit*travel_duration + -0.008 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 20/1000 --- L(Train): 0.3525239 --- L(Val, RNN): 0.3532653 --- L(Val, SINDy): 0.7905875 --- Time: 1.28s; --- Convergence: 3.79e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.011 1 + 0.901 value_stay[t] + 0.047 reward + -0.004 harvest_duration + -0.12 value_stay^2 + -0.093 value_stay*reward + -0.107 value_stay*harvest_duration + 0.072 reward^2 + 0.051 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = 0.021 1 + 0.997 value_exit[t] + -0.009 travel_duration + 0.023 value_exit^2 + -0.035 value_exit*travel_duration + -0.008 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 21/1000 --- L(Train): 0.3500310 --- L(Val, RNN): 0.3528956 --- L(Val, SINDy): 0.6875381 --- Time: 0.89s; --- Convergence: 3.74e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.014 1 + 0.893 value_stay[t] + 0.048 reward + -0.003 harvest_duration + -0.129 value_stay^2 + -0.103 value_stay*reward + -0.116 value_stay*harvest_duration + 0.075 reward^2 + 0.052 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = 0.021 1 + 0.996 value_exit[t] + -0.008 travel_duration + 0.025 value_exit^2 + -0.038 value_exit*travel_duration + -0.007 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 22/1000 --- L(Train): 0.3568775 --- L(Val, RNN): 0.3525400 --- L(Val, SINDy): 0.7034635 --- Time: 0.93s; --- Convergence: 3.65e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.017 1 + 0.884 value_stay[t] + 0.048 reward + -0.003 harvest_duration + -0.139 value_stay^2 + -0.113 value_stay*reward + -0.125 value_stay*harvest_duration + 0.077 reward^2 + 0.052 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = 0.02 1 + 0.994 value_exit[t] + -0.009 travel_duration + 0.027 value_exit^2 + -0.038 value_exit*travel_duration + -0.008 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 23/1000 --- L(Train): 0.3557719 --- L(Val, RNN): 0.3522120 --- L(Val, SINDy): 0.6536233 --- Time: 0.87s; --- Convergence: 3.47e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.021 1 + 0.875 value_stay[t] + 0.05 reward + -0.001 harvest_duration + -0.149 value_stay^2 + -0.122 value_stay*reward + -0.135 value_stay*harvest_duration + 0.08 reward^2 + 0.054 reward*harvest_duration + -0.003 harvest_duration^2 \n",
      "value_exit[t+1] = 0.017 1 + 0.994 value_exit[t] + -0.011 travel_duration + 0.028 value_exit^2 + -0.039 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 24/1000 --- L(Train): 0.3575087 --- L(Val, RNN): 0.3519222 --- L(Val, SINDy): 0.6478154 --- Time: 1.14s; --- Convergence: 3.18e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.023 1 + 0.865 value_stay[t] + 0.05 reward + -0.001 harvest_duration + -0.159 value_stay^2 + -0.133 value_stay*reward + -0.145 value_stay*harvest_duration + 0.082 reward^2 + 0.054 reward*harvest_duration + -0.003 harvest_duration^2 \n",
      "value_exit[t+1] = 0.015 1 + 0.993 value_exit[t] + -0.009 travel_duration + 0.029 value_exit^2 + -0.042 value_exit*travel_duration + -0.008 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 25/1000 --- L(Train): 0.3548397 --- L(Val, RNN): 0.3516714 --- L(Val, SINDy): 0.5933520 --- Time: 1.02s; --- Convergence: 2.84e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.026 1 + 0.855 value_stay[t] + 0.05 reward + -0.0 harvest_duration + -0.169 value_stay^2 + -0.143 value_stay*reward + -0.155 value_stay*harvest_duration + 0.084 reward^2 + 0.054 reward*harvest_duration + -0.002 harvest_duration^2 \n",
      "value_exit[t+1] = 0.012 1 + 0.992 value_exit[t] + -0.009 travel_duration + 0.03 value_exit^2 + -0.044 value_exit*travel_duration + -0.008 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 26/1000 --- L(Train): 0.3529368 --- L(Val, RNN): 0.3514187 --- L(Val, SINDy): 0.6199722 --- Time: 1.07s; --- Convergence: 2.69e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.031 1 + 0.845 value_stay[t] + 0.053 reward + 0.003 harvest_duration + -0.18 value_stay^2 + -0.154 value_stay*reward + -0.165 value_stay*harvest_duration + 0.088 reward^2 + 0.057 reward*harvest_duration + 0.001 harvest_duration^2 \n",
      "value_exit[t+1] = 0.007 1 + 0.993 value_exit[t] + -0.013 travel_duration + 0.031 value_exit^2 + -0.042 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 27/1000 --- L(Train): 0.3510900 --- L(Val, RNN): 0.3511938 --- L(Val, SINDy): 0.6046557 --- Time: 0.97s; --- Convergence: 2.47e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.031 1 + 0.834 value_stay[t] + 0.053 reward + 0.003 harvest_duration + -0.191 value_stay^2 + -0.166 value_stay*reward + -0.176 value_stay*harvest_duration + 0.091 reward^2 + 0.057 reward*harvest_duration + 0.001 harvest_duration^2 \n",
      "value_exit[t+1] = 0.004 1 + 0.993 value_exit[t] + -0.01 travel_duration + 0.032 value_exit^2 + -0.046 value_exit*travel_duration + -0.009 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 28/1000 --- L(Train): 0.3570781 --- L(Val, RNN): 0.3509254 --- L(Val, SINDy): 0.5531638 --- Time: 1.16s; --- Convergence: 2.58e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.032 1 + 0.824 value_stay[t] + 0.055 reward + 0.003 harvest_duration + -0.202 value_stay^2 + -0.176 value_stay*reward + -0.186 value_stay*harvest_duration + 0.095 reward^2 + 0.059 reward*harvest_duration + 0.001 harvest_duration^2 \n",
      "value_exit[t+1] = 0.001 1 + 0.993 value_exit[t] + -0.009 travel_duration + 0.033 value_exit^2 + -0.049 value_exit*travel_duration + -0.007 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 29/1000 --- L(Train): 0.3575248 --- L(Val, RNN): 0.3506469 --- L(Val, SINDy): 0.5077839 --- Time: 0.94s; --- Convergence: 2.68e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.036 1 + 0.815 value_stay[t] + 0.06 reward + 0.007 harvest_duration + -0.212 value_stay^2 + -0.186 value_stay*reward + -0.196 value_stay*harvest_duration + 0.102 reward^2 + 0.064 reward*harvest_duration + 0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.003 1 + 0.993 value_exit[t] + -0.009 travel_duration + 0.033 value_exit^2 + -0.05 value_exit*travel_duration + -0.008 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 30/1000 --- L(Train): 0.3566967 --- L(Val, RNN): 0.3503599 --- L(Val, SINDy): 0.4736639 --- Time: 1.04s; --- Convergence: 2.78e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.805 value_stay[t] + 0.067 reward + 0.011 harvest_duration + -0.223 value_stay^2 + -0.196 value_stay*reward + -0.205 value_stay*harvest_duration + 0.11 reward^2 + 0.07 reward*harvest_duration + 0.009 harvest_duration^2 \n",
      "value_exit[t+1] = -0.01 1 + 0.995 value_exit[t] + -0.012 travel_duration + 0.034 value_exit^2 + -0.048 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 31/1000 --- L(Train): 0.3506030 --- L(Val, RNN): 0.3500711 --- L(Val, SINDy): 0.4739839 --- Time: 0.95s; --- Convergence: 2.83e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.795 value_stay[t] + 0.071 reward + 0.013 harvest_duration + -0.235 value_stay^2 + -0.207 value_stay*reward + -0.216 value_stay*harvest_duration + 0.116 reward^2 + 0.075 reward*harvest_duration + 0.011 harvest_duration^2 \n",
      "value_exit[t+1] = -0.015 1 + 0.996 value_exit[t] + -0.014 travel_duration + 0.034 value_exit^2 + -0.047 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 32/1000 --- L(Train): 0.3505533 --- L(Val, RNN): 0.3497564 --- L(Val, SINDy): 0.4693975 --- Time: 1.28s; --- Convergence: 2.99e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.784 value_stay[t] + 0.075 reward + 0.013 harvest_duration + -0.247 value_stay^2 + -0.217 value_stay*reward + -0.227 value_stay*harvest_duration + 0.122 reward^2 + 0.079 reward*harvest_duration + 0.011 harvest_duration^2 \n",
      "value_exit[t+1] = -0.019 1 + 0.997 value_exit[t] + -0.014 travel_duration + 0.034 value_exit^2 + -0.048 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 33/1000 --- L(Train): 0.3538852 --- L(Val, RNN): 0.3494076 --- L(Val, SINDy): 0.4455453 --- Time: 0.85s; --- Convergence: 3.24e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.773 value_stay[t] + 0.078 reward + 0.011 harvest_duration + -0.258 value_stay^2 + -0.229 value_stay*reward + -0.238 value_stay*harvest_duration + 0.128 reward^2 + 0.082 reward*harvest_duration + 0.009 harvest_duration^2 \n",
      "value_exit[t+1] = -0.02 1 + 0.997 value_exit[t] + -0.011 travel_duration + 0.035 value_exit^2 + -0.053 value_exit*travel_duration + -0.009 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 34/1000 --- L(Train): 0.3527975 --- L(Val, RNN): 0.3490729 --- L(Val, SINDy): 0.4368377 --- Time: 0.91s; --- Convergence: 3.29e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.762 value_stay[t] + 0.083 reward + 0.01 harvest_duration + -0.27 value_stay^2 + -0.239 value_stay*reward + -0.249 value_stay*harvest_duration + 0.135 reward^2 + 0.087 reward*harvest_duration + 0.008 harvest_duration^2 \n",
      "value_exit[t+1] = -0.021 1 + 0.997 value_exit[t] + -0.008 travel_duration + 0.035 value_exit^2 + -0.056 value_exit*travel_duration + -0.007 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 35/1000 --- L(Train): 0.3520170 --- L(Val, RNN): 0.3487906 --- L(Val, SINDy): 0.4361921 --- Time: 1.14s; --- Convergence: 3.06e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.752 value_stay[t] + 0.091 reward + 0.013 harvest_duration + -0.282 value_stay^2 + -0.249 value_stay*reward + -0.259 value_stay*harvest_duration + 0.145 reward^2 + 0.095 reward*harvest_duration + 0.011 harvest_duration^2 \n",
      "value_exit[t+1] = -0.027 1 + 0.999 value_exit[t] + -0.01 travel_duration + 0.035 value_exit^2 + -0.054 value_exit*travel_duration + -0.009 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 36/1000 --- L(Train): 0.3490347 --- L(Val, RNN): 0.3484930 --- L(Val, SINDy): 0.4278950 --- Time: 1.15s; --- Convergence: 3.02e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.741 value_stay[t] + 0.095 reward + 0.012 harvest_duration + -0.294 value_stay^2 + -0.26 value_stay*reward + -0.271 value_stay*harvest_duration + 0.151 reward^2 + 0.099 reward*harvest_duration + 0.01 harvest_duration^2 \n",
      "value_exit[t+1] = -0.033 1 + 1.001 value_exit[t] + -0.014 travel_duration + 0.035 value_exit^2 + -0.052 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 37/1000 --- L(Train): 0.3562283 --- L(Val, RNN): 0.3481841 --- L(Val, SINDy): 0.4156739 --- Time: 0.89s; --- Convergence: 3.05e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.729 value_stay[t] + 0.096 reward + 0.007 harvest_duration + -0.307 value_stay^2 + -0.271 value_stay*reward + -0.283 value_stay*harvest_duration + 0.155 reward^2 + 0.1 reward*harvest_duration + 0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.036 1 + 1.003 value_exit[t] + -0.014 travel_duration + 0.035 value_exit^2 + -0.052 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 38/1000 --- L(Train): 0.3536738 --- L(Val, RNN): 0.3478884 --- L(Val, SINDy): 0.4162408 --- Time: 1.08s; --- Convergence: 3.01e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.718 value_stay[t] + 0.098 reward + 0.003 harvest_duration + -0.319 value_stay^2 + -0.282 value_stay*reward + -0.294 value_stay*harvest_duration + 0.159 reward^2 + 0.102 reward*harvest_duration + 0.001 harvest_duration^2 \n",
      "value_exit[t+1] = -0.039 1 + 1.004 value_exit[t] + -0.014 travel_duration + 0.035 value_exit^2 + -0.053 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 39/1000 --- L(Train): 0.3504746 --- L(Val, RNN): 0.3475860 --- L(Val, SINDy): 0.4062343 --- Time: 1.12s; --- Convergence: 3.01e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.707 value_stay[t] + 0.101 reward + 0.002 harvest_duration + -0.331 value_stay^2 + -0.293 value_stay*reward + -0.305 value_stay*harvest_duration + 0.164 reward^2 + 0.105 reward*harvest_duration + -0.0 harvest_duration^2 \n",
      "value_exit[t+1] = -0.04 1 + 1.004 value_exit[t] + -0.012 travel_duration + 0.035 value_exit^2 + -0.056 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 40/1000 --- L(Train): 0.3540649 --- L(Val, RNN): 0.3472151 --- L(Val, SINDy): 0.4050747 --- Time: 0.86s; --- Convergence: 3.36e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.697 value_stay[t] + 0.106 reward + 0.002 harvest_duration + -0.343 value_stay^2 + -0.303 value_stay*reward + -0.315 value_stay*harvest_duration + 0.171 reward^2 + 0.11 reward*harvest_duration + 0.0 harvest_duration^2 \n",
      "value_exit[t+1] = -0.04 1 + 1.004 value_exit[t] + -0.009 travel_duration + 0.036 value_exit^2 + -0.059 value_exit*travel_duration + -0.008 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 41/1000 --- L(Train): 0.3426217 --- L(Val, RNN): 0.3468423 --- L(Val, SINDy): 0.3944792 --- Time: 0.89s; --- Convergence: 3.54e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.686 value_stay[t] + 0.109 reward + 0.002 harvest_duration + -0.355 value_stay^2 + -0.314 value_stay*reward + -0.326 value_stay*harvest_duration + 0.176 reward^2 + 0.113 reward*harvest_duration + 0.0 harvest_duration^2 \n",
      "value_exit[t+1] = -0.043 1 + 1.005 value_exit[t] + -0.009 travel_duration + 0.036 value_exit^2 + -0.06 value_exit*travel_duration + -0.008 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 42/1000 --- L(Train): 0.3422602 --- L(Val, RNN): 0.3465401 --- L(Val, SINDy): 0.3996658 --- Time: 0.86s; --- Convergence: 3.28e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.675 value_stay[t] + 0.11 reward + -0.0 harvest_duration + -0.367 value_stay^2 + -0.326 value_stay*reward + -0.337 value_stay*harvest_duration + 0.179 reward^2 + 0.114 reward*harvest_duration + -0.002 harvest_duration^2 \n",
      "value_exit[t+1] = -0.047 1 + 1.007 value_exit[t] + -0.011 travel_duration + 0.035 value_exit^2 + -0.059 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 43/1000 --- L(Train): 0.3462494 --- L(Val, RNN): 0.3460844 --- L(Val, SINDy): 0.3920983 --- Time: 0.92s; --- Convergence: 3.92e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.664 value_stay[t] + 0.11 reward + -0.002 harvest_duration + -0.379 value_stay^2 + -0.338 value_stay*reward + -0.349 value_stay*harvest_duration + 0.182 reward^2 + 0.114 reward*harvest_duration + -0.004 harvest_duration^2 \n",
      "value_exit[t+1] = -0.052 1 + 1.009 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.058 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 44/1000 --- L(Train): 0.3527253 --- L(Val, RNN): 0.3457117 --- L(Val, SINDy): 0.3909274 --- Time: 1.11s; --- Convergence: 3.82e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.653 value_stay[t] + 0.112 reward + -0.003 harvest_duration + -0.391 value_stay^2 + -0.349 value_stay*reward + -0.359 value_stay*harvest_duration + 0.185 reward^2 + 0.116 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.055 1 + 1.01 value_exit[t] + -0.014 travel_duration + 0.035 value_exit^2 + -0.057 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 45/1000 --- L(Train): 0.3512395 --- L(Val, RNN): 0.3453275 --- L(Val, SINDy): 0.3882940 --- Time: 1.22s; --- Convergence: 3.83e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.644 value_stay[t] + 0.113 reward + -0.004 harvest_duration + -0.401 value_stay^2 + -0.359 value_stay*reward + -0.369 value_stay*harvest_duration + 0.188 reward^2 + 0.117 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.058 1 + 1.012 value_exit[t] + -0.015 travel_duration + 0.035 value_exit^2 + -0.057 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 46/1000 --- L(Train): 0.3444504 --- L(Val, RNN): 0.3449175 --- L(Val, SINDy): 0.3779397 --- Time: 1.33s; --- Convergence: 3.97e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.635 value_stay[t] + 0.114 reward + -0.004 harvest_duration + -0.411 value_stay^2 + -0.368 value_stay*reward + -0.378 value_stay*harvest_duration + 0.191 reward^2 + 0.119 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.06 1 + 1.012 value_exit[t] + -0.015 travel_duration + 0.035 value_exit^2 + -0.058 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 47/1000 --- L(Train): 0.3441795 --- L(Val, RNN): 0.3444341 --- L(Val, SINDy): 0.3814792 --- Time: 1.07s; --- Convergence: 4.40e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.626 value_stay[t] + 0.115 reward + -0.005 harvest_duration + -0.42 value_stay^2 + -0.377 value_stay*reward + -0.386 value_stay*harvest_duration + 0.193 reward^2 + 0.119 reward*harvest_duration + -0.007 harvest_duration^2 \n",
      "value_exit[t+1] = -0.06 1 + 1.012 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.06 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 48/1000 --- L(Train): 0.3467800 --- L(Val, RNN): 0.3439369 --- L(Val, SINDy): 0.3791466 --- Time: 0.95s; --- Convergence: 4.69e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.617 value_stay[t] + 0.114 reward + -0.006 harvest_duration + -0.429 value_stay^2 + -0.387 value_stay*reward + -0.395 value_stay*harvest_duration + 0.194 reward^2 + 0.118 reward*harvest_duration + -0.008 harvest_duration^2 \n",
      "value_exit[t+1] = -0.06 1 + 1.012 value_exit[t] + -0.011 travel_duration + 0.035 value_exit^2 + -0.063 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 49/1000 --- L(Train): 0.3483420 --- L(Val, RNN): 0.3434385 --- L(Val, SINDy): 0.3782424 --- Time: 1.11s; --- Convergence: 4.84e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.608 value_stay[t] + 0.115 reward + -0.004 harvest_duration + -0.438 value_stay^2 + -0.396 value_stay*reward + -0.404 value_stay*harvest_duration + 0.196 reward^2 + 0.119 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.061 1 + 1.012 value_exit[t] + -0.01 travel_duration + 0.035 value_exit^2 + -0.064 value_exit*travel_duration + -0.009 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 50/1000 --- L(Train): 0.3501617 --- L(Val, RNN): 0.3428674 --- L(Val, SINDy): 0.3696032 --- Time: 1.05s; --- Convergence: 5.27e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.6 value_stay[t] + 0.117 reward + -0.002 harvest_duration + -0.447 value_stay^2 + -0.405 value_stay*reward + -0.412 value_stay*harvest_duration + 0.199 reward^2 + 0.121 reward*harvest_duration + -0.004 harvest_duration^2 \n",
      "value_exit[t+1] = -0.063 1 + 1.013 value_exit[t] + -0.011 travel_duration + 0.035 value_exit^2 + -0.065 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 51/1000 --- L(Train): 0.3495021 --- L(Val, RNN): 0.3423029 --- L(Val, SINDy): 0.3668642 --- Time: 1.15s; --- Convergence: 5.46e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.05 1 + 0.592 value_stay[t] + 0.119 reward + 0.002 harvest_duration + -0.454 value_stay^2 + -0.412 value_stay*reward + -0.418 value_stay*harvest_duration + 0.204 reward^2 + 0.123 reward*harvest_duration + -0.0 harvest_duration^2 \n",
      "value_exit[t+1] = -0.066 1 + 1.014 value_exit[t] + -0.012 travel_duration + 0.035 value_exit^2 + -0.064 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 52/1000 --- L(Train): 0.3510835 --- L(Val, RNN): 0.3417113 --- L(Val, SINDy): 0.3673845 --- Time: 0.87s; --- Convergence: 5.69e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.053 1 + 0.585 value_stay[t] + 0.122 reward + 0.005 harvest_duration + -0.46 value_stay^2 + -0.418 value_stay*reward + -0.424 value_stay*harvest_duration + 0.208 reward^2 + 0.126 reward*harvest_duration + 0.003 harvest_duration^2 \n",
      "value_exit[t+1] = -0.068 1 + 1.015 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.064 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 53/1000 --- L(Train): 0.3417630 --- L(Val, RNN): 0.3410207 --- L(Val, SINDy): 0.3655974 --- Time: 1.10s; --- Convergence: 6.30e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.056 1 + 0.579 value_stay[t] + 0.127 reward + 0.008 harvest_duration + -0.464 value_stay^2 + -0.422 value_stay*reward + -0.429 value_stay*harvest_duration + 0.215 reward^2 + 0.131 reward*harvest_duration + 0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.069 1 + 1.015 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.065 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 54/1000 --- L(Train): 0.3466619 --- L(Val, RNN): 0.3402878 --- L(Val, SINDy): 0.3620326 --- Time: 1.15s; --- Convergence: 6.81e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.06 1 + 0.575 value_stay[t] + 0.133 reward + 0.012 harvest_duration + -0.465 value_stay^2 + -0.422 value_stay*reward + -0.432 value_stay*harvest_duration + 0.224 reward^2 + 0.137 reward*harvest_duration + 0.01 harvest_duration^2 \n",
      "value_exit[t+1] = -0.07 1 + 1.015 value_exit[t] + -0.012 travel_duration + 0.035 value_exit^2 + -0.066 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 55/1000 --- L(Train): 0.3463366 --- L(Val, RNN): 0.3394898 --- L(Val, SINDy): 0.3630628 --- Time: 1.21s; --- Convergence: 7.40e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.062 1 + 0.573 value_stay[t] + 0.141 reward + 0.015 harvest_duration + -0.462 value_stay^2 + -0.419 value_stay*reward + -0.433 value_stay*harvest_duration + 0.233 reward^2 + 0.145 reward*harvest_duration + 0.013 harvest_duration^2 \n",
      "value_exit[t+1] = -0.07 1 + 1.015 value_exit[t] + -0.011 travel_duration + 0.035 value_exit^2 + -0.067 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 56/1000 --- L(Train): 0.3468562 --- L(Val, RNN): 0.3387275 --- L(Val, SINDy): 0.3614927 --- Time: 1.08s; --- Convergence: 7.51e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.061 1 + 0.572 value_stay[t] + 0.147 reward + 0.014 harvest_duration + -0.457 value_stay^2 + -0.414 value_stay*reward + -0.433 value_stay*harvest_duration + 0.243 reward^2 + 0.151 reward*harvest_duration + 0.012 harvest_duration^2 \n",
      "value_exit[t+1] = -0.071 1 + 1.016 value_exit[t] + -0.012 travel_duration + 0.035 value_exit^2 + -0.068 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 57/1000 --- L(Train): 0.3445237 --- L(Val, RNN): 0.3378399 --- L(Val, SINDy): 0.3604084 --- Time: 0.96s; --- Convergence: 8.19e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.057 1 + 0.57 value_stay[t] + 0.153 reward + 0.01 harvest_duration + -0.45 value_stay^2 + -0.407 value_stay*reward + -0.432 value_stay*harvest_duration + 0.254 reward^2 + 0.157 reward*harvest_duration + 0.008 harvest_duration^2 \n",
      "value_exit[t+1] = -0.073 1 + 1.016 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.068 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 58/1000 --- L(Train): 0.3453823 --- L(Val, RNN): 0.3368942 --- L(Val, SINDy): 0.3605940 --- Time: 0.89s; --- Convergence: 8.83e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.055 1 + 0.573 value_stay[t] + 0.162 reward + 0.009 harvest_duration + -0.44 value_stay^2 + -0.397 value_stay*reward + -0.426 value_stay*harvest_duration + 0.266 reward^2 + 0.166 reward*harvest_duration + 0.007 harvest_duration^2 \n",
      "value_exit[t+1] = -0.074 1 + 1.016 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.068 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 59/1000 --- L(Train): 0.3413489 --- L(Val, RNN): 0.3359607 --- L(Val, SINDy): 0.3616739 --- Time: 1.13s; --- Convergence: 9.08e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.06 1 + 0.581 value_stay[t] + 0.173 reward + 0.013 harvest_duration + -0.428 value_stay^2 + -0.386 value_stay*reward + -0.417 value_stay*harvest_duration + 0.279 reward^2 + 0.177 reward*harvest_duration + 0.011 harvest_duration^2 \n",
      "value_exit[t+1] = -0.075 1 + 1.016 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.069 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 60/1000 --- L(Train): 0.3419703 --- L(Val, RNN): 0.3349842 --- L(Val, SINDy): 0.3587418 --- Time: 0.88s; --- Convergence: 9.42e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.065 1 + 0.59 value_stay[t] + 0.185 reward + 0.018 harvest_duration + -0.416 value_stay^2 + -0.373 value_stay*reward + -0.406 value_stay*harvest_duration + 0.293 reward^2 + 0.189 reward*harvest_duration + 0.016 harvest_duration^2 \n",
      "value_exit[t+1] = -0.075 1 + 1.016 value_exit[t] + -0.012 travel_duration + 0.035 value_exit^2 + -0.07 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 61/1000 --- L(Train): 0.3459201 --- L(Val, RNN): 0.3339262 --- L(Val, SINDy): 0.3547858 --- Time: 1.02s; --- Convergence: 1.00e-03; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.061 1 + 0.595 value_stay[t] + 0.192 reward + 0.014 harvest_duration + -0.402 value_stay^2 + -0.359 value_stay*reward + -0.398 value_stay*harvest_duration + 0.306 reward^2 + 0.196 reward*harvest_duration + 0.012 harvest_duration^2 \n",
      "value_exit[t+1] = -0.076 1 + 1.016 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.071 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 62/1000 --- L(Train): 0.3440435 --- L(Val, RNN): 0.3328950 --- L(Val, SINDy): 0.3550497 --- Time: 0.93s; --- Convergence: 1.02e-03; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.056 1 + 0.604 value_stay[t] + 0.201 reward + 0.008 harvest_duration + -0.387 value_stay^2 + -0.345 value_stay*reward + -0.387 value_stay*harvest_duration + 0.32 reward^2 + 0.205 reward*harvest_duration + 0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 1.016 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.072 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 63/1000 --- L(Train): 0.3428254 --- L(Val, RNN): 0.3320184 --- L(Val, SINDy): 0.3563865 --- Time: 0.88s; --- Convergence: 9.46e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.055 1 + 0.614 value_stay[t] + 0.212 reward + 0.006 harvest_duration + -0.372 value_stay^2 + -0.33 value_stay*reward + -0.375 value_stay*harvest_duration + 0.334 reward^2 + 0.216 reward*harvest_duration + 0.004 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 1.015 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.073 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 64/1000 --- L(Train): 0.3454114 --- L(Val, RNN): 0.3311209 --- L(Val, SINDy): 0.3521585 --- Time: 0.85s; --- Convergence: 9.22e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.056 1 + 0.626 value_stay[t] + 0.225 reward + 0.006 harvest_duration + -0.357 value_stay^2 + -0.314 value_stay*reward + -0.361 value_stay*harvest_duration + 0.35 reward^2 + 0.229 reward*harvest_duration + 0.004 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 1.015 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.074 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 65/1000 --- L(Train): 0.3415206 --- L(Val, RNN): 0.3302599 --- L(Val, SINDy): 0.3514231 --- Time: 0.92s; --- Convergence: 8.91e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.06 1 + 0.64 value_stay[t] + 0.239 reward + 0.009 harvest_duration + -0.341 value_stay^2 + -0.298 value_stay*reward + -0.347 value_stay*harvest_duration + 0.366 reward^2 + 0.243 reward*harvest_duration + 0.007 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 1.015 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.075 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 66/1000 --- L(Train): 0.3388797 --- L(Val, RNN): 0.3296049 --- L(Val, SINDy): 0.3527990 --- Time: 1.03s; --- Convergence: 7.73e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.062 1 + 0.652 value_stay[t] + 0.251 reward + 0.009 harvest_duration + -0.325 value_stay^2 + -0.283 value_stay*reward + -0.333 value_stay*harvest_duration + 0.381 reward^2 + 0.255 reward*harvest_duration + 0.007 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 1.014 value_exit[t] + -0.014 travel_duration + 0.035 value_exit^2 + -0.076 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 67/1000 --- L(Train): 0.3406454 --- L(Val, RNN): 0.3288473 --- L(Val, SINDy): 0.3509893 --- Time: 0.95s; --- Convergence: 7.65e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.061 1 + 0.661 value_stay[t] + 0.262 reward + 0.007 harvest_duration + -0.311 value_stay^2 + -0.268 value_stay*reward + -0.323 value_stay*harvest_duration + 0.394 reward^2 + 0.266 reward*harvest_duration + 0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 1.014 value_exit[t] + -0.014 travel_duration + 0.035 value_exit^2 + -0.076 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 68/1000 --- L(Train): 0.3396269 --- L(Val, RNN): 0.3283428 --- L(Val, SINDy): 0.3483960 --- Time: 1.05s; --- Convergence: 6.35e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.057 1 + 0.666 value_stay[t] + 0.269 reward + 0.002 harvest_duration + -0.3 value_stay^2 + -0.256 value_stay*reward + -0.316 value_stay*harvest_duration + 0.405 reward^2 + 0.274 reward*harvest_duration + -0.0 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 1.013 value_exit[t] + -0.014 travel_duration + 0.036 value_exit^2 + -0.077 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 69/1000 --- L(Train): 0.3375436 --- L(Val, RNN): 0.3281747 --- L(Val, SINDy): 0.3474358 --- Time: 1.22s; --- Convergence: 4.02e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.661 value_stay[t] + 0.265 reward + -0.008 harvest_duration + -0.298 value_stay^2 + -0.254 value_stay*reward + -0.32 value_stay*harvest_duration + 0.405 reward^2 + 0.269 reward*harvest_duration + -0.01 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 1.013 value_exit[t] + -0.014 travel_duration + 0.036 value_exit^2 + -0.079 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 70/1000 --- L(Train): 0.3446465 --- L(Val, RNN): 0.3269562 --- L(Val, SINDy): 0.3474319 --- Time: 1.00s; --- Convergence: 8.10e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.656 value_stay[t] + 0.261 reward + -0.017 harvest_duration + -0.296 value_stay^2 + -0.253 value_stay*reward + -0.324 value_stay*harvest_duration + 0.404 reward^2 + 0.266 reward*harvest_duration + -0.019 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 1.012 value_exit[t] + -0.014 travel_duration + 0.036 value_exit^2 + -0.08 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 71/1000 --- L(Train): 0.3426362 --- L(Val, RNN): 0.3267430 --- L(Val, SINDy): 0.3497319 --- Time: 1.06s; --- Convergence: 5.12e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.032 1 + 0.652 value_stay[t] + 0.259 reward + -0.024 harvest_duration + -0.291 value_stay^2 + -0.249 value_stay*reward + -0.327 value_stay*harvest_duration + 0.405 reward^2 + 0.264 reward*harvest_duration + -0.026 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 1.012 value_exit[t] + -0.015 travel_duration + 0.036 value_exit^2 + -0.08 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 72/1000 --- L(Train): 0.3441774 --- L(Val, RNN): 0.3263136 --- L(Val, SINDy): 0.3490880 --- Time: 2.56s; --- Convergence: 4.71e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.027 1 + 0.65 value_stay[t] + 0.26 reward + -0.03 harvest_duration + -0.285 value_stay^2 + -0.244 value_stay*reward + -0.327 value_stay*harvest_duration + 0.409 reward^2 + 0.264 reward*harvest_duration + -0.032 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 1.011 value_exit[t] + -0.015 travel_duration + 0.036 value_exit^2 + -0.081 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 73/1000 --- L(Train): 0.3390588 --- L(Val, RNN): 0.3254374 --- L(Val, SINDy): 0.3470588 --- Time: 3.92s; --- Convergence: 6.73e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.025 1 + 0.652 value_stay[t] + 0.262 reward + -0.033 harvest_duration + -0.276 value_stay^2 + -0.236 value_stay*reward + -0.324 value_stay*harvest_duration + 0.416 reward^2 + 0.267 reward*harvest_duration + -0.035 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 1.011 value_exit[t] + -0.014 travel_duration + 0.036 value_exit^2 + -0.083 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 74/1000 --- L(Train): 0.3372434 --- L(Val, RNN): 0.3248359 --- L(Val, SINDy): 0.3453377 --- Time: 6.66s; --- Convergence: 6.37e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.025 1 + 0.654 value_stay[t] + 0.266 reward + -0.034 harvest_duration + -0.267 value_stay^2 + -0.228 value_stay*reward + -0.32 value_stay*harvest_duration + 0.423 reward^2 + 0.271 reward*harvest_duration + -0.036 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 1.01 value_exit[t] + -0.014 travel_duration + 0.036 value_exit^2 + -0.084 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 75/1000 --- L(Train): 0.3409837 --- L(Val, RNN): 0.3240981 --- L(Val, SINDy): 0.3449801 --- Time: 4.08s; --- Convergence: 6.88e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.026 1 + 0.657 value_stay[t] + 0.271 reward + -0.034 harvest_duration + -0.257 value_stay^2 + -0.219 value_stay*reward + -0.316 value_stay*harvest_duration + 0.431 reward^2 + 0.276 reward*harvest_duration + -0.036 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 1.01 value_exit[t] + -0.015 travel_duration + 0.036 value_exit^2 + -0.084 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 76/1000 --- L(Train): 0.3402959 --- L(Val, RNN): 0.3237267 --- L(Val, SINDy): 0.3450522 --- Time: 3.54s; --- Convergence: 5.29e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.028 1 + 0.661 value_stay[t] + 0.277 reward + -0.032 harvest_duration + -0.247 value_stay^2 + -0.21 value_stay*reward + -0.31 value_stay*harvest_duration + 0.44 reward^2 + 0.282 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 1.01 value_exit[t] + -0.016 travel_duration + 0.036 value_exit^2 + -0.085 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 77/1000 --- L(Train): 0.3391602 --- L(Val, RNN): 0.3231411 --- L(Val, SINDy): 0.3455248 --- Time: 1.91s; --- Convergence: 5.58e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.033 1 + 0.668 value_stay[t] + 0.286 reward + -0.028 harvest_duration + -0.234 value_stay^2 + -0.198 value_stay*reward + -0.301 value_stay*harvest_duration + 0.451 reward^2 + 0.291 reward*harvest_duration + -0.03 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 1.008 value_exit[t] + -0.013 travel_duration + 0.037 value_exit^2 + -0.088 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 78/1000 --- L(Train): 0.3365828 --- L(Val, RNN): 0.3229696 --- L(Val, SINDy): 0.3479059 --- Time: 2.94s; --- Convergence: 3.64e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.676 value_stay[t] + 0.296 reward + -0.022 harvest_duration + -0.22 value_stay^2 + -0.185 value_stay*reward + -0.292 value_stay*harvest_duration + 0.464 reward^2 + 0.3 reward*harvest_duration + -0.024 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 1.009 value_exit[t] + -0.015 travel_duration + 0.036 value_exit^2 + -0.087 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 79/1000 --- L(Train): 0.3364283 --- L(Val, RNN): 0.3219639 --- L(Val, SINDy): 0.3514905 --- Time: 2.97s; --- Convergence: 6.85e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.683 value_stay[t] + 0.305 reward + -0.018 harvest_duration + -0.207 value_stay^2 + -0.173 value_stay*reward + -0.283 value_stay*harvest_duration + 0.476 reward^2 + 0.309 reward*harvest_duration + -0.02 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 1.01 value_exit[t] + -0.017 travel_duration + 0.036 value_exit^2 + -0.086 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 80/1000 --- L(Train): 0.3407446 --- L(Val, RNN): 0.3220393 --- L(Val, SINDy): 0.3496934 --- Time: 1.61s; --- Convergence: 3.80e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.687 value_stay[t] + 0.312 reward + -0.016 harvest_duration + -0.197 value_stay^2 + -0.164 value_stay*reward + -0.278 value_stay*harvest_duration + 0.485 reward^2 + 0.316 reward*harvest_duration + -0.018 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 1.009 value_exit[t] + -0.016 travel_duration + 0.037 value_exit^2 + -0.088 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 81/1000 --- L(Train): 0.3352766 --- L(Val, RNN): 0.3208854 --- L(Val, SINDy): 0.3485561 --- Time: 2.00s; --- Convergence: 7.67e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.686 value_stay[t] + 0.314 reward + -0.018 harvest_duration + -0.19 value_stay^2 + -0.158 value_stay*reward + -0.277 value_stay*harvest_duration + 0.491 reward^2 + 0.319 reward*harvest_duration + -0.02 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 1.007 value_exit[t] + -0.014 travel_duration + 0.037 value_exit^2 + -0.091 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 82/1000 --- L(Train): 0.3329794 --- L(Val, RNN): 0.3205969 --- L(Val, SINDy): 0.3481927 --- Time: 3.66s; --- Convergence: 5.28e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.679 value_stay[t] + 0.312 reward + -0.024 harvest_duration + -0.189 value_stay^2 + -0.158 value_stay*reward + -0.281 value_stay*harvest_duration + 0.492 reward^2 + 0.316 reward*harvest_duration + -0.026 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.01 value_exit[t] + -0.018 travel_duration + 0.036 value_exit^2 + -0.088 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 83/1000 --- L(Train): 0.3393174 --- L(Val, RNN): 0.3201086 --- L(Val, SINDy): 0.3479555 --- Time: 2.93s; --- Convergence: 5.08e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.034 1 + 0.671 value_stay[t] + 0.308 reward + -0.032 harvest_duration + -0.189 value_stay^2 + -0.159 value_stay*reward + -0.287 value_stay*harvest_duration + 0.492 reward^2 + 0.312 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 1.007 value_exit[t] + -0.016 travel_duration + 0.037 value_exit^2 + -0.091 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 84/1000 --- L(Train): 0.3390567 --- L(Val, RNN): 0.3196678 --- L(Val, SINDy): 0.3459640 --- Time: 4.26s; --- Convergence: 4.74e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.029 1 + 0.663 value_stay[t] + 0.306 reward + -0.039 harvest_duration + -0.187 value_stay^2 + -0.159 value_stay*reward + -0.292 value_stay*harvest_duration + 0.494 reward^2 + 0.31 reward*harvest_duration + -0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 1.006 value_exit[t] + -0.015 travel_duration + 0.037 value_exit^2 + -0.093 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 85/1000 --- L(Train): 0.3421928 --- L(Val, RNN): 0.3199960 --- L(Val, SINDy): 0.3454741 --- Time: 2.63s; --- Convergence: 4.01e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.024 1 + 0.656 value_stay[t] + 0.304 reward + -0.044 harvest_duration + -0.184 value_stay^2 + -0.157 value_stay*reward + -0.296 value_stay*harvest_duration + 0.498 reward^2 + 0.309 reward*harvest_duration + -0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.007 value_exit[t] + -0.016 travel_duration + 0.037 value_exit^2 + -0.092 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 86/1000 --- L(Train): 0.3487736 --- L(Val, RNN): 0.3195281 --- L(Val, SINDy): 0.3464850 --- Time: 2.48s; --- Convergence: 4.35e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.02 1 + 0.649 value_stay[t] + 0.303 reward + -0.049 harvest_duration + -0.181 value_stay^2 + -0.156 value_stay*reward + -0.301 value_stay*harvest_duration + 0.501 reward^2 + 0.308 reward*harvest_duration + -0.051 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.008 value_exit[t] + -0.017 travel_duration + 0.037 value_exit^2 + -0.091 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 87/1000 --- L(Train): 0.3400750 --- L(Val, RNN): 0.3196983 --- L(Val, SINDy): 0.3495249 --- Time: 2.54s; --- Convergence: 3.02e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.017 1 + 0.642 value_stay[t] + 0.303 reward + -0.053 harvest_duration + -0.179 value_stay^2 + -0.155 value_stay*reward + -0.305 value_stay*harvest_duration + 0.505 reward^2 + 0.307 reward*harvest_duration + -0.055 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.007 value_exit[t] + -0.016 travel_duration + 0.037 value_exit^2 + -0.093 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 88/1000 --- L(Train): 0.3444048 --- L(Val, RNN): 0.3201163 --- L(Val, SINDy): 0.3482822 --- Time: 2.18s; --- Convergence: 3.60e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.018 1 + 0.637 value_stay[t] + 0.305 reward + -0.053 harvest_duration + -0.173 value_stay^2 + -0.152 value_stay*reward + -0.307 value_stay*harvest_duration + 0.512 reward^2 + 0.31 reward*harvest_duration + -0.055 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.007 value_exit[t] + -0.015 travel_duration + 0.037 value_exit^2 + -0.095 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 89/1000 --- L(Train): 0.3427295 --- L(Val, RNN): 0.3194780 --- L(Val, SINDy): 0.3461807 --- Time: 2.28s; --- Convergence: 4.99e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.021 1 + 0.635 value_stay[t] + 0.31 reward + -0.052 harvest_duration + -0.165 value_stay^2 + -0.146 value_stay*reward + -0.307 value_stay*harvest_duration + 0.52 reward^2 + 0.314 reward*harvest_duration + -0.054 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.008 value_exit[t] + -0.016 travel_duration + 0.037 value_exit^2 + -0.095 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 90/1000 --- L(Train): 0.3470559 --- L(Val, RNN): 0.3198629 --- L(Val, SINDy): 0.3443653 --- Time: 2.61s; --- Convergence: 4.42e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.024 1 + 0.631 value_stay[t] + 0.314 reward + -0.05 harvest_duration + -0.159 value_stay^2 + -0.142 value_stay*reward + -0.307 value_stay*harvest_duration + 0.528 reward^2 + 0.318 reward*harvest_duration + -0.052 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.01 value_exit[t] + -0.018 travel_duration + 0.036 value_exit^2 + -0.094 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 91/1000 --- L(Train): 0.3406839 --- L(Val, RNN): 0.3208330 --- L(Val, SINDy): 0.3436926 --- Time: 2.41s; --- Convergence: 7.06e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.026 1 + 0.627 value_stay[t] + 0.315 reward + -0.049 harvest_duration + -0.154 value_stay^2 + -0.14 value_stay*reward + -0.309 value_stay*harvest_duration + 0.534 reward^2 + 0.32 reward*harvest_duration + -0.051 harvest_duration^2 \n",
      "value_exit[t+1] = -0.092 1 + 1.011 value_exit[t] + -0.017 travel_duration + 0.036 value_exit^2 + -0.094 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 92/1000 --- L(Train): 0.3457157 --- L(Val, RNN): 0.3194764 --- L(Val, SINDy): 0.3432645 --- Time: 3.19s; --- Convergence: 1.03e-03; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.027 1 + 0.622 value_stay[t] + 0.317 reward + -0.049 harvest_duration + -0.15 value_stay^2 + -0.138 value_stay*reward + -0.311 value_stay*harvest_duration + 0.539 reward^2 + 0.321 reward*harvest_duration + -0.051 harvest_duration^2 \n",
      "value_exit[t+1] = -0.092 1 + 1.011 value_exit[t] + -0.016 travel_duration + 0.036 value_exit^2 + -0.096 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 93/1000 --- L(Train): 0.3494869 --- L(Val, RNN): 0.3189677 --- L(Val, SINDy): 0.3427914 --- Time: 1.85s; --- Convergence: 7.70e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.029 1 + 0.619 value_stay[t] + 0.319 reward + -0.048 harvest_duration + -0.146 value_stay^2 + -0.136 value_stay*reward + -0.313 value_stay*harvest_duration + 0.545 reward^2 + 0.323 reward*harvest_duration + -0.05 harvest_duration^2 \n",
      "value_exit[t+1] = -0.093 1 + 1.012 value_exit[t] + -0.016 travel_duration + 0.035 value_exit^2 + -0.096 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 94/1000 --- L(Train): 0.3455680 --- L(Val, RNN): 0.3187747 --- L(Val, SINDy): 0.3438128 --- Time: 2.07s; --- Convergence: 4.82e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.031 1 + 0.614 value_stay[t] + 0.32 reward + -0.047 harvest_duration + -0.142 value_stay^2 + -0.134 value_stay*reward + -0.315 value_stay*harvest_duration + 0.55 reward^2 + 0.324 reward*harvest_duration + -0.049 harvest_duration^2 \n",
      "value_exit[t+1] = -0.096 1 + 1.014 value_exit[t] + -0.017 travel_duration + 0.035 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 95/1000 --- L(Train): 0.3483471 --- L(Val, RNN): 0.3199693 --- L(Val, SINDy): 0.3424125 --- Time: 1.24s; --- Convergence: 8.38e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.032 1 + 0.609 value_stay[t] + 0.32 reward + -0.047 harvest_duration + -0.138 value_stay^2 + -0.133 value_stay*reward + -0.318 value_stay*harvest_duration + 0.554 reward^2 + 0.324 reward*harvest_duration + -0.049 harvest_duration^2 \n",
      "value_exit[t+1] = -0.097 1 + 1.015 value_exit[t] + -0.017 travel_duration + 0.034 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 96/1000 --- L(Train): 0.3507940 --- L(Val, RNN): 0.3188273 --- L(Val, SINDy): 0.3409331 --- Time: 1.05s; --- Convergence: 9.90e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.034 1 + 0.605 value_stay[t] + 0.321 reward + -0.046 harvest_duration + -0.133 value_stay^2 + -0.131 value_stay*reward + -0.32 value_stay*harvest_duration + 0.558 reward^2 + 0.325 reward*harvest_duration + -0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.098 1 + 1.016 value_exit[t] + -0.016 travel_duration + 0.034 value_exit^2 + -0.097 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 97/1000 --- L(Train): 0.3424662 --- L(Val, RNN): 0.3183057 --- L(Val, SINDy): 0.3427114 --- Time: 0.85s; --- Convergence: 7.56e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.604 value_stay[t] + 0.324 reward + -0.043 harvest_duration + -0.125 value_stay^2 + -0.125 value_stay*reward + -0.318 value_stay*harvest_duration + 0.565 reward^2 + 0.328 reward*harvest_duration + -0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.1 1 + 1.017 value_exit[t] + -0.016 travel_duration + 0.034 value_exit^2 + -0.097 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 98/1000 --- L(Train): 0.3504297 --- L(Val, RNN): 0.3183243 --- L(Val, SINDy): 0.3423878 --- Time: 1.03s; --- Convergence: 3.87e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.604 value_stay[t] + 0.327 reward + -0.04 harvest_duration + -0.116 value_stay^2 + -0.119 value_stay*reward + -0.315 value_stay*harvest_duration + 0.572 reward^2 + 0.331 reward*harvest_duration + -0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.101 1 + 1.018 value_exit[t] + -0.017 travel_duration + 0.033 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 99/1000 --- L(Train): 0.3496413 --- L(Val, RNN): 0.3183845 --- L(Val, SINDy): 0.3417611 --- Time: 1.16s; --- Convergence: 2.24e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.606 value_stay[t] + 0.331 reward + -0.036 harvest_duration + -0.106 value_stay^2 + -0.112 value_stay*reward + -0.312 value_stay*harvest_duration + 0.58 reward^2 + 0.335 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.102 1 + 1.019 value_exit[t] + -0.017 travel_duration + 0.033 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 100/1000 --- L(Train): 0.3490184 --- L(Val, RNN): 0.3190697 --- L(Val, SINDy): 0.3418972 --- Time: 1.02s; --- Convergence: 4.54e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.051 1 + 0.607 value_stay[t] + 0.334 reward + -0.033 harvest_duration + -0.095 value_stay^2 + -0.104 value_stay*reward + -0.308 value_stay*harvest_duration + 0.587 reward^2 + 0.338 reward*harvest_duration + -0.035 harvest_duration^2 \n",
      "value_exit[t+1] = -0.102 1 + 1.019 value_exit[t] + -0.016 travel_duration + 0.033 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 101/1000 --- L(Train): 0.3504912 --- L(Val, RNN): 0.3184176 --- L(Val, SINDy): 0.3434471 --- Time: 0.92s; --- Convergence: 5.53e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.054 1 + 0.608 value_stay[t] + 0.336 reward + -0.032 harvest_duration + -0.086 value_stay^2 + -0.097 value_stay*reward + -0.305 value_stay*harvest_duration + 0.593 reward^2 + 0.34 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.102 1 + 1.019 value_exit[t] + -0.016 travel_duration + 0.033 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 102/1000 --- L(Train): 0.3507538 --- L(Val, RNN): 0.3177734 --- L(Val, SINDy): 0.3441548 --- Time: 1.22s; --- Convergence: 5.99e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.054 1 + 0.606 value_stay[t] + 0.335 reward + -0.032 harvest_duration + -0.079 value_stay^2 + -0.093 value_stay*reward + -0.305 value_stay*harvest_duration + 0.597 reward^2 + 0.339 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.102 1 + 1.019 value_exit[t] + -0.016 travel_duration + 0.033 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 103/1000 --- L(Train): 0.3520292 --- L(Val, RNN): 0.3182232 --- L(Val, SINDy): 0.3420197 --- Time: 1.17s; --- Convergence: 5.24e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.051 1 + 0.601 value_stay[t] + 0.331 reward + -0.036 harvest_duration + -0.075 value_stay^2 + -0.092 value_stay*reward + -0.308 value_stay*harvest_duration + 0.597 reward^2 + 0.336 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.102 1 + 1.019 value_exit[t] + -0.017 travel_duration + 0.033 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 104/1000 --- L(Train): 0.3564698 --- L(Val, RNN): 0.3190125 --- L(Val, SINDy): 0.3394367 --- Time: 0.93s; --- Convergence: 6.57e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.597 value_stay[t] + 0.328 reward + -0.04 harvest_duration + -0.069 value_stay^2 + -0.089 value_stay*reward + -0.31 value_stay*harvest_duration + 0.598 reward^2 + 0.332 reward*harvest_duration + -0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.1 1 + 1.017 value_exit[t] + -0.015 travel_duration + 0.034 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 105/1000 --- L(Train): 0.3507742 --- L(Val, RNN): 0.3181209 --- L(Val, SINDy): 0.3386493 --- Time: 1.04s; --- Convergence: 7.74e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.596 value_stay[t] + 0.327 reward + -0.041 harvest_duration + -0.06 value_stay^2 + -0.083 value_stay*reward + -0.309 value_stay*harvest_duration + 0.602 reward^2 + 0.331 reward*harvest_duration + -0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.099 1 + 1.016 value_exit[t] + -0.016 travel_duration + 0.034 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 106/1000 --- L(Train): 0.3468998 --- L(Val, RNN): 0.3183652 --- L(Val, SINDy): 0.3416104 --- Time: 1.15s; --- Convergence: 5.09e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.052 1 + 0.599 value_stay[t] + 0.329 reward + -0.039 harvest_duration + -0.048 value_stay^2 + -0.074 value_stay*reward + -0.303 value_stay*harvest_duration + 0.609 reward^2 + 0.334 reward*harvest_duration + -0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.1 1 + 1.017 value_exit[t] + -0.018 travel_duration + 0.034 value_exit^2 + -0.096 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 107/1000 --- L(Train): 0.3521019 --- L(Val, RNN): 0.3184474 --- L(Val, SINDy): 0.3424486 --- Time: 1.81s; --- Convergence: 2.96e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.056 1 + 0.603 value_stay[t] + 0.333 reward + -0.037 harvest_duration + -0.036 value_stay^2 + -0.063 value_stay*reward + -0.297 value_stay*harvest_duration + 0.617 reward^2 + 0.337 reward*harvest_duration + -0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.093 1 + 1.01 value_exit[t] + -0.013 travel_duration + 0.036 value_exit^2 + -0.101 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 108/1000 --- L(Train): 0.3484773 --- L(Val, RNN): 0.3188996 --- L(Val, SINDy): 0.3421502 --- Time: 1.72s; --- Convergence: 3.74e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.058 1 + 0.604 value_stay[t] + 0.335 reward + -0.036 harvest_duration + -0.026 value_stay^2 + -0.053 value_stay*reward + -0.293 value_stay*harvest_duration + 0.623 reward^2 + 0.339 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.093 1 + 1.01 value_exit[t] + -0.014 travel_duration + 0.036 value_exit^2 + -0.1 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 109/1000 --- L(Train): 0.3570294 --- L(Val, RNN): 0.3181408 --- L(Val, SINDy): 0.3392879 --- Time: 1.30s; --- Convergence: 5.66e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.057 1 + 0.6 value_stay[t] + 0.334 reward + -0.039 harvest_duration + -0.02 value_stay^2 + -0.047 value_stay*reward + -0.294 value_stay*harvest_duration + 0.626 reward^2 + 0.338 reward*harvest_duration + -0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.098 1 + 1.015 value_exit[t] + -0.021 travel_duration + 0.034 value_exit^2 + -0.093 value_exit*travel_duration + -0.02 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 110/1000 --- L(Train): 0.3545318 --- L(Val, RNN): 0.3178687 --- L(Val, SINDy): 0.3407318 --- Time: 1.09s; --- Convergence: 4.19e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.053 1 + 0.592 value_stay[t] + 0.329 reward + -0.045 harvest_duration + -0.019 value_stay^2 + -0.046 value_stay*reward + -0.299 value_stay*harvest_duration + 0.627 reward^2 + 0.333 reward*harvest_duration + -0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.094 1 + 1.011 value_exit[t] + -0.018 travel_duration + 0.037 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 111/1000 --- L(Train): 0.3512340 --- L(Val, RNN): 0.3181413 --- L(Val, SINDy): 0.3422728 --- Time: 0.79s; --- Convergence: 3.46e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.05 1 + 0.584 value_stay[t] + 0.324 reward + -0.05 harvest_duration + -0.018 value_stay^2 + -0.044 value_stay*reward + -0.304 value_stay*harvest_duration + 0.627 reward^2 + 0.329 reward*harvest_duration + -0.052 harvest_duration^2 \n",
      "value_exit[t+1] = -0.09 1 + 1.006 value_exit[t] + -0.014 travel_duration + 0.039 value_exit^2 + -0.1 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 112/1000 --- L(Train): 0.3534231 --- L(Val, RNN): 0.3186450 --- L(Val, SINDy): 0.3405035 --- Time: 1.00s; --- Convergence: 4.25e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.051 1 + 0.581 value_stay[t] + 0.324 reward + -0.05 harvest_duration + -0.013 value_stay^2 + -0.039 value_stay*reward + -0.305 value_stay*harvest_duration + 0.631 reward^2 + 0.328 reward*harvest_duration + -0.052 harvest_duration^2 \n",
      "value_exit[t+1] = -0.092 1 + 1.008 value_exit[t] + -0.016 travel_duration + 0.038 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 113/1000 --- L(Train): 0.3610145 --- L(Val, RNN): 0.3182284 --- L(Val, SINDy): 0.3394031 --- Time: 1.05s; --- Convergence: 4.21e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.057 1 + 0.582 value_stay[t] + 0.329 reward + -0.046 harvest_duration + -0.003 value_stay^2 + -0.03 value_stay*reward + -0.301 value_stay*harvest_duration + 0.639 reward^2 + 0.333 reward*harvest_duration + -0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.094 1 + 1.01 value_exit[t] + -0.019 travel_duration + 0.037 value_exit^2 + -0.095 value_exit*travel_duration + -0.018 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 114/1000 --- L(Train): 0.3556114 --- L(Val, RNN): 0.3178515 --- L(Val, SINDy): 0.3387427 --- Time: 0.91s; --- Convergence: 3.99e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.063 1 + 0.581 value_stay[t] + 0.332 reward + -0.042 harvest_duration + 0.005 value_stay^2 + -0.022 value_stay*reward + -0.299 value_stay*harvest_duration + 0.647 reward^2 + 0.336 reward*harvest_duration + -0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.007 value_exit[t] + -0.017 travel_duration + 0.039 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 115/1000 --- L(Train): 0.3580656 --- L(Val, RNN): 0.3178938 --- L(Val, SINDy): 0.3391317 --- Time: 1.11s; --- Convergence: 2.21e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.066 1 + 0.577 value_stay[t] + 0.332 reward + -0.041 harvest_duration + 0.01 value_stay^2 + -0.017 value_stay*reward + -0.299 value_stay*harvest_duration + 0.652 reward^2 + 0.337 reward*harvest_duration + -0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.005 value_exit[t] + -0.014 travel_duration + 0.041 value_exit^2 + -0.1 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 116/1000 --- L(Train): 0.3500769 --- L(Val, RNN): 0.3184628 --- L(Val, SINDy): 0.3385895 --- Time: 1.26s; --- Convergence: 3.95e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.066 1 + 0.571 value_stay[t] + 0.329 reward + -0.043 harvest_duration + 0.011 value_stay^2 + -0.016 value_stay*reward + -0.303 value_stay*harvest_duration + 0.653 reward^2 + 0.333 reward*harvest_duration + -0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.005 value_exit[t] + -0.015 travel_duration + 0.041 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 117/1000 --- L(Train): 0.3564915 --- L(Val, RNN): 0.3185722 --- L(Val, SINDy): 0.3379352 --- Time: 1.14s; --- Convergence: 2.52e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.065 1 + 0.563 value_stay[t] + 0.325 reward + -0.046 harvest_duration + 0.012 value_stay^2 + -0.016 value_stay*reward + -0.309 value_stay*harvest_duration + 0.653 reward^2 + 0.329 reward*harvest_duration + -0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.007 value_exit[t] + -0.018 travel_duration + 0.039 value_exit^2 + -0.096 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 118/1000 --- L(Train): 0.3624997 --- L(Val, RNN): 0.3182514 --- L(Val, SINDy): 0.3376493 --- Time: 0.84s; --- Convergence: 2.86e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.065 1 + 0.557 value_stay[t] + 0.321 reward + -0.048 harvest_duration + 0.013 value_stay^2 + -0.015 value_stay*reward + -0.313 value_stay*harvest_duration + 0.654 reward^2 + 0.325 reward*harvest_duration + -0.05 harvest_duration^2 \n",
      "value_exit[t+1] = -0.092 1 + 1.008 value_exit[t] + -0.018 travel_duration + 0.039 value_exit^2 + -0.096 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 119/1000 --- L(Train): 0.3559091 --- L(Val, RNN): 0.3180479 --- L(Val, SINDy): 0.3374208 --- Time: 0.93s; --- Convergence: 2.45e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.067 1 + 0.551 value_stay[t] + 0.319 reward + -0.048 harvest_duration + 0.016 value_stay^2 + -0.013 value_stay*reward + -0.316 value_stay*harvest_duration + 0.656 reward^2 + 0.323 reward*harvest_duration + -0.05 harvest_duration^2 \n",
      "value_exit[t+1] = -0.09 1 + 1.006 value_exit[t] + -0.017 travel_duration + 0.04 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 120/1000 --- L(Train): 0.3552007 --- L(Val, RNN): 0.3182454 --- L(Val, SINDy): 0.3377611 --- Time: 1.29s; --- Convergence: 2.21e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.07 1 + 0.548 value_stay[t] + 0.319 reward + -0.047 harvest_duration + 0.02 value_stay^2 + -0.009 value_stay*reward + -0.318 value_stay*harvest_duration + 0.66 reward^2 + 0.323 reward*harvest_duration + -0.049 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.005 value_exit[t] + -0.015 travel_duration + 0.041 value_exit^2 + -0.098 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 121/1000 --- L(Train): 0.3587048 --- L(Val, RNN): 0.3185634 --- L(Val, SINDy): 0.3392268 --- Time: 1.24s; --- Convergence: 2.70e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.073 1 + 0.546 value_stay[t] + 0.319 reward + -0.045 harvest_duration + 0.026 value_stay^2 + -0.004 value_stay*reward + -0.318 value_stay*harvest_duration + 0.664 reward^2 + 0.323 reward*harvest_duration + -0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.004 value_exit[t] + -0.015 travel_duration + 0.042 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 122/1000 --- L(Train): 0.3668035 --- L(Val, RNN): 0.3187285 --- L(Val, SINDy): 0.3379600 --- Time: 0.93s; --- Convergence: 2.17e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.077 1 + 0.544 value_stay[t] + 0.32 reward + -0.043 harvest_duration + 0.031 value_stay^2 + 0.0 value_stay*reward + -0.318 value_stay*harvest_duration + 0.668 reward^2 + 0.324 reward*harvest_duration + -0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.004 value_exit[t] + -0.015 travel_duration + 0.042 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 123/1000 --- L(Train): 0.3620897 --- L(Val, RNN): 0.3187662 --- L(Val, SINDy): 0.3382119 --- Time: 1.11s; --- Convergence: 1.28e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.08 1 + 0.542 value_stay[t] + 0.319 reward + -0.042 harvest_duration + 0.035 value_stay^2 + 0.004 value_stay*reward + -0.319 value_stay*harvest_duration + 0.671 reward^2 + 0.323 reward*harvest_duration + -0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.006 value_exit[t] + -0.016 travel_duration + 0.041 value_exit^2 + -0.097 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 124/1000 --- L(Train): 0.3604553 --- L(Val, RNN): 0.3189983 --- L(Val, SINDy): 0.3383479 --- Time: 1.32s; --- Convergence: 1.80e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.08 1 + 0.537 value_stay[t] + 0.316 reward + -0.043 harvest_duration + 0.036 value_stay^2 + 0.004 value_stay*reward + -0.322 value_stay*harvest_duration + 0.672 reward^2 + 0.32 reward*harvest_duration + -0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.007 value_exit[t] + -0.018 travel_duration + 0.04 value_exit^2 + -0.096 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 125/1000 --- L(Train): 0.3586362 --- L(Val, RNN): 0.3192618 --- L(Val, SINDy): 0.3371812 --- Time: 0.86s; --- Convergence: 2.22e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.08 1 + 0.531 value_stay[t] + 0.312 reward + -0.045 harvest_duration + 0.037 value_stay^2 + 0.005 value_stay*reward + -0.326 value_stay*harvest_duration + 0.672 reward^2 + 0.317 reward*harvest_duration + -0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.007 value_exit[t] + -0.018 travel_duration + 0.04 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 126/1000 --- L(Train): 0.3613584 --- L(Val, RNN): 0.3192604 --- L(Val, SINDy): 0.3376358 --- Time: 1.09s; --- Convergence: 1.12e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.081 1 + 0.526 value_stay[t] + 0.31 reward + -0.046 harvest_duration + 0.039 value_stay^2 + 0.006 value_stay*reward + -0.329 value_stay*harvest_duration + 0.673 reward^2 + 0.314 reward*harvest_duration + -0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.005 value_exit[t] + -0.016 travel_duration + 0.041 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 127/1000 --- L(Train): 0.3645270 --- L(Val, RNN): 0.3196726 --- L(Val, SINDy): 0.3398442 --- Time: 1.13s; --- Convergence: 2.62e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.082 1 + 0.523 value_stay[t] + 0.308 reward + -0.046 harvest_duration + 0.041 value_stay^2 + 0.008 value_stay*reward + -0.332 value_stay*harvest_duration + 0.675 reward^2 + 0.312 reward*harvest_duration + -0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.004 value_exit[t] + -0.014 travel_duration + 0.042 value_exit^2 + -0.099 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 128/1000 --- L(Train): 0.3657410 --- L(Val, RNN): 0.3202441 --- L(Val, SINDy): 0.3401618 --- Time: 0.90s; --- Convergence: 4.17e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.083 1 + 0.519 value_stay[t] + 0.306 reward + -0.045 harvest_duration + 0.044 value_stay^2 + 0.011 value_stay*reward + -0.333 value_stay*harvest_duration + 0.677 reward^2 + 0.311 reward*harvest_duration + -0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.004 value_exit[t] + -0.015 travel_duration + 0.042 value_exit^2 + -0.099 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 129/1000 --- L(Train): 0.3619585 --- L(Val, RNN): 0.3202040 --- L(Val, SINDy): 0.3411242 --- Time: 0.93s; --- Convergence: 2.28e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.086 1 + 0.517 value_stay[t] + 0.306 reward + -0.044 harvest_duration + 0.048 value_stay^2 + 0.015 value_stay*reward + -0.333 value_stay*harvest_duration + 0.68 reward^2 + 0.31 reward*harvest_duration + -0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.007 value_exit[t] + -0.017 travel_duration + 0.04 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 130/1000 --- L(Train): 0.3605959 --- L(Val, RNN): 0.3202021 --- L(Val, SINDy): 0.3404817 --- Time: 0.86s; --- Convergence: 1.15e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.089 1 + 0.515 value_stay[t] + 0.306 reward + -0.042 harvest_duration + 0.051 value_stay^2 + 0.019 value_stay*reward + -0.334 value_stay*harvest_duration + 0.683 reward^2 + 0.31 reward*harvest_duration + -0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.092 1 + 1.008 value_exit[t] + -0.019 travel_duration + 0.039 value_exit^2 + -0.095 value_exit*travel_duration + -0.018 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 131/1000 --- L(Train): 0.3557698 --- L(Val, RNN): 0.3204004 --- L(Val, SINDy): 0.3389804 --- Time: 0.81s; --- Convergence: 1.57e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.091 1 + 0.512 value_stay[t] + 0.304 reward + -0.041 harvest_duration + 0.055 value_stay^2 + 0.022 value_stay*reward + -0.335 value_stay*harvest_duration + 0.686 reward^2 + 0.309 reward*harvest_duration + -0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.007 value_exit[t] + -0.018 travel_duration + 0.039 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 132/1000 --- L(Train): 0.3705032 --- L(Val, RNN): 0.3205675 --- L(Val, SINDy): 0.3382632 --- Time: 0.99s; --- Convergence: 1.62e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.093 1 + 0.51 value_stay[t] + 0.303 reward + -0.04 harvest_duration + 0.058 value_stay^2 + 0.025 value_stay*reward + -0.335 value_stay*harvest_duration + 0.688 reward^2 + 0.308 reward*harvest_duration + -0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.006 value_exit[t] + -0.016 travel_duration + 0.041 value_exit^2 + -0.097 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 133/1000 --- L(Train): 0.3702162 --- L(Val, RNN): 0.3208049 --- L(Val, SINDy): 0.3364748 --- Time: 1.03s; --- Convergence: 2.00e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.095 1 + 0.508 value_stay[t] + 0.302 reward + -0.04 harvest_duration + 0.061 value_stay^2 + 0.028 value_stay*reward + -0.336 value_stay*harvest_duration + 0.69 reward^2 + 0.306 reward*harvest_duration + -0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.005 value_exit[t] + -0.015 travel_duration + 0.041 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 134/1000 --- L(Train): 0.3584071 --- L(Val, RNN): 0.3207325 --- L(Val, SINDy): 0.3359192 --- Time: 0.91s; --- Convergence: 1.36e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.097 1 + 0.506 value_stay[t] + 0.3 reward + -0.039 harvest_duration + 0.064 value_stay^2 + 0.03 value_stay*reward + -0.337 value_stay*harvest_duration + 0.691 reward^2 + 0.304 reward*harvest_duration + -0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.005 value_exit[t] + -0.015 travel_duration + 0.041 value_exit^2 + -0.098 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 135/1000 --- L(Train): 0.3589655 --- L(Val, RNN): 0.3210141 --- L(Val, SINDy): 0.3367481 --- Time: 1.05s; --- Convergence: 2.09e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.098 1 + 0.503 value_stay[t] + 0.297 reward + -0.04 harvest_duration + 0.067 value_stay^2 + 0.033 value_stay*reward + -0.338 value_stay*harvest_duration + 0.692 reward^2 + 0.302 reward*harvest_duration + -0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.006 value_exit[t] + -0.016 travel_duration + 0.041 value_exit^2 + -0.097 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 136/1000 --- L(Train): 0.3773002 --- L(Val, RNN): 0.3214541 --- L(Val, SINDy): 0.3381172 --- Time: 1.06s; --- Convergence: 3.24e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.1 1 + 0.501 value_stay[t] + 0.295 reward + -0.039 harvest_duration + 0.07 value_stay^2 + 0.035 value_stay*reward + -0.339 value_stay*harvest_duration + 0.693 reward^2 + 0.299 reward*harvest_duration + -0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.09 1 + 1.007 value_exit[t] + -0.017 travel_duration + 0.04 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 137/1000 --- L(Train): 0.3679981 --- L(Val, RNN): 0.3217641 --- L(Val, SINDy): 0.3395804 --- Time: 0.92s; --- Convergence: 3.17e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.101 1 + 0.499 value_stay[t] + 0.294 reward + -0.039 harvest_duration + 0.072 value_stay^2 + 0.038 value_stay*reward + -0.34 value_stay*harvest_duration + 0.695 reward^2 + 0.298 reward*harvest_duration + -0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.007 value_exit[t] + -0.018 travel_duration + 0.04 value_exit^2 + -0.096 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 138/1000 --- L(Train): 0.3678401 --- L(Val, RNN): 0.3216742 --- L(Val, SINDy): 0.3400463 --- Time: 1.26s; --- Convergence: 2.04e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.103 1 + 0.498 value_stay[t] + 0.292 reward + -0.038 harvest_duration + 0.075 value_stay^2 + 0.04 value_stay*reward + -0.34 value_stay*harvest_duration + 0.697 reward^2 + 0.297 reward*harvest_duration + -0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.007 value_exit[t] + -0.018 travel_duration + 0.04 value_exit^2 + -0.096 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 139/1000 --- L(Train): 0.3676948 --- L(Val, RNN): 0.3214630 --- L(Val, SINDy): 0.3422829 --- Time: 0.93s; --- Convergence: 2.07e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.107 1 + 0.499 value_stay[t] + 0.293 reward + -0.036 harvest_duration + 0.08 value_stay^2 + 0.045 value_stay*reward + -0.339 value_stay*harvest_duration + 0.699 reward^2 + 0.297 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.005 value_exit[t] + -0.016 travel_duration + 0.041 value_exit^2 + -0.097 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 140/1000 --- L(Train): 0.3764676 --- L(Val, RNN): 0.3218382 --- L(Val, SINDy): 0.3409794 --- Time: 1.15s; --- Convergence: 2.91e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.11 1 + 0.5 value_stay[t] + 0.293 reward + -0.034 harvest_duration + 0.085 value_stay^2 + 0.049 value_stay*reward + -0.337 value_stay*harvest_duration + 0.702 reward^2 + 0.297 reward*harvest_duration + -0.036 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.004 value_exit[t] + -0.014 travel_duration + 0.042 value_exit^2 + -0.099 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 141/1000 --- L(Train): 0.3816854 --- L(Val, RNN): 0.3224647 --- L(Val, SINDy): 0.3385123 --- Time: 1.40s; --- Convergence: 4.59e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.114 1 + 0.501 value_stay[t] + 0.293 reward + -0.032 harvest_duration + 0.09 value_stay^2 + 0.053 value_stay*reward + -0.336 value_stay*harvest_duration + 0.705 reward^2 + 0.297 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.014 travel_duration + 0.042 value_exit^2 + -0.099 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 142/1000 --- L(Train): 0.3720662 --- L(Val, RNN): 0.3224407 --- L(Val, SINDy): 0.3375566 --- Time: 0.97s; --- Convergence: 2.41e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.116 1 + 0.501 value_stay[t] + 0.292 reward + -0.032 harvest_duration + 0.093 value_stay^2 + 0.056 value_stay*reward + -0.335 value_stay*harvest_duration + 0.706 reward^2 + 0.296 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.004 value_exit[t] + -0.015 travel_duration + 0.042 value_exit^2 + -0.098 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 143/1000 --- L(Train): 0.3794422 --- L(Val, RNN): 0.3222483 --- L(Val, SINDy): 0.3381962 --- Time: 0.99s; --- Convergence: 2.17e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.118 1 + 0.5 value_stay[t] + 0.289 reward + -0.032 harvest_duration + 0.096 value_stay^2 + 0.057 value_stay*reward + -0.336 value_stay*harvest_duration + 0.707 reward^2 + 0.293 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.006 value_exit[t] + -0.017 travel_duration + 0.041 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 144/1000 --- L(Train): 0.3851089 --- L(Val, RNN): 0.3225189 --- L(Val, SINDy): 0.3386226 --- Time: 1.15s; --- Convergence: 2.44e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.118 1 + 0.497 value_stay[t] + 0.286 reward + -0.034 harvest_duration + 0.096 value_stay^2 + 0.059 value_stay*reward + -0.338 value_stay*harvest_duration + 0.706 reward^2 + 0.29 reward*harvest_duration + -0.036 harvest_duration^2 \n",
      "value_exit[t+1] = -0.09 1 + 1.006 value_exit[t] + -0.018 travel_duration + 0.04 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 145/1000 --- L(Train): 0.3859713 --- L(Val, RNN): 0.3229151 --- L(Val, SINDy): 0.3385253 --- Time: 1.10s; --- Convergence: 3.20e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.118 1 + 0.494 value_stay[t] + 0.283 reward + -0.036 harvest_duration + 0.097 value_stay^2 + 0.059 value_stay*reward + -0.341 value_stay*harvest_duration + 0.706 reward^2 + 0.287 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.005 value_exit[t] + -0.017 travel_duration + 0.041 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 146/1000 --- L(Train): 0.3801723 --- L(Val, RNN): 0.3232304 --- L(Val, SINDy): 0.3396293 --- Time: 1.30s; --- Convergence: 3.18e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.119 1 + 0.493 value_stay[t] + 0.28 reward + -0.037 harvest_duration + 0.099 value_stay^2 + 0.061 value_stay*reward + -0.342 value_stay*harvest_duration + 0.706 reward^2 + 0.285 reward*harvest_duration + -0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.015 travel_duration + 0.042 value_exit^2 + -0.098 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 147/1000 --- L(Train): 0.3625561 --- L(Val, RNN): 0.3234298 --- L(Val, SINDy): 0.3399337 --- Time: 0.90s; --- Convergence: 2.59e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.121 1 + 0.492 value_stay[t] + 0.279 reward + -0.037 harvest_duration + 0.102 value_stay^2 + 0.063 value_stay*reward + -0.343 value_stay*harvest_duration + 0.707 reward^2 + 0.283 reward*harvest_duration + -0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.002 value_exit[t] + -0.014 travel_duration + 0.043 value_exit^2 + -0.099 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 148/1000 --- L(Train): 0.3800977 --- L(Val, RNN): 0.3235027 --- L(Val, SINDy): 0.3399130 --- Time: 1.21s; --- Convergence: 1.66e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.124 1 + 0.493 value_stay[t] + 0.278 reward + -0.037 harvest_duration + 0.106 value_stay^2 + 0.067 value_stay*reward + -0.342 value_stay*harvest_duration + 0.709 reward^2 + 0.282 reward*harvest_duration + -0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.003 value_exit[t] + -0.015 travel_duration + 0.043 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 149/1000 --- L(Train): 0.3868265 --- L(Val, RNN): 0.3235816 --- L(Val, SINDy): 0.3392246 --- Time: 0.93s; --- Convergence: 1.22e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.129 1 + 0.496 value_stay[t] + 0.279 reward + -0.034 harvest_duration + 0.112 value_stay^2 + 0.072 value_stay*reward + -0.34 value_stay*harvest_duration + 0.712 reward^2 + 0.283 reward*harvest_duration + -0.036 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.005 value_exit[t] + -0.017 travel_duration + 0.041 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 150/1000 --- L(Train): 0.3915248 --- L(Val, RNN): 0.3238239 --- L(Val, SINDy): 0.3383423 --- Time: 0.95s; --- Convergence: 1.82e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.133 1 + 0.498 value_stay[t] + 0.279 reward + -0.033 harvest_duration + 0.117 value_stay^2 + 0.077 value_stay*reward + -0.338 value_stay*harvest_duration + 0.715 reward^2 + 0.283 reward*harvest_duration + -0.035 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.005 value_exit[t] + -0.017 travel_duration + 0.041 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 151/1000 --- L(Train): 0.3771703 --- L(Val, RNN): 0.3239193 --- L(Val, SINDy): 0.3375174 --- Time: 0.98s; --- Convergence: 1.39e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.136 1 + 0.499 value_stay[t] + 0.277 reward + -0.032 harvest_duration + 0.12 value_stay^2 + 0.08 value_stay*reward + -0.338 value_stay*harvest_duration + 0.716 reward^2 + 0.282 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.016 travel_duration + 0.042 value_exit^2 + -0.097 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 152/1000 --- L(Train): 0.3857234 --- L(Val, RNN): 0.3241553 --- L(Val, SINDy): 0.3378377 --- Time: 0.92s; --- Convergence: 1.87e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.136 1 + 0.496 value_stay[t] + 0.274 reward + -0.035 harvest_duration + 0.121 value_stay^2 + 0.081 value_stay*reward + -0.341 value_stay*harvest_duration + 0.715 reward^2 + 0.278 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.002 value_exit[t] + -0.014 travel_duration + 0.044 value_exit^2 + -0.099 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 153/1000 --- L(Train): 0.3878178 --- L(Val, RNN): 0.3244281 --- L(Val, SINDy): 0.3390090 --- Time: 1.76s; --- Convergence: 2.30e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.136 1 + 0.493 value_stay[t] + 0.269 reward + -0.038 harvest_duration + 0.12 value_stay^2 + 0.081 value_stay*reward + -0.345 value_stay*harvest_duration + 0.714 reward^2 + 0.273 reward*harvest_duration + -0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.002 value_exit[t] + -0.015 travel_duration + 0.043 value_exit^2 + -0.098 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 154/1000 --- L(Train): 0.3906905 --- L(Val, RNN): 0.3247790 --- L(Val, SINDy): 0.3381380 --- Time: 2.35s; --- Convergence: 2.91e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.137 1 + 0.49 value_stay[t] + 0.266 reward + -0.04 harvest_duration + 0.121 value_stay^2 + 0.082 value_stay*reward + -0.348 value_stay*harvest_duration + 0.713 reward^2 + 0.27 reward*harvest_duration + -0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.016 travel_duration + 0.043 value_exit^2 + -0.097 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 155/1000 --- L(Train): 0.3895659 --- L(Val, RNN): 0.3249811 --- L(Val, SINDy): 0.3378260 --- Time: 3.64s; --- Convergence: 2.46e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.138 1 + 0.489 value_stay[t] + 0.263 reward + -0.042 harvest_duration + 0.122 value_stay^2 + 0.083 value_stay*reward + -0.35 value_stay*harvest_duration + 0.712 reward^2 + 0.267 reward*harvest_duration + -0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.004 value_exit[t] + -0.017 travel_duration + 0.042 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 156/1000 --- L(Train): 0.3780435 --- L(Val, RNN): 0.3250820 --- L(Val, SINDy): 0.3396377 --- Time: 5.51s; --- Convergence: 1.74e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.142 1 + 0.49 value_stay[t] + 0.262 reward + -0.041 harvest_duration + 0.125 value_stay^2 + 0.086 value_stay*reward + -0.35 value_stay*harvest_duration + 0.714 reward^2 + 0.266 reward*harvest_duration + -0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.017 travel_duration + 0.043 value_exit^2 + -0.097 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 157/1000 --- L(Train): 0.3843363 --- L(Val, RNN): 0.3252389 --- L(Val, SINDy): 0.3434076 --- Time: 3.79s; --- Convergence: 1.65e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.148 1 + 0.493 value_stay[t] + 0.263 reward + -0.037 harvest_duration + 0.13 value_stay^2 + 0.091 value_stay*reward + -0.347 value_stay*harvest_duration + 0.718 reward^2 + 0.268 reward*harvest_duration + -0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 1.001 value_exit[t] + -0.015 travel_duration + 0.044 value_exit^2 + -0.099 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 158/1000 --- L(Train): 0.3957593 --- L(Val, RNN): 0.3254926 --- L(Val, SINDy): 0.3415511 --- Time: 3.11s; --- Convergence: 2.09e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.153 1 + 0.496 value_stay[t] + 0.265 reward + -0.034 harvest_duration + 0.135 value_stay^2 + 0.096 value_stay*reward + -0.344 value_stay*harvest_duration + 0.721 reward^2 + 0.269 reward*harvest_duration + -0.036 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 1.0 value_exit[t] + -0.014 travel_duration + 0.045 value_exit^2 + -0.1 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 159/1000 --- L(Train): 0.3976619 --- L(Val, RNN): 0.3258745 --- L(Val, SINDy): 0.3398752 --- Time: 3.68s; --- Convergence: 2.96e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.159 1 + 0.499 value_stay[t] + 0.265 reward + -0.032 harvest_duration + 0.14 value_stay^2 + 0.1 value_stay*reward + -0.343 value_stay*harvest_duration + 0.724 reward^2 + 0.27 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 1.0 value_exit[t] + -0.014 travel_duration + 0.045 value_exit^2 + -0.1 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 160/1000 --- L(Train): 0.3910590 --- L(Val, RNN): 0.3260571 --- L(Val, SINDy): 0.3400107 --- Time: 6.47s; --- Convergence: 2.39e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.161 1 + 0.499 value_stay[t] + 0.264 reward + -0.031 harvest_duration + 0.142 value_stay^2 + 0.102 value_stay*reward + -0.343 value_stay*harvest_duration + 0.725 reward^2 + 0.268 reward*harvest_duration + -0.033 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.002 value_exit[t] + -0.016 travel_duration + 0.044 value_exit^2 + -0.098 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 161/1000 --- L(Train): 0.3898806 --- L(Val, RNN): 0.3260823 --- L(Val, SINDy): 0.3412288 --- Time: 5.19s; --- Convergence: 1.32e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.162 1 + 0.497 value_stay[t] + 0.261 reward + -0.032 harvest_duration + 0.141 value_stay^2 + 0.102 value_stay*reward + -0.346 value_stay*harvest_duration + 0.724 reward^2 + 0.265 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.017 travel_duration + 0.043 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 162/1000 --- L(Train): 0.4051255 --- L(Val, RNN): 0.3263068 --- L(Val, SINDy): 0.3408326 --- Time: 3.70s; --- Convergence: 1.78e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.161 1 + 0.493 value_stay[t] + 0.257 reward + -0.035 harvest_duration + 0.139 value_stay^2 + 0.1 value_stay*reward + -0.35 value_stay*harvest_duration + 0.721 reward^2 + 0.261 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.018 travel_duration + 0.042 value_exit^2 + -0.096 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 163/1000 --- L(Train): 0.3977874 --- L(Val, RNN): 0.3267061 --- L(Val, SINDy): 0.3388878 --- Time: 2.56s; --- Convergence: 2.89e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.159 1 + 0.487 value_stay[t] + 0.251 reward + -0.039 harvest_duration + 0.136 value_stay^2 + 0.097 value_stay*reward + -0.356 value_stay*harvest_duration + 0.718 reward^2 + 0.255 reward*harvest_duration + -0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 1.0 value_exit[t] + -0.015 travel_duration + 0.045 value_exit^2 + -0.099 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 164/1000 --- L(Train): 0.3998370 --- L(Val, RNN): 0.3270072 --- L(Val, SINDy): 0.3385317 --- Time: 2.90s; --- Convergence: 2.95e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.158 1 + 0.483 value_stay[t] + 0.246 reward + -0.042 harvest_duration + 0.134 value_stay^2 + 0.094 value_stay*reward + -0.36 value_stay*harvest_duration + 0.715 reward^2 + 0.25 reward*harvest_duration + -0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.998 value_exit[t] + -0.012 travel_duration + 0.047 value_exit^2 + -0.102 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 165/1000 --- L(Train): 0.3992549 --- L(Val, RNN): 0.3271177 --- L(Val, SINDy): 0.3396792 --- Time: 1.87s; --- Convergence: 2.03e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.162 1 + 0.485 value_stay[t] + 0.246 reward + -0.04 harvest_duration + 0.138 value_stay^2 + 0.098 value_stay*reward + -0.359 value_stay*harvest_duration + 0.717 reward^2 + 0.251 reward*harvest_duration + -0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 1.001 value_exit[t] + -0.015 travel_duration + 0.045 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 166/1000 --- L(Train): 0.3949247 --- L(Val, RNN): 0.3269964 --- L(Val, SINDy): 0.3406721 --- Time: 2.94s; --- Convergence: 1.62e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.167 1 + 0.489 value_stay[t] + 0.248 reward + -0.038 harvest_duration + 0.143 value_stay^2 + 0.102 value_stay*reward + -0.357 value_stay*harvest_duration + 0.72 reward^2 + 0.252 reward*harvest_duration + -0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.018 travel_duration + 0.042 value_exit^2 + -0.096 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 167/1000 --- L(Train): 0.3963901 --- L(Val, RNN): 0.3270382 --- L(Val, SINDy): 0.3401881 --- Time: 1.83s; --- Convergence: 1.02e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.171 1 + 0.491 value_stay[t] + 0.249 reward + -0.035 harvest_duration + 0.147 value_stay^2 + 0.107 value_stay*reward + -0.355 value_stay*harvest_duration + 0.723 reward^2 + 0.254 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.005 value_exit[t] + -0.02 travel_duration + 0.041 value_exit^2 + -0.094 value_exit*travel_duration + -0.019 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 168/1000 --- L(Train): 0.4219224 --- L(Val, RNN): 0.3273104 --- L(Val, SINDy): 0.3390715 --- Time: 1.59s; --- Convergence: 1.87e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.174 1 + 0.493 value_stay[t] + 0.25 reward + -0.033 harvest_duration + 0.15 value_stay^2 + 0.11 value_stay*reward + -0.353 value_stay*harvest_duration + 0.726 reward^2 + 0.254 reward*harvest_duration + -0.035 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.004 value_exit[t] + -0.019 travel_duration + 0.042 value_exit^2 + -0.095 value_exit*travel_duration + -0.018 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 169/1000 --- L(Train): 0.4172429 --- L(Val, RNN): 0.3276533 --- L(Val, SINDy): 0.3374776 --- Time: 0.95s; --- Convergence: 2.65e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.175 1 + 0.493 value_stay[t] + 0.249 reward + -0.034 harvest_duration + 0.152 value_stay^2 + 0.112 value_stay*reward + -0.354 value_stay*harvest_duration + 0.726 reward^2 + 0.253 reward*harvest_duration + -0.036 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.001 value_exit[t] + -0.016 travel_duration + 0.045 value_exit^2 + -0.098 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 170/1000 --- L(Train): 0.3941471 --- L(Val, RNN): 0.3277910 --- L(Val, SINDy): 0.3372464 --- Time: 1.17s; --- Convergence: 2.01e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.174 1 + 0.491 value_stay[t] + 0.246 reward + -0.036 harvest_duration + 0.151 value_stay^2 + 0.111 value_stay*reward + -0.357 value_stay*harvest_duration + 0.725 reward^2 + 0.25 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.998 value_exit[t] + -0.013 travel_duration + 0.047 value_exit^2 + -0.101 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 171/1000 --- L(Train): 0.3950651 --- L(Val, RNN): 0.3278462 --- L(Val, SINDy): 0.3382113 --- Time: 0.85s; --- Convergence: 1.28e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.173 1 + 0.487 value_stay[t] + 0.242 reward + -0.038 harvest_duration + 0.149 value_stay^2 + 0.11 value_stay*reward + -0.36 value_stay*harvest_duration + 0.723 reward^2 + 0.246 reward*harvest_duration + -0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.999 value_exit[t] + -0.013 travel_duration + 0.046 value_exit^2 + -0.101 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 172/1000 --- L(Train): 0.4054131 --- L(Val, RNN): 0.3279414 --- L(Val, SINDy): 0.3396854 --- Time: 0.90s; --- Convergence: 1.12e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.174 1 + 0.487 value_stay[t] + 0.241 reward + -0.038 harvest_duration + 0.15 value_stay^2 + 0.112 value_stay*reward + -0.361 value_stay*harvest_duration + 0.723 reward^2 + 0.245 reward*harvest_duration + -0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.018 travel_duration + 0.043 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 173/1000 --- L(Train): 0.4119178 --- L(Val, RNN): 0.3281453 --- L(Val, SINDy): 0.3396498 --- Time: 0.81s; --- Convergence: 1.58e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.177 1 + 0.487 value_stay[t] + 0.241 reward + -0.037 harvest_duration + 0.152 value_stay^2 + 0.115 value_stay*reward + -0.361 value_stay*harvest_duration + 0.725 reward^2 + 0.245 reward*harvest_duration + -0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.004 value_exit[t] + -0.019 travel_duration + 0.042 value_exit^2 + -0.095 value_exit*travel_duration + -0.018 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 174/1000 --- L(Train): 0.3892592 --- L(Val, RNN): 0.3282237 --- L(Val, SINDy): 0.3401778 --- Time: 0.84s; --- Convergence: 1.18e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.179 1 + 0.488 value_stay[t] + 0.241 reward + -0.035 harvest_duration + 0.154 value_stay^2 + 0.117 value_stay*reward + -0.36 value_stay*harvest_duration + 0.727 reward^2 + 0.246 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.002 value_exit[t] + -0.018 travel_duration + 0.043 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 175/1000 --- L(Train): 0.3996973 --- L(Val, RNN): 0.3283603 --- L(Val, SINDy): 0.3410309 --- Time: 1.06s; --- Convergence: 1.27e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.181 1 + 0.488 value_stay[t] + 0.241 reward + -0.035 harvest_duration + 0.156 value_stay^2 + 0.12 value_stay*reward + -0.36 value_stay*harvest_duration + 0.728 reward^2 + 0.246 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 1.0 value_exit[t] + -0.015 travel_duration + 0.045 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 176/1000 --- L(Train): 0.4106077 --- L(Val, RNN): 0.3285976 --- L(Val, SINDy): 0.3399905 --- Time: 1.17s; --- Convergence: 1.82e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.182 1 + 0.487 value_stay[t] + 0.24 reward + -0.035 harvest_duration + 0.155 value_stay^2 + 0.12 value_stay*reward + -0.362 value_stay*harvest_duration + 0.728 reward^2 + 0.244 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.999 value_exit[t] + -0.014 travel_duration + 0.047 value_exit^2 + -0.101 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 177/1000 --- L(Train): 0.4110871 --- L(Val, RNN): 0.3288158 --- L(Val, SINDy): 0.3373711 --- Time: 0.98s; --- Convergence: 2.00e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.182 1 + 0.484 value_stay[t] + 0.237 reward + -0.036 harvest_duration + 0.154 value_stay^2 + 0.12 value_stay*reward + -0.364 value_stay*harvest_duration + 0.728 reward^2 + 0.242 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.999 value_exit[t] + -0.014 travel_duration + 0.046 value_exit^2 + -0.1 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 178/1000 --- L(Train): 0.4193509 --- L(Val, RNN): 0.3289137 --- L(Val, SINDy): 0.3375634 --- Time: 1.17s; --- Convergence: 1.49e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.181 1 + 0.482 value_stay[t] + 0.235 reward + -0.036 harvest_duration + 0.153 value_stay^2 + 0.12 value_stay*reward + -0.367 value_stay*harvest_duration + 0.727 reward^2 + 0.239 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.001 value_exit[t] + -0.016 travel_duration + 0.044 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 179/1000 --- L(Train): 0.4000045 --- L(Val, RNN): 0.3289104 --- L(Val, SINDy): 0.3370635 --- Time: 0.99s; --- Convergence: 7.62e-05; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.181 1 + 0.479 value_stay[t] + 0.233 reward + -0.037 harvest_duration + 0.152 value_stay^2 + 0.12 value_stay*reward + -0.369 value_stay*harvest_duration + 0.726 reward^2 + 0.237 reward*harvest_duration + -0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.018 travel_duration + 0.043 value_exit^2 + -0.096 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 180/1000 --- L(Train): 0.3963223 --- L(Val, RNN): 0.3290032 --- L(Val, SINDy): 0.3376008 --- Time: 1.00s; --- Convergence: 8.45e-05; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.182 1 + 0.478 value_stay[t] + 0.232 reward + -0.037 harvest_duration + 0.151 value_stay^2 + 0.12 value_stay*reward + -0.371 value_stay*harvest_duration + 0.726 reward^2 + 0.236 reward*harvest_duration + -0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.002 value_exit[t] + -0.018 travel_duration + 0.043 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 181/1000 --- L(Train): 0.4198335 --- L(Val, RNN): 0.3292559 --- L(Val, SINDy): 0.3373412 --- Time: 1.02s; --- Convergence: 1.69e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.183 1 + 0.477 value_stay[t] + 0.231 reward + -0.036 harvest_duration + 0.151 value_stay^2 + 0.122 value_stay*reward + -0.372 value_stay*harvest_duration + 0.727 reward^2 + 0.236 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + -0.016 travel_duration + 0.045 value_exit^2 + -0.099 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 182/1000 --- L(Train): 0.4334241 --- L(Val, RNN): 0.3296250 --- L(Val, SINDy): 0.3371840 --- Time: 0.83s; --- Convergence: 2.69e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.184 1 + 0.476 value_stay[t] + 0.231 reward + -0.036 harvest_duration + 0.15 value_stay^2 + 0.124 value_stay*reward + -0.372 value_stay*harvest_duration + 0.728 reward^2 + 0.235 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.999 value_exit[t] + -0.014 travel_duration + 0.046 value_exit^2 + -0.1 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 183/1000 --- L(Train): 0.4184193 --- L(Val, RNN): 0.3299550 --- L(Val, SINDy): 0.3379574 --- Time: 0.84s; --- Convergence: 2.99e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.184 1 + 0.474 value_stay[t] + 0.23 reward + -0.035 harvest_duration + 0.15 value_stay^2 + 0.125 value_stay*reward + -0.373 value_stay*harvest_duration + 0.728 reward^2 + 0.234 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.999 value_exit[t] + -0.014 travel_duration + 0.047 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 184/1000 --- L(Train): 0.4123039 --- L(Val, RNN): 0.3300574 --- L(Val, SINDy): 0.3385688 --- Time: 0.84s; --- Convergence: 2.01e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.184 1 + 0.472 value_stay[t] + 0.228 reward + -0.035 harvest_duration + 0.149 value_stay^2 + 0.125 value_stay*reward + -0.375 value_stay*harvest_duration + 0.728 reward^2 + 0.233 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 1.0 value_exit[t] + -0.015 travel_duration + 0.046 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 185/1000 --- L(Train): 0.3994339 --- L(Val, RNN): 0.3300838 --- L(Val, SINDy): 0.3390663 --- Time: 0.88s; --- Convergence: 1.14e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.184 1 + 0.47 value_stay[t] + 0.227 reward + -0.035 harvest_duration + 0.148 value_stay^2 + 0.126 value_stay*reward + -0.376 value_stay*harvest_duration + 0.727 reward^2 + 0.231 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.001 value_exit[t] + -0.017 travel_duration + 0.045 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 186/1000 --- L(Train): 0.4804729 --- L(Val, RNN): 0.3301141 --- L(Val, SINDy): 0.3391569 --- Time: 0.89s; --- Convergence: 7.20e-05; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.185 1 + 0.469 value_stay[t] + 0.226 reward + -0.034 harvest_duration + 0.147 value_stay^2 + 0.127 value_stay*reward + -0.377 value_stay*harvest_duration + 0.728 reward^2 + 0.23 reward*harvest_duration + -0.036 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.002 value_exit[t] + -0.017 travel_duration + 0.044 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 187/1000 --- L(Train): 0.4674323 --- L(Val, RNN): 0.3303348 --- L(Val, SINDy): 0.3376388 --- Time: 0.79s; --- Convergence: 1.46e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.186 1 + 0.468 value_stay[t] + 0.225 reward + -0.033 harvest_duration + 0.147 value_stay^2 + 0.129 value_stay*reward + -0.377 value_stay*harvest_duration + 0.728 reward^2 + 0.23 reward*harvest_duration + -0.035 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.002 value_exit[t] + -0.018 travel_duration + 0.044 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 188/1000 --- L(Train): 0.4357972 --- L(Val, RNN): 0.3305675 --- L(Val, SINDy): 0.3372146 --- Time: 0.84s; --- Convergence: 1.90e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.187 1 + 0.468 value_stay[t] + 0.225 reward + -0.032 harvest_duration + 0.147 value_stay^2 + 0.13 value_stay*reward + -0.377 value_stay*harvest_duration + 0.729 reward^2 + 0.229 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.001 value_exit[t] + -0.017 travel_duration + 0.044 value_exit^2 + -0.098 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 189/1000 --- L(Train): 0.4300498 --- L(Val, RNN): 0.3307293 --- L(Val, SINDy): 0.3379092 --- Time: 1.00s; --- Convergence: 1.76e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.188 1 + 0.467 value_stay[t] + 0.224 reward + -0.031 harvest_duration + 0.147 value_stay^2 + 0.131 value_stay*reward + -0.377 value_stay*harvest_duration + 0.729 reward^2 + 0.228 reward*harvest_duration + -0.033 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + -0.016 travel_duration + 0.045 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 190/1000 --- L(Train): 0.4416681 --- L(Val, RNN): 0.3309361 --- L(Val, SINDy): 0.3381314 --- Time: 0.87s; --- Convergence: 1.91e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.189 1 + 0.466 value_stay[t] + 0.223 reward + -0.031 harvest_duration + 0.146 value_stay^2 + 0.132 value_stay*reward + -0.378 value_stay*harvest_duration + 0.729 reward^2 + 0.227 reward*harvest_duration + -0.033 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.999 value_exit[t] + -0.014 travel_duration + 0.046 value_exit^2 + -0.1 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 191/1000 --- L(Train): 0.4738328 --- L(Val, RNN): 0.3311182 --- L(Val, SINDy): 0.3381907 --- Time: 0.82s; --- Convergence: 1.87e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.189 1 + 0.465 value_stay[t] + 0.222 reward + -0.031 harvest_duration + 0.145 value_stay^2 + 0.132 value_stay*reward + -0.379 value_stay*harvest_duration + 0.728 reward^2 + 0.226 reward*harvest_duration + -0.033 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.998 value_exit[t] + -0.014 travel_duration + 0.047 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 192/1000 --- L(Train): 0.4482856 --- L(Val, RNN): 0.3313543 --- L(Val, SINDy): 0.3388438 --- Time: 1.10s; --- Convergence: 2.11e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.188 1 + 0.463 value_stay[t] + 0.219 reward + -0.031 harvest_duration + 0.144 value_stay^2 + 0.132 value_stay*reward + -0.381 value_stay*harvest_duration + 0.726 reward^2 + 0.223 reward*harvest_duration + -0.033 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 0.999 value_exit[t] + -0.015 travel_duration + 0.046 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 193/1000 --- L(Train): 0.4541990 --- L(Val, RNN): 0.3316438 --- L(Val, SINDy): 0.3387214 --- Time: 0.87s; --- Convergence: 2.50e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.189 1 + 0.462 value_stay[t] + 0.217 reward + -0.031 harvest_duration + 0.144 value_stay^2 + 0.133 value_stay*reward + -0.381 value_stay*harvest_duration + 0.725 reward^2 + 0.222 reward*harvest_duration + -0.033 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.001 value_exit[t] + -0.017 travel_duration + 0.045 value_exit^2 + -0.098 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 194/1000 --- L(Train): 0.4646768 --- L(Val, RNN): 0.3316591 --- L(Val, SINDy): 0.3386627 --- Time: 0.90s; --- Convergence: 1.33e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.191 1 + 0.463 value_stay[t] + 0.216 reward + -0.03 harvest_duration + 0.144 value_stay^2 + 0.134 value_stay*reward + -0.381 value_stay*harvest_duration + 0.725 reward^2 + 0.221 reward*harvest_duration + -0.032 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.002 value_exit[t] + -0.017 travel_duration + 0.044 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 195/1000 --- L(Train): 0.4486984 --- L(Val, RNN): 0.3317057 --- L(Val, SINDy): 0.3383778 --- Time: 1.00s; --- Convergence: 8.97e-05; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.193 1 + 0.463 value_stay[t] + 0.216 reward + -0.028 harvest_duration + 0.145 value_stay^2 + 0.135 value_stay*reward + -0.38 value_stay*harvest_duration + 0.725 reward^2 + 0.22 reward*harvest_duration + -0.03 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.001 value_exit[t] + -0.016 travel_duration + 0.045 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 196/1000 --- L(Train): 0.4498152 --- L(Val, RNN): 0.3318886 --- L(Val, SINDy): 0.3382736 --- Time: 1.30s; --- Convergence: 1.36e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.195 1 + 0.464 value_stay[t] + 0.215 reward + -0.027 harvest_duration + 0.146 value_stay^2 + 0.137 value_stay*reward + -0.38 value_stay*harvest_duration + 0.725 reward^2 + 0.219 reward*harvest_duration + -0.029 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 0.999 value_exit[t] + -0.015 travel_duration + 0.046 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 197/1000 --- L(Train): 0.4610845 --- L(Val, RNN): 0.3319443 --- L(Val, SINDy): 0.3380778 --- Time: 0.85s; --- Convergence: 9.60e-05; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.197 1 + 0.465 value_stay[t] + 0.214 reward + -0.026 harvest_duration + 0.146 value_stay^2 + 0.138 value_stay*reward + -0.38 value_stay*harvest_duration + 0.724 reward^2 + 0.218 reward*harvest_duration + -0.028 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.998 value_exit[t] + -0.014 travel_duration + 0.047 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 198/1000 --- L(Train): 0.4591763 --- L(Val, RNN): 0.3320583 --- L(Val, SINDy): 0.3380427 --- Time: 0.93s; --- Convergence: 1.05e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.198 1 + 0.464 value_stay[t] + 0.212 reward + -0.026 harvest_duration + 0.146 value_stay^2 + 0.138 value_stay*reward + -0.38 value_stay*harvest_duration + 0.723 reward^2 + 0.216 reward*harvest_duration + -0.028 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.998 value_exit[t] + -0.014 travel_duration + 0.047 value_exit^2 + -0.1 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 199/1000 --- L(Train): 0.4608829 --- L(Val, RNN): 0.3322850 --- L(Val, SINDy): 0.3381572 --- Time: 0.84s; --- Convergence: 1.66e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.198 1 + 0.463 value_stay[t] + 0.209 reward + -0.027 harvest_duration + 0.145 value_stay^2 + 0.138 value_stay*reward + -0.382 value_stay*harvest_duration + 0.721 reward^2 + 0.213 reward*harvest_duration + -0.029 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 0.999 value_exit[t] + -0.015 travel_duration + 0.046 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\n",
      ">>> Warmup complete (epoch 200). Reset optimizer state for 2 SINDy parameters (fresh start at full regularization strength).\n",
      "\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 200/1000 --- L(Train): 0.4484673 --- L(Val, RNN): 0.3324696 --- L(Val, SINDy): 0.3384752 --- Time: 0.93s; --- Convergence: 1.75e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.198 1 + 0.462 value_stay[t] + 0.206 reward + -0.028 harvest_duration + 0.144 value_stay^2 + 0.138 value_stay*reward + -0.383 value_stay*harvest_duration + 0.719 reward^2 + 0.211 reward*harvest_duration + -0.03 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + -0.016 travel_duration + 0.045 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 1, 0, 0, 0, 0, 0, 1\n",
      "value_exit: 0, 1, 1, 1, 0, 1\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 201/1000 --- L(Train): 0.4447877 --- L(Val, RNN): 0.3326565 --- L(Val, SINDy): 0.4140917 --- Time: 0.88s; --- Convergence: 1.81e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 1/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.208 1 + 0.472 value_stay[t] + 0.216 reward + -0.018 harvest_duration + 0.154 value_stay^2 + 0.148 value_stay*reward + -0.373 value_stay*harvest_duration + 0.729 reward^2 + 0.221 reward*harvest_duration + -0.02 harvest_duration^2 \n",
      "value_exit[t+1] = -0.075 1 + 0.99 value_exit[t] + -0.006 travel_duration + 0.055 value_exit^2 + -0.108 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 2, 0, 0, 0, 0, 0, 2\n",
      "value_exit: 0, 2, 2, 0, 0, 2\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 202/1000 --- L(Train): 3.1607802 --- L(Val, RNN): 0.3335262 --- L(Val, SINDy): 0.3742627 --- Time: 1.15s; --- Convergence: 5.25e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 2/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.212 1 + 0.477 value_stay[t] + 0.22 reward + -0.014 harvest_duration + 0.158 value_stay^2 + 0.153 value_stay*reward + -0.369 value_stay*harvest_duration + 0.732 reward^2 + 0.224 reward*harvest_duration + -0.016 harvest_duration^2 \n",
      "value_exit[t+1] = -0.071 1 + 0.986 value_exit[t] + -0.002 travel_duration + 0.059 value_exit^2 + -0.112 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 3, 0, 0, 0, 0, 0, 3\n",
      "value_exit: 0, 3, 3, 0, 0, 3\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 203/1000 --- L(Train): 1.9332011 --- L(Val, RNN): 0.3344940 --- L(Val, SINDy): 0.3566760 --- Time: 0.86s; --- Convergence: 7.47e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 3/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.209 1 + 0.473 value_stay[t] + 0.214 reward + -0.019 harvest_duration + 0.154 value_stay^2 + 0.15 value_stay*reward + -0.373 value_stay*harvest_duration + 0.727 reward^2 + 0.219 reward*harvest_duration + -0.021 harvest_duration^2 \n",
      "value_exit[t+1] = -0.076 1 + 0.991 value_exit[t] + -0.007 travel_duration + 0.055 value_exit^2 + -0.108 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 4, 0, 0, 0, 0, 0, 4\n",
      "value_exit: 0, 4, 4, 0, 0, 4\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 204/1000 --- L(Train): 1.4744061 --- L(Val, RNN): 0.3351893 --- L(Val, SINDy): 0.3581871 --- Time: 0.89s; --- Convergence: 7.21e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 4/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.205 1 + 0.469 value_stay[t] + 0.209 reward + -0.025 harvest_duration + 0.149 value_stay^2 + 0.147 value_stay*reward + -0.378 value_stay*harvest_duration + 0.722 reward^2 + 0.213 reward*harvest_duration + -0.027 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.996 value_exit[t] + -0.012 travel_duration + 0.05 value_exit^2 + -0.103 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 5, 0, 0, 0, 0, 0, 5\n",
      "value_exit: 0, 5, 5, 1, 0, 5\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 205/1000 --- L(Train): 1.5572056 --- L(Val, RNN): 0.3357444 --- L(Val, SINDy): 0.3562026 --- Time: 1.02s; --- Convergence: 6.38e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 5/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.201 1 + 0.465 value_stay[t] + 0.203 reward + -0.03 harvest_duration + 0.145 value_stay^2 + 0.144 value_stay*reward + -0.383 value_stay*harvest_duration + 0.717 reward^2 + 0.208 reward*harvest_duration + -0.032 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.002 value_exit[t] + -0.018 travel_duration + 0.044 value_exit^2 + -0.097 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 6, 0, 0, 0, 0, 0, 6\n",
      "value_exit: 0, 6, 6, 2, 0, 6\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 206/1000 --- L(Train): 1.4218611 --- L(Val, RNN): 0.3360967 --- L(Val, SINDy): 0.3555548 --- Time: 0.93s; --- Convergence: 4.95e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 6/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.198 1 + 0.462 value_stay[t] + 0.199 reward + -0.034 harvest_duration + 0.141 value_stay^2 + 0.142 value_stay*reward + -0.386 value_stay*harvest_duration + 0.712 reward^2 + 0.203 reward*harvest_duration + -0.036 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.006 value_exit[t] + -0.022 travel_duration + 0.04 value_exit^2 + -0.093 value_exit*travel_duration + -0.021 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 7, 0, 0, 0, 0, 0, 7\n",
      "value_exit: 0, 7, 7, 3, 0, 7\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 207/1000 --- L(Train): 1.0544778 --- L(Val, RNN): 0.3363020 --- L(Val, SINDy): 0.3596557 --- Time: 0.88s; --- Convergence: 3.50e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 7/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.197 1 + 0.461 value_stay[t] + 0.197 reward + -0.036 harvest_duration + 0.14 value_stay^2 + 0.142 value_stay*reward + -0.388 value_stay*harvest_duration + 0.711 reward^2 + 0.202 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.092 1 + 1.007 value_exit[t] + -0.024 travel_duration + 0.038 value_exit^2 + -0.091 value_exit*travel_duration + -0.023 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 8, 0, 0, 0, 0, 0, 8\n",
      "value_exit: 0, 8, 8, 4, 0, 8\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 208/1000 --- L(Train): 0.8520912 --- L(Val, RNN): 0.3365931 --- L(Val, SINDy): 0.3643555 --- Time: 0.85s; --- Convergence: 3.21e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 8/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.199 1 + 0.463 value_stay[t] + 0.198 reward + -0.035 harvest_duration + 0.142 value_stay^2 + 0.144 value_stay*reward + -0.386 value_stay*harvest_duration + 0.712 reward^2 + 0.202 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.006 value_exit[t] + -0.023 travel_duration + 0.039 value_exit^2 + -0.092 value_exit*travel_duration + -0.022 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 9, 0, 0, 0, 0, 0, 9\n",
      "value_exit: 0, 9, 9, 5, 0, 9\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 209/1000 --- L(Train): 0.9432642 --- L(Val, RNN): 0.3370097 --- L(Val, SINDy): 0.3638059 --- Time: 0.75s; --- Convergence: 3.69e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 9/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.202 1 + 0.465 value_stay[t] + 0.2 reward + -0.033 harvest_duration + 0.144 value_stay^2 + 0.147 value_stay*reward + -0.384 value_stay*harvest_duration + 0.713 reward^2 + 0.204 reward*harvest_duration + -0.035 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.004 value_exit[t] + -0.021 travel_duration + 0.041 value_exit^2 + -0.094 value_exit*travel_duration + -0.019 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 10, 0, 0, 0, 0, 0, 10\n",
      "value_exit: 0, 10, 10, 6, 0, 10\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 210/1000 --- L(Train): 0.9578822 --- L(Val, RNN): 0.3375063 --- L(Val, SINDy): 0.3599927 --- Time: 0.91s; --- Convergence: 4.33e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 10/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.205 1 + 0.468 value_stay[t] + 0.202 reward + -0.031 harvest_duration + 0.147 value_stay^2 + 0.15 value_stay*reward + -0.382 value_stay*harvest_duration + 0.715 reward^2 + 0.206 reward*harvest_duration + -0.033 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.001 value_exit[t] + -0.017 travel_duration + 0.044 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 11, 0, 0, 0, 0, 0, 11\n",
      "value_exit: 0, 11, 11, 7, 0, 11\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 211/1000 --- L(Train): 0.9274210 --- L(Val, RNN): 0.3380558 --- L(Val, SINDy): 0.3571654 --- Time: 1.01s; --- Convergence: 4.91e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 11/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.208 1 + 0.471 value_stay[t] + 0.204 reward + -0.028 harvest_duration + 0.149 value_stay^2 + 0.153 value_stay*reward + -0.379 value_stay*harvest_duration + 0.717 reward^2 + 0.208 reward*harvest_duration + -0.03 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.998 value_exit[t] + -0.014 travel_duration + 0.047 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 12, 0, 0, 0, 0, 0, 12\n",
      "value_exit: 0, 12, 12, 8, 0, 12\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 212/1000 --- L(Train): 0.8633414 --- L(Val, RNN): 0.3386598 --- L(Val, SINDy): 0.3523088 --- Time: 1.26s; --- Convergence: 5.47e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 12/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.209 1 + 0.473 value_stay[t] + 0.205 reward + -0.027 harvest_duration + 0.15 value_stay^2 + 0.155 value_stay*reward + -0.378 value_stay*harvest_duration + 0.718 reward^2 + 0.209 reward*harvest_duration + -0.029 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.995 value_exit[t] + -0.011 travel_duration + 0.05 value_exit^2 + -0.103 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 13, 0, 0, 0, 0, 0, 13\n",
      "value_exit: 0, 13, 13, 0, 0, 13\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 213/1000 --- L(Train): 0.7515696 --- L(Val, RNN): 0.3391999 --- L(Val, SINDy): 0.3476968 --- Time: 0.84s; --- Convergence: 5.44e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 13/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.209 1 + 0.471 value_stay[t] + 0.203 reward + -0.028 harvest_duration + 0.149 value_stay^2 + 0.154 value_stay*reward + -0.38 value_stay*harvest_duration + 0.716 reward^2 + 0.207 reward*harvest_duration + -0.03 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.994 value_exit[t] + -0.01 travel_duration + 0.051 value_exit^2 + -0.104 value_exit*travel_duration + -0.009 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 14, 0, 0, 0, 0, 0, 14\n",
      "value_exit: 0, 14, 14, 0, 0, 14\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 214/1000 --- L(Train): 0.6936690 --- L(Val, RNN): 0.3396359 --- L(Val, SINDy): 0.3457995 --- Time: 1.02s; --- Convergence: 4.90e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 14/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.207 1 + 0.47 value_stay[t] + 0.2 reward + -0.03 harvest_duration + 0.147 value_stay^2 + 0.152 value_stay*reward + -0.382 value_stay*harvest_duration + 0.713 reward^2 + 0.204 reward*harvest_duration + -0.032 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.994 value_exit[t] + -0.01 travel_duration + 0.051 value_exit^2 + -0.104 value_exit*travel_duration + -0.009 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 15, 0, 0, 0, 0, 0, 15\n",
      "value_exit: 0, 15, 15, 0, 0, 15\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 215/1000 --- L(Train): 0.6556407 --- L(Val, RNN): 0.3398949 --- L(Val, SINDy): 0.3463714 --- Time: 0.98s; --- Convergence: 3.74e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 15/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.206 1 + 0.467 value_stay[t] + 0.197 reward + -0.032 harvest_duration + 0.144 value_stay^2 + 0.15 value_stay*reward + -0.384 value_stay*harvest_duration + 0.71 reward^2 + 0.201 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.995 value_exit[t] + -0.012 travel_duration + 0.05 value_exit^2 + -0.103 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 16, 0, 0, 0, 0, 0, 16\n",
      "value_exit: 0, 16, 16, 0, 0, 16\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 216/1000 --- L(Train): 0.6325753 --- L(Val, RNN): 0.3400549 --- L(Val, SINDy): 0.3492553 --- Time: 1.25s; --- Convergence: 2.67e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 16/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.204 1 + 0.465 value_stay[t] + 0.194 reward + -0.033 harvest_duration + 0.142 value_stay^2 + 0.148 value_stay*reward + -0.386 value_stay*harvest_duration + 0.707 reward^2 + 0.198 reward*harvest_duration + -0.035 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.014 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 17, 0, 0, 0, 0, 0, 17\n",
      "value_exit: 0, 17, 17, 1, 0, 17\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 217/1000 --- L(Train): 0.6362990 --- L(Val, RNN): 0.3401966 --- L(Val, SINDy): 0.3540957 --- Time: 2.04s; --- Convergence: 2.04e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 17/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.204 1 + 0.464 value_stay[t] + 0.192 reward + -0.033 harvest_duration + 0.141 value_stay^2 + 0.147 value_stay*reward + -0.387 value_stay*harvest_duration + 0.706 reward^2 + 0.196 reward*harvest_duration + -0.035 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.998 value_exit[t] + -0.016 travel_duration + 0.047 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 18, 0, 0, 0, 0, 0, 18\n",
      "value_exit: 0, 18, 18, 2, 0, 18\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 218/1000 --- L(Train): 0.5982640 --- L(Val, RNN): 0.3404363 --- L(Val, SINDy): 0.3567891 --- Time: 5.11s; --- Convergence: 2.22e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 18/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.205 1 + 0.464 value_stay[t] + 0.191 reward + -0.032 harvest_duration + 0.14 value_stay^2 + 0.147 value_stay*reward + -0.387 value_stay*harvest_duration + 0.705 reward^2 + 0.196 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + -0.017 travel_duration + 0.046 value_exit^2 + -0.098 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 19, 0, 0, 0, 0, 0, 19\n",
      "value_exit: 0, 19, 19, 3, 0, 19\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 219/1000 --- L(Train): 0.5860381 --- L(Val, RNN): 0.3407426 --- L(Val, SINDy): 0.3560641 --- Time: 5.89s; --- Convergence: 2.64e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 19/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.207 1 + 0.465 value_stay[t] + 0.192 reward + -0.03 harvest_duration + 0.141 value_stay^2 + 0.148 value_stay*reward + -0.386 value_stay*harvest_duration + 0.705 reward^2 + 0.196 reward*harvest_duration + -0.032 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + -0.017 travel_duration + 0.046 value_exit^2 + -0.098 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 20, 0, 0, 0, 0, 0, 20\n",
      "value_exit: 0, 20, 20, 4, 0, 20\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 220/1000 --- L(Train): 0.5970812 --- L(Val, RNN): 0.3411337 --- L(Val, SINDy): 0.3530634 --- Time: 2.71s; --- Convergence: 3.28e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 20/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.21 1 + 0.466 value_stay[t] + 0.193 reward + -0.027 harvest_duration + 0.142 value_stay^2 + 0.149 value_stay*reward + -0.384 value_stay*harvest_duration + 0.707 reward^2 + 0.197 reward*harvest_duration + -0.029 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 0.999 value_exit[t] + -0.017 travel_duration + 0.047 value_exit^2 + -0.099 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 21, 0, 0, 0, 0, 0, 21\n",
      "value_exit: 0, 21, 21, 5, 0, 21\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 221/1000 --- L(Train): 0.5584361 --- L(Val, RNN): 0.3415103 --- L(Val, SINDy): 0.3498115 --- Time: 2.25s; --- Convergence: 3.52e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 21/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.213 1 + 0.468 value_stay[t] + 0.194 reward + -0.024 harvest_duration + 0.143 value_stay^2 + 0.151 value_stay*reward + -0.383 value_stay*harvest_duration + 0.708 reward^2 + 0.198 reward*harvest_duration + -0.026 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.998 value_exit[t] + -0.016 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 22, 0, 0, 0, 0, 0, 22\n",
      "value_exit: 0, 22, 22, 6, 0, 22\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 222/1000 --- L(Train): 0.5047039 --- L(Val, RNN): 0.3417369 --- L(Val, SINDy): 0.3491075 --- Time: 2.27s; --- Convergence: 2.89e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 22/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.215 1 + 0.469 value_stay[t] + 0.195 reward + -0.021 harvest_duration + 0.144 value_stay^2 + 0.152 value_stay*reward + -0.381 value_stay*harvest_duration + 0.709 reward^2 + 0.199 reward*harvest_duration + -0.023 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.996 value_exit[t] + -0.014 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 23, 0, 0, 0, 0, 0, 23\n",
      "value_exit: 0, 23, 23, 7, 0, 23\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 223/1000 --- L(Train): 0.5085118 --- L(Val, RNN): 0.3417372 --- L(Val, SINDy): 0.3487705 --- Time: 2.34s; --- Convergence: 1.45e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 23/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.215 1 + 0.468 value_stay[t] + 0.194 reward + -0.021 harvest_duration + 0.143 value_stay^2 + 0.151 value_stay*reward + -0.382 value_stay*harvest_duration + 0.707 reward^2 + 0.198 reward*harvest_duration + -0.023 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.995 value_exit[t] + -0.013 travel_duration + 0.051 value_exit^2 + -0.102 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 24, 0, 0, 0, 0, 0, 24\n",
      "value_exit: 0, 24, 24, 0, 0, 24\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 224/1000 --- L(Train): 0.5148552 --- L(Val, RNN): 0.3416036 --- L(Val, SINDy): 0.3485470 --- Time: 2.92s; --- Convergence: 1.39e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 24/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.214 1 + 0.466 value_stay[t] + 0.191 reward + -0.022 harvest_duration + 0.14 value_stay^2 + 0.148 value_stay*reward + -0.384 value_stay*harvest_duration + 0.704 reward^2 + 0.195 reward*harvest_duration + -0.024 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.994 value_exit[t] + -0.012 travel_duration + 0.052 value_exit^2 + -0.103 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 25, 0, 0, 0, 0, 0, 25\n",
      "value_exit: 0, 25, 25, 0, 0, 25\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 225/1000 --- L(Train): 0.5211936 --- L(Val, RNN): 0.3416046 --- L(Val, SINDy): 0.3476354 --- Time: 2.35s; --- Convergence: 7.01e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 25/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.213 1 + 0.463 value_stay[t] + 0.188 reward + -0.023 harvest_duration + 0.138 value_stay^2 + 0.146 value_stay*reward + -0.387 value_stay*harvest_duration + 0.702 reward^2 + 0.192 reward*harvest_duration + -0.025 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.993 value_exit[t] + -0.011 travel_duration + 0.052 value_exit^2 + -0.104 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 26, 0, 0, 0, 0, 0, 26\n",
      "value_exit: 0, 26, 26, 0, 0, 26\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 226/1000 --- L(Train): 0.4919272 --- L(Val, RNN): 0.3416593 --- L(Val, SINDy): 0.3483410 --- Time: 2.70s; --- Convergence: 6.24e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 26/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.213 1 + 0.463 value_stay[t] + 0.187 reward + -0.023 harvest_duration + 0.136 value_stay^2 + 0.145 value_stay*reward + -0.387 value_stay*harvest_duration + 0.701 reward^2 + 0.191 reward*harvest_duration + -0.025 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.993 value_exit[t] + -0.012 travel_duration + 0.052 value_exit^2 + -0.103 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 27, 0, 0, 0, 0, 0, 27\n",
      "value_exit: 0, 27, 27, 0, 0, 27\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 227/1000 --- L(Train): 0.4713509 --- L(Val, RNN): 0.3416198 --- L(Val, SINDy): 0.3495976 --- Time: 1.81s; --- Convergence: 5.10e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 27/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.215 1 + 0.464 value_stay[t] + 0.188 reward + -0.021 harvest_duration + 0.138 value_stay^2 + 0.147 value_stay*reward + -0.386 value_stay*harvest_duration + 0.702 reward^2 + 0.192 reward*harvest_duration + -0.023 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.995 value_exit[t] + -0.014 travel_duration + 0.05 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 28, 0, 0, 0, 0, 0, 28\n",
      "value_exit: 0, 28, 28, 0, 0, 28\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 228/1000 --- L(Train): 0.4704758 --- L(Val, RNN): 0.3414546 --- L(Val, SINDy): 0.3502482 --- Time: 2.54s; --- Convergence: 1.08e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 28/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.218 1 + 0.466 value_stay[t] + 0.189 reward + -0.019 harvest_duration + 0.139 value_stay^2 + 0.149 value_stay*reward + -0.384 value_stay*harvest_duration + 0.703 reward^2 + 0.193 reward*harvest_duration + -0.021 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.016 travel_duration + 0.049 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 29, 0, 0, 0, 0, 0, 29\n",
      "value_exit: 0, 29, 29, 1, 0, 29\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 229/1000 --- L(Train): 0.4700187 --- L(Val, RNN): 0.3414069 --- L(Val, SINDy): 0.3488831 --- Time: 2.02s; --- Convergence: 7.79e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 29/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.22 1 + 0.467 value_stay[t] + 0.189 reward + -0.018 harvest_duration + 0.14 value_stay^2 + 0.151 value_stay*reward + -0.384 value_stay*harvest_duration + 0.704 reward^2 + 0.193 reward*harvest_duration + -0.02 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.996 value_exit[t] + -0.016 travel_duration + 0.049 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 30, 0, 0, 0, 0, 0, 30\n",
      "value_exit: 0, 30, 30, 2, 0, 30\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 230/1000 --- L(Train): 0.4533333 --- L(Val, RNN): 0.3413812 --- L(Val, SINDy): 0.3468323 --- Time: 1.88s; --- Convergence: 5.18e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 30/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.219 1 + 0.465 value_stay[t] + 0.187 reward + -0.019 harvest_duration + 0.138 value_stay^2 + 0.15 value_stay*reward + -0.385 value_stay*harvest_duration + 0.702 reward^2 + 0.191 reward*harvest_duration + -0.021 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.995 value_exit[t] + -0.014 travel_duration + 0.051 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 31, 0, 0, 0, 0, 0, 31\n",
      "value_exit: 0, 31, 31, 0, 0, 31\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 231/1000 --- L(Train): 0.4477691 --- L(Val, RNN): 0.3412105 --- L(Val, SINDy): 0.3463387 --- Time: 1.85s; --- Convergence: 1.11e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 31/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.218 1 + 0.464 value_stay[t] + 0.184 reward + -0.02 harvest_duration + 0.137 value_stay^2 + 0.149 value_stay*reward + -0.387 value_stay*harvest_duration + 0.7 reward^2 + 0.189 reward*harvest_duration + -0.022 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.993 value_exit[t] + -0.013 travel_duration + 0.052 value_exit^2 + -0.103 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 32, 0, 0, 0, 0, 0, 32\n",
      "value_exit: 0, 32, 32, 0, 0, 32\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 232/1000 --- L(Train): 0.4516536 --- L(Val, RNN): 0.3410363 --- L(Val, SINDy): 0.3468645 --- Time: 2.58s; --- Convergence: 1.43e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 32/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.217 1 + 0.462 value_stay[t] + 0.182 reward + -0.022 harvest_duration + 0.135 value_stay^2 + 0.148 value_stay*reward + -0.389 value_stay*harvest_duration + 0.697 reward^2 + 0.186 reward*harvest_duration + -0.024 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 0.992 value_exit[t] + -0.012 travel_duration + 0.054 value_exit^2 + -0.104 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 33, 0, 0, 0, 0, 0, 33\n",
      "value_exit: 0, 33, 33, 0, 0, 33\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 233/1000 --- L(Train): 0.4683941 --- L(Val, RNN): 0.3409162 --- L(Val, SINDy): 0.3478959 --- Time: 1.36s; --- Convergence: 1.31e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 33/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.217 1 + 0.461 value_stay[t] + 0.18 reward + -0.023 harvest_duration + 0.134 value_stay^2 + 0.147 value_stay*reward + -0.391 value_stay*harvest_duration + 0.696 reward^2 + 0.184 reward*harvest_duration + -0.025 harvest_duration^2 \n",
      "value_exit[t+1] = -0.076 1 + 0.991 value_exit[t] + -0.011 travel_duration + 0.054 value_exit^2 + -0.104 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 34, 0, 0, 0, 0, 0, 34\n",
      "value_exit: 0, 34, 34, 0, 0, 34\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 234/1000 --- L(Train): 0.4588708 --- L(Val, RNN): 0.3408676 --- L(Val, SINDy): 0.3485125 --- Time: 0.93s; --- Convergence: 9.00e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 34/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.218 1 + 0.462 value_stay[t] + 0.18 reward + -0.022 harvest_duration + 0.134 value_stay^2 + 0.149 value_stay*reward + -0.39 value_stay*harvest_duration + 0.696 reward^2 + 0.185 reward*harvest_duration + -0.024 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 0.992 value_exit[t] + -0.012 travel_duration + 0.053 value_exit^2 + -0.103 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 35, 0, 0, 0, 0, 0, 35\n",
      "value_exit: 0, 35, 35, 0, 0, 35\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 235/1000 --- L(Train): 0.4448075 --- L(Val, RNN): 0.3408245 --- L(Val, SINDy): 0.3480214 --- Time: 1.27s; --- Convergence: 6.66e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 35/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.22 1 + 0.463 value_stay[t] + 0.181 reward + -0.02 harvest_duration + 0.136 value_stay^2 + 0.15 value_stay*reward + -0.389 value_stay*harvest_duration + 0.697 reward^2 + 0.185 reward*harvest_duration + -0.022 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.993 value_exit[t] + -0.014 travel_duration + 0.053 value_exit^2 + -0.102 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 36, 0, 0, 0, 0, 0, 36\n",
      "value_exit: 0, 36, 36, 0, 0, 36\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 236/1000 --- L(Train): 0.4349307 --- L(Val, RNN): 0.3408145 --- L(Val, SINDy): 0.3466058 --- Time: 1.18s; --- Convergence: 3.83e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 36/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.223 1 + 0.464 value_stay[t] + 0.182 reward + -0.018 harvest_duration + 0.137 value_stay^2 + 0.152 value_stay*reward + -0.388 value_stay*harvest_duration + 0.699 reward^2 + 0.186 reward*harvest_duration + -0.02 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.994 value_exit[t] + -0.015 travel_duration + 0.052 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 37, 0, 0, 0, 0, 0, 37\n",
      "value_exit: 0, 37, 37, 0, 0, 37\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 237/1000 --- L(Train): 0.4441873 --- L(Val, RNN): 0.3407576 --- L(Val, SINDy): 0.3444271 --- Time: 1.13s; --- Convergence: 4.76e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 37/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.224 1 + 0.465 value_stay[t] + 0.182 reward + -0.017 harvest_duration + 0.137 value_stay^2 + 0.153 value_stay*reward + -0.387 value_stay*harvest_duration + 0.699 reward^2 + 0.186 reward*harvest_duration + -0.019 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.994 value_exit[t] + -0.015 travel_duration + 0.052 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 38, 0, 0, 0, 0, 0, 38\n",
      "value_exit: 0, 38, 38, 0, 0, 38\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 238/1000 --- L(Train): 0.4413984 --- L(Val, RNN): 0.3405870 --- L(Val, SINDy): 0.3431724 --- Time: 1.05s; --- Convergence: 1.09e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 38/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.225 1 + 0.465 value_stay[t] + 0.181 reward + -0.017 harvest_duration + 0.137 value_stay^2 + 0.153 value_stay*reward + -0.387 value_stay*harvest_duration + 0.699 reward^2 + 0.185 reward*harvest_duration + -0.019 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.994 value_exit[t] + -0.015 travel_duration + 0.052 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 39, 0, 0, 0, 0, 0, 39\n",
      "value_exit: 0, 39, 39, 0, 0, 39\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 239/1000 --- L(Train): 0.4399113 --- L(Val, RNN): 0.3402090 --- L(Val, SINDy): 0.3435743 --- Time: 0.88s; --- Convergence: 2.44e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 39/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.224 1 + 0.463 value_stay[t] + 0.179 reward + -0.017 harvest_duration + 0.136 value_stay^2 + 0.153 value_stay*reward + -0.389 value_stay*harvest_duration + 0.698 reward^2 + 0.184 reward*harvest_duration + -0.019 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.992 value_exit[t] + -0.014 travel_duration + 0.053 value_exit^2 + -0.102 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 40, 0, 0, 0, 0, 0, 40\n",
      "value_exit: 0, 40, 40, 0, 0, 40\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 240/1000 --- L(Train): 0.4256577 --- L(Val, RNN): 0.3397526 --- L(Val, SINDy): 0.3443553 --- Time: 1.10s; --- Convergence: 3.50e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 40/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.224 1 + 0.462 value_stay[t] + 0.178 reward + -0.018 harvest_duration + 0.135 value_stay^2 + 0.152 value_stay*reward + -0.39 value_stay*harvest_duration + 0.696 reward^2 + 0.182 reward*harvest_duration + -0.02 harvest_duration^2 \n",
      "value_exit[t+1] = -0.076 1 + 0.991 value_exit[t] + -0.013 travel_duration + 0.054 value_exit^2 + -0.103 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 41, 0, 0, 0, 0, 0, 41\n",
      "value_exit: 0, 41, 41, 0, 0, 41\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 241/1000 --- L(Train): 0.4417495 --- L(Val, RNN): 0.3392924 --- L(Val, SINDy): 0.3455099 --- Time: 0.90s; --- Convergence: 4.05e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 41/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.225 1 + 0.462 value_stay[t] + 0.177 reward + -0.018 harvest_duration + 0.134 value_stay^2 + 0.151 value_stay*reward + -0.391 value_stay*harvest_duration + 0.696 reward^2 + 0.181 reward*harvest_duration + -0.02 harvest_duration^2 \n",
      "value_exit[t+1] = -0.076 1 + 0.99 value_exit[t] + -0.012 travel_duration + 0.055 value_exit^2 + -0.104 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 42, 0, 0, 0, 0, 0, 42\n",
      "value_exit: 0, 42, 42, 0, 0, 42\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 242/1000 --- L(Train): 0.4323932 --- L(Val, RNN): 0.3389630 --- L(Val, SINDy): 0.3457211 --- Time: 0.85s; --- Convergence: 3.67e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 42/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.225 1 + 0.461 value_stay[t] + 0.176 reward + -0.017 harvest_duration + 0.133 value_stay^2 + 0.151 value_stay*reward + -0.392 value_stay*harvest_duration + 0.695 reward^2 + 0.18 reward*harvest_duration + -0.019 harvest_duration^2 \n",
      "value_exit[t+1] = -0.075 1 + 0.989 value_exit[t] + -0.011 travel_duration + 0.056 value_exit^2 + -0.104 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 43, 0, 0, 0, 0, 0, 43\n",
      "value_exit: 0, 43, 43, 0, 0, 43\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 243/1000 --- L(Train): 0.4378382 --- L(Val, RNN): 0.3388860 --- L(Val, SINDy): 0.3450460 --- Time: 0.97s; --- Convergence: 2.22e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 43/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.226 1 + 0.461 value_stay[t] + 0.175 reward + -0.017 harvest_duration + 0.133 value_stay^2 + 0.151 value_stay*reward + -0.392 value_stay*harvest_duration + 0.695 reward^2 + 0.179 reward*harvest_duration + -0.019 harvest_duration^2 \n",
      "value_exit[t+1] = -0.075 1 + 0.989 value_exit[t] + -0.011 travel_duration + 0.056 value_exit^2 + -0.104 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 44, 0, 0, 0, 0, 0, 44\n",
      "value_exit: 0, 44, 44, 0, 0, 44\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 244/1000 --- L(Train): 0.4199235 --- L(Val, RNN): 0.3387924 --- L(Val, SINDy): 0.3438163 --- Time: 1.09s; --- Convergence: 1.58e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 44/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.227 1 + 0.461 value_stay[t] + 0.175 reward + -0.016 harvest_duration + 0.133 value_stay^2 + 0.152 value_stay*reward + -0.392 value_stay*harvest_duration + 0.695 reward^2 + 0.179 reward*harvest_duration + -0.018 harvest_duration^2 \n",
      "value_exit[t+1] = -0.075 1 + 0.99 value_exit[t] + -0.012 travel_duration + 0.055 value_exit^2 + -0.104 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 45, 0, 0, 0, 0, 0, 45\n",
      "value_exit: 0, 45, 45, 0, 0, 45\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 245/1000 --- L(Train): 0.4334109 --- L(Val, RNN): 0.3387683 --- L(Val, SINDy): 0.3424699 --- Time: 0.83s; --- Convergence: 9.10e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 45/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.229 1 + 0.462 value_stay[t] + 0.176 reward + -0.014 harvest_duration + 0.134 value_stay^2 + 0.153 value_stay*reward + -0.391 value_stay*harvest_duration + 0.697 reward^2 + 0.18 reward*harvest_duration + -0.016 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 0.991 value_exit[t] + -0.014 travel_duration + 0.054 value_exit^2 + -0.102 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 46, 0, 0, 0, 0, 0, 46\n",
      "value_exit: 0, 46, 46, 0, 0, 46\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 246/1000 --- L(Train): 0.4161119 --- L(Val, RNN): 0.3384843 --- L(Val, SINDy): 0.3422161 --- Time: 0.93s; --- Convergence: 1.87e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 46/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.231 1 + 0.463 value_stay[t] + 0.176 reward + -0.013 harvest_duration + 0.135 value_stay^2 + 0.154 value_stay*reward + -0.39 value_stay*harvest_duration + 0.698 reward^2 + 0.181 reward*harvest_duration + -0.015 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.993 value_exit[t] + -0.015 travel_duration + 0.052 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 47, 0, 0, 0, 0, 0, 47\n",
      "value_exit: 0, 47, 47, 0, 0, 47\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 247/1000 --- L(Train): 0.4267038 --- L(Val, RNN): 0.3383148 --- L(Val, SINDy): 0.3421980 --- Time: 1.06s; --- Convergence: 1.78e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 47/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.233 1 + 0.463 value_stay[t] + 0.176 reward + -0.012 harvest_duration + 0.135 value_stay^2 + 0.155 value_stay*reward + -0.39 value_stay*harvest_duration + 0.698 reward^2 + 0.18 reward*harvest_duration + -0.014 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.994 value_exit[t] + -0.016 travel_duration + 0.052 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 48, 0, 0, 0, 0, 0, 48\n",
      "value_exit: 0, 48, 48, 0, 0, 48\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 248/1000 --- L(Train): 0.4255576 --- L(Val, RNN): 0.3381517 --- L(Val, SINDy): 0.3419876 --- Time: 1.01s; --- Convergence: 1.71e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 48/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.233 1 + 0.463 value_stay[t] + 0.175 reward + -0.012 harvest_duration + 0.135 value_stay^2 + 0.155 value_stay*reward + -0.391 value_stay*harvest_duration + 0.697 reward^2 + 0.18 reward*harvest_duration + -0.014 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.993 value_exit[t] + -0.016 travel_duration + 0.052 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 49, 0, 0, 0, 0, 0, 49\n",
      "value_exit: 0, 49, 49, 0, 0, 49\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 249/1000 --- L(Train): 0.4095676 --- L(Val, RNN): 0.3377096 --- L(Val, SINDy): 0.3418244 --- Time: 1.08s; --- Convergence: 3.06e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 49/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.233 1 + 0.462 value_stay[t] + 0.174 reward + -0.012 harvest_duration + 0.134 value_stay^2 + 0.154 value_stay*reward + -0.392 value_stay*harvest_duration + 0.697 reward^2 + 0.179 reward*harvest_duration + -0.014 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.992 value_exit[t] + -0.015 travel_duration + 0.053 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 50, 0, 0, 0, 0, 0, 50\n",
      "value_exit: 0, 50, 50, 0, 0, 50\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 250/1000 --- L(Train): 0.4053139 --- L(Val, RNN): 0.3373820 --- L(Val, SINDy): 0.3416665 --- Time: 0.84s; --- Convergence: 3.17e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 50/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.234 1 + 0.462 value_stay[t] + 0.174 reward + -0.012 harvest_duration + 0.133 value_stay^2 + 0.154 value_stay*reward + -0.393 value_stay*harvest_duration + 0.697 reward^2 + 0.178 reward*harvest_duration + -0.014 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 0.991 value_exit[t] + -0.014 travel_duration + 0.054 value_exit^2 + -0.103 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 51, 0, 0, 0, 0, 0, 51\n",
      "value_exit: 0, 51, 51, 0, 0, 51\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 251/1000 --- L(Train): 0.4160195 --- L(Val, RNN): 0.3371405 --- L(Val, SINDy): 0.3410721 --- Time: 1.06s; --- Convergence: 2.79e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 51/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.235 1 + 0.461 value_stay[t] + 0.173 reward + -0.012 harvest_duration + 0.133 value_stay^2 + 0.154 value_stay*reward + -0.393 value_stay*harvest_duration + 0.696 reward^2 + 0.177 reward*harvest_duration + -0.014 harvest_duration^2 \n",
      "value_exit[t+1] = -0.076 1 + 0.99 value_exit[t] + -0.013 travel_duration + 0.055 value_exit^2 + -0.103 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 52, 0, 0, 0, 0, 0, 52\n",
      "value_exit: 0, 52, 52, 0, 0, 52\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 252/1000 --- L(Train): 0.4128440 --- L(Val, RNN): 0.3368619 --- L(Val, SINDy): 0.3409139 --- Time: 1.00s; --- Convergence: 2.79e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 52/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.236 1 + 0.461 value_stay[t] + 0.172 reward + -0.012 harvest_duration + 0.133 value_stay^2 + 0.154 value_stay*reward + -0.394 value_stay*harvest_duration + 0.696 reward^2 + 0.177 reward*harvest_duration + -0.014 harvest_duration^2 \n",
      "value_exit[t+1] = -0.076 1 + 0.99 value_exit[t] + -0.013 travel_duration + 0.055 value_exit^2 + -0.103 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 53, 0, 0, 0, 0, 0, 53\n",
      "value_exit: 0, 53, 53, 0, 0, 53\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 253/1000 --- L(Train): 0.4012853 --- L(Val, RNN): 0.3366408 --- L(Val, SINDy): 0.3406148 --- Time: 0.95s; --- Convergence: 2.50e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 53/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.238 1 + 0.463 value_stay[t] + 0.173 reward + -0.01 harvest_duration + 0.134 value_stay^2 + 0.156 value_stay*reward + -0.393 value_stay*harvest_duration + 0.697 reward^2 + 0.177 reward*harvest_duration + -0.012 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 0.992 value_exit[t] + -0.014 travel_duration + 0.053 value_exit^2 + -0.102 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 54, 0, 0, 0, 0, 0, 54\n",
      "value_exit: 0, 54, 54, 0, 0, 54\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 254/1000 --- L(Train): 0.3974013 --- L(Val, RNN): 0.3366806 --- L(Val, SINDy): 0.3400703 --- Time: 0.90s; --- Convergence: 1.45e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 54/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.24 1 + 0.463 value_stay[t] + 0.173 reward + -0.009 harvest_duration + 0.135 value_stay^2 + 0.157 value_stay*reward + -0.393 value_stay*harvest_duration + 0.698 reward^2 + 0.177 reward*harvest_duration + -0.011 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.993 value_exit[t] + -0.016 travel_duration + 0.052 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 55, 0, 0, 0, 0, 0, 55\n",
      "value_exit: 0, 55, 55, 0, 0, 55\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 255/1000 --- L(Train): 0.3951344 --- L(Val, RNN): 0.3366409 --- L(Val, SINDy): 0.3402516 --- Time: 0.82s; --- Convergence: 9.23e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 55/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.241 1 + 0.464 value_stay[t] + 0.172 reward + -0.009 harvest_duration + 0.135 value_stay^2 + 0.157 value_stay*reward + -0.393 value_stay*harvest_duration + 0.697 reward^2 + 0.176 reward*harvest_duration + -0.011 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.993 value_exit[t] + -0.016 travel_duration + 0.052 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 56, 0, 0, 0, 0, 0, 56\n",
      "value_exit: 0, 56, 56, 0, 0, 56\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 256/1000 --- L(Train): 0.4093504 --- L(Val, RNN): 0.3367124 --- L(Val, SINDy): 0.3402778 --- Time: 0.93s; --- Convergence: 8.20e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 56/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.242 1 + 0.464 value_stay[t] + 0.171 reward + -0.009 harvest_duration + 0.135 value_stay^2 + 0.157 value_stay*reward + -0.394 value_stay*harvest_duration + 0.697 reward^2 + 0.176 reward*harvest_duration + -0.011 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.993 value_exit[t] + -0.016 travel_duration + 0.052 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 57, 0, 0, 0, 0, 0, 57\n",
      "value_exit: 0, 57, 57, 0, 0, 57\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 257/1000 --- L(Train): 0.4095838 --- L(Val, RNN): 0.3367396 --- L(Val, SINDy): 0.3400997 --- Time: 0.88s; --- Convergence: 5.46e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 57/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.243 1 + 0.464 value_stay[t] + 0.171 reward + -0.009 harvest_duration + 0.135 value_stay^2 + 0.158 value_stay*reward + -0.394 value_stay*harvest_duration + 0.698 reward^2 + 0.175 reward*harvest_duration + -0.011 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.993 value_exit[t] + -0.015 travel_duration + 0.052 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 58, 0, 0, 0, 0, 0, 58\n",
      "value_exit: 0, 58, 58, 0, 0, 58\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 258/1000 --- L(Train): 0.3910172 --- L(Val, RNN): 0.3365801 --- L(Val, SINDy): 0.3400141 --- Time: 0.92s; --- Convergence: 1.07e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 58/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.244 1 + 0.464 value_stay[t] + 0.17 reward + -0.01 harvest_duration + 0.135 value_stay^2 + 0.158 value_stay*reward + -0.395 value_stay*harvest_duration + 0.698 reward^2 + 0.175 reward*harvest_duration + -0.012 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 0.991 value_exit[t] + -0.014 travel_duration + 0.054 value_exit^2 + -0.103 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 59, 0, 0, 0, 0, 0, 59\n",
      "value_exit: 0, 59, 59, 0, 0, 59\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 259/1000 --- L(Train): 0.3974985 --- L(Val, RNN): 0.3364162 --- L(Val, SINDy): 0.3401904 --- Time: 0.90s; --- Convergence: 1.35e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 59/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.246 1 + 0.465 value_stay[t] + 0.171 reward + -0.009 harvest_duration + 0.136 value_stay^2 + 0.161 value_stay*reward + -0.395 value_stay*harvest_duration + 0.699 reward^2 + 0.176 reward*harvest_duration + -0.011 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 0.992 value_exit[t] + -0.014 travel_duration + 0.054 value_exit^2 + -0.102 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 60, 0, 0, 0, 0, 0, 60\n",
      "value_exit: 0, 60, 60, 0, 0, 60\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 260/1000 --- L(Train): 0.4178391 --- L(Val, RNN): 0.3361446 --- L(Val, SINDy): 0.3402289 --- Time: 0.79s; --- Convergence: 2.04e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 60/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.246 1 + 0.463 value_stay[t] + 0.17 reward + -0.01 harvest_duration + 0.135 value_stay^2 + 0.161 value_stay*reward + -0.397 value_stay*harvest_duration + 0.699 reward^2 + 0.175 reward*harvest_duration + -0.012 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.993 value_exit[t] + -0.015 travel_duration + 0.052 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 61, 0, 0, 0, 0, 0, 61\n",
      "value_exit: 0, 61, 61, 0, 0, 61\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 261/1000 --- L(Train): 0.4142573 --- L(Val, RNN): 0.3359531 --- L(Val, SINDy): 0.3400510 --- Time: 1.13s; --- Convergence: 1.98e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 61/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.245 1 + 0.461 value_stay[t] + 0.169 reward + -0.011 harvest_duration + 0.133 value_stay^2 + 0.16 value_stay*reward + -0.399 value_stay*harvest_duration + 0.698 reward^2 + 0.173 reward*harvest_duration + -0.013 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.994 value_exit[t] + -0.015 travel_duration + 0.051 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 62, 0, 0, 0, 0, 0, 62\n",
      "value_exit: 0, 62, 62, 0, 0, 62\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 262/1000 --- L(Train): 0.3982800 --- L(Val, RNN): 0.3360634 --- L(Val, SINDy): 0.3401947 --- Time: 0.88s; --- Convergence: 1.54e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 62/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.246 1 + 0.46 value_stay[t] + 0.169 reward + -0.011 harvest_duration + 0.132 value_stay^2 + 0.161 value_stay*reward + -0.4 value_stay*harvest_duration + 0.699 reward^2 + 0.173 reward*harvest_duration + -0.013 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.993 value_exit[t] + -0.015 travel_duration + 0.052 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 63, 0, 0, 0, 0, 0, 63\n",
      "value_exit: 0, 63, 63, 0, 0, 63\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 263/1000 --- L(Train): 0.3953603 --- L(Val, RNN): 0.3360024 --- L(Val, SINDy): 0.3398199 --- Time: 1.09s; --- Convergence: 1.07e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 63/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.246 1 + 0.459 value_stay[t] + 0.168 reward + -0.011 harvest_duration + 0.13 value_stay^2 + 0.161 value_stay*reward + -0.402 value_stay*harvest_duration + 0.699 reward^2 + 0.172 reward*harvest_duration + -0.013 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.992 value_exit[t] + -0.014 travel_duration + 0.053 value_exit^2 + -0.102 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 64, 0, 0, 0, 0, 0, 64\n",
      "value_exit: 0, 64, 64, 0, 0, 64\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 264/1000 --- L(Train): 0.4097185 --- L(Val, RNN): 0.3359258 --- L(Val, SINDy): 0.3394373 --- Time: 0.94s; --- Convergence: 9.20e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 64/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.247 1 + 0.458 value_stay[t] + 0.168 reward + -0.01 harvest_duration + 0.13 value_stay^2 + 0.162 value_stay*reward + -0.402 value_stay*harvest_duration + 0.7 reward^2 + 0.172 reward*harvest_duration + -0.012 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.992 value_exit[t] + -0.014 travel_duration + 0.053 value_exit^2 + -0.102 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 65, 0, 0, 0, 0, 0, 65\n",
      "value_exit: 0, 65, 65, 0, 0, 65\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 265/1000 --- L(Train): 0.4087511 --- L(Val, RNN): 0.3358991 --- L(Val, SINDy): 0.3392429 --- Time: 0.84s; --- Convergence: 5.94e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 65/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.249 1 + 0.459 value_stay[t] + 0.169 reward + -0.008 harvest_duration + 0.131 value_stay^2 + 0.164 value_stay*reward + -0.401 value_stay*harvest_duration + 0.702 reward^2 + 0.174 reward*harvest_duration + -0.01 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.994 value_exit[t] + -0.015 travel_duration + 0.051 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 66, 0, 0, 0, 0, 0, 66\n",
      "value_exit: 0, 66, 66, 0, 0, 66\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 266/1000 --- L(Train): 0.4072311 --- L(Val, RNN): 0.3357196 --- L(Val, SINDy): 0.3395881 --- Time: 1.16s; --- Convergence: 1.19e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 66/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.25 1 + 0.459 value_stay[t] + 0.17 reward + -0.006 harvest_duration + 0.131 value_stay^2 + 0.165 value_stay*reward + -0.401 value_stay*harvest_duration + 0.703 reward^2 + 0.174 reward*harvest_duration + -0.008 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.995 value_exit[t] + -0.016 travel_duration + 0.05 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 67, 0, 0, 0, 0, 0, 67\n",
      "value_exit: 0, 67, 67, 1, 0, 67\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 267/1000 --- L(Train): 0.3912229 --- L(Val, RNN): 0.3357886 --- L(Val, SINDy): 0.3386891 --- Time: 0.90s; --- Convergence: 9.42e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 67/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.251 1 + 0.458 value_stay[t] + 0.17 reward + -0.005 harvest_duration + 0.13 value_stay^2 + 0.166 value_stay*reward + -0.401 value_stay*harvest_duration + 0.704 reward^2 + 0.174 reward*harvest_duration + -0.007 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.996 value_exit[t] + -0.016 travel_duration + 0.049 value_exit^2 + -0.099 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 68, 0, 0, 0, 0, 0, 68\n",
      "value_exit: 0, 68, 68, 2, 0, 68\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 268/1000 --- L(Train): 0.4034178 --- L(Val, RNN): 0.3357879 --- L(Val, SINDy): 0.3385125 --- Time: 1.03s; --- Convergence: 4.75e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 68/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.25 1 + 0.456 value_stay[t] + 0.168 reward + -0.005 harvest_duration + 0.128 value_stay^2 + 0.165 value_stay*reward + -0.403 value_stay*harvest_duration + 0.703 reward^2 + 0.172 reward*harvest_duration + -0.007 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.995 value_exit[t] + -0.015 travel_duration + 0.05 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 69, 0, 0, 0, 0, 0, 69\n",
      "value_exit: 0, 69, 69, 0, 0, 69\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 269/1000 --- L(Train): 0.3969114 --- L(Val, RNN): 0.3356634 --- L(Val, SINDy): 0.3389864 --- Time: 1.05s; --- Convergence: 8.60e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 69/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.247 1 + 0.451 value_stay[t] + 0.164 reward + -0.008 harvest_duration + 0.123 value_stay^2 + 0.162 value_stay*reward + -0.407 value_stay*harvest_duration + 0.7 reward^2 + 0.168 reward*harvest_duration + -0.01 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.993 value_exit[t] + -0.013 travel_duration + 0.052 value_exit^2 + -0.102 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 70, 0, 0, 0, 0, 0, 70\n",
      "value_exit: 0, 70, 70, 0, 0, 70\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 270/1000 --- L(Train): 0.3909675 --- L(Val, RNN): 0.3354580 --- L(Val, SINDy): 0.3395458 --- Time: 1.02s; --- Convergence: 1.46e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 70/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.248 1 + 0.451 value_stay[t] + 0.164 reward + -0.007 harvest_duration + 0.123 value_stay^2 + 0.164 value_stay*reward + -0.407 value_stay*harvest_duration + 0.701 reward^2 + 0.168 reward*harvest_duration + -0.009 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.993 value_exit[t] + -0.013 travel_duration + 0.052 value_exit^2 + -0.102 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 71, 0, 0, 0, 0, 0, 71\n",
      "value_exit: 0, 71, 71, 0, 0, 71\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 271/1000 --- L(Train): 0.3883924 --- L(Val, RNN): 0.3353890 --- L(Val, SINDy): 0.3393134 --- Time: 0.86s; --- Convergence: 1.07e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 71/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.25 1 + 0.452 value_stay[t] + 0.166 reward + -0.005 harvest_duration + 0.124 value_stay^2 + 0.167 value_stay*reward + -0.405 value_stay*harvest_duration + 0.703 reward^2 + 0.17 reward*harvest_duration + -0.007 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.995 value_exit[t] + -0.015 travel_duration + 0.05 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 72, 0, 0, 0, 0, 0, 72\n",
      "value_exit: 0, 72, 72, 0, 0, 72\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 272/1000 --- L(Train): 0.3950132 --- L(Val, RNN): 0.3353010 --- L(Val, SINDy): 0.3390819 --- Time: 1.11s; --- Convergence: 9.77e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 72/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.252 1 + 0.453 value_stay[t] + 0.166 reward + -0.003 harvest_duration + 0.125 value_stay^2 + 0.169 value_stay*reward + -0.404 value_stay*harvest_duration + 0.704 reward^2 + 0.17 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.996 value_exit[t] + -0.016 travel_duration + 0.049 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 73, 0, 0, 0, 0, 0, 73\n",
      "value_exit: 0, 73, 73, 1, 0, 73\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 273/1000 --- L(Train): 0.3924995 --- L(Val, RNN): 0.3352695 --- L(Val, SINDy): 0.3387547 --- Time: 0.98s; --- Convergence: 6.46e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 73/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.252 1 + 0.452 value_stay[t] + 0.166 reward + -0.003 harvest_duration + 0.124 value_stay^2 + 0.17 value_stay*reward + -0.404 value_stay*harvest_duration + 0.704 reward^2 + 0.17 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.016 travel_duration + 0.049 value_exit^2 + -0.099 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 74, 0, 0, 0, 0, 0, 74\n",
      "value_exit: 0, 74, 74, 2, 0, 74\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 274/1000 --- L(Train): 0.3953518 --- L(Val, RNN): 0.3350610 --- L(Val, SINDy): 0.3390274 --- Time: 0.80s; --- Convergence: 1.37e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 74/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.251 1 + 0.45 value_stay[t] + 0.164 reward + -0.004 harvest_duration + 0.123 value_stay^2 + 0.169 value_stay*reward + -0.406 value_stay*harvest_duration + 0.703 reward^2 + 0.168 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.995 value_exit[t] + -0.015 travel_duration + 0.05 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 75, 0, 0, 0, 0, 0, 75\n",
      "value_exit: 0, 75, 75, 3, 0, 75\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 275/1000 --- L(Train): 0.3966038 --- L(Val, RNN): 0.3350385 --- L(Val, SINDy): 0.3376936 --- Time: 0.89s; --- Convergence: 7.95e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 75/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.25 1 + 0.448 value_stay[t] + 0.162 reward + -0.005 harvest_duration + 0.121 value_stay^2 + 0.168 value_stay*reward + -0.408 value_stay*harvest_duration + 0.702 reward^2 + 0.166 reward*harvest_duration + -0.007 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.994 value_exit[t] + -0.014 travel_duration + 0.051 value_exit^2 + -0.102 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 76, 0, 0, 0, 0, 0, 76\n",
      "value_exit: 0, 76, 76, 0, 0, 76\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 276/1000 --- L(Train): 0.3907987 --- L(Val, RNN): 0.3348608 --- L(Val, SINDy): 0.3378172 --- Time: 1.58s; --- Convergence: 1.29e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 76/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.249 1 + 0.447 value_stay[t] + 0.16 reward + -0.006 harvest_duration + 0.12 value_stay^2 + 0.168 value_stay*reward + -0.409 value_stay*harvest_duration + 0.7 reward^2 + 0.164 reward*harvest_duration + -0.008 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.995 value_exit[t] + -0.014 travel_duration + 0.05 value_exit^2 + -0.102 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 77, 0, 0, 0, 0, 0, 77\n",
      "value_exit: 0, 77, 77, 0, 0, 77\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 277/1000 --- L(Train): 0.3966623 --- L(Val, RNN): 0.3346118 --- L(Val, SINDy): 0.3383250 --- Time: 1.58s; --- Convergence: 1.89e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 77/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.249 1 + 0.446 value_stay[t] + 0.159 reward + -0.005 harvest_duration + 0.12 value_stay^2 + 0.169 value_stay*reward + -0.409 value_stay*harvest_duration + 0.7 reward^2 + 0.163 reward*harvest_duration + -0.007 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.996 value_exit[t] + -0.015 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 78, 0, 0, 0, 0, 0, 78\n",
      "value_exit: 0, 78, 78, 1, 0, 78\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 278/1000 --- L(Train): 0.3937236 --- L(Val, RNN): 0.3346241 --- L(Val, SINDy): 0.3381226 --- Time: 4.97s; --- Convergence: 1.01e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 78/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.251 1 + 0.448 value_stay[t] + 0.16 reward + -0.004 harvest_duration + 0.122 value_stay^2 + 0.172 value_stay*reward + -0.408 value_stay*harvest_duration + 0.702 reward^2 + 0.164 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.016 travel_duration + 0.049 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 79, 0, 0, 0, 0, 0, 79\n",
      "value_exit: 0, 79, 79, 2, 0, 79\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 279/1000 --- L(Train): 0.3813202 --- L(Val, RNN): 0.3347065 --- L(Val, SINDy): 0.3381020 --- Time: 5.31s; --- Convergence: 9.15e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 79/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.252 1 + 0.448 value_stay[t] + 0.16 reward + -0.003 harvest_duration + 0.123 value_stay^2 + 0.174 value_stay*reward + -0.407 value_stay*harvest_duration + 0.702 reward^2 + 0.164 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.996 value_exit[t] + -0.015 travel_duration + 0.049 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 80, 0, 0, 0, 0, 0, 80\n",
      "value_exit: 0, 80, 80, 3, 0, 80\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 280/1000 --- L(Train): 0.3823008 --- L(Val, RNN): 0.3347776 --- L(Val, SINDy): 0.3381369 --- Time: 3.78s; --- Convergence: 8.13e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 80/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.252 1 + 0.448 value_stay[t] + 0.159 reward + -0.003 harvest_duration + 0.123 value_stay^2 + 0.175 value_stay*reward + -0.407 value_stay*harvest_duration + 0.702 reward^2 + 0.163 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.996 value_exit[t] + -0.014 travel_duration + 0.05 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 81, 0, 0, 0, 0, 0, 81\n",
      "value_exit: 0, 81, 81, 4, 0, 81\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 281/1000 --- L(Train): 0.3869972 --- L(Val, RNN): 0.3346428 --- L(Val, SINDy): 0.3377096 --- Time: 3.67s; --- Convergence: 1.08e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 81/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.251 1 + 0.447 value_stay[t] + 0.157 reward + -0.004 harvest_duration + 0.122 value_stay^2 + 0.175 value_stay*reward + -0.408 value_stay*harvest_duration + 0.701 reward^2 + 0.161 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.995 value_exit[t] + -0.014 travel_duration + 0.05 value_exit^2 + -0.102 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 82, 0, 0, 0, 0, 0, 82\n",
      "value_exit: 0, 82, 82, 0, 0, 82\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 282/1000 --- L(Train): 0.3909203 --- L(Val, RNN): 0.3345253 --- L(Val, SINDy): 0.3388458 --- Time: 2.74s; --- Convergence: 1.13e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 82/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.251 1 + 0.447 value_stay[t] + 0.156 reward + -0.004 harvest_duration + 0.122 value_stay^2 + 0.176 value_stay*reward + -0.408 value_stay*harvest_duration + 0.701 reward^2 + 0.16 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.995 value_exit[t] + -0.014 travel_duration + 0.05 value_exit^2 + -0.102 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 83, 0, 0, 0, 0, 0, 83\n",
      "value_exit: 0, 83, 83, 0, 0, 83\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 283/1000 --- L(Train): 0.3836643 --- L(Val, RNN): 0.3345347 --- L(Val, SINDy): 0.3386226 --- Time: 2.12s; --- Convergence: 6.11e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 83/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.253 1 + 0.448 value_stay[t] + 0.156 reward + -0.003 harvest_duration + 0.124 value_stay^2 + 0.178 value_stay*reward + -0.407 value_stay*harvest_duration + 0.702 reward^2 + 0.161 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.996 value_exit[t] + -0.015 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 84, 0, 0, 0, 0, 0, 84\n",
      "value_exit: 0, 84, 84, 1, 0, 84\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 284/1000 --- L(Train): 0.3834963 --- L(Val, RNN): 0.3343023 --- L(Val, SINDy): 0.3379078 --- Time: 2.45s; --- Convergence: 1.47e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 84/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.252 1 + 0.447 value_stay[t] + 0.155 reward + -0.003 harvest_duration + 0.124 value_stay^2 + 0.178 value_stay*reward + -0.408 value_stay*harvest_duration + 0.701 reward^2 + 0.159 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.997 value_exit[t] + -0.016 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 85, 0, 0, 0, 0, 0, 85\n",
      "value_exit: 0, 85, 85, 2, 0, 85\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 285/1000 --- L(Train): 0.3842850 --- L(Val, RNN): 0.3345172 --- L(Val, SINDy): 0.3382327 --- Time: 3.86s; --- Convergence: 1.81e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 85/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.252 1 + 0.447 value_stay[t] + 0.154 reward + -0.003 harvest_duration + 0.124 value_stay^2 + 0.179 value_stay*reward + -0.408 value_stay*harvest_duration + 0.7 reward^2 + 0.158 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.997 value_exit[t] + -0.016 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 86, 0, 0, 0, 0, 0, 86\n",
      "value_exit: 0, 86, 86, 3, 0, 86\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 286/1000 --- L(Train): 0.3910502 --- L(Val, RNN): 0.3346549 --- L(Val, SINDy): 0.3379798 --- Time: 3.08s; --- Convergence: 1.59e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 86/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.252 1 + 0.446 value_stay[t] + 0.153 reward + -0.003 harvest_duration + 0.123 value_stay^2 + 0.179 value_stay*reward + -0.408 value_stay*harvest_duration + 0.7 reward^2 + 0.157 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.997 value_exit[t] + -0.016 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 87, 0, 0, 0, 0, 0, 87\n",
      "value_exit: 0, 87, 87, 4, 0, 87\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 287/1000 --- L(Train): 0.3877548 --- L(Val, RNN): 0.3343971 --- L(Val, SINDy): 0.3379901 --- Time: 3.38s; --- Convergence: 2.09e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 87/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.252 1 + 0.445 value_stay[t] + 0.152 reward + -0.003 harvest_duration + 0.123 value_stay^2 + 0.179 value_stay*reward + -0.408 value_stay*harvest_duration + 0.699 reward^2 + 0.156 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.015 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 88, 0, 0, 0, 0, 0, 88\n",
      "value_exit: 0, 88, 88, 5, 0, 88\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 288/1000 --- L(Train): 0.3922175 --- L(Val, RNN): 0.3343978 --- L(Val, SINDy): 0.3375506 --- Time: 2.40s; --- Convergence: 1.05e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 88/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.254 1 + 0.446 value_stay[t] + 0.152 reward + -0.001 harvest_duration + 0.125 value_stay^2 + 0.181 value_stay*reward + -0.407 value_stay*harvest_duration + 0.7 reward^2 + 0.156 reward*harvest_duration + -0.003 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.996 value_exit[t] + -0.015 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 89, 0, 0, 0, 0, 0, 89\n",
      "value_exit: 0, 89, 89, 6, 0, 89\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 289/1000 --- L(Train): 0.3916637 --- L(Val, RNN): 0.3345414 --- L(Val, SINDy): 0.3386424 --- Time: 2.55s; --- Convergence: 1.24e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 89/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.255 1 + 0.448 value_stay[t] + 0.153 reward + 0.0 harvest_duration + 0.126 value_stay^2 + 0.183 value_stay*reward + -0.406 value_stay*harvest_duration + 0.702 reward^2 + 0.157 reward*harvest_duration + -0.002 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.996 value_exit[t] + -0.014 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 90, 0, 0, 0, 0, 0, 90\n",
      "value_exit: 0, 90, 90, 7, 0, 90\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 290/1000 --- L(Train): 0.3904198 --- L(Val, RNN): 0.3345659 --- L(Val, SINDy): 0.3376216 --- Time: 2.77s; --- Convergence: 7.43e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 90/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.256 1 + 0.448 value_stay[t] + 0.154 reward + 0.001 harvest_duration + 0.127 value_stay^2 + 0.185 value_stay*reward + -0.405 value_stay*harvest_duration + 0.703 reward^2 + 0.158 reward*harvest_duration + -0.001 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.996 value_exit[t] + -0.015 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 91, 0, 0, 0, 0, 0, 91\n",
      "value_exit: 0, 91, 91, 8, 0, 91\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 291/1000 --- L(Train): 0.3851419 --- L(Val, RNN): 0.3344281 --- L(Val, SINDy): 0.3374900 --- Time: 2.19s; --- Convergence: 1.06e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 91/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.257 1 + 0.448 value_stay[t] + 0.153 reward + 0.002 harvest_duration + 0.127 value_stay^2 + 0.186 value_stay*reward + -0.405 value_stay*harvest_duration + 0.703 reward^2 + 0.157 reward*harvest_duration + -0.0 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.015 travel_duration + 0.048 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 92, 0, 0, 0, 0, 0, 92\n",
      "value_exit: 0, 92, 92, 9, 0, 92\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 292/1000 --- L(Train): 0.3836258 --- L(Val, RNN): 0.3343716 --- L(Val, SINDy): 0.3382090 --- Time: 1.01s; --- Convergence: 8.13e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 92/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.256 1 + 0.446 value_stay[t] + 0.151 reward + 0.0 harvest_duration + 0.126 value_stay^2 + 0.185 value_stay*reward + -0.406 value_stay*harvest_duration + 0.702 reward^2 + 0.155 reward*harvest_duration + -0.002 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.015 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 93, 0, 0, 0, 0, 0, 93\n",
      "value_exit: 0, 93, 93, 10, 0, 93\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 293/1000 --- L(Train): 0.3974268 --- L(Val, RNN): 0.3342558 --- L(Val, SINDy): 0.3383515 --- Time: 1.19s; --- Convergence: 9.86e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 93/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.254 1 + 0.444 value_stay[t] + 0.149 reward + -0.001 harvest_duration + 0.124 value_stay^2 + 0.184 value_stay*reward + -0.408 value_stay*harvest_duration + 0.7 reward^2 + 0.153 reward*harvest_duration + -0.003 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.997 value_exit[t] + -0.015 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 94, 0, 0, 0, 0, 0, 94\n",
      "value_exit: 0, 94, 94, 11, 0, 94\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 294/1000 --- L(Train): 0.3940150 --- L(Val, RNN): 0.3342577 --- L(Val, SINDy): 0.3377537 --- Time: 1.11s; --- Convergence: 5.03e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 94/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.254 1 + 0.444 value_stay[t] + 0.148 reward + -0.001 harvest_duration + 0.124 value_stay^2 + 0.184 value_stay*reward + -0.409 value_stay*harvest_duration + 0.7 reward^2 + 0.152 reward*harvest_duration + -0.003 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.015 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 95, 0, 0, 0, 0, 0, 95\n",
      "value_exit: 0, 95, 95, 12, 0, 95\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 295/1000 --- L(Train): 0.3884927 --- L(Val, RNN): 0.3341983 --- L(Val, SINDy): 0.3385646 --- Time: 0.97s; --- Convergence: 5.48e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 95/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.256 1 + 0.445 value_stay[t] + 0.149 reward + 0.0 harvest_duration + 0.126 value_stay^2 + 0.187 value_stay*reward + -0.407 value_stay*harvest_duration + 0.702 reward^2 + 0.154 reward*harvest_duration + -0.002 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.015 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 96, 0, 0, 0, 0, 0, 96\n",
      "value_exit: 0, 96, 96, 13, 0, 96\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 296/1000 --- L(Train): 0.3879983 --- L(Val, RNN): 0.3341958 --- L(Val, SINDy): 0.3381571 --- Time: 1.27s; --- Convergence: 2.87e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 96/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.258 1 + 0.447 value_stay[t] + 0.151 reward + 0.002 harvest_duration + 0.128 value_stay^2 + 0.189 value_stay*reward + -0.406 value_stay*harvest_duration + 0.704 reward^2 + 0.155 reward*harvest_duration + -0.0 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.996 value_exit[t] + -0.015 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 97, 0, 0, 0, 0, 0, 97\n",
      "value_exit: 0, 97, 97, 14, 0, 97\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 297/1000 --- L(Train): 0.3982072 --- L(Val, RNN): 0.3343278 --- L(Val, SINDy): 0.3374274 --- Time: 0.99s; --- Convergence: 8.04e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 97/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.257 1 + 0.446 value_stay[t] + 0.15 reward + 0.0 harvest_duration + 0.127 value_stay^2 + 0.189 value_stay*reward + -0.407 value_stay*harvest_duration + 0.704 reward^2 + 0.154 reward*harvest_duration + -0.002 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.015 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 98, 0, 0, 0, 0, 0, 98\n",
      "value_exit: 0, 98, 98, 15, 0, 98\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 298/1000 --- L(Train): 0.4078288 --- L(Val, RNN): 0.3342167 --- L(Val, SINDy): 0.3377714 --- Time: 0.98s; --- Convergence: 9.57e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 98/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.256 1 + 0.444 value_stay[t] + 0.148 reward + -0.002 harvest_duration + 0.125 value_stay^2 + 0.189 value_stay*reward + -0.409 value_stay*harvest_duration + 0.702 reward^2 + 0.152 reward*harvest_duration + -0.004 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.015 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 99, 0, 0, 0, 0, 0, 99\n",
      "value_exit: 0, 99, 99, 16, 0, 99\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 299/1000 --- L(Train): 0.3983968 --- L(Val, RNN): 0.3341685 --- L(Val, SINDy): 0.3374518 --- Time: 1.10s; --- Convergence: 7.20e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 99/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 15):\n",
      "value_stay[t+1] = 0.256 1 + 0.444 value_stay[t] + 0.148 reward + 0.126 value_stay^2 + 0.19 value_stay*reward + -0.409 value_stay*harvest_duration + 0.703 reward^2 + 0.152 reward*harvest_duration + -0.004 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.997 value_exit[t] + -0.015 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, 100\n",
      "value_exit: 0, 100, 100, 17, 0, 100\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 300/1000 --- L(Train): 1.1520814 --- L(Val, RNN): 0.3352242 --- L(Val, SINDy): 0.3553483 --- Time: 0.83s; --- Convergence: 5.64e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 14):\n",
      "value_stay[t+1] = 0.257 1 + 0.445 value_stay[t] + 0.148 reward + 0.127 value_stay^2 + 0.192 value_stay*reward + -0.408 value_stay*harvest_duration + 0.704 reward^2 + 0.152 reward*harvest_duration + -0.003 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 1.0 value_exit[t] + -0.015 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, 101\n",
      "value_exit: 0, -, 101, 18, 0, 101\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 301/1000 --- L(Train): 2.3231125 --- L(Val, RNN): 0.3360482 --- L(Val, SINDy): 0.3984447 --- Time: 0.85s; --- Convergence: 6.94e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 1/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 13):\n",
      "value_stay[t+1] = 0.258 1 + 0.446 value_stay[t] + 0.149 reward + 0.129 value_stay^2 + 0.194 value_stay*reward + -0.407 value_stay*harvest_duration + 0.705 reward^2 + 0.153 reward*harvest_duration \n",
      "value_exit[t+1] = -0.082 1 + 1.0 value_exit[t] + -0.015 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, 102, 19, 0, 102\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 302/1000 --- L(Train): 2.6778023 --- L(Val, RNN): 0.3368646 --- L(Val, SINDy): 0.4243608 --- Time: 1.10s; --- Convergence: 7.55e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 2/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_stay[t+1] = 0.259 1 + 0.447 value_stay[t] + 0.15 reward + 0.13 value_stay^2 + 0.196 value_stay*reward + -0.406 value_stay*harvest_duration + 0.707 reward^2 + 0.154 reward*harvest_duration \n",
      "value_exit[t+1] = -0.081 1 + 1.0 value_exit[t] + -0.014 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, 103, 20, 0, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 303/1000 --- L(Train): 2.7547169 --- L(Val, RNN): 0.3375870 --- L(Val, SINDy): 0.4403746 --- Time: 0.98s; --- Convergence: 7.39e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 3/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 11):\n",
      "value_stay[t+1] = 0.26 1 + 0.447 value_stay[t] + 0.15 reward + 0.131 value_stay^2 + 0.198 value_stay*reward + -0.406 value_stay*harvest_duration + 0.708 reward^2 + 0.154 reward*harvest_duration \n",
      "value_exit[t+1] = -0.087 1 + 1.0 value_exit[t] + 0.044 value_exit^2 + -0.096 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 21, 0, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 304/1000 --- L(Train): 2.2402971 --- L(Val, RNN): 0.3383176 --- L(Val, SINDy): 0.4382166 --- Time: 0.91s; --- Convergence: 7.35e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 4/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 11):\n",
      "value_stay[t+1] = 0.261 1 + 0.448 value_stay[t] + 0.151 reward + 0.132 value_stay^2 + 0.2 value_stay*reward + -0.405 value_stay*harvest_duration + 0.709 reward^2 + 0.156 reward*harvest_duration \n",
      "value_exit[t+1] = -0.096 1 + 1.0 value_exit[t] + 0.035 value_exit^2 + -0.087 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 22, 0, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 305/1000 --- L(Train): 1.7055143 --- L(Val, RNN): 0.3392475 --- L(Val, SINDy): 0.4323960 --- Time: 1.02s; --- Convergence: 8.32e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 5/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 11):\n",
      "value_stay[t+1] = 0.262 1 + 0.449 value_stay[t] + 0.154 reward + 0.134 value_stay^2 + 0.204 value_stay*reward + -0.404 value_stay*harvest_duration + 0.712 reward^2 + 0.158 reward*harvest_duration \n",
      "value_exit[t+1] = -0.108 1 + 1.0 value_exit[t] + 0.024 value_exit^2 + -0.075 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 23, 0, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 306/1000 --- L(Train): 1.2679596 --- L(Val, RNN): 0.3406608 --- L(Val, SINDy): 0.4221447 --- Time: 0.96s; --- Convergence: 1.12e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 6/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.264 1 + 0.451 value_stay[t] + 0.156 reward + 0.137 value_stay^2 + 0.208 value_stay*reward + -0.402 value_stay*harvest_duration + 0.715 reward^2 + 0.16 reward*harvest_duration \n",
      "value_exit[t+1] = -0.122 1 + 1.0 value_exit[t] + 0.01 value_exit^2 + -0.061 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 24, 0, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 307/1000 --- L(Train): 0.9231516 --- L(Val, RNN): 0.3421144 --- L(Val, SINDy): 0.4473107 --- Time: 1.02s; --- Convergence: 1.29e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 7/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.262 1 + 0.45 value_stay[t] + 0.157 reward + 0.136 value_stay^2 + 0.211 value_stay*reward + -0.401 value_stay*harvest_duration + 0.716 reward^2 + 0.161 reward*harvest_duration \n",
      "value_exit[t+1] = -0.138 1 + 1.0 value_exit[t] + -0.004 value_exit^2 + -0.045 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 25, 1, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 308/1000 --- L(Train): 0.6688848 --- L(Val, RNN): 0.3434555 --- L(Val, SINDy): 0.5171546 --- Time: 0.99s; --- Convergence: 1.31e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 8/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.257 1 + 0.444 value_stay[t] + 0.154 reward + 0.132 value_stay^2 + 0.209 value_stay*reward + -0.405 value_stay*harvest_duration + 0.714 reward^2 + 0.158 reward*harvest_duration \n",
      "value_exit[t+1] = -0.155 1 + 1.0 value_exit[t] + -0.02 value_exit^2 + -0.028 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 26, 2, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 309/1000 --- L(Train): 0.5472672 --- L(Val, RNN): 0.3459631 --- L(Val, SINDy): 0.6779090 --- Time: 1.10s; --- Convergence: 1.91e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 9/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.254 1 + 0.443 value_stay[t] + 0.155 reward + 0.131 value_stay^2 + 0.212 value_stay*reward + -0.405 value_stay*harvest_duration + 0.715 reward^2 + 0.159 reward*harvest_duration \n",
      "value_exit[t+1] = -0.17 1 + 1.0 value_exit[t] + -0.034 value_exit^2 + -0.012 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 27, 3, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 310/1000 --- L(Train): 0.5296525 --- L(Val, RNN): 0.3457997 --- L(Val, SINDy): 0.8174689 --- Time: 0.92s; --- Convergence: 1.04e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 10/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.245 1 + 0.433 value_stay[t] + 0.146 reward + 0.122 value_stay^2 + 0.205 value_stay*reward + -0.414 value_stay*harvest_duration + 0.708 reward^2 + 0.151 reward*harvest_duration \n",
      "value_exit[t+1] = -0.176 1 + 1.0 value_exit[t] + -0.041 value_exit^2 + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 28, 4, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 311/1000 --- L(Train): 0.5662240 --- L(Val, RNN): 0.3496209 --- L(Val, SINDy): 0.9165456 --- Time: 0.87s; --- Convergence: 2.43e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 11/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.24 1 + 0.428 value_stay[t] + 0.142 reward + 0.118 value_stay^2 + 0.202 value_stay*reward + -0.418 value_stay*harvest_duration + 0.703 reward^2 + 0.147 reward*harvest_duration \n",
      "value_exit[t+1] = -0.18 1 + 1.0 value_exit[t] + -0.047 value_exit^2 + 0.009 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 29, 5, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 312/1000 --- L(Train): 0.6074606 --- L(Val, RNN): 0.3504353 --- L(Val, SINDy): 0.9122661 --- Time: 1.10s; --- Convergence: 1.62e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 12/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.242 1 + 0.43 value_stay[t] + 0.144 reward + 0.12 value_stay^2 + 0.206 value_stay*reward + -0.415 value_stay*harvest_duration + 0.705 reward^2 + 0.149 reward*harvest_duration \n",
      "value_exit[t+1] = -0.179 1 + 1.0 value_exit[t] + -0.047 value_exit^2 + 0.014 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 30, 6, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 313/1000 --- L(Train): 0.6215689 --- L(Val, RNN): 0.3504556 --- L(Val, SINDy): 0.8462824 --- Time: 0.88s; --- Convergence: 8.21e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 13/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.247 1 + 0.435 value_stay[t] + 0.149 reward + 0.125 value_stay^2 + 0.212 value_stay*reward + -0.409 value_stay*harvest_duration + 0.71 reward^2 + 0.154 reward*harvest_duration \n",
      "value_exit[t+1] = -0.171 1 + 1.0 value_exit[t] + -0.042 value_exit^2 + 0.012 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 31, 7, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 314/1000 --- L(Train): 0.6109530 --- L(Val, RNN): 0.3519282 --- L(Val, SINDy): 0.7780113 --- Time: 0.96s; --- Convergence: 1.15e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 14/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.256 1 + 0.444 value_stay[t] + 0.158 reward + 0.134 value_stay^2 + 0.221 value_stay*reward + -0.4 value_stay*harvest_duration + 0.718 reward^2 + 0.162 reward*harvest_duration \n",
      "value_exit[t+1] = -0.159 1 + 1.0 value_exit[t] + -0.034 value_exit^2 + 0.006 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 32, 8, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 315/1000 --- L(Train): 0.5885673 --- L(Val, RNN): 0.3552010 --- L(Val, SINDy): 0.7124249 --- Time: 0.84s; --- Convergence: 2.21e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 15/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.26 1 + 0.448 value_stay[t] + 0.162 reward + 0.137 value_stay^2 + 0.226 value_stay*reward + -0.395 value_stay*harvest_duration + 0.721 reward^2 + 0.166 reward*harvest_duration \n",
      "value_exit[t+1] = -0.147 1 + 1.0 value_exit[t] + -0.024 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 33, 9, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 316/1000 --- L(Train): 0.5366163 --- L(Val, RNN): 0.3575165 --- L(Val, SINDy): 0.6485744 --- Time: 0.94s; --- Convergence: 2.26e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 16/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.256 1 + 0.443 value_stay[t] + 0.156 reward + 0.132 value_stay^2 + 0.221 value_stay*reward + -0.4 value_stay*harvest_duration + 0.715 reward^2 + 0.16 reward*harvest_duration \n",
      "value_exit[t+1] = -0.133 1 + 1.0 value_exit[t] + -0.014 value_exit^2 + -0.01 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 34, 10, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 317/1000 --- L(Train): 0.5060468 --- L(Val, RNN): 0.3575545 --- L(Val, SINDy): 0.5771055 --- Time: 0.91s; --- Convergence: 1.15e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 17/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.249 1 + 0.435 value_stay[t] + 0.148 reward + 0.124 value_stay^2 + 0.213 value_stay*reward + -0.407 value_stay*harvest_duration + 0.706 reward^2 + 0.152 reward*harvest_duration \n",
      "value_exit[t+1] = -0.119 1 + 1.0 value_exit[t] + -0.003 value_exit^2 + -0.019 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 35, 11, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 318/1000 --- L(Train): 0.4826047 --- L(Val, RNN): 0.3586328 --- L(Val, SINDy): 0.5412547 --- Time: 0.91s; --- Convergence: 1.11e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 18/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.245 1 + 0.431 value_stay[t] + 0.143 reward + 0.12 value_stay^2 + 0.21 value_stay*reward + -0.411 value_stay*harvest_duration + 0.7 reward^2 + 0.147 reward*harvest_duration \n",
      "value_exit[t+1] = -0.106 1 + 1.0 value_exit[t] + 0.006 value_exit^2 + -0.027 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 36, 12, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 319/1000 --- L(Train): 0.4718719 --- L(Val, RNN): 0.3611810 --- L(Val, SINDy): 0.5337070 --- Time: 0.80s; --- Convergence: 1.83e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 19/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.245 1 + 0.432 value_stay[t] + 0.143 reward + 0.12 value_stay^2 + 0.21 value_stay*reward + -0.41 value_stay*harvest_duration + 0.699 reward^2 + 0.147 reward*harvest_duration \n",
      "value_exit[t+1] = -0.094 1 + 1.0 value_exit[t] + 0.015 value_exit^2 + -0.033 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 37, 13, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 320/1000 --- L(Train): 0.4638515 --- L(Val, RNN): 0.3635511 --- L(Val, SINDy): 0.5147980 --- Time: 0.81s; --- Convergence: 2.10e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 20/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.25 1 + 0.436 value_stay[t] + 0.146 reward + 0.125 value_stay^2 + 0.215 value_stay*reward + -0.405 value_stay*harvest_duration + 0.702 reward^2 + 0.15 reward*harvest_duration \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + 0.022 value_exit^2 + -0.037 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 38, 14, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 321/1000 --- L(Train): 0.4639621 --- L(Val, RNN): 0.3643679 --- L(Val, SINDy): 0.5056142 --- Time: 0.96s; --- Convergence: 1.46e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 21/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.253 1 + 0.44 value_stay[t] + 0.149 reward + 0.128 value_stay^2 + 0.219 value_stay*reward + -0.4 value_stay*harvest_duration + 0.704 reward^2 + 0.153 reward*harvest_duration \n",
      "value_exit[t+1] = -0.078 1 + 1.0 value_exit[t] + 0.028 value_exit^2 + -0.04 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 39, 15, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 322/1000 --- L(Train): 0.4566699 --- L(Val, RNN): 0.3649165 --- L(Val, SINDy): 0.5046097 --- Time: 1.17s; --- Convergence: 1.00e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 22/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.257 1 + 0.443 value_stay[t] + 0.152 reward + 0.132 value_stay^2 + 0.222 value_stay*reward + -0.396 value_stay*harvest_duration + 0.706 reward^2 + 0.156 reward*harvest_duration \n",
      "value_exit[t+1] = -0.072 1 + 1.0 value_exit[t] + 0.033 value_exit^2 + -0.042 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 40, 16, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 323/1000 --- L(Train): 0.4557136 --- L(Val, RNN): 0.3665542 --- L(Val, SINDy): 0.4979204 --- Time: 0.89s; --- Convergence: 1.32e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 23/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.261 1 + 0.447 value_stay[t] + 0.156 reward + 0.135 value_stay^2 + 0.226 value_stay*reward + -0.392 value_stay*harvest_duration + 0.709 reward^2 + 0.16 reward*harvest_duration \n",
      "value_exit[t+1] = -0.068 1 + 1.0 value_exit[t] + 0.037 value_exit^2 + -0.042 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 41, 17, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 324/1000 --- L(Train): 0.4534968 --- L(Val, RNN): 0.3689851 --- L(Val, SINDy): 0.4669539 --- Time: 1.13s; --- Convergence: 1.88e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 24/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.264 1 + 0.449 value_stay[t] + 0.158 reward + 0.136 value_stay^2 + 0.229 value_stay*reward + -0.389 value_stay*harvest_duration + 0.71 reward^2 + 0.162 reward*harvest_duration \n",
      "value_exit[t+1] = -0.066 1 + 1.0 value_exit[t] + 0.04 value_exit^2 + -0.041 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 42, 18, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 325/1000 --- L(Train): 0.4423286 --- L(Val, RNN): 0.3699670 --- L(Val, SINDy): 0.4570677 --- Time: 1.18s; --- Convergence: 1.43e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 25/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.263 1 + 0.448 value_stay[t] + 0.157 reward + 0.134 value_stay^2 + 0.228 value_stay*reward + -0.39 value_stay*harvest_duration + 0.708 reward^2 + 0.161 reward*harvest_duration \n",
      "value_exit[t+1] = -0.066 1 + 1.0 value_exit[t] + 0.041 value_exit^2 + -0.039 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 43, 19, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 326/1000 --- L(Train): 0.4407564 --- L(Val, RNN): 0.3698279 --- L(Val, SINDy): 0.4570597 --- Time: 1.29s; --- Convergence: 7.84e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 26/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.261 1 + 0.444 value_stay[t] + 0.154 reward + 0.13 value_stay^2 + 0.224 value_stay*reward + -0.392 value_stay*harvest_duration + 0.704 reward^2 + 0.158 reward*harvest_duration \n",
      "value_exit[t+1] = -0.067 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.035 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 44, 20, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 327/1000 --- L(Train): 0.4419249 --- L(Val, RNN): 0.3706358 --- L(Val, SINDy): 0.4636413 --- Time: 0.87s; --- Convergence: 7.96e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 27/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.258 1 + 0.44 value_stay[t] + 0.15 reward + 0.126 value_stay^2 + 0.22 value_stay*reward + -0.395 value_stay*harvest_duration + 0.7 reward^2 + 0.154 reward*harvest_duration \n",
      "value_exit[t+1] = -0.068 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.032 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 45, 21, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 328/1000 --- L(Train): 0.4299424 --- L(Val, RNN): 0.3725477 --- L(Val, SINDy): 0.4653551 --- Time: 0.90s; --- Convergence: 1.35e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 28/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.256 1 + 0.437 value_stay[t] + 0.148 reward + 0.122 value_stay^2 + 0.217 value_stay*reward + -0.398 value_stay*harvest_duration + 0.697 reward^2 + 0.152 reward*harvest_duration \n",
      "value_exit[t+1] = -0.071 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.028 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 46, 22, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 329/1000 --- L(Train): 0.4351868 --- L(Val, RNN): 0.3738073 --- L(Val, SINDy): 0.4677475 --- Time: 0.96s; --- Convergence: 1.31e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 29/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.256 1 + 0.436 value_stay[t] + 0.147 reward + 0.12 value_stay^2 + 0.216 value_stay*reward + -0.398 value_stay*harvest_duration + 0.695 reward^2 + 0.151 reward*harvest_duration \n",
      "value_exit[t+1] = -0.074 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.023 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 47, 23, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 330/1000 --- L(Train): 0.4309554 --- L(Val, RNN): 0.3739759 --- L(Val, SINDy): 0.4691229 --- Time: 1.00s; --- Convergence: 7.38e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 30/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.258 1 + 0.436 value_stay[t] + 0.148 reward + 0.119 value_stay^2 + 0.216 value_stay*reward + -0.397 value_stay*harvest_duration + 0.695 reward^2 + 0.152 reward*harvest_duration \n",
      "value_exit[t+1] = -0.077 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.018 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 48, 24, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 331/1000 --- L(Train): 0.4220161 --- L(Val, RNN): 0.3743378 --- L(Val, SINDy): 0.4666590 --- Time: 1.00s; --- Convergence: 5.50e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 31/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.261 1 + 0.438 value_stay[t] + 0.151 reward + 0.119 value_stay^2 + 0.218 value_stay*reward + -0.394 value_stay*harvest_duration + 0.697 reward^2 + 0.155 reward*harvest_duration \n",
      "value_exit[t+1] = -0.08 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.014 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 49, 25, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 332/1000 --- L(Train): 0.4227268 --- L(Val, RNN): 0.3750714 --- L(Val, SINDy): 0.4695570 --- Time: 0.98s; --- Convergence: 6.42e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 32/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.265 1 + 0.44 value_stay[t] + 0.154 reward + 0.121 value_stay^2 + 0.22 value_stay*reward + -0.391 value_stay*harvest_duration + 0.699 reward^2 + 0.158 reward*harvest_duration \n",
      "value_exit[t+1] = -0.082 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.01 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 50, 26, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 333/1000 --- L(Train): 0.4213771 --- L(Val, RNN): 0.3757006 --- L(Val, SINDy): 0.4769077 --- Time: 1.30s; --- Convergence: 6.35e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 33/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.27 1 + 0.444 value_stay[t] + 0.158 reward + 0.124 value_stay^2 + 0.224 value_stay*reward + -0.387 value_stay*harvest_duration + 0.703 reward^2 + 0.162 reward*harvest_duration \n",
      "value_exit[t+1] = -0.084 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.007 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 51, 27, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 334/1000 --- L(Train): 0.4166925 --- L(Val, RNN): 0.3759897 --- L(Val, SINDy): 0.4919677 --- Time: 0.96s; --- Convergence: 4.62e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 34/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.275 1 + 0.447 value_stay[t] + 0.162 reward + 0.125 value_stay^2 + 0.226 value_stay*reward + -0.383 value_stay*harvest_duration + 0.706 reward^2 + 0.166 reward*harvest_duration \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 52, 28, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 335/1000 --- L(Train): 0.4182623 --- L(Val, RNN): 0.3756913 --- L(Val, SINDy): 0.4963505 --- Time: 0.97s; --- Convergence: 3.80e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 35/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.279 1 + 0.45 value_stay[t] + 0.166 reward + 0.127 value_stay^2 + 0.229 value_stay*reward + -0.38 value_stay*harvest_duration + 0.709 reward^2 + 0.17 reward*harvest_duration \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 53, 29, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 336/1000 --- L(Train): 0.4148588 --- L(Val, RNN): 0.3756020 --- L(Val, SINDy): 0.4960997 --- Time: 1.08s; --- Convergence: 2.35e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 36/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.282 1 + 0.451 value_stay[t] + 0.167 reward + 0.127 value_stay^2 + 0.229 value_stay*reward + -0.378 value_stay*harvest_duration + 0.709 reward^2 + 0.171 reward*harvest_duration \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 54, 30, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 337/1000 --- L(Train): 0.4138311 --- L(Val, RNN): 0.3757301 --- L(Val, SINDy): 0.4933369 --- Time: 0.96s; --- Convergence: 1.81e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 37/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.282 1 + 0.45 value_stay[t] + 0.167 reward + 0.125 value_stay^2 + 0.228 value_stay*reward + -0.378 value_stay*harvest_duration + 0.709 reward^2 + 0.171 reward*harvest_duration \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + 0.044 value_exit^2 + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 55, 31, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 338/1000 --- L(Train): 0.4087628 --- L(Val, RNN): 0.3757549 --- L(Val, SINDy): 0.4896396 --- Time: 0.92s; --- Convergence: 1.03e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 38/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.283 1 + 0.448 value_stay[t] + 0.167 reward + 0.122 value_stay^2 + 0.226 value_stay*reward + -0.379 value_stay*harvest_duration + 0.707 reward^2 + 0.171 reward*harvest_duration \n",
      "value_exit[t+1] = -0.083 1 + 1.0 value_exit[t] + 0.045 value_exit^2 + 0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 56, 32, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 339/1000 --- L(Train): 0.4105177 --- L(Val, RNN): 0.3754927 --- L(Val, SINDy): 0.4892283 --- Time: 1.11s; --- Convergence: 1.83e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 39/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.283 1 + 0.447 value_stay[t] + 0.167 reward + 0.12 value_stay^2 + 0.225 value_stay*reward + -0.38 value_stay*harvest_duration + 0.707 reward^2 + 0.171 reward*harvest_duration \n",
      "value_exit[t+1] = -0.082 1 + 1.0 value_exit[t] + 0.046 value_exit^2 + 0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 57, 33, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 340/1000 --- L(Train): 0.4113697 --- L(Val, RNN): 0.3750161 --- L(Val, SINDy): 0.4873317 --- Time: 2.24s; --- Convergence: 3.30e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 40/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.284 1 + 0.446 value_stay[t] + 0.168 reward + 0.118 value_stay^2 + 0.225 value_stay*reward + -0.38 value_stay*harvest_duration + 0.707 reward^2 + 0.172 reward*harvest_duration \n",
      "value_exit[t+1] = -0.078 1 + 1.0 value_exit[t] + 0.047 value_exit^2 + 0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 58, 34, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 341/1000 --- L(Train): 0.4055852 --- L(Val, RNN): 0.3744906 --- L(Val, SINDy): 0.4837913 --- Time: 4.67s; --- Convergence: 4.28e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 41/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.285 1 + 0.445 value_stay[t] + 0.168 reward + 0.115 value_stay^2 + 0.224 value_stay*reward + -0.381 value_stay*harvest_duration + 0.708 reward^2 + 0.173 reward*harvest_duration \n",
      "value_exit[t+1] = -0.075 1 + 1.0 value_exit[t] + 0.048 value_exit^2 + 0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 59, 35, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 342/1000 --- L(Train): 0.4025204 --- L(Val, RNN): 0.3738575 --- L(Val, SINDy): 0.4817400 --- Time: 4.44s; --- Convergence: 5.30e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 42/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.285 1 + 0.443 value_stay[t] + 0.168 reward + 0.112 value_stay^2 + 0.222 value_stay*reward + -0.382 value_stay*harvest_duration + 0.707 reward^2 + 0.173 reward*harvest_duration \n",
      "value_exit[t+1] = -0.071 1 + 1.0 value_exit[t] + 0.05 value_exit^2 + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 60, 36, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 343/1000 --- L(Train): 0.4058847 --- L(Val, RNN): 0.3733142 --- L(Val, SINDy): 0.4795115 --- Time: 3.44s; --- Convergence: 5.37e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 43/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.285 1 + 0.441 value_stay[t] + 0.169 reward + 0.108 value_stay^2 + 0.221 value_stay*reward + -0.384 value_stay*harvest_duration + 0.706 reward^2 + 0.173 reward*harvest_duration \n",
      "value_exit[t+1] = -0.066 1 + 1.0 value_exit[t] + 0.051 value_exit^2 + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 0, 37, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 344/1000 --- L(Train): 0.4047338 --- L(Val, RNN): 0.3728246 --- L(Val, SINDy): 0.4785167 --- Time: 3.67s; --- Convergence: 5.13e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 44/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.286 1 + 0.44 value_stay[t] + 0.17 reward + 0.106 value_stay^2 + 0.221 value_stay*reward + -0.384 value_stay*harvest_duration + 0.707 reward^2 + 0.174 reward*harvest_duration \n",
      "value_exit[t+1] = -0.061 1 + 1.0 value_exit[t] + 0.053 value_exit^2 + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 0, 38, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 345/1000 --- L(Train): 0.4064340 --- L(Val, RNN): 0.3721532 --- L(Val, SINDy): 0.4783028 --- Time: 5.11s; --- Convergence: 5.92e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 45/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.287 1 + 0.439 value_stay[t] + 0.171 reward + 0.104 value_stay^2 + 0.222 value_stay*reward + -0.384 value_stay*harvest_duration + 0.708 reward^2 + 0.176 reward*harvest_duration \n",
      "value_exit[t+1] = -0.056 1 + 1.0 value_exit[t] + 0.055 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 0, 39, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 346/1000 --- L(Train): 0.3986992 --- L(Val, RNN): 0.3713073 --- L(Val, SINDy): 0.4767755 --- Time: 2.63s; --- Convergence: 7.19e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 46/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.289 1 + 0.439 value_stay[t] + 0.173 reward + 0.103 value_stay^2 + 0.222 value_stay*reward + -0.383 value_stay*harvest_duration + 0.709 reward^2 + 0.178 reward*harvest_duration \n",
      "value_exit[t+1] = -0.051 1 + 1.0 value_exit[t] + 0.056 value_exit^2 + -0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 0, 40, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 347/1000 --- L(Train): 0.3984274 --- L(Val, RNN): 0.3705930 --- L(Val, SINDy): 0.4751840 --- Time: 1.80s; --- Convergence: 7.17e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 47/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.292 1 + 0.44 value_stay[t] + 0.175 reward + 0.102 value_stay^2 + 0.224 value_stay*reward + -0.382 value_stay*harvest_duration + 0.71 reward^2 + 0.18 reward*harvest_duration \n",
      "value_exit[t+1] = -0.046 1 + 1.0 value_exit[t] + 0.058 value_exit^2 + -0.005 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 1, -, -, 0, 41, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 348/1000 --- L(Train): 0.3987691 --- L(Val, RNN): 0.3698566 --- L(Val, SINDy): 0.4734010 --- Time: 2.40s; --- Convergence: 7.27e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 48/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.293 1 + 0.44 value_stay[t] + 0.177 reward + 0.1 value_stay^2 + 0.224 value_stay*reward + -0.382 value_stay*harvest_duration + 0.711 reward^2 + 0.181 reward*harvest_duration \n",
      "value_exit[t+1] = -0.042 1 + 1.0 value_exit[t] + 0.06 value_exit^2 + -0.007 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 2, -, -, 0, 42, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 349/1000 --- L(Train): 0.3988968 --- L(Val, RNN): 0.3693002 --- L(Val, SINDy): 0.4722442 --- Time: 3.77s; --- Convergence: 6.41e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 49/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.295 1 + 0.44 value_stay[t] + 0.178 reward + 0.099 value_stay^2 + 0.225 value_stay*reward + -0.381 value_stay*harvest_duration + 0.712 reward^2 + 0.183 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.061 value_exit^2 + -0.008 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 3, -, -, 0, 43, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 350/1000 --- L(Train): 0.3948970 --- L(Val, RNN): 0.3690347 --- L(Val, SINDy): 0.4713446 --- Time: 2.87s; --- Convergence: 4.54e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 50/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.297 1 + 0.44 value_stay[t] + 0.18 reward + 0.098 value_stay^2 + 0.225 value_stay*reward + -0.381 value_stay*harvest_duration + 0.712 reward^2 + 0.184 reward*harvest_duration \n",
      "value_exit[t+1] = -0.034 1 + 1.0 value_exit[t] + 0.062 value_exit^2 + -0.009 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 4, -, -, 0, 44, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 351/1000 --- L(Train): 0.3972763 --- L(Val, RNN): 0.3685449 --- L(Val, SINDy): 0.4713044 --- Time: 1.62s; --- Convergence: 4.72e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 51/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.297 1 + 0.439 value_stay[t] + 0.18 reward + 0.095 value_stay^2 + 0.224 value_stay*reward + -0.382 value_stay*harvest_duration + 0.712 reward^2 + 0.184 reward*harvest_duration \n",
      "value_exit[t+1] = -0.031 1 + 1.0 value_exit[t] + 0.063 value_exit^2 + -0.01 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 5, -, -, 0, 45, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 352/1000 --- L(Train): 0.3957275 --- L(Val, RNN): 0.3677547 --- L(Val, SINDy): 0.4699499 --- Time: 2.61s; --- Convergence: 6.31e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 52/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.297 1 + 0.437 value_stay[t] + 0.179 reward + 0.092 value_stay^2 + 0.223 value_stay*reward + -0.383 value_stay*harvest_duration + 0.711 reward^2 + 0.183 reward*harvest_duration \n",
      "value_exit[t+1] = -0.028 1 + 1.0 value_exit[t] + 0.064 value_exit^2 + -0.011 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 6, -, -, 0, 46, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 353/1000 --- L(Train): 0.3956258 --- L(Val, RNN): 0.3669232 --- L(Val, SINDy): 0.4677081 --- Time: 2.21s; --- Convergence: 7.31e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 53/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.299 1 + 0.437 value_stay[t] + 0.18 reward + 0.09 value_stay^2 + 0.222 value_stay*reward + -0.383 value_stay*harvest_duration + 0.71 reward^2 + 0.184 reward*harvest_duration \n",
      "value_exit[t+1] = -0.027 1 + 1.0 value_exit[t] + 0.065 value_exit^2 + -0.011 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 7, -, -, 0, 47, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 354/1000 --- L(Train): 0.3940746 --- L(Val, RNN): 0.3665599 --- L(Val, SINDy): 0.4646212 --- Time: 2.25s; --- Convergence: 5.47e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 54/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.302 1 + 0.439 value_stay[t] + 0.181 reward + 0.091 value_stay^2 + 0.224 value_stay*reward + -0.381 value_stay*harvest_duration + 0.711 reward^2 + 0.186 reward*harvest_duration \n",
      "value_exit[t+1] = -0.025 1 + 1.0 value_exit[t] + 0.066 value_exit^2 + -0.011 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 8, -, -, 0, 48, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 355/1000 --- L(Train): 0.3960564 --- L(Val, RNN): 0.3660711 --- L(Val, SINDy): 0.4619758 --- Time: 2.08s; --- Convergence: 5.18e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 55/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.305 1 + 0.441 value_stay[t] + 0.183 reward + 0.091 value_stay^2 + 0.225 value_stay*reward + -0.379 value_stay*harvest_duration + 0.712 reward^2 + 0.188 reward*harvest_duration \n",
      "value_exit[t+1] = -0.025 1 + 1.0 value_exit[t] + 0.066 value_exit^2 + -0.011 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 9, -, -, 0, 49, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 356/1000 --- L(Train): 0.3917784 --- L(Val, RNN): 0.3654449 --- L(Val, SINDy): 0.4591423 --- Time: 1.07s; --- Convergence: 5.72e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 56/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.308 1 + 0.442 value_stay[t] + 0.184 reward + 0.09 value_stay^2 + 0.225 value_stay*reward + -0.378 value_stay*harvest_duration + 0.712 reward^2 + 0.188 reward*harvest_duration \n",
      "value_exit[t+1] = -0.025 1 + 1.0 value_exit[t] + 0.066 value_exit^2 + -0.01 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 10, -, -, 0, 50, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 357/1000 --- L(Train): 0.3914028 --- L(Val, RNN): 0.3644816 --- L(Val, SINDy): 0.4567034 --- Time: 0.91s; --- Convergence: 7.68e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 57/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.31 1 + 0.441 value_stay[t] + 0.184 reward + 0.088 value_stay^2 + 0.224 value_stay*reward + -0.379 value_stay*harvest_duration + 0.71 reward^2 + 0.188 reward*harvest_duration \n",
      "value_exit[t+1] = -0.026 1 + 1.0 value_exit[t] + 0.066 value_exit^2 + -0.009 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 11, -, -, 0, 51, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 358/1000 --- L(Train): 0.3884457 --- L(Val, RNN): 0.3638746 --- L(Val, SINDy): 0.4540978 --- Time: 0.91s; --- Convergence: 6.87e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 58/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.312 1 + 0.441 value_stay[t] + 0.183 reward + 0.086 value_stay^2 + 0.223 value_stay*reward + -0.378 value_stay*harvest_duration + 0.709 reward^2 + 0.188 reward*harvest_duration \n",
      "value_exit[t+1] = -0.027 1 + 1.0 value_exit[t] + 0.066 value_exit^2 + -0.008 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 12, -, -, 0, 52, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 359/1000 --- L(Train): 0.3890775 --- L(Val, RNN): 0.3636337 --- L(Val, SINDy): 0.4525570 --- Time: 0.86s; --- Convergence: 4.64e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 59/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.313 1 + 0.441 value_stay[t] + 0.183 reward + 0.084 value_stay^2 + 0.222 value_stay*reward + -0.379 value_stay*harvest_duration + 0.708 reward^2 + 0.188 reward*harvest_duration \n",
      "value_exit[t+1] = -0.028 1 + 1.0 value_exit[t] + 0.065 value_exit^2 + -0.006 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 13, -, -, 0, 53, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 360/1000 --- L(Train): 0.3886282 --- L(Val, RNN): 0.3628688 --- L(Val, SINDy): 0.4511923 --- Time: 0.99s; --- Convergence: 6.15e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 60/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.315 1 + 0.442 value_stay[t] + 0.184 reward + 0.083 value_stay^2 + 0.222 value_stay*reward + -0.378 value_stay*harvest_duration + 0.707 reward^2 + 0.188 reward*harvest_duration \n",
      "value_exit[t+1] = -0.029 1 + 1.0 value_exit[t] + 0.065 value_exit^2 + -0.005 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 14, -, -, 0, 54, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 361/1000 --- L(Train): 0.3918735 --- L(Val, RNN): 0.3619251 --- L(Val, SINDy): 0.4510588 --- Time: 1.01s; --- Convergence: 7.79e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 61/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.318 1 + 0.442 value_stay[t] + 0.184 reward + 0.082 value_stay^2 + 0.222 value_stay*reward + -0.378 value_stay*harvest_duration + 0.707 reward^2 + 0.189 reward*harvest_duration \n",
      "value_exit[t+1] = -0.03 1 + 1.0 value_exit[t] + 0.065 value_exit^2 + -0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 15, -, -, 0, 55, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 362/1000 --- L(Train): 0.3881640 --- L(Val, RNN): 0.3614249 --- L(Val, SINDy): 0.4519139 --- Time: 1.18s; --- Convergence: 6.40e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 62/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.321 1 + 0.444 value_stay[t] + 0.186 reward + 0.083 value_stay^2 + 0.224 value_stay*reward + -0.375 value_stay*harvest_duration + 0.708 reward^2 + 0.19 reward*harvest_duration \n",
      "value_exit[t+1] = -0.031 1 + 1.0 value_exit[t] + 0.065 value_exit^2 + -0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 16, -, -, 0, 56, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 363/1000 --- L(Train): 0.3891884 --- L(Val, RNN): 0.3612573 --- L(Val, SINDy): 0.4510693 --- Time: 0.88s; --- Convergence: 4.04e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 63/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.325 1 + 0.446 value_stay[t] + 0.188 reward + 0.083 value_stay^2 + 0.225 value_stay*reward + -0.373 value_stay*harvest_duration + 0.709 reward^2 + 0.192 reward*harvest_duration \n",
      "value_exit[t+1] = -0.032 1 + 1.0 value_exit[t] + 0.064 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 17, -, -, 0, 57, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 364/1000 --- L(Train): 0.3833376 --- L(Val, RNN): 0.3607487 --- L(Val, SINDy): 0.4489166 --- Time: 1.02s; --- Convergence: 4.56e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 64/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.327 1 + 0.448 value_stay[t] + 0.189 reward + 0.083 value_stay^2 + 0.226 value_stay*reward + -0.372 value_stay*harvest_duration + 0.709 reward^2 + 0.193 reward*harvest_duration \n",
      "value_exit[t+1] = -0.033 1 + 1.0 value_exit[t] + 0.064 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 18, -, -, 0, 58, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 365/1000 --- L(Train): 0.3844191 --- L(Val, RNN): 0.3599393 --- L(Val, SINDy): 0.4468477 --- Time: 0.96s; --- Convergence: 6.33e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 65/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.329 1 + 0.448 value_stay[t] + 0.189 reward + 0.081 value_stay^2 + 0.226 value_stay*reward + -0.371 value_stay*harvest_duration + 0.708 reward^2 + 0.193 reward*harvest_duration \n",
      "value_exit[t+1] = -0.034 1 + 1.0 value_exit[t] + 0.064 value_exit^2 + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 19, -, -, 0, 59, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 366/1000 --- L(Train): 0.3863412 --- L(Val, RNN): 0.3594700 --- L(Val, SINDy): 0.4461243 --- Time: 1.04s; --- Convergence: 5.51e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 66/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.33 1 + 0.447 value_stay[t] + 0.188 reward + 0.079 value_stay^2 + 0.224 value_stay*reward + -0.372 value_stay*harvest_duration + 0.707 reward^2 + 0.193 reward*harvest_duration \n",
      "value_exit[t+1] = -0.035 1 + 1.0 value_exit[t] + 0.064 value_exit^2 + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 20, -, -, 0, 60, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 367/1000 --- L(Train): 0.3815255 --- L(Val, RNN): 0.3592374 --- L(Val, SINDy): 0.4449315 --- Time: 0.87s; --- Convergence: 3.92e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 67/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.332 1 + 0.447 value_stay[t] + 0.188 reward + 0.077 value_stay^2 + 0.223 value_stay*reward + -0.371 value_stay*harvest_duration + 0.705 reward^2 + 0.193 reward*harvest_duration \n",
      "value_exit[t+1] = -0.035 1 + 1.0 value_exit[t] + 0.064 value_exit^2 + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 21, -, -, 0, 61, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 368/1000 --- L(Train): 0.3855280 --- L(Val, RNN): 0.3589957 --- L(Val, SINDy): 0.4448040 --- Time: 0.84s; --- Convergence: 3.17e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 68/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.334 1 + 0.447 value_stay[t] + 0.189 reward + 0.076 value_stay^2 + 0.223 value_stay*reward + -0.37 value_stay*harvest_duration + 0.705 reward^2 + 0.193 reward*harvest_duration \n",
      "value_exit[t+1] = -0.035 1 + 1.0 value_exit[t] + 0.064 value_exit^2 + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 22, -, -, 0, 62, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 369/1000 --- L(Train): 0.3839014 --- L(Val, RNN): 0.3582517 --- L(Val, SINDy): 0.4438934 --- Time: 1.11s; --- Convergence: 5.30e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 69/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.336 1 + 0.448 value_stay[t] + 0.189 reward + 0.075 value_stay^2 + 0.223 value_stay*reward + -0.37 value_stay*harvest_duration + 0.704 reward^2 + 0.193 reward*harvest_duration \n",
      "value_exit[t+1] = -0.035 1 + 1.0 value_exit[t] + 0.065 value_exit^2 + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 23, -, -, 0, 63, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 370/1000 --- L(Train): 0.3810094 --- L(Val, RNN): 0.3576827 --- L(Val, SINDy): 0.4435016 --- Time: 1.34s; --- Convergence: 5.50e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 70/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.338 1 + 0.448 value_stay[t] + 0.189 reward + 0.074 value_stay^2 + 0.223 value_stay*reward + -0.368 value_stay*harvest_duration + 0.704 reward^2 + 0.194 reward*harvest_duration \n",
      "value_exit[t+1] = -0.035 1 + 1.0 value_exit[t] + 0.065 value_exit^2 + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 24, -, -, 0, 64, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 371/1000 --- L(Train): 0.3850397 --- L(Val, RNN): 0.3574932 --- L(Val, SINDy): 0.4433270 --- Time: 1.47s; --- Convergence: 3.70e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 71/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.34 1 + 0.449 value_stay[t] + 0.19 reward + 0.073 value_stay^2 + 0.224 value_stay*reward + -0.367 value_stay*harvest_duration + 0.704 reward^2 + 0.195 reward*harvest_duration \n",
      "value_exit[t+1] = -0.035 1 + 1.0 value_exit[t] + 0.065 value_exit^2 + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 25, -, -, 0, 65, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 372/1000 --- L(Train): 0.3804282 --- L(Val, RNN): 0.3571743 --- L(Val, SINDy): 0.4429793 --- Time: 0.89s; --- Convergence: 3.44e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 72/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.343 1 + 0.451 value_stay[t] + 0.192 reward + 0.074 value_stay^2 + 0.225 value_stay*reward + -0.365 value_stay*harvest_duration + 0.705 reward^2 + 0.196 reward*harvest_duration \n",
      "value_exit[t+1] = -0.035 1 + 1.0 value_exit[t] + 0.066 value_exit^2 + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 26, -, -, 0, 66, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 373/1000 --- L(Train): 0.3835864 --- L(Val, RNN): 0.3565357 --- L(Val, SINDy): 0.4418430 --- Time: 1.25s; --- Convergence: 4.91e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 73/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.345 1 + 0.452 value_stay[t] + 0.193 reward + 0.073 value_stay^2 + 0.226 value_stay*reward + -0.364 value_stay*harvest_duration + 0.705 reward^2 + 0.197 reward*harvest_duration \n",
      "value_exit[t+1] = -0.034 1 + 1.0 value_exit[t] + 0.066 value_exit^2 + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 27, -, -, 0, 67, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 374/1000 --- L(Train): 0.3826292 --- L(Val, RNN): 0.3560379 --- L(Val, SINDy): 0.4409771 --- Time: 0.93s; --- Convergence: 4.95e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 74/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.346 1 + 0.451 value_stay[t] + 0.193 reward + 0.071 value_stay^2 + 0.225 value_stay*reward + -0.364 value_stay*harvest_duration + 0.704 reward^2 + 0.197 reward*harvest_duration \n",
      "value_exit[t+1] = -0.034 1 + 1.0 value_exit[t] + 0.067 value_exit^2 + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 28, -, -, 0, 68, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 375/1000 --- L(Train): 0.3822999 --- L(Val, RNN): 0.3558404 --- L(Val, SINDy): 0.4399580 --- Time: 0.87s; --- Convergence: 3.46e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 75/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.346 1 + 0.448 value_stay[t] + 0.192 reward + 0.066 value_stay^2 + 0.223 value_stay*reward + -0.366 value_stay*harvest_duration + 0.702 reward^2 + 0.196 reward*harvest_duration \n",
      "value_exit[t+1] = -0.033 1 + 1.0 value_exit[t] + 0.067 value_exit^2 + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 29, -, -, 0, 69, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 376/1000 --- L(Train): 0.3795273 --- L(Val, RNN): 0.3555544 --- L(Val, SINDy): 0.4386193 --- Time: 0.92s; --- Convergence: 3.16e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 76/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.345 1 + 0.446 value_stay[t] + 0.191 reward + 0.061 value_stay^2 + 0.222 value_stay*reward + -0.367 value_stay*harvest_duration + 0.7 reward^2 + 0.195 reward*harvest_duration \n",
      "value_exit[t+1] = -0.032 1 + 1.0 value_exit[t] + 0.068 value_exit^2 + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 30, -, -, 0, 70, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 377/1000 --- L(Train): 0.3778847 --- L(Val, RNN): 0.3550833 --- L(Val, SINDy): 0.4380585 --- Time: 0.98s; --- Convergence: 3.94e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 77/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.346 1 + 0.445 value_stay[t] + 0.191 reward + 0.059 value_stay^2 + 0.222 value_stay*reward + -0.368 value_stay*harvest_duration + 0.7 reward^2 + 0.195 reward*harvest_duration \n",
      "value_exit[t+1] = -0.031 1 + 1.0 value_exit[t] + 0.068 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 31, -, -, 0, 71, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 378/1000 --- L(Train): 0.3823486 --- L(Val, RNN): 0.3546937 --- L(Val, SINDy): 0.4376440 --- Time: 0.97s; --- Convergence: 3.92e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 78/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.348 1 + 0.446 value_stay[t] + 0.193 reward + 0.059 value_stay^2 + 0.223 value_stay*reward + -0.366 value_stay*harvest_duration + 0.7 reward^2 + 0.197 reward*harvest_duration \n",
      "value_exit[t+1] = -0.031 1 + 1.0 value_exit[t] + 0.069 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 32, -, -, 0, 72, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 379/1000 --- L(Train): 0.3809029 --- L(Val, RNN): 0.3544349 --- L(Val, SINDy): 0.4372691 --- Time: 1.12s; --- Convergence: 3.25e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 79/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.352 1 + 0.448 value_stay[t] + 0.195 reward + 0.06 value_stay^2 + 0.226 value_stay*reward + -0.363 value_stay*harvest_duration + 0.702 reward^2 + 0.199 reward*harvest_duration \n",
      "value_exit[t+1] = -0.03 1 + 1.0 value_exit[t] + 0.069 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 33, -, -, 0, 73, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 380/1000 --- L(Train): 0.3829245 --- L(Val, RNN): 0.3541735 --- L(Val, SINDy): 0.4363851 --- Time: 1.15s; --- Convergence: 2.93e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 80/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.354 1 + 0.45 value_stay[t] + 0.197 reward + 0.06 value_stay^2 + 0.228 value_stay*reward + -0.361 value_stay*harvest_duration + 0.703 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.03 1 + 1.0 value_exit[t] + 0.07 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 34, -, -, 0, 74, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 381/1000 --- L(Train): 0.3823634 --- L(Val, RNN): 0.3538725 --- L(Val, SINDy): 0.4355955 --- Time: 1.15s; --- Convergence: 2.97e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 81/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.356 1 + 0.45 value_stay[t] + 0.197 reward + 0.059 value_stay^2 + 0.227 value_stay*reward + -0.361 value_stay*harvest_duration + 0.702 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.03 1 + 1.0 value_exit[t] + 0.07 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 35, -, -, 0, 75, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 382/1000 --- L(Train): 0.3882413 --- L(Val, RNN): 0.3535313 --- L(Val, SINDy): 0.4349793 --- Time: 1.04s; --- Convergence: 3.19e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 82/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.357 1 + 0.45 value_stay[t] + 0.197 reward + 0.057 value_stay^2 + 0.227 value_stay*reward + -0.36 value_stay*harvest_duration + 0.701 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.03 1 + 1.0 value_exit[t] + 0.07 value_exit^2 + -0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 36, -, -, 0, 76, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 383/1000 --- L(Train): 0.3758229 --- L(Val, RNN): 0.3532594 --- L(Val, SINDy): 0.4342207 --- Time: 0.82s; --- Convergence: 2.96e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 83/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.359 1 + 0.45 value_stay[t] + 0.197 reward + 0.056 value_stay^2 + 0.227 value_stay*reward + -0.36 value_stay*harvest_duration + 0.7 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.03 1 + 1.0 value_exit[t] + 0.07 value_exit^2 + -0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 37, -, -, 0, 77, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 384/1000 --- L(Train): 0.3778823 --- L(Val, RNN): 0.3530051 --- L(Val, SINDy): 0.4334933 --- Time: 1.02s; --- Convergence: 2.75e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 84/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.36 1 + 0.45 value_stay[t] + 0.196 reward + 0.055 value_stay^2 + 0.226 value_stay*reward + -0.359 value_stay*harvest_duration + 0.699 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.03 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 38, -, -, 0, 78, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 385/1000 --- L(Train): 0.3807187 --- L(Val, RNN): 0.3527064 --- L(Val, SINDy): 0.4328265 --- Time: 1.24s; --- Convergence: 2.87e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 85/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.361 1 + 0.449 value_stay[t] + 0.195 reward + 0.052 value_stay^2 + 0.225 value_stay*reward + -0.36 value_stay*harvest_duration + 0.697 reward^2 + 0.2 reward*harvest_duration \n",
      "value_exit[t+1] = -0.03 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 39, -, -, 0, 79, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 386/1000 --- L(Train): 0.3775881 --- L(Val, RNN): 0.3525140 --- L(Val, SINDy): 0.4320050 --- Time: 1.20s; --- Convergence: 2.40e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 86/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.361 1 + 0.448 value_stay[t] + 0.194 reward + 0.05 value_stay^2 + 0.223 value_stay*reward + -0.36 value_stay*harvest_duration + 0.694 reward^2 + 0.198 reward*harvest_duration \n",
      "value_exit[t+1] = -0.031 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 1, 0, 0, 0, 0, -\n",
      "value_exit: 40, -, -, 0, 80, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 387/1000 --- L(Train): 0.3784277 --- L(Val, RNN): 0.3523140 --- L(Val, SINDy): 0.4312381 --- Time: 0.90s; --- Convergence: 2.20e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 87/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.363 1 + 0.449 value_stay[t] + 0.194 reward + 0.049 value_stay^2 + 0.222 value_stay*reward + -0.359 value_stay*harvest_duration + 0.693 reward^2 + 0.198 reward*harvest_duration \n",
      "value_exit[t+1] = -0.032 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 2, 0, 0, 0, 0, -\n",
      "value_exit: 41, -, -, 0, 81, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 388/1000 --- L(Train): 0.3793118 --- L(Val, RNN): 0.3519314 --- L(Val, SINDy): 0.4306388 --- Time: 1.03s; --- Convergence: 3.01e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 88/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.368 1 + 0.453 value_stay[t] + 0.196 reward + 0.052 value_stay^2 + 0.225 value_stay*reward + -0.356 value_stay*harvest_duration + 0.694 reward^2 + 0.2 reward*harvest_duration \n",
      "value_exit[t+1] = -0.032 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 42, -, -, 0, 82, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 389/1000 --- L(Train): 0.3796552 --- L(Val, RNN): 0.3517359 --- L(Val, SINDy): 0.4299800 --- Time: 0.88s; --- Convergence: 2.48e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 89/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.372 1 + 0.457 value_stay[t] + 0.198 reward + 0.055 value_stay^2 + 0.227 value_stay*reward + -0.351 value_stay*harvest_duration + 0.695 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.033 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 43, -, -, 0, 83, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 390/1000 --- L(Train): 0.3796007 --- L(Val, RNN): 0.3516094 --- L(Val, SINDy): 0.4292380 --- Time: 1.06s; --- Convergence: 1.87e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 90/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.376 1 + 0.459 value_stay[t] + 0.199 reward + 0.056 value_stay^2 + 0.228 value_stay*reward + -0.349 value_stay*harvest_duration + 0.695 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.034 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 44, -, -, 0, 84, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 391/1000 --- L(Train): 0.3745319 --- L(Val, RNN): 0.3512953 --- L(Val, SINDy): 0.4286235 --- Time: 0.83s; --- Convergence: 2.51e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 91/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.376 1 + 0.459 value_stay[t] + 0.197 reward + 0.054 value_stay^2 + 0.226 value_stay*reward + -0.349 value_stay*harvest_duration + 0.693 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.035 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 45, -, -, 0, 85, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 392/1000 --- L(Train): 0.3777174 --- L(Val, RNN): 0.3509279 --- L(Val, SINDy): 0.4280448 --- Time: 1.07s; --- Convergence: 3.09e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 92/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.376 1 + 0.457 value_stay[t] + 0.195 reward + 0.051 value_stay^2 + 0.224 value_stay*reward + -0.351 value_stay*harvest_duration + 0.69 reward^2 + 0.199 reward*harvest_duration \n",
      "value_exit[t+1] = -0.036 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 46, -, -, 0, 86, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 393/1000 --- L(Train): 0.3787279 --- L(Val, RNN): 0.3508641 --- L(Val, SINDy): 0.4273395 --- Time: 0.88s; --- Convergence: 1.86e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 93/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.377 1 + 0.456 value_stay[t] + 0.194 reward + 0.048 value_stay^2 + 0.221 value_stay*reward + -0.352 value_stay*harvest_duration + 0.687 reward^2 + 0.198 reward*harvest_duration \n",
      "value_exit[t+1] = -0.036 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 1, 0, 0, 0, 0, -\n",
      "value_exit: 47, -, -, 0, 87, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 394/1000 --- L(Train): 0.3797129 --- L(Val, RNN): 0.3507236 --- L(Val, SINDy): 0.4266005 --- Time: 0.88s; --- Convergence: 1.63e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 94/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.378 1 + 0.456 value_stay[t] + 0.193 reward + 0.047 value_stay^2 + 0.221 value_stay*reward + -0.351 value_stay*harvest_duration + 0.686 reward^2 + 0.197 reward*harvest_duration \n",
      "value_exit[t+1] = -0.037 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 2, 0, 0, 0, 0, -\n",
      "value_exit: 48, -, -, 0, 88, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 395/1000 --- L(Train): 0.3840516 --- L(Val, RNN): 0.3504306 --- L(Val, SINDy): 0.4259879 --- Time: 1.03s; --- Convergence: 2.28e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 95/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.38 1 + 0.457 value_stay[t] + 0.193 reward + 0.047 value_stay^2 + 0.22 value_stay*reward + -0.35 value_stay*harvest_duration + 0.685 reward^2 + 0.197 reward*harvest_duration \n",
      "value_exit[t+1] = -0.037 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 3, 0, 0, 0, 0, -\n",
      "value_exit: 49, -, -, 0, 89, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 396/1000 --- L(Train): 0.3815412 --- L(Val, RNN): 0.3501771 --- L(Val, SINDy): 0.4254302 --- Time: 0.95s; --- Convergence: 2.41e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 96/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.382 1 + 0.458 value_stay[t] + 0.193 reward + 0.047 value_stay^2 + 0.22 value_stay*reward + -0.349 value_stay*harvest_duration + 0.685 reward^2 + 0.198 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 4, 0, 0, 0, 0, -\n",
      "value_exit: 50, -, -, 0, 90, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 397/1000 --- L(Train): 0.3798553 --- L(Val, RNN): 0.3500863 --- L(Val, SINDy): 0.4249040 --- Time: 0.90s; --- Convergence: 1.66e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 97/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.384 1 + 0.459 value_stay[t] + 0.194 reward + 0.047 value_stay^2 + 0.221 value_stay*reward + -0.348 value_stay*harvest_duration + 0.685 reward^2 + 0.199 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 5, 0, 0, 0, 0, -\n",
      "value_exit: 51, -, -, 0, 91, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 398/1000 --- L(Train): 0.3771397 --- L(Val, RNN): 0.3499930 --- L(Val, SINDy): 0.4244349 --- Time: 0.91s; --- Convergence: 1.30e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 98/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.385 1 + 0.46 value_stay[t] + 0.195 reward + 0.047 value_stay^2 + 0.222 value_stay*reward + -0.347 value_stay*harvest_duration + 0.685 reward^2 + 0.199 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 6, 0, 0, 0, 0, -\n",
      "value_exit: 52, -, -, 0, 92, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 399/1000 --- L(Train): 0.3795062 --- L(Val, RNN): 0.3498028 --- L(Val, SINDy): 0.4239236 --- Time: 1.01s; --- Convergence: 1.60e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 99/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.387 1 + 0.461 value_stay[t] + 0.197 reward + 0.047 value_stay^2 + 0.223 value_stay*reward + -0.345 value_stay*harvest_duration + 0.686 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.072 value_exit^2 + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 7, 0, 0, 0, 0, -\n",
      "value_exit: 53, -, -, 0, 93, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 400/1000 --- L(Train): 0.3763884 --- L(Val, RNN): 0.3495343 --- L(Val, SINDy): 0.4233840 --- Time: 1.02s; --- Convergence: 2.14e-04; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.389 1 + 0.461 value_stay[t] + 0.198 reward + 0.047 value_stay^2 + 0.225 value_stay*reward + -0.345 value_stay*harvest_duration + 0.687 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.072 value_exit^2 + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 8, 0, 0, 0, 0, -\n",
      "value_exit: 54, -, -, 0, 94, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 401/1000 --- L(Train): 0.3817411 --- L(Val, RNN): 0.3494411 --- L(Val, SINDy): 0.4225146 --- Time: 1.62s; --- Convergence: 1.54e-04; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 1/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.388 1 + 0.459 value_stay[t] + 0.198 reward + 0.043 value_stay^2 + 0.224 value_stay*reward + -0.347 value_stay*harvest_duration + 0.686 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.072 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 9, 0, 0, 0, 0, -\n",
      "value_exit: 55, -, -, 0, 95, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 402/1000 --- L(Train): 0.3813535 --- L(Val, RNN): 0.3494253 --- L(Val, SINDy): 0.4219857 --- Time: 3.27s; --- Convergence: 8.48e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 2/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.387 1 + 0.456 value_stay[t] + 0.197 reward + 0.038 value_stay^2 + 0.222 value_stay*reward + -0.349 value_stay*harvest_duration + 0.685 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.073 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 10, 0, 0, 0, 0, -\n",
      "value_exit: 56, -, -, 0, 96, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 403/1000 --- L(Train): 0.3774808 --- L(Val, RNN): 0.3493804 --- L(Val, SINDy): 0.4215022 --- Time: 3.88s; --- Convergence: 6.48e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 3/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.386 1 + 0.453 value_stay[t] + 0.196 reward + 0.034 value_stay^2 + 0.221 value_stay*reward + -0.351 value_stay*harvest_duration + 0.684 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.073 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 11, 0, 0, 0, 0, -\n",
      "value_exit: 57, -, -, 0, 97, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 404/1000 --- L(Train): 0.3795100 --- L(Val, RNN): 0.3492528 --- L(Val, SINDy): 0.4208545 --- Time: 3.69s; --- Convergence: 9.62e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 4/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.386 1 + 0.452 value_stay[t] + 0.197 reward + 0.031 value_stay^2 + 0.221 value_stay*reward + -0.352 value_stay*harvest_duration + 0.684 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.074 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 12, 0, 0, 0, 0, -\n",
      "value_exit: 58, -, -, 0, 98, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 405/1000 --- L(Train): 0.3786492 --- L(Val, RNN): 0.3490922 --- L(Val, SINDy): 0.4197773 --- Time: 5.24s; --- Convergence: 1.28e-04; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 5/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.387 1 + 0.451 value_stay[t] + 0.197 reward + 0.029 value_stay^2 + 0.221 value_stay*reward + -0.352 value_stay*harvest_duration + 0.684 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.074 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 13, 0, 0, 0, 0, -\n",
      "value_exit: 59, -, -, 0, 99, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 406/1000 --- L(Train): 0.3789916 --- L(Val, RNN): 0.3489975 --- L(Val, SINDy): 0.4183827 --- Time: 4.61s; --- Convergence: 1.12e-04; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 6/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.389 1 + 0.452 value_stay[t] + 0.199 reward + 0.03 value_stay^2 + 0.223 value_stay*reward + -0.351 value_stay*harvest_duration + 0.685 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.074 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 14, 0, 0, 0, 0, -\n",
      "value_exit: 60, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 407/1000 --- L(Train): 0.3735381 --- L(Val, RNN): 0.3489585 --- L(Val, SINDy): 0.4167441 --- Time: 8.08s; --- Convergence: 7.53e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 7/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.392 1 + 0.454 value_stay[t] + 0.202 reward + 0.032 value_stay^2 + 0.227 value_stay*reward + -0.348 value_stay*harvest_duration + 0.687 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.075 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 15, 0, 0, 0, 0, -\n",
      "value_exit: 61, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 408/1000 --- L(Train): 0.3734650 --- L(Val, RNN): 0.3489278 --- L(Val, SINDy): 0.4159847 --- Time: 3.56s; --- Convergence: 5.30e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 8/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.394 1 + 0.456 value_stay[t] + 0.204 reward + 0.033 value_stay^2 + 0.23 value_stay*reward + -0.345 value_stay*harvest_duration + 0.689 reward^2 + 0.208 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.075 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 16, 0, 0, 0, 0, -\n",
      "value_exit: 62, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 409/1000 --- L(Train): 0.3800357 --- L(Val, RNN): 0.3488278 --- L(Val, SINDy): 0.4160467 --- Time: 3.57s; --- Convergence: 7.65e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 9/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.396 1 + 0.458 value_stay[t] + 0.206 reward + 0.034 value_stay^2 + 0.232 value_stay*reward + -0.343 value_stay*harvest_duration + 0.69 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.076 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 17, 0, 0, 0, 0, -\n",
      "value_exit: 63, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 410/1000 --- L(Train): 0.3746231 --- L(Val, RNN): 0.3487060 --- L(Val, SINDy): 0.4159558 --- Time: 5.91s; --- Convergence: 9.91e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 10/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.397 1 + 0.457 value_stay[t] + 0.206 reward + 0.033 value_stay^2 + 0.232 value_stay*reward + -0.343 value_stay*harvest_duration + 0.69 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.076 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 18, 0, 0, 0, 0, -\n",
      "value_exit: 64, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 411/1000 --- L(Train): 0.3746335 --- L(Val, RNN): 0.3485884 --- L(Val, SINDy): 0.4161132 --- Time: 4.71s; --- Convergence: 1.08e-04; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 11/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.397 1 + 0.456 value_stay[t] + 0.205 reward + 0.03 value_stay^2 + 0.231 value_stay*reward + -0.344 value_stay*harvest_duration + 0.688 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.076 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 19, 0, 0, 0, 0, -\n",
      "value_exit: 65, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 412/1000 --- L(Train): 0.3717536 --- L(Val, RNN): 0.3485264 --- L(Val, SINDy): 0.4164698 --- Time: 1.12s; --- Convergence: 8.52e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 12/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.397 1 + 0.454 value_stay[t] + 0.203 reward + 0.027 value_stay^2 + 0.23 value_stay*reward + -0.345 value_stay*harvest_duration + 0.686 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.077 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 20, 0, 0, 0, 0, -\n",
      "value_exit: 66, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 413/1000 --- L(Train): 0.3695362 --- L(Val, RNN): 0.3484888 --- L(Val, SINDy): 0.4178076 --- Time: 0.98s; --- Convergence: 6.14e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 13/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.396 1 + 0.453 value_stay[t] + 0.202 reward + 0.025 value_stay^2 + 0.228 value_stay*reward + -0.347 value_stay*harvest_duration + 0.684 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.077 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 21, 0, 0, 0, 0, -\n",
      "value_exit: 67, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 414/1000 --- L(Train): 0.3773001 --- L(Val, RNN): 0.3484398 --- L(Val, SINDy): 0.4186694 --- Time: 0.86s; --- Convergence: 5.52e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 14/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.397 1 + 0.452 value_stay[t] + 0.201 reward + 0.023 value_stay^2 + 0.227 value_stay*reward + -0.347 value_stay*harvest_duration + 0.683 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.078 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 22, 0, 0, 0, 0, -\n",
      "value_exit: 68, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 415/1000 --- L(Train): 0.3719016 --- L(Val, RNN): 0.3483388 --- L(Val, SINDy): 0.4200667 --- Time: 0.96s; --- Convergence: 7.81e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 15/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.398 1 + 0.453 value_stay[t] + 0.201 reward + 0.024 value_stay^2 + 0.228 value_stay*reward + -0.346 value_stay*harvest_duration + 0.682 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.078 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 23, 0, 0, 0, 0, -\n",
      "value_exit: 69, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 416/1000 --- L(Train): 0.3790147 --- L(Val, RNN): 0.3482241 --- L(Val, SINDy): 0.4214403 --- Time: 1.38s; --- Convergence: 9.64e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 16/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.401 1 + 0.456 value_stay[t] + 0.201 reward + 0.026 value_stay^2 + 0.23 value_stay*reward + -0.344 value_stay*harvest_duration + 0.682 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.079 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 24, 0, 0, 0, 0, -\n",
      "value_exit: 70, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 417/1000 --- L(Train): 0.3715467 --- L(Val, RNN): 0.3481454 --- L(Val, SINDy): 0.4228951 --- Time: 1.03s; --- Convergence: 8.75e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 17/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.403 1 + 0.458 value_stay[t] + 0.202 reward + 0.027 value_stay^2 + 0.231 value_stay*reward + -0.342 value_stay*harvest_duration + 0.682 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.079 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 25, 0, 0, 0, 0, -\n",
      "value_exit: 71, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 418/1000 --- L(Train): 0.3738428 --- L(Val, RNN): 0.3481345 --- L(Val, SINDy): 0.4245373 --- Time: 1.13s; --- Convergence: 4.92e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 18/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.405 1 + 0.459 value_stay[t] + 0.202 reward + 0.028 value_stay^2 + 0.232 value_stay*reward + -0.341 value_stay*harvest_duration + 0.682 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.08 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 26, 0, 0, 0, 0, -\n",
      "value_exit: 72, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 419/1000 --- L(Train): 0.3770886 --- L(Val, RNN): 0.3480780 --- L(Val, SINDy): 0.4259552 --- Time: 0.87s; --- Convergence: 5.29e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 19/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.406 1 + 0.459 value_stay[t] + 0.202 reward + 0.027 value_stay^2 + 0.232 value_stay*reward + -0.342 value_stay*harvest_duration + 0.68 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = -0.037 1 + 1.0 value_exit[t] + 0.08 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 27, 0, 0, 0, 0, -\n",
      "value_exit: 73, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 420/1000 --- L(Train): 0.3669173 --- L(Val, RNN): 0.3479397 --- L(Val, SINDy): 0.4122423 --- Time: 0.86s; --- Convergence: 9.56e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 20/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.406 1 + 0.458 value_stay[t] + 0.201 reward + 0.025 value_stay^2 + 0.232 value_stay*reward + -0.343 value_stay*harvest_duration + 0.679 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = -0.037 1 + 1.0 value_exit[t] + 0.081 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 28, 0, 0, 0, 0, -\n",
      "value_exit: 74, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 421/1000 --- L(Train): 0.3759782 --- L(Val, RNN): 0.3478089 --- L(Val, SINDy): 0.4139423 --- Time: 0.90s; --- Convergence: 1.13e-04; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 21/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.407 1 + 0.458 value_stay[t] + 0.2 reward + 0.024 value_stay^2 + 0.231 value_stay*reward + -0.343 value_stay*harvest_duration + 0.677 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = -0.037 1 + 1.0 value_exit[t] + 0.081 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 29, 0, 0, 0, 0, -\n",
      "value_exit: 75, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 422/1000 --- L(Train): 0.3750668 --- L(Val, RNN): 0.3477551 --- L(Val, SINDy): 0.4154533 --- Time: 1.11s; --- Convergence: 8.35e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 22/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.408 1 + 0.458 value_stay[t] + 0.2 reward + 0.023 value_stay^2 + 0.231 value_stay*reward + -0.343 value_stay*harvest_duration + 0.676 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.081 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 30, 0, 0, 0, 0, -\n",
      "value_exit: 76, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 423/1000 --- L(Train): 0.3744653 --- L(Val, RNN): 0.3477734 --- L(Val, SINDy): 0.4163147 --- Time: 0.94s; --- Convergence: 5.09e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 23/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.409 1 + 0.458 value_stay[t] + 0.199 reward + 0.021 value_stay^2 + 0.231 value_stay*reward + -0.344 value_stay*harvest_duration + 0.675 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.082 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 31, 0, 0, 0, 0, -\n",
      "value_exit: 77, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 424/1000 --- L(Train): 0.3799876 --- L(Val, RNN): 0.3477749 --- L(Val, SINDy): 0.4165060 --- Time: 1.13s; --- Convergence: 2.62e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 24/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.409 1 + 0.457 value_stay[t] + 0.198 reward + 0.02 value_stay^2 + 0.231 value_stay*reward + -0.344 value_stay*harvest_duration + 0.673 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.082 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 32, 0, 0, 0, 0, -\n",
      "value_exit: 78, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 425/1000 --- L(Train): 0.3717726 --- L(Val, RNN): 0.3476925 --- L(Val, SINDy): 0.4166583 --- Time: 1.01s; --- Convergence: 5.43e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 25/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.41 1 + 0.457 value_stay[t] + 0.197 reward + 0.018 value_stay^2 + 0.23 value_stay*reward + -0.344 value_stay*harvest_duration + 0.672 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.083 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 33, 0, 0, 0, 0, -\n",
      "value_exit: 79, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 426/1000 --- L(Train): 0.3751509 --- L(Val, RNN): 0.3475934 --- L(Val, SINDy): 0.4165919 --- Time: 1.19s; --- Convergence: 7.67e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 26/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.41 1 + 0.457 value_stay[t] + 0.197 reward + 0.018 value_stay^2 + 0.23 value_stay*reward + -0.345 value_stay*harvest_duration + 0.671 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.083 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 34, 0, 0, 0, 0, -\n",
      "value_exit: 80, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 427/1000 --- L(Train): 0.3819354 --- L(Val, RNN): 0.3475345 --- L(Val, SINDy): 0.4167605 --- Time: 0.89s; --- Convergence: 6.78e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 27/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.412 1 + 0.458 value_stay[t] + 0.198 reward + 0.018 value_stay^2 + 0.232 value_stay*reward + -0.343 value_stay*harvest_duration + 0.671 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.084 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 35, 0, 0, 0, 0, -\n",
      "value_exit: 81, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 428/1000 --- L(Train): 0.3729434 --- L(Val, RNN): 0.3475198 --- L(Val, SINDy): 0.4163536 --- Time: 1.17s; --- Convergence: 4.13e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 28/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.414 1 + 0.459 value_stay[t] + 0.199 reward + 0.019 value_stay^2 + 0.235 value_stay*reward + -0.341 value_stay*harvest_duration + 0.672 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.084 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 36, 0, 0, 0, 0, -\n",
      "value_exit: 82, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 429/1000 --- L(Train): 0.3692357 --- L(Val, RNN): 0.3474933 --- L(Val, SINDy): 0.4155027 --- Time: 0.88s; --- Convergence: 3.39e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 29/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.414 1 + 0.458 value_stay[t] + 0.199 reward + 0.017 value_stay^2 + 0.236 value_stay*reward + -0.342 value_stay*harvest_duration + 0.672 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = -0.039 1 + 1.0 value_exit[t] + 0.085 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 37, 0, 0, 0, 0, -\n",
      "value_exit: 83, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 430/1000 --- L(Train): 0.3698045 --- L(Val, RNN): 0.3474045 --- L(Val, SINDy): 0.4151246 --- Time: 1.05s; --- Convergence: 6.13e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 30/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.414 1 + 0.457 value_stay[t] + 0.199 reward + 0.015 value_stay^2 + 0.236 value_stay*reward + -0.342 value_stay*harvest_duration + 0.671 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.039 1 + 1.0 value_exit[t] + 0.085 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 38, 0, 0, 0, 0, -\n",
      "value_exit: 84, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 431/1000 --- L(Train): 0.3730584 --- L(Val, RNN): 0.3473240 --- L(Val, SINDy): 0.4144312 --- Time: 0.92s; --- Convergence: 7.09e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 31/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.414 1 + 0.456 value_stay[t] + 0.199 reward + 0.014 value_stay^2 + 0.236 value_stay*reward + -0.343 value_stay*harvest_duration + 0.67 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.039 1 + 1.0 value_exit[t] + 0.085 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 39, 0, 0, 0, 0, -\n",
      "value_exit: 85, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 432/1000 --- L(Train): 0.3748904 --- L(Val, RNN): 0.3472565 --- L(Val, SINDy): 0.4136215 --- Time: 1.12s; --- Convergence: 6.92e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 32/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.415 1 + 0.455 value_stay[t] + 0.198 reward + 0.013 value_stay^2 + 0.237 value_stay*reward + -0.343 value_stay*harvest_duration + 0.669 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.039 1 + 1.0 value_exit[t] + 0.086 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 40, 0, 0, 0, 0, -\n",
      "value_exit: 86, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 433/1000 --- L(Train): 0.3776133 --- L(Val, RNN): 0.3472238 --- L(Val, SINDy): 0.4130865 --- Time: 1.01s; --- Convergence: 5.10e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 33/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.415 1 + 0.455 value_stay[t] + 0.198 reward + 0.012 value_stay^2 + 0.238 value_stay*reward + -0.342 value_stay*harvest_duration + 0.669 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.04 1 + 1.0 value_exit[t] + 0.086 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 41, 0, 0, 0, 0, -\n",
      "value_exit: 87, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 434/1000 --- L(Train): 0.3719390 --- L(Val, RNN): 0.3471946 --- L(Val, SINDy): 0.4121572 --- Time: 0.95s; --- Convergence: 4.01e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 34/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.416 1 + 0.455 value_stay[t] + 0.198 reward + 0.012 value_stay^2 + 0.239 value_stay*reward + -0.342 value_stay*harvest_duration + 0.668 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.04 1 + 1.0 value_exit[t] + 0.087 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 42, 0, 0, 0, 0, -\n",
      "value_exit: 88, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 435/1000 --- L(Train): 0.3706002 --- L(Val, RNN): 0.3471297 --- L(Val, SINDy): 0.4115404 --- Time: 0.97s; --- Convergence: 5.25e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 35/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.416 1 + 0.455 value_stay[t] + 0.198 reward + 0.011 value_stay^2 + 0.239 value_stay*reward + -0.342 value_stay*harvest_duration + 0.667 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.04 1 + 1.0 value_exit[t] + 0.087 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 43, 0, 0, 0, 0, -\n",
      "value_exit: 89, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 436/1000 --- L(Train): 0.3758097 --- L(Val, RNN): 0.3470839 --- L(Val, SINDy): 0.4106090 --- Time: 1.14s; --- Convergence: 4.91e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 36/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.417 1 + 0.456 value_stay[t] + 0.198 reward + 0.011 value_stay^2 + 0.24 value_stay*reward + -0.341 value_stay*harvest_duration + 0.667 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.04 1 + 1.0 value_exit[t] + 0.087 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 44, 0, 0, 0, 0, -\n",
      "value_exit: 90, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 437/1000 --- L(Train): 0.3773444 --- L(Val, RNN): 0.3470285 --- L(Val, SINDy): 0.4102717 --- Time: 1.33s; --- Convergence: 5.23e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 37/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.418 1 + 0.456 value_stay[t] + 0.198 reward + 0.01 value_stay^2 + 0.24 value_stay*reward + -0.341 value_stay*harvest_duration + 0.666 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.041 1 + 1.0 value_exit[t] + 0.088 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 45, 0, 0, 0, 0, -\n",
      "value_exit: 91, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 438/1000 --- L(Train): 0.3740463 --- L(Val, RNN): 0.3469730 --- L(Val, SINDy): 0.4099302 --- Time: 0.92s; --- Convergence: 5.39e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 38/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.42 1 + 0.456 value_stay[t] + 0.198 reward + 0.01 value_stay^2 + 0.242 value_stay*reward + -0.34 value_stay*harvest_duration + 0.666 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.041 1 + 1.0 value_exit[t] + 0.088 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 46, 0, 0, 0, 0, -\n",
      "value_exit: 92, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 439/1000 --- L(Train): 0.3798763 --- L(Val, RNN): 0.3469125 --- L(Val, SINDy): 0.4101532 --- Time: 0.86s; --- Convergence: 5.72e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 39/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.421 1 + 0.457 value_stay[t] + 0.199 reward + 0.011 value_stay^2 + 0.243 value_stay*reward + -0.339 value_stay*harvest_duration + 0.667 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = -0.041 1 + 1.0 value_exit[t] + 0.089 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 47, 0, 0, 0, 0, -\n",
      "value_exit: 93, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 440/1000 --- L(Train): 0.3744872 --- L(Val, RNN): 0.3468626 --- L(Val, SINDy): 0.4101725 --- Time: 1.08s; --- Convergence: 5.36e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 40/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.423 1 + 0.458 value_stay[t] + 0.2 reward + 0.011 value_stay^2 + 0.245 value_stay*reward + -0.338 value_stay*harvest_duration + 0.667 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = -0.041 1 + 1.0 value_exit[t] + 0.089 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 48, 0, 0, 0, 0, -\n",
      "value_exit: 94, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 441/1000 --- L(Train): 0.3768109 --- L(Val, RNN): 0.3468042 --- L(Val, SINDy): 0.4102109 --- Time: 0.90s; --- Convergence: 5.60e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 41/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.424 1 + 0.459 value_stay[t] + 0.2 reward + 0.011 value_stay^2 + 0.245 value_stay*reward + -0.338 value_stay*harvest_duration + 0.666 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = -0.041 1 + 1.0 value_exit[t] + 0.089 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 49, 0, 0, 0, 0, -\n",
      "value_exit: 95, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 442/1000 --- L(Train): 0.3769868 --- L(Val, RNN): 0.3467458 --- L(Val, SINDy): 0.4104244 --- Time: 0.87s; --- Convergence: 5.72e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 42/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.425 1 + 0.458 value_stay[t] + 0.199 reward + 0.01 value_stay^2 + 0.245 value_stay*reward + -0.338 value_stay*harvest_duration + 0.665 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = -0.041 1 + 1.0 value_exit[t] + 0.09 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 50, 0, 0, 0, 0, -\n",
      "value_exit: 96, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 443/1000 --- L(Train): 0.3713870 --- L(Val, RNN): 0.3467261 --- L(Val, SINDy): 0.4104598 --- Time: 0.95s; --- Convergence: 3.85e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 43/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.426 1 + 0.458 value_stay[t] + 0.199 reward + 0.009 value_stay^2 + 0.245 value_stay*reward + -0.339 value_stay*harvest_duration + 0.664 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.042 1 + 1.0 value_exit[t] + 0.09 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 51, 0, 0, 0, 0, -\n",
      "value_exit: 97, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 444/1000 --- L(Train): 0.3732224 --- L(Val, RNN): 0.3466872 --- L(Val, SINDy): 0.4107773 --- Time: 1.02s; --- Convergence: 3.87e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 44/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.427 1 + 0.458 value_stay[t] + 0.198 reward + 0.008 value_stay^2 + 0.245 value_stay*reward + -0.339 value_stay*harvest_duration + 0.663 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.042 1 + 1.0 value_exit[t] + 0.09 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 52, 0, 0, 0, 0, -\n",
      "value_exit: 98, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 445/1000 --- L(Train): 0.3741748 --- L(Val, RNN): 0.3466274 --- L(Val, SINDy): 0.4110738 --- Time: 0.93s; --- Convergence: 4.92e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 45/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.428 1 + 0.458 value_stay[t] + 0.198 reward + 0.008 value_stay^2 + 0.245 value_stay*reward + -0.339 value_stay*harvest_duration + 0.663 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.042 1 + 1.0 value_exit[t] + 0.091 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 53, 0, 0, 0, 0, -\n",
      "value_exit: 99, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 446/1000 --- L(Train): 0.3735318 --- L(Val, RNN): 0.3465526 --- L(Val, SINDy): 0.4113401 --- Time: 1.45s; --- Convergence: 6.20e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 46/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.429 1 + 0.458 value_stay[t] + 0.198 reward + 0.008 value_stay^2 + 0.244 value_stay*reward + -0.339 value_stay*harvest_duration + 0.662 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.091 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 54, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 447/1000 --- L(Train): 0.3735065 --- L(Val, RNN): 0.3464987 --- L(Val, SINDy): 0.4119343 --- Time: 1.01s; --- Convergence: 5.80e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 47/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.429 1 + 0.458 value_stay[t] + 0.197 reward + 0.007 value_stay^2 + 0.244 value_stay*reward + -0.339 value_stay*harvest_duration + 0.661 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.091 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 55, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 448/1000 --- L(Train): 0.3695376 --- L(Val, RNN): 0.3464519 --- L(Val, SINDy): 0.4121370 --- Time: 1.00s; --- Convergence: 5.24e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 48/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.43 1 + 0.458 value_stay[t] + 0.197 reward + 0.006 value_stay^2 + 0.245 value_stay*reward + -0.338 value_stay*harvest_duration + 0.661 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.091 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 56, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 449/1000 --- L(Train): 0.3709962 --- L(Val, RNN): 0.3464325 --- L(Val, SINDy): 0.4122249 --- Time: 0.92s; --- Convergence: 3.59e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 49/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.432 1 + 0.459 value_stay[t] + 0.198 reward + 0.007 value_stay^2 + 0.246 value_stay*reward + -0.337 value_stay*harvest_duration + 0.661 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.09 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 57, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 450/1000 --- L(Train): 0.3655441 --- L(Val, RNN): 0.3463890 --- L(Val, SINDy): 0.4122800 --- Time: 0.93s; --- Convergence: 3.97e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 50/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.434 1 + 0.461 value_stay[t] + 0.199 reward + 0.008 value_stay^2 + 0.248 value_stay*reward + -0.336 value_stay*harvest_duration + 0.662 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.089 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 58, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 451/1000 --- L(Train): 0.3739131 --- L(Val, RNN): 0.3463371 --- L(Val, SINDy): 0.4122140 --- Time: 0.88s; --- Convergence: 4.58e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 51/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.436 1 + 0.462 value_stay[t] + 0.2 reward + 0.009 value_stay^2 + 0.25 value_stay*reward + -0.334 value_stay*harvest_duration + 0.663 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.088 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 59, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 452/1000 --- L(Train): 0.3746315 --- L(Val, RNN): 0.3462571 --- L(Val, SINDy): 0.4120743 --- Time: 0.86s; --- Convergence: 6.29e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 52/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.437 1 + 0.462 value_stay[t] + 0.2 reward + 0.008 value_stay^2 + 0.25 value_stay*reward + -0.334 value_stay*harvest_duration + 0.663 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.086 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 60, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 453/1000 --- L(Train): 0.3678398 --- L(Val, RNN): 0.3461992 --- L(Val, SINDy): 0.4118743 --- Time: 1.08s; --- Convergence: 6.04e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 53/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.436 1 + 0.46 value_stay[t] + 0.199 reward + 0.006 value_stay^2 + 0.249 value_stay*reward + -0.335 value_stay*harvest_duration + 0.661 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.085 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 61, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 454/1000 --- L(Train): 0.3705787 --- L(Val, RNN): 0.3462073 --- L(Val, SINDy): 0.4114251 --- Time: 0.92s; --- Convergence: 3.42e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 54/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.436 1 + 0.458 value_stay[t] + 0.197 reward + 0.003 value_stay^2 + 0.247 value_stay*reward + -0.337 value_stay*harvest_duration + 0.659 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.083 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 62, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 455/1000 --- L(Train): 0.3716637 --- L(Val, RNN): 0.3461912 --- L(Val, SINDy): 0.4112168 --- Time: 1.17s; --- Convergence: 2.52e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 55/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.436 1 + 0.457 value_stay[t] + 0.196 reward + 0.001 value_stay^2 + 0.247 value_stay*reward + -0.337 value_stay*harvest_duration + 0.658 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.081 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 63, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 456/1000 --- L(Train): 0.3712626 --- L(Val, RNN): 0.3461170 --- L(Val, SINDy): 0.4110893 --- Time: 1.20s; --- Convergence: 4.97e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 56/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.437 1 + 0.457 value_stay[t] + 0.197 reward + 0.001 value_stay^2 + 0.247 value_stay*reward + -0.337 value_stay*harvest_duration + 0.657 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.079 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 64, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 457/1000 --- L(Train): 0.3713816 --- L(Val, RNN): 0.3460170 --- L(Val, SINDy): 0.4110021 --- Time: 0.85s; --- Convergence: 7.48e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 57/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.439 1 + 0.459 value_stay[t] + 0.198 reward + 0.002 value_stay^2 + 0.249 value_stay*reward + -0.335 value_stay*harvest_duration + 0.658 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.077 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 65, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 458/1000 --- L(Train): 0.3679925 --- L(Val, RNN): 0.3459736 --- L(Val, SINDy): 0.4107817 --- Time: 1.14s; --- Convergence: 5.91e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 58/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.442 1 + 0.461 value_stay[t] + 0.2 reward + 0.005 value_stay^2 + 0.252 value_stay*reward + -0.332 value_stay*harvest_duration + 0.66 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.075 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 66, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 459/1000 --- L(Train): 0.3718669 --- L(Val, RNN): 0.3459518 --- L(Val, SINDy): 0.4103137 --- Time: 1.14s; --- Convergence: 4.05e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 59/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.444 1 + 0.462 value_stay[t] + 0.201 reward + 0.006 value_stay^2 + 0.254 value_stay*reward + -0.33 value_stay*harvest_duration + 0.661 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.073 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 67, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 460/1000 --- L(Train): 0.3742196 --- L(Val, RNN): 0.3459013 --- L(Val, SINDy): 0.4101378 --- Time: 0.89s; --- Convergence: 4.55e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 60/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.444 1 + 0.462 value_stay[t] + 0.201 reward + 0.005 value_stay^2 + 0.254 value_stay*reward + -0.33 value_stay*harvest_duration + 0.661 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.071 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 68, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 461/1000 --- L(Train): 0.3711054 --- L(Val, RNN): 0.3458448 --- L(Val, SINDy): 0.4098079 --- Time: 0.91s; --- Convergence: 5.10e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 61/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.444 1 + 0.461 value_stay[t] + 0.2 reward + 0.003 value_stay^2 + 0.253 value_stay*reward + -0.332 value_stay*harvest_duration + 0.66 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.068 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 69, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 462/1000 --- L(Train): 0.3689216 --- L(Val, RNN): 0.3457913 --- L(Val, SINDy): 0.4096112 --- Time: 1.01s; --- Convergence: 5.23e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 62/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.444 1 + 0.459 value_stay[t] + 0.199 reward + 0.001 value_stay^2 + 0.252 value_stay*reward + -0.333 value_stay*harvest_duration + 0.659 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.066 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 70, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 463/1000 --- L(Train): 0.3662840 --- L(Val, RNN): 0.3457596 --- L(Val, SINDy): 0.4090571 --- Time: 0.98s; --- Convergence: 4.20e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 63/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.445 1 + 0.459 value_stay[t] + 0.199 reward + 0.0 value_stay^2 + 0.253 value_stay*reward + -0.333 value_stay*harvest_duration + 0.658 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.064 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 71, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 464/1000 --- L(Train): 0.3730666 --- L(Val, RNN): 0.3457141 --- L(Val, SINDy): 0.4087892 --- Time: 0.96s; --- Convergence: 4.37e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 64/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.446 1 + 0.459 value_stay[t] + 0.2 reward + 0.0 value_stay^2 + 0.253 value_stay*reward + -0.332 value_stay*harvest_duration + 0.659 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.062 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 72, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 465/1000 --- L(Train): 0.3707382 --- L(Val, RNN): 0.3456525 --- L(Val, SINDy): 0.4084393 --- Time: 1.18s; --- Convergence: 5.27e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 65/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.448 1 + 0.46 value_stay[t] + 0.2 reward + 0.0 value_stay^2 + 0.255 value_stay*reward + -0.331 value_stay*harvest_duration + 0.659 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.059 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 73, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 466/1000 --- L(Train): 0.3750858 --- L(Val, RNN): 0.3456040 --- L(Val, SINDy): 0.4079603 --- Time: 2.18s; --- Convergence: 5.06e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 66/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.449 1 + 0.46 value_stay[t] + 0.201 reward + 0.0 value_stay^2 + 0.256 value_stay*reward + -0.331 value_stay*harvest_duration + 0.66 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.057 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 74, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 467/1000 --- L(Train): 0.3737274 --- L(Val, RNN): 0.3455559 --- L(Val, SINDy): 0.4073479 --- Time: 3.63s; --- Convergence: 4.93e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 67/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.45 1 + 0.46 value_stay[t] + 0.201 reward + -0.001 value_stay^2 + 0.256 value_stay*reward + -0.331 value_stay*harvest_duration + 0.66 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.054 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 75, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 468/1000 --- L(Train): 0.3654805 --- L(Val, RNN): 0.3455361 --- L(Val, SINDy): 0.4066587 --- Time: 4.42s; --- Convergence: 3.46e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 68/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.451 1 + 0.459 value_stay[t] + 0.202 reward + -0.002 value_stay^2 + 0.257 value_stay*reward + -0.331 value_stay*harvest_duration + 0.66 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.052 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 76, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 469/1000 --- L(Train): 0.3705725 --- L(Val, RNN): 0.3454995 --- L(Val, SINDy): 0.4059586 --- Time: 3.83s; --- Convergence: 3.56e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 69/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.452 1 + 0.459 value_stay[t] + 0.202 reward + -0.002 value_stay^2 + 0.258 value_stay*reward + -0.331 value_stay*harvest_duration + 0.66 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.05 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 77, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 1, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 470/1000 --- L(Train): 0.3657854 --- L(Val, RNN): 0.3454361 --- L(Val, SINDy): 0.4051760 --- Time: 3.93s; --- Convergence: 4.95e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 70/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.452 1 + 0.459 value_stay[t] + 0.203 reward + -0.003 value_stay^2 + 0.259 value_stay*reward + -0.331 value_stay*harvest_duration + 0.66 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.047 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 78, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 2, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 471/1000 --- L(Train): 0.3681871 --- L(Val, RNN): 0.3453911 --- L(Val, SINDy): 0.4043032 --- Time: 3.93s; --- Convergence: 4.72e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 71/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.453 1 + 0.458 value_stay[t] + 0.203 reward + -0.005 value_stay^2 + 0.259 value_stay*reward + -0.331 value_stay*harvest_duration + 0.66 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.045 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 79, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 3, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 472/1000 --- L(Train): 0.3692430 --- L(Val, RNN): 0.3453498 --- L(Val, SINDy): 0.4033465 --- Time: 2.96s; --- Convergence: 4.43e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 72/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.453 1 + 0.457 value_stay[t] + 0.202 reward + -0.006 value_stay^2 + 0.259 value_stay*reward + -0.332 value_stay*harvest_duration + 0.66 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.043 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 80, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 4, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 473/1000 --- L(Train): 0.3734902 --- L(Val, RNN): 0.3453241 --- L(Val, SINDy): 0.4025129 --- Time: 4.54s; --- Convergence: 3.50e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 73/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.454 1 + 0.457 value_stay[t] + 0.202 reward + -0.007 value_stay^2 + 0.259 value_stay*reward + -0.333 value_stay*harvest_duration + 0.659 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.041 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 81, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 5, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 474/1000 --- L(Train): 0.3730217 --- L(Val, RNN): 0.3452972 --- L(Val, SINDy): 0.4016408 --- Time: 3.14s; --- Convergence: 3.10e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 74/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.455 1 + 0.457 value_stay[t] + 0.202 reward + -0.007 value_stay^2 + 0.26 value_stay*reward + -0.332 value_stay*harvest_duration + 0.659 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.039 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 82, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 6, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 475/1000 --- L(Train): 0.3726875 --- L(Val, RNN): 0.3452435 --- L(Val, SINDy): 0.4008093 --- Time: 3.91s; --- Convergence: 4.23e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 75/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.457 1 + 0.458 value_stay[t] + 0.202 reward + -0.007 value_stay^2 + 0.261 value_stay*reward + -0.331 value_stay*harvest_duration + 0.659 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.037 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 83, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 7, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 476/1000 --- L(Train): 0.3737390 --- L(Val, RNN): 0.3451929 --- L(Val, SINDy): 0.3998232 --- Time: 4.82s; --- Convergence: 4.64e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 76/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.458 1 + 0.458 value_stay[t] + 0.203 reward + -0.007 value_stay^2 + 0.262 value_stay*reward + -0.331 value_stay*harvest_duration + 0.659 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.035 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 84, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 8, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 477/1000 --- L(Train): 0.3669684 --- L(Val, RNN): 0.3451518 --- L(Val, SINDy): 0.3987162 --- Time: 1.92s; --- Convergence: 4.38e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 77/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.459 1 + 0.459 value_stay[t] + 0.203 reward + -0.007 value_stay^2 + 0.262 value_stay*reward + -0.331 value_stay*harvest_duration + 0.659 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.033 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 85, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 9, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 478/1000 --- L(Train): 0.3701122 --- L(Val, RNN): 0.3450897 --- L(Val, SINDy): 0.3974814 --- Time: 1.85s; --- Convergence: 5.30e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 78/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.46 1 + 0.459 value_stay[t] + 0.203 reward + -0.006 value_stay^2 + 0.263 value_stay*reward + -0.331 value_stay*harvest_duration + 0.659 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.032 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 86, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 10, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 479/1000 --- L(Train): 0.3705098 --- L(Val, RNN): 0.3450239 --- L(Val, SINDy): 0.3902108 --- Time: 1.92s; --- Convergence: 5.94e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 79/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.461 1 + 0.46 value_stay[t] + 0.203 reward + -0.006 value_stay^2 + 0.264 value_stay*reward + -0.331 value_stay*harvest_duration + 0.658 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.03 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 87, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 11, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 480/1000 --- L(Train): 0.3678575 --- L(Val, RNN): 0.3449965 --- L(Val, SINDy): 0.3899887 --- Time: 1.51s; --- Convergence: 4.34e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 80/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.462 1 + 0.46 value_stay[t] + 0.203 reward + -0.006 value_stay^2 + 0.264 value_stay*reward + -0.331 value_stay*harvest_duration + 0.658 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.028 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 88, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 12, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 481/1000 --- L(Train): 0.3726833 --- L(Val, RNN): 0.3449732 --- L(Val, SINDy): 0.3896952 --- Time: 1.38s; --- Convergence: 3.33e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 81/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.463 1 + 0.461 value_stay[t] + 0.203 reward + -0.006 value_stay^2 + 0.265 value_stay*reward + -0.33 value_stay*harvest_duration + 0.658 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.027 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 89, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 13, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 482/1000 --- L(Train): 0.3689084 --- L(Val, RNN): 0.3449326 --- L(Val, SINDy): 0.3895976 --- Time: 1.09s; --- Convergence: 3.70e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 82/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.464 1 + 0.461 value_stay[t] + 0.202 reward + -0.006 value_stay^2 + 0.265 value_stay*reward + -0.331 value_stay*harvest_duration + 0.657 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.026 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 90, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 14, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 483/1000 --- L(Train): 0.3714116 --- L(Val, RNN): 0.3448871 --- L(Val, SINDy): 0.3893574 --- Time: 0.85s; --- Convergence: 4.12e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 83/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.465 1 + 0.46 value_stay[t] + 0.202 reward + -0.007 value_stay^2 + 0.264 value_stay*reward + -0.331 value_stay*harvest_duration + 0.656 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.024 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 91, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 15, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 484/1000 --- L(Train): 0.3697670 --- L(Val, RNN): 0.3448431 --- L(Val, SINDy): 0.3892559 --- Time: 1.06s; --- Convergence: 4.26e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 84/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.465 1 + 0.46 value_stay[t] + 0.201 reward + -0.008 value_stay^2 + 0.264 value_stay*reward + -0.332 value_stay*harvest_duration + 0.655 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.023 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 92, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 16, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 485/1000 --- L(Train): 0.3691989 --- L(Val, RNN): 0.3448027 --- L(Val, SINDy): 0.3893646 --- Time: 0.88s; --- Convergence: 4.15e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 85/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.466 1 + 0.46 value_stay[t] + 0.2 reward + -0.009 value_stay^2 + 0.263 value_stay*reward + -0.332 value_stay*harvest_duration + 0.654 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.022 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 93, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 17, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 486/1000 --- L(Train): 0.3722007 --- L(Val, RNN): 0.3448082 --- L(Val, SINDy): 0.3890905 --- Time: 1.00s; --- Convergence: 2.35e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 86/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.467 1 + 0.46 value_stay[t] + 0.2 reward + -0.009 value_stay^2 + 0.264 value_stay*reward + -0.332 value_stay*harvest_duration + 0.654 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.021 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 94, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 18, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 487/1000 --- L(Train): 0.3701658 --- L(Val, RNN): 0.3447977 --- L(Val, SINDy): 0.3887752 --- Time: 1.04s; --- Convergence: 1.70e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 87/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.468 1 + 0.461 value_stay[t] + 0.2 reward + -0.008 value_stay^2 + 0.265 value_stay*reward + -0.331 value_stay*harvest_duration + 0.654 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.02 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 95, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 19, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 488/1000 --- L(Train): 0.3726661 --- L(Val, RNN): 0.3447084 --- L(Val, SINDy): 0.3885655 --- Time: 0.83s; --- Convergence: 5.32e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 88/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.469 1 + 0.462 value_stay[t] + 0.2 reward + -0.007 value_stay^2 + 0.265 value_stay*reward + -0.329 value_stay*harvest_duration + 0.653 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.019 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 96, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 20, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 489/1000 --- L(Train): 0.3666119 --- L(Val, RNN): 0.3446021 --- L(Val, SINDy): 0.3884603 --- Time: 0.89s; --- Convergence: 7.97e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 89/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.47 1 + 0.463 value_stay[t] + 0.2 reward + -0.006 value_stay^2 + 0.266 value_stay*reward + -0.328 value_stay*harvest_duration + 0.653 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.018 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 97, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 21, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 490/1000 --- L(Train): 0.3691347 --- L(Val, RNN): 0.3445840 --- L(Val, SINDy): 0.3881683 --- Time: 0.99s; --- Convergence: 4.89e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 90/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.471 1 + 0.463 value_stay[t] + 0.2 reward + -0.006 value_stay^2 + 0.266 value_stay*reward + -0.328 value_stay*harvest_duration + 0.653 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.017 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 98, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 22, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 491/1000 --- L(Train): 0.3701485 --- L(Val, RNN): 0.3446094 --- L(Val, SINDy): 0.3878242 --- Time: 0.89s; --- Convergence: 3.71e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 91/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.471 1 + 0.463 value_stay[t] + 0.199 reward + -0.006 value_stay^2 + 0.267 value_stay*reward + -0.327 value_stay*harvest_duration + 0.652 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.016 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 99, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 23, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 492/1000 --- L(Train): 0.3743506 --- L(Val, RNN): 0.3445883 --- L(Val, SINDy): 0.3876110 --- Time: 1.05s; --- Convergence: 2.91e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 92/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.472 1 + 0.462 value_stay[t] + 0.199 reward + 0.267 value_stay*reward + -0.327 value_stay*harvest_duration + 0.652 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.015 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 24, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 493/1000 --- L(Train): 0.3665832 --- L(Val, RNN): 0.3444941 --- L(Val, SINDy): 0.3875657 --- Time: 0.88s; --- Convergence: 6.17e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 93/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.472 1 + 0.462 value_stay[t] + 0.199 reward + 0.267 value_stay*reward + -0.327 value_stay*harvest_duration + 0.651 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.014 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 25, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 494/1000 --- L(Train): 0.3660432 --- L(Val, RNN): 0.3444289 --- L(Val, SINDy): 0.3874678 --- Time: 1.16s; --- Convergence: 6.34e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 94/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.472 1 + 0.461 value_stay[t] + 0.198 reward + 0.267 value_stay*reward + -0.327 value_stay*harvest_duration + 0.651 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.013 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 26, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 495/1000 --- L(Train): 0.3665302 --- L(Val, RNN): 0.3444220 --- L(Val, SINDy): 0.3872454 --- Time: 0.91s; --- Convergence: 3.52e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 95/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.472 1 + 0.461 value_stay[t] + 0.198 reward + 0.267 value_stay*reward + -0.327 value_stay*harvest_duration + 0.65 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.013 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 27, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 496/1000 --- L(Train): 0.3711646 --- L(Val, RNN): 0.3444180 --- L(Val, SINDy): 0.3870362 --- Time: 0.85s; --- Convergence: 1.95e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 96/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.473 1 + 0.46 value_stay[t] + 0.198 reward + 0.267 value_stay*reward + -0.327 value_stay*harvest_duration + 0.65 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.012 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 28, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 497/1000 --- L(Train): 0.3633914 --- L(Val, RNN): 0.3443672 --- L(Val, SINDy): 0.3869735 --- Time: 0.85s; --- Convergence: 3.52e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 97/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.473 1 + 0.459 value_stay[t] + 0.197 reward + 0.266 value_stay*reward + -0.327 value_stay*harvest_duration + 0.649 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.011 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 29, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 498/1000 --- L(Train): 0.3652858 --- L(Val, RNN): 0.3442998 --- L(Val, SINDy): 0.3869306 --- Time: 0.99s; --- Convergence: 5.13e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 98/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.474 1 + 0.46 value_stay[t] + 0.199 reward + 0.268 value_stay*reward + -0.325 value_stay*harvest_duration + 0.65 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.011 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 30, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 499/1000 --- L(Train): 0.3694041 --- L(Val, RNN): 0.3442630 --- L(Val, SINDy): 0.3867461 --- Time: 1.01s; --- Convergence: 4.41e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 99/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.477 1 + 0.462 value_stay[t] + 0.201 reward + 0.271 value_stay*reward + -0.322 value_stay*harvest_duration + 0.653 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.01 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 31, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 500/1000 --- L(Train): 0.3692845 --- L(Val, RNN): 0.3442353 --- L(Val, SINDy): 0.3866070 --- Time: 1.10s; --- Convergence: 3.58e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.479 1 + 0.464 value_stay[t] + 0.203 reward + 0.273 value_stay*reward + -0.32 value_stay*harvest_duration + 0.654 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.009 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 32, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 501/1000 --- L(Train): 0.3647441 --- L(Val, RNN): 0.3441973 --- L(Val, SINDy): 0.3864539 --- Time: 0.92s; --- Convergence: 3.69e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 1/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.481 1 + 0.465 value_stay[t] + 0.204 reward + 0.274 value_stay*reward + -0.319 value_stay*harvest_duration + 0.655 reward^2 + 0.208 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.009 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 33, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 502/1000 --- L(Train): 0.3705634 --- L(Val, RNN): 0.3441466 --- L(Val, SINDy): 0.3869449 --- Time: 0.92s; --- Convergence: 4.38e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 2/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.482 1 + 0.464 value_stay[t] + 0.204 reward + 0.274 value_stay*reward + -0.319 value_stay*harvest_duration + 0.655 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.008 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 34, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 503/1000 --- L(Train): 0.3646459 --- L(Val, RNN): 0.3441068 --- L(Val, SINDy): 0.3867967 --- Time: 0.85s; --- Convergence: 4.18e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 3/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.48 1 + 0.461 value_stay[t] + 0.202 reward + 0.271 value_stay*reward + -0.322 value_stay*harvest_duration + 0.653 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.008 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 35, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 504/1000 --- L(Train): 0.3636296 --- L(Val, RNN): 0.3440905 --- L(Val, SINDy): 0.3864077 --- Time: 0.78s; --- Convergence: 2.91e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 4/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.478 1 + 0.457 value_stay[t] + 0.2 reward + 0.268 value_stay*reward + -0.326 value_stay*harvest_duration + 0.65 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.007 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 36, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 505/1000 --- L(Train): 0.3610073 --- L(Val, RNN): 0.3440702 --- L(Val, SINDy): 0.3860923 --- Time: 0.88s; --- Convergence: 2.47e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 5/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.477 1 + 0.454 value_stay[t] + 0.199 reward + 0.266 value_stay*reward + -0.328 value_stay*harvest_duration + 0.649 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.007 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 37, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 506/1000 --- L(Train): 0.3718454 --- L(Val, RNN): 0.3440401 --- L(Val, SINDy): 0.3859821 --- Time: 1.01s; --- Convergence: 2.74e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 6/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.479 1 + 0.455 value_stay[t] + 0.2 reward + 0.267 value_stay*reward + -0.328 value_stay*harvest_duration + 0.65 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.007 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 38, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 507/1000 --- L(Train): 0.3618016 --- L(Val, RNN): 0.3439894 --- L(Val, SINDy): 0.3860320 --- Time: 0.92s; --- Convergence: 3.90e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 7/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.48 1 + 0.456 value_stay[t] + 0.201 reward + 0.268 value_stay*reward + -0.327 value_stay*harvest_duration + 0.651 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.006 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 39, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 508/1000 --- L(Train): 0.3642789 --- L(Val, RNN): 0.3439571 --- L(Val, SINDy): 0.3861868 --- Time: 0.99s; --- Convergence: 3.57e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 8/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.482 1 + 0.456 value_stay[t] + 0.203 reward + 0.269 value_stay*reward + -0.326 value_stay*harvest_duration + 0.652 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.006 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 40, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 509/1000 --- L(Train): 0.3629949 --- L(Val, RNN): 0.3439481 --- L(Val, SINDy): 0.3861590 --- Time: 0.77s; --- Convergence: 2.24e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 9/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.483 1 + 0.457 value_stay[t] + 0.204 reward + 0.271 value_stay*reward + -0.325 value_stay*harvest_duration + 0.653 reward^2 + 0.208 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.005 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 41, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 510/1000 --- L(Train): 0.3639279 --- L(Val, RNN): 0.3439304 --- L(Val, SINDy): 0.3861838 --- Time: 0.83s; --- Convergence: 2.00e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 10/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.485 1 + 0.457 value_stay[t] + 0.205 reward + 0.272 value_stay*reward + -0.325 value_stay*harvest_duration + 0.653 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.005 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 42, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 511/1000 --- L(Train): 0.3659389 --- L(Val, RNN): 0.3438947 --- L(Val, SINDy): 0.3862823 --- Time: 0.87s; --- Convergence: 2.78e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 11/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.486 1 + 0.457 value_stay[t] + 0.205 reward + 0.272 value_stay*reward + -0.324 value_stay*harvest_duration + 0.654 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.005 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 43, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 512/1000 --- L(Train): 0.3694316 --- L(Val, RNN): 0.3438468 --- L(Val, SINDy): 0.3865724 --- Time: 0.85s; --- Convergence: 3.79e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 12/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.486 1 + 0.457 value_stay[t] + 0.205 reward + 0.272 value_stay*reward + -0.324 value_stay*harvest_duration + 0.654 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.005 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 44, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 513/1000 --- L(Train): 0.3613293 --- L(Val, RNN): 0.3438208 --- L(Val, SINDy): 0.3865302 --- Time: 1.18s; --- Convergence: 3.19e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 13/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.487 1 + 0.456 value_stay[t] + 0.205 reward + 0.271 value_stay*reward + -0.325 value_stay*harvest_duration + 0.653 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.004 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 45, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 514/1000 --- L(Train): 0.3642024 --- L(Val, RNN): 0.3438081 --- L(Val, SINDy): 0.3864008 --- Time: 0.94s; --- Convergence: 2.24e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 14/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.487 1 + 0.455 value_stay[t] + 0.205 reward + 0.271 value_stay*reward + -0.325 value_stay*harvest_duration + 0.653 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.004 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 46, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 515/1000 --- L(Train): 0.3647425 --- L(Val, RNN): 0.3437966 --- L(Val, SINDy): 0.3863511 --- Time: 0.99s; --- Convergence: 1.69e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 15/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.487 1 + 0.454 value_stay[t] + 0.204 reward + 0.27 value_stay*reward + -0.326 value_stay*harvest_duration + 0.652 reward^2 + 0.208 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.004 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 47, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 516/1000 --- L(Train): 0.3695446 --- L(Val, RNN): 0.3437771 --- L(Val, SINDy): 0.3863072 --- Time: 1.26s; --- Convergence: 1.82e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 16/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.487 1 + 0.454 value_stay[t] + 0.204 reward + 0.269 value_stay*reward + -0.327 value_stay*harvest_duration + 0.651 reward^2 + 0.208 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.004 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 48, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 517/1000 --- L(Train): 0.3653282 --- L(Val, RNN): 0.3437473 --- L(Val, SINDy): 0.3862334 --- Time: 1.70s; --- Convergence: 2.40e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 17/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.489 1 + 0.454 value_stay[t] + 0.205 reward + 0.27 value_stay*reward + -0.326 value_stay*harvest_duration + 0.652 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.003 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 49, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 518/1000 --- L(Train): 0.3693472 --- L(Val, RNN): 0.3437114 --- L(Val, SINDy): 0.3861579 --- Time: 1.15s; --- Convergence: 2.99e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 18/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.491 1 + 0.456 value_stay[t] + 0.206 reward + 0.272 value_stay*reward + -0.324 value_stay*harvest_duration + 0.653 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.003 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 50, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 519/1000 --- L(Train): 0.3669060 --- L(Val, RNN): 0.3436812 --- L(Val, SINDy): 0.3857056 --- Time: 0.91s; --- Convergence: 3.01e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 19/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.493 1 + 0.458 value_stay[t] + 0.207 reward + 0.274 value_stay*reward + -0.322 value_stay*harvest_duration + 0.654 reward^2 + 0.211 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.003 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 51, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 520/1000 --- L(Train): 0.3634162 --- L(Val, RNN): 0.3436606 --- L(Val, SINDy): 0.3854290 --- Time: 1.11s; --- Convergence: 2.53e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 20/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.495 1 + 0.459 value_stay[t] + 0.208 reward + 0.275 value_stay*reward + -0.321 value_stay*harvest_duration + 0.654 reward^2 + 0.212 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.003 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 52, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 521/1000 --- L(Train): 0.3652404 --- L(Val, RNN): 0.3436430 --- L(Val, SINDy): 0.3852577 --- Time: 0.99s; --- Convergence: 2.15e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 21/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.495 1 + 0.458 value_stay[t] + 0.208 reward + 0.274 value_stay*reward + -0.321 value_stay*harvest_duration + 0.653 reward^2 + 0.212 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.003 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 53, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 522/1000 --- L(Train): 0.3649713 --- L(Val, RNN): 0.3436220 --- L(Val, SINDy): 0.3852593 --- Time: 0.95s; --- Convergence: 2.12e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 22/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.495 1 + 0.456 value_stay[t] + 0.206 reward + 0.272 value_stay*reward + -0.323 value_stay*harvest_duration + 0.651 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 54, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 523/1000 --- L(Train): 0.3637085 --- L(Val, RNN): 0.3436047 --- L(Val, SINDy): 0.3852507 --- Time: 1.17s; --- Convergence: 1.93e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 23/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.494 1 + 0.455 value_stay[t] + 0.205 reward + 0.27 value_stay*reward + -0.325 value_stay*harvest_duration + 0.65 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 55, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 524/1000 --- L(Train): 0.3690872 --- L(Val, RNN): 0.3435935 --- L(Val, SINDy): 0.3852004 --- Time: 0.83s; --- Convergence: 1.52e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 24/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.494 1 + 0.453 value_stay[t] + 0.203 reward + 0.269 value_stay*reward + -0.326 value_stay*harvest_duration + 0.648 reward^2 + 0.208 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 56, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 525/1000 --- L(Train): 0.3629631 --- L(Val, RNN): 0.3435710 --- L(Val, SINDy): 0.3851233 --- Time: 0.81s; --- Convergence: 1.89e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 25/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.494 1 + 0.452 value_stay[t] + 0.203 reward + 0.268 value_stay*reward + -0.327 value_stay*harvest_duration + 0.647 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 57, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 526/1000 --- L(Train): 0.3687652 --- L(Val, RNN): 0.3435443 --- L(Val, SINDy): 0.3850049 --- Time: 1.14s; --- Convergence: 2.28e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 26/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.496 1 + 0.453 value_stay[t] + 0.203 reward + 0.269 value_stay*reward + -0.326 value_stay*harvest_duration + 0.647 reward^2 + 0.208 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 58, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 527/1000 --- L(Train): 0.3659714 --- L(Val, RNN): 0.3435265 --- L(Val, SINDy): 0.3849169 --- Time: 1.15s; --- Convergence: 2.03e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 27/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.498 1 + 0.455 value_stay[t] + 0.205 reward + 0.271 value_stay*reward + -0.324 value_stay*harvest_duration + 0.648 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 59, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 528/1000 --- L(Train): 0.3661322 --- L(Val, RNN): 0.3435068 --- L(Val, SINDy): 0.3848862 --- Time: 0.90s; --- Convergence: 2.00e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 28/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.5 1 + 0.457 value_stay[t] + 0.206 reward + 0.273 value_stay*reward + -0.322 value_stay*harvest_duration + 0.649 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 60, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 529/1000 --- L(Train): 0.3642037 --- L(Val, RNN): 0.3434909 --- L(Val, SINDy): 0.3848641 --- Time: 1.02s; --- Convergence: 1.79e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 29/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.501 1 + 0.458 value_stay[t] + 0.207 reward + 0.274 value_stay*reward + -0.321 value_stay*harvest_duration + 0.65 reward^2 + 0.211 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 61, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 530/1000 --- L(Train): 0.3683787 --- L(Val, RNN): 0.3434753 --- L(Val, SINDy): 0.3847640 --- Time: 1.19s; --- Convergence: 1.68e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 30/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.502 1 + 0.458 value_stay[t] + 0.208 reward + 0.275 value_stay*reward + -0.321 value_stay*harvest_duration + 0.65 reward^2 + 0.212 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 62, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 531/1000 --- L(Train): 0.3622389 --- L(Val, RNN): 0.3434475 --- L(Val, SINDy): 0.3846807 --- Time: 1.28s; --- Convergence: 2.23e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 31/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.503 1 + 0.458 value_stay[t] + 0.208 reward + 0.276 value_stay*reward + -0.32 value_stay*harvest_duration + 0.651 reward^2 + 0.212 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 63, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 532/1000 --- L(Train): 0.3625254 --- L(Val, RNN): 0.3434214 --- L(Val, SINDy): 0.3845554 --- Time: 1.12s; --- Convergence: 2.42e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 32/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.503 1 + 0.457 value_stay[t] + 0.208 reward + 0.276 value_stay*reward + -0.321 value_stay*harvest_duration + 0.65 reward^2 + 0.212 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 64, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 533/1000 --- L(Train): 0.3665890 --- L(Val, RNN): 0.3433937 --- L(Val, SINDy): 0.3844197 --- Time: 1.20s; --- Convergence: 2.60e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 33/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.502 1 + 0.456 value_stay[t] + 0.207 reward + 0.275 value_stay*reward + -0.322 value_stay*harvest_duration + 0.649 reward^2 + 0.211 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 65, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 534/1000 --- L(Train): 0.3659846 --- L(Val, RNN): 0.3433613 --- L(Val, SINDy): 0.3843498 --- Time: 1.25s; --- Convergence: 2.92e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 34/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.501 1 + 0.454 value_stay[t] + 0.206 reward + 0.273 value_stay*reward + -0.324 value_stay*harvest_duration + 0.647 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 66, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 535/1000 --- L(Train): 0.3679020 --- L(Val, RNN): 0.3433402 --- L(Val, SINDy): 0.3842421 --- Time: 1.36s; --- Convergence: 2.51e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 35/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.501 1 + 0.452 value_stay[t] + 0.205 reward + 0.272 value_stay*reward + -0.325 value_stay*harvest_duration + 0.646 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 67, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 536/1000 --- L(Train): 0.3651432 --- L(Val, RNN): 0.3433251 --- L(Val, SINDy): 0.3840971 --- Time: 1.59s; --- Convergence: 2.01e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 36/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.501 1 + 0.452 value_stay[t] + 0.205 reward + 0.273 value_stay*reward + -0.324 value_stay*harvest_duration + 0.645 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 68, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 537/1000 --- L(Train): 0.3637676 --- L(Val, RNN): 0.3432965 --- L(Val, SINDy): 0.3840265 --- Time: 1.12s; --- Convergence: 2.44e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 37/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.502 1 + 0.453 value_stay[t] + 0.205 reward + 0.274 value_stay*reward + -0.323 value_stay*harvest_duration + 0.646 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 69, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 538/1000 --- L(Train): 0.3680082 --- L(Val, RNN): 0.3432626 --- L(Val, SINDy): 0.3839793 --- Time: 1.28s; --- Convergence: 2.91e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 38/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.504 1 + 0.455 value_stay[t] + 0.207 reward + 0.276 value_stay*reward + -0.32 value_stay*harvest_duration + 0.646 reward^2 + 0.211 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 70, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 539/1000 --- L(Train): 0.3681235 --- L(Val, RNN): 0.3432288 --- L(Val, SINDy): 0.3839189 --- Time: 1.42s; --- Convergence: 3.14e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 39/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.506 1 + 0.456 value_stay[t] + 0.207 reward + 0.277 value_stay*reward + -0.318 value_stay*harvest_duration + 0.647 reward^2 + 0.212 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 71, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 540/1000 --- L(Train): 0.3663154 --- L(Val, RNN): 0.3431999 --- L(Val, SINDy): 0.3838030 --- Time: 1.98s; --- Convergence: 3.02e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 40/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.507 1 + 0.457 value_stay[t] + 0.208 reward + 0.278 value_stay*reward + -0.317 value_stay*harvest_duration + 0.647 reward^2 + 0.212 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 72, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 541/1000 --- L(Train): 0.3654511 --- L(Val, RNN): 0.3431812 --- L(Val, SINDy): 0.3836257 --- Time: 2.58s; --- Convergence: 2.44e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 41/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.508 1 + 0.457 value_stay[t] + 0.208 reward + 0.278 value_stay*reward + -0.317 value_stay*harvest_duration + 0.646 reward^2 + 0.212 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 73, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 542/1000 --- L(Train): 0.3617485 --- L(Val, RNN): 0.3431684 --- L(Val, SINDy): 0.3834546 --- Time: 3.88s; --- Convergence: 1.86e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 42/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.507 1 + 0.456 value_stay[t] + 0.207 reward + 0.277 value_stay*reward + -0.317 value_stay*harvest_duration + 0.645 reward^2 + 0.211 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 74, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 543/1000 --- L(Train): 0.3657504 --- L(Val, RNN): 0.3431467 --- L(Val, SINDy): 0.3833325 --- Time: 4.12s; --- Convergence: 2.02e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 43/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.506 1 + 0.453 value_stay[t] + 0.206 reward + 0.276 value_stay*reward + -0.319 value_stay*harvest_duration + 0.644 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 75, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 544/1000 --- L(Train): 0.3663920 --- L(Val, RNN): 0.3431181 --- L(Val, SINDy): 0.3832791 --- Time: 2.55s; --- Convergence: 2.44e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 44/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.506 1 + 0.451 value_stay[t] + 0.205 reward + 0.275 value_stay*reward + -0.321 value_stay*harvest_duration + 0.643 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 76, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 545/1000 --- L(Train): 0.3630203 --- L(Val, RNN): 0.3430866 --- L(Val, SINDy): 0.3832024 --- Time: 2.45s; --- Convergence: 2.80e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 45/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.506 1 + 0.451 value_stay[t] + 0.205 reward + 0.275 value_stay*reward + -0.321 value_stay*harvest_duration + 0.642 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 77, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 546/1000 --- L(Train): 0.3658516 --- L(Val, RNN): 0.3430578 --- L(Val, SINDy): 0.3831146 --- Time: 2.43s; --- Convergence: 2.84e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 46/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.507 1 + 0.451 value_stay[t] + 0.206 reward + 0.276 value_stay*reward + -0.321 value_stay*harvest_duration + 0.642 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 78, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 547/1000 --- L(Train): 0.3640478 --- L(Val, RNN): 0.3430391 --- L(Val, SINDy): 0.3830053 --- Time: 2.30s; --- Convergence: 2.36e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 47/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.507 1 + 0.45 value_stay[t] + 0.206 reward + 0.276 value_stay*reward + -0.321 value_stay*harvest_duration + 0.642 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 79, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 548/1000 --- L(Train): 0.3640516 --- L(Val, RNN): 0.3430222 --- L(Val, SINDy): 0.3829255 --- Time: 3.09s; --- Convergence: 2.02e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 48/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.509 1 + 0.451 value_stay[t] + 0.207 reward + 0.277 value_stay*reward + -0.32 value_stay*harvest_duration + 0.643 reward^2 + 0.211 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 80, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 549/1000 --- L(Train): 0.3586763 --- L(Val, RNN): 0.3430047 --- L(Val, SINDy): 0.3828850 --- Time: 2.86s; --- Convergence: 1.88e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 49/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.51 1 + 0.451 value_stay[t] + 0.208 reward + 0.278 value_stay*reward + -0.319 value_stay*harvest_duration + 0.643 reward^2 + 0.212 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 81, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 550/1000 --- L(Train): 0.3705635 --- L(Val, RNN): 0.3429877 --- L(Val, SINDy): 0.3828650 --- Time: 1.94s; --- Convergence: 1.79e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 50/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.511 1 + 0.452 value_stay[t] + 0.209 reward + 0.279 value_stay*reward + -0.318 value_stay*harvest_duration + 0.644 reward^2 + 0.213 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 82, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 551/1000 --- L(Train): 0.3663258 --- L(Val, RNN): 0.3429645 --- L(Val, SINDy): 0.3828220 --- Time: 1.66s; --- Convergence: 2.06e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 51/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.511 1 + 0.451 value_stay[t] + 0.209 reward + 0.28 value_stay*reward + -0.319 value_stay*harvest_duration + 0.643 reward^2 + 0.213 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 83, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 552/1000 --- L(Train): 0.3666076 --- L(Val, RNN): 0.3429381 --- L(Val, SINDy): 0.3827398 --- Time: 2.88s; --- Convergence: 2.35e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 52/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.512 1 + 0.45 value_stay[t] + 0.209 reward + 0.279 value_stay*reward + -0.319 value_stay*harvest_duration + 0.643 reward^2 + 0.213 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 84, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 553/1000 --- L(Train): 0.3660104 --- L(Val, RNN): 0.3429167 --- L(Val, SINDy): 0.3826372 --- Time: 4.12s; --- Convergence: 2.24e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 53/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.512 1 + 0.449 value_stay[t] + 0.209 reward + 0.279 value_stay*reward + -0.32 value_stay*harvest_duration + 0.643 reward^2 + 0.213 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 85, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 554/1000 --- L(Train): 0.3609335 --- L(Val, RNN): 0.3429018 --- L(Val, SINDy): 0.3824848 --- Time: 5.14s; --- Convergence: 1.87e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 54/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.512 1 + 0.448 value_stay[t] + 0.209 reward + 0.279 value_stay*reward + -0.321 value_stay*harvest_duration + 0.642 reward^2 + 0.213 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 86, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 555/1000 --- L(Train): 0.3621766 --- L(Val, RNN): 0.3428927 --- L(Val, SINDy): 0.3824051 --- Time: 5.45s; --- Convergence: 1.39e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 55/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.512 1 + 0.448 value_stay[t] + 0.209 reward + 0.279 value_stay*reward + -0.321 value_stay*harvest_duration + 0.642 reward^2 + 0.213 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 87, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 556/1000 --- L(Train): 0.3623827 --- L(Val, RNN): 0.3428798 --- L(Val, SINDy): 0.3823571 --- Time: 2.13s; --- Convergence: 1.34e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 56/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.512 1 + 0.447 value_stay[t] + 0.209 reward + 0.279 value_stay*reward + -0.322 value_stay*harvest_duration + 0.642 reward^2 + 0.213 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 88, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 557/1000 --- L(Train): 0.3650373 --- L(Val, RNN): 0.3428560 --- L(Val, SINDy): 0.3823522 --- Time: 1.23s; --- Convergence: 1.86e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 57/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.513 1 + 0.447 value_stay[t] + 0.21 reward + 0.28 value_stay*reward + -0.322 value_stay*harvest_duration + 0.642 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 89, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 558/1000 --- L(Train): 0.3576426 --- L(Val, RNN): 0.3428297 --- L(Val, SINDy): 0.3823220 --- Time: 1.12s; --- Convergence: 2.25e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 58/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.514 1 + 0.447 value_stay[t] + 0.21 reward + 0.281 value_stay*reward + -0.322 value_stay*harvest_duration + 0.643 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 90, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 559/1000 --- L(Train): 0.3609682 --- L(Val, RNN): 0.3428059 --- L(Val, SINDy): 0.3822565 --- Time: 1.17s; --- Convergence: 2.31e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 59/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.515 1 + 0.447 value_stay[t] + 0.211 reward + 0.282 value_stay*reward + -0.321 value_stay*harvest_duration + 0.643 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 91, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 560/1000 --- L(Train): 0.3640748 --- L(Val, RNN): 0.3427873 --- L(Val, SINDy): 0.3821236 --- Time: 1.00s; --- Convergence: 2.09e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 60/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.516 1 + 0.448 value_stay[t] + 0.212 reward + 0.283 value_stay*reward + -0.321 value_stay*harvest_duration + 0.643 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 92, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 561/1000 --- L(Train): 0.3621508 --- L(Val, RNN): 0.3427744 --- L(Val, SINDy): 0.3819216 --- Time: 0.95s; --- Convergence: 1.69e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 61/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.517 1 + 0.448 value_stay[t] + 0.212 reward + 0.283 value_stay*reward + -0.32 value_stay*harvest_duration + 0.643 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 93, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 562/1000 --- L(Train): 0.3636276 --- L(Val, RNN): 0.3427622 --- L(Val, SINDy): 0.3817240 --- Time: 0.93s; --- Convergence: 1.45e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 62/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.517 1 + 0.447 value_stay[t] + 0.211 reward + 0.283 value_stay*reward + -0.321 value_stay*harvest_duration + 0.642 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 94, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 563/1000 --- L(Train): 0.3613627 --- L(Val, RNN): 0.3427342 --- L(Val, SINDy): 0.3816149 --- Time: 0.97s; --- Convergence: 2.13e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 63/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.517 1 + 0.446 value_stay[t] + 0.21 reward + 0.283 value_stay*reward + -0.322 value_stay*harvest_duration + 0.641 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 95, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 564/1000 --- L(Train): 0.3626023 --- L(Val, RNN): 0.3427013 --- L(Val, SINDy): 0.3815654 --- Time: 1.16s; --- Convergence: 2.71e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 64/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.517 1 + 0.446 value_stay[t] + 0.21 reward + 0.283 value_stay*reward + -0.322 value_stay*harvest_duration + 0.64 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 96, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 565/1000 --- L(Train): 0.3620121 --- L(Val, RNN): 0.3426766 --- L(Val, SINDy): 0.3815646 --- Time: 1.37s; --- Convergence: 2.59e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 65/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.518 1 + 0.446 value_stay[t] + 0.211 reward + 0.284 value_stay*reward + -0.322 value_stay*harvest_duration + 0.64 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 97, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 566/1000 --- L(Train): 0.3628227 --- L(Val, RNN): 0.3426652 --- L(Val, SINDy): 0.3814716 --- Time: 1.04s; --- Convergence: 1.86e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 66/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.519 1 + 0.447 value_stay[t] + 0.211 reward + 0.285 value_stay*reward + -0.321 value_stay*harvest_duration + 0.64 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 98, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 567/1000 --- L(Train): 0.3608483 --- L(Val, RNN): 0.3426556 --- L(Val, SINDy): 0.3812990 --- Time: 1.03s; --- Convergence: 1.41e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 67/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.521 1 + 0.448 value_stay[t] + 0.212 reward + 0.287 value_stay*reward + -0.32 value_stay*harvest_duration + 0.64 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 99, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 568/1000 --- L(Train): 0.3623815 --- L(Val, RNN): 0.3426216 --- L(Val, SINDy): 0.3811940 --- Time: 1.11s; --- Convergence: 2.41e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 68/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.522 1 + 0.449 value_stay[t] + 0.213 reward + 0.288 value_stay*reward + -0.32 value_stay*harvest_duration + 0.64 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 569/1000 --- L(Train): 0.3661499 --- L(Val, RNN): 0.3425831 --- L(Val, SINDy): 0.3811698 --- Time: 0.92s; --- Convergence: 3.12e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 69/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.521 1 + 0.447 value_stay[t] + 0.212 reward + 0.286 value_stay*reward + -0.321 value_stay*harvest_duration + 0.639 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 570/1000 --- L(Train): 0.3606897 --- L(Val, RNN): 0.3425637 --- L(Val, SINDy): 0.3811240 --- Time: 1.05s; --- Convergence: 2.54e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 70/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.521 1 + 0.446 value_stay[t] + 0.21 reward + 0.285 value_stay*reward + -0.323 value_stay*harvest_duration + 0.637 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 571/1000 --- L(Train): 0.3633547 --- L(Val, RNN): 0.3425567 --- L(Val, SINDy): 0.3810612 --- Time: 0.94s; --- Convergence: 1.62e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 71/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.521 1 + 0.444 value_stay[t] + 0.21 reward + 0.285 value_stay*reward + -0.324 value_stay*harvest_duration + 0.636 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 572/1000 --- L(Train): 0.3672169 --- L(Val, RNN): 0.3425515 --- L(Val, SINDy): 0.3809696 --- Time: 0.92s; --- Convergence: 1.07e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 72/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.522 1 + 0.445 value_stay[t] + 0.21 reward + 0.286 value_stay*reward + -0.323 value_stay*harvest_duration + 0.636 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 573/1000 --- L(Train): 0.3642777 --- L(Val, RNN): 0.3425333 --- L(Val, SINDy): 0.3808821 --- Time: 0.84s; --- Convergence: 1.44e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 73/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.524 1 + 0.446 value_stay[t] + 0.211 reward + 0.288 value_stay*reward + -0.321 value_stay*harvest_duration + 0.636 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 574/1000 --- L(Train): 0.3642775 --- L(Val, RNN): 0.3425005 --- L(Val, SINDy): 0.3808663 --- Time: 0.93s; --- Convergence: 2.36e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 74/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.525 1 + 0.446 value_stay[t] + 0.211 reward + 0.288 value_stay*reward + -0.321 value_stay*harvest_duration + 0.636 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 575/1000 --- L(Train): 0.3624990 --- L(Val, RNN): 0.3424727 --- L(Val, SINDy): 0.3808321 --- Time: 0.95s; --- Convergence: 2.57e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 75/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.525 1 + 0.446 value_stay[t] + 0.211 reward + 0.289 value_stay*reward + -0.321 value_stay*harvest_duration + 0.635 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 576/1000 --- L(Train): 0.3577339 --- L(Val, RNN): 0.3424709 --- L(Val, SINDy): 0.3806777 --- Time: 1.17s; --- Convergence: 1.38e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 76/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.526 1 + 0.445 value_stay[t] + 0.211 reward + 0.289 value_stay*reward + -0.321 value_stay*harvest_duration + 0.634 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 577/1000 --- L(Train): 0.3622602 --- L(Val, RNN): 0.3424700 --- L(Val, SINDy): 0.3805240 --- Time: 0.89s; --- Convergence: 7.31e-06; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 77/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.526 1 + 0.444 value_stay[t] + 0.21 reward + 0.288 value_stay*reward + -0.322 value_stay*harvest_duration + 0.633 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 578/1000 --- L(Train): 0.3660682 --- L(Val, RNN): 0.3424579 --- L(Val, SINDy): 0.3804989 --- Time: 0.89s; --- Convergence: 9.75e-06; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 78/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.526 1 + 0.443 value_stay[t] + 0.21 reward + 0.288 value_stay*reward + -0.322 value_stay*harvest_duration + 0.631 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 579/1000 --- L(Train): 0.3619913 --- L(Val, RNN): 0.3424436 --- L(Val, SINDy): 0.3805393 --- Time: 1.24s; --- Convergence: 1.20e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 79/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.526 1 + 0.442 value_stay[t] + 0.21 reward + 0.288 value_stay*reward + -0.322 value_stay*harvest_duration + 0.63 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 580/1000 --- L(Train): 0.3619173 --- L(Val, RNN): 0.3424174 --- L(Val, SINDy): 0.3805666 --- Time: 1.18s; --- Convergence: 1.91e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 80/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.527 1 + 0.442 value_stay[t] + 0.21 reward + 0.289 value_stay*reward + -0.322 value_stay*harvest_duration + 0.63 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 581/1000 --- L(Train): 0.3659081 --- L(Val, RNN): 0.3423817 --- L(Val, SINDy): 0.3805253 --- Time: 1.13s; --- Convergence: 2.74e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 81/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.527 1 + 0.442 value_stay[t] + 0.21 reward + 0.29 value_stay*reward + -0.322 value_stay*harvest_duration + 0.63 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 582/1000 --- L(Train): 0.3644541 --- L(Val, RNN): 0.3423732 --- L(Val, SINDy): 0.3803266 --- Time: 1.20s; --- Convergence: 1.80e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 82/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.528 1 + 0.442 value_stay[t] + 0.211 reward + 0.291 value_stay*reward + -0.322 value_stay*harvest_duration + 0.63 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 583/1000 --- L(Train): 0.3615425 --- L(Val, RNN): 0.3423684 --- L(Val, SINDy): 0.3801395 --- Time: 1.23s; --- Convergence: 1.14e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 83/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.529 1 + 0.442 value_stay[t] + 0.211 reward + 0.292 value_stay*reward + -0.322 value_stay*harvest_duration + 0.63 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 584/1000 --- L(Train): 0.3658529 --- L(Val, RNN): 0.3423447 --- L(Val, SINDy): 0.3800513 --- Time: 0.87s; --- Convergence: 1.75e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 84/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.529 1 + 0.441 value_stay[t] + 0.211 reward + 0.292 value_stay*reward + -0.323 value_stay*harvest_duration + 0.629 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 585/1000 --- L(Train): 0.3599625 --- L(Val, RNN): 0.3423179 --- L(Val, SINDy): 0.3800439 --- Time: 0.87s; --- Convergence: 2.22e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 85/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.529 1 + 0.44 value_stay[t] + 0.211 reward + 0.293 value_stay*reward + -0.323 value_stay*harvest_duration + 0.628 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 586/1000 --- L(Train): 0.3605773 --- L(Val, RNN): 0.3423015 --- L(Val, SINDy): 0.3799653 --- Time: 0.90s; --- Convergence: 1.93e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 86/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.53 1 + 0.439 value_stay[t] + 0.211 reward + 0.293 value_stay*reward + -0.323 value_stay*harvest_duration + 0.628 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 587/1000 --- L(Train): 0.3604962 --- L(Val, RNN): 0.3422893 --- L(Val, SINDy): 0.3798243 --- Time: 0.98s; --- Convergence: 1.58e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 87/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.531 1 + 0.439 value_stay[t] + 0.212 reward + 0.294 value_stay*reward + -0.323 value_stay*harvest_duration + 0.627 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 588/1000 --- L(Train): 0.3681714 --- L(Val, RNN): 0.3422758 --- L(Val, SINDy): 0.3796985 --- Time: 0.92s; --- Convergence: 1.46e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 88/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.531 1 + 0.438 value_stay[t] + 0.212 reward + 0.295 value_stay*reward + -0.323 value_stay*harvest_duration + 0.627 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 589/1000 --- L(Train): 0.3643793 --- L(Val, RNN): 0.3422542 --- L(Val, SINDy): 0.3796640 --- Time: 0.97s; --- Convergence: 1.81e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 89/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.532 1 + 0.438 value_stay[t] + 0.212 reward + 0.295 value_stay*reward + -0.323 value_stay*harvest_duration + 0.627 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 590/1000 --- L(Train): 0.3615069 --- L(Val, RNN): 0.3422268 --- L(Val, SINDy): 0.3796621 --- Time: 1.06s; --- Convergence: 2.28e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 90/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.533 1 + 0.438 value_stay[t] + 0.212 reward + 0.296 value_stay*reward + -0.323 value_stay*harvest_duration + 0.627 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 591/1000 --- L(Train): 0.3656744 --- L(Val, RNN): 0.3422016 --- L(Val, SINDy): 0.3795224 --- Time: 0.90s; --- Convergence: 2.40e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 91/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.533 1 + 0.437 value_stay[t] + 0.212 reward + 0.296 value_stay*reward + -0.323 value_stay*harvest_duration + 0.626 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 592/1000 --- L(Train): 0.3643988 --- L(Val, RNN): 0.3421845 --- L(Val, SINDy): 0.3795120 --- Time: 1.02s; --- Convergence: 2.05e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 92/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.533 1 + 0.437 value_stay[t] + 0.212 reward + 0.296 value_stay*reward + -0.323 value_stay*harvest_duration + 0.625 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 593/1000 --- L(Train): 0.3698106 --- L(Val, RNN): 0.3421700 --- L(Val, SINDy): 0.3794172 --- Time: 1.04s; --- Convergence: 1.75e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 93/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.534 1 + 0.436 value_stay[t] + 0.211 reward + 0.295 value_stay*reward + -0.323 value_stay*harvest_duration + 0.624 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 594/1000 --- L(Train): 0.3619542 --- L(Val, RNN): 0.3421596 --- L(Val, SINDy): 0.3793224 --- Time: 1.09s; --- Convergence: 1.39e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 94/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.534 1 + 0.435 value_stay[t] + 0.211 reward + 0.295 value_stay*reward + -0.324 value_stay*harvest_duration + 0.623 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 595/1000 --- L(Train): 0.3608983 --- L(Val, RNN): 0.3421503 --- L(Val, SINDy): 0.3792485 --- Time: 1.22s; --- Convergence: 1.16e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 95/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.534 1 + 0.435 value_stay[t] + 0.21 reward + 0.295 value_stay*reward + -0.324 value_stay*harvest_duration + 0.622 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 596/1000 --- L(Train): 0.3583156 --- L(Val, RNN): 0.3421380 --- L(Val, SINDy): 0.3792336 --- Time: 1.02s; --- Convergence: 1.20e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 96/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.535 1 + 0.435 value_stay[t] + 0.21 reward + 0.295 value_stay*reward + -0.323 value_stay*harvest_duration + 0.621 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 597/1000 --- L(Train): 0.3661791 --- L(Val, RNN): 0.3421132 --- L(Val, SINDy): 0.3792148 --- Time: 0.91s; --- Convergence: 1.84e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 97/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.535 1 + 0.435 value_stay[t] + 0.21 reward + 0.295 value_stay*reward + -0.322 value_stay*harvest_duration + 0.62 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 598/1000 --- L(Train): 0.3616232 --- L(Val, RNN): 0.3420779 --- L(Val, SINDy): 0.3791458 --- Time: 0.95s; --- Convergence: 2.68e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 98/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.536 1 + 0.436 value_stay[t] + 0.21 reward + 0.296 value_stay*reward + -0.321 value_stay*harvest_duration + 0.62 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 599/1000 --- L(Train): 0.3621583 --- L(Val, RNN): 0.3420607 --- L(Val, SINDy): 0.3789503 --- Time: 0.86s; --- Convergence: 2.20e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 99/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.537 1 + 0.436 value_stay[t] + 0.211 reward + 0.297 value_stay*reward + -0.32 value_stay*harvest_duration + 0.62 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 600/1000 --- L(Train): 0.3589615 --- L(Val, RNN): 0.3420403 --- L(Val, SINDy): 0.3787663 --- Time: 1.04s; --- Convergence: 2.12e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.538 1 + 0.437 value_stay[t] + 0.211 reward + 0.298 value_stay*reward + -0.319 value_stay*harvest_duration + 0.62 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 601/1000 --- L(Train): 0.3620219 --- L(Val, RNN): 0.3420265 --- L(Val, SINDy): 0.3787298 --- Time: 0.94s; --- Convergence: 1.75e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 1/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.539 1 + 0.437 value_stay[t] + 0.211 reward + 0.298 value_stay*reward + -0.319 value_stay*harvest_duration + 0.62 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 602/1000 --- L(Train): 0.3634082 --- L(Val, RNN): 0.3420174 --- L(Val, SINDy): 0.3786880 --- Time: 0.95s; --- Convergence: 1.33e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 2/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.54 1 + 0.436 value_stay[t] + 0.211 reward + 0.299 value_stay*reward + -0.319 value_stay*harvest_duration + 0.619 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 603/1000 --- L(Train): 0.3645284 --- L(Val, RNN): 0.3420129 --- L(Val, SINDy): 0.3786290 --- Time: 1.00s; --- Convergence: 8.93e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 3/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.54 1 + 0.436 value_stay[t] + 0.211 reward + 0.298 value_stay*reward + -0.319 value_stay*harvest_duration + 0.618 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 604/1000 --- L(Train): 0.3642260 --- L(Val, RNN): 0.3420009 --- L(Val, SINDy): 0.3786610 --- Time: 1.09s; --- Convergence: 1.04e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 4/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.541 1 + 0.435 value_stay[t] + 0.211 reward + 0.298 value_stay*reward + -0.319 value_stay*harvest_duration + 0.618 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 605/1000 --- L(Train): 0.3574764 --- L(Val, RNN): 0.3419888 --- L(Val, SINDy): 0.3786747 --- Time: 1.03s; --- Convergence: 1.13e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 5/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.541 1 + 0.435 value_stay[t] + 0.211 reward + 0.298 value_stay*reward + -0.319 value_stay*harvest_duration + 0.617 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 606/1000 --- L(Train): 0.3643435 --- L(Val, RNN): 0.3419784 --- L(Val, SINDy): 0.3786298 --- Time: 1.14s; --- Convergence: 1.09e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 6/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.542 1 + 0.434 value_stay[t] + 0.211 reward + 0.298 value_stay*reward + -0.32 value_stay*harvest_duration + 0.616 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 607/1000 --- L(Train): 0.3567380 --- L(Val, RNN): 0.3419709 --- L(Val, SINDy): 0.3785442 --- Time: 0.80s; --- Convergence: 9.19e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 7/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.542 1 + 0.434 value_stay[t] + 0.211 reward + 0.299 value_stay*reward + -0.319 value_stay*harvest_duration + 0.616 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 608/1000 --- L(Train): 0.3588273 --- L(Val, RNN): 0.3419652 --- L(Val, SINDy): 0.3784112 --- Time: 0.83s; --- Convergence: 7.41e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 8/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.543 1 + 0.434 value_stay[t] + 0.212 reward + 0.3 value_stay*reward + -0.319 value_stay*harvest_duration + 0.617 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 609/1000 --- L(Train): 0.3619881 --- L(Val, RNN): 0.3419586 --- L(Val, SINDy): 0.3783429 --- Time: 0.97s; --- Convergence: 7.03e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 9/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.544 1 + 0.434 value_stay[t] + 0.212 reward + 0.3 value_stay*reward + -0.319 value_stay*harvest_duration + 0.617 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 610/1000 --- L(Train): 0.3657564 --- L(Val, RNN): 0.3419466 --- L(Val, SINDy): 0.3783420 --- Time: 0.88s; --- Convergence: 9.52e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 10/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.545 1 + 0.434 value_stay[t] + 0.213 reward + 0.301 value_stay*reward + -0.319 value_stay*harvest_duration + 0.617 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 611/1000 --- L(Train): 0.3663440 --- L(Val, RNN): 0.3419330 --- L(Val, SINDy): 0.3783582 --- Time: 0.92s; --- Convergence: 1.15e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 11/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.545 1 + 0.433 value_stay[t] + 0.213 reward + 0.301 value_stay*reward + -0.319 value_stay*harvest_duration + 0.617 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 612/1000 --- L(Train): 0.3650921 --- L(Val, RNN): 0.3419230 --- L(Val, SINDy): 0.3783421 --- Time: 0.86s; --- Convergence: 1.08e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 12/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.545 1 + 0.433 value_stay[t] + 0.213 reward + 0.301 value_stay*reward + -0.32 value_stay*harvest_duration + 0.616 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 613/1000 --- L(Train): 0.3624527 --- L(Val, RNN): 0.3419205 --- L(Val, SINDy): 0.3782842 --- Time: 0.82s; --- Convergence: 6.65e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 13/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.545 1 + 0.432 value_stay[t] + 0.213 reward + 0.302 value_stay*reward + -0.32 value_stay*harvest_duration + 0.616 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 614/1000 --- L(Train): 0.3618668 --- L(Val, RNN): 0.3419220 --- L(Val, SINDy): 0.3782052 --- Time: 1.02s; --- Convergence: 4.10e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 14/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.546 1 + 0.431 value_stay[t] + 0.213 reward + 0.302 value_stay*reward + -0.321 value_stay*harvest_duration + 0.616 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 615/1000 --- L(Train): 0.3629475 --- L(Val, RNN): 0.3419182 --- L(Val, SINDy): 0.3781466 --- Time: 0.84s; --- Convergence: 3.94e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 15/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.546 1 + 0.43 value_stay[t] + 0.213 reward + 0.302 value_stay*reward + -0.322 value_stay*harvest_duration + 0.615 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 616/1000 --- L(Train): 0.3676503 --- L(Val, RNN): 0.3419096 --- L(Val, SINDy): 0.3780737 --- Time: 0.99s; --- Convergence: 6.31e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 16/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.546 1 + 0.43 value_stay[t] + 0.213 reward + 0.302 value_stay*reward + -0.322 value_stay*harvest_duration + 0.615 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 617/1000 --- L(Train): 0.3621689 --- L(Val, RNN): 0.3418997 --- L(Val, SINDy): 0.3780175 --- Time: 1.19s; --- Convergence: 8.09e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 17/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.547 1 + 0.43 value_stay[t] + 0.214 reward + 0.303 value_stay*reward + -0.322 value_stay*harvest_duration + 0.615 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 618/1000 --- L(Train): 0.3588872 --- L(Val, RNN): 0.3418910 --- L(Val, SINDy): 0.3780015 --- Time: 1.12s; --- Convergence: 8.38e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 18/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.548 1 + 0.43 value_stay[t] + 0.214 reward + 0.304 value_stay*reward + -0.321 value_stay*harvest_duration + 0.615 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 619/1000 --- L(Train): 0.3660077 --- L(Val, RNN): 0.3418856 --- L(Val, SINDy): 0.3780595 --- Time: 1.33s; --- Convergence: 6.89e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 19/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.549 1 + 0.431 value_stay[t] + 0.214 reward + 0.304 value_stay*reward + -0.32 value_stay*harvest_duration + 0.614 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 620/1000 --- L(Train): 0.3615175 --- L(Val, RNN): 0.3418836 --- L(Val, SINDy): 0.3780865 --- Time: 3.26s; --- Convergence: 4.46e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 20/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.55 1 + 0.431 value_stay[t] + 0.214 reward + 0.304 value_stay*reward + -0.319 value_stay*harvest_duration + 0.613 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 621/1000 --- L(Train): 0.3642443 --- L(Val, RNN): 0.3418860 --- L(Val, SINDy): 0.3780331 --- Time: 1.99s; --- Convergence: 3.44e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 21/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.55 1 + 0.43 value_stay[t] + 0.213 reward + 0.303 value_stay*reward + -0.32 value_stay*harvest_duration + 0.612 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 622/1000 --- L(Train): 0.3612081 --- L(Val, RNN): 0.3418823 --- L(Val, SINDy): 0.3779435 --- Time: 4.06s; --- Convergence: 3.57e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 22/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.55 1 + 0.429 value_stay[t] + 0.212 reward + 0.302 value_stay*reward + -0.321 value_stay*harvest_duration + 0.61 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 623/1000 --- L(Train): 0.3656524 --- L(Val, RNN): 0.3418749 --- L(Val, SINDy): 0.3778699 --- Time: 3.32s; --- Convergence: 5.51e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 23/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.55 1 + 0.428 value_stay[t] + 0.212 reward + 0.302 value_stay*reward + -0.321 value_stay*harvest_duration + 0.609 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 624/1000 --- L(Train): 0.3598296 --- L(Val, RNN): 0.3418649 --- L(Val, SINDy): 0.3778403 --- Time: 2.09s; --- Convergence: 7.75e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 24/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.551 1 + 0.427 value_stay[t] + 0.212 reward + 0.303 value_stay*reward + -0.321 value_stay*harvest_duration + 0.609 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 625/1000 --- L(Train): 0.3591668 --- L(Val, RNN): 0.3418538 --- L(Val, SINDy): 0.3778292 --- Time: 2.29s; --- Convergence: 9.43e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 25/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.551 1 + 0.427 value_stay[t] + 0.212 reward + 0.304 value_stay*reward + -0.321 value_stay*harvest_duration + 0.609 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 626/1000 --- L(Train): 0.3616627 --- L(Val, RNN): 0.3418486 --- L(Val, SINDy): 0.3777905 --- Time: 3.55s; --- Convergence: 7.29e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 26/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.552 1 + 0.428 value_stay[t] + 0.213 reward + 0.305 value_stay*reward + -0.32 value_stay*harvest_duration + 0.609 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 627/1000 --- L(Train): 0.3562533 --- L(Val, RNN): 0.3418441 --- L(Val, SINDy): 0.3777660 --- Time: 1.87s; --- Convergence: 5.90e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 27/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.554 1 + 0.428 value_stay[t] + 0.214 reward + 0.307 value_stay*reward + -0.318 value_stay*harvest_duration + 0.609 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 628/1000 --- L(Train): 0.3664028 --- L(Val, RNN): 0.3418393 --- L(Val, SINDy): 0.3777508 --- Time: 2.75s; --- Convergence: 5.38e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 28/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.554 1 + 0.428 value_stay[t] + 0.214 reward + 0.307 value_stay*reward + -0.318 value_stay*harvest_duration + 0.608 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 629/1000 --- L(Train): 0.3591440 --- L(Val, RNN): 0.3418280 --- L(Val, SINDy): 0.3777277 --- Time: 2.46s; --- Convergence: 8.31e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 29/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.555 1 + 0.428 value_stay[t] + 0.213 reward + 0.308 value_stay*reward + -0.318 value_stay*harvest_duration + 0.607 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 630/1000 --- L(Train): 0.3659040 --- L(Val, RNN): 0.3418100 --- L(Val, SINDy): 0.3776730 --- Time: 2.92s; --- Convergence: 1.32e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 30/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.555 1 + 0.426 value_stay[t] + 0.213 reward + 0.307 value_stay*reward + -0.319 value_stay*harvest_duration + 0.606 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 631/1000 --- L(Train): 0.3611558 --- L(Val, RNN): 0.3417903 --- L(Val, SINDy): 0.3776374 --- Time: 2.68s; --- Convergence: 1.64e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 31/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.555 1 + 0.425 value_stay[t] + 0.212 reward + 0.307 value_stay*reward + -0.319 value_stay*harvest_duration + 0.605 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 632/1000 --- L(Train): 0.3613176 --- L(Val, RNN): 0.3417744 --- L(Val, SINDy): 0.3775899 --- Time: 2.49s; --- Convergence: 1.61e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 32/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.555 1 + 0.424 value_stay[t] + 0.212 reward + 0.307 value_stay*reward + -0.32 value_stay*harvest_duration + 0.604 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 633/1000 --- L(Train): 0.3632334 --- L(Val, RNN): 0.3417686 --- L(Val, SINDy): 0.3774695 --- Time: 2.16s; --- Convergence: 1.10e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 33/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.555 1 + 0.423 value_stay[t] + 0.212 reward + 0.307 value_stay*reward + -0.32 value_stay*harvest_duration + 0.603 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 634/1000 --- L(Train): 0.3653057 --- L(Val, RNN): 0.3417658 --- L(Val, SINDy): 0.3773617 --- Time: 2.85s; --- Convergence: 6.91e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 34/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.556 1 + 0.423 value_stay[t] + 0.212 reward + 0.308 value_stay*reward + -0.32 value_stay*harvest_duration + 0.603 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 635/1000 --- L(Train): 0.3574790 --- L(Val, RNN): 0.3417650 --- L(Val, SINDy): 0.3772391 --- Time: 3.38s; --- Convergence: 3.83e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 35/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.557 1 + 0.424 value_stay[t] + 0.213 reward + 0.31 value_stay*reward + -0.319 value_stay*harvest_duration + 0.604 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 636/1000 --- L(Train): 0.3648139 --- L(Val, RNN): 0.3417566 --- L(Val, SINDy): 0.3772228 --- Time: 3.39s; --- Convergence: 6.14e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 36/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.559 1 + 0.425 value_stay[t] + 0.214 reward + 0.312 value_stay*reward + -0.317 value_stay*harvest_duration + 0.604 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 637/1000 --- L(Train): 0.3590020 --- L(Val, RNN): 0.3417400 --- L(Val, SINDy): 0.3772922 --- Time: 1.77s; --- Convergence: 1.14e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 37/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.56 1 + 0.425 value_stay[t] + 0.215 reward + 0.312 value_stay*reward + -0.317 value_stay*harvest_duration + 0.604 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 638/1000 --- L(Train): 0.3648155 --- L(Val, RNN): 0.3417270 --- L(Val, SINDy): 0.3772949 --- Time: 2.30s; --- Convergence: 1.22e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 38/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.561 1 + 0.425 value_stay[t] + 0.215 reward + 0.313 value_stay*reward + -0.317 value_stay*harvest_duration + 0.603 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 639/1000 --- L(Train): 0.3640892 --- L(Val, RNN): 0.3417230 --- L(Val, SINDy): 0.3771772 --- Time: 2.10s; --- Convergence: 8.09e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 39/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.56 1 + 0.423 value_stay[t] + 0.214 reward + 0.312 value_stay*reward + -0.318 value_stay*harvest_duration + 0.601 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 640/1000 --- L(Train): 0.3602675 --- L(Val, RNN): 0.3417216 --- L(Val, SINDy): 0.3770520 --- Time: 1.91s; --- Convergence: 4.76e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 40/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.56 1 + 0.421 value_stay[t] + 0.212 reward + 0.31 value_stay*reward + -0.32 value_stay*harvest_duration + 0.6 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 641/1000 --- L(Train): 0.3576217 --- L(Val, RNN): 0.3417166 --- L(Val, SINDy): 0.3769947 --- Time: 0.88s; --- Convergence: 4.85e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 41/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.56 1 + 0.421 value_stay[t] + 0.212 reward + 0.31 value_stay*reward + -0.321 value_stay*harvest_duration + 0.599 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 642/1000 --- L(Train): 0.3660133 --- L(Val, RNN): 0.3417084 --- L(Val, SINDy): 0.3770321 --- Time: 0.90s; --- Convergence: 6.52e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 42/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.561 1 + 0.42 value_stay[t] + 0.212 reward + 0.311 value_stay*reward + -0.321 value_stay*harvest_duration + 0.598 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 643/1000 --- L(Train): 0.3546817 --- L(Val, RNN): 0.3417006 --- L(Val, SINDy): 0.3771248 --- Time: 1.20s; --- Convergence: 7.20e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 43/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.562 1 + 0.421 value_stay[t] + 0.213 reward + 0.313 value_stay*reward + -0.319 value_stay*harvest_duration + 0.598 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 644/1000 --- L(Train): 0.3588096 --- L(Val, RNN): 0.3416958 --- L(Val, SINDy): 0.3770957 --- Time: 1.14s; --- Convergence: 5.95e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 44/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.564 1 + 0.423 value_stay[t] + 0.214 reward + 0.314 value_stay*reward + -0.318 value_stay*harvest_duration + 0.598 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 645/1000 --- L(Train): 0.3636984 --- L(Val, RNN): 0.3416950 --- L(Val, SINDy): 0.3770362 --- Time: 1.03s; --- Convergence: 3.39e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 45/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.565 1 + 0.423 value_stay[t] + 0.215 reward + 0.316 value_stay*reward + -0.317 value_stay*harvest_duration + 0.598 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 646/1000 --- L(Train): 0.3630505 --- L(Val, RNN): 0.3416893 --- L(Val, SINDy): 0.3768636 --- Time: 1.22s; --- Convergence: 4.53e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 46/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.566 1 + 0.423 value_stay[t] + 0.214 reward + 0.316 value_stay*reward + -0.316 value_stay*harvest_duration + 0.597 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 647/1000 --- L(Train): 0.3605965 --- L(Val, RNN): 0.3416797 --- L(Val, SINDy): 0.3768050 --- Time: 0.90s; --- Convergence: 7.11e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 47/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.566 1 + 0.422 value_stay[t] + 0.213 reward + 0.314 value_stay*reward + -0.318 value_stay*harvest_duration + 0.595 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 648/1000 --- L(Train): 0.3639513 --- L(Val, RNN): 0.3416632 --- L(Val, SINDy): 0.3768978 --- Time: 0.90s; --- Convergence: 1.18e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 48/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.565 1 + 0.42 value_stay[t] + 0.211 reward + 0.313 value_stay*reward + -0.319 value_stay*harvest_duration + 0.593 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 649/1000 --- L(Train): 0.3573262 --- L(Val, RNN): 0.3416502 --- L(Val, SINDy): 0.3770624 --- Time: 0.90s; --- Convergence: 1.24e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 49/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.565 1 + 0.419 value_stay[t] + 0.21 reward + 0.311 value_stay*reward + -0.32 value_stay*harvest_duration + 0.591 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 650/1000 --- L(Train): 0.3599604 --- L(Val, RNN): 0.3416466 --- L(Val, SINDy): 0.3770877 --- Time: 0.92s; --- Convergence: 8.01e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 50/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.566 1 + 0.419 value_stay[t] + 0.21 reward + 0.312 value_stay*reward + -0.319 value_stay*harvest_duration + 0.591 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 651/1000 --- L(Train): 0.3624707 --- L(Val, RNN): 0.3416475 --- L(Val, SINDy): 0.3769781 --- Time: 1.17s; --- Convergence: 4.45e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 51/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.567 1 + 0.42 value_stay[t] + 0.211 reward + 0.313 value_stay*reward + -0.317 value_stay*harvest_duration + 0.591 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 652/1000 --- L(Train): 0.3636895 --- L(Val, RNN): 0.3416509 --- L(Val, SINDy): 0.3767871 --- Time: 1.03s; --- Convergence: 3.92e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 52/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.568 1 + 0.421 value_stay[t] + 0.211 reward + 0.314 value_stay*reward + -0.316 value_stay*harvest_duration + 0.591 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 653/1000 --- L(Train): 0.3607150 --- L(Val, RNN): 0.3416485 --- L(Val, SINDy): 0.3766414 --- Time: 0.88s; --- Convergence: 3.17e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 53/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.569 1 + 0.421 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.315 value_stay*harvest_duration + 0.59 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 654/1000 --- L(Train): 0.3557492 --- L(Val, RNN): 0.3416319 --- L(Val, SINDy): 0.3766315 --- Time: 1.29s; --- Convergence: 9.88e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 54/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.57 1 + 0.421 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.315 value_stay*harvest_duration + 0.59 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 655/1000 --- L(Train): 0.3625109 --- L(Val, RNN): 0.3416095 --- L(Val, SINDy): 0.3767032 --- Time: 1.44s; --- Convergence: 1.61e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 55/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.57 1 + 0.42 value_stay[t] + 0.212 reward + 0.316 value_stay*reward + -0.315 value_stay*harvest_duration + 0.59 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 656/1000 --- L(Train): 0.3608837 --- L(Val, RNN): 0.3415927 --- L(Val, SINDy): 0.3767112 --- Time: 1.62s; --- Convergence: 1.65e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 56/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.571 1 + 0.42 value_stay[t] + 0.212 reward + 0.316 value_stay*reward + -0.314 value_stay*harvest_duration + 0.59 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 657/1000 --- L(Train): 0.3625047 --- L(Val, RNN): 0.3415880 --- L(Val, SINDy): 0.3766240 --- Time: 1.19s; --- Convergence: 1.06e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 57/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.571 1 + 0.419 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.315 value_stay*harvest_duration + 0.589 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 658/1000 --- L(Train): 0.3610261 --- L(Val, RNN): 0.3415899 --- L(Val, SINDy): 0.3765411 --- Time: 1.14s; --- Convergence: 6.21e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 58/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.571 1 + 0.417 value_stay[t] + 0.211 reward + 0.314 value_stay*reward + -0.316 value_stay*harvest_duration + 0.588 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 659/1000 --- L(Train): 0.3572452 --- L(Val, RNN): 0.3415890 --- L(Val, SINDy): 0.3764585 --- Time: 1.04s; --- Convergence: 3.52e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 59/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.57 1 + 0.416 value_stay[t] + 0.21 reward + 0.313 value_stay*reward + -0.317 value_stay*harvest_duration + 0.587 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 660/1000 --- L(Train): 0.3606377 --- L(Val, RNN): 0.3415786 --- L(Val, SINDy): 0.3764251 --- Time: 0.94s; --- Convergence: 6.98e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 60/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.571 1 + 0.416 value_stay[t] + 0.21 reward + 0.314 value_stay*reward + -0.316 value_stay*harvest_duration + 0.586 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 661/1000 --- L(Train): 0.3598684 --- L(Val, RNN): 0.3415594 --- L(Val, SINDy): 0.3763767 --- Time: 1.07s; --- Convergence: 1.31e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 61/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.573 1 + 0.416 value_stay[t] + 0.211 reward + 0.314 value_stay*reward + -0.316 value_stay*harvest_duration + 0.587 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 662/1000 --- L(Train): 0.3643670 --- L(Val, RNN): 0.3415404 --- L(Val, SINDy): 0.3764144 --- Time: 1.29s; --- Convergence: 1.60e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 62/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.574 1 + 0.417 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.314 value_stay*harvest_duration + 0.587 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 663/1000 --- L(Train): 0.3637523 --- L(Val, RNN): 0.3415310 --- L(Val, SINDy): 0.3763593 --- Time: 1.01s; --- Convergence: 1.27e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 63/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.575 1 + 0.418 value_stay[t] + 0.212 reward + 0.316 value_stay*reward + -0.313 value_stay*harvest_duration + 0.587 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 664/1000 --- L(Train): 0.3600869 --- L(Val, RNN): 0.3415297 --- L(Val, SINDy): 0.3762352 --- Time: 0.97s; --- Convergence: 7.04e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 64/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.576 1 + 0.418 value_stay[t] + 0.212 reward + 0.316 value_stay*reward + -0.313 value_stay*harvest_duration + 0.587 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 665/1000 --- L(Train): 0.3585068 --- L(Val, RNN): 0.3415238 --- L(Val, SINDy): 0.3761833 --- Time: 1.16s; --- Convergence: 6.47e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 65/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.576 1 + 0.417 value_stay[t] + 0.212 reward + 0.316 value_stay*reward + -0.313 value_stay*harvest_duration + 0.586 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 666/1000 --- L(Train): 0.3579481 --- L(Val, RNN): 0.3415175 --- L(Val, SINDy): 0.3761733 --- Time: 1.24s; --- Convergence: 6.38e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 66/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.576 1 + 0.416 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.314 value_stay*harvest_duration + 0.586 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 667/1000 --- L(Train): 0.3649154 --- L(Val, RNN): 0.3415122 --- L(Val, SINDy): 0.3761111 --- Time: 1.18s; --- Convergence: 5.81e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 67/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.577 1 + 0.415 value_stay[t] + 0.211 reward + 0.314 value_stay*reward + -0.314 value_stay*harvest_duration + 0.585 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 668/1000 --- L(Train): 0.3626155 --- L(Val, RNN): 0.3415118 --- L(Val, SINDy): 0.3760544 --- Time: 1.24s; --- Convergence: 3.13e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 68/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.577 1 + 0.415 value_stay[t] + 0.211 reward + 0.314 value_stay*reward + -0.314 value_stay*harvest_duration + 0.585 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 669/1000 --- L(Train): 0.3628088 --- L(Val, RNN): 0.3415109 --- L(Val, SINDy): 0.3760453 --- Time: 1.01s; --- Convergence: 2.01e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 69/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.578 1 + 0.414 value_stay[t] + 0.211 reward + 0.314 value_stay*reward + -0.314 value_stay*harvest_duration + 0.584 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 670/1000 --- L(Train): 0.3598355 --- L(Val, RNN): 0.3415110 --- L(Val, SINDy): 0.3760951 --- Time: 1.02s; --- Convergence: 1.04e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 70/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.579 1 + 0.415 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.313 value_stay*harvest_duration + 0.585 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 671/1000 --- L(Train): 0.3649501 --- L(Val, RNN): 0.3415113 --- L(Val, SINDy): 0.3761322 --- Time: 1.16s; --- Convergence: 7.12e-07; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 71/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.58 1 + 0.415 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.312 value_stay*harvest_duration + 0.585 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 672/1000 --- L(Train): 0.3583632 --- L(Val, RNN): 0.3415067 --- L(Val, SINDy): 0.3761136 --- Time: 1.13s; --- Convergence: 2.68e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 72/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.581 1 + 0.415 value_stay[t] + 0.212 reward + 0.316 value_stay*reward + -0.311 value_stay*harvest_duration + 0.585 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 673/1000 --- L(Train): 0.3589538 --- L(Val, RNN): 0.3414986 --- L(Val, SINDy): 0.3760851 --- Time: 0.98s; --- Convergence: 5.39e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 73/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.582 1 + 0.415 value_stay[t] + 0.212 reward + 0.316 value_stay*reward + -0.311 value_stay*harvest_duration + 0.585 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 674/1000 --- L(Train): 0.3595826 --- L(Val, RNN): 0.3414883 --- L(Val, SINDy): 0.3760397 --- Time: 0.93s; --- Convergence: 7.82e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 74/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.582 1 + 0.415 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.311 value_stay*harvest_duration + 0.584 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 675/1000 --- L(Train): 0.3609232 --- L(Val, RNN): 0.3414819 --- L(Val, SINDy): 0.3759878 --- Time: 0.98s; --- Convergence: 7.13e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 75/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.583 1 + 0.415 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.311 value_stay*harvest_duration + 0.584 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 676/1000 --- L(Train): 0.3568865 --- L(Val, RNN): 0.3414816 --- L(Val, SINDy): 0.3759101 --- Time: 1.19s; --- Convergence: 3.71e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 76/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.583 1 + 0.414 value_stay[t] + 0.212 reward + 0.314 value_stay*reward + -0.311 value_stay*harvest_duration + 0.583 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 677/1000 --- L(Train): 0.3592932 --- L(Val, RNN): 0.3414803 --- L(Val, SINDy): 0.3758247 --- Time: 0.95s; --- Convergence: 2.53e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 77/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.583 1 + 0.413 value_stay[t] + 0.212 reward + 0.314 value_stay*reward + -0.312 value_stay*harvest_duration + 0.583 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 678/1000 --- L(Train): 0.3604621 --- L(Val, RNN): 0.3414704 --- L(Val, SINDy): 0.3757730 --- Time: 1.13s; --- Convergence: 6.20e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 78/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.584 1 + 0.413 value_stay[t] + 0.212 reward + 0.314 value_stay*reward + -0.312 value_stay*harvest_duration + 0.583 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 679/1000 --- L(Train): 0.3585027 --- L(Val, RNN): 0.3414547 --- L(Val, SINDy): 0.3757894 --- Time: 0.97s; --- Convergence: 1.09e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 79/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.584 1 + 0.413 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.312 value_stay*harvest_duration + 0.583 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 680/1000 --- L(Train): 0.3581427 --- L(Val, RNN): 0.3414408 --- L(Val, SINDy): 0.3757972 --- Time: 0.96s; --- Convergence: 1.24e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 80/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.585 1 + 0.413 value_stay[t] + 0.213 reward + 0.316 value_stay*reward + -0.312 value_stay*harvest_duration + 0.584 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 681/1000 --- L(Train): 0.3588038 --- L(Val, RNN): 0.3414340 --- L(Val, SINDy): 0.3757443 --- Time: 1.09s; --- Convergence: 9.60e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 81/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.586 1 + 0.413 value_stay[t] + 0.214 reward + 0.317 value_stay*reward + -0.312 value_stay*harvest_duration + 0.585 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 682/1000 --- L(Train): 0.3685688 --- L(Val, RNN): 0.3414296 --- L(Val, SINDy): 0.3756595 --- Time: 0.91s; --- Convergence: 7.01e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 82/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.586 1 + 0.412 value_stay[t] + 0.214 reward + 0.317 value_stay*reward + -0.312 value_stay*harvest_duration + 0.585 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 683/1000 --- L(Train): 0.3618478 --- L(Val, RNN): 0.3414228 --- L(Val, SINDy): 0.3755871 --- Time: 1.26s; --- Convergence: 6.90e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 83/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.586 1 + 0.412 value_stay[t] + 0.214 reward + 0.318 value_stay*reward + -0.312 value_stay*harvest_duration + 0.585 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 684/1000 --- L(Train): 0.3588219 --- L(Val, RNN): 0.3414117 --- L(Val, SINDy): 0.3755218 --- Time: 0.96s; --- Convergence: 9.01e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 84/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.587 1 + 0.412 value_stay[t] + 0.215 reward + 0.318 value_stay*reward + -0.312 value_stay*harvest_duration + 0.585 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 685/1000 --- L(Train): 0.3667223 --- L(Val, RNN): 0.3413967 --- L(Val, SINDy): 0.3755517 --- Time: 0.89s; --- Convergence: 1.20e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 85/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.587 1 + 0.411 value_stay[t] + 0.215 reward + 0.319 value_stay*reward + -0.313 value_stay*harvest_duration + 0.585 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 686/1000 --- L(Train): 0.3570832 --- L(Val, RNN): 0.3413818 --- L(Val, SINDy): 0.3755606 --- Time: 0.98s; --- Convergence: 1.35e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 86/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.588 1 + 0.411 value_stay[t] + 0.215 reward + 0.32 value_stay*reward + -0.314 value_stay*harvest_duration + 0.585 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 687/1000 --- L(Train): 0.3603348 --- L(Val, RNN): 0.3413779 --- L(Val, SINDy): 0.3754926 --- Time: 1.15s; --- Convergence: 8.71e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 87/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.588 1 + 0.41 value_stay[t] + 0.216 reward + 0.32 value_stay*reward + -0.314 value_stay*harvest_duration + 0.585 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 688/1000 --- L(Train): 0.3593707 --- L(Val, RNN): 0.3413732 --- L(Val, SINDy): 0.3753872 --- Time: 0.93s; --- Convergence: 6.69e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 88/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.589 1 + 0.41 value_stay[t] + 0.216 reward + 0.321 value_stay*reward + -0.314 value_stay*harvest_duration + 0.584 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 689/1000 --- L(Train): 0.3586486 --- L(Val, RNN): 0.3413670 --- L(Val, SINDy): 0.3753463 --- Time: 0.85s; --- Convergence: 6.45e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 89/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.589 1 + 0.41 value_stay[t] + 0.216 reward + 0.321 value_stay*reward + -0.314 value_stay*harvest_duration + 0.584 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 690/1000 --- L(Train): 0.3627514 --- L(Val, RNN): 0.3413566 --- L(Val, SINDy): 0.3753290 --- Time: 1.05s; --- Convergence: 8.41e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 90/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.59 1 + 0.41 value_stay[t] + 0.216 reward + 0.322 value_stay*reward + -0.315 value_stay*harvest_duration + 0.583 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 691/1000 --- L(Train): 0.3606988 --- L(Val, RNN): 0.3413469 --- L(Val, SINDy): 0.3752808 --- Time: 1.04s; --- Convergence: 9.03e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 91/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.59 1 + 0.409 value_stay[t] + 0.216 reward + 0.322 value_stay*reward + -0.315 value_stay*harvest_duration + 0.583 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 692/1000 --- L(Train): 0.3638946 --- L(Val, RNN): 0.3413372 --- L(Val, SINDy): 0.3752518 --- Time: 0.85s; --- Convergence: 9.40e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 92/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.591 1 + 0.409 value_stay[t] + 0.216 reward + 0.323 value_stay*reward + -0.315 value_stay*harvest_duration + 0.582 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 693/1000 --- L(Train): 0.3663177 --- L(Val, RNN): 0.3413325 --- L(Val, SINDy): 0.3751965 --- Time: 0.96s; --- Convergence: 7.03e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 93/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.591 1 + 0.409 value_stay[t] + 0.216 reward + 0.323 value_stay*reward + -0.315 value_stay*harvest_duration + 0.581 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 694/1000 --- L(Train): 0.3607577 --- L(Val, RNN): 0.3413276 --- L(Val, SINDy): 0.3751430 --- Time: 0.94s; --- Convergence: 5.97e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 94/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.592 1 + 0.409 value_stay[t] + 0.215 reward + 0.323 value_stay*reward + -0.315 value_stay*harvest_duration + 0.581 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 695/1000 --- L(Train): 0.3553823 --- L(Val, RNN): 0.3413230 --- L(Val, SINDy): 0.3751180 --- Time: 0.86s; --- Convergence: 5.28e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 95/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.592 1 + 0.409 value_stay[t] + 0.215 reward + 0.323 value_stay*reward + -0.315 value_stay*harvest_duration + 0.58 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 696/1000 --- L(Train): 0.3597292 --- L(Val, RNN): 0.3413173 --- L(Val, SINDy): 0.3751266 --- Time: 1.03s; --- Convergence: 5.50e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 96/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.593 1 + 0.409 value_stay[t] + 0.215 reward + 0.324 value_stay*reward + -0.315 value_stay*harvest_duration + 0.58 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 697/1000 --- L(Train): 0.3615157 --- L(Val, RNN): 0.3413113 --- L(Val, SINDy): 0.3751179 --- Time: 0.96s; --- Convergence: 5.76e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 97/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.593 1 + 0.408 value_stay[t] + 0.216 reward + 0.325 value_stay*reward + -0.315 value_stay*harvest_duration + 0.579 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 698/1000 --- L(Train): 0.3601859 --- L(Val, RNN): 0.3412984 --- L(Val, SINDy): 0.3751273 --- Time: 0.86s; --- Convergence: 9.32e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 98/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.593 1 + 0.408 value_stay[t] + 0.216 reward + 0.326 value_stay*reward + -0.315 value_stay*harvest_duration + 0.579 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 699/1000 --- L(Train): 0.3565252 --- L(Val, RNN): 0.3412854 --- L(Val, SINDy): 0.3750554 --- Time: 0.96s; --- Convergence: 1.12e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 99/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.593 1 + 0.407 value_stay[t] + 0.216 reward + 0.327 value_stay*reward + -0.315 value_stay*harvest_duration + 0.579 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 700/1000 --- L(Train): 0.3655179 --- L(Val, RNN): 0.3412765 --- L(Val, SINDy): 0.3749119 --- Time: 1.13s; --- Convergence: 1.00e-05; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.594 1 + 0.407 value_stay[t] + 0.216 reward + 0.327 value_stay*reward + -0.316 value_stay*harvest_duration + 0.578 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 701/1000 --- L(Train): 0.3644591 --- L(Val, RNN): 0.3412745 --- L(Val, SINDy): 0.3747798 --- Time: 1.44s; --- Convergence: 6.02e-06; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 1/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.594 1 + 0.406 value_stay[t] + 0.216 reward + 0.328 value_stay*reward + -0.316 value_stay*harvest_duration + 0.578 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 702/1000 --- L(Train): 0.3581049 --- L(Val, RNN): 0.3412731 --- L(Val, SINDy): 0.3747279 --- Time: 1.57s; --- Convergence: 3.69e-06; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 2/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.594 1 + 0.406 value_stay[t] + 0.216 reward + 0.329 value_stay*reward + -0.316 value_stay*harvest_duration + 0.577 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 703/1000 --- L(Train): 0.3628161 --- L(Val, RNN): 0.3412689 --- L(Val, SINDy): 0.3748184 --- Time: 1.87s; --- Convergence: 3.98e-06; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 3/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.594 1 + 0.405 value_stay[t] + 0.216 reward + 0.329 value_stay*reward + -0.316 value_stay*harvest_duration + 0.577 reward^2 + 0.221 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 704/1000 --- L(Train): 0.3592226 --- L(Val, RNN): 0.3412651 --- L(Val, SINDy): 0.3748671 --- Time: 4.17s; --- Convergence: 3.87e-06; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 4/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.594 1 + 0.405 value_stay[t] + 0.216 reward + 0.33 value_stay*reward + -0.317 value_stay*harvest_duration + 0.576 reward^2 + 0.221 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 705/1000 --- L(Train): 0.3589009 --- L(Val, RNN): 0.3412605 --- L(Val, SINDy): 0.3748213 --- Time: 5.31s; --- Convergence: 4.23e-06; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 5/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.594 1 + 0.404 value_stay[t] + 0.216 reward + 0.331 value_stay*reward + -0.317 value_stay*harvest_duration + 0.576 reward^2 + 0.221 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 706/1000 --- L(Train): 0.3600669 --- L(Val, RNN): 0.3412542 --- L(Val, SINDy): 0.3747756 --- Time: 5.91s; --- Convergence: 5.27e-06; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 6/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.594 1 + 0.403 value_stay[t] + 0.217 reward + 0.332 value_stay*reward + -0.318 value_stay*harvest_duration + 0.576 reward^2 + 0.221 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 707/1000 --- L(Train): 0.3615042 --- L(Val, RNN): 0.3412496 --- L(Val, SINDy): 0.3747495 --- Time: 5.94s; --- Convergence: 4.93e-06; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 7/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.595 1 + 0.403 value_stay[t] + 0.217 reward + 0.334 value_stay*reward + -0.318 value_stay*harvest_duration + 0.575 reward^2 + 0.221 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 708/1000 --- L(Train): 0.3549580 --- L(Val, RNN): 0.3412451 --- L(Val, SINDy): 0.3747332 --- Time: 2.09s; --- Convergence: 4.75e-06; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 8/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.596 1 + 0.404 value_stay[t] + 0.218 reward + 0.336 value_stay*reward + -0.317 value_stay*harvest_duration + 0.575 reward^2 + 0.222 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 709/1000 --- L(Train): 0.3633988 --- L(Val, RNN): 0.3412420 --- L(Val, SINDy): 0.3747146 --- Time: 3.94s; --- Convergence: 3.88e-06; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 9/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.596 1 + 0.404 value_stay[t] + 0.218 reward + 0.337 value_stay*reward + -0.317 value_stay*harvest_duration + 0.575 reward^2 + 0.222 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\n",
      "Training interrupted. Continuing with further operations...\n",
      "\n",
      "================================================================================\n",
      "Starting second stage SINDy fitting (threshold=0.05, single model)\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 1/1000 --- L(Train): 0.0679438 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.01 1 + 0.991 value_stay[t] + 0.009 reward + 0.01 harvest_duration + -0.011 value_stay^2 + -0.009 value_stay*reward + -0.01 value_stay*harvest_duration + 0.011 reward^2 + 0.009 reward*harvest_duration + 0.01 harvest_duration^2 \n",
      "value_exit[t+1] = 0.009 1 + 0.991 value_exit[t] + 0.01 travel_duration + 0.01 value_exit^2 + -0.011 value_exit*travel_duration + 0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 2/1000 --- L(Train): 0.3698150 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.008 1 + 0.981 value_stay[t] + 0.019 reward + 0.009 harvest_duration + -0.021 value_stay^2 + -0.019 value_stay*reward + -0.02 value_stay*harvest_duration + 0.021 reward^2 + 0.019 reward*harvest_duration + 0.009 harvest_duration^2 \n",
      "value_exit[t+1] = 0.001 1 + 0.998 value_exit[t] + 0.002 travel_duration + 0.003 value_exit^2 + -0.004 value_exit*travel_duration + 0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 3/1000 --- L(Train): 0.0769846 --- L(Val, SINDy): 0.0000000 --- Time: 0.27s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.011 1 + 0.971 value_stay[t] + 0.028 reward + 0.011 harvest_duration + -0.031 value_stay^2 + -0.026 value_stay*reward + -0.03 value_stay*harvest_duration + 0.031 reward^2 + 0.029 reward*harvest_duration + 0.012 harvest_duration^2 \n",
      "value_exit[t+1] = -0.006 1 + 1.006 value_exit[t] + -0.005 travel_duration + -0.004 value_exit^2 + 0.003 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 4/1000 --- L(Train): 0.1222406 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.017 1 + 0.961 value_stay[t] + 0.038 reward + 0.017 harvest_duration + -0.041 value_stay^2 + -0.03 value_stay*reward + -0.04 value_stay*harvest_duration + 0.041 reward^2 + 0.039 reward*harvest_duration + 0.017 harvest_duration^2 \n",
      "value_exit[t+1] = -0.009 1 + 1.008 value_exit[t] + -0.008 travel_duration + -0.007 value_exit^2 + 0.006 value_exit*travel_duration + -0.008 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 5/1000 --- L(Train): 0.2250931 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.023 1 + 0.952 value_stay[t] + 0.048 reward + 0.023 harvest_duration + -0.05 value_stay^2 + -0.031 value_stay*reward + -0.049 value_stay*harvest_duration + 0.051 reward^2 + 0.049 reward*harvest_duration + 0.023 harvest_duration^2 \n",
      "value_exit[t+1] = -0.008 1 + 1.007 value_exit[t] + -0.007 travel_duration + -0.006 value_exit^2 + 0.005 value_exit*travel_duration + -0.007 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 6/1000 --- L(Train): 0.1682639 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.028 1 + 0.943 value_stay[t] + 0.058 reward + 0.028 harvest_duration + -0.06 value_stay^2 + -0.032 value_stay*reward + -0.059 value_stay*harvest_duration + 0.061 reward^2 + 0.058 reward*harvest_duration + 0.028 harvest_duration^2 \n",
      "value_exit[t+1] = -0.005 1 + 1.004 value_exit[t] + -0.004 travel_duration + -0.003 value_exit^2 + 0.002 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 7/1000 --- L(Train): 0.0702509 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.031 1 + 0.933 value_stay[t] + 0.068 reward + 0.031 harvest_duration + -0.07 value_stay^2 + -0.033 value_stay*reward + -0.068 value_stay*harvest_duration + 0.071 reward^2 + 0.068 reward*harvest_duration + 0.031 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 1.0 value_exit[t] + -0.0 travel_duration + 0.001 value_exit^2 + -0.002 value_exit*travel_duration + 0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 8/1000 --- L(Train): 0.0426422 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.033 1 + 0.923 value_stay[t] + 0.078 reward + 0.033 harvest_duration + -0.079 value_stay^2 + -0.034 value_stay*reward + -0.078 value_stay*harvest_duration + 0.08 reward^2 + 0.078 reward*harvest_duration + 0.033 harvest_duration^2 \n",
      "value_exit[t+1] = 0.002 1 + 0.997 value_exit[t] + 0.003 travel_duration + 0.004 value_exit^2 + -0.005 value_exit*travel_duration + 0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 9/1000 --- L(Train): 0.0864310 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.035 1 + 0.914 value_stay[t] + 0.087 reward + 0.035 harvest_duration + -0.088 value_stay^2 + -0.032 value_stay*reward + -0.087 value_stay*harvest_duration + 0.09 reward^2 + 0.087 reward*harvest_duration + 0.035 harvest_duration^2 \n",
      "value_exit[t+1] = 0.004 1 + 0.995 value_exit[t] + 0.005 travel_duration + 0.006 value_exit^2 + -0.007 value_exit*travel_duration + 0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 10/1000 --- L(Train): 0.1216199 --- L(Val, SINDy): 0.0000000 --- Time: 0.28s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.905 value_stay[t] + 0.097 reward + 0.038 harvest_duration + -0.097 value_stay^2 + -0.029 value_stay*reward + -0.096 value_stay*harvest_duration + 0.1 reward^2 + 0.097 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = 0.004 1 + 0.995 value_exit[t] + 0.005 travel_duration + 0.006 value_exit^2 + -0.007 value_exit*travel_duration + 0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 11/1000 --- L(Train): 0.1028378 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.896 value_stay[t] + 0.106 reward + 0.042 harvest_duration + -0.106 value_stay^2 + -0.023 value_stay*reward + -0.105 value_stay*harvest_duration + 0.109 reward^2 + 0.107 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.002 1 + 0.996 value_exit[t] + 0.003 travel_duration + 0.005 value_exit^2 + -0.006 value_exit*travel_duration + 0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 12/1000 --- L(Train): 0.0567309 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.887 value_stay[t] + 0.116 reward + 0.045 harvest_duration + -0.114 value_stay^2 + -0.017 value_stay*reward + -0.114 value_stay*harvest_duration + 0.119 reward^2 + 0.116 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.998 value_exit[t] + 0.001 travel_duration + 0.003 value_exit^2 + -0.004 value_exit*travel_duration + 0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 13/1000 --- L(Train): 0.0295713 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.879 value_stay[t] + 0.126 reward + 0.048 harvest_duration + -0.123 value_stay^2 + -0.01 value_stay*reward + -0.122 value_stay*harvest_duration + 0.129 reward^2 + 0.126 reward*harvest_duration + 0.049 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 1.0 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.002 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 14/1000 --- L(Train): 0.0386319 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.05 1 + 0.87 value_stay[t] + 0.135 reward + 0.05 harvest_duration + -0.131 value_stay^2 + -0.003 value_stay*reward + -0.131 value_stay*harvest_duration + 0.138 reward^2 + 0.135 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = -0.004 1 + 1.002 value_exit[t] + -0.003 travel_duration + -0.001 value_exit^2 + -0.0 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 15/1000 --- L(Train): 0.0618805 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.051 1 + 0.862 value_stay[t] + 0.144 reward + 0.051 harvest_duration + -0.139 value_stay^2 + 0.005 value_stay*reward + -0.139 value_stay*harvest_duration + 0.147 reward^2 + 0.144 reward*harvest_duration + 0.051 harvest_duration^2 \n",
      "value_exit[t+1] = -0.005 1 + 1.003 value_exit[t] + -0.004 travel_duration + -0.002 value_exit^2 + 0.001 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 16/1000 --- L(Train): 0.0681846 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.052 1 + 0.854 value_stay[t] + 0.153 reward + 0.052 harvest_duration + -0.146 value_stay^2 + 0.013 value_stay*reward + -0.147 value_stay*harvest_duration + 0.156 reward^2 + 0.154 reward*harvest_duration + 0.052 harvest_duration^2 \n",
      "value_exit[t+1] = -0.005 1 + 1.003 value_exit[t] + -0.004 travel_duration + -0.002 value_exit^2 + 0.0 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 17/1000 --- L(Train): 0.0511231 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.054 1 + 0.846 value_stay[t] + 0.162 reward + 0.054 harvest_duration + -0.153 value_stay^2 + 0.021 value_stay*reward + -0.155 value_stay*harvest_duration + 0.165 reward^2 + 0.163 reward*harvest_duration + 0.054 harvest_duration^2 \n",
      "value_exit[t+1] = -0.004 1 + 1.001 value_exit[t] + -0.003 travel_duration + -0.001 value_exit^2 + -0.001 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 18/1000 --- L(Train): 0.0289331 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.056 1 + 0.839 value_stay[t] + 0.171 reward + 0.056 harvest_duration + -0.16 value_stay^2 + 0.03 value_stay*reward + -0.162 value_stay*harvest_duration + 0.174 reward^2 + 0.172 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.999 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.003 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 19/1000 --- L(Train): 0.0210141 --- L(Val, SINDy): 0.0000000 --- Time: 0.29s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.058 1 + 0.832 value_stay[t] + 0.18 reward + 0.058 harvest_duration + -0.166 value_stay^2 + 0.039 value_stay*reward + -0.169 value_stay*harvest_duration + 0.183 reward^2 + 0.18 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.997 value_exit[t] + 0.001 travel_duration + 0.003 value_exit^2 + -0.005 value_exit*travel_duration + 0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 20/1000 --- L(Train): 0.0292556 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.06 1 + 0.825 value_stay[t] + 0.189 reward + 0.06 harvest_duration + -0.172 value_stay^2 + 0.049 value_stay*reward + -0.176 value_stay*harvest_duration + 0.192 reward^2 + 0.189 reward*harvest_duration + 0.06 harvest_duration^2 \n",
      "value_exit[t+1] = 0.001 1 + 0.996 value_exit[t] + 0.002 travel_duration + 0.005 value_exit^2 + -0.006 value_exit*travel_duration + 0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 21/1000 --- L(Train): 0.0395570 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.06 1 + 0.819 value_stay[t] + 0.197 reward + 0.06 harvest_duration + -0.178 value_stay^2 + 0.058 value_stay*reward + -0.183 value_stay*harvest_duration + 0.2 reward^2 + 0.198 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = 0.002 1 + 0.995 value_exit[t] + 0.002 travel_duration + 0.005 value_exit^2 + -0.007 value_exit*travel_duration + 0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 22/1000 --- L(Train): 0.0389137 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.06 1 + 0.812 value_stay[t] + 0.206 reward + 0.06 harvest_duration + -0.183 value_stay^2 + 0.067 value_stay*reward + -0.189 value_stay*harvest_duration + 0.208 reward^2 + 0.206 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = 0.001 1 + 0.995 value_exit[t] + 0.002 travel_duration + 0.005 value_exit^2 + -0.007 value_exit*travel_duration + 0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 23/1000 --- L(Train): 0.0281515 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.06 1 + 0.806 value_stay[t] + 0.214 reward + 0.06 harvest_duration + -0.188 value_stay^2 + 0.077 value_stay*reward + -0.195 value_stay*harvest_duration + 0.217 reward^2 + 0.214 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.996 value_exit[t] + 0.001 travel_duration + 0.004 value_exit^2 + -0.006 value_exit*travel_duration + 0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 24/1000 --- L(Train): 0.0180971 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.061 1 + 0.801 value_stay[t] + 0.222 reward + 0.061 harvest_duration + -0.193 value_stay^2 + 0.086 value_stay*reward + -0.201 value_stay*harvest_duration + 0.224 reward^2 + 0.222 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.997 value_exit[t] + 0.0 travel_duration + 0.003 value_exit^2 + -0.005 value_exit*travel_duration + 0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 25/1000 --- L(Train): 0.0168013 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.061 1 + 0.796 value_stay[t] + 0.23 reward + 0.061 harvest_duration + -0.197 value_stay^2 + 0.096 value_stay*reward + -0.206 value_stay*harvest_duration + 0.232 reward^2 + 0.23 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.998 value_exit[t] + -0.001 travel_duration + 0.002 value_exit^2 + -0.004 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 26/1000 --- L(Train): 0.0221422 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.062 1 + 0.791 value_stay[t] + 0.237 reward + 0.062 harvest_duration + -0.2 value_stay^2 + 0.107 value_stay*reward + -0.21 value_stay*harvest_duration + 0.24 reward^2 + 0.238 reward*harvest_duration + 0.062 harvest_duration^2 \n",
      "value_exit[t+1] = -0.003 1 + 0.999 value_exit[t] + -0.002 travel_duration + 0.001 value_exit^2 + -0.003 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 27/1000 --- L(Train): 0.0259015 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.062 1 + 0.786 value_stay[t] + 0.245 reward + 0.062 harvest_duration + -0.203 value_stay^2 + 0.117 value_stay*reward + -0.215 value_stay*harvest_duration + 0.247 reward^2 + 0.245 reward*harvest_duration + 0.062 harvest_duration^2 \n",
      "value_exit[t+1] = -0.004 1 + 0.999 value_exit[t] + -0.003 travel_duration + 0.0 value_exit^2 + -0.003 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 28/1000 --- L(Train): 0.0232896 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.061 1 + 0.782 value_stay[t] + 0.252 reward + 0.062 harvest_duration + -0.206 value_stay^2 + 0.126 value_stay*reward + -0.219 value_stay*harvest_duration + 0.254 reward^2 + 0.252 reward*harvest_duration + 0.062 harvest_duration^2 \n",
      "value_exit[t+1] = -0.003 1 + 0.999 value_exit[t] + -0.002 travel_duration + 0.001 value_exit^2 + -0.004 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 29/1000 --- L(Train): 0.0171324 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.06 1 + 0.778 value_stay[t] + 0.259 reward + 0.06 harvest_duration + -0.209 value_stay^2 + 0.136 value_stay*reward + -0.223 value_stay*harvest_duration + 0.261 reward^2 + 0.259 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.998 value_exit[t] + -0.002 travel_duration + 0.001 value_exit^2 + -0.005 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 30/1000 --- L(Train): 0.0134005 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.059 1 + 0.774 value_stay[t] + 0.266 reward + 0.06 harvest_duration + -0.211 value_stay^2 + 0.146 value_stay*reward + -0.227 value_stay*harvest_duration + 0.268 reward^2 + 0.266 reward*harvest_duration + 0.06 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.997 value_exit[t] + -0.001 travel_duration + 0.002 value_exit^2 + -0.006 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 31/1000 --- L(Train): 0.0144461 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.059 1 + 0.771 value_stay[t] + 0.272 reward + 0.059 harvest_duration + -0.213 value_stay^2 + 0.155 value_stay*reward + -0.231 value_stay*harvest_duration + 0.274 reward^2 + 0.273 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.995 value_exit[t] + 0.0 travel_duration + 0.003 value_exit^2 + -0.007 value_exit*travel_duration + 0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 32/1000 --- L(Train): 0.0172947 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.058 1 + 0.768 value_stay[t] + 0.278 reward + 0.058 harvest_duration + -0.214 value_stay^2 + 0.165 value_stay*reward + -0.234 value_stay*harvest_duration + 0.28 reward^2 + 0.279 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.995 value_exit[t] + 0.001 travel_duration + 0.004 value_exit^2 + -0.008 value_exit*travel_duration + 0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 33/1000 --- L(Train): 0.0177888 --- L(Val, SINDy): 0.0000000 --- Time: 0.28s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.058 1 + 0.765 value_stay[t] + 0.284 reward + 0.058 harvest_duration + -0.215 value_stay^2 + 0.175 value_stay*reward + -0.236 value_stay*harvest_duration + 0.286 reward^2 + 0.285 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.995 value_exit[t] + 0.001 travel_duration + 0.003 value_exit^2 + -0.008 value_exit*travel_duration + 0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 34/1000 --- L(Train): 0.0151986 --- L(Val, SINDy): 0.0000000 --- Time: 0.27s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.057 1 + 0.763 value_stay[t] + 0.29 reward + 0.057 harvest_duration + -0.216 value_stay^2 + 0.184 value_stay*reward + -0.239 value_stay*harvest_duration + 0.291 reward^2 + 0.291 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.995 value_exit[t] + 0.001 travel_duration + 0.003 value_exit^2 + -0.008 value_exit*travel_duration + 0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 35/1000 --- L(Train): 0.0122926 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.055 1 + 0.76 value_stay[t] + 0.296 reward + 0.056 harvest_duration + -0.217 value_stay^2 + 0.192 value_stay*reward + -0.241 value_stay*harvest_duration + 0.297 reward^2 + 0.296 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.995 value_exit[t] + -0.0 travel_duration + 0.002 value_exit^2 + -0.007 value_exit*travel_duration + -0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 36/1000 --- L(Train): 0.0116654 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.054 1 + 0.758 value_stay[t] + 0.301 reward + 0.054 harvest_duration + -0.217 value_stay^2 + 0.201 value_stay*reward + -0.243 value_stay*harvest_duration + 0.301 reward^2 + 0.301 reward*harvest_duration + 0.054 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.996 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.007 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 37/1000 --- L(Train): 0.0129875 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.053 1 + 0.756 value_stay[t] + 0.306 reward + 0.053 harvest_duration + -0.218 value_stay^2 + 0.209 value_stay*reward + -0.245 value_stay*harvest_duration + 0.306 reward^2 + 0.306 reward*harvest_duration + 0.053 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.997 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.006 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 38/1000 --- L(Train): 0.0139412 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.052 1 + 0.755 value_stay[t] + 0.31 reward + 0.052 harvest_duration + -0.218 value_stay^2 + 0.217 value_stay*reward + -0.247 value_stay*harvest_duration + 0.311 reward^2 + 0.311 reward*harvest_duration + 0.052 harvest_duration^2 \n",
      "value_exit[t+1] = -0.003 1 + 0.997 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.006 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 39/1000 --- L(Train): 0.0131458 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.051 1 + 0.753 value_stay[t] + 0.315 reward + 0.051 harvest_duration + -0.218 value_stay^2 + 0.224 value_stay*reward + -0.249 value_stay*harvest_duration + 0.315 reward^2 + 0.315 reward*harvest_duration + 0.051 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.996 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.007 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 40/1000 --- L(Train): 0.0114825 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.05 1 + 0.752 value_stay[t] + 0.319 reward + 0.05 harvest_duration + -0.218 value_stay^2 + 0.231 value_stay*reward + -0.25 value_stay*harvest_duration + 0.319 reward^2 + 0.319 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.996 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.007 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 41/1000 --- L(Train): 0.0106504 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.75 value_stay[t] + 0.323 reward + 0.049 harvest_duration + -0.217 value_stay^2 + 0.237 value_stay*reward + -0.251 value_stay*harvest_duration + 0.322 reward^2 + 0.323 reward*harvest_duration + 0.049 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.995 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.008 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 42/1000 --- L(Train): 0.0111004 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.749 value_stay[t] + 0.326 reward + 0.048 harvest_duration + -0.217 value_stay^2 + 0.243 value_stay*reward + -0.252 value_stay*harvest_duration + 0.325 reward^2 + 0.326 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.994 value_exit[t] + -0.0 travel_duration + 0.001 value_exit^2 + -0.009 value_exit*travel_duration + -0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 43/1000 --- L(Train): 0.0117764 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.748 value_stay[t] + 0.329 reward + 0.047 harvest_duration + -0.217 value_stay^2 + 0.248 value_stay*reward + -0.254 value_stay*harvest_duration + 0.328 reward^2 + 0.33 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.994 value_exit[t] + 0.0 travel_duration + 0.002 value_exit^2 + -0.009 value_exit*travel_duration + 0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 44/1000 --- L(Train): 0.0116133 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.747 value_stay[t] + 0.332 reward + 0.046 harvest_duration + -0.216 value_stay^2 + 0.252 value_stay*reward + -0.254 value_stay*harvest_duration + 0.331 reward^2 + 0.333 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.994 value_exit[t] + 0.0 travel_duration + 0.002 value_exit^2 + -0.01 value_exit*travel_duration + 0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 45/1000 --- L(Train): 0.0107543 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.746 value_stay[t] + 0.335 reward + 0.045 harvest_duration + -0.216 value_stay^2 + 0.256 value_stay*reward + -0.255 value_stay*harvest_duration + 0.333 reward^2 + 0.335 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.994 value_exit[t] + -0.0 travel_duration + 0.001 value_exit^2 + -0.01 value_exit*travel_duration + -0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 46/1000 --- L(Train): 0.0101362 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.746 value_stay[t] + 0.337 reward + 0.045 harvest_duration + -0.215 value_stay^2 + 0.26 value_stay*reward + -0.256 value_stay*harvest_duration + 0.336 reward^2 + 0.338 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.994 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.009 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 47/1000 --- L(Train): 0.0102401 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.34 reward + 0.044 harvest_duration + -0.215 value_stay^2 + 0.263 value_stay*reward + -0.257 value_stay*harvest_duration + 0.338 reward^2 + 0.34 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.995 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.009 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 48/1000 --- L(Train): 0.0106155 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.744 value_stay[t] + 0.342 reward + 0.043 harvest_duration + -0.214 value_stay^2 + 0.265 value_stay*reward + -0.257 value_stay*harvest_duration + 0.339 reward^2 + 0.342 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.995 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.009 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 49/1000 --- L(Train): 0.0105971 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.744 value_stay[t] + 0.343 reward + 0.043 harvest_duration + -0.214 value_stay^2 + 0.266 value_stay*reward + -0.258 value_stay*harvest_duration + 0.341 reward^2 + 0.344 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.995 value_exit[t] + -0.001 travel_duration + -0.001 value_exit^2 + -0.009 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 50/1000 --- L(Train): 0.0101414 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.743 value_stay[t] + 0.345 reward + 0.042 harvest_duration + -0.213 value_stay^2 + 0.267 value_stay*reward + -0.259 value_stay*harvest_duration + 0.342 reward^2 + 0.345 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.995 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.01 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 51/1000 --- L(Train): 0.0097495 --- L(Val, SINDy): 0.0000000 --- Time: 0.28s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.743 value_stay[t] + 0.346 reward + 0.042 harvest_duration + -0.212 value_stay^2 + 0.268 value_stay*reward + -0.259 value_stay*harvest_duration + 0.343 reward^2 + 0.346 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.994 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.01 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 52/1000 --- L(Train): 0.0097491 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.742 value_stay[t] + 0.347 reward + 0.042 harvest_duration + -0.212 value_stay^2 + 0.268 value_stay*reward + -0.259 value_stay*harvest_duration + 0.344 reward^2 + 0.348 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.994 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.011 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 53/1000 --- L(Train): 0.0099314 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.742 value_stay[t] + 0.348 reward + 0.042 harvest_duration + -0.211 value_stay^2 + 0.267 value_stay*reward + -0.26 value_stay*harvest_duration + 0.344 reward^2 + 0.348 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.993 value_exit[t] + -0.0 travel_duration + 0.001 value_exit^2 + -0.011 value_exit*travel_duration + -0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 54/1000 --- L(Train): 0.0099134 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.741 value_stay[t] + 0.349 reward + 0.042 harvest_duration + -0.211 value_stay^2 + 0.266 value_stay*reward + -0.26 value_stay*harvest_duration + 0.345 reward^2 + 0.349 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.993 value_exit[t] + -0.0 travel_duration + 0.001 value_exit^2 + -0.012 value_exit*travel_duration + -0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 55/1000 --- L(Train): 0.0096457 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.741 value_stay[t] + 0.349 reward + 0.042 harvest_duration + -0.211 value_stay^2 + 0.264 value_stay*reward + -0.261 value_stay*harvest_duration + 0.345 reward^2 + 0.35 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.993 value_exit[t] + -0.0 travel_duration + 0.001 value_exit^2 + -0.012 value_exit*travel_duration + -0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 56/1000 --- L(Train): 0.0094074 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.741 value_stay[t] + 0.35 reward + 0.042 harvest_duration + -0.21 value_stay^2 + 0.263 value_stay*reward + -0.261 value_stay*harvest_duration + 0.345 reward^2 + 0.35 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.993 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.012 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 57/1000 --- L(Train): 0.0093887 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.74 value_stay[t] + 0.35 reward + 0.042 harvest_duration + -0.209 value_stay^2 + 0.261 value_stay*reward + -0.261 value_stay*harvest_duration + 0.345 reward^2 + 0.35 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.993 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.012 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 58/1000 --- L(Train): 0.0094670 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.74 value_stay[t] + 0.35 reward + 0.043 harvest_duration + -0.209 value_stay^2 + 0.258 value_stay*reward + -0.261 value_stay*harvest_duration + 0.345 reward^2 + 0.351 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.993 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.012 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 59/1000 --- L(Train): 0.0094267 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.74 value_stay[t] + 0.35 reward + 0.043 harvest_duration + -0.208 value_stay^2 + 0.255 value_stay*reward + -0.262 value_stay*harvest_duration + 0.345 reward^2 + 0.351 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.993 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.012 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 60/1000 --- L(Train): 0.0092531 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.74 value_stay[t] + 0.35 reward + 0.043 harvest_duration + -0.208 value_stay^2 + 0.252 value_stay*reward + -0.262 value_stay*harvest_duration + 0.345 reward^2 + 0.351 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.993 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.012 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 61/1000 --- L(Train): 0.0091118 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.74 value_stay[t] + 0.35 reward + 0.043 harvest_duration + -0.207 value_stay^2 + 0.249 value_stay*reward + -0.262 value_stay*harvest_duration + 0.344 reward^2 + 0.35 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.993 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.013 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 62/1000 --- L(Train): 0.0090960 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.74 value_stay[t] + 0.35 reward + 0.043 harvest_duration + -0.207 value_stay^2 + 0.246 value_stay*reward + -0.262 value_stay*harvest_duration + 0.344 reward^2 + 0.35 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.013 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 63/1000 --- L(Train): 0.0091191 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.74 value_stay[t] + 0.35 reward + 0.044 harvest_duration + -0.206 value_stay^2 + 0.243 value_stay*reward + -0.262 value_stay*harvest_duration + 0.343 reward^2 + 0.35 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.014 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 64/1000 --- L(Train): 0.0090649 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.74 value_stay[t] + 0.349 reward + 0.044 harvest_duration + -0.205 value_stay^2 + 0.24 value_stay*reward + -0.262 value_stay*harvest_duration + 0.342 reward^2 + 0.35 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.014 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 65/1000 --- L(Train): 0.0089476 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.74 value_stay[t] + 0.349 reward + 0.044 harvest_duration + -0.205 value_stay^2 + 0.236 value_stay*reward + -0.262 value_stay*harvest_duration + 0.342 reward^2 + 0.349 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.014 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 66/1000 --- L(Train): 0.0088654 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.74 value_stay[t] + 0.349 reward + 0.044 harvest_duration + -0.204 value_stay^2 + 0.233 value_stay*reward + -0.262 value_stay*harvest_duration + 0.341 reward^2 + 0.349 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.014 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 67/1000 --- L(Train): 0.0088527 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.74 value_stay[t] + 0.348 reward + 0.045 harvest_duration + -0.203 value_stay^2 + 0.229 value_stay*reward + -0.262 value_stay*harvest_duration + 0.34 reward^2 + 0.348 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.014 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 68/1000 --- L(Train): 0.0088459 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.74 value_stay[t] + 0.348 reward + 0.045 harvest_duration + -0.202 value_stay^2 + 0.226 value_stay*reward + -0.262 value_stay*harvest_duration + 0.339 reward^2 + 0.348 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.014 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 69/1000 --- L(Train): 0.0087893 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.74 value_stay[t] + 0.347 reward + 0.045 harvest_duration + -0.201 value_stay^2 + 0.223 value_stay*reward + -0.261 value_stay*harvest_duration + 0.339 reward^2 + 0.348 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.015 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 70/1000 --- L(Train): 0.0087093 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.74 value_stay[t] + 0.347 reward + 0.045 harvest_duration + -0.2 value_stay^2 + 0.22 value_stay*reward + -0.261 value_stay*harvest_duration + 0.338 reward^2 + 0.347 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.015 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 71/1000 --- L(Train): 0.0086626 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.741 value_stay[t] + 0.346 reward + 0.045 harvest_duration + -0.199 value_stay^2 + 0.216 value_stay*reward + -0.261 value_stay*harvest_duration + 0.337 reward^2 + 0.347 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.015 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 72/1000 --- L(Train): 0.0086504 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.741 value_stay[t] + 0.346 reward + 0.045 harvest_duration + -0.198 value_stay^2 + 0.213 value_stay*reward + -0.261 value_stay*harvest_duration + 0.336 reward^2 + 0.346 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.016 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 73/1000 --- L(Train): 0.0086275 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.741 value_stay[t] + 0.345 reward + 0.045 harvest_duration + -0.197 value_stay^2 + 0.211 value_stay*reward + -0.26 value_stay*harvest_duration + 0.336 reward^2 + 0.346 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.016 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 74/1000 --- L(Train): 0.0085758 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.741 value_stay[t] + 0.345 reward + 0.046 harvest_duration + -0.196 value_stay^2 + 0.208 value_stay*reward + -0.26 value_stay*harvest_duration + 0.335 reward^2 + 0.345 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.016 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 75/1000 --- L(Train): 0.0085237 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.742 value_stay[t] + 0.345 reward + 0.045 harvest_duration + -0.195 value_stay^2 + 0.205 value_stay*reward + -0.26 value_stay*harvest_duration + 0.334 reward^2 + 0.345 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.016 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 76/1000 --- L(Train): 0.0084957 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.742 value_stay[t] + 0.344 reward + 0.045 harvest_duration + -0.193 value_stay^2 + 0.202 value_stay*reward + -0.26 value_stay*harvest_duration + 0.333 reward^2 + 0.345 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.991 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.017 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 77/1000 --- L(Train): 0.0084790 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.742 value_stay[t] + 0.344 reward + 0.045 harvest_duration + -0.192 value_stay^2 + 0.2 value_stay*reward + -0.259 value_stay*harvest_duration + 0.333 reward^2 + 0.344 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.991 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.017 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 78/1000 --- L(Train): 0.0084492 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.743 value_stay[t] + 0.344 reward + 0.045 harvest_duration + -0.191 value_stay^2 + 0.197 value_stay*reward + -0.259 value_stay*harvest_duration + 0.332 reward^2 + 0.344 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.991 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.017 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 79/1000 --- L(Train): 0.0084070 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.743 value_stay[t] + 0.344 reward + 0.045 harvest_duration + -0.19 value_stay^2 + 0.195 value_stay*reward + -0.259 value_stay*harvest_duration + 0.332 reward^2 + 0.344 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.017 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 80/1000 --- L(Train): 0.0083719 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.743 value_stay[t] + 0.343 reward + 0.045 harvest_duration + -0.189 value_stay^2 + 0.192 value_stay*reward + -0.258 value_stay*harvest_duration + 0.331 reward^2 + 0.344 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.018 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 81/1000 --- L(Train): 0.0083509 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.744 value_stay[t] + 0.343 reward + 0.045 harvest_duration + -0.187 value_stay^2 + 0.19 value_stay*reward + -0.258 value_stay*harvest_duration + 0.33 reward^2 + 0.344 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.018 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 82/1000 --- L(Train): 0.0083299 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.744 value_stay[t] + 0.343 reward + 0.045 harvest_duration + -0.186 value_stay^2 + 0.188 value_stay*reward + -0.258 value_stay*harvest_duration + 0.33 reward^2 + 0.344 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.018 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 83/1000 --- L(Train): 0.0082983 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.744 value_stay[t] + 0.343 reward + 0.045 harvest_duration + -0.185 value_stay^2 + 0.186 value_stay*reward + -0.257 value_stay*harvest_duration + 0.329 reward^2 + 0.343 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.019 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 84/1000 --- L(Train): 0.0082640 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.744 value_stay[t] + 0.343 reward + 0.045 harvest_duration + -0.184 value_stay^2 + 0.184 value_stay*reward + -0.257 value_stay*harvest_duration + 0.329 reward^2 + 0.343 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.019 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 85/1000 --- L(Train): 0.0082392 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.343 reward + 0.044 harvest_duration + -0.182 value_stay^2 + 0.181 value_stay*reward + -0.257 value_stay*harvest_duration + 0.329 reward^2 + 0.343 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.019 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 86/1000 --- L(Train): 0.0082196 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.343 reward + 0.044 harvest_duration + -0.181 value_stay^2 + 0.179 value_stay*reward + -0.257 value_stay*harvest_duration + 0.328 reward^2 + 0.344 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.019 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 87/1000 --- L(Train): 0.0081944 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.343 reward + 0.044 harvest_duration + -0.18 value_stay^2 + 0.177 value_stay*reward + -0.257 value_stay*harvest_duration + 0.328 reward^2 + 0.344 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.02 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 88/1000 --- L(Train): 0.0081642 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.343 reward + 0.044 harvest_duration + -0.179 value_stay^2 + 0.175 value_stay*reward + -0.257 value_stay*harvest_duration + 0.328 reward^2 + 0.344 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.02 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 89/1000 --- L(Train): 0.0081379 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.344 reward + 0.044 harvest_duration + -0.178 value_stay^2 + 0.173 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.344 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.02 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 90/1000 --- L(Train): 0.0081171 --- L(Val, SINDy): 0.0000000 --- Time: 0.28s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.344 reward + 0.044 harvest_duration + -0.177 value_stay^2 + 0.171 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.344 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.021 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 91/1000 --- L(Train): 0.0080955 --- L(Val, SINDy): 0.0000000 --- Time: 0.27s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.344 reward + 0.044 harvest_duration + -0.176 value_stay^2 + 0.169 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.344 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.021 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 92/1000 --- L(Train): 0.0080700 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.344 reward + 0.044 harvest_duration + -0.175 value_stay^2 + 0.167 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.345 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.021 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 93/1000 --- L(Train): 0.0080443 --- L(Val, SINDy): 0.0000000 --- Time: 0.28s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.345 reward + 0.044 harvest_duration + -0.174 value_stay^2 + 0.165 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.345 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.021 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 94/1000 --- L(Train): 0.0080229 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.345 reward + 0.044 harvest_duration + -0.173 value_stay^2 + 0.163 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.345 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.022 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 95/1000 --- L(Train): 0.0080031 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.345 reward + 0.044 harvest_duration + -0.172 value_stay^2 + 0.161 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.346 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.022 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 96/1000 --- L(Train): 0.0079800 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.346 reward + 0.044 harvest_duration + -0.171 value_stay^2 + 0.159 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.346 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.022 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 97/1000 --- L(Train): 0.0079553 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.745 value_stay[t] + 0.346 reward + 0.044 harvest_duration + -0.17 value_stay^2 + 0.157 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.346 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.022 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 98/1000 --- L(Train): 0.0079336 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.744 value_stay[t] + 0.347 reward + 0.044 harvest_duration + -0.169 value_stay^2 + 0.155 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.347 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.023 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 99/1000 --- L(Train): 0.0079138 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.744 value_stay[t] + 0.347 reward + 0.044 harvest_duration + -0.169 value_stay^2 + 0.154 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.347 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.023 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 100/1000 --- L(Train): 0.0078920 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.744 value_stay[t] + 0.347 reward + 0.044 harvest_duration + -0.168 value_stay^2 + 0.152 value_stay*reward + -0.258 value_stay*harvest_duration + 0.327 reward^2 + 0.348 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.023 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 101/1000 --- L(Train): 0.0078692 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.744 value_stay[t] + 0.348 reward + 0.043 harvest_duration + -0.167 value_stay^2 + 0.15 value_stay*reward + -0.258 value_stay*harvest_duration + 0.327 reward^2 + 0.348 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.024 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 102/1000 --- L(Train): 0.0078481 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.744 value_stay[t] + 0.348 reward + 0.043 harvest_duration + -0.166 value_stay^2 + 0.148 value_stay*reward + -0.258 value_stay*harvest_duration + 0.327 reward^2 + 0.349 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.024 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 103/1000 --- L(Train): 0.0078283 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.744 value_stay[t] + 0.349 reward + 0.043 harvest_duration + -0.165 value_stay^2 + 0.146 value_stay*reward + -0.258 value_stay*harvest_duration + 0.327 reward^2 + 0.349 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.024 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 104/1000 --- L(Train): 0.0078079 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.743 value_stay[t] + 0.35 reward + 0.043 harvest_duration + -0.164 value_stay^2 + 0.144 value_stay*reward + -0.258 value_stay*harvest_duration + 0.327 reward^2 + 0.35 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.024 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 105/1000 --- L(Train): 0.0077873 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.743 value_stay[t] + 0.35 reward + 0.043 harvest_duration + -0.164 value_stay^2 + 0.142 value_stay*reward + -0.259 value_stay*harvest_duration + 0.327 reward^2 + 0.35 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.025 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 106/1000 --- L(Train): 0.0077673 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.743 value_stay[t] + 0.351 reward + 0.043 harvest_duration + -0.163 value_stay^2 + 0.14 value_stay*reward + -0.259 value_stay*harvest_duration + 0.327 reward^2 + 0.351 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.025 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 107/1000 --- L(Train): 0.0077475 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.743 value_stay[t] + 0.351 reward + 0.043 harvest_duration + -0.162 value_stay^2 + 0.139 value_stay*reward + -0.259 value_stay*harvest_duration + 0.327 reward^2 + 0.352 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.025 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 108/1000 --- L(Train): 0.0077274 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.742 value_stay[t] + 0.352 reward + 0.043 harvest_duration + -0.161 value_stay^2 + 0.137 value_stay*reward + -0.259 value_stay*harvest_duration + 0.327 reward^2 + 0.352 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.026 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 109/1000 --- L(Train): 0.0077075 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.742 value_stay[t] + 0.352 reward + 0.043 harvest_duration + -0.16 value_stay^2 + 0.135 value_stay*reward + -0.259 value_stay*harvest_duration + 0.327 reward^2 + 0.353 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.026 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 110/1000 --- L(Train): 0.0076875 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.742 value_stay[t] + 0.353 reward + 0.043 harvest_duration + -0.159 value_stay^2 + 0.133 value_stay*reward + -0.26 value_stay*harvest_duration + 0.327 reward^2 + 0.353 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.026 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 111/1000 --- L(Train): 0.0076684 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.742 value_stay[t] + 0.353 reward + 0.043 harvest_duration + -0.158 value_stay^2 + 0.132 value_stay*reward + -0.26 value_stay*harvest_duration + 0.328 reward^2 + 0.354 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.026 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 112/1000 --- L(Train): 0.0076495 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.742 value_stay[t] + 0.354 reward + 0.043 harvest_duration + -0.158 value_stay^2 + 0.13 value_stay*reward + -0.26 value_stay*harvest_duration + 0.328 reward^2 + 0.354 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.027 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 113/1000 --- L(Train): 0.0076303 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.741 value_stay[t] + 0.355 reward + 0.043 harvest_duration + -0.157 value_stay^2 + 0.128 value_stay*reward + -0.26 value_stay*harvest_duration + 0.328 reward^2 + 0.355 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.027 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 114/1000 --- L(Train): 0.0076111 --- L(Val, SINDy): 0.0000000 --- Time: 0.27s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.741 value_stay[t] + 0.355 reward + 0.043 harvest_duration + -0.156 value_stay^2 + 0.126 value_stay*reward + -0.26 value_stay*harvest_duration + 0.328 reward^2 + 0.356 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.027 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 115/1000 --- L(Train): 0.0075930 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.741 value_stay[t] + 0.356 reward + 0.043 harvest_duration + -0.155 value_stay^2 + 0.125 value_stay*reward + -0.261 value_stay*harvest_duration + 0.328 reward^2 + 0.356 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.028 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 116/1000 --- L(Train): 0.0075748 --- L(Val, SINDy): 0.0000000 --- Time: 0.27s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.741 value_stay[t] + 0.356 reward + 0.043 harvest_duration + -0.154 value_stay^2 + 0.123 value_stay*reward + -0.261 value_stay*harvest_duration + 0.328 reward^2 + 0.357 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.028 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 117/1000 --- L(Train): 0.0075561 --- L(Val, SINDy): 0.0000000 --- Time: 0.14s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.741 value_stay[t] + 0.357 reward + 0.043 harvest_duration + -0.153 value_stay^2 + 0.121 value_stay*reward + -0.261 value_stay*harvest_duration + 0.328 reward^2 + 0.357 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.028 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 118/1000 --- L(Train): 0.0075383 --- L(Val, SINDy): 0.0000000 --- Time: 0.09s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.741 value_stay[t] + 0.358 reward + 0.043 harvest_duration + -0.152 value_stay^2 + 0.119 value_stay*reward + -0.261 value_stay*harvest_duration + 0.328 reward^2 + 0.358 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.028 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 119/1000 --- L(Train): 0.0075211 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.74 value_stay[t] + 0.358 reward + 0.042 harvest_duration + -0.151 value_stay^2 + 0.118 value_stay*reward + -0.261 value_stay*harvest_duration + 0.328 reward^2 + 0.358 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.029 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 120/1000 --- L(Train): 0.0075035 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.74 value_stay[t] + 0.359 reward + 0.042 harvest_duration + -0.15 value_stay^2 + 0.116 value_stay*reward + -0.261 value_stay*harvest_duration + 0.328 reward^2 + 0.359 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.029 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 121/1000 --- L(Train): 0.0074857 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.74 value_stay[t] + 0.359 reward + 0.042 harvest_duration + -0.149 value_stay^2 + 0.114 value_stay*reward + -0.262 value_stay*harvest_duration + 0.328 reward^2 + 0.36 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.029 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 122/1000 --- L(Train): 0.0074682 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.74 value_stay[t] + 0.36 reward + 0.042 harvest_duration + -0.148 value_stay^2 + 0.112 value_stay*reward + -0.262 value_stay*harvest_duration + 0.328 reward^2 + 0.36 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.03 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 123/1000 --- L(Train): 0.0074510 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.74 value_stay[t] + 0.36 reward + 0.042 harvest_duration + -0.147 value_stay^2 + 0.111 value_stay*reward + -0.262 value_stay*harvest_duration + 0.328 reward^2 + 0.361 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.03 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 124/1000 --- L(Train): 0.0074348 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.74 value_stay[t] + 0.361 reward + 0.042 harvest_duration + -0.146 value_stay^2 + 0.109 value_stay*reward + -0.262 value_stay*harvest_duration + 0.328 reward^2 + 0.361 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.03 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 125/1000 --- L(Train): 0.0074179 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.739 value_stay[t] + 0.361 reward + 0.042 harvest_duration + -0.145 value_stay^2 + 0.107 value_stay*reward + -0.262 value_stay*harvest_duration + 0.328 reward^2 + 0.362 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.03 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 126/1000 --- L(Train): 0.0074011 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.739 value_stay[t] + 0.362 reward + 0.042 harvest_duration + -0.145 value_stay^2 + 0.105 value_stay*reward + -0.262 value_stay*harvest_duration + 0.328 reward^2 + 0.362 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.031 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 127/1000 --- L(Train): 0.0073850 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.739 value_stay[t] + 0.362 reward + 0.042 harvest_duration + -0.144 value_stay^2 + 0.103 value_stay*reward + -0.263 value_stay*harvest_duration + 0.328 reward^2 + 0.363 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.031 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 128/1000 --- L(Train): 0.0073692 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.739 value_stay[t] + 0.363 reward + 0.042 harvest_duration + -0.143 value_stay^2 + 0.101 value_stay*reward + -0.263 value_stay*harvest_duration + 0.328 reward^2 + 0.363 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.031 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 129/1000 --- L(Train): 0.0073533 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.739 value_stay[t] + 0.363 reward + 0.042 harvest_duration + -0.142 value_stay^2 + 0.099 value_stay*reward + -0.263 value_stay*harvest_duration + 0.328 reward^2 + 0.364 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.032 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 130/1000 --- L(Train): 0.0073370 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.739 value_stay[t] + 0.364 reward + 0.042 harvest_duration + -0.141 value_stay^2 + 0.097 value_stay*reward + -0.263 value_stay*harvest_duration + 0.328 reward^2 + 0.364 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.032 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 131/1000 --- L(Train): 0.0073214 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.739 value_stay[t] + 0.364 reward + 0.042 harvest_duration + -0.14 value_stay^2 + 0.095 value_stay*reward + -0.263 value_stay*harvest_duration + 0.328 reward^2 + 0.365 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.032 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 132/1000 --- L(Train): 0.0073062 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.738 value_stay[t] + 0.365 reward + 0.042 harvest_duration + -0.139 value_stay^2 + 0.094 value_stay*reward + -0.263 value_stay*harvest_duration + 0.328 reward^2 + 0.365 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.033 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 133/1000 --- L(Train): 0.0072915 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.738 value_stay[t] + 0.365 reward + 0.041 harvest_duration + -0.138 value_stay^2 + 0.092 value_stay*reward + -0.263 value_stay*harvest_duration + 0.328 reward^2 + 0.366 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.033 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 134/1000 --- L(Train): 0.0072772 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.738 value_stay[t] + 0.366 reward + 0.041 harvest_duration + -0.137 value_stay^2 + 0.09 value_stay*reward + -0.264 value_stay*harvest_duration + 0.328 reward^2 + 0.366 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.033 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 135/1000 --- L(Train): 0.0072631 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.738 value_stay[t] + 0.366 reward + 0.041 harvest_duration + -0.136 value_stay^2 + 0.088 value_stay*reward + -0.264 value_stay*harvest_duration + 0.328 reward^2 + 0.367 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.033 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 136/1000 --- L(Train): 0.0072486 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.738 value_stay[t] + 0.367 reward + 0.041 harvest_duration + -0.135 value_stay^2 + 0.086 value_stay*reward + -0.264 value_stay*harvest_duration + 0.328 reward^2 + 0.367 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.034 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 137/1000 --- L(Train): 0.0072335 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.738 value_stay[t] + 0.367 reward + 0.041 harvest_duration + -0.134 value_stay^2 + 0.084 value_stay*reward + -0.264 value_stay*harvest_duration + 0.328 reward^2 + 0.368 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.034 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 138/1000 --- L(Train): 0.0072190 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.738 value_stay[t] + 0.368 reward + 0.041 harvest_duration + -0.133 value_stay^2 + 0.082 value_stay*reward + -0.264 value_stay*harvest_duration + 0.327 reward^2 + 0.368 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.034 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 139/1000 --- L(Train): 0.0072052 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.737 value_stay[t] + 0.368 reward + 0.041 harvest_duration + -0.132 value_stay^2 + 0.08 value_stay*reward + -0.264 value_stay*harvest_duration + 0.327 reward^2 + 0.369 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.035 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 140/1000 --- L(Train): 0.0071906 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.737 value_stay[t] + 0.369 reward + 0.041 harvest_duration + -0.131 value_stay^2 + 0.078 value_stay*reward + -0.264 value_stay*harvest_duration + 0.327 reward^2 + 0.369 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.035 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 141/1000 --- L(Train): 0.0071763 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.737 value_stay[t] + 0.369 reward + 0.041 harvest_duration + -0.13 value_stay^2 + 0.076 value_stay*reward + -0.264 value_stay*harvest_duration + 0.327 reward^2 + 0.37 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.035 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 142/1000 --- L(Train): 0.0071629 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.737 value_stay[t] + 0.37 reward + 0.041 harvest_duration + -0.129 value_stay^2 + 0.074 value_stay*reward + -0.265 value_stay*harvest_duration + 0.327 reward^2 + 0.37 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.035 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 143/1000 --- L(Train): 0.0071491 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.737 value_stay[t] + 0.37 reward + 0.041 harvest_duration + -0.128 value_stay^2 + 0.072 value_stay*reward + -0.265 value_stay*harvest_duration + 0.327 reward^2 + 0.371 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.036 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 144/1000 --- L(Train): 0.0071357 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.737 value_stay[t] + 0.371 reward + 0.041 harvest_duration + -0.127 value_stay^2 + 0.07 value_stay*reward + -0.265 value_stay*harvest_duration + 0.327 reward^2 + 0.371 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.036 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 145/1000 --- L(Train): 0.0071231 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.737 value_stay[t] + 0.371 reward + 0.041 harvest_duration + -0.126 value_stay^2 + 0.067 value_stay*reward + -0.265 value_stay*harvest_duration + 0.327 reward^2 + 0.372 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.036 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\u001b[H\u001b[2J\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 146/1000 --- L(Train): 0.0071100 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.737 value_stay[t] + 0.372 reward + 0.041 harvest_duration + -0.125 value_stay^2 + 0.065 value_stay*reward + -0.265 value_stay*harvest_duration + 0.327 reward^2 + 0.372 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.037 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 147/1000 --- L(Train): 0.0070968 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.736 value_stay[t] + 0.372 reward + 0.041 harvest_duration + -0.124 value_stay^2 + 0.063 value_stay*reward + -0.265 value_stay*harvest_duration + 0.326 reward^2 + 0.373 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.037 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 148/1000 --- L(Train): 0.0070842 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.736 value_stay[t] + 0.373 reward + 0.041 harvest_duration + -0.123 value_stay^2 + 0.061 value_stay*reward + -0.265 value_stay*harvest_duration + 0.326 reward^2 + 0.373 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.037 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 149/1000 --- L(Train): 0.0070712 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.736 value_stay[t] + 0.373 reward + 0.041 harvest_duration + -0.122 value_stay^2 + 0.059 value_stay*reward + -0.265 value_stay*harvest_duration + 0.326 reward^2 + 0.373 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.037 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 150/1000 --- L(Train): 0.0070591 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.736 value_stay[t] + 0.374 reward + 0.04 harvest_duration + -0.121 value_stay^2 + 0.057 value_stay*reward + -0.266 value_stay*harvest_duration + 0.326 reward^2 + 0.374 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.038 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 151/1000 --- L(Train): 0.0070471 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.736 value_stay[t] + 0.374 reward + 0.04 harvest_duration + -0.12 value_stay^2 + 0.055 value_stay*reward + -0.266 value_stay*harvest_duration + 0.326 reward^2 + 0.374 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.038 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 152/1000 --- L(Train): 0.0070345 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.736 value_stay[t] + 0.375 reward + 0.04 harvest_duration + -0.119 value_stay^2 + 0.053 value_stay*reward + -0.266 value_stay*harvest_duration + 0.326 reward^2 + 0.375 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.038 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 153/1000 --- L(Train): 0.0070222 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.736 value_stay[t] + 0.375 reward + 0.04 harvest_duration + -0.118 value_stay^2 + 0.051 value_stay*reward + -0.266 value_stay*harvest_duration + 0.326 reward^2 + 0.375 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.039 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 154/1000 --- L(Train): 0.0070103 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.736 value_stay[t] + 0.376 reward + 0.04 harvest_duration + -0.117 value_stay^2 + 0.049 value_stay*reward + -0.266 value_stay*harvest_duration + 0.325 reward^2 + 0.376 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.039 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 155/1000 --- L(Train): 0.0069985 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.735 value_stay[t] + 0.376 reward + 0.04 harvest_duration + -0.116 value_stay^2 + 0.048 value_stay*reward + -0.266 value_stay*harvest_duration + 0.325 reward^2 + 0.376 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.039 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 156/1000 --- L(Train): 0.0069870 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.735 value_stay[t] + 0.377 reward + 0.04 harvest_duration + -0.115 value_stay^2 + 0.046 value_stay*reward + -0.266 value_stay*harvest_duration + 0.325 reward^2 + 0.377 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.039 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 157/1000 --- L(Train): 0.0069757 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.735 value_stay[t] + 0.377 reward + 0.04 harvest_duration + -0.114 value_stay^2 + 0.044 value_stay*reward + -0.266 value_stay*harvest_duration + 0.325 reward^2 + 0.377 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.04 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 158/1000 --- L(Train): 0.0069645 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.735 value_stay[t] + 0.378 reward + 0.04 harvest_duration + -0.113 value_stay^2 + 0.042 value_stay*reward + -0.267 value_stay*harvest_duration + 0.325 reward^2 + 0.378 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.04 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 159/1000 --- L(Train): 0.0069533 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.735 value_stay[t] + 0.378 reward + 0.04 harvest_duration + -0.113 value_stay^2 + 0.04 value_stay*reward + -0.267 value_stay*harvest_duration + 0.325 reward^2 + 0.378 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.04 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 160/1000 --- L(Train): 0.0069427 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.735 value_stay[t] + 0.379 reward + 0.04 harvest_duration + -0.112 value_stay^2 + 0.038 value_stay*reward + -0.267 value_stay*harvest_duration + 0.325 reward^2 + 0.379 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.041 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 161/1000 --- L(Train): 0.0069316 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.735 value_stay[t] + 0.379 reward + 0.04 harvest_duration + -0.111 value_stay^2 + 0.036 value_stay*reward + -0.267 value_stay*harvest_duration + 0.324 reward^2 + 0.379 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.041 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 162/1000 --- L(Train): 0.0069205 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.735 value_stay[t] + 0.38 reward + 0.04 harvest_duration + -0.11 value_stay^2 + 0.034 value_stay*reward + -0.267 value_stay*harvest_duration + 0.324 reward^2 + 0.38 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.041 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 163/1000 --- L(Train): 0.0069095 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.734 value_stay[t] + 0.38 reward + 0.04 harvest_duration + -0.109 value_stay^2 + 0.032 value_stay*reward + -0.267 value_stay*harvest_duration + 0.324 reward^2 + 0.381 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.041 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 164/1000 --- L(Train): 0.0068990 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.734 value_stay[t] + 0.381 reward + 0.04 harvest_duration + -0.108 value_stay^2 + 0.03 value_stay*reward + -0.267 value_stay*harvest_duration + 0.324 reward^2 + 0.381 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.042 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 165/1000 --- L(Train): 0.0068888 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.734 value_stay[t] + 0.381 reward + 0.039 harvest_duration + -0.107 value_stay^2 + 0.028 value_stay*reward + -0.268 value_stay*harvest_duration + 0.324 reward^2 + 0.382 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.042 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 166/1000 --- L(Train): 0.0068784 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.734 value_stay[t] + 0.382 reward + 0.039 harvest_duration + -0.106 value_stay^2 + 0.026 value_stay*reward + -0.268 value_stay*harvest_duration + 0.324 reward^2 + 0.382 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.042 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 167/1000 --- L(Train): 0.0068684 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.734 value_stay[t] + 0.382 reward + 0.039 harvest_duration + -0.105 value_stay^2 + 0.024 value_stay*reward + -0.268 value_stay*harvest_duration + 0.323 reward^2 + 0.383 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.043 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 168/1000 --- L(Train): 0.0068587 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.734 value_stay[t] + 0.383 reward + 0.039 harvest_duration + -0.104 value_stay^2 + 0.022 value_stay*reward + -0.268 value_stay*harvest_duration + 0.323 reward^2 + 0.383 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.043 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 169/1000 --- L(Train): 0.0068495 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.734 value_stay[t] + 0.383 reward + 0.039 harvest_duration + -0.103 value_stay^2 + 0.02 value_stay*reward + -0.268 value_stay*harvest_duration + 0.323 reward^2 + 0.384 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.043 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 170/1000 --- L(Train): 0.0068402 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.733 value_stay[t] + 0.384 reward + 0.039 harvest_duration + -0.102 value_stay^2 + 0.018 value_stay*reward + -0.268 value_stay*harvest_duration + 0.323 reward^2 + 0.384 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.043 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 171/1000 --- L(Train): 0.0068310 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.733 value_stay[t] + 0.384 reward + 0.039 harvest_duration + -0.101 value_stay^2 + 0.016 value_stay*reward + -0.268 value_stay*harvest_duration + 0.323 reward^2 + 0.385 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.044 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 172/1000 --- L(Train): 0.0068214 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.733 value_stay[t] + 0.385 reward + 0.039 harvest_duration + -0.1 value_stay^2 + 0.014 value_stay*reward + -0.269 value_stay*harvest_duration + 0.323 reward^2 + 0.385 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.044 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 173/1000 --- L(Train): 0.0068115 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.733 value_stay[t] + 0.385 reward + 0.039 harvest_duration + -0.099 value_stay^2 + 0.012 value_stay*reward + -0.269 value_stay*harvest_duration + 0.322 reward^2 + 0.386 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.044 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 174/1000 --- L(Train): 0.0068023 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.733 value_stay[t] + 0.386 reward + 0.039 harvest_duration + -0.098 value_stay^2 + 0.01 value_stay*reward + -0.269 value_stay*harvest_duration + 0.322 reward^2 + 0.386 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.044 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 175/1000 --- L(Train): 0.0067934 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.733 value_stay[t] + 0.387 reward + 0.039 harvest_duration + -0.097 value_stay^2 + 0.008 value_stay*reward + -0.269 value_stay*harvest_duration + 0.322 reward^2 + 0.387 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.045 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 176/1000 --- L(Train): 0.0067844 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.733 value_stay[t] + 0.387 reward + 0.039 harvest_duration + -0.096 value_stay^2 + 0.006 value_stay*reward + -0.269 value_stay*harvest_duration + 0.322 reward^2 + 0.387 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.045 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 177/1000 --- L(Train): 0.0067757 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.732 value_stay[t] + 0.388 reward + 0.039 harvest_duration + -0.095 value_stay^2 + 0.004 value_stay*reward + -0.269 value_stay*harvest_duration + 0.322 reward^2 + 0.388 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.045 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 178/1000 --- L(Train): 0.0067670 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.732 value_stay[t] + 0.388 reward + 0.039 harvest_duration + -0.094 value_stay^2 + 0.002 value_stay*reward + -0.269 value_stay*harvest_duration + 0.321 reward^2 + 0.388 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.046 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 179/1000 --- L(Train): 0.0067582 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.732 value_stay[t] + 0.389 reward + 0.039 harvest_duration + -0.093 value_stay^2 + 0.0 value_stay*reward + -0.27 value_stay*harvest_duration + 0.321 reward^2 + 0.389 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.046 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 180/1000 --- L(Train): 0.0067494 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.732 value_stay[t] + 0.389 reward + 0.039 harvest_duration + -0.092 value_stay^2 + -0.002 value_stay*reward + -0.27 value_stay*harvest_duration + 0.321 reward^2 + 0.389 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.046 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 181/1000 --- L(Train): 0.0067407 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.732 value_stay[t] + 0.39 reward + 0.038 harvest_duration + -0.091 value_stay^2 + -0.003 value_stay*reward + -0.27 value_stay*harvest_duration + 0.321 reward^2 + 0.39 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.046 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 182/1000 --- L(Train): 0.0067320 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.732 value_stay[t] + 0.39 reward + 0.038 harvest_duration + -0.09 value_stay^2 + -0.003 value_stay*reward + -0.27 value_stay*harvest_duration + 0.321 reward^2 + 0.391 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.047 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 183/1000 --- L(Train): 0.0067237 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.732 value_stay[t] + 0.391 reward + 0.038 harvest_duration + -0.089 value_stay^2 + -0.002 value_stay*reward + -0.27 value_stay*harvest_duration + 0.32 reward^2 + 0.391 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.047 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 184/1000 --- L(Train): 0.0067160 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.731 value_stay[t] + 0.391 reward + 0.038 harvest_duration + -0.089 value_stay^2 + -0.0 value_stay*reward + -0.27 value_stay*harvest_duration + 0.32 reward^2 + 0.392 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.047 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 185/1000 --- L(Train): 0.0067082 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.037 1 + 0.731 value_stay[t] + 0.392 reward + 0.037 harvest_duration + -0.088 value_stay^2 + 0.002 value_stay*reward + -0.271 value_stay*harvest_duration + 0.32 reward^2 + 0.392 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.047 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 186/1000 --- L(Train): 0.0067001 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.037 1 + 0.731 value_stay[t] + 0.392 reward + 0.037 harvest_duration + -0.087 value_stay^2 + 0.003 value_stay*reward + -0.271 value_stay*harvest_duration + 0.32 reward^2 + 0.392 reward*harvest_duration + 0.037 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.048 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 187/1000 --- L(Train): 0.0066923 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.037 1 + 0.73 value_stay[t] + 0.393 reward + 0.037 harvest_duration + -0.086 value_stay^2 + 0.004 value_stay*reward + -0.271 value_stay*harvest_duration + 0.319 reward^2 + 0.393 reward*harvest_duration + 0.037 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.048 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 188/1000 --- L(Train): 0.0066845 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.037 1 + 0.73 value_stay[t] + 0.393 reward + 0.037 harvest_duration + -0.086 value_stay^2 + 0.005 value_stay*reward + -0.272 value_stay*harvest_duration + 0.319 reward^2 + 0.393 reward*harvest_duration + 0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.048 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 189/1000 --- L(Train): 0.0066767 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.037 1 + 0.73 value_stay[t] + 0.393 reward + 0.037 harvest_duration + -0.085 value_stay^2 + 0.005 value_stay*reward + -0.272 value_stay*harvest_duration + 0.318 reward^2 + 0.394 reward*harvest_duration + 0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.049 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 190/1000 --- L(Train): 0.0066687 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.037 1 + 0.729 value_stay[t] + 0.394 reward + 0.037 harvest_duration + -0.085 value_stay^2 + 0.004 value_stay*reward + -0.272 value_stay*harvest_duration + 0.318 reward^2 + 0.394 reward*harvest_duration + 0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.049 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 191/1000 --- L(Train): 0.0066605 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.037 1 + 0.729 value_stay[t] + 0.394 reward + 0.037 harvest_duration + -0.084 value_stay^2 + 0.003 value_stay*reward + -0.273 value_stay*harvest_duration + 0.318 reward^2 + 0.394 reward*harvest_duration + 0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.049 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 192/1000 --- L(Train): 0.0066534 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.037 1 + 0.728 value_stay[t] + 0.394 reward + 0.037 harvest_duration + -0.084 value_stay^2 + 0.002 value_stay*reward + -0.273 value_stay*harvest_duration + 0.317 reward^2 + 0.395 reward*harvest_duration + 0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.049 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 193/1000 --- L(Train): 0.0066464 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.728 value_stay[t] + 0.394 reward + 0.038 harvest_duration + -0.083 value_stay^2 + 0.0 value_stay*reward + -0.274 value_stay*harvest_duration + 0.317 reward^2 + 0.395 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.05 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 194/1000 --- L(Train): 0.0066392 --- L(Val, SINDy): 0.0000000 --- Time: 0.11s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.727 value_stay[t] + 0.395 reward + 0.038 harvest_duration + -0.083 value_stay^2 + -0.001 value_stay*reward + -0.274 value_stay*harvest_duration + 0.316 reward^2 + 0.395 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.05 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 195/1000 --- L(Train): 0.0066317 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.727 value_stay[t] + 0.395 reward + 0.038 harvest_duration + -0.082 value_stay^2 + -0.002 value_stay*reward + -0.275 value_stay*harvest_duration + 0.316 reward^2 + 0.395 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.05 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 196/1000 --- L(Train): 0.0066241 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.726 value_stay[t] + 0.395 reward + 0.038 harvest_duration + -0.082 value_stay^2 + -0.002 value_stay*reward + -0.275 value_stay*harvest_duration + 0.315 reward^2 + 0.395 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.05 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 197/1000 --- L(Train): 0.0066166 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.726 value_stay[t] + 0.395 reward + 0.038 harvest_duration + -0.082 value_stay^2 + -0.002 value_stay*reward + -0.276 value_stay*harvest_duration + 0.314 reward^2 + 0.396 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.051 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 198/1000 --- L(Train): 0.0066099 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.726 value_stay[t] + 0.396 reward + 0.038 harvest_duration + -0.081 value_stay^2 + -0.0 value_stay*reward + -0.276 value_stay*harvest_duration + 0.314 reward^2 + 0.396 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.051 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 199/1000 --- L(Train): 0.0066029 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.725 value_stay[t] + 0.396 reward + 0.038 harvest_duration + -0.081 value_stay^2 + 0.001 value_stay*reward + -0.277 value_stay*harvest_duration + 0.313 reward^2 + 0.396 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.051 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 200/1000 --- L(Train): 0.0065958 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.725 value_stay[t] + 0.396 reward + 0.038 harvest_duration + -0.08 value_stay^2 + 0.003 value_stay*reward + -0.277 value_stay*harvest_duration + 0.313 reward^2 + 0.396 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.051 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 201/1000 --- L(Train): 0.0065888 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.724 value_stay[t] + 0.396 reward + 0.038 harvest_duration + -0.08 value_stay^2 + 0.004 value_stay*reward + -0.278 value_stay*harvest_duration + 0.312 reward^2 + 0.396 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.052 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 202/1000 --- L(Train): 0.0065817 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.724 value_stay[t] + 0.396 reward + 0.038 harvest_duration + -0.079 value_stay^2 + 0.004 value_stay*reward + -0.278 value_stay*harvest_duration + 0.311 reward^2 + 0.396 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.052 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 203/1000 --- L(Train): 0.0065753 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.723 value_stay[t] + 0.396 reward + 0.039 harvest_duration + -0.079 value_stay^2 + 0.004 value_stay*reward + -0.278 value_stay*harvest_duration + 0.311 reward^2 + 0.396 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.052 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 204/1000 --- L(Train): 0.0065690 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.723 value_stay[t] + 0.396 reward + 0.039 harvest_duration + -0.078 value_stay^2 + 0.003 value_stay*reward + -0.279 value_stay*harvest_duration + 0.31 reward^2 + 0.397 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.053 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 205/1000 --- L(Train): 0.0065626 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.723 value_stay[t] + 0.396 reward + 0.039 harvest_duration + -0.078 value_stay^2 + 0.002 value_stay*reward + -0.279 value_stay*harvest_duration + 0.309 reward^2 + 0.397 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.053 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 206/1000 --- L(Train): 0.0065561 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.722 value_stay[t] + 0.396 reward + 0.039 harvest_duration + -0.078 value_stay^2 + 0.001 value_stay*reward + -0.28 value_stay*harvest_duration + 0.308 reward^2 + 0.397 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.053 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 207/1000 --- L(Train): 0.0065496 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.722 value_stay[t] + 0.396 reward + 0.039 harvest_duration + -0.077 value_stay^2 + -0.0 value_stay*reward + -0.28 value_stay*harvest_duration + 0.308 reward^2 + 0.397 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.053 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 208/1000 --- L(Train): 0.0065430 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.721 value_stay[t] + 0.397 reward + 0.039 harvest_duration + -0.076 value_stay^2 + -0.001 value_stay*reward + -0.28 value_stay*harvest_duration + 0.307 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.054 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 209/1000 --- L(Train): 0.0065367 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.721 value_stay[t] + 0.397 reward + 0.039 harvest_duration + -0.076 value_stay^2 + -0.0 value_stay*reward + -0.281 value_stay*harvest_duration + 0.306 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.054 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 210/1000 --- L(Train): 0.0065304 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.721 value_stay[t] + 0.397 reward + 0.039 harvest_duration + -0.075 value_stay^2 + 0.001 value_stay*reward + -0.281 value_stay*harvest_duration + 0.305 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.054 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 211/1000 --- L(Train): 0.0065240 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.72 value_stay[t] + 0.397 reward + 0.039 harvest_duration + -0.075 value_stay^2 + 0.002 value_stay*reward + -0.281 value_stay*harvest_duration + 0.305 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.054 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 212/1000 --- L(Train): 0.0065175 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.72 value_stay[t] + 0.397 reward + 0.039 harvest_duration + -0.074 value_stay^2 + 0.002 value_stay*reward + -0.282 value_stay*harvest_duration + 0.304 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.055 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 213/1000 --- L(Train): 0.0065112 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.72 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.074 value_stay^2 + 0.002 value_stay*reward + -0.282 value_stay*harvest_duration + 0.303 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.055 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 214/1000 --- L(Train): 0.0065052 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.72 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.073 value_stay^2 + 0.001 value_stay*reward + -0.282 value_stay*harvest_duration + 0.302 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.055 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 215/1000 --- L(Train): 0.0064995 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.719 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.072 value_stay^2 + 0.0 value_stay*reward + -0.282 value_stay*harvest_duration + 0.302 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.055 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 216/1000 --- L(Train): 0.0064937 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.719 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.072 value_stay^2 + -0.001 value_stay*reward + -0.283 value_stay*harvest_duration + 0.301 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.056 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 217/1000 --- L(Train): 0.0064880 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.719 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.071 value_stay^2 + -0.001 value_stay*reward + -0.283 value_stay*harvest_duration + 0.3 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.056 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 218/1000 --- L(Train): 0.0064820 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.718 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.07 value_stay^2 + -0.0 value_stay*reward + -0.283 value_stay*harvest_duration + 0.299 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.056 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 219/1000 --- L(Train): 0.0064758 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.718 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.07 value_stay^2 + 0.001 value_stay*reward + -0.284 value_stay*harvest_duration + 0.299 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.056 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 220/1000 --- L(Train): 0.0064699 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.718 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.069 value_stay^2 + 0.002 value_stay*reward + -0.284 value_stay*harvest_duration + 0.298 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.057 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 221/1000 --- L(Train): 0.0064639 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.717 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.069 value_stay^2 + 0.003 value_stay*reward + -0.284 value_stay*harvest_duration + 0.297 reward^2 + 0.398 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.057 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 222/1000 --- L(Train): 0.0064582 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.717 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.068 value_stay^2 + 0.002 value_stay*reward + -0.285 value_stay*harvest_duration + 0.296 reward^2 + 0.398 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.057 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 223/1000 --- L(Train): 0.0064530 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.717 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.067 value_stay^2 + 0.002 value_stay*reward + -0.285 value_stay*harvest_duration + 0.296 reward^2 + 0.398 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.057 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 224/1000 --- L(Train): 0.0064477 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.716 value_stay[t] + 0.398 reward + 0.04 harvest_duration + -0.067 value_stay^2 + 0.001 value_stay*reward + -0.285 value_stay*harvest_duration + 0.295 reward^2 + 0.398 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.058 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 225/1000 --- L(Train): 0.0064424 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.716 value_stay[t] + 0.398 reward + 0.04 harvest_duration + -0.066 value_stay^2 + 0.0 value_stay*reward + -0.286 value_stay*harvest_duration + 0.294 reward^2 + 0.398 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.058 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 226/1000 --- L(Train): 0.0064365 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.716 value_stay[t] + 0.398 reward + 0.04 harvest_duration + -0.066 value_stay^2 + -0.001 value_stay*reward + -0.286 value_stay*harvest_duration + 0.294 reward^2 + 0.398 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.058 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 227/1000 --- L(Train): 0.0064308 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.715 value_stay[t] + 0.398 reward + 0.041 harvest_duration + -0.065 value_stay^2 + -0.002 value_stay*reward + -0.286 value_stay*harvest_duration + 0.293 reward^2 + 0.398 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.058 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 228/1000 --- L(Train): 0.0064249 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.715 value_stay[t] + 0.398 reward + 0.041 harvest_duration + -0.065 value_stay^2 + -0.001 value_stay*reward + -0.287 value_stay*harvest_duration + 0.292 reward^2 + 0.398 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.059 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 229/1000 --- L(Train): 0.0064195 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.715 value_stay[t] + 0.398 reward + 0.041 harvest_duration + -0.064 value_stay^2 + 0.0 value_stay*reward + -0.287 value_stay*harvest_duration + 0.291 reward^2 + 0.398 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.059 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 230/1000 --- L(Train): 0.0064139 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.714 value_stay[t] + 0.398 reward + 0.041 harvest_duration + -0.064 value_stay^2 + 0.001 value_stay*reward + -0.287 value_stay*harvest_duration + 0.291 reward^2 + 0.398 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.059 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 231/1000 --- L(Train): 0.0064087 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.714 value_stay[t] + 0.398 reward + 0.041 harvest_duration + -0.063 value_stay^2 + 0.001 value_stay*reward + -0.288 value_stay*harvest_duration + 0.29 reward^2 + 0.399 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.059 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 232/1000 --- L(Train): 0.0064035 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.714 value_stay[t] + 0.398 reward + 0.041 harvest_duration + -0.062 value_stay^2 + 0.001 value_stay*reward + -0.288 value_stay*harvest_duration + 0.289 reward^2 + 0.399 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.059 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 233/1000 --- L(Train): 0.0063982 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.713 value_stay[t] + 0.399 reward + 0.041 harvest_duration + -0.062 value_stay^2 + 0.0 value_stay*reward + -0.289 value_stay*harvest_duration + 0.288 reward^2 + 0.399 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.06 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 234/1000 --- L(Train): 0.0063925 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.713 value_stay[t] + 0.399 reward + 0.041 harvest_duration + -0.061 value_stay^2 + -0.0 value_stay*reward + -0.289 value_stay*harvest_duration + 0.288 reward^2 + 0.399 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.06 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 235/1000 --- L(Train): 0.0063876 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.712 value_stay[t] + 0.399 reward + 0.041 harvest_duration + -0.061 value_stay^2 + -0.0 value_stay*reward + -0.289 value_stay*harvest_duration + 0.287 reward^2 + 0.399 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.06 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 236/1000 --- L(Train): 0.0063828 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.712 value_stay[t] + 0.399 reward + 0.041 harvest_duration + -0.06 value_stay^2 + 0.001 value_stay*reward + -0.29 value_stay*harvest_duration + 0.286 reward^2 + 0.399 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.06 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 237/1000 --- L(Train): 0.0063779 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.712 value_stay[t] + 0.399 reward + 0.041 harvest_duration + -0.06 value_stay^2 + 0.001 value_stay*reward + -0.29 value_stay*harvest_duration + 0.286 reward^2 + 0.399 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.061 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 238/1000 --- L(Train): 0.0063726 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.711 value_stay[t] + 0.399 reward + 0.041 harvest_duration + -0.059 value_stay^2 + 0.001 value_stay*reward + -0.29 value_stay*harvest_duration + 0.285 reward^2 + 0.4 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.061 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 239/1000 --- L(Train): 0.0063673 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.711 value_stay[t] + 0.399 reward + 0.041 harvest_duration + -0.059 value_stay^2 + 0.001 value_stay*reward + -0.291 value_stay*harvest_duration + 0.284 reward^2 + 0.4 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.061 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 240/1000 --- L(Train): 0.0063624 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.711 value_stay[t] + 0.4 reward + 0.041 harvest_duration + -0.058 value_stay^2 + -0.0 value_stay*reward + -0.291 value_stay*harvest_duration + 0.284 reward^2 + 0.4 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.061 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 241/1000 --- L(Train): 0.0063573 --- L(Val, SINDy): 0.0000000 --- Time: 0.09s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.71 value_stay[t] + 0.4 reward + 0.041 harvest_duration + -0.057 value_stay^2 + 0.0 value_stay*reward + -0.292 value_stay*harvest_duration + 0.283 reward^2 + 0.4 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.062 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 242/1000 --- L(Train): 0.0063527 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.71 value_stay[t] + 0.4 reward + 0.042 harvest_duration + -0.057 value_stay^2 + -0.0 value_stay*reward + -0.292 value_stay*harvest_duration + 0.282 reward^2 + 0.4 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.062 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 243/1000 --- L(Train): 0.0063482 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.709 value_stay[t] + 0.4 reward + 0.042 harvest_duration + -0.056 value_stay^2 + 0.001 value_stay*reward + -0.292 value_stay*harvest_duration + 0.281 reward^2 + 0.4 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.062 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 244/1000 --- L(Train): 0.0063435 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.709 value_stay[t] + 0.4 reward + 0.042 harvest_duration + -0.056 value_stay^2 + 0.001 value_stay*reward + -0.293 value_stay*harvest_duration + 0.281 reward^2 + 0.4 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.062 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 245/1000 --- L(Train): 0.0063387 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.709 value_stay[t] + 0.4 reward + 0.042 harvest_duration + -0.055 value_stay^2 + 0.001 value_stay*reward + -0.293 value_stay*harvest_duration + 0.28 reward^2 + 0.401 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.063 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 246/1000 --- L(Train): 0.0063340 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.708 value_stay[t] + 0.4 reward + 0.042 harvest_duration + -0.055 value_stay^2 + 0.0 value_stay*reward + -0.293 value_stay*harvest_duration + 0.279 reward^2 + 0.401 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.063 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 247/1000 --- L(Train): 0.0063299 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.708 value_stay[t] + 0.401 reward + 0.042 harvest_duration + -0.054 value_stay^2 + -0.001 value_stay*reward + -0.294 value_stay*harvest_duration + 0.279 reward^2 + 0.401 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.063 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 248/1000 --- L(Train): 0.0063253 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.708 value_stay[t] + 0.401 reward + 0.042 harvest_duration + -0.054 value_stay^2 + -0.001 value_stay*reward + -0.294 value_stay*harvest_duration + 0.278 reward^2 + 0.401 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.063 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 249/1000 --- L(Train): 0.0063206 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.707 value_stay[t] + 0.401 reward + 0.042 harvest_duration + -0.053 value_stay^2 + 0.0 value_stay*reward + -0.295 value_stay*harvest_duration + 0.277 reward^2 + 0.401 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.063 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 250/1000 --- L(Train): 0.0063160 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.707 value_stay[t] + 0.401 reward + 0.042 harvest_duration + -0.052 value_stay^2 + 0.001 value_stay*reward + -0.295 value_stay*harvest_duration + 0.276 reward^2 + 0.401 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.064 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 251/1000 --- L(Train): 0.0063117 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.706 value_stay[t] + 0.401 reward + 0.042 harvest_duration + -0.052 value_stay^2 + 0.001 value_stay*reward + -0.295 value_stay*harvest_duration + 0.276 reward^2 + 0.401 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.064 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 1, 0, 0, 1, 0, 1, 0, 0, 0, 1\n",
      "value_exit: 1, 1, 1, 1, 0, 1\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 252/1000 --- L(Train): 0.0063072 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.706 value_stay[t] + 0.401 reward + 0.042 harvest_duration + -0.051 value_stay^2 + 0.0 value_stay*reward + -0.296 value_stay*harvest_duration + 0.275 reward^2 + 0.402 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.064 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 2, 0, 0, 2, 0, 2, 0, 0, 0, 2\n",
      "value_exit: 2, 2, 2, 2, 0, 2\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 253/1000 --- L(Train): 0.0063029 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.706 value_stay[t] + 0.401 reward + 0.042 harvest_duration + -0.051 value_stay^2 + -0.0 value_stay*reward + -0.296 value_stay*harvest_duration + 0.274 reward^2 + 0.402 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.064 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 3, 0, 0, 3, 0, 3, 0, 0, 0, 3\n",
      "value_exit: 3, 3, 3, 3, 0, 3\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 254/1000 --- L(Train): 0.0062984 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.705 value_stay[t] + 0.402 reward + 0.042 harvest_duration + -0.05 value_stay^2 + -0.0 value_stay*reward + -0.296 value_stay*harvest_duration + 0.273 reward^2 + 0.402 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.065 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 4, 0, 0, 4, 0, 4, 0, 0, 0, 4\n",
      "value_exit: 4, 4, 4, 4, 0, 4\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 255/1000 --- L(Train): 0.0062942 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.705 value_stay[t] + 0.402 reward + 0.042 harvest_duration + -0.049 value_stay^2 + 0.001 value_stay*reward + -0.297 value_stay*harvest_duration + 0.273 reward^2 + 0.402 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.065 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 5, 0, 0, 5, 1, 5, 0, 0, 0, 5\n",
      "value_exit: 5, 5, 5, 5, 0, 5\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 256/1000 --- L(Train): 0.0062898 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.705 value_stay[t] + 0.402 reward + 0.042 harvest_duration + -0.049 value_stay^2 + 0.001 value_stay*reward + -0.297 value_stay*harvest_duration + 0.272 reward^2 + 0.402 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.065 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 6, 0, 0, 6, 2, 6, 0, 0, 0, 6\n",
      "value_exit: 6, 6, 6, 6, 0, 6\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 257/1000 --- L(Train): 0.0062852 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.704 value_stay[t] + 0.402 reward + 0.042 harvest_duration + -0.048 value_stay^2 + 0.001 value_stay*reward + -0.298 value_stay*harvest_duration + 0.271 reward^2 + 0.402 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.065 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 7, 0, 0, 7, 3, 7, 0, 0, 0, 7\n",
      "value_exit: 7, 7, 7, 7, 0, 7\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 258/1000 --- L(Train): 0.0062809 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.704 value_stay[t] + 0.402 reward + 0.043 harvest_duration + -0.048 value_stay^2 + 0.001 value_stay*reward + -0.298 value_stay*harvest_duration + 0.27 reward^2 + 0.402 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.065 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 8, 0, 0, 8, 4, 8, 0, 0, 0, 8\n",
      "value_exit: 8, 8, 8, 8, 0, 8\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 259/1000 --- L(Train): 0.0062765 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.704 value_stay[t] + 0.402 reward + 0.043 harvest_duration + -0.047 value_stay^2 + 0.0 value_stay*reward + -0.298 value_stay*harvest_duration + 0.27 reward^2 + 0.403 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.066 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 9, 0, 0, 9, 5, 9, 0, 0, 0, 9\n",
      "value_exit: 9, 9, 9, 9, 0, 9\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 260/1000 --- L(Train): 0.0062723 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.703 value_stay[t] + 0.402 reward + 0.043 harvest_duration + -0.047 value_stay^2 + -0.001 value_stay*reward + -0.299 value_stay*harvest_duration + 0.269 reward^2 + 0.403 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.066 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 10, 0, 0, 10, 6, 10, 0, 0, 0, 10\n",
      "value_exit: 10, 10, 10, 10, 0, 10\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 261/1000 --- L(Train): 0.0062683 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.703 value_stay[t] + 0.403 reward + 0.043 harvest_duration + -0.046 value_stay^2 + -0.001 value_stay*reward + -0.299 value_stay*harvest_duration + 0.268 reward^2 + 0.403 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.066 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 11, 0, 0, 11, 7, 11, 0, 0, 0, 11\n",
      "value_exit: 11, 11, 11, 11, 0, 11\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 262/1000 --- L(Train): 0.0062642 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.702 value_stay[t] + 0.403 reward + 0.043 harvest_duration + -0.045 value_stay^2 + 0.0 value_stay*reward + -0.299 value_stay*harvest_duration + 0.267 reward^2 + 0.403 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.066 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 12, 0, 0, 12, 8, 12, 0, 0, 0, 12\n",
      "value_exit: 12, 12, 12, 12, 0, 12\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 263/1000 --- L(Train): 0.0062599 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.702 value_stay[t] + 0.403 reward + 0.043 harvest_duration + -0.045 value_stay^2 + 0.0 value_stay*reward + -0.3 value_stay*harvest_duration + 0.267 reward^2 + 0.403 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.001 value_exit^2 + -0.067 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 13, 0, 0, 13, 9, 13, 0, 0, 0, 13\n",
      "value_exit: 13, 13, 13, 13, 0, 13\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 264/1000 --- L(Train): 0.0062558 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.702 value_stay[t] + 0.403 reward + 0.043 harvest_duration + -0.044 value_stay^2 + 0.0 value_stay*reward + -0.3 value_stay*harvest_duration + 0.266 reward^2 + 0.403 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.067 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 14, 0, 0, 14, 10, 14, 0, 0, 0, 14\n",
      "value_exit: 14, 14, 14, 14, 0, 14\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 265/1000 --- L(Train): 0.0062515 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.701 value_stay[t] + 0.403 reward + 0.043 harvest_duration + -0.044 value_stay^2 + -0.0 value_stay*reward + -0.3 value_stay*harvest_duration + 0.265 reward^2 + 0.403 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.067 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 15, 0, 0, 15, 11, 15, 0, 0, 0, 15\n",
      "value_exit: 15, 15, 15, 15, 0, 15\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 266/1000 --- L(Train): 0.0062476 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.701 value_stay[t] + 0.403 reward + 0.043 harvest_duration + -0.043 value_stay^2 + 0.0 value_stay*reward + -0.301 value_stay*harvest_duration + 0.264 reward^2 + 0.404 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.067 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 16, 0, 0, 16, 12, 16, 0, 0, 0, 16\n",
      "value_exit: 16, 16, 16, 16, 0, 16\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 267/1000 --- L(Train): 0.0062437 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.701 value_stay[t] + 0.403 reward + 0.043 harvest_duration + -0.043 value_stay^2 + 0.0 value_stay*reward + -0.301 value_stay*harvest_duration + 0.264 reward^2 + 0.404 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.067 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 17, 0, 0, 17, 13, 17, 0, 0, 0, 17\n",
      "value_exit: 17, 17, 17, 17, 0, 17\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 268/1000 --- L(Train): 0.0062395 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.7 value_stay[t] + 0.404 reward + 0.043 harvest_duration + -0.042 value_stay^2 + 0.0 value_stay*reward + -0.302 value_stay*harvest_duration + 0.263 reward^2 + 0.404 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.068 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 18, 0, 0, 18, 14, 18, 0, 0, 0, 18\n",
      "value_exit: 18, 18, 18, 18, 0, 18\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 269/1000 --- L(Train): 0.0062354 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.7 value_stay[t] + 0.404 reward + 0.044 harvest_duration + -0.041 value_stay^2 + -0.001 value_stay*reward + -0.302 value_stay*harvest_duration + 0.262 reward^2 + 0.404 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.068 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 19, 0, 0, 19, 15, 19, 0, 0, 0, 19\n",
      "value_exit: 19, 19, 19, 19, 0, 19\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 270/1000 --- L(Train): 0.0062318 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.699 value_stay[t] + 0.404 reward + 0.044 harvest_duration + -0.041 value_stay^2 + -0.001 value_stay*reward + -0.302 value_stay*harvest_duration + 0.261 reward^2 + 0.404 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.068 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 20, 0, 0, 20, 16, 20, 0, 0, 0, 20\n",
      "value_exit: 20, 20, 20, 20, 0, 20\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 271/1000 --- L(Train): 0.0062279 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.699 value_stay[t] + 0.404 reward + 0.043 harvest_duration + -0.04 value_stay^2 + 0.001 value_stay*reward + -0.303 value_stay*harvest_duration + 0.261 reward^2 + 0.404 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.068 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 21, 0, 0, 21, 17, 21, 0, 0, 0, 21\n",
      "value_exit: 21, 21, 21, 21, 0, 21\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 272/1000 --- L(Train): 0.0062241 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.699 value_stay[t] + 0.404 reward + 0.044 harvest_duration + -0.04 value_stay^2 + 0.001 value_stay*reward + -0.303 value_stay*harvest_duration + 0.26 reward^2 + 0.404 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.068 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 22, 0, 0, 22, 18, 22, 0, 0, 0, 22\n",
      "value_exit: 22, 22, 22, 22, 0, 22\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 273/1000 --- L(Train): 0.0062204 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.698 value_stay[t] + 0.404 reward + 0.044 harvest_duration + -0.039 value_stay^2 + 0.001 value_stay*reward + -0.303 value_stay*harvest_duration + 0.259 reward^2 + 0.405 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.069 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 23, 0, 0, 23, 19, 23, 0, 0, 0, 23\n",
      "value_exit: 23, 23, 23, 23, 0, 23\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 274/1000 --- L(Train): 0.0062167 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.698 value_stay[t] + 0.404 reward + 0.044 harvest_duration + -0.039 value_stay^2 + 0.001 value_stay*reward + -0.304 value_stay*harvest_duration + 0.258 reward^2 + 0.405 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.069 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 24, 0, 0, 24, 20, 24, 0, 0, 0, 24\n",
      "value_exit: 24, 24, 24, 24, 0, 24\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 275/1000 --- L(Train): 0.0062132 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.698 value_stay[t] + 0.404 reward + 0.044 harvest_duration + -0.038 value_stay^2 + 0.0 value_stay*reward + -0.304 value_stay*harvest_duration + 0.257 reward^2 + 0.405 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.069 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 25, 0, 0, 25, 21, 25, 0, 0, 0, 25\n",
      "value_exit: 25, 25, 25, 25, 0, 25\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 276/1000 --- L(Train): 0.0062099 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.697 value_stay[t] + 0.405 reward + 0.044 harvest_duration + -0.037 value_stay^2 + -0.001 value_stay*reward + -0.305 value_stay*harvest_duration + 0.257 reward^2 + 0.405 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.069 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 26, 0, 0, 26, 22, 26, 0, 0, 0, 26\n",
      "value_exit: 26, 26, 26, 26, 0, 26\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 277/1000 --- L(Train): 0.0062065 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.697 value_stay[t] + 0.405 reward + 0.044 harvest_duration + -0.037 value_stay^2 + -0.001 value_stay*reward + -0.305 value_stay*harvest_duration + 0.256 reward^2 + 0.405 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.069 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 27, 0, 0, 27, 23, 27, 0, 0, 0, 27\n",
      "value_exit: 27, 27, 27, 27, 0, 27\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 278/1000 --- L(Train): 0.0062030 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.697 value_stay[t] + 0.405 reward + 0.044 harvest_duration + -0.036 value_stay^2 + 0.0 value_stay*reward + -0.305 value_stay*harvest_duration + 0.255 reward^2 + 0.405 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.07 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 28, 0, 0, 28, 24, 28, 0, 0, 0, 28\n",
      "value_exit: 28, 28, 28, 28, 0, 28\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 279/1000 --- L(Train): 0.0061994 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.696 value_stay[t] + 0.405 reward + 0.044 harvest_duration + -0.036 value_stay^2 + 0.0 value_stay*reward + -0.306 value_stay*harvest_duration + 0.254 reward^2 + 0.405 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.07 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 29, 0, 0, 29, 25, 29, 0, 0, 0, 29\n",
      "value_exit: 29, 29, 29, 29, 0, 29\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 280/1000 --- L(Train): 0.0061952 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.696 value_stay[t] + 0.405 reward + 0.044 harvest_duration + -0.035 value_stay^2 + 0.0 value_stay*reward + -0.306 value_stay*harvest_duration + 0.254 reward^2 + 0.406 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.07 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 30, 0, 0, 30, 26, 30, 0, 0, 0, 30\n",
      "value_exit: 30, 30, 30, 30, 0, 30\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 281/1000 --- L(Train): 0.0061915 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.695 value_stay[t] + 0.405 reward + 0.044 harvest_duration + -0.035 value_stay^2 + -0.0 value_stay*reward + -0.306 value_stay*harvest_duration + 0.253 reward^2 + 0.406 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.07 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 31, 0, 0, 31, 27, 31, 0, 0, 0, 31\n",
      "value_exit: 31, 31, 31, 31, 0, 31\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 282/1000 --- L(Train): 0.0061883 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.695 value_stay[t] + 0.405 reward + 0.044 harvest_duration + -0.034 value_stay^2 + 0.0 value_stay*reward + -0.307 value_stay*harvest_duration + 0.252 reward^2 + 0.406 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.07 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 32, 0, 0, 32, 28, 32, 0, 0, 0, 32\n",
      "value_exit: 32, 32, 32, 32, 0, 32\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 283/1000 --- L(Train): 0.0061851 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.695 value_stay[t] + 0.406 reward + 0.044 harvest_duration + -0.034 value_stay^2 + 0.0 value_stay*reward + -0.307 value_stay*harvest_duration + 0.251 reward^2 + 0.406 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.071 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 33, 0, 0, 33, 29, 33, 0, 0, 0, 33\n",
      "value_exit: 33, 33, 33, 33, 0, 33\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 284/1000 --- L(Train): 0.0061820 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.694 value_stay[t] + 0.406 reward + 0.044 harvest_duration + -0.033 value_stay^2 + 0.0 value_stay*reward + -0.308 value_stay*harvest_duration + 0.25 reward^2 + 0.406 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.071 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 34, 0, 0, 34, 30, 34, 0, 0, 0, 34\n",
      "value_exit: 34, 34, 34, 34, 0, 34\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 285/1000 --- L(Train): 0.0061785 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.694 value_stay[t] + 0.406 reward + 0.045 harvest_duration + -0.032 value_stay^2 + -0.001 value_stay*reward + -0.308 value_stay*harvest_duration + 0.25 reward^2 + 0.406 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.071 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 35, 0, 0, 35, 31, 35, 0, 0, 0, 35\n",
      "value_exit: 35, 35, 35, 35, 0, 35\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 286/1000 --- L(Train): 0.0061749 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.694 value_stay[t] + 0.406 reward + 0.045 harvest_duration + -0.032 value_stay^2 + -0.0 value_stay*reward + -0.308 value_stay*harvest_duration + 0.249 reward^2 + 0.406 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.071 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 36, 0, 0, 36, 32, 36, 0, 0, 0, 36\n",
      "value_exit: 36, 36, 36, 36, 0, 36\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 287/1000 --- L(Train): 0.0061717 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.693 value_stay[t] + 0.406 reward + 0.045 harvest_duration + -0.031 value_stay^2 + 0.001 value_stay*reward + -0.309 value_stay*harvest_duration + 0.248 reward^2 + 0.407 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.071 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 37, 0, 0, 37, 33, 37, 0, 0, 0, 37\n",
      "value_exit: 37, 37, 37, 37, 0, 37\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 288/1000 --- L(Train): 0.0061686 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.693 value_stay[t] + 0.406 reward + 0.045 harvest_duration + -0.031 value_stay^2 + 0.001 value_stay*reward + -0.309 value_stay*harvest_duration + 0.247 reward^2 + 0.407 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.072 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 38, 0, 0, 38, 34, 38, 0, 0, 0, 38\n",
      "value_exit: 38, 38, 38, 38, 0, 38\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 289/1000 --- L(Train): 0.0061654 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.692 value_stay[t] + 0.407 reward + 0.045 harvest_duration + -0.03 value_stay^2 + 0.001 value_stay*reward + -0.309 value_stay*harvest_duration + 0.246 reward^2 + 0.407 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.072 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 39, 0, 0, 39, 35, 39, 0, 0, 0, 39\n",
      "value_exit: 39, 39, 39, 39, 0, 39\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 290/1000 --- L(Train): 0.0061621 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.692 value_stay[t] + 0.407 reward + 0.045 harvest_duration + -0.03 value_stay^2 + 0.001 value_stay*reward + -0.31 value_stay*harvest_duration + 0.246 reward^2 + 0.407 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.072 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 40, 0, 0, 40, 36, 40, 0, 0, 0, 40\n",
      "value_exit: 40, 40, 40, 40, 0, 40\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 291/1000 --- L(Train): 0.0061587 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.692 value_stay[t] + 0.407 reward + 0.045 harvest_duration + -0.029 value_stay^2 + 0.0 value_stay*reward + -0.31 value_stay*harvest_duration + 0.245 reward^2 + 0.407 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.072 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 41, 0, 0, 41, 37, 41, 0, 0, 0, 41\n",
      "value_exit: 41, 41, 41, 41, 0, 41\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 292/1000 --- L(Train): 0.0061552 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.691 value_stay[t] + 0.407 reward + 0.045 harvest_duration + -0.028 value_stay^2 + -0.001 value_stay*reward + -0.311 value_stay*harvest_duration + 0.244 reward^2 + 0.407 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.072 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 42, 0, 0, 42, 38, 42, 0, 0, 0, 42\n",
      "value_exit: 42, 42, 42, 42, 0, 42\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 293/1000 --- L(Train): 0.0061518 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.691 value_stay[t] + 0.407 reward + 0.045 harvest_duration + -0.028 value_stay^2 + -0.001 value_stay*reward + -0.311 value_stay*harvest_duration + 0.243 reward^2 + 0.407 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.073 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 43, 0, 0, 43, 39, 43, 0, 0, 0, 43\n",
      "value_exit: 43, 43, 43, 43, 0, 43\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 294/1000 --- L(Train): 0.0061481 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.691 value_stay[t] + 0.407 reward + 0.045 harvest_duration + -0.027 value_stay^2 + 0.0 value_stay*reward + -0.311 value_stay*harvest_duration + 0.242 reward^2 + 0.408 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.073 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 44, 0, 0, 44, 40, 44, 0, 0, 0, 44\n",
      "value_exit: 44, 44, 44, 44, 0, 44\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 295/1000 --- L(Train): 0.0061451 --- L(Val, SINDy): 0.0000000 --- Time: 0.09s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.69 value_stay[t] + 0.407 reward + 0.045 harvest_duration + -0.027 value_stay^2 + 0.001 value_stay*reward + -0.312 value_stay*harvest_duration + 0.242 reward^2 + 0.408 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.073 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 45, 0, 0, 45, 41, 45, 0, 0, 0, 45\n",
      "value_exit: 45, 45, 45, 45, 0, 45\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 296/1000 --- L(Train): 0.0061426 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.69 value_stay[t] + 0.408 reward + 0.045 harvest_duration + -0.026 value_stay^2 + 0.001 value_stay*reward + -0.312 value_stay*harvest_duration + 0.241 reward^2 + 0.408 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.073 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 46, 0, 0, 46, 42, 46, 0, 0, 0, 46\n",
      "value_exit: 46, 46, 46, 46, 0, 46\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 297/1000 --- L(Train): 0.0061397 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.689 value_stay[t] + 0.408 reward + 0.045 harvest_duration + -0.026 value_stay^2 + 0.0 value_stay*reward + -0.312 value_stay*harvest_duration + 0.24 reward^2 + 0.408 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.073 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 47, 0, 0, 47, 43, 47, 0, 0, 0, 47\n",
      "value_exit: 47, 47, 47, 47, 0, 47\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 298/1000 --- L(Train): 0.0061365 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.689 value_stay[t] + 0.408 reward + 0.045 harvest_duration + -0.025 value_stay^2 + -0.001 value_stay*reward + -0.313 value_stay*harvest_duration + 0.239 reward^2 + 0.408 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.074 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 48, 0, 0, 48, 44, 48, 0, 0, 0, 48\n",
      "value_exit: 48, 48, 48, 48, 0, 48\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 299/1000 --- L(Train): 0.0061331 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.689 value_stay[t] + 0.408 reward + 0.046 harvest_duration + -0.024 value_stay^2 + -0.0 value_stay*reward + -0.313 value_stay*harvest_duration + 0.239 reward^2 + 0.408 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.074 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 49, 0, 0, 49, 45, 49, 0, 0, 0, 49\n",
      "value_exit: 49, 49, 49, 49, 0, 49\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 300/1000 --- L(Train): 0.0061301 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.688 value_stay[t] + 0.408 reward + 0.046 harvest_duration + -0.024 value_stay^2 + 0.001 value_stay*reward + -0.313 value_stay*harvest_duration + 0.238 reward^2 + 0.408 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.074 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 50, 0, 0, 50, 46, 50, 0, 0, 0, 50\n",
      "value_exit: 50, 50, 50, 50, 0, 50\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 301/1000 --- L(Train): 0.0061274 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.688 value_stay[t] + 0.408 reward + 0.045 harvest_duration + -0.023 value_stay^2 + 0.001 value_stay*reward + -0.314 value_stay*harvest_duration + 0.237 reward^2 + 0.409 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.074 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 51, 0, 0, 51, 47, 51, 0, 0, 0, 51\n",
      "value_exit: 51, 51, 51, 51, 0, 51\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 302/1000 --- L(Train): 0.0061248 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.688 value_stay[t] + 0.408 reward + 0.046 harvest_duration + -0.023 value_stay^2 + 0.001 value_stay*reward + -0.314 value_stay*harvest_duration + 0.236 reward^2 + 0.409 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.074 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 52, 0, 0, 52, 48, 52, 0, 0, 0, 52\n",
      "value_exit: 52, 52, 52, 52, 0, 52\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 303/1000 --- L(Train): 0.0061214 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.687 value_stay[t] + 0.409 reward + 0.046 harvest_duration + -0.022 value_stay^2 + 0.001 value_stay*reward + -0.315 value_stay*harvest_duration + 0.235 reward^2 + 0.409 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.074 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 53, 0, 0, 53, 49, 53, 0, 0, 0, 53\n",
      "value_exit: 53, 53, 53, 53, 0, 53\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 304/1000 --- L(Train): 0.0061183 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.687 value_stay[t] + 0.409 reward + 0.046 harvest_duration + -0.022 value_stay^2 + 0.0 value_stay*reward + -0.315 value_stay*harvest_duration + 0.234 reward^2 + 0.409 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.075 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 54, 0, 0, 54, 50, 54, 0, 0, 0, 54\n",
      "value_exit: 54, 54, 54, 54, 0, 54\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 305/1000 --- L(Train): 0.0061156 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.686 value_stay[t] + 0.409 reward + 0.046 harvest_duration + -0.021 value_stay^2 + -0.001 value_stay*reward + -0.315 value_stay*harvest_duration + 0.234 reward^2 + 0.409 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.075 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 55, 0, 0, 55, 51, 55, 0, 0, 0, 55\n",
      "value_exit: 55, 55, 55, 55, 0, 55\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 306/1000 --- L(Train): 0.0061129 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.686 value_stay[t] + 0.409 reward + 0.046 harvest_duration + -0.02 value_stay^2 + -0.001 value_stay*reward + -0.316 value_stay*harvest_duration + 0.233 reward^2 + 0.409 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.075 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 56, 0, 0, 56, 52, 56, 0, 0, 0, 56\n",
      "value_exit: 56, 56, 56, 56, 0, 56\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 307/1000 --- L(Train): 0.0061098 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.686 value_stay[t] + 0.409 reward + 0.046 harvest_duration + -0.02 value_stay^2 + 0.0 value_stay*reward + -0.316 value_stay*harvest_duration + 0.232 reward^2 + 0.409 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.075 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 57, 0, 0, 57, 53, 57, 0, 0, 0, 57\n",
      "value_exit: 57, 57, 57, 57, 0, 57\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 308/1000 --- L(Train): 0.0061070 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.685 value_stay[t] + 0.409 reward + 0.046 harvest_duration + -0.019 value_stay^2 + 0.001 value_stay*reward + -0.317 value_stay*harvest_duration + 0.231 reward^2 + 0.41 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.075 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 58, 0, 0, 58, 54, 58, 0, 0, 0, 58\n",
      "value_exit: 58, 58, 58, 58, 0, 58\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 309/1000 --- L(Train): 0.0061045 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.685 value_stay[t] + 0.41 reward + 0.046 harvest_duration + -0.019 value_stay^2 + 0.001 value_stay*reward + -0.317 value_stay*harvest_duration + 0.23 reward^2 + 0.41 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.076 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 59, 0, 0, 59, 55, 59, 0, 0, 0, 59\n",
      "value_exit: 59, 59, 59, 59, 0, 59\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 310/1000 --- L(Train): 0.0061018 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.685 value_stay[t] + 0.41 reward + 0.046 harvest_duration + -0.018 value_stay^2 + 0.0 value_stay*reward + -0.317 value_stay*harvest_duration + 0.23 reward^2 + 0.41 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.076 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 60, 0, 0, 60, 56, 60, 0, 0, 0, 60\n",
      "value_exit: 60, 60, 60, 60, 0, 60\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 311/1000 --- L(Train): 0.0060994 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.684 value_stay[t] + 0.41 reward + 0.046 harvest_duration + -0.018 value_stay^2 + -0.001 value_stay*reward + -0.318 value_stay*harvest_duration + 0.229 reward^2 + 0.41 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.076 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 61, 0, 0, 61, 57, 61, 0, 0, 0, 61\n",
      "value_exit: 61, 61, 61, 61, 0, 61\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 312/1000 --- L(Train): 0.0060969 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.684 value_stay[t] + 0.41 reward + 0.047 harvest_duration + -0.017 value_stay^2 + -0.0 value_stay*reward + -0.318 value_stay*harvest_duration + 0.228 reward^2 + 0.41 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.076 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 62, 0, 0, 62, 58, 62, 0, 0, 0, 62\n",
      "value_exit: 62, 62, 62, 62, 0, 62\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 313/1000 --- L(Train): 0.0060944 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.684 value_stay[t] + 0.41 reward + 0.047 harvest_duration + -0.016 value_stay^2 + 0.001 value_stay*reward + -0.318 value_stay*harvest_duration + 0.227 reward^2 + 0.41 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.076 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 63, 0, 0, 63, 59, 63, 0, 0, 0, 63\n",
      "value_exit: 63, 63, 63, 63, 0, 63\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 314/1000 --- L(Train): 0.0060920 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.683 value_stay[t] + 0.41 reward + 0.046 harvest_duration + -0.016 value_stay^2 + 0.001 value_stay*reward + -0.319 value_stay*harvest_duration + 0.226 reward^2 + 0.411 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.076 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 64, 0, 0, 64, 60, 64, 0, 0, 0, 64\n",
      "value_exit: 64, 64, 64, 64, 0, 64\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 315/1000 --- L(Train): 0.0060899 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.683 value_stay[t] + 0.41 reward + 0.047 harvest_duration + -0.015 value_stay^2 + 0.001 value_stay*reward + -0.319 value_stay*harvest_duration + 0.226 reward^2 + 0.411 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.077 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 65, 0, 0, 65, 61, 65, 0, 0, 0, 65\n",
      "value_exit: 65, 65, 65, 65, 0, 65\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 316/1000 --- L(Train): 0.0060870 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.682 value_stay[t] + 0.411 reward + 0.047 harvest_duration + -0.015 value_stay^2 + 0.001 value_stay*reward + -0.319 value_stay*harvest_duration + 0.225 reward^2 + 0.411 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.077 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 66, 0, 0, 66, 62, 66, 0, 0, 0, 66\n",
      "value_exit: 66, 66, 66, 66, 0, 66\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 317/1000 --- L(Train): 0.0060840 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.682 value_stay[t] + 0.411 reward + 0.047 harvest_duration + -0.014 value_stay^2 + 0.0 value_stay*reward + -0.32 value_stay*harvest_duration + 0.224 reward^2 + 0.411 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.077 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 67, 0, 0, 67, 63, 67, 0, 0, 0, 67\n",
      "value_exit: 67, 67, 67, 67, 0, 67\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 318/1000 --- L(Train): 0.0060813 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.682 value_stay[t] + 0.411 reward + 0.047 harvest_duration + -0.014 value_stay^2 + -0.001 value_stay*reward + -0.32 value_stay*harvest_duration + 0.223 reward^2 + 0.411 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.077 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 68, 0, 0, 68, 64, 68, 0, 0, 0, 68\n",
      "value_exit: 68, 68, 68, 68, 0, 68\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 319/1000 --- L(Train): 0.0060791 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.681 value_stay[t] + 0.411 reward + 0.047 harvest_duration + -0.013 value_stay^2 + -0.001 value_stay*reward + -0.32 value_stay*harvest_duration + 0.222 reward^2 + 0.411 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.077 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 69, 0, 0, 69, 65, 69, 0, 0, 0, 69\n",
      "value_exit: 69, 69, 69, 69, 0, 69\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 320/1000 --- L(Train): 0.0060773 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.681 value_stay[t] + 0.411 reward + 0.047 harvest_duration + -0.012 value_stay^2 + 0.0 value_stay*reward + -0.321 value_stay*harvest_duration + 0.221 reward^2 + 0.412 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.077 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 70, 0, 0, 70, 66, 70, 0, 0, 0, 70\n",
      "value_exit: 70, 70, 70, 70, 0, 70\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 321/1000 --- L(Train): 0.0060753 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.681 value_stay[t] + 0.411 reward + 0.047 harvest_duration + -0.012 value_stay^2 + 0.001 value_stay*reward + -0.321 value_stay*harvest_duration + 0.221 reward^2 + 0.412 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.078 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 71, 0, 0, 71, 67, 71, 0, 0, 0, 71\n",
      "value_exit: 71, 71, 71, 71, 0, 71\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 322/1000 --- L(Train): 0.0060729 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.68 value_stay[t] + 0.412 reward + 0.047 harvest_duration + -0.011 value_stay^2 + 0.001 value_stay*reward + -0.322 value_stay*harvest_duration + 0.22 reward^2 + 0.412 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.078 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 72, 0, 0, 72, 68, 72, 0, 0, 0, 72\n",
      "value_exit: 72, 72, 72, 72, 0, 72\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 323/1000 --- L(Train): 0.0060701 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.68 value_stay[t] + 0.412 reward + 0.047 harvest_duration + -0.011 value_stay^2 + 0.0 value_stay*reward + -0.322 value_stay*harvest_duration + 0.219 reward^2 + 0.412 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.078 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 73, 0, 0, 73, 69, 73, 0, 0, 0, 73\n",
      "value_exit: 73, 73, 73, 73, 0, 73\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 324/1000 --- L(Train): 0.0060674 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.679 value_stay[t] + 0.412 reward + 0.047 harvest_duration + -0.01 value_stay^2 + -0.001 value_stay*reward + -0.322 value_stay*harvest_duration + 0.218 reward^2 + 0.412 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.078 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 74, 0, 0, 74, 70, 74, 0, 0, 0, 74\n",
      "value_exit: 74, 74, 74, 74, 0, 74\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 325/1000 --- L(Train): 0.0060650 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.679 value_stay[t] + 0.412 reward + 0.048 harvest_duration + -0.01 value_stay^2 + -0.0 value_stay*reward + -0.323 value_stay*harvest_duration + 0.217 reward^2 + 0.412 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.078 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 75, 0, 0, 75, 71, 75, 0, 0, 0, 75\n",
      "value_exit: 75, 75, 75, 75, 0, 75\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 326/1000 --- L(Train): 0.0060629 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.679 value_stay[t] + 0.412 reward + 0.048 harvest_duration + -0.009 value_stay^2 + 0.001 value_stay*reward + -0.323 value_stay*harvest_duration + 0.216 reward^2 + 0.412 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.078 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 76, 0, 0, 76, 72, 76, 0, 0, 0, 76\n",
      "value_exit: 76, 76, 76, 76, 0, 76\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 327/1000 --- L(Train): 0.0060612 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.678 value_stay[t] + 0.412 reward + 0.047 harvest_duration + -0.009 value_stay^2 + 0.001 value_stay*reward + -0.324 value_stay*harvest_duration + 0.216 reward^2 + 0.413 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.079 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 77, 0, 0, 77, 73, 77, 0, 0, 0, 77\n",
      "value_exit: 77, 77, 77, 77, 0, 77\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 328/1000 --- L(Train): 0.0060593 --- L(Val, SINDy): 0.0000000 --- Time: 0.09s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.678 value_stay[t] + 0.412 reward + 0.048 harvest_duration + -0.008 value_stay^2 + 0.002 value_stay*reward + -0.324 value_stay*harvest_duration + 0.215 reward^2 + 0.413 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.079 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 78, 0, 0, 78, 74, 78, 0, 0, 0, 78\n",
      "value_exit: 78, 78, 78, 78, 0, 78\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 329/1000 --- L(Train): 0.0060574 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.678 value_stay[t] + 0.413 reward + 0.048 harvest_duration + -0.007 value_stay^2 + 0.001 value_stay*reward + -0.324 value_stay*harvest_duration + 0.214 reward^2 + 0.413 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.079 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 79, 0, 0, 79, 75, 79, 0, 0, 0, 79\n",
      "value_exit: 79, 79, 79, 79, 0, 79\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 330/1000 --- L(Train): 0.0060554 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.677 value_stay[t] + 0.413 reward + 0.047 harvest_duration + -0.007 value_stay^2 + 0.0 value_stay*reward + -0.325 value_stay*harvest_duration + 0.213 reward^2 + 0.413 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.079 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 80, 0, 0, 80, 76, 80, 0, 0, 0, 80\n",
      "value_exit: 80, 80, 80, 80, 0, 80\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 331/1000 --- L(Train): 0.0060533 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.677 value_stay[t] + 0.413 reward + 0.048 harvest_duration + -0.006 value_stay^2 + -0.001 value_stay*reward + -0.325 value_stay*harvest_duration + 0.212 reward^2 + 0.413 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.079 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 81, 0, 0, 81, 77, 81, 0, 0, 0, 81\n",
      "value_exit: 81, 81, 81, 81, 0, 81\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 332/1000 --- L(Train): 0.0060503 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.677 value_stay[t] + 0.413 reward + 0.048 harvest_duration + -0.006 value_stay^2 + -0.0 value_stay*reward + -0.325 value_stay*harvest_duration + 0.211 reward^2 + 0.413 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.079 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 82, 0, 0, 82, 78, 82, 0, 0, 0, 82\n",
      "value_exit: 82, 82, 82, 82, 0, 82\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 333/1000 --- L(Train): 0.0060475 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.676 value_stay[t] + 0.413 reward + 0.048 harvest_duration + -0.005 value_stay^2 + 0.0 value_stay*reward + -0.326 value_stay*harvest_duration + 0.211 reward^2 + 0.414 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.08 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 83, 0, 0, 83, 79, 83, 0, 0, 0, 83\n",
      "value_exit: 83, 83, 83, 83, 0, 83\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 334/1000 --- L(Train): 0.0060458 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.676 value_stay[t] + 0.413 reward + 0.048 harvest_duration + -0.005 value_stay^2 + 0.001 value_stay*reward + -0.326 value_stay*harvest_duration + 0.21 reward^2 + 0.414 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.08 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 84, 0, 0, 84, 80, 84, 0, 0, 0, 84\n",
      "value_exit: 84, 84, 84, 84, 0, 84\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 335/1000 --- L(Train): 0.0060443 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.675 value_stay[t] + 0.414 reward + 0.048 harvest_duration + -0.004 value_stay^2 + 0.001 value_stay*reward + -0.326 value_stay*harvest_duration + 0.209 reward^2 + 0.414 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.08 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 85, 0, 0, 85, 81, 85, 0, 0, 0, 85\n",
      "value_exit: 85, 85, 85, 85, 0, 85\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 336/1000 --- L(Train): 0.0060426 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.675 value_stay[t] + 0.414 reward + 0.048 harvest_duration + -0.003 value_stay^2 + 0.0 value_stay*reward + -0.327 value_stay*harvest_duration + 0.208 reward^2 + 0.414 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.08 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 86, 0, 0, 86, 82, 86, 0, 0, 0, 86\n",
      "value_exit: 86, 86, 86, 86, 0, 86\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 337/1000 --- L(Train): 0.0060406 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.675 value_stay[t] + 0.414 reward + 0.048 harvest_duration + -0.003 value_stay^2 + -0.0 value_stay*reward + -0.327 value_stay*harvest_duration + 0.207 reward^2 + 0.414 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.08 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 87, 0, 0, 87, 83, 87, 0, 0, 0, 87\n",
      "value_exit: 87, 87, 87, 87, 0, 87\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 338/1000 --- L(Train): 0.0060383 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.674 value_stay[t] + 0.414 reward + 0.049 harvest_duration + -0.002 value_stay^2 + -0.0 value_stay*reward + -0.328 value_stay*harvest_duration + 0.206 reward^2 + 0.414 reward*harvest_duration + 0.049 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.08 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 88, 0, 0, 88, 84, 88, 0, 0, 0, 88\n",
      "value_exit: 88, 88, 88, 88, 0, 88\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 339/1000 --- L(Train): 0.0060362 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.674 value_stay[t] + 0.414 reward + 0.048 harvest_duration + -0.002 value_stay^2 + 0.001 value_stay*reward + -0.328 value_stay*harvest_duration + 0.206 reward^2 + 0.415 reward*harvest_duration + 0.049 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.992 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.081 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 89, 0, 0, 89, 85, 89, 0, 0, 0, 89\n",
      "value_exit: 89, 89, 89, 89, 0, 89\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 340/1000 --- L(Train): 0.0060346 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.673 value_stay[t] + 0.414 reward + 0.048 harvest_duration + -0.001 value_stay^2 + 0.002 value_stay*reward + -0.328 value_stay*harvest_duration + 0.205 reward^2 + 0.415 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.992 value_exit[t] + -0.001 travel_duration + -0.001 value_exit^2 + -0.081 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 90, 0, 0, 90, 86, 90, 0, 0, 0, 90\n",
      "value_exit: 90, 90, 90, 90, 0, 90\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 341/1000 --- L(Train): 0.0060329 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.673 value_stay[t] + 0.415 reward + 0.049 harvest_duration + -0.001 value_stay^2 + 0.002 value_stay*reward + -0.329 value_stay*harvest_duration + 0.204 reward^2 + 0.415 reward*harvest_duration + 0.049 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.992 value_exit[t] + -0.001 travel_duration + -0.001 value_exit^2 + -0.081 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 91, 0, 0, 91, 87, 91, 0, 0, 0, 91\n",
      "value_exit: 91, 91, 91, 91, 0, 91\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 342/1000 --- L(Train): 0.0060309 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.673 value_stay[t] + 0.415 reward + 0.049 harvest_duration + 0.0 value_stay^2 + 0.002 value_stay*reward + -0.329 value_stay*harvest_duration + 0.203 reward^2 + 0.415 reward*harvest_duration + 0.049 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.992 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.081 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 92, 0, 0, 92, 88, 92, 0, 0, 0, 92\n",
      "value_exit: 92, 92, 92, 92, 0, 92\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 343/1000 --- L(Train): 0.0060287 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.672 value_stay[t] + 0.415 reward + 0.048 harvest_duration + 0.0 value_stay^2 + 0.001 value_stay*reward + -0.33 value_stay*harvest_duration + 0.202 reward^2 + 0.415 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.081 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 93, 0, 0, 93, 89, 93, 0, 0, 0, 93\n",
      "value_exit: 93, 93, 93, 93, 0, 93\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 344/1000 --- L(Train): 0.0060271 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.672 value_stay[t] + 0.415 reward + 0.049 harvest_duration + 0.0 value_stay^2 + -0.0 value_stay*reward + -0.33 value_stay*harvest_duration + 0.201 reward^2 + 0.415 reward*harvest_duration + 0.049 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.081 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 94, 0, 0, 94, 90, 94, 0, 0, 0, 94\n",
      "value_exit: 94, 94, 94, 94, 0, 94\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 345/1000 --- L(Train): 0.0060251 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.672 value_stay[t] + 0.415 reward + 0.049 harvest_duration + -0.0 value_stay^2 + -0.0 value_stay*reward + -0.33 value_stay*harvest_duration + 0.2 reward^2 + 0.416 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.993 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.081 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 95, 0, 0, 95, 91, 95, 0, 0, 0, 95\n",
      "value_exit: 95, 95, 95, 95, 0, 95\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 346/1000 --- L(Train): 0.0060231 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.671 value_stay[t] + 0.415 reward + 0.049 harvest_duration + -0.0 value_stay^2 + 0.001 value_stay*reward + -0.331 value_stay*harvest_duration + 0.2 reward^2 + 0.416 reward*harvest_duration + 0.049 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.993 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.082 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 96, 0, 0, 96, 92, 96, 0, 0, 0, 96\n",
      "value_exit: 96, 96, 96, 96, 0, 96\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 347/1000 --- L(Train): 0.0060214 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.671 value_stay[t] + 0.416 reward + 0.049 harvest_duration + -0.001 value_stay^2 + 0.002 value_stay*reward + -0.331 value_stay*harvest_duration + 0.199 reward^2 + 0.416 reward*harvest_duration + 0.049 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.993 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.082 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 97, 0, 0, 97, 93, 97, 0, 0, 0, 97\n",
      "value_exit: 97, 97, 97, 97, 0, 97\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 348/1000 --- L(Train): 0.0060200 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.05 1 + 0.671 value_stay[t] + 0.416 reward + 0.05 harvest_duration + -0.0 value_stay^2 + 0.002 value_stay*reward + -0.331 value_stay*harvest_duration + 0.198 reward^2 + 0.416 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.993 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.082 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 98, 0, 0, 98, 94, 98, 0, 0, 0, 98\n",
      "value_exit: 98, 98, 98, 98, 0, 98\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 349/1000 --- L(Train): 0.0060184 --- L(Val, SINDy): 0.0000000 --- Time: 0.09s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.671 value_stay[t] + 0.416 reward + 0.049 harvest_duration + -0.0 value_stay^2 + 0.002 value_stay*reward + -0.331 value_stay*harvest_duration + 0.197 reward^2 + 0.416 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.993 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.082 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 99, 0, 0, 99, 95, 99, 0, 0, 0, 99\n",
      "value_exit: 99, 99, 99, 99, 0, 99\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 350/1000 --- L(Train): 0.0060170 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 15):\n",
      "value_stay[t+1] = 0.049 1 + 0.67 value_stay[t] + 0.416 reward + 0.049 harvest_duration + -0.0 value_stay^2 + 0.001 value_stay*reward + -0.331 value_stay*harvest_duration + 0.196 reward^2 + 0.416 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = 0.994 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.082 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 100, 0, 0, 100, 96, 100, 0, 0, 0, 100\n",
      "value_exit: -, 100, 100, 100, 0, 100\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 351/1000 --- L(Train): 0.0060162 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 14):\n",
      "value_stay[t+1] = 0.05 1 + 0.67 value_stay[t] + 0.416 reward + 0.05 harvest_duration + 0.0 value_stay^2 + 0.001 value_stay*reward + -0.332 value_stay*harvest_duration + 0.195 reward^2 + 0.417 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = 0.994 value_exit[t] + -0.001 travel_duration + -0.082 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 101, 0, 0, 101, 97, 101, 0, 0, 0, 0\n",
      "value_exit: -, 101, 101, -, 0, 101\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 352/1000 --- L(Train): 0.0060145 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 13):\n",
      "value_stay[t+1] = 0.05 1 + 0.67 value_stay[t] + 0.416 reward + 0.05 harvest_duration + 0.0 value_stay^2 + -0.332 value_stay*harvest_duration + 0.195 reward^2 + 0.417 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = 0.994 value_exit[t] + -0.001 travel_duration + -0.083 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 102, 0, 0, 102, 98, -, 0, 0, 0, 1\n",
      "value_exit: -, 102, 102, -, 0, 102\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 353/1000 --- L(Train): 0.0060143 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_stay[t+1] = 0.05 1 + 0.67 value_stay[t] + 0.417 reward + 0.05 harvest_duration + 0.0 value_stay^2 + -0.332 value_stay*harvest_duration + 0.194 reward^2 + 0.417 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = 0.994 value_exit[t] + -0.083 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 103, 0, 0, 103, 99, -, 0, 0, 0, 2\n",
      "value_exit: -, 103, -, -, 0, 103\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 354/1000 --- L(Train): 0.0063723 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 11):\n",
      "value_stay[t+1] = 0.05 1 + 0.67 value_stay[t] + 0.417 reward + 0.05 harvest_duration + -0.332 value_stay*harvest_duration + 0.193 reward^2 + 0.417 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = 0.994 value_exit[t] + -0.083 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 104, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, 104, -, -, 0, 104\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 355/1000 --- L(Train): 0.0171811 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.05 1 + 0.67 value_stay[t] + 0.417 reward + 0.05 harvest_duration + -0.332 value_stay*harvest_duration + 0.192 reward^2 + 0.417 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.083 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 105, 0, 0, 1, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 0, 105\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 356/1000 --- L(Train): 0.0415292 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.05 1 + 0.67 value_stay[t] + 0.417 reward + 0.05 harvest_duration + -0.332 value_stay*harvest_duration + 0.191 reward^2 + 0.418 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.083 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 106, 0, 0, 2, -, -, 0, 0, 0, 1\n",
      "value_exit: -, -, -, -, 0, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 357/1000 --- L(Train): 0.0638916 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.418 reward + 0.05 harvest_duration + -0.332 value_stay*harvest_duration + 0.19 reward^2 + 0.418 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.079 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 3, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 0, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 358/1000 --- L(Train): 0.0622400 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.673 value_stay[t] + 0.42 reward + 0.062 harvest_duration + -0.328 value_stay*harvest_duration + 0.191 reward^2 + 0.42 reward*harvest_duration + 0.062 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.071 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 0, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 359/1000 --- L(Train): 0.0535363 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.674 value_stay[t] + 0.42 reward + 0.064 harvest_duration + -0.328 value_stay*harvest_duration + 0.19 reward^2 + 0.42 reward*harvest_duration + 0.064 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.06 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 0, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 360/1000 --- L(Train): 0.0413205 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.419 reward + 0.056 harvest_duration + -0.331 value_stay*harvest_duration + 0.188 reward^2 + 0.419 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.048 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 1, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 361/1000 --- L(Train): 0.0284234 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.418 reward + 0.051 harvest_duration + -0.333 value_stay*harvest_duration + 0.187 reward^2 + 0.418 reward*harvest_duration + 0.051 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.034 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 2, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 362/1000 --- L(Train): 0.0190179 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.419 reward + 0.054 harvest_duration + -0.331 value_stay*harvest_duration + 0.187 reward^2 + 0.419 reward*harvest_duration + 0.054 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.02 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 3, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 363/1000 --- L(Train): 0.0134318 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.673 value_stay[t] + 0.421 reward + 0.061 harvest_duration + -0.329 value_stay*harvest_duration + 0.187 reward^2 + 0.421 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.007 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 4, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 364/1000 --- L(Train): 0.0114087 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.674 value_stay[t] + 0.421 reward + 0.062 harvest_duration + -0.328 value_stay*harvest_duration + 0.186 reward^2 + 0.421 reward*harvest_duration + 0.062 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.006 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 5, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 365/1000 --- L(Train): 0.0125463 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.672 value_stay[t] + 0.42 reward + 0.057 harvest_duration + -0.33 value_stay*harvest_duration + 0.185 reward^2 + 0.42 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.017 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 6, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 366/1000 --- L(Train): 0.0156896 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.419 reward + 0.053 harvest_duration + -0.332 value_stay*harvest_duration + 0.183 reward^2 + 0.42 reward*harvest_duration + 0.053 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.026 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 7, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 367/1000 --- L(Train): 0.0195231 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.42 reward + 0.054 harvest_duration + -0.332 value_stay*harvest_duration + 0.182 reward^2 + 0.42 reward*harvest_duration + 0.054 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.033 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 8, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 368/1000 --- L(Train): 0.0227669 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.672 value_stay[t] + 0.421 reward + 0.058 harvest_duration + -0.33 value_stay*harvest_duration + 0.182 reward^2 + 0.421 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.037 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 9, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 369/1000 --- L(Train): 0.0246113 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.673 value_stay[t] + 0.422 reward + 0.061 harvest_duration + -0.329 value_stay*harvest_duration + 0.182 reward^2 + 0.422 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.039 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 10, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 370/1000 --- L(Train): 0.0247713 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.672 value_stay[t] + 0.422 reward + 0.059 harvest_duration + -0.33 value_stay*harvest_duration + 0.181 reward^2 + 0.422 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.039 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 11, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 371/1000 --- L(Train): 0.0233353 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.421 reward + 0.055 harvest_duration + -0.332 value_stay*harvest_duration + 0.179 reward^2 + 0.421 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.037 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 12, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 372/1000 --- L(Train): 0.0207042 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.421 reward + 0.054 harvest_duration + -0.332 value_stay*harvest_duration + 0.178 reward^2 + 0.421 reward*harvest_duration + 0.054 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.034 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 13, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 373/1000 --- L(Train): 0.0174912 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.421 reward + 0.056 harvest_duration + -0.331 value_stay*harvest_duration + 0.178 reward^2 + 0.422 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.029 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 14, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 374/1000 --- L(Train): 0.0143616 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.672 value_stay[t] + 0.423 reward + 0.059 harvest_duration + -0.33 value_stay*harvest_duration + 0.178 reward^2 + 0.423 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.023 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 15, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 375/1000 --- L(Train): 0.0116628 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.672 value_stay[t] + 0.423 reward + 0.06 harvest_duration + -0.33 value_stay*harvest_duration + 0.177 reward^2 + 0.423 reward*harvest_duration + 0.06 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.016 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 16, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 376/1000 --- L(Train): 0.0097927 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.423 reward + 0.058 harvest_duration + -0.331 value_stay*harvest_duration + 0.176 reward^2 + 0.423 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.01 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 17, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 377/1000 --- L(Train): 0.0088213 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.422 reward + 0.055 harvest_duration + -0.332 value_stay*harvest_duration + 0.174 reward^2 + 0.422 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 18, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 378/1000 --- L(Train): 0.0086743 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.422 reward + 0.055 harvest_duration + -0.332 value_stay*harvest_duration + 0.174 reward^2 + 0.423 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 19, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 379/1000 --- L(Train): 0.0091661 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.423 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.173 reward^2 + 0.423 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.008 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 20, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 380/1000 --- L(Train): 0.0099707 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.672 value_stay[t] + 0.424 reward + 0.059 harvest_duration + -0.33 value_stay*harvest_duration + 0.173 reward^2 + 0.424 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.012 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 21, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 381/1000 --- L(Train): 0.0108111 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.672 value_stay[t] + 0.424 reward + 0.059 harvest_duration + -0.33 value_stay*harvest_duration + 0.172 reward^2 + 0.424 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.015 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 22, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 382/1000 --- L(Train): 0.0114317 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.424 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.171 reward^2 + 0.424 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.018 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 23, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 383/1000 --- L(Train): 0.0117198 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.423 reward + 0.055 harvest_duration + -0.332 value_stay*harvest_duration + 0.17 reward^2 + 0.424 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.019 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 24, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 384/1000 --- L(Train): 0.0115927 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.424 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.169 reward^2 + 0.424 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.019 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 25, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 385/1000 --- L(Train): 0.0111641 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.425 reward + 0.058 harvest_duration + -0.331 value_stay*harvest_duration + 0.169 reward^2 + 0.425 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.018 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 26, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 386/1000 --- L(Train): 0.0104887 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.672 value_stay[t] + 0.425 reward + 0.059 harvest_duration + -0.33 value_stay*harvest_duration + 0.168 reward^2 + 0.425 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.016 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 27, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 387/1000 --- L(Train): 0.0097370 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.425 reward + 0.058 harvest_duration + -0.331 value_stay*harvest_duration + 0.167 reward^2 + 0.426 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.014 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 28, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 388/1000 --- L(Train): 0.0090256 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.425 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.166 reward^2 + 0.425 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.011 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 29, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 389/1000 --- L(Train): 0.0084572 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.425 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.165 reward^2 + 0.425 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.008 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 30, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 390/1000 --- L(Train): 0.0080986 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.425 reward + 0.056 harvest_duration + -0.331 value_stay*harvest_duration + 0.165 reward^2 + 0.426 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.005 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 31, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 391/1000 --- L(Train): 0.0079419 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.426 reward + 0.058 harvest_duration + -0.331 value_stay*harvest_duration + 0.164 reward^2 + 0.426 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 32, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 392/1000 --- L(Train): 0.0079673 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.426 reward + 0.058 harvest_duration + -0.331 value_stay*harvest_duration + 0.163 reward^2 + 0.427 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 33, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 393/1000 --- L(Train): 0.0081084 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.426 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.162 reward^2 + 0.427 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 34, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 394/1000 --- L(Train): 0.0083080 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.426 reward + 0.056 harvest_duration + -0.331 value_stay*harvest_duration + 0.161 reward^2 + 0.427 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.006 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 35, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 395/1000 --- L(Train): 0.0084794 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.427 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.161 reward^2 + 0.427 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.007 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 36, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 396/1000 --- L(Train): 0.0085767 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.427 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.16 reward^2 + 0.427 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.008 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 37, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 397/1000 --- L(Train): 0.0086012 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.427 reward + 0.058 harvest_duration + -0.331 value_stay*harvest_duration + 0.159 reward^2 + 0.428 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.009 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 38, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 398/1000 --- L(Train): 0.0085266 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.428 reward + 0.058 harvest_duration + -0.331 value_stay*harvest_duration + 0.159 reward^2 + 0.428 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.009 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 39, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 399/1000 --- L(Train): 0.0083880 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.428 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.158 reward^2 + 0.428 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.008 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 40, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 400/1000 --- L(Train): 0.0082139 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.428 reward + 0.056 harvest_duration + -0.331 value_stay*harvest_duration + 0.157 reward^2 + 0.428 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.008 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 41, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 401/1000 --- L(Train): 0.0080382 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.428 reward + 0.056 harvest_duration + -0.331 value_stay*harvest_duration + 0.156 reward^2 + 0.428 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.006 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 42, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 402/1000 --- L(Train): 0.0078863 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.428 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.156 reward^2 + 0.429 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.005 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 43, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 403/1000 --- L(Train): 0.0077706 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.429 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.155 reward^2 + 0.429 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 44, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 404/1000 --- L(Train): 0.0077111 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.429 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.154 reward^2 + 0.429 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 45, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 405/1000 --- L(Train): 0.0076962 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.429 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.153 reward^2 + 0.429 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 46, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 406/1000 --- L(Train): 0.0077245 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.429 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.152 reward^2 + 0.43 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 47, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 407/1000 --- L(Train): 0.0077634 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.43 reward + 0.056 harvest_duration + -0.331 value_stay*harvest_duration + 0.152 reward^2 + 0.43 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 48, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 408/1000 --- L(Train): 0.0078075 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.43 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.151 reward^2 + 0.43 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 49, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 409/1000 --- L(Train): 0.0078412 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.43 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.15 reward^2 + 0.431 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 50, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 410/1000 --- L(Train): 0.0078392 --- L(Val, SINDy): 0.0000000 --- Time: 0.09s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.43 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.149 reward^2 + 0.431 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 51, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 411/1000 --- L(Train): 0.0078330 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.431 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.149 reward^2 + 0.431 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 52, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 412/1000 --- L(Train): 0.0078023 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.431 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.148 reward^2 + 0.431 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 53, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 413/1000 --- L(Train): 0.0077585 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.431 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.147 reward^2 + 0.431 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 54, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 414/1000 --- L(Train): 0.0077174 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.431 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.146 reward^2 + 0.432 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 55, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 415/1000 --- L(Train): 0.0076680 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.432 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.146 reward^2 + 0.432 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 56, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 416/1000 --- L(Train): 0.0076519 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.432 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.145 reward^2 + 0.432 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 57, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 417/1000 --- L(Train): 0.0076305 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.432 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.144 reward^2 + 0.432 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 58, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 418/1000 --- L(Train): 0.0076204 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.432 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.143 reward^2 + 0.432 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 59, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 419/1000 --- L(Train): 0.0076278 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.432 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.143 reward^2 + 0.433 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 60, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 420/1000 --- L(Train): 0.0076287 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.433 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.142 reward^2 + 0.433 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 61, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 421/1000 --- L(Train): 0.0076387 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.433 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.141 reward^2 + 0.433 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 62, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 422/1000 --- L(Train): 0.0076439 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.433 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.14 reward^2 + 0.433 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 63, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 423/1000 --- L(Train): 0.0076415 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.433 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.139 reward^2 + 0.434 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 64, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 424/1000 --- L(Train): 0.0076497 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.434 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.139 reward^2 + 0.434 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 65, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 425/1000 --- L(Train): 0.0076399 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.434 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.138 reward^2 + 0.434 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 66, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 426/1000 --- L(Train): 0.0076214 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.434 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.137 reward^2 + 0.434 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 67, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 427/1000 --- L(Train): 0.0076113 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.434 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.136 reward^2 + 0.435 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 68, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 428/1000 --- L(Train): 0.0075970 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.434 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.136 reward^2 + 0.435 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 69, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 429/1000 --- L(Train): 0.0075857 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.435 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.135 reward^2 + 0.435 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 70, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 430/1000 --- L(Train): 0.0075990 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.435 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.134 reward^2 + 0.435 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 71, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 431/1000 --- L(Train): 0.0075902 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.435 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.133 reward^2 + 0.435 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 72, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 432/1000 --- L(Train): 0.0076027 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.435 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.133 reward^2 + 0.436 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 73, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 433/1000 --- L(Train): 0.0076170 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.436 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.132 reward^2 + 0.436 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 74, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 434/1000 --- L(Train): 0.0076208 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.436 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.131 reward^2 + 0.436 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 75, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 435/1000 --- L(Train): 0.0076091 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.436 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.13 reward^2 + 0.436 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 76, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 436/1000 --- L(Train): 0.0075985 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.436 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.13 reward^2 + 0.437 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 77, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 437/1000 --- L(Train): 0.0076064 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.437 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.129 reward^2 + 0.437 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 78, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 438/1000 --- L(Train): 0.0075865 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.437 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.128 reward^2 + 0.437 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 79, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 439/1000 --- L(Train): 0.0075840 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.437 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.127 reward^2 + 0.437 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 80, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 440/1000 --- L(Train): 0.0075829 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.437 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.127 reward^2 + 0.437 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 81, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 441/1000 --- L(Train): 0.0075801 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.437 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.126 reward^2 + 0.438 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 82, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 442/1000 --- L(Train): 0.0075799 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.438 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.125 reward^2 + 0.438 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 83, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 443/1000 --- L(Train): 0.0075768 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.438 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.124 reward^2 + 0.438 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 84, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 444/1000 --- L(Train): 0.0075894 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.438 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.124 reward^2 + 0.438 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 85, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 445/1000 --- L(Train): 0.0075787 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.438 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.123 reward^2 + 0.439 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 86, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 446/1000 --- L(Train): 0.0075897 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.438 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.122 reward^2 + 0.439 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 87, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 447/1000 --- L(Train): 0.0075664 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.439 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.121 reward^2 + 0.439 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 88, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 448/1000 --- L(Train): 0.0075742 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.439 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.121 reward^2 + 0.439 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 89, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 449/1000 --- L(Train): 0.0075742 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.439 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.12 reward^2 + 0.44 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 90, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 450/1000 --- L(Train): 0.0075570 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.439 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.119 reward^2 + 0.44 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 91, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 451/1000 --- L(Train): 0.0075621 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.44 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.118 reward^2 + 0.44 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 92, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 452/1000 --- L(Train): 0.0075764 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.44 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.118 reward^2 + 0.44 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 93, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 453/1000 --- L(Train): 0.0075608 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.44 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.117 reward^2 + 0.44 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 94, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 454/1000 --- L(Train): 0.0075641 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.44 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.116 reward^2 + 0.441 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 95, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 455/1000 --- L(Train): 0.0075598 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.441 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.115 reward^2 + 0.441 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 96, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 456/1000 --- L(Train): 0.0075713 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.441 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.115 reward^2 + 0.441 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 97, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 457/1000 --- L(Train): 0.0075682 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.441 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.114 reward^2 + 0.441 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 98, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 458/1000 --- L(Train): 0.0075665 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.441 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.113 reward^2 + 0.442 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 99, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 459/1000 --- L(Train): 0.0075568 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.441 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.112 reward^2 + 0.442 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 460/1000 --- L(Train): 0.0075530 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.442 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.112 reward^2 + 0.442 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 461/1000 --- L(Train): 0.0075524 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.442 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.111 reward^2 + 0.442 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 462/1000 --- L(Train): 0.0075515 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.442 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.11 reward^2 + 0.442 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 463/1000 --- L(Train): 0.0075651 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.442 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.109 reward^2 + 0.443 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 464/1000 --- L(Train): 0.0075614 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.443 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.109 reward^2 + 0.443 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 465/1000 --- L(Train): 0.0075630 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.443 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.108 reward^2 + 0.443 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 466/1000 --- L(Train): 0.0077042 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.443 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.107 reward^2 + 0.443 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 467/1000 --- L(Train): 0.0076024 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.443 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.106 reward^2 + 0.444 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 468/1000 --- L(Train): 0.0075518 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.443 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.106 reward^2 + 0.444 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 469/1000 --- L(Train): 0.0076344 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.444 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.105 reward^2 + 0.444 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 470/1000 --- L(Train): 0.0076420 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.444 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.104 reward^2 + 0.444 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 471/1000 --- L(Train): 0.0076508 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.444 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.104 reward^2 + 0.444 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 472/1000 --- L(Train): 0.0075902 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.444 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.103 reward^2 + 0.445 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 473/1000 --- L(Train): 0.0075512 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.445 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.102 reward^2 + 0.445 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 474/1000 --- L(Train): 0.0075909 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.445 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.101 reward^2 + 0.445 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 475/1000 --- L(Train): 0.0076384 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.445 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.101 reward^2 + 0.445 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 476/1000 --- L(Train): 0.0076803 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.445 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.1 reward^2 + 0.445 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 477/1000 --- L(Train): 0.0076141 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.445 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.099 reward^2 + 0.446 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 478/1000 --- L(Train): 0.0076397 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.446 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.098 reward^2 + 0.446 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 479/1000 --- L(Train): 0.0075851 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.446 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.098 reward^2 + 0.446 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 480/1000 --- L(Train): 0.0076137 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.446 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.097 reward^2 + 0.446 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 481/1000 --- L(Train): 0.0076335 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.446 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.096 reward^2 + 0.447 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 482/1000 --- L(Train): 0.0076221 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.446 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.095 reward^2 + 0.447 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 483/1000 --- L(Train): 0.0076201 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.447 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.095 reward^2 + 0.447 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 484/1000 --- L(Train): 0.0075723 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.447 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.094 reward^2 + 0.447 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 485/1000 --- L(Train): 0.0075909 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.447 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.093 reward^2 + 0.447 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 486/1000 --- L(Train): 0.0075790 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.447 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.093 reward^2 + 0.448 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 487/1000 --- L(Train): 0.0075936 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.448 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.092 reward^2 + 0.448 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 488/1000 --- L(Train): 0.0075974 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.448 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.091 reward^2 + 0.448 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 489/1000 --- L(Train): 0.0075956 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.448 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.09 reward^2 + 0.448 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 490/1000 --- L(Train): 0.0075825 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.448 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.09 reward^2 + 0.449 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 491/1000 --- L(Train): 0.0076044 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.448 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.089 reward^2 + 0.449 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 492/1000 --- L(Train): 0.0075802 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.449 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.088 reward^2 + 0.449 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 493/1000 --- L(Train): 0.0075647 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.449 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.088 reward^2 + 0.449 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 494/1000 --- L(Train): 0.0075829 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.449 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.087 reward^2 + 0.449 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 495/1000 --- L(Train): 0.0075532 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.449 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.086 reward^2 + 0.45 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 496/1000 --- L(Train): 0.0075604 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.45 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.085 reward^2 + 0.45 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 497/1000 --- L(Train): 0.0075594 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.45 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.085 reward^2 + 0.45 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 498/1000 --- L(Train): 0.0075484 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.45 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.084 reward^2 + 0.45 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 499/1000 --- L(Train): 0.0075602 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.45 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.083 reward^2 + 0.45 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 500/1000 --- L(Train): 0.0075491 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.45 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.082 reward^2 + 0.451 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 501/1000 --- L(Train): 0.0075389 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.451 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.082 reward^2 + 0.451 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 502/1000 --- L(Train): 0.0075481 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.451 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.081 reward^2 + 0.451 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 503/1000 --- L(Train): 0.0075567 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.451 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.08 reward^2 + 0.451 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 504/1000 --- L(Train): 0.0075358 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.451 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.08 reward^2 + 0.452 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 505/1000 --- L(Train): 0.0075567 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.451 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.079 reward^2 + 0.452 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 506/1000 --- L(Train): 0.0075542 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.452 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.078 reward^2 + 0.452 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 507/1000 --- L(Train): 0.0075357 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.452 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.077 reward^2 + 0.452 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 508/1000 --- L(Train): 0.0075413 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.452 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.077 reward^2 + 0.452 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 509/1000 --- L(Train): 0.0075461 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.452 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.076 reward^2 + 0.453 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 510/1000 --- L(Train): 0.0075356 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.453 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.075 reward^2 + 0.453 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 511/1000 --- L(Train): 0.0075352 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.453 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.075 reward^2 + 0.453 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 512/1000 --- L(Train): 0.0075384 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.453 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.074 reward^2 + 0.453 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 513/1000 --- L(Train): 0.0075360 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.453 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.073 reward^2 + 0.453 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 514/1000 --- L(Train): 0.0075348 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.453 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.073 reward^2 + 0.454 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 515/1000 --- L(Train): 0.0075562 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.454 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.072 reward^2 + 0.454 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 516/1000 --- L(Train): 0.0075515 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.454 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.071 reward^2 + 0.454 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 517/1000 --- L(Train): 0.0075562 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.454 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.07 reward^2 + 0.454 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 518/1000 --- L(Train): 0.0075326 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.454 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.07 reward^2 + 0.455 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 519/1000 --- L(Train): 0.0075506 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.454 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.069 reward^2 + 0.455 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 520/1000 --- L(Train): 0.0075366 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.455 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.068 reward^2 + 0.455 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 521/1000 --- L(Train): 0.0075376 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.455 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.068 reward^2 + 0.455 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 522/1000 --- L(Train): 0.0075589 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.455 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.067 reward^2 + 0.455 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 523/1000 --- L(Train): 0.0075474 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.455 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.066 reward^2 + 0.456 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 524/1000 --- L(Train): 0.0075497 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.455 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.066 reward^2 + 0.456 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 525/1000 --- L(Train): 0.0075405 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.456 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.065 reward^2 + 0.456 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 526/1000 --- L(Train): 0.0075417 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.456 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.064 reward^2 + 0.456 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 527/1000 --- L(Train): 0.0075335 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.456 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.063 reward^2 + 0.456 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 528/1000 --- L(Train): 0.0075424 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.456 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.063 reward^2 + 0.457 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 529/1000 --- L(Train): 0.0075324 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.457 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.062 reward^2 + 0.457 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 530/1000 --- L(Train): 0.0075298 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.457 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.061 reward^2 + 0.457 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 531/1000 --- L(Train): 0.0075375 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.457 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.061 reward^2 + 0.457 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 532/1000 --- L(Train): 0.0075269 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.457 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.06 reward^2 + 0.457 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 533/1000 --- L(Train): 0.0075275 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.457 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.059 reward^2 + 0.458 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 534/1000 --- L(Train): 0.0075318 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.458 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.059 reward^2 + 0.458 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 535/1000 --- L(Train): 0.0075240 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.458 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.058 reward^2 + 0.458 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 536/1000 --- L(Train): 0.0075270 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.458 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.057 reward^2 + 0.458 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 537/1000 --- L(Train): 0.0075294 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.458 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.057 reward^2 + 0.458 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 538/1000 --- L(Train): 0.0075230 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.458 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.056 reward^2 + 0.459 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 539/1000 --- L(Train): 0.0075260 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.459 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.055 reward^2 + 0.459 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 540/1000 --- L(Train): 0.0075277 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.459 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.054 reward^2 + 0.459 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 541/1000 --- L(Train): 0.0075226 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.459 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.054 reward^2 + 0.459 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 542/1000 --- L(Train): 0.0075248 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.459 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.053 reward^2 + 0.46 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 543/1000 --- L(Train): 0.0075258 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.459 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.052 reward^2 + 0.46 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 544/1000 --- L(Train): 0.0075224 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.46 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.052 reward^2 + 0.46 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 545/1000 --- L(Train): 0.0075237 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.46 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.051 reward^2 + 0.46 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 546/1000 --- L(Train): 0.0075246 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.46 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.05 reward^2 + 0.46 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 547/1000 --- L(Train): 0.0075222 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.46 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.05 reward^2 + 0.461 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 1, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 548/1000 --- L(Train): 0.0075228 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.46 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.049 reward^2 + 0.461 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 2, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 549/1000 --- L(Train): 0.0075230 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.461 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.048 reward^2 + 0.461 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 3, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 550/1000 --- L(Train): 0.0075213 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.461 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.048 reward^2 + 0.461 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 4, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 551/1000 --- L(Train): 0.0075220 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.461 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.047 reward^2 + 0.461 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 5, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 552/1000 --- L(Train): 0.0075222 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.461 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.046 reward^2 + 0.462 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 6, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 553/1000 --- L(Train): 0.0075209 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.461 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.046 reward^2 + 0.462 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 7, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 554/1000 --- L(Train): 0.0075584 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.462 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.045 reward^2 + 0.462 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 8, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 555/1000 --- L(Train): 0.0075276 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.462 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.044 reward^2 + 0.462 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 9, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 556/1000 --- L(Train): 0.0075633 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.462 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.044 reward^2 + 0.462 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 10, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 557/1000 --- L(Train): 0.0075263 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.462 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.043 reward^2 + 0.463 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 11, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 558/1000 --- L(Train): 0.0075379 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.462 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.042 reward^2 + 0.463 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 12, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 559/1000 --- L(Train): 0.0075475 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.463 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.042 reward^2 + 0.463 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 13, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 560/1000 --- L(Train): 0.0075222 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.463 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.041 reward^2 + 0.463 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 14, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 561/1000 --- L(Train): 0.0075346 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.463 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.04 reward^2 + 0.463 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 15, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 562/1000 --- L(Train): 0.0075390 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.463 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.04 reward^2 + 0.464 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 16, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 563/1000 --- L(Train): 0.0075217 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.463 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.039 reward^2 + 0.464 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 17, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 564/1000 --- L(Train): 0.0075290 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.464 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.038 reward^2 + 0.464 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 18, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 565/1000 --- L(Train): 0.0075342 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.464 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.038 reward^2 + 0.464 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 19, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 566/1000 --- L(Train): 0.0075264 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.464 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.037 reward^2 + 0.464 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 20, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 567/1000 --- L(Train): 0.0075306 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.464 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.036 reward^2 + 0.465 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 21, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 568/1000 --- L(Train): 0.0075328 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.464 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.036 reward^2 + 0.465 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 22, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 569/1000 --- L(Train): 0.0075254 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.465 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.035 reward^2 + 0.465 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 23, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 570/1000 --- L(Train): 0.0075245 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.465 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.034 reward^2 + 0.465 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 24, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 571/1000 --- L(Train): 0.0075275 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.465 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.034 reward^2 + 0.465 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 25, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 572/1000 --- L(Train): 0.0075265 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.465 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.033 reward^2 + 0.466 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 26, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 573/1000 --- L(Train): 0.0075192 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.465 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.032 reward^2 + 0.466 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 27, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 574/1000 --- L(Train): 0.0075265 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.466 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.032 reward^2 + 0.466 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 28, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 575/1000 --- L(Train): 0.0075241 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.466 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.031 reward^2 + 0.466 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 29, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 576/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.466 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.03 reward^2 + 0.466 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 30, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 577/1000 --- L(Train): 0.0075239 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.466 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.03 reward^2 + 0.467 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 31, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 578/1000 --- L(Train): 0.0075228 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.466 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.029 reward^2 + 0.467 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 32, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 579/1000 --- L(Train): 0.0075215 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.467 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.028 reward^2 + 0.467 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 33, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 580/1000 --- L(Train): 0.0075224 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.467 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.028 reward^2 + 0.467 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 34, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 581/1000 --- L(Train): 0.0075231 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.467 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.027 reward^2 + 0.467 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 35, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 582/1000 --- L(Train): 0.0075219 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.467 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.026 reward^2 + 0.468 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 36, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 583/1000 --- L(Train): 0.0075199 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.467 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.026 reward^2 + 0.468 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 37, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 584/1000 --- L(Train): 0.0075218 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.468 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.025 reward^2 + 0.468 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 38, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 585/1000 --- L(Train): 0.0075213 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.468 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.024 reward^2 + 0.468 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 39, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 586/1000 --- L(Train): 0.0075191 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.468 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.024 reward^2 + 0.468 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 40, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 587/1000 --- L(Train): 0.0075207 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.468 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.023 reward^2 + 0.469 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 41, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 588/1000 --- L(Train): 0.0075325 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.468 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.022 reward^2 + 0.469 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 42, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 589/1000 --- L(Train): 0.0075196 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.469 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.022 reward^2 + 0.469 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 43, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 590/1000 --- L(Train): 0.0075315 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.469 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.021 reward^2 + 0.469 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 44, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 591/1000 --- L(Train): 0.0075246 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.469 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.021 reward^2 + 0.469 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 45, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 592/1000 --- L(Train): 0.0075201 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.469 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.02 reward^2 + 0.469 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 46, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 593/1000 --- L(Train): 0.0075280 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.469 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.019 reward^2 + 0.47 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 47, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 594/1000 --- L(Train): 0.0075212 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.47 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.019 reward^2 + 0.47 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 48, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 595/1000 --- L(Train): 0.0075202 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.47 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.018 reward^2 + 0.47 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 49, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 596/1000 --- L(Train): 0.0075246 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.47 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.017 reward^2 + 0.47 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 50, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 597/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.47 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.017 reward^2 + 0.47 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 51, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 598/1000 --- L(Train): 0.0075206 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.47 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.016 reward^2 + 0.471 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 52, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 599/1000 --- L(Train): 0.0075235 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.47 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.015 reward^2 + 0.471 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 53, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 600/1000 --- L(Train): 0.0075202 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.471 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.015 reward^2 + 0.471 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 54, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 601/1000 --- L(Train): 0.0075217 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.471 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.014 reward^2 + 0.471 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 55, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 602/1000 --- L(Train): 0.0075230 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.471 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.014 reward^2 + 0.471 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 56, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 603/1000 --- L(Train): 0.0075191 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.471 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.013 reward^2 + 0.472 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 57, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 604/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.471 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.012 reward^2 + 0.472 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 58, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 605/1000 --- L(Train): 0.0075205 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.472 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.012 reward^2 + 0.472 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 59, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 606/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.472 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.011 reward^2 + 0.472 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 60, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 607/1000 --- L(Train): 0.0075201 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.472 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.01 reward^2 + 0.472 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 61, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 608/1000 --- L(Train): 0.0075208 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.472 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.01 reward^2 + 0.473 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 62, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 609/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.472 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.009 reward^2 + 0.473 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 63, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 610/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.473 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.008 reward^2 + 0.473 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 64, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 611/1000 --- L(Train): 0.0075192 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.473 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.008 reward^2 + 0.473 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 65, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 612/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.473 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.007 reward^2 + 0.473 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 66, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 613/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.473 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.007 reward^2 + 0.473 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 67, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 614/1000 --- L(Train): 0.0075208 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.473 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.006 reward^2 + 0.474 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 68, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 615/1000 --- L(Train): 0.0075201 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.474 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.005 reward^2 + 0.474 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 69, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 616/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.474 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.005 reward^2 + 0.474 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 70, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 617/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.474 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.004 reward^2 + 0.474 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 71, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 618/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.474 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.004 reward^2 + 0.474 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 72, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 619/1000 --- L(Train): 0.0075191 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.474 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.003 reward^2 + 0.475 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 73, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 620/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.474 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.002 reward^2 + 0.475 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 74, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 621/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.475 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.002 reward^2 + 0.475 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 75, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 622/1000 --- L(Train): 0.0075178 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.475 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.001 reward^2 + 0.475 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 76, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 623/1000 --- L(Train): 0.0075177 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.475 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.475 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 77, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 624/1000 --- L(Train): 0.0075179 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.475 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + -0.0 reward^2 + 0.475 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 78, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 625/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.475 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 79, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 626/1000 --- L(Train): 0.0075941 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 80, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 627/1000 --- L(Train): 0.0075545 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 81, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 628/1000 --- L(Train): 0.0075262 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 82, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 629/1000 --- L(Train): 0.0075319 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 83, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 630/1000 --- L(Train): 0.0075547 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 84, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 631/1000 --- L(Train): 0.0075630 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + -0.0 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 85, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 632/1000 --- L(Train): 0.0075499 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 86, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 633/1000 --- L(Train): 0.0075303 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.001 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 87, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 634/1000 --- L(Train): 0.0075219 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.001 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 88, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 635/1000 --- L(Train): 0.0075288 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.001 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 89, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 636/1000 --- L(Train): 0.0075397 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.002 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 90, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 637/1000 --- L(Train): 0.0075427 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.002 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 91, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 638/1000 --- L(Train): 0.0075363 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.001 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 92, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 639/1000 --- L(Train): 0.0075280 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.001 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 93, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 640/1000 --- L(Train): 0.0075240 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.001 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 94, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 641/1000 --- L(Train): 0.0075258 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.001 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 95, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 642/1000 --- L(Train): 0.0075306 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 96, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 643/1000 --- L(Train): 0.0075338 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + -0.0 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 97, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 644/1000 --- L(Train): 0.0075323 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 98, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 645/1000 --- L(Train): 0.0075272 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.001 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 99, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 646/1000 --- L(Train): 0.0075234 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 647/1000 --- L(Train): 0.0075241 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 648/1000 --- L(Train): 0.0075280 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 649/1000 --- L(Train): 0.0075295 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 650/1000 --- L(Train): 0.0075275 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 651/1000 --- L(Train): 0.0075251 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 652/1000 --- L(Train): 0.0075243 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 653/1000 --- L(Train): 0.0075231 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 654/1000 --- L(Train): 0.0075224 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 655/1000 --- L(Train): 0.0075233 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 656/1000 --- L(Train): 0.0075242 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 657/1000 --- L(Train): 0.0075233 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 658/1000 --- L(Train): 0.0075214 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 659/1000 --- L(Train): 0.0075209 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 660/1000 --- L(Train): 0.0075217 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 661/1000 --- L(Train): 0.0075221 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 662/1000 --- L(Train): 0.0075220 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 663/1000 --- L(Train): 0.0075214 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 664/1000 --- L(Train): 0.0075209 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 665/1000 --- L(Train): 0.0075205 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 666/1000 --- L(Train): 0.0075206 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 667/1000 --- L(Train): 0.0075211 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 668/1000 --- L(Train): 0.0075216 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 669/1000 --- L(Train): 0.0075217 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 670/1000 --- L(Train): 0.0075214 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 671/1000 --- L(Train): 0.0075214 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 672/1000 --- L(Train): 0.0075219 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 673/1000 --- L(Train): 0.0075219 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 674/1000 --- L(Train): 0.0075219 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 675/1000 --- L(Train): 0.0075219 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 676/1000 --- L(Train): 0.0075217 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 677/1000 --- L(Train): 0.0075217 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 678/1000 --- L(Train): 0.0075218 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 679/1000 --- L(Train): 0.0075210 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 680/1000 --- L(Train): 0.0075206 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 681/1000 --- L(Train): 0.0075208 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 682/1000 --- L(Train): 0.0075213 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 683/1000 --- L(Train): 0.0075211 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 684/1000 --- L(Train): 0.0075203 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 685/1000 --- L(Train): 0.0075199 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 686/1000 --- L(Train): 0.0075204 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 687/1000 --- L(Train): 0.0075205 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 688/1000 --- L(Train): 0.0075202 --- L(Val, SINDy): 0.0000000 --- Time: 0.09s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 689/1000 --- L(Train): 0.0075199 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 690/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 691/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 692/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 693/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 694/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 695/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 696/1000 --- L(Train): 0.0075199 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 697/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 698/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 699/1000 --- L(Train): 0.0075202 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 700/1000 --- L(Train): 0.0075204 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 701/1000 --- L(Train): 0.0075203 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 702/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 703/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 704/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 705/1000 --- L(Train): 0.0075203 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 706/1000 --- L(Train): 0.0075402 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 707/1000 --- L(Train): 0.0075210 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 708/1000 --- L(Train): 0.0075423 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 709/1000 --- L(Train): 0.0075250 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 710/1000 --- L(Train): 0.0075255 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 711/1000 --- L(Train): 0.0075349 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 712/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 713/1000 --- L(Train): 0.0075259 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 714/1000 --- L(Train): 0.0075288 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 715/1000 --- L(Train): 0.0075191 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 716/1000 --- L(Train): 0.0075257 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 717/1000 --- L(Train): 0.0075251 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 718/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 719/1000 --- L(Train): 0.0075243 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 720/1000 --- L(Train): 0.0075234 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 721/1000 --- L(Train): 0.0075191 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 722/1000 --- L(Train): 0.0075231 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 723/1000 --- L(Train): 0.0075220 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 724/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 725/1000 --- L(Train): 0.0075222 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 726/1000 --- L(Train): 0.0075209 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 727/1000 --- L(Train): 0.0075192 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 728/1000 --- L(Train): 0.0075214 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 729/1000 --- L(Train): 0.0075205 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 730/1000 --- L(Train): 0.0075192 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 731/1000 --- L(Train): 0.0075207 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 732/1000 --- L(Train): 0.0075198 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 733/1000 --- L(Train): 0.0075190 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 734/1000 --- L(Train): 0.0075203 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 735/1000 --- L(Train): 0.0075196 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 736/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 737/1000 --- L(Train): 0.0075202 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 738/1000 --- L(Train): 0.0075198 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 739/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 740/1000 --- L(Train): 0.0075199 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 741/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 742/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 743/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 744/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 745/1000 --- L(Train): 0.0075188 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 746/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 747/1000 --- L(Train): 0.0075190 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 748/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 749/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 750/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 751/1000 --- L(Train): 0.0075180 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 752/1000 --- L(Train): 0.0075185 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 753/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 754/1000 --- L(Train): 0.0075470 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 755/1000 --- L(Train): 0.0075202 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 756/1000 --- L(Train): 0.0075503 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 757/1000 --- L(Train): 0.0075287 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 758/1000 --- L(Train): 0.0075255 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 759/1000 --- L(Train): 0.0075418 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 760/1000 --- L(Train): 0.0075227 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 761/1000 --- L(Train): 0.0075262 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 762/1000 --- L(Train): 0.0075350 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\u001b[H\u001b[2J\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 763/1000 --- L(Train): 0.0075206 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 764/1000 --- L(Train): 0.0075243 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 765/1000 --- L(Train): 0.0075303 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 766/1000 --- L(Train): 0.0075204 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 767/1000 --- L(Train): 0.0075229 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 768/1000 --- L(Train): 0.0075276 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 769/1000 --- L(Train): 0.0075206 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 770/1000 --- L(Train): 0.0075216 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 771/1000 --- L(Train): 0.0075249 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 772/1000 --- L(Train): 0.0075196 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 773/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 774/1000 --- L(Train): 0.0075225 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 775/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 776/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 777/1000 --- L(Train): 0.0075213 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 778/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.09s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 779/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 780/1000 --- L(Train): 0.0075211 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 781/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 782/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 783/1000 --- L(Train): 0.0075202 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 784/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 785/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 786/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 787/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 788/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 789/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 790/1000 --- L(Train): 0.0075190 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 791/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 792/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 793/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 794/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 795/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 796/1000 --- L(Train): 0.0075188 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 797/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 798/1000 --- L(Train): 0.0075185 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 799/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 800/1000 --- L(Train): 0.0075179 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 801/1000 --- L(Train): 0.0075181 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 802/1000 --- L(Train): 0.0075181 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 803/1000 --- L(Train): 0.0075179 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 804/1000 --- L(Train): 0.0075178 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 805/1000 --- L(Train): 0.0075180 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 806/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 807/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 808/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 809/1000 --- L(Train): 0.0075185 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 810/1000 --- L(Train): 0.0075188 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 811/1000 --- L(Train): 0.0075185 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 812/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 813/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 814/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 815/1000 --- L(Train): 0.0075181 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 816/1000 --- L(Train): 0.0075181 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 817/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 818/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 819/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 820/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 821/1000 --- L(Train): 0.0075181 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 822/1000 --- L(Train): 0.0075180 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 823/1000 --- L(Train): 0.0075181 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 824/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 825/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 826/1000 --- L(Train): 0.0075190 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 827/1000 --- L(Train): 0.0075196 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 828/1000 --- L(Train): 0.0075201 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 829/1000 --- L(Train): 0.0075199 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 830/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 831/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 832/1000 --- L(Train): 0.0075185 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 833/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 834/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 835/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.12s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 836/1000 --- L(Train): 0.0075192 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 837/1000 --- L(Train): 0.0075185 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 838/1000 --- L(Train): 0.0075180 --- L(Val, SINDy): 0.0000000 --- Time: 0.09s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 839/1000 --- L(Train): 0.0075181 --- L(Val, SINDy): 0.0000000 --- Time: 0.10s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 840/1000 --- L(Train): 0.0075190 --- L(Val, SINDy): 0.0000000 --- Time: 0.12s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 841/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.12s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 842/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.15s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 843/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.13s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 844/1000 --- L(Train): 0.0075188 --- L(Val, SINDy): 0.0000000 --- Time: 0.14s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 845/1000 --- L(Train): 0.0075190 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 846/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.15s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 847/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 848/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 849/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 850/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 851/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 852/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 853/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 854/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 855/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 856/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 857/1000 --- L(Train): 0.0075179 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 858/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 859/1000 --- L(Train): 0.0075177 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 860/1000 --- L(Train): 0.0075188 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 861/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 862/1000 --- L(Train): 0.0075191 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 863/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 864/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 865/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 866/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 867/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 868/1000 --- L(Train): 0.0075192 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 869/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 870/1000 --- L(Train): 0.0075191 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 871/1000 --- L(Train): 0.0075191 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 872/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 873/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 874/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 875/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 876/1000 --- L(Train): 0.0075199 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 877/1000 --- L(Train): 0.0075205 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 878/1000 --- L(Train): 0.0075208 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 879/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 880/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 881/1000 --- L(Train): 0.0075209 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 882/1000 --- L(Train): 0.0075224 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 883/1000 --- L(Train): 0.0075220 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 884/1000 --- L(Train): 0.0075201 --- L(Val, SINDy): 0.0000000 --- Time: 0.15s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 885/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 886/1000 --- L(Train): 0.0075190 --- L(Val, SINDy): 0.0000000 --- Time: 0.16s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 887/1000 --- L(Train): 0.0075201 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 888/1000 --- L(Train): 0.0075207 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 889/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.14s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 890/1000 --- L(Train): 0.0075190 --- L(Val, SINDy): 0.0000000 --- Time: 0.14s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 891/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 892/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 893/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 894/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 895/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 896/1000 --- L(Train): 0.0075188 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 897/1000 --- L(Train): 0.0075192 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 898/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 899/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 900/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 901/1000 --- L(Train): 0.0075185 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 902/1000 --- L(Train): 0.0075190 --- L(Val, SINDy): 0.0000000 --- Time: 0.16s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 903/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 904/1000 --- L(Train): 0.0075201 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 905/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 906/1000 --- L(Train): 0.0075196 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 907/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 908/1000 --- L(Train): 0.0075201 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 909/1000 --- L(Train): 0.0075198 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 910/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 911/1000 --- L(Train): 0.0075506 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 912/1000 --- L(Train): 0.0075235 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 913/1000 --- L(Train): 0.0075580 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 914/1000 --- L(Train): 0.0075246 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 915/1000 --- L(Train): 0.0075359 --- L(Val, SINDy): 0.0000000 --- Time: 0.28s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 916/1000 --- L(Train): 0.0075412 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 917/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 918/1000 --- L(Train): 0.0075364 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 919/1000 --- L(Train): 0.0075308 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 920/1000 --- L(Train): 0.0075188 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 921/1000 --- L(Train): 0.0075324 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 922/1000 --- L(Train): 0.0075258 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 923/1000 --- L(Train): 0.0075196 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 924/1000 --- L(Train): 0.0075287 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 925/1000 --- L(Train): 0.0075223 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 926/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 927/1000 --- L(Train): 0.0075267 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 928/1000 --- L(Train): 0.0075221 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 929/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 930/1000 --- L(Train): 0.0075247 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 931/1000 --- L(Train): 0.0075209 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 932/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 933/1000 --- L(Train): 0.0075223 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 934/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 935/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 936/1000 --- L(Train): 0.0075211 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 937/1000 --- L(Train): 0.0075196 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 938/1000 --- L(Train): 0.0075188 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 939/1000 --- L(Train): 0.0075206 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 940/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.27s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 941/1000 --- L(Train): 0.0075185 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 942/1000 --- L(Train): 0.0075196 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 943/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 944/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 945/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 946/1000 --- L(Train): 0.0075198 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 947/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 948/1000 --- L(Train): 0.0075206 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 949/1000 --- L(Train): 0.0075196 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 950/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 951/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 952/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 953/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 954/1000 --- L(Train): 0.0075185 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 955/1000 --- L(Train): 0.0075178 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 956/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 957/1000 --- L(Train): 0.0075181 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 958/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 959/1000 --- L(Train): 0.0075180 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 960/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 961/1000 --- L(Train): 0.0075179 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 962/1000 --- L(Train): 0.0075178 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 963/1000 --- L(Train): 0.0075181 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 964/1000 --- L(Train): 0.0075176 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 965/1000 --- L(Train): 0.0075171 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 966/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 967/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 968/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 969/1000 --- L(Train): 0.0075176 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 970/1000 --- L(Train): 0.0075171 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 971/1000 --- L(Train): 0.0075173 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 972/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 973/1000 --- L(Train): 0.0075170 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 974/1000 --- L(Train): 0.0075170 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 975/1000 --- L(Train): 0.0075171 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 976/1000 --- L(Train): 0.0075173 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 977/1000 --- L(Train): 0.0075174 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 978/1000 --- L(Train): 0.0075173 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 979/1000 --- L(Train): 0.0075173 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 980/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 981/1000 --- L(Train): 0.0075177 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 982/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 983/1000 --- L(Train): 0.0075173 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 984/1000 --- L(Train): 0.0075173 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 985/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 986/1000 --- L(Train): 0.0075180 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 987/1000 --- L(Train): 0.0075180 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 988/1000 --- L(Train): 0.0075178 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 989/1000 --- L(Train): 0.0075178 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 990/1000 --- L(Train): 0.0075178 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 991/1000 --- L(Train): 0.0075171 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 992/1000 --- L(Train): 0.0075168 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 993/1000 --- L(Train): 0.0075173 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 994/1000 --- L(Train): 0.0075177 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 995/1000 --- L(Train): 0.0075177 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 996/1000 --- L(Train): 0.0075179 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 997/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 998/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 999/1000 --- L(Train): 0.0075177 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 1000/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 1001/1000 --- L(Train): 0.0075180 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\n",
      "Training result:\n",
      "L(Train): 0.0000000 --- L(Val, RNN): 0.3412420 --- L(Val, SINDy): 0.3886036 --- LR: 3.1250000e-04\n",
      "\n",
      "RNN training finished.\n",
      "Training took 1158.69 seconds.\n",
      "Saving SPICE model to ../params/bustamante2023/spice_bustamante2023.pkl...\n",
      "================================================================================\n",
      "\n",
      "Training complete!\n",
      "\n",
      "Example SPICE model (participant 0):\n",
      "--------------------------------------------------------------------------------\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nStarting training on {estimator.device}...\")\n",
    "print(\"=\" * 80)\n",
    "estimator.fit(dataset.xs, dataset.ys, dataset.xs, dataset.ys)\n",
    "# estimator.load_spice(args.model)\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nTraining complete!\")\n",
    "\n",
    "# Print example SPICE model for first participant\n",
    "print(\"\\nExample SPICE model (participant 0):\")\n",
    "print(\"-\" * 80)\n",
    "estimator.print_spice_model(participant_id=0)\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.load_spice(path_spice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     participant_id                subject_id  last_reward  relative_optimal  \\\n",
      "0                 0  08aiu2bm6t15qij5826jxz50     8.241283          1.461283   \n",
      "1                 1  09j932f828pn7h7bozp9mpnl     5.344722         -1.435278   \n",
      "2                 2  0ax9htcbhfi3ncsospqzwjx2     8.945571          2.165571   \n",
      "3                 3  0e6zivqly335lojgb4c6606t     7.554696          0.774696   \n",
      "4                 4  0fawro1pivqnh4lem4ayf4o0     3.089682         -3.690318   \n",
      "..              ...                       ...          ...               ...   \n",
      "245             245  fzllq0yp08zefacpmy7dqq0u     9.041866          2.261866   \n",
      "246             246  g2n23l2w8uf3brbllm4sbrcx     8.106489          1.326489   \n",
      "247             247  g9wqksieqbldodjoyuci048q     6.765186         -0.014814   \n",
      "248             248  garkh3hmuozi9loxpee54z20     7.720383          0.940383   \n",
      "249             249  gd6af6pqeo2d0x2dcumwirmy     3.908357         -2.871643   \n",
      "\n",
      "     over_harvester  \n",
      "0                 0  \n",
      "1                 1  \n",
      "2                 0  \n",
      "3                 0  \n",
      "4                 1  \n",
      "..              ...  \n",
      "245               0  \n",
      "246               0  \n",
      "247               1  \n",
      "248               0  \n",
      "249               1  \n",
      "\n",
      "[250 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file)\n",
    "df['last_reward'] = df.groupby('subject_id')['last_reward'].fillna(method='bfill')\n",
    "df['participant_id'] = pd.factorize(df['subject_id'])[0]\n",
    "exit_df = df[df['decision'] == 1]\n",
    "mean_exit_threshold = exit_df.groupby(['participant_id', 'subject_id'])['last_reward'].mean().reset_index()\n",
    "mean_exit_threshold['relative_optimal'] = mean_exit_threshold['last_reward'] - 6.78 #from Bustamante et al. Table S7, experiment 1\n",
    "mean_exit_threshold['over_harvester'] = np.where(mean_exit_threshold['relative_optimal'] <= 0, 1, 0)\n",
    "print(mean_exit_threshold)\n",
    "overharvesters = mean_exit_threshold[mean_exit_threshold['over_harvester'] == 1]['participant_id'].unique()\n",
    "underharvesters = mean_exit_threshold[mean_exit_threshold['over_harvester'] == 0]['participant_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OVERHARVESTERS\n",
      "Participant number 1\n",
      "value_stay[t+1] = 0.773 value_stay[t] + 0.5 reward + 0.061 harvest_duration + -0.229 value_stay*harvest_duration + 0.496 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 4\n",
      "value_stay[t+1] = 0.164 1 + 0.724 value_stay[t] + 0.249 reward + 0.168 harvest_duration + -0.277 value_stay*harvest_duration + 0.248 reward*harvest_duration + 0.165 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 7\n",
      "value_stay[t+1] = 0.085 1 + 0.712 value_stay[t] + 0.455 reward + 0.085 harvest_duration + -0.287 value_stay*harvest_duration + 0.455 reward*harvest_duration + 0.085 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 12\n",
      "value_stay[t+1] = 0.095 1 + 0.717 value_stay[t] + 0.435 reward + 0.096 harvest_duration + -0.282 value_stay*harvest_duration + 0.434 reward*harvest_duration + 0.093 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 13\n",
      "value_stay[t+1] = 0.096 1 + 0.713 value_stay[t] + 0.443 reward + 0.095 harvest_duration + -0.288 value_stay*harvest_duration + 0.44 reward*harvest_duration + 0.095 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 14\n",
      "value_stay[t+1] = 0.071 1 + 0.699 value_stay[t] + 0.481 reward + 0.071 harvest_duration + -0.3 value_stay*harvest_duration + 0.481 reward*harvest_duration + 0.071 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 20\n",
      "value_stay[t+1] = 0.066 1 + 0.794 value_stay[t] + 0.463 reward + 0.066 harvest_duration + -0.079 value_stay^2 + -0.206 value_stay*harvest_duration + 0.462 reward*harvest_duration + 0.067 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 23\n",
      "value_stay[t+1] = 0.725 value_stay[t] + 0.51 reward + 0.11 harvest_duration + -0.271 value_stay*harvest_duration + 0.506 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 24\n",
      "value_stay[t+1] = 0.063 1 + 0.701 value_stay[t] + 0.499 reward + 0.064 harvest_duration + -0.303 value_stay*harvest_duration + 0.496 reward*harvest_duration + 0.064 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 25\n",
      "value_stay[t+1] = 0.796 value_stay[t] + 0.519 reward + -0.204 value_stay*harvest_duration + 0.52 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 26\n",
      "value_stay[t+1] = 0.128 1 + 0.777 value_stay[t] + 0.245 reward + 0.125 harvest_duration + -0.224 value_stay*harvest_duration + 0.242 reward*harvest_duration + 0.125 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 27\n",
      "value_stay[t+1] = 0.079 1 + 0.712 value_stay[t] + 0.515 reward + 0.08 harvest_duration + -0.288 value_stay*harvest_duration + 0.519 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 30\n",
      "value_stay[t+1] = 0.072 1 + 0.704 value_stay[t] + 0.466 reward + 0.071 harvest_duration + -0.295 value_stay*harvest_duration + 0.466 reward*harvest_duration + 0.072 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 32\n",
      "value_stay[t+1] = 0.076 1 + 0.698 value_stay[t] + 0.483 reward + 0.076 harvest_duration + -0.298 value_stay*harvest_duration + 0.482 reward*harvest_duration + 0.076 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 33\n",
      "value_stay[t+1] = 0.255 1 + 0.731 value_stay[t] + 0.256 harvest_duration + -0.042 value_stay^2 + -0.269 value_stay*harvest_duration + 0.256 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 35\n",
      "value_stay[t+1] = 0.069 1 + 0.706 value_stay[t] + 0.488 reward + 0.07 harvest_duration + -0.297 value_stay*harvest_duration + 0.487 reward*harvest_duration + 0.07 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 36\n",
      "value_stay[t+1] = 0.176 1 + 0.718 value_stay[t] + 0.218 reward + 0.176 harvest_duration + -0.277 value_stay*harvest_duration + 0.218 reward*harvest_duration + 0.177 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 37\n",
      "value_stay[t+1] = 0.268 1 + 0.781 value_stay[t] + 0.267 harvest_duration + -0.13 value_stay^2 + -0.218 value_stay*harvest_duration + 0.267 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 38\n",
      "value_stay[t+1] = 0.813 value_stay[t] + 0.506 reward + -0.09 value_stay^2 + -0.187 value_stay*harvest_duration + 0.507 reward*harvest_duration + 0.065 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 43\n",
      "value_stay[t+1] = 0.4 1 + 0.822 value_stay[t] + 0.35 reward + -0.18 value_stay*harvest_duration + 0.351 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 44\n",
      "value_stay[t+1] = 0.072 1 + 0.703 value_stay[t] + 0.481 reward + 0.072 harvest_duration + -0.298 value_stay*harvest_duration + 0.485 reward*harvest_duration + 0.072 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 45\n",
      "value_stay[t+1] = 0.161 1 + 0.752 value_stay[t] + 0.165 reward + 0.165 harvest_duration + -0.247 value_stay*harvest_duration + 0.165 reward*harvest_duration + 0.166 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 46\n",
      "value_stay[t+1] = 0.084 1 + 0.636 value_stay[t] + 0.083 harvest_duration + -0.367 value_stay*harvest_duration + 0.587 reward^2 + 0.084 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 47\n",
      "value_stay[t+1] = 0.191 1 + 0.743 value_stay[t] + 0.11 reward + 0.192 harvest_duration + -0.257 value_stay*harvest_duration + 0.114 reward*harvest_duration + 0.191 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 49\n",
      "value_stay[t+1] = 0.267 1 + 0.788 value_stay[t] + 0.266 harvest_duration + -0.141 value_stay^2 + -0.212 value_stay*harvest_duration + 0.267 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 51\n",
      "value_stay[t+1] = 0.839 value_stay[t] + 0.474 reward + -0.161 value_stay*harvest_duration + 0.477 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 54\n",
      "value_stay[t+1] = 0.944 value_stay[t] + 0.477 reward + -0.172 value_stay^2 + -0.057 value_stay*harvest_duration + 0.483 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 59\n",
      "value_stay[t+1] = 0.157 1 + 0.721 value_stay[t] + 0.273 reward + 0.157 harvest_duration + -0.276 value_stay*harvest_duration + 0.27 reward*harvest_duration + 0.157 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 66\n",
      "value_stay[t+1] = 0.779 value_stay[t] + 0.508 reward + -0.22 value_stay*harvest_duration + 0.509 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 68\n",
      "value_stay[t+1] = 0.114 1 + 0.749 value_stay[t] + 0.335 reward + 0.114 harvest_duration + -0.25 value_stay*harvest_duration + 0.336 reward*harvest_duration + 0.115 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 70\n",
      "value_stay[t+1] = 0.073 1 + 0.709 value_stay[t] + 0.481 reward + 0.072 harvest_duration + -0.29 value_stay*harvest_duration + 0.478 reward*harvest_duration + 0.072 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 71\n",
      "value_stay[t+1] = 0.064 1 + 0.774 value_stay[t] + 0.428 reward + 0.066 harvest_duration + -0.227 value_stay*harvest_duration + 0.432 reward*harvest_duration + 0.063 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 72\n",
      "value_stay[t+1] = 0.069 1 + 0.701 value_stay[t] + 0.486 reward + 0.068 harvest_duration + -0.299 value_stay*harvest_duration + 0.486 reward*harvest_duration + 0.068 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 73\n",
      "value_stay[t+1] = 0.085 1 + 0.715 value_stay[t] + 0.435 reward + 0.086 harvest_duration + -0.284 value_stay*harvest_duration + 0.435 reward*harvest_duration + 0.086 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 74\n",
      "value_stay[t+1] = 0.817 value_stay[t] + 0.404 reward + -0.183 value_stay*harvest_duration + 0.4 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 75\n",
      "value_stay[t+1] = 0.108 1 + 0.803 value_stay[t] + 0.231 reward + 0.11 harvest_duration + -0.197 value_stay*harvest_duration + 0.232 reward*harvest_duration + 0.109 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 77\n",
      "value_stay[t+1] = 0.724 value_stay[t] + 0.508 reward + -0.275 value_stay*harvest_duration + 0.509 reward*harvest_duration + 0.052 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 78\n",
      "value_stay[t+1] = 0.235 1 + 0.737 value_stay[t] + 0.512 reward + -0.265 value_stay*harvest_duration + 0.515 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 79\n",
      "value_stay[t+1] = 0.195 1 + 0.717 value_stay[t] + 0.176 reward + 0.196 harvest_duration + -0.283 value_stay*harvest_duration + 0.174 reward*harvest_duration + 0.195 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 80\n",
      "value_stay[t+1] = 0.776 value_stay[t] + 0.51 reward + -0.226 value_stay*harvest_duration + 0.509 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 81\n",
      "value_stay[t+1] = 0.081 1 + 0.712 value_stay[t] + 0.509 reward + -0.29 value_stay*harvest_duration + 0.506 reward*harvest_duration + 0.081 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 82\n",
      "value_stay[t+1] = 0.072 1 + 0.813 value_stay[t] + 0.38 reward + -0.187 value_stay*harvest_duration + 0.376 reward*harvest_duration + 0.071 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 84\n",
      "value_stay[t+1] = 0.764 value_stay[t] + 0.51 reward + -0.231 value_stay*harvest_duration + 0.505 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 86\n",
      "value_stay[t+1] = 0.724 value_stay[t] + 0.508 reward + 0.061 harvest_duration + -0.276 value_stay*harvest_duration + 0.504 reward*harvest_duration + 0.062 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 90\n",
      "value_stay[t+1] = 0.147 1 + 0.415 value_stay[t] + 0.149 harvest_duration + -0.588 value_stay*harvest_duration + 0.148 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 92\n",
      "value_stay[t+1] = 0.068 1 + 0.698 value_stay[t] + 0.487 reward + 0.068 harvest_duration + -0.303 value_stay*harvest_duration + 0.487 reward*harvest_duration + 0.069 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 93\n",
      "value_stay[t+1] = 0.073 1 + 0.704 value_stay[t] + 0.481 reward + 0.073 harvest_duration + -0.296 value_stay*harvest_duration + 0.48 reward*harvest_duration + 0.073 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 95\n",
      "value_stay[t+1] = 0.073 1 + 0.754 value_stay[t] + 0.445 reward + 0.072 harvest_duration + -0.248 value_stay*harvest_duration + 0.444 reward*harvest_duration + 0.073 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 97\n",
      "value_stay[t+1] = 0.113 1 + 0.724 value_stay[t] + 0.385 reward + 0.112 harvest_duration + -0.276 value_stay*harvest_duration + 0.388 reward*harvest_duration + 0.112 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 99\n",
      "value_stay[t+1] = 0.065 1 + 0.697 value_stay[t] + 0.497 reward + 0.065 harvest_duration + -0.302 value_stay*harvest_duration + 0.497 reward*harvest_duration + 0.064 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 100\n",
      "value_stay[t+1] = 0.074 1 + 0.684 value_stay[t] + 0.455 reward + 0.074 harvest_duration + -0.318 value_stay*harvest_duration + 0.457 reward*harvest_duration + 0.074 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 101\n",
      "value_stay[t+1] = 0.722 value_stay[t] + 0.501 reward + 0.176 harvest_duration + -0.278 value_stay*harvest_duration + 0.504 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 103\n",
      "value_stay[t+1] = 0.072 1 + 0.77 value_stay[t] + 0.468 reward + -0.231 value_stay*harvest_duration + 0.464 reward*harvest_duration + 0.072 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 104\n",
      "value_stay[t+1] = 0.8 value_stay[t] + 0.522 reward + -0.2 value_stay*harvest_duration + 0.523 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 105\n",
      "value_stay[t+1] = 0.27 1 + 0.804 value_stay[t] + 0.269 harvest_duration + -0.165 value_stay^2 + -0.196 value_stay*harvest_duration + 0.269 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 109\n",
      "value_stay[t+1] = 0.076 1 + 0.729 value_stay[t] + 0.502 reward + -0.274 value_stay*harvest_duration + 0.499 reward*harvest_duration + 0.076 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 110\n",
      "value_stay[t+1] = 0.863 value_stay[t] + 0.438 reward + -0.138 value_stay*harvest_duration + 0.44 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 112\n",
      "value_stay[t+1] = 0.111 1 + 0.792 value_stay[t] + 0.245 reward + 0.111 harvest_duration + -0.205 value_stay*harvest_duration + 0.248 reward*harvest_duration + 0.114 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 113\n",
      "value_stay[t+1] = 0.775 value_stay[t] + 0.51 reward + -0.223 value_stay*harvest_duration + 0.513 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 114\n",
      "value_stay[t+1] = 0.21 1 + 0.708 value_stay[t] + 0.142 reward + 0.208 harvest_duration + -0.285 value_stay*harvest_duration + 0.144 reward*harvest_duration + 0.208 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 115\n",
      "value_stay[t+1] = 0.141 1 + 0.429 value_stay[t] + 0.144 harvest_duration + -0.572 value_stay*harvest_duration + 0.142 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 116\n",
      "value_stay[t+1] = 0.084 1 + 0.741 value_stay[t] + 0.435 reward + 0.083 harvest_duration + -0.261 value_stay*harvest_duration + 0.434 reward*harvest_duration + 0.084 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 120\n",
      "value_stay[t+1] = 0.069 1 + 0.788 value_stay[t] + 0.447 reward + 0.069 harvest_duration + -0.056 value_stay^2 + -0.214 value_stay*harvest_duration + 0.452 reward*harvest_duration + 0.069 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 121\n",
      "value_stay[t+1] = 0.062 1 + 0.694 value_stay[t] + 0.496 reward + 0.062 harvest_duration + -0.303 value_stay*harvest_duration + 0.496 reward*harvest_duration + 0.062 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 122\n",
      "value_stay[t+1] = 0.06 1 + 0.776 value_stay[t] + 0.477 reward + 0.06 harvest_duration + -0.057 value_stay^2 + -0.223 value_stay*harvest_duration + 0.474 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 123\n",
      "value_stay[t+1] = 0.698 value_stay[t] + 0.44 reward + -0.298 value_stay*harvest_duration + 0.11 reward^2 + 0.435 reward*harvest_duration + 0.071 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 124\n",
      "value_stay[t+1] = 0.841 value_stay[t] + 0.49 reward + -0.157 value_stay*harvest_duration + 0.486 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 125\n",
      "value_stay[t+1] = 0.879 value_stay[t] + 0.405 reward + -0.122 value_stay*harvest_duration + 0.408 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 126\n",
      "value_stay[t+1] = 0.726 value_stay[t] + 0.504 reward + -0.27 value_stay*harvest_duration + 0.508 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 127\n",
      "value_stay[t+1] = 0.707 value_stay[t] + 0.508 reward + 0.062 harvest_duration + -0.293 value_stay*harvest_duration + 0.509 reward*harvest_duration + 0.062 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 128\n",
      "value_stay[t+1] = 0.232 1 + 0.793 value_stay[t] + 0.47 reward + -0.207 value_stay*harvest_duration + 0.464 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 130\n",
      "value_stay[t+1] = 0.236 1 + 0.775 value_stay[t] + 0.055 reward + 0.236 harvest_duration + -0.093 value_stay^2 + -0.225 value_stay*harvest_duration + 0.056 reward*harvest_duration + 0.236 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 131\n",
      "value_stay[t+1] = 0.127 1 + 0.496 value_stay[t] + 0.127 harvest_duration + -0.503 value_stay*harvest_duration + 0.128 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 132\n",
      "value_stay[t+1] = 0.772 value_stay[t] + 0.502 reward + -0.225 value_stay*harvest_duration + 0.5 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 133\n",
      "value_stay[t+1] = 0.131 1 + 0.783 value_stay[t] + 0.2 reward + 0.131 harvest_duration + -0.215 value_stay*harvest_duration + 0.199 reward*harvest_duration + 0.131 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 134\n",
      "value_stay[t+1] = 0.826 value_stay[t] + 0.502 reward + -0.173 value_stay*harvest_duration + 0.502 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 135\n",
      "value_stay[t+1] = 0.06 1 + 0.682 value_stay[t] + 0.489 reward + 0.06 harvest_duration + -0.318 value_stay*harvest_duration + 0.49 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 139\n",
      "value_stay[t+1] = 0.837 value_stay[t] + 0.484 reward + -0.164 value_stay*harvest_duration + 0.485 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 140\n",
      "value_stay[t+1] = 0.077 1 + 0.707 value_stay[t] + 0.474 reward + 0.075 harvest_duration + -0.294 value_stay*harvest_duration + 0.472 reward*harvest_duration + 0.076 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 142\n",
      "value_stay[t+1] = 0.302 1 + 0.737 value_stay[t] + 0.506 reward + -0.262 value_stay*harvest_duration + 0.506 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 143\n",
      "value_stay[t+1] = 0.05 1 + 0.701 value_stay[t] + 0.504 reward + 0.051 harvest_duration + -0.301 value_stay*harvest_duration + 0.5 reward*harvest_duration + 0.052 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 144\n",
      "value_stay[t+1] = 0.058 1 + 0.719 value_stay[t] + 0.499 reward + 0.058 harvest_duration + -0.283 value_stay*harvest_duration + 0.499 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 146\n",
      "value_stay[t+1] = 0.061 1 + 0.716 value_stay[t] + 0.5 reward + 0.062 harvest_duration + -0.283 value_stay*harvest_duration + 0.498 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 148\n",
      "value_stay[t+1] = 0.229 1 + 0.715 value_stay[t] + 0.068 reward + 0.228 harvest_duration + -0.282 value_stay*harvest_duration + 0.069 reward*harvest_duration + 0.227 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 152\n",
      "value_stay[t+1] = 0.064 1 + 0.763 value_stay[t] + 0.448 reward + 0.064 harvest_duration + -0.236 value_stay*harvest_duration + 0.445 reward*harvest_duration + 0.065 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 153\n",
      "value_stay[t+1] = 0.885 value_stay[t] + 0.391 reward + -0.115 value_stay*harvest_duration + 0.391 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 154\n",
      "value_stay[t+1] = 0.209 1 + 0.724 value_stay[t] + 0.104 reward + 0.211 harvest_duration + -0.277 value_stay*harvest_duration + 0.105 reward*harvest_duration + 0.212 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 160\n",
      "value_stay[t+1] = 0.102 1 + 0.728 value_stay[t] + 0.407 reward + 0.1 harvest_duration + -0.273 value_stay*harvest_duration + 0.403 reward*harvest_duration + 0.102 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 161\n",
      "value_stay[t+1] = 0.845 value_stay[t] + 0.448 reward + -0.155 value_stay*harvest_duration + 0.448 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 162\n",
      "value_stay[t+1] = 0.061 1 + 0.688 value_stay[t] + 0.488 reward + 0.062 harvest_duration + -0.31 value_stay*harvest_duration + 0.488 reward*harvest_duration + 0.062 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 164\n",
      "value_stay[t+1] = 0.083 1 + 0.785 value_stay[t] + 0.352 reward + 0.082 harvest_duration + -0.214 value_stay*harvest_duration + 0.348 reward*harvest_duration + 0.081 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 165\n",
      "value_stay[t+1] = 0.067 1 + 0.692 value_stay[t] + 0.493 reward + 0.068 harvest_duration + -0.308 value_stay*harvest_duration + 0.494 reward*harvest_duration + 0.068 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 166\n",
      "value_stay[t+1] = 0.828 value_stay[t] + 0.492 reward + -0.172 value_stay*harvest_duration + 0.492 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 167\n",
      "value_stay[t+1] = 0.129 1 + 0.466 value_stay[t] + 0.078 reward + 0.129 harvest_duration + -0.534 value_stay*harvest_duration + 0.078 reward*harvest_duration + 0.13 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 168\n",
      "value_stay[t+1] = 0.841 value_stay[t] + 0.408 reward + -0.158 value_stay*harvest_duration + 0.403 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 171\n",
      "value_stay[t+1] = 0.056 1 + 0.747 value_stay[t] + 0.482 reward + 0.056 harvest_duration + -0.255 value_stay*harvest_duration + 0.485 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 172\n",
      "value_stay[t+1] = 0.184 1 + 0.805 value_stay[t] + 0.453 reward + -0.194 value_stay*harvest_duration + 0.457 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 174\n",
      "value_stay[t+1] = 0.076 1 + 0.704 value_stay[t] + 0.474 reward + 0.074 harvest_duration + -0.296 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.075 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 176\n",
      "value_stay[t+1] = 0.06 1 + 0.747 value_stay[t] + 0.474 reward + 0.059 harvest_duration + -0.256 value_stay*harvest_duration + 0.476 reward*harvest_duration + 0.06 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 177\n",
      "value_stay[t+1] = 0.739 value_stay[t] + 0.512 reward + 0.123 harvest_duration + -0.262 value_stay*harvest_duration + 0.511 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 181\n",
      "value_stay[t+1] = 0.107 1 + 0.717 value_stay[t] + 0.408 reward + 0.106 harvest_duration + -0.279 value_stay*harvest_duration + 0.407 reward*harvest_duration + 0.106 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 182\n",
      "value_stay[t+1] = 0.097 1 + 0.569 value_stay[t] + 0.119 reward + 0.097 harvest_duration + -0.425 value_stay*harvest_duration + 0.324 reward^2 + 0.117 reward*harvest_duration + 0.097 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 184\n",
      "value_stay[t+1] = 0.098 1 + 0.715 value_stay[t] + 0.437 reward + 0.099 harvest_duration + -0.283 value_stay*harvest_duration + 0.433 reward*harvest_duration + 0.098 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 185\n",
      "value_stay[t+1] = 0.269 1 + 0.805 value_stay[t] + 0.27 harvest_duration + -0.167 value_stay^2 + -0.195 value_stay*harvest_duration + 0.269 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 186\n",
      "value_stay[t+1] = 0.133 1 + 0.731 value_stay[t] + 0.312 reward + 0.132 harvest_duration + -0.266 value_stay*harvest_duration + 0.316 reward*harvest_duration + 0.137 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 188\n",
      "value_stay[t+1] = 0.207 1 + 0.714 value_stay[t] + 0.145 reward + 0.205 harvest_duration + -0.285 value_stay*harvest_duration + 0.142 reward*harvest_duration + 0.208 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 189\n",
      "value_stay[t+1] = 0.133 1 + 0.458 value_stay[t] + 0.142 reward + 0.133 harvest_duration + -0.538 value_stay*harvest_duration + 0.131 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 191\n",
      "value_stay[t+1] = 0.231 1 + 0.709 value_stay[t] + 0.083 reward + 0.231 harvest_duration + -0.293 value_stay*harvest_duration + 0.083 reward*harvest_duration + 0.231 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 194\n",
      "value_stay[t+1] = 0.076 1 + 0.725 value_stay[t] + 0.495 reward + -0.277 value_stay*harvest_duration + 0.497 reward*harvest_duration + 0.078 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 195\n",
      "value_stay[t+1] = 0.06 1 + 0.678 value_stay[t] + 0.472 reward + 0.06 harvest_duration + -0.322 value_stay*harvest_duration + 0.467 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 198\n",
      "value_stay[t+1] = 0.84 value_stay[t] + 0.459 reward + -0.159 value_stay*harvest_duration + 0.461 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 199\n",
      "value_stay[t+1] = 0.145 1 + 0.418 value_stay[t] + 0.146 harvest_duration + -0.581 value_stay*harvest_duration + 0.144 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 202\n",
      "value_stay[t+1] = 0.252 1 + 0.754 value_stay[t] + 0.13 reward + 0.252 harvest_duration + -0.081 value_stay^2 + -0.246 value_stay*harvest_duration + 0.251 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 206\n",
      "value_stay[t+1] = 0.822 value_stay[t] + 0.468 reward + -0.179 value_stay*harvest_duration + 0.471 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 208\n",
      "value_stay[t+1] = 0.268 1 + 0.793 value_stay[t] + 0.266 harvest_duration + -0.148 value_stay^2 + -0.207 value_stay*harvest_duration + 0.268 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 209\n",
      "value_stay[t+1] = 0.065 1 + 0.697 value_stay[t] + 0.498 reward + 0.065 harvest_duration + -0.303 value_stay*harvest_duration + 0.495 reward*harvest_duration + 0.065 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 211\n",
      "value_stay[t+1] = 0.776 value_stay[t] + 0.476 reward + -0.223 value_stay*harvest_duration + 0.476 reward*harvest_duration + 0.062 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 214\n",
      "value_stay[t+1] = 0.269 1 + 0.805 value_stay[t] + 0.27 harvest_duration + -0.167 value_stay^2 + -0.195 value_stay*harvest_duration + 0.269 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 215\n",
      "value_stay[t+1] = 0.201 1 + 0.736 value_stay[t] + 0.106 reward + 0.2 harvest_duration + -0.266 value_stay*harvest_duration + 0.107 reward*harvest_duration + 0.201 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 216\n",
      "value_stay[t+1] = 0.726 value_stay[t] + 0.508 reward + -0.273 value_stay*harvest_duration + 0.508 reward*harvest_duration + 0.071 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 218\n",
      "value_stay[t+1] = 0.123 1 + 0.723 value_stay[t] + 0.36 reward + 0.123 harvest_duration + -0.276 value_stay*harvest_duration + 0.36 reward*harvest_duration + 0.123 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 219\n",
      "value_stay[t+1] = 0.265 1 + 0.79 value_stay[t] + 0.265 harvest_duration + -0.14 value_stay^2 + -0.21 value_stay*harvest_duration + 0.264 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 220\n",
      "value_stay[t+1] = 0.118 1 + 0.792 value_stay[t] + 0.219 reward + 0.117 harvest_duration + -0.208 value_stay*harvest_duration + 0.223 reward*harvest_duration + 0.117 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 221\n",
      "value_stay[t+1] = 0.221 1 + 0.71 value_stay[t] + 0.113 reward + 0.221 harvest_duration + -0.29 value_stay*harvest_duration + 0.112 reward*harvest_duration + 0.221 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 222\n",
      "value_stay[t+1] = 0.801 value_stay[t] + 0.49 reward + -0.199 value_stay*harvest_duration + 0.49 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 223\n",
      "value_stay[t+1] = 0.833 value_stay[t] + 0.391 reward + -0.166 value_stay*harvest_duration + 0.392 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 225\n",
      "value_stay[t+1] = 0.268 1 + 0.794 value_stay[t] + 0.267 harvest_duration + -0.151 value_stay^2 + -0.205 value_stay*harvest_duration + 0.268 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 226\n",
      "value_stay[t+1] = 0.793 value_stay[t] + 0.427 reward + 0.185 harvest_duration + -0.206 value_stay*harvest_duration + 0.423 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 230\n",
      "value_stay[t+1] = 0.144 1 + 0.455 value_stay[t] + 0.145 harvest_duration + -0.548 value_stay*harvest_duration + 0.144 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 231\n",
      "value_stay[t+1] = 0.051 1 + 0.721 value_stay[t] + 0.506 reward + -0.28 value_stay*harvest_duration + 0.506 reward*harvest_duration + 0.052 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 233\n",
      "value_stay[t+1] = 0.103 1 + 0.761 value_stay[t] + 0.484 reward + 0.102 harvest_duration + -0.239 value_stay*harvest_duration + 0.488 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 235\n",
      "value_stay[t+1] = 0.217 1 + 0.711 value_stay[t] + 0.121 reward + 0.217 harvest_duration + -0.29 value_stay*harvest_duration + 0.121 reward*harvest_duration + 0.217 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 236\n",
      "value_stay[t+1] = 0.817 value_stay[t] + 0.439 reward + -0.183 value_stay*harvest_duration + 0.443 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 238\n",
      "value_stay[t+1] = 0.182 1 + 0.722 value_stay[t] + 0.209 reward + 0.179 harvest_duration + -0.279 value_stay*harvest_duration + 0.214 reward*harvest_duration + 0.178 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 239\n",
      "value_stay[t+1] = 0.061 1 + 0.679 value_stay[t] + 0.468 reward + 0.06 harvest_duration + -0.319 value_stay*harvest_duration + 0.47 reward*harvest_duration + 0.06 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 240\n",
      "value_stay[t+1] = 0.08 1 + 0.803 value_stay[t] + 0.318 reward + 0.082 harvest_duration + -0.196 value_stay*harvest_duration + 0.314 reward*harvest_duration + 0.081 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 241\n",
      "value_stay[t+1] = 0.266 1 + 0.791 value_stay[t] + 0.267 harvest_duration + -0.144 value_stay^2 + -0.208 value_stay*harvest_duration + 0.266 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 242\n",
      "value_stay[t+1] = 0.193 1 + 0.722 value_stay[t] + 0.167 reward + 0.194 harvest_duration + -0.275 value_stay*harvest_duration + 0.167 reward*harvest_duration + 0.189 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 243\n",
      "value_stay[t+1] = 0.144 1 + 0.421 value_stay[t] + 0.145 harvest_duration + -0.583 value_stay*harvest_duration + 0.147 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 247\n",
      "value_stay[t+1] = 0.122 1 + 0.507 value_stay[t] + 0.081 reward + 0.122 harvest_duration + -0.487 value_stay*harvest_duration + 0.081 reward*harvest_duration + 0.11 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 249\n",
      "value_stay[t+1] = 0.145 1 + 0.437 value_stay[t] + 0.144 harvest_duration + -0.563 value_stay*harvest_duration + 0.144 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n"
     ]
    }
   ],
   "source": [
    "print('OVERHARVESTERS') \n",
    "for p in overharvesters:\n",
    "    print('Participant number', p)\n",
    "    estimator.print_spice_model(participant_id=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNDERHARVESTERS\n",
      "Participant number 0\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 2\n",
      "value_stay[t+1] = 0.82 value_stay[t] + 0.208 reward + -0.179 value_stay*harvest_duration + 0.11 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 3\n",
      "value_stay[t+1] = 0.097 1 + 0.681 value_stay[t] + 0.488 reward + 0.097 harvest_duration + -0.317 value_stay*harvest_duration + 0.485 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 5\n",
      "value_stay[t+1] = 0.057 1 + 0.665 value_stay[t] + 0.481 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.479 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 6\n",
      "value_stay[t+1] = 0.055 1 + 0.667 value_stay[t] + 0.397 reward + 0.056 harvest_duration + -0.335 value_stay*harvest_duration + 0.16 reward^2 + 0.397 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 8\n",
      "value_stay[t+1] = 0.109 1 + 0.626 value_stay[t] + -0.176 reward + 0.111 harvest_duration + -0.374 value_stay*harvest_duration + -0.174 reward*harvest_duration + 0.11 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 9\n",
      "value_stay[t+1] = 0.106 1 + 0.532 value_stay[t] + 0.177 reward + 0.105 harvest_duration + -0.467 value_stay*harvest_duration + 0.052 reward^2 + 0.181 reward*harvest_duration + 0.104 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 10\n",
      "value_stay[t+1] = 0.064 1 + 0.619 value_stay[t] + 0.395 reward + 0.064 harvest_duration + -0.378 value_stay*harvest_duration + 0.398 reward*harvest_duration + 0.064 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 11\n",
      "value_stay[t+1] = 0.173 1 + 0.728 value_stay[t] + 0.362 reward + -0.271 value_stay*harvest_duration + 0.259 reward^2 + 0.366 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 15\n",
      "value_stay[t+1] = 0.861 value_stay[t] + 0.106 harvest_duration + -0.135 value_stay*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 16\n",
      "value_stay[t+1] = 0.148 1 + 0.422 value_stay[t] + 0.148 harvest_duration + -0.58 value_stay*harvest_duration + 0.147 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 17\n",
      "value_stay[t+1] = 0.733 value_stay[t] + 0.461 reward + 0.068 harvest_duration + -0.264 value_stay*harvest_duration + 0.057 reward^2 + 0.462 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 18\n",
      "value_stay[t+1] = 0.811 value_stay[t] + 0.292 reward + -0.191 value_stay*harvest_duration + 0.296 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 19\n",
      "value_stay[t+1] = 0.812 value_stay[t] + 0.391 reward + -0.188 value_stay*harvest_duration + 0.391 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 21\n",
      "value_stay[t+1] = 0.081 1 + 0.648 value_stay[t] + 0.081 harvest_duration + -0.351 value_stay*harvest_duration + 0.371 reward^2 + 0.08 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 22\n",
      "value_stay[t+1] = 0.251 1 + 0.846 value_stay[t] + -0.154 value_stay*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 28\n",
      "value_stay[t+1] = 0.06 1 + 0.641 value_stay[t] + 0.257 reward + 0.06 harvest_duration + -0.356 value_stay*harvest_duration + 0.33 reward^2 + 0.254 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 29\n",
      "value_stay[t+1] = 0.127 1 + 0.471 value_stay[t] + 0.111 reward + 0.128 harvest_duration + -0.524 value_stay*harvest_duration + 0.109 reward*harvest_duration + 0.129 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 31\n",
      "value_stay[t+1] = 0.797 value_stay[t] + 0.301 reward + -0.203 value_stay*harvest_duration + 0.105 reward^2 + 0.298 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 34\n",
      "value_stay[t+1] = 0.816 value_stay[t] + 0.369 reward + -0.185 value_stay*harvest_duration + 0.049 reward^2 + 0.37 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 39\n",
      "value_stay[t+1] = 0.076 1 + 0.708 value_stay[t] + 0.486 reward + 0.076 harvest_duration + -0.291 value_stay*harvest_duration + 0.484 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 40\n",
      "value_stay[t+1] = 0.056 1 + 0.669 value_stay[t] + 0.48 reward + 0.056 harvest_duration + -0.327 value_stay*harvest_duration + 0.48 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 41\n",
      "value_stay[t+1] = 0.777 value_stay[t] + -0.222 value_stay*harvest_duration + 0.085 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 42\n",
      "value_stay[t+1] = 0.059 1 + 0.647 value_stay[t] + 0.412 reward + 0.059 harvest_duration + -0.353 value_stay*harvest_duration + 0.075 reward^2 + 0.412 reward*harvest_duration + 0.06 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 48\n",
      "value_stay[t+1] = 0.802 value_stay[t] + 0.321 reward + -0.199 value_stay*harvest_duration + 0.318 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 50\n",
      "value_stay[t+1] = 0.148 1 + 0.408 value_stay[t] + 0.148 harvest_duration + -0.592 value_stay*harvest_duration + 0.148 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 52\n",
      "value_stay[t+1] = 0.842 value_stay[t] + 0.109 reward + -0.158 value_stay*harvest_duration + 0.461 reward^2 + 0.108 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 53\n",
      "value_stay[t+1] = 0.101 1 + 0.674 value_stay[t] + 0.403 reward + 0.1 harvest_duration + -0.325 value_stay*harvest_duration + 0.119 reward^2 + 0.399 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 55\n",
      "value_stay[t+1] = 0.086 1 + 0.684 value_stay[t] + 0.426 reward + 0.085 harvest_duration + -0.322 value_stay*harvest_duration + 0.123 reward^2 + 0.425 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 56\n",
      "value_stay[t+1] = 0.236 1 + 0.708 value_stay[t] + 0.331 reward + -0.293 value_stay*harvest_duration + 0.294 reward^2 + 0.328 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 57\n",
      "value_stay[t+1] = 0.056 1 + 0.677 value_stay[t] + 0.501 reward + 0.054 harvest_duration + -0.325 value_stay*harvest_duration + 0.498 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 58\n",
      "value_stay[t+1] = 0.094 1 + 0.817 value_stay[t] + 0.094 harvest_duration + -0.186 value_stay*harvest_duration + 0.081 reward^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 60\n",
      "value_stay[t+1] = 0.051 1 + 0.779 value_stay[t] + -0.22 value_stay*harvest_duration + 0.375 reward^2 + 0.051 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 61\n",
      "value_stay[t+1] = 0.148 1 + 0.405 value_stay[t] + 0.148 harvest_duration + -0.591 value_stay*harvest_duration + 0.147 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 62\n",
      "value_stay[t+1] = 0.758 value_stay[t] + 0.434 reward + -0.244 value_stay*harvest_duration + 0.125 reward^2 + 0.431 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 63\n",
      "value_stay[t+1] = 0.847 value_stay[t] + 0.112 reward + -0.156 value_stay*harvest_duration + 0.398 reward^2 + 0.112 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 64\n",
      "value_stay[t+1] = 0.237 1 + 0.801 value_stay[t] + -0.2 value_stay*harvest_duration + 0.29 reward^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 65\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 67\n",
      "value_stay[t+1] = 0.15 1 + 0.41 value_stay[t] + 0.15 harvest_duration + -0.594 value_stay*harvest_duration + 0.148 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 69\n",
      "value_stay[t+1] = 0.691 value_stay[t] + 0.486 reward + 0.13 harvest_duration + -0.307 value_stay*harvest_duration + 0.486 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 76\n",
      "value_stay[t+1] = 0.068 1 + 0.64 value_stay[t] + 0.349 reward + 0.069 harvest_duration + -0.364 value_stay*harvest_duration + 0.198 reward^2 + 0.348 reward*harvest_duration + 0.069 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 83\n",
      "value_stay[t+1] = 0.829 value_stay[t] + 0.132 harvest_duration + -0.19 value_stay*harvest_duration + 0.111 reward^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 85\n",
      "value_stay[t+1] = 0.054 1 + 0.654 value_stay[t] + 0.291 reward + 0.055 harvest_duration + -0.344 value_stay*harvest_duration + 0.284 reward^2 + 0.291 reward*harvest_duration + 0.054 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 87\n",
      "value_stay[t+1] = 0.149 1 + 0.4 value_stay[t] + 0.151 harvest_duration + -0.605 value_stay*harvest_duration + 0.151 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 88\n",
      "value_stay[t+1] = 0.085 1 + 0.683 value_stay[t] + -0.128 reward + 0.084 harvest_duration + -0.325 value_stay*harvest_duration + -0.132 reward*harvest_duration + 0.085 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 89\n",
      "value_stay[t+1] = 0.702 value_stay[t] + 0.469 reward + 0.109 harvest_duration + -0.297 value_stay*harvest_duration + 0.471 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 91\n",
      "value_stay[t+1] = 0.082 1 + 0.596 value_stay[t] + 0.245 reward + 0.082 harvest_duration + -0.403 value_stay*harvest_duration + 0.244 reward^2 + 0.25 reward*harvest_duration + 0.084 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 94\n",
      "value_stay[t+1] = 0.089 1 + 0.693 value_stay[t] + 0.298 reward + 0.09 harvest_duration + -0.304 value_stay*harvest_duration + 0.366 reward^2 + 0.298 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 96\n",
      "value_stay[t+1] = 0.083 1 + 0.693 value_stay[t] + 0.338 reward + 0.083 harvest_duration + -0.304 value_stay*harvest_duration + 0.259 reward^2 + 0.343 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 98\n",
      "value_stay[t+1] = 0.088 1 + 0.697 value_stay[t] + 0.348 reward + 0.088 harvest_duration + -0.305 value_stay*harvest_duration + 0.28 reward^2 + 0.349 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 102\n",
      "value_stay[t+1] = 0.673 value_stay[t] + 0.417 reward + 0.053 harvest_duration + -0.328 value_stay*harvest_duration + 0.102 reward^2 + 0.416 reward*harvest_duration + 0.053 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 106\n",
      "value_stay[t+1] = 0.058 1 + 0.666 value_stay[t] + 0.486 reward + 0.06 harvest_duration + -0.331 value_stay*harvest_duration + 0.483 reward*harvest_duration + 0.06 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 107\n",
      "value_stay[t+1] = 0.822 value_stay[t] + 0.229 reward + -0.177 value_stay*harvest_duration + 0.221 reward^2 + 0.231 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 108\n",
      "value_stay[t+1] = 0.104 1 + 0.789 value_stay[t] + 0.104 harvest_duration + -0.209 value_stay*harvest_duration + 0.144 reward^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 111\n",
      "value_stay[t+1] = 0.761 value_stay[t] + 0.486 reward + -0.24 value_stay*harvest_duration + 0.487 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 117\n",
      "value_stay[t+1] = 0.192 1 + 0.717 value_stay[t] + 0.488 reward + -0.281 value_stay*harvest_duration + 0.485 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 118\n",
      "value_stay[t+1] = 0.053 1 + 0.736 value_stay[t] + 0.516 reward + 0.052 harvest_duration + -0.052 value_stay^2 + -0.264 value_stay*harvest_duration + 0.516 reward*harvest_duration + 0.052 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 119\n",
      "value_stay[t+1] = 0.1 1 + 0.549 value_stay[t] + 0.163 reward + 0.099 harvest_duration + -0.45 value_stay*harvest_duration + 0.165 reward^2 + 0.163 reward*harvest_duration + 0.099 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 129\n",
      "value_stay[t+1] = 0.132 1 + 0.463 value_stay[t] + 0.096 reward + 0.131 harvest_duration + -0.532 value_stay*harvest_duration + 0.097 reward*harvest_duration + 0.131 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 136\n",
      "value_stay[t+1] = 0.801 value_stay[t] + 0.336 reward + -0.201 value_stay*harvest_duration + 0.336 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 137\n",
      "value_stay[t+1] = 0.153 1 + 0.389 value_stay[t] + 0.153 harvest_duration + -0.605 value_stay*harvest_duration + 0.153 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 138\n",
      "value_stay[t+1] = 0.224 1 + 0.708 value_stay[t] + 0.359 reward + -0.294 value_stay*harvest_duration + 0.229 reward^2 + 0.356 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 141\n",
      "value_stay[t+1] = 0.796 value_stay[t] + 0.101 reward + 0.078 harvest_duration + -0.204 value_stay*harvest_duration + 0.265 reward^2 + 0.098 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 145\n",
      "value_stay[t+1] = 0.725 value_stay[t] + 0.496 reward + 0.089 harvest_duration + -0.275 value_stay*harvest_duration + 0.495 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 147\n",
      "value_stay[t+1] = 0.095 1 + 0.596 value_stay[t] + 0.061 reward + 0.095 harvest_duration + -0.405 value_stay*harvest_duration + 0.061 reward*harvest_duration + 0.094 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 149\n",
      "value_stay[t+1] = 0.764 value_stay[t] + 0.496 reward + -0.237 value_stay*harvest_duration + 0.495 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 150\n",
      "value_stay[t+1] = 0.172 1 + 0.723 value_stay[t] + 0.488 reward + -0.275 value_stay*harvest_duration + 0.491 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 151\n",
      "value_stay[t+1] = 0.066 1 + 0.638 value_stay[t] + 0.372 reward + 0.066 harvest_duration + -0.363 value_stay*harvest_duration + 0.149 reward^2 + 0.369 reward*harvest_duration + 0.065 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 155\n",
      "value_stay[t+1] = 0.762 value_stay[t] + 0.463 reward + -0.24 value_stay*harvest_duration + 0.052 reward^2 + 0.465 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 156\n",
      "value_stay[t+1] = 0.104 1 + 0.761 value_stay[t] + 0.104 harvest_duration + -0.239 value_stay*harvest_duration + 0.427 reward^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 157\n",
      "value_stay[t+1] = 0.134 1 + 0.461 value_stay[t] + 0.083 reward + 0.133 harvest_duration + -0.535 value_stay*harvest_duration + 0.083 reward*harvest_duration + 0.134 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 158\n",
      "value_stay[t+1] = 0.105 1 + 0.764 value_stay[t] + 0.105 harvest_duration + -0.236 value_stay*harvest_duration + 0.297 reward^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 159\n",
      "value_stay[t+1] = 0.764 value_stay[t] + 0.403 reward + -0.236 value_stay*harvest_duration + 0.185 reward^2 + 0.406 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 163\n",
      "value_stay[t+1] = 0.869 value_stay[t] + 0.076 reward + -0.13 value_stay*harvest_duration + 0.295 reward^2 + 0.076 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 169\n",
      "value_stay[t+1] = 0.152 1 + 0.391 value_stay[t] + 0.152 harvest_duration + -0.604 value_stay*harvest_duration + 0.152 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 170\n",
      "value_stay[t+1] = 0.689 value_stay[t] + 0.496 reward + -0.308 value_stay*harvest_duration + 0.492 reward*harvest_duration + 0.072 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 173\n",
      "value_stay[t+1] = 0.073 1 + 0.72 value_stay[t] + -0.061 reward + 0.073 harvest_duration + -0.25 value_stay*harvest_duration + -0.058 reward*harvest_duration + 0.072 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 175\n",
      "value_stay[t+1] = 0.699 value_stay[t] + 0.469 reward + 0.107 harvest_duration + -0.299 value_stay*harvest_duration + 0.469 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 178\n",
      "value_stay[t+1] = 0.141 1 + 0.433 value_stay[t] + 0.14 harvest_duration + -0.563 value_stay*harvest_duration + 0.071 reward*harvest_duration + 0.141 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 179\n",
      "value_stay[t+1] = 0.125 1 + 0.506 value_stay[t] + -0.126 reward + 0.125 harvest_duration + -0.494 value_stay*harvest_duration + 0.125 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 180\n",
      "value_stay[t+1] = 0.796 value_stay[t] + 0.292 reward + -0.204 value_stay*harvest_duration + 0.131 reward^2 + 0.292 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 183\n",
      "value_stay[t+1] = 0.846 value_stay[t] + -0.091 reward + 0.071 harvest_duration + -0.154 value_stay*harvest_duration + -0.092 reward*harvest_duration + 0.054 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 187\n",
      "value_stay[t+1] = 0.137 1 + 0.444 value_stay[t] + 0.138 harvest_duration + -0.559 value_stay*harvest_duration + 0.137 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 190\n",
      "value_stay[t+1] = 0.808 value_stay[t] + 0.433 reward + -0.194 value_stay*harvest_duration + 0.43 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 192\n",
      "value_stay[t+1] = 0.269 1 + 0.779 value_stay[t] + 0.268 harvest_duration + -0.13 value_stay^2 + -0.221 value_stay*harvest_duration + 0.27 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 193\n",
      "value_stay[t+1] = 0.072 1 + 0.843 value_stay[t] + -0.092 reward + -0.156 value_stay*harvest_duration + -0.092 reward*harvest_duration + 0.071 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 196\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.434 reward + 0.057 harvest_duration + -0.328 value_stay*harvest_duration + 0.075 reward^2 + 0.435 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 197\n",
      "value_stay[t+1] = 0.748 value_stay[t] + 0.535 reward + -0.25 value_stay*harvest_duration + 0.535 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 200\n",
      "value_stay[t+1] = 0.809 value_stay[t] + 0.283 reward + -0.191 value_stay*harvest_duration + 0.183 reward^2 + 0.286 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 201\n",
      "value_stay[t+1] = 0.112 1 + 0.624 value_stay[t] + -0.175 reward + 0.111 harvest_duration + -0.376 value_stay*harvest_duration + -0.175 reward*harvest_duration + 0.111 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 203\n",
      "value_stay[t+1] = 0.073 1 + 0.627 value_stay[t] + 0.148 reward + 0.072 harvest_duration + -0.375 value_stay*harvest_duration + 0.382 reward^2 + 0.148 reward*harvest_duration + 0.072 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 204\n",
      "value_stay[t+1] = 0.052 1 + 0.668 value_stay[t] + 0.481 reward + 0.053 harvest_duration + -0.329 value_stay*harvest_duration + 0.478 reward*harvest_duration + 0.052 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 205\n",
      "value_stay[t+1] = 0.112 1 + 0.595 value_stay[t] + -0.143 reward + 0.112 harvest_duration + -0.412 value_stay*harvest_duration + -0.143 reward*harvest_duration + 0.112 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 207\n",
      "value_stay[t+1] = 0.146 1 + 0.417 value_stay[t] + 0.146 harvest_duration + -0.582 value_stay*harvest_duration + 0.147 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 210\n",
      "value_stay[t+1] = 0.057 1 + 0.675 value_stay[t] + 0.48 reward + 0.058 harvest_duration + -0.328 value_stay*harvest_duration + 0.482 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 212\n",
      "value_stay[t+1] = 0.099 1 + 0.557 value_stay[t] + 0.16 reward + 0.098 harvest_duration + -0.444 value_stay*harvest_duration + 0.237 reward^2 + 0.163 reward*harvest_duration + 0.099 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 213\n",
      "value_stay[t+1] = 0.114 1 + 0.62 value_stay[t] + -0.174 reward + 0.112 harvest_duration + -0.385 value_stay*harvest_duration + -0.172 reward*harvest_duration + 0.114 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 217\n",
      "value_stay[t+1] = 0.142 1 + 0.457 value_stay[t] + 0.141 harvest_duration + -0.54 value_stay*harvest_duration + 0.142 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 224\n",
      "value_stay[t+1] = 0.103 1 + 0.648 value_stay[t] + -0.171 reward + 0.104 harvest_duration + -0.357 value_stay*harvest_duration + -0.171 reward*harvest_duration + 0.103 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 227\n",
      "value_stay[t+1] = 0.682 value_stay[t] + 0.497 reward + 0.052 harvest_duration + -0.321 value_stay*harvest_duration + 0.497 reward*harvest_duration + 0.052 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 228\n",
      "value_stay[t+1] = 0.149 1 + 0.413 value_stay[t] + 0.148 harvest_duration + -0.588 value_stay*harvest_duration + 0.149 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 229\n",
      "value_stay[t+1] = 0.817 value_stay[t] + 0.22 reward + -0.181 value_stay*harvest_duration + 0.175 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 232\n",
      "value_stay[t+1] = 0.102 1 + 0.771 value_stay[t] + 0.102 harvest_duration + -0.23 value_stay*harvest_duration + 0.314 reward^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 234\n",
      "value_stay[t+1] = 0.756 value_stay[t] + 0.511 reward + -0.245 value_stay*harvest_duration + 0.51 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 237\n",
      "value_stay[t+1] = 0.062 1 + 0.651 value_stay[t] + 0.415 reward + 0.061 harvest_duration + -0.352 value_stay*harvest_duration + 0.081 reward^2 + 0.415 reward*harvest_duration + 0.062 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 244\n",
      "value_stay[t+1] = 0.832 value_stay[t] + 0.368 reward + -0.169 value_stay*harvest_duration + 0.365 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 245\n",
      "value_stay[t+1] = 0.151 1 + 0.432 value_stay[t] + 0.151 harvest_duration + -0.567 value_stay*harvest_duration + 0.151 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 246\n",
      "value_stay[t+1] = 0.819 value_stay[t] + 0.285 reward + -0.183 value_stay*harvest_duration + 0.134 reward^2 + 0.286 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 248\n",
      "value_stay[t+1] = 0.101 1 + 0.569 value_stay[t] + 0.06 reward + 0.101 harvest_duration + -0.432 value_stay*harvest_duration + 0.06 reward*harvest_duration + 0.101 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n"
     ]
    }
   ],
   "source": [
    "print('UNDERHARVESTERS') \n",
    "for p in underharvesters:\n",
    "    print('Participant number', p)\n",
    "    estimator.print_spice_model(participant_id=p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MVT Model by Constantino et al. (2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "from weinhardt2025.benchmarking.benchmarking_bustamante2023 import MarginalValueTheoremModel\n",
    "from weinhardt2025.benchmarking.benchmarking_gru import training\n",
    "from spice.resources.bandits import AgentNetwork\n",
    "\n",
    "\n",
    "mvt = MarginalValueTheoremModel(\n",
    "    n_participants=n_participants,\n",
    "    depletion=None,  # if None: learn value; else: fix to given value;\n",
    "    baseline_gain=None,  # if None: learn value; else: fix to given value;\n",
    "    batch_first=True,\n",
    "    )\n",
    "\n",
    "epochs = 1000\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=mvt.parameters(), lr=0.01)\n",
    "\n",
    "path_mvt = '../../weinhardt2025/params/bustamante2023/baseline_bustamante2023.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000: L(Train): 0.7199206352233887; L(Test): 0.7148324251174927\n",
      "Epoch 2/1000: L(Train): 0.7145852446556091; L(Test): 0.7100205421447754\n",
      "Epoch 3/1000: L(Train): 0.709622323513031; L(Test): 0.7053030133247375\n",
      "Epoch 4/1000: L(Train): 0.7049347162246704; L(Test): 0.7006457448005676\n",
      "Epoch 5/1000: L(Train): 0.7001373767852783; L(Test): 0.6960488557815552\n",
      "Epoch 6/1000: L(Train): 0.69582599401474; L(Test): 0.6915087699890137\n",
      "Epoch 7/1000: L(Train): 0.6915344595909119; L(Test): 0.6870206594467163\n",
      "Epoch 8/1000: L(Train): 0.6870281100273132; L(Test): 0.6825779676437378\n",
      "Epoch 9/1000: L(Train): 0.6827908754348755; L(Test): 0.6781867146492004\n",
      "Epoch 10/1000: L(Train): 0.6779783368110657; L(Test): 0.6738501191139221\n",
      "Epoch 11/1000: L(Train): 0.6740661859512329; L(Test): 0.6695634722709656\n",
      "Epoch 12/1000: L(Train): 0.6697940826416016; L(Test): 0.6653233170509338\n",
      "Epoch 13/1000: L(Train): 0.6652541160583496; L(Test): 0.6611303091049194\n",
      "Epoch 14/1000: L(Train): 0.6611160039901733; L(Test): 0.6569823026657104\n",
      "Epoch 15/1000: L(Train): 0.6568900942802429; L(Test): 0.652880847454071\n",
      "Epoch 16/1000: L(Train): 0.6528928875923157; L(Test): 0.6488248109817505\n",
      "Epoch 17/1000: L(Train): 0.6490197777748108; L(Test): 0.6448135375976562\n",
      "Epoch 18/1000: L(Train): 0.6447246074676514; L(Test): 0.6408495306968689\n",
      "Epoch 19/1000: L(Train): 0.6409608125686646; L(Test): 0.6369319558143616\n",
      "Epoch 20/1000: L(Train): 0.6366987228393555; L(Test): 0.633060872554779\n",
      "Epoch 21/1000: L(Train): 0.6330204010009766; L(Test): 0.6292343735694885\n",
      "Epoch 22/1000: L(Train): 0.629463255405426; L(Test): 0.6254522204399109\n",
      "Epoch 23/1000: L(Train): 0.62552410364151; L(Test): 0.6217140555381775\n",
      "Epoch 24/1000: L(Train): 0.6219736337661743; L(Test): 0.6180192828178406\n",
      "Epoch 25/1000: L(Train): 0.6184539794921875; L(Test): 0.6143694519996643\n",
      "Epoch 26/1000: L(Train): 0.6143827438354492; L(Test): 0.6107633113861084\n",
      "Epoch 27/1000: L(Train): 0.6109620928764343; L(Test): 0.6072007417678833\n",
      "Epoch 28/1000: L(Train): 0.6069067716598511; L(Test): 0.6036789417266846\n",
      "Epoch 29/1000: L(Train): 0.6036773920059204; L(Test): 0.6001981496810913\n",
      "Epoch 30/1000: L(Train): 0.600479781627655; L(Test): 0.596759557723999\n",
      "Epoch 31/1000: L(Train): 0.5967574119567871; L(Test): 0.593361496925354\n",
      "Epoch 32/1000: L(Train): 0.593315839767456; L(Test): 0.5900037884712219\n",
      "Epoch 33/1000: L(Train): 0.5902352929115295; L(Test): 0.5866857767105103\n",
      "Epoch 34/1000: L(Train): 0.5861316919326782; L(Test): 0.5834041833877563\n",
      "Epoch 35/1000: L(Train): 0.583764374256134; L(Test): 0.5801633596420288\n",
      "Epoch 36/1000: L(Train): 0.5800980925559998; L(Test): 0.5769590139389038\n",
      "Epoch 37/1000: L(Train): 0.5770981907844543; L(Test): 0.573792576789856\n",
      "Epoch 38/1000: L(Train): 0.5735121369361877; L(Test): 0.5706624984741211\n",
      "Epoch 39/1000: L(Train): 0.5710322856903076; L(Test): 0.5675681233406067\n",
      "Epoch 40/1000: L(Train): 0.5678266286849976; L(Test): 0.5645108819007874\n",
      "Epoch 41/1000: L(Train): 0.5644029378890991; L(Test): 0.5614891052246094\n",
      "Epoch 42/1000: L(Train): 0.5618523359298706; L(Test): 0.5585018396377563\n",
      "Epoch 43/1000: L(Train): 0.5584064722061157; L(Test): 0.5555476546287537\n",
      "Epoch 44/1000: L(Train): 0.5558965802192688; L(Test): 0.5526271462440491\n",
      "Epoch 45/1000: L(Train): 0.5527957081794739; L(Test): 0.549739420413971\n",
      "Epoch 46/1000: L(Train): 0.5497692823410034; L(Test): 0.5468831658363342\n",
      "Epoch 47/1000: L(Train): 0.547430694103241; L(Test): 0.544059157371521\n",
      "Epoch 48/1000: L(Train): 0.5432100296020508; L(Test): 0.5412635803222656\n",
      "Epoch 49/1000: L(Train): 0.5414409637451172; L(Test): 0.5384984612464905\n",
      "Epoch 50/1000: L(Train): 0.5395830273628235; L(Test): 0.5357651710510254\n",
      "Epoch 51/1000: L(Train): 0.536592960357666; L(Test): 0.5330621004104614\n",
      "Epoch 52/1000: L(Train): 0.5318370461463928; L(Test): 0.530385434627533\n",
      "Epoch 53/1000: L(Train): 0.5304440855979919; L(Test): 0.5277374982833862\n",
      "Epoch 54/1000: L(Train): 0.5277808904647827; L(Test): 0.5251175165176392\n",
      "Epoch 55/1000: L(Train): 0.525389552116394; L(Test): 0.5225257277488708\n",
      "Epoch 56/1000: L(Train): 0.5226140022277832; L(Test): 0.5199601650238037\n",
      "Epoch 57/1000: L(Train): 0.5199989080429077; L(Test): 0.5174216628074646\n",
      "Epoch 58/1000: L(Train): 0.5178260803222656; L(Test): 0.5149185061454773\n",
      "Epoch 59/1000: L(Train): 0.5150222778320312; L(Test): 0.5124719738960266\n",
      "Epoch 60/1000: L(Train): 0.5119452476501465; L(Test): 0.5100937485694885\n",
      "Epoch 61/1000: L(Train): 0.5099132061004639; L(Test): 0.5077918171882629\n",
      "Epoch 62/1000: L(Train): 0.5076957941055298; L(Test): 0.5055922269821167\n",
      "Epoch 63/1000: L(Train): 0.5058284401893616; L(Test): 0.5034951567649841\n",
      "Epoch 64/1000: L(Train): 0.503658652305603; L(Test): 0.5014760494232178\n",
      "Epoch 65/1000: L(Train): 0.5014793872833252; L(Test): 0.49950578808784485\n",
      "Epoch 66/1000: L(Train): 0.49888402223587036; L(Test): 0.49757257103919983\n",
      "Epoch 67/1000: L(Train): 0.49730005860328674; L(Test): 0.4956713318824768\n",
      "Epoch 68/1000: L(Train): 0.49549752473831177; L(Test): 0.4937955141067505\n",
      "Epoch 69/1000: L(Train): 0.49403271079063416; L(Test): 0.49194398522377014\n",
      "Epoch 70/1000: L(Train): 0.4913465976715088; L(Test): 0.490111380815506\n",
      "Epoch 71/1000: L(Train): 0.49027112126350403; L(Test): 0.48829808831214905\n",
      "Epoch 72/1000: L(Train): 0.48798152804374695; L(Test): 0.48650336265563965\n",
      "Epoch 73/1000: L(Train): 0.4864262640476227; L(Test): 0.4847274124622345\n",
      "Epoch 74/1000: L(Train): 0.4854368269443512; L(Test): 0.48297154903411865\n",
      "Epoch 75/1000: L(Train): 0.48386651277542114; L(Test): 0.4812348484992981\n",
      "Epoch 76/1000: L(Train): 0.4807489216327667; L(Test): 0.47951561212539673\n",
      "Epoch 77/1000: L(Train): 0.4783444106578827; L(Test): 0.4778137803077698\n",
      "Epoch 78/1000: L(Train): 0.47755953669548035; L(Test): 0.4761297404766083\n",
      "Epoch 79/1000: L(Train): 0.476301908493042; L(Test): 0.4744630753993988\n",
      "Epoch 80/1000: L(Train): 0.4737924635410309; L(Test): 0.4728138744831085\n",
      "Epoch 81/1000: L(Train): 0.47331762313842773; L(Test): 0.47118255496025085\n",
      "Epoch 82/1000: L(Train): 0.47085896134376526; L(Test): 0.4695679247379303\n",
      "Epoch 83/1000: L(Train): 0.4695826768875122; L(Test): 0.4679698944091797\n",
      "Epoch 84/1000: L(Train): 0.46788081526756287; L(Test): 0.46638891100883484\n",
      "Epoch 85/1000: L(Train): 0.4672963321208954; L(Test): 0.46482476592063904\n",
      "Epoch 86/1000: L(Train): 0.46602484583854675; L(Test): 0.4632780849933624\n",
      "Epoch 87/1000: L(Train): 0.46337929368019104; L(Test): 0.46174734830856323\n",
      "Epoch 88/1000: L(Train): 0.4606248736381531; L(Test): 0.46023157238960266\n",
      "Epoch 89/1000: L(Train): 0.46179354190826416; L(Test): 0.4587332010269165\n",
      "Epoch 90/1000: L(Train): 0.45900291204452515; L(Test): 0.45725056529045105\n",
      "Epoch 91/1000: L(Train): 0.4576076865196228; L(Test): 0.4557839334011078\n",
      "Epoch 92/1000: L(Train): 0.45578891038894653; L(Test): 0.45433279871940613\n",
      "Epoch 93/1000: L(Train): 0.4546738266944885; L(Test): 0.4528968632221222\n",
      "Epoch 94/1000: L(Train): 0.45490550994873047; L(Test): 0.4514783024787903\n",
      "Epoch 95/1000: L(Train): 0.4503993093967438; L(Test): 0.4500730633735657\n",
      "Epoch 96/1000: L(Train): 0.450319766998291; L(Test): 0.4486832916736603\n",
      "Epoch 97/1000: L(Train): 0.4485532343387604; L(Test): 0.4473072588443756\n",
      "Epoch 98/1000: L(Train): 0.44739004969596863; L(Test): 0.44594621658325195\n",
      "Epoch 99/1000: L(Train): 0.44737163186073303; L(Test): 0.4446001648902893\n",
      "Epoch 100/1000: L(Train): 0.4449220597743988; L(Test): 0.4432680010795593\n",
      "Epoch 101/1000: L(Train): 0.4423545002937317; L(Test): 0.44194963574409485\n",
      "Epoch 102/1000: L(Train): 0.4428296387195587; L(Test): 0.44064587354660034\n",
      "Epoch 103/1000: L(Train): 0.4416307508945465; L(Test): 0.4393561780452728\n",
      "Epoch 104/1000: L(Train): 0.4384117126464844; L(Test): 0.43807923793792725\n",
      "Epoch 105/1000: L(Train): 0.43671101331710815; L(Test): 0.4368145763874054\n",
      "Epoch 106/1000: L(Train): 0.4361323416233063; L(Test): 0.43556320667266846\n",
      "Epoch 107/1000: L(Train): 0.43558675050735474; L(Test): 0.4343249797821045\n",
      "Epoch 108/1000: L(Train): 0.4343051016330719; L(Test): 0.4331001341342926\n",
      "Epoch 109/1000: L(Train): 0.43425479531288147; L(Test): 0.4318893849849701\n",
      "Epoch 110/1000: L(Train): 0.4324130117893219; L(Test): 0.4306917190551758\n",
      "Epoch 111/1000: L(Train): 0.4317089319229126; L(Test): 0.42950794100761414\n",
      "Epoch 112/1000: L(Train): 0.4297536313533783; L(Test): 0.42833763360977173\n",
      "Epoch 113/1000: L(Train): 0.4288071095943451; L(Test): 0.42718032002449036\n",
      "Epoch 114/1000: L(Train): 0.4286558926105499; L(Test): 0.42603638768196106\n",
      "Epoch 115/1000: L(Train): 0.4250946044921875; L(Test): 0.4249034821987152\n",
      "Epoch 116/1000: L(Train): 0.42450907826423645; L(Test): 0.42378145456314087\n",
      "Epoch 117/1000: L(Train): 0.4265052378177643; L(Test): 0.4226728081703186\n",
      "Epoch 118/1000: L(Train): 0.4239017367362976; L(Test): 0.4215765595436096\n",
      "Epoch 119/1000: L(Train): 0.42256930470466614; L(Test): 0.4204927086830139\n",
      "Epoch 120/1000: L(Train): 0.42041274905204773; L(Test): 0.419420450925827\n",
      "Epoch 121/1000: L(Train): 0.4200228750705719; L(Test): 0.41836005449295044\n",
      "Epoch 122/1000: L(Train): 0.4187779128551483; L(Test): 0.4173104465007782\n",
      "Epoch 123/1000: L(Train): 0.4168955683708191; L(Test): 0.41627079248428345\n",
      "Epoch 124/1000: L(Train): 0.41547372937202454; L(Test): 0.41524171829223633\n",
      "Epoch 125/1000: L(Train): 0.4126351475715637; L(Test): 0.4142218828201294\n",
      "Epoch 126/1000: L(Train): 0.41336479783058167; L(Test): 0.41321250796318054\n",
      "Epoch 127/1000: L(Train): 0.41033807396888733; L(Test): 0.4122123122215271\n",
      "Epoch 128/1000: L(Train): 0.41111233830451965; L(Test): 0.41122254729270935\n",
      "Epoch 129/1000: L(Train): 0.410549521446228; L(Test): 0.41024354100227356\n",
      "Epoch 130/1000: L(Train): 0.4097180962562561; L(Test): 0.4092753231525421\n",
      "Epoch 131/1000: L(Train): 0.40880900621414185; L(Test): 0.40831759572029114\n",
      "Epoch 132/1000: L(Train): 0.40734270215034485; L(Test): 0.4073708951473236\n",
      "Epoch 133/1000: L(Train): 0.4101347327232361; L(Test): 0.4064359962940216\n",
      "Epoch 134/1000: L(Train): 0.40700143575668335; L(Test): 0.4055115580558777\n",
      "Epoch 135/1000: L(Train): 0.4056491255760193; L(Test): 0.40459728240966797\n",
      "Epoch 136/1000: L(Train): 0.4080066978931427; L(Test): 0.4036949872970581\n",
      "Epoch 137/1000: L(Train): 0.40393367409706116; L(Test): 0.40280282497406006\n",
      "Epoch 138/1000: L(Train): 0.4018670916557312; L(Test): 0.4019196331501007\n",
      "Epoch 139/1000: L(Train): 0.4001571536064148; L(Test): 0.4010446071624756\n",
      "Epoch 140/1000: L(Train): 0.40451037883758545; L(Test): 0.4001806676387787\n",
      "Epoch 141/1000: L(Train): 0.4004639685153961; L(Test): 0.3993268609046936\n",
      "Epoch 142/1000: L(Train): 0.39823755621910095; L(Test): 0.39848172664642334\n",
      "Epoch 143/1000: L(Train): 0.3972952663898468; L(Test): 0.3976452052593231\n",
      "Epoch 144/1000: L(Train): 0.3974948823451996; L(Test): 0.3968178629875183\n",
      "Epoch 145/1000: L(Train): 0.3958020508289337; L(Test): 0.3959991931915283\n",
      "Epoch 146/1000: L(Train): 0.39664801955223083; L(Test): 0.3951895833015442\n",
      "Epoch 147/1000: L(Train): 0.3926500380039215; L(Test): 0.3943876326084137\n",
      "Epoch 148/1000: L(Train): 0.39470139145851135; L(Test): 0.3935950994491577\n",
      "Epoch 149/1000: L(Train): 0.3894953727722168; L(Test): 0.39280956983566284\n",
      "Epoch 150/1000: L(Train): 0.3909122049808502; L(Test): 0.3920321464538574\n",
      "Epoch 151/1000: L(Train): 0.3904803693294525; L(Test): 0.3912626802921295\n",
      "Epoch 152/1000: L(Train): 0.3912319242954254; L(Test): 0.39050284028053284\n",
      "Epoch 153/1000: L(Train): 0.388849139213562; L(Test): 0.389751136302948\n",
      "Epoch 154/1000: L(Train): 0.3903445303440094; L(Test): 0.389008492231369\n",
      "Epoch 155/1000: L(Train): 0.38743627071380615; L(Test): 0.38827332854270935\n",
      "Epoch 156/1000: L(Train): 0.38822871446609497; L(Test): 0.38754716515541077\n",
      "Epoch 157/1000: L(Train): 0.3861652612686157; L(Test): 0.3868286907672882\n",
      "Epoch 158/1000: L(Train): 0.3873416483402252; L(Test): 0.38611900806427\n",
      "Epoch 159/1000: L(Train): 0.38789427280426025; L(Test): 0.3854183554649353\n",
      "Epoch 160/1000: L(Train): 0.3861376941204071; L(Test): 0.3847261667251587\n",
      "Epoch 161/1000: L(Train): 0.38466134667396545; L(Test): 0.3840417265892029\n",
      "Epoch 162/1000: L(Train): 0.38427460193634033; L(Test): 0.38336506485939026\n",
      "Epoch 163/1000: L(Train): 0.38265207409858704; L(Test): 0.3826962411403656\n",
      "Epoch 164/1000: L(Train): 0.38295722007751465; L(Test): 0.38203519582748413\n",
      "Epoch 165/1000: L(Train): 0.3810214102268219; L(Test): 0.38138115406036377\n",
      "Epoch 166/1000: L(Train): 0.3822687268257141; L(Test): 0.38073551654815674\n",
      "Epoch 167/1000: L(Train): 0.3828103542327881; L(Test): 0.3800976276397705\n",
      "Epoch 168/1000: L(Train): 0.38002198934555054; L(Test): 0.3794667720794678\n",
      "Epoch 169/1000: L(Train): 0.38062235713005066; L(Test): 0.3788439631462097\n",
      "Epoch 170/1000: L(Train): 0.37741151452064514; L(Test): 0.37822747230529785\n",
      "Epoch 171/1000: L(Train): 0.3760077655315399; L(Test): 0.3776169419288635\n",
      "Epoch 172/1000: L(Train): 0.3772178590297699; L(Test): 0.37701308727264404\n",
      "Epoch 173/1000: L(Train): 0.3758834898471832; L(Test): 0.37641581892967224\n",
      "Epoch 174/1000: L(Train): 0.3780187964439392; L(Test): 0.37582603096961975\n",
      "Epoch 175/1000: L(Train): 0.37487590312957764; L(Test): 0.37524276971817017\n",
      "Epoch 176/1000: L(Train): 0.3748200833797455; L(Test): 0.3746660649776459\n",
      "Epoch 177/1000: L(Train): 0.3735692501068115; L(Test): 0.37409523129463196\n",
      "Epoch 178/1000: L(Train): 0.3742918074131012; L(Test): 0.37353068590164185\n",
      "Epoch 179/1000: L(Train): 0.37379467487335205; L(Test): 0.3729728162288666\n",
      "Epoch 180/1000: L(Train): 0.37345635890960693; L(Test): 0.3724212348461151\n",
      "Epoch 181/1000: L(Train): 0.37278053164482117; L(Test): 0.3718758225440979\n",
      "Epoch 182/1000: L(Train): 0.37136033177375793; L(Test): 0.37133681774139404\n",
      "Epoch 183/1000: L(Train): 0.37030819058418274; L(Test): 0.37080302834510803\n",
      "Epoch 184/1000: L(Train): 0.3720363676548004; L(Test): 0.3702758252620697\n",
      "Epoch 185/1000: L(Train): 0.3687981069087982; L(Test): 0.36975449323654175\n",
      "Epoch 186/1000: L(Train): 0.3683622181415558; L(Test): 0.36923858523368835\n",
      "Epoch 187/1000: L(Train): 0.36913755536079407; L(Test): 0.36872828006744385\n",
      "Epoch 188/1000: L(Train): 0.36920490860939026; L(Test): 0.36822405457496643\n",
      "Epoch 189/1000: L(Train): 0.3681223690509796; L(Test): 0.3677254319190979\n",
      "Epoch 190/1000: L(Train): 0.36809176206588745; L(Test): 0.3672327697277069\n",
      "Epoch 191/1000: L(Train): 0.36708706617355347; L(Test): 0.3667456805706024\n",
      "Epoch 192/1000: L(Train): 0.36642810702323914; L(Test): 0.3662642240524292\n",
      "Epoch 193/1000: L(Train): 0.36600732803344727; L(Test): 0.36578816175460815\n",
      "Epoch 194/1000: L(Train): 0.36404919624328613; L(Test): 0.3653172254562378\n",
      "Epoch 195/1000: L(Train): 0.366094172000885; L(Test): 0.3648515045642853\n",
      "Epoch 196/1000: L(Train): 0.36505019664764404; L(Test): 0.3643908202648163\n",
      "Epoch 197/1000: L(Train): 0.3649682402610779; L(Test): 0.36393532156944275\n",
      "Epoch 198/1000: L(Train): 0.3672950863838196; L(Test): 0.3634856641292572\n",
      "Epoch 199/1000: L(Train): 0.36161765456199646; L(Test): 0.36304041743278503\n",
      "Epoch 200/1000: L(Train): 0.36139973998069763; L(Test): 0.3625994920730591\n",
      "Epoch 201/1000: L(Train): 0.3614361584186554; L(Test): 0.3621631860733032\n",
      "Epoch 202/1000: L(Train): 0.36093661189079285; L(Test): 0.36173108220100403\n",
      "Epoch 203/1000: L(Train): 0.362560898065567; L(Test): 0.3613044321537018\n",
      "Epoch 204/1000: L(Train): 0.36411502957344055; L(Test): 0.36088308691978455\n",
      "Epoch 205/1000: L(Train): 0.3616369664669037; L(Test): 0.36046695709228516\n",
      "Epoch 206/1000: L(Train): 0.3608797788619995; L(Test): 0.3600556552410126\n",
      "Epoch 207/1000: L(Train): 0.3586304485797882; L(Test): 0.3596487045288086\n",
      "Epoch 208/1000: L(Train): 0.3577647805213928; L(Test): 0.3592454791069031\n",
      "Epoch 209/1000: L(Train): 0.3596413731575012; L(Test): 0.35884690284729004\n",
      "Epoch 210/1000: L(Train): 0.357500821352005; L(Test): 0.35845252871513367\n",
      "Epoch 211/1000: L(Train): 0.3553750216960907; L(Test): 0.35806185007095337\n",
      "Epoch 212/1000: L(Train): 0.35896405577659607; L(Test): 0.3576756715774536\n",
      "Epoch 213/1000: L(Train): 0.3570634126663208; L(Test): 0.35729411244392395\n",
      "Epoch 214/1000: L(Train): 0.35759711265563965; L(Test): 0.35691675543785095\n",
      "Epoch 215/1000: L(Train): 0.3548424541950226; L(Test): 0.35654306411743164\n",
      "Epoch 216/1000: L(Train): 0.35689038038253784; L(Test): 0.3561733663082123\n",
      "Epoch 217/1000: L(Train): 0.35444700717926025; L(Test): 0.35580694675445557\n",
      "Epoch 218/1000: L(Train): 0.3571511209011078; L(Test): 0.3554452657699585\n",
      "Epoch 219/1000: L(Train): 0.35532787442207336; L(Test): 0.35508742928504944\n",
      "Epoch 220/1000: L(Train): 0.3565944731235504; L(Test): 0.3547337055206299\n",
      "Epoch 221/1000: L(Train): 0.3556481599807739; L(Test): 0.3543839752674103\n",
      "Epoch 222/1000: L(Train): 0.3556497097015381; L(Test): 0.35403817892074585\n",
      "Epoch 223/1000: L(Train): 0.355923593044281; L(Test): 0.35369569063186646\n",
      "Epoch 224/1000: L(Train): 0.35599032044410706; L(Test): 0.35335689783096313\n",
      "Epoch 225/1000: L(Train): 0.3555983603000641; L(Test): 0.35302236676216125\n",
      "Epoch 226/1000: L(Train): 0.3509577810764313; L(Test): 0.35269084572792053\n",
      "Epoch 227/1000: L(Train): 0.35337749123573303; L(Test): 0.3523625135421753\n",
      "Epoch 228/1000: L(Train): 0.35231995582580566; L(Test): 0.3520375192165375\n",
      "Epoch 229/1000: L(Train): 0.3515492081642151; L(Test): 0.35171595215797424\n",
      "Epoch 230/1000: L(Train): 0.3538404107093811; L(Test): 0.3513978123664856\n",
      "Epoch 231/1000: L(Train): 0.3495214283466339; L(Test): 0.35108259320259094\n",
      "Epoch 232/1000: L(Train): 0.3561999797821045; L(Test): 0.35077157616615295\n",
      "Epoch 233/1000: L(Train): 0.3515247106552124; L(Test): 0.3504638969898224\n",
      "Epoch 234/1000: L(Train): 0.35108324885368347; L(Test): 0.350159615278244\n",
      "Epoch 235/1000: L(Train): 0.34967464208602905; L(Test): 0.3498586118221283\n",
      "Epoch 236/1000: L(Train): 0.34994497895240784; L(Test): 0.34956005215644836\n",
      "Epoch 237/1000: L(Train): 0.35105761885643005; L(Test): 0.349264532327652\n",
      "Epoch 238/1000: L(Train): 0.34693625569343567; L(Test): 0.34897103905677795\n",
      "Epoch 239/1000: L(Train): 0.3502373993396759; L(Test): 0.348680317401886\n",
      "Epoch 240/1000: L(Train): 0.3450835943222046; L(Test): 0.34839165210723877\n",
      "Epoch 241/1000: L(Train): 0.3463301956653595; L(Test): 0.3481055796146393\n",
      "Epoch 242/1000: L(Train): 0.3495059907436371; L(Test): 0.34782296419143677\n",
      "Epoch 243/1000: L(Train): 0.34596434235572815; L(Test): 0.3475428819656372\n",
      "Epoch 244/1000: L(Train): 0.3466634750366211; L(Test): 0.34726589918136597\n",
      "Epoch 245/1000: L(Train): 0.34722939133644104; L(Test): 0.3469918668270111\n",
      "Epoch 246/1000: L(Train): 0.3443942070007324; L(Test): 0.34672021865844727\n",
      "Epoch 247/1000: L(Train): 0.34316185116767883; L(Test): 0.3464505672454834\n",
      "Epoch 248/1000: L(Train): 0.3462326228618622; L(Test): 0.34618374705314636\n",
      "Epoch 249/1000: L(Train): 0.3475340008735657; L(Test): 0.3459196388721466\n",
      "Epoch 250/1000: L(Train): 0.34426575899124146; L(Test): 0.3456578254699707\n",
      "Epoch 251/1000: L(Train): 0.3432222604751587; L(Test): 0.34539857506752014\n",
      "Epoch 252/1000: L(Train): 0.34586042165756226; L(Test): 0.34514203667640686\n",
      "Epoch 253/1000: L(Train): 0.34697431325912476; L(Test): 0.34488818049430847\n",
      "Epoch 254/1000: L(Train): 0.3453241288661957; L(Test): 0.34463658928871155\n",
      "Epoch 255/1000: L(Train): 0.3448653817176819; L(Test): 0.344387412071228\n",
      "Epoch 256/1000: L(Train): 0.34352561831474304; L(Test): 0.3441409468650818\n",
      "Epoch 257/1000: L(Train): 0.34226274490356445; L(Test): 0.34389665722846985\n",
      "Epoch 258/1000: L(Train): 0.340168833732605; L(Test): 0.34365418553352356\n",
      "Epoch 259/1000: L(Train): 0.33957985043525696; L(Test): 0.34341296553611755\n",
      "Epoch 260/1000: L(Train): 0.34331056475639343; L(Test): 0.3431742787361145\n",
      "Epoch 261/1000: L(Train): 0.3451841175556183; L(Test): 0.34293854236602783\n",
      "Epoch 262/1000: L(Train): 0.3452194333076477; L(Test): 0.3427055776119232\n",
      "Epoch 263/1000: L(Train): 0.34367635846138; L(Test): 0.34247544407844543\n",
      "Epoch 264/1000: L(Train): 0.34278473258018494; L(Test): 0.3422476053237915\n",
      "Epoch 265/1000: L(Train): 0.34553995728492737; L(Test): 0.3420223891735077\n",
      "Epoch 266/1000: L(Train): 0.34229713678359985; L(Test): 0.3417992889881134\n",
      "Epoch 267/1000: L(Train): 0.33938145637512207; L(Test): 0.34157758951187134\n",
      "Epoch 268/1000: L(Train): 0.3400139808654785; L(Test): 0.3413577377796173\n",
      "Epoch 269/1000: L(Train): 0.3404391407966614; L(Test): 0.34114015102386475\n",
      "Epoch 270/1000: L(Train): 0.3406992256641388; L(Test): 0.34092432260513306\n",
      "Epoch 271/1000: L(Train): 0.3418784737586975; L(Test): 0.34071052074432373\n",
      "Epoch 272/1000: L(Train): 0.3431640565395355; L(Test): 0.34049907326698303\n",
      "Epoch 273/1000: L(Train): 0.3432299792766571; L(Test): 0.3402895927429199\n",
      "Epoch 274/1000: L(Train): 0.33776068687438965; L(Test): 0.3400816321372986\n",
      "Epoch 275/1000: L(Train): 0.33950749039649963; L(Test): 0.3398754596710205\n",
      "Epoch 276/1000: L(Train): 0.3426736295223236; L(Test): 0.3396710753440857\n",
      "Epoch 277/1000: L(Train): 0.3372044563293457; L(Test): 0.33946824073791504\n",
      "Epoch 278/1000: L(Train): 0.3394348919391632; L(Test): 0.3392672538757324\n",
      "Epoch 279/1000: L(Train): 0.33605432510375977; L(Test): 0.3390676975250244\n",
      "Epoch 280/1000: L(Train): 0.3373347818851471; L(Test): 0.3388698101043701\n",
      "Epoch 281/1000: L(Train): 0.34364578127861023; L(Test): 0.3386746942996979\n",
      "Epoch 282/1000: L(Train): 0.33771538734436035; L(Test): 0.3384811282157898\n",
      "Epoch 283/1000: L(Train): 0.3369626998901367; L(Test): 0.3382892310619354\n",
      "Epoch 284/1000: L(Train): 0.34015926718711853; L(Test): 0.3380992114543915\n",
      "Epoch 285/1000: L(Train): 0.33834102749824524; L(Test): 0.3379109799861908\n",
      "Epoch 286/1000: L(Train): 0.3381258547306061; L(Test): 0.3377242684364319\n",
      "Epoch 287/1000: L(Train): 0.3353138566017151; L(Test): 0.33753880858421326\n",
      "Epoch 288/1000: L(Train): 0.3385085165500641; L(Test): 0.3373549282550812\n",
      "Epoch 289/1000: L(Train): 0.33668896555900574; L(Test): 0.3371727764606476\n",
      "Epoch 290/1000: L(Train): 0.3365534543991089; L(Test): 0.33699125051498413\n",
      "Epoch 291/1000: L(Train): 0.3356263339519501; L(Test): 0.3368109166622162\n",
      "Epoch 292/1000: L(Train): 0.33649930357933044; L(Test): 0.3366314172744751\n",
      "Epoch 293/1000: L(Train): 0.3362348973751068; L(Test): 0.3364536464214325\n",
      "Epoch 294/1000: L(Train): 0.3346118927001953; L(Test): 0.3362772464752197\n",
      "Epoch 295/1000: L(Train): 0.33719879388809204; L(Test): 0.33610236644744873\n",
      "Epoch 296/1000: L(Train): 0.335311621427536; L(Test): 0.33592838048934937\n",
      "Epoch 297/1000: L(Train): 0.33635658025741577; L(Test): 0.33575594425201416\n",
      "Epoch 298/1000: L(Train): 0.33552125096321106; L(Test): 0.3355846703052521\n",
      "Epoch 299/1000: L(Train): 0.3370095491409302; L(Test): 0.3354146182537079\n",
      "Epoch 300/1000: L(Train): 0.3339012861251831; L(Test): 0.3352459669113159\n",
      "Epoch 301/1000: L(Train): 0.33435165882110596; L(Test): 0.33507829904556274\n",
      "Epoch 302/1000: L(Train): 0.33432042598724365; L(Test): 0.33491218090057373\n",
      "Epoch 303/1000: L(Train): 0.33649900555610657; L(Test): 0.33474743366241455\n",
      "Epoch 304/1000: L(Train): 0.3322787284851074; L(Test): 0.33458372950553894\n",
      "Epoch 305/1000: L(Train): 0.3311535120010376; L(Test): 0.3344210982322693\n",
      "Epoch 306/1000: L(Train): 0.333267480134964; L(Test): 0.3342598080635071\n",
      "Epoch 307/1000: L(Train): 0.3363357484340668; L(Test): 0.3341001868247986\n",
      "Epoch 308/1000: L(Train): 0.33448508381843567; L(Test): 0.33394163846969604\n",
      "Epoch 309/1000: L(Train): 0.3311399519443512; L(Test): 0.33378446102142334\n",
      "Epoch 310/1000: L(Train): 0.3344784677028656; L(Test): 0.3336282968521118\n",
      "Epoch 311/1000: L(Train): 0.333603173494339; L(Test): 0.3334732949733734\n",
      "Epoch 312/1000: L(Train): 0.33307337760925293; L(Test): 0.33331960439682007\n",
      "Epoch 313/1000: L(Train): 0.3329371213912964; L(Test): 0.3331671357154846\n",
      "Epoch 314/1000: L(Train): 0.33533787727355957; L(Test): 0.3330155611038208\n",
      "Epoch 315/1000: L(Train): 0.33239278197288513; L(Test): 0.33286532759666443\n",
      "Epoch 316/1000: L(Train): 0.33315449953079224; L(Test): 0.3327164351940155\n",
      "Epoch 317/1000: L(Train): 0.33536064624786377; L(Test): 0.3325686454772949\n",
      "Epoch 318/1000: L(Train): 0.3306545615196228; L(Test): 0.3324219584465027\n",
      "Epoch 319/1000: L(Train): 0.3351065218448639; L(Test): 0.3322770893573761\n",
      "Epoch 320/1000: L(Train): 0.3320004642009735; L(Test): 0.3321336507797241\n",
      "Epoch 321/1000: L(Train): 0.3307083249092102; L(Test): 0.3319910764694214\n",
      "Epoch 322/1000: L(Train): 0.32737720012664795; L(Test): 0.331849068403244\n",
      "Epoch 323/1000: L(Train): 0.3335934281349182; L(Test): 0.33170878887176514\n",
      "Epoch 324/1000: L(Train): 0.33244603872299194; L(Test): 0.3315691649913788\n",
      "Epoch 325/1000: L(Train): 0.3317187428474426; L(Test): 0.3314305245876312\n",
      "Epoch 326/1000: L(Train): 0.32938718795776367; L(Test): 0.33129239082336426\n",
      "Epoch 327/1000: L(Train): 0.33391156792640686; L(Test): 0.33115583658218384\n",
      "Epoch 328/1000: L(Train): 0.3283458650112152; L(Test): 0.33101996779441833\n",
      "Epoch 329/1000: L(Train): 0.3335522711277008; L(Test): 0.3308853507041931\n",
      "Epoch 330/1000: L(Train): 0.33223801851272583; L(Test): 0.3307517170906067\n",
      "Epoch 331/1000: L(Train): 0.3329163193702698; L(Test): 0.33061888813972473\n",
      "Epoch 332/1000: L(Train): 0.33015966415405273; L(Test): 0.33048680424690247\n",
      "Epoch 333/1000: L(Train): 0.32880446314811707; L(Test): 0.33035585284233093\n",
      "Epoch 334/1000: L(Train): 0.3313044607639313; L(Test): 0.33022600412368774\n",
      "Epoch 335/1000: L(Train): 0.32936426997184753; L(Test): 0.3300970494747162\n",
      "Epoch 336/1000: L(Train): 0.33231422305107117; L(Test): 0.32996901869773865\n",
      "Epoch 337/1000: L(Train): 0.331419438123703; L(Test): 0.32984206080436707\n",
      "Epoch 338/1000: L(Train): 0.3258887827396393; L(Test): 0.32971569895744324\n",
      "Epoch 339/1000: L(Train): 0.3281879723072052; L(Test): 0.3295900821685791\n",
      "Epoch 340/1000: L(Train): 0.3321631848812103; L(Test): 0.3294656276702881\n",
      "Epoch 341/1000: L(Train): 0.32651129364967346; L(Test): 0.3293418884277344\n",
      "Epoch 342/1000: L(Train): 0.33057454228401184; L(Test): 0.32921937108039856\n",
      "Epoch 343/1000: L(Train): 0.33167004585266113; L(Test): 0.3290979564189911\n",
      "Epoch 344/1000: L(Train): 0.3263157904148102; L(Test): 0.32897669076919556\n",
      "Epoch 345/1000: L(Train): 0.3273128867149353; L(Test): 0.32885634899139404\n",
      "Epoch 346/1000: L(Train): 0.3267240822315216; L(Test): 0.3287367820739746\n",
      "Epoch 347/1000: L(Train): 0.3269425630569458; L(Test): 0.32861778140068054\n",
      "Epoch 348/1000: L(Train): 0.33165794610977173; L(Test): 0.32850003242492676\n",
      "Epoch 349/1000: L(Train): 0.3259139657020569; L(Test): 0.3283831775188446\n",
      "Epoch 350/1000: L(Train): 0.32719001173973083; L(Test): 0.3282669186592102\n",
      "Epoch 351/1000: L(Train): 0.32970893383026123; L(Test): 0.3281513452529907\n",
      "Epoch 352/1000: L(Train): 0.32884636521339417; L(Test): 0.3280367851257324\n",
      "Epoch 353/1000: L(Train): 0.3294046223163605; L(Test): 0.32792308926582336\n",
      "Epoch 354/1000: L(Train): 0.3302910327911377; L(Test): 0.3278101682662964\n",
      "Epoch 355/1000: L(Train): 0.32757750153541565; L(Test): 0.32769790291786194\n",
      "Epoch 356/1000: L(Train): 0.32439547777175903; L(Test): 0.32758596539497375\n",
      "Epoch 357/1000: L(Train): 0.32635214924812317; L(Test): 0.32747477293014526\n",
      "Epoch 358/1000: L(Train): 0.3293849527835846; L(Test): 0.32736465334892273\n",
      "Epoch 359/1000: L(Train): 0.3261192739009857; L(Test): 0.3272553086280823\n",
      "Epoch 360/1000: L(Train): 0.32613709568977356; L(Test): 0.32714635133743286\n",
      "Epoch 361/1000: L(Train): 0.322775274515152; L(Test): 0.3270378112792969\n",
      "Epoch 362/1000: L(Train): 0.3243585526943207; L(Test): 0.3269299864768982\n",
      "Epoch 363/1000: L(Train): 0.3285757005214691; L(Test): 0.3268227279186249\n",
      "Epoch 364/1000: L(Train): 0.3269525468349457; L(Test): 0.3267163336277008\n",
      "Epoch 365/1000: L(Train): 0.32660043239593506; L(Test): 0.3266105353832245\n",
      "Epoch 366/1000: L(Train): 0.3248954713344574; L(Test): 0.32650554180145264\n",
      "Epoch 367/1000: L(Train): 0.3243081569671631; L(Test): 0.3264012336730957\n",
      "Epoch 368/1000: L(Train): 0.32321277260780334; L(Test): 0.32629847526550293\n",
      "Epoch 369/1000: L(Train): 0.3271670937538147; L(Test): 0.3261968791484833\n",
      "Epoch 370/1000: L(Train): 0.32210683822631836; L(Test): 0.3260956108570099\n",
      "Epoch 371/1000: L(Train): 0.3262719511985779; L(Test): 0.3259950876235962\n",
      "Epoch 372/1000: L(Train): 0.3252544403076172; L(Test): 0.32589539885520935\n",
      "Epoch 373/1000: L(Train): 0.32391199469566345; L(Test): 0.3257963955402374\n",
      "Epoch 374/1000: L(Train): 0.32829219102859497; L(Test): 0.32569795846939087\n",
      "Epoch 375/1000: L(Train): 0.32666078209877014; L(Test): 0.3256002962589264\n",
      "Epoch 376/1000: L(Train): 0.324517160654068; L(Test): 0.3255036771297455\n",
      "Epoch 377/1000: L(Train): 0.33009612560272217; L(Test): 0.3254079222679138\n",
      "Epoch 378/1000: L(Train): 0.3295691907405853; L(Test): 0.3253130614757538\n",
      "Epoch 379/1000: L(Train): 0.32588306069374084; L(Test): 0.32521888613700867\n",
      "Epoch 380/1000: L(Train): 0.32722073793411255; L(Test): 0.32512563467025757\n",
      "Epoch 381/1000: L(Train): 0.32725149393081665; L(Test): 0.32503318786621094\n",
      "Epoch 382/1000: L(Train): 0.32285353541374207; L(Test): 0.32494160532951355\n",
      "Epoch 383/1000: L(Train): 0.326823353767395; L(Test): 0.32485076785087585\n",
      "Epoch 384/1000: L(Train): 0.32538431882858276; L(Test): 0.3247600793838501\n",
      "Epoch 385/1000: L(Train): 0.3241996467113495; L(Test): 0.3246699571609497\n",
      "Epoch 386/1000: L(Train): 0.3255036175251007; L(Test): 0.3245804011821747\n",
      "Epoch 387/1000: L(Train): 0.3271792232990265; L(Test): 0.32449135184288025\n",
      "Epoch 388/1000: L(Train): 0.32601213455200195; L(Test): 0.3244028687477112\n",
      "Epoch 389/1000: L(Train): 0.324199378490448; L(Test): 0.32431504130363464\n",
      "Epoch 390/1000: L(Train): 0.3247925341129303; L(Test): 0.324227511882782\n",
      "Epoch 391/1000: L(Train): 0.32686352729797363; L(Test): 0.3241405189037323\n",
      "Epoch 392/1000: L(Train): 0.32356077432632446; L(Test): 0.32405415177345276\n",
      "Epoch 393/1000: L(Train): 0.324556440114975; L(Test): 0.3239685893058777\n",
      "Epoch 394/1000: L(Train): 0.3227541148662567; L(Test): 0.3238837420940399\n",
      "Epoch 395/1000: L(Train): 0.32313960790634155; L(Test): 0.3237994313240051\n",
      "Epoch 396/1000: L(Train): 0.3239680826663971; L(Test): 0.3237157166004181\n",
      "Epoch 397/1000: L(Train): 0.3202255368232727; L(Test): 0.32363179326057434\n",
      "Epoch 398/1000: L(Train): 0.3234511911869049; L(Test): 0.3235485851764679\n",
      "Epoch 399/1000: L(Train): 0.32651057839393616; L(Test): 0.3234664797782898\n",
      "Epoch 400/1000: L(Train): 0.32343026995658875; L(Test): 0.3233850598335266\n",
      "Epoch 401/1000: L(Train): 0.32663899660110474; L(Test): 0.3233044743537903\n",
      "Epoch 402/1000: L(Train): 0.32257649302482605; L(Test): 0.32322460412979126\n",
      "Epoch 403/1000: L(Train): 0.326446533203125; L(Test): 0.32314541935920715\n",
      "Epoch 404/1000: L(Train): 0.32339364290237427; L(Test): 0.3230665624141693\n",
      "Epoch 405/1000: L(Train): 0.3215975761413574; L(Test): 0.3229883313179016\n",
      "Epoch 406/1000: L(Train): 0.3237091898918152; L(Test): 0.32291072607040405\n",
      "Epoch 407/1000: L(Train): 0.3253113925457001; L(Test): 0.32283350825309753\n",
      "Epoch 408/1000: L(Train): 0.3254026770591736; L(Test): 0.32275664806365967\n",
      "Epoch 409/1000: L(Train): 0.3230365812778473; L(Test): 0.3226802945137024\n",
      "Epoch 410/1000: L(Train): 0.32429876923561096; L(Test): 0.32260432839393616\n",
      "Epoch 411/1000: L(Train): 0.3215641379356384; L(Test): 0.32252898812294006\n",
      "Epoch 412/1000: L(Train): 0.320363849401474; L(Test): 0.32245418429374695\n",
      "Epoch 413/1000: L(Train): 0.3239184617996216; L(Test): 0.3223799467086792\n",
      "Epoch 414/1000: L(Train): 0.3230500817298889; L(Test): 0.3223065733909607\n",
      "Epoch 415/1000: L(Train): 0.32314532995224; L(Test): 0.322233647108078\n",
      "Epoch 416/1000: L(Train): 0.32125377655029297; L(Test): 0.32216089963912964\n",
      "Epoch 417/1000: L(Train): 0.32108837366104126; L(Test): 0.3220883309841156\n",
      "Epoch 418/1000: L(Train): 0.3230617940425873; L(Test): 0.32201629877090454\n",
      "Epoch 419/1000: L(Train): 0.3211226761341095; L(Test): 0.3219444453716278\n",
      "Epoch 420/1000: L(Train): 0.32492610812187195; L(Test): 0.3218729794025421\n",
      "Epoch 421/1000: L(Train): 0.322516530752182; L(Test): 0.321802020072937\n",
      "Epoch 422/1000: L(Train): 0.32397782802581787; L(Test): 0.3217316269874573\n",
      "Epoch 423/1000: L(Train): 0.3190852999687195; L(Test): 0.32166165113449097\n",
      "Epoch 424/1000: L(Train): 0.32228219509124756; L(Test): 0.3215920925140381\n",
      "Epoch 425/1000: L(Train): 0.31985655426979065; L(Test): 0.32152286171913147\n",
      "Epoch 426/1000: L(Train): 0.3188819885253906; L(Test): 0.32145363092422485\n",
      "Epoch 427/1000: L(Train): 0.3227880895137787; L(Test): 0.32138487696647644\n",
      "Epoch 428/1000: L(Train): 0.3235052227973938; L(Test): 0.3213167190551758\n",
      "Epoch 429/1000: L(Train): 0.3181976079940796; L(Test): 0.3212489187717438\n",
      "Epoch 430/1000: L(Train): 0.3233032822608948; L(Test): 0.32118144631385803\n",
      "Epoch 431/1000: L(Train): 0.32104256749153137; L(Test): 0.3211143910884857\n",
      "Epoch 432/1000: L(Train): 0.32323211431503296; L(Test): 0.32104790210723877\n",
      "Epoch 433/1000: L(Train): 0.3191848695278168; L(Test): 0.320981502532959\n",
      "Epoch 434/1000: L(Train): 0.32157596945762634; L(Test): 0.3209156095981598\n",
      "Epoch 435/1000: L(Train): 0.3217225968837738; L(Test): 0.3208499848842621\n",
      "Epoch 436/1000: L(Train): 0.32054856419563293; L(Test): 0.32078462839126587\n",
      "Epoch 437/1000: L(Train): 0.31923675537109375; L(Test): 0.3207195997238159\n",
      "Epoch 438/1000: L(Train): 0.3156682550907135; L(Test): 0.32065457105636597\n",
      "Epoch 439/1000: L(Train): 0.32012999057769775; L(Test): 0.3205901086330414\n",
      "Epoch 440/1000: L(Train): 0.31971102952957153; L(Test): 0.3205258548259735\n",
      "Epoch 441/1000: L(Train): 0.3189367651939392; L(Test): 0.3204619586467743\n",
      "Epoch 442/1000: L(Train): 0.3161664605140686; L(Test): 0.3203984498977661\n",
      "Epoch 443/1000: L(Train): 0.32018667459487915; L(Test): 0.3203352391719818\n",
      "Epoch 444/1000: L(Train): 0.32341521978378296; L(Test): 0.3202725350856781\n",
      "Epoch 445/1000: L(Train): 0.3206557035446167; L(Test): 0.3202100992202759\n",
      "Epoch 446/1000: L(Train): 0.3227972388267517; L(Test): 0.3201479911804199\n",
      "Epoch 447/1000: L(Train): 0.32036101818084717; L(Test): 0.3200863301753998\n",
      "Epoch 448/1000: L(Train): 0.31997358798980713; L(Test): 0.32002514600753784\n",
      "Epoch 449/1000: L(Train): 0.32000499963760376; L(Test): 0.3199642598628998\n",
      "Epoch 450/1000: L(Train): 0.318817138671875; L(Test): 0.3199034333229065\n",
      "Epoch 451/1000: L(Train): 0.32038626074790955; L(Test): 0.3198430836200714\n",
      "Epoch 452/1000: L(Train): 0.3224569857120514; L(Test): 0.319783091545105\n",
      "Epoch 453/1000: L(Train): 0.31787246465682983; L(Test): 0.31972354650497437\n",
      "Epoch 454/1000: L(Train): 0.31546586751937866; L(Test): 0.3196641802787781\n",
      "Epoch 455/1000: L(Train): 0.31855037808418274; L(Test): 0.31960543990135193\n",
      "Epoch 456/1000: L(Train): 0.3175966739654541; L(Test): 0.31954705715179443\n",
      "Epoch 457/1000: L(Train): 0.3181159198284149; L(Test): 0.3194889724254608\n",
      "Epoch 458/1000: L(Train): 0.31942328810691833; L(Test): 0.3194313645362854\n",
      "Epoch 459/1000: L(Train): 0.319963663816452; L(Test): 0.319374144077301\n",
      "Epoch 460/1000: L(Train): 0.32262638211250305; L(Test): 0.31931713223457336\n",
      "Epoch 461/1000: L(Train): 0.32167723774909973; L(Test): 0.3192604184150696\n",
      "Epoch 462/1000: L(Train): 0.3142376244068146; L(Test): 0.319203644990921\n",
      "Epoch 463/1000: L(Train): 0.32068750262260437; L(Test): 0.3191471993923187\n",
      "Epoch 464/1000: L(Train): 0.32377365231513977; L(Test): 0.31909140944480896\n",
      "Epoch 465/1000: L(Train): 0.31899917125701904; L(Test): 0.31903567910194397\n",
      "Epoch 466/1000: L(Train): 0.3171599209308624; L(Test): 0.31898030638694763\n",
      "Epoch 467/1000: L(Train): 0.3215601444244385; L(Test): 0.3189252018928528\n",
      "Epoch 468/1000: L(Train): 0.3221905529499054; L(Test): 0.31887057423591614\n",
      "Epoch 469/1000: L(Train): 0.32112887501716614; L(Test): 0.31881624460220337\n",
      "Epoch 470/1000: L(Train): 0.320011168718338; L(Test): 0.31876206398010254\n",
      "Epoch 471/1000: L(Train): 0.318353533744812; L(Test): 0.31870830059051514\n",
      "Epoch 472/1000: L(Train): 0.3168703615665436; L(Test): 0.31865447759628296\n",
      "Epoch 473/1000: L(Train): 0.322919100522995; L(Test): 0.31860092282295227\n",
      "Epoch 474/1000: L(Train): 0.3174031376838684; L(Test): 0.3185475766658783\n",
      "Epoch 475/1000: L(Train): 0.31887444853782654; L(Test): 0.3184944987297058\n",
      "Epoch 476/1000: L(Train): 0.32085537910461426; L(Test): 0.31844162940979004\n",
      "Epoch 477/1000: L(Train): 0.3206416368484497; L(Test): 0.31838902831077576\n",
      "Epoch 478/1000: L(Train): 0.31806179881095886; L(Test): 0.3183368444442749\n",
      "Epoch 479/1000: L(Train): 0.31445205211639404; L(Test): 0.3182847499847412\n",
      "Epoch 480/1000: L(Train): 0.3200182020664215; L(Test): 0.3182329535484314\n",
      "Epoch 481/1000: L(Train): 0.31759998202323914; L(Test): 0.3181813359260559\n",
      "Epoch 482/1000: L(Train): 0.321444034576416; L(Test): 0.31813010573387146\n",
      "Epoch 483/1000: L(Train): 0.31736090779304504; L(Test): 0.31807941198349\n",
      "Epoch 484/1000: L(Train): 0.3199710547924042; L(Test): 0.31802889704704285\n",
      "Epoch 485/1000: L(Train): 0.3138357996940613; L(Test): 0.31797879934310913\n",
      "Epoch 486/1000: L(Train): 0.31684479117393494; L(Test): 0.31792888045310974\n",
      "Epoch 487/1000: L(Train): 0.3175966441631317; L(Test): 0.31787925958633423\n",
      "Epoch 488/1000: L(Train): 0.3177323043346405; L(Test): 0.31783005595207214\n",
      "Epoch 489/1000: L(Train): 0.3159680664539337; L(Test): 0.3177811801433563\n",
      "Epoch 490/1000: L(Train): 0.32239729166030884; L(Test): 0.31773248314857483\n",
      "Epoch 491/1000: L(Train): 0.32051190733909607; L(Test): 0.31768396496772766\n",
      "Epoch 492/1000: L(Train): 0.3178112208843231; L(Test): 0.31763577461242676\n",
      "Epoch 493/1000: L(Train): 0.31227943301200867; L(Test): 0.31758782267570496\n",
      "Epoch 494/1000: L(Train): 0.3187468349933624; L(Test): 0.3175399899482727\n",
      "Epoch 495/1000: L(Train): 0.31521210074424744; L(Test): 0.31749215722084045\n",
      "Epoch 496/1000: L(Train): 0.32110971212387085; L(Test): 0.3174446225166321\n",
      "Epoch 497/1000: L(Train): 0.31711000204086304; L(Test): 0.3173973262310028\n",
      "Epoch 498/1000: L(Train): 0.3133423328399658; L(Test): 0.3173500895500183\n",
      "Epoch 499/1000: L(Train): 0.3187218904495239; L(Test): 0.3173031210899353\n",
      "Epoch 500/1000: L(Train): 0.315162718296051; L(Test): 0.31725645065307617\n",
      "Epoch 501/1000: L(Train): 0.31293007731437683; L(Test): 0.31720978021621704\n",
      "Epoch 502/1000: L(Train): 0.3165219724178314; L(Test): 0.31716325879096985\n",
      "Epoch 503/1000: L(Train): 0.3197053074836731; L(Test): 0.3171170651912689\n",
      "Epoch 504/1000: L(Train): 0.31821951270103455; L(Test): 0.317070871591568\n",
      "Epoch 505/1000: L(Train): 0.31752416491508484; L(Test): 0.31702515482902527\n",
      "Epoch 506/1000: L(Train): 0.31453239917755127; L(Test): 0.31697922945022583\n",
      "Epoch 507/1000: L(Train): 0.31721749901771545; L(Test): 0.3169335424900055\n",
      "Epoch 508/1000: L(Train): 0.31648361682891846; L(Test): 0.3168879449367523\n",
      "Epoch 509/1000: L(Train): 0.31583327054977417; L(Test): 0.31684255599975586\n",
      "Epoch 510/1000: L(Train): 0.3162895441055298; L(Test): 0.3167974650859833\n",
      "Epoch 511/1000: L(Train): 0.3132426142692566; L(Test): 0.3167526423931122\n",
      "Epoch 512/1000: L(Train): 0.31509870290756226; L(Test): 0.316707968711853\n",
      "Epoch 513/1000: L(Train): 0.31751906871795654; L(Test): 0.31666362285614014\n",
      "Epoch 514/1000: L(Train): 0.3158162534236908; L(Test): 0.3166193664073944\n",
      "Epoch 515/1000: L(Train): 0.3137693703174591; L(Test): 0.31657516956329346\n",
      "Epoch 516/1000: L(Train): 0.31561484932899475; L(Test): 0.3165311813354492\n",
      "Epoch 517/1000: L(Train): 0.31687992811203003; L(Test): 0.3164873421192169\n",
      "Epoch 518/1000: L(Train): 0.31649088859558105; L(Test): 0.31644371151924133\n",
      "Epoch 519/1000: L(Train): 0.31469425559043884; L(Test): 0.31640031933784485\n",
      "Epoch 520/1000: L(Train): 0.3157229721546173; L(Test): 0.31635719537734985\n",
      "Epoch 521/1000: L(Train): 0.31519749760627747; L(Test): 0.316314160823822\n",
      "Epoch 522/1000: L(Train): 0.3149261474609375; L(Test): 0.3162713348865509\n",
      "Epoch 523/1000: L(Train): 0.3158775568008423; L(Test): 0.3162287771701813\n",
      "Epoch 524/1000: L(Train): 0.3126286268234253; L(Test): 0.31618642807006836\n",
      "Epoch 525/1000: L(Train): 0.31842219829559326; L(Test): 0.31614431738853455\n",
      "Epoch 526/1000: L(Train): 0.31766802072525024; L(Test): 0.3161025047302246\n",
      "Epoch 527/1000: L(Train): 0.31670868396759033; L(Test): 0.3160611391067505\n",
      "Epoch 528/1000: L(Train): 0.31694984436035156; L(Test): 0.31602001190185547\n",
      "Epoch 529/1000: L(Train): 0.3146306872367859; L(Test): 0.3159787952899933\n",
      "Epoch 530/1000: L(Train): 0.3189704716205597; L(Test): 0.3159377872943878\n",
      "Epoch 531/1000: L(Train): 0.3190087378025055; L(Test): 0.31589677929878235\n",
      "Epoch 532/1000: L(Train): 0.31654229760169983; L(Test): 0.31585603952407837\n",
      "Epoch 533/1000: L(Train): 0.31243085861206055; L(Test): 0.3158152997493744\n",
      "Epoch 534/1000: L(Train): 0.31181788444519043; L(Test): 0.31577491760253906\n",
      "Epoch 535/1000: L(Train): 0.31493309140205383; L(Test): 0.3157348334789276\n",
      "Epoch 536/1000: L(Train): 0.31550949811935425; L(Test): 0.3156951069831848\n",
      "Epoch 537/1000: L(Train): 0.3169828951358795; L(Test): 0.3156557083129883\n",
      "Epoch 538/1000: L(Train): 0.3162955045700073; L(Test): 0.3156163990497589\n",
      "Epoch 539/1000: L(Train): 0.31525346636772156; L(Test): 0.3155771493911743\n",
      "Epoch 540/1000: L(Train): 0.3200781047344208; L(Test): 0.3155381679534912\n",
      "Epoch 541/1000: L(Train): 0.3167172372341156; L(Test): 0.3154991567134857\n",
      "Epoch 542/1000: L(Train): 0.31847554445266724; L(Test): 0.31546008586883545\n",
      "Epoch 543/1000: L(Train): 0.31246325373649597; L(Test): 0.31542131304740906\n",
      "Epoch 544/1000: L(Train): 0.31648993492126465; L(Test): 0.31538262963294983\n",
      "Epoch 545/1000: L(Train): 0.31347227096557617; L(Test): 0.3153437674045563\n",
      "Epoch 546/1000: L(Train): 0.319217711687088; L(Test): 0.3153049051761627\n",
      "Epoch 547/1000: L(Train): 0.3140023946762085; L(Test): 0.31526613235473633\n",
      "Epoch 548/1000: L(Train): 0.314003586769104; L(Test): 0.3152276575565338\n",
      "Epoch 549/1000: L(Train): 0.31575170159339905; L(Test): 0.315189391374588\n",
      "Epoch 550/1000: L(Train): 0.3171725571155548; L(Test): 0.3151512145996094\n",
      "Epoch 551/1000: L(Train): 0.31259626150131226; L(Test): 0.3151131272315979\n",
      "Epoch 552/1000: L(Train): 0.31194067001342773; L(Test): 0.31507524847984314\n",
      "Epoch 553/1000: L(Train): 0.3102971017360687; L(Test): 0.3150375485420227\n",
      "Epoch 554/1000: L(Train): 0.3160738945007324; L(Test): 0.3149999976158142\n",
      "Epoch 555/1000: L(Train): 0.31302744150161743; L(Test): 0.3149625360965729\n",
      "Epoch 556/1000: L(Train): 0.3148740231990814; L(Test): 0.3149252235889435\n",
      "Epoch 557/1000: L(Train): 0.31674307584762573; L(Test): 0.3148881494998932\n",
      "Epoch 558/1000: L(Train): 0.31977003812789917; L(Test): 0.31485122442245483\n",
      "Epoch 559/1000: L(Train): 0.313524454832077; L(Test): 0.3148145079612732\n",
      "Epoch 560/1000: L(Train): 0.31770163774490356; L(Test): 0.31477785110473633\n",
      "Epoch 561/1000: L(Train): 0.31585392355918884; L(Test): 0.31474149227142334\n",
      "Epoch 562/1000: L(Train): 0.3121728003025055; L(Test): 0.3147050440311432\n",
      "Epoch 563/1000: L(Train): 0.3157799243927002; L(Test): 0.31466910243034363\n",
      "Epoch 564/1000: L(Train): 0.31634220480918884; L(Test): 0.31463316082954407\n",
      "Epoch 565/1000: L(Train): 0.3154768943786621; L(Test): 0.314597487449646\n",
      "Epoch 566/1000: L(Train): 0.3157205879688263; L(Test): 0.3145618438720703\n",
      "Epoch 567/1000: L(Train): 0.31659939885139465; L(Test): 0.31452620029449463\n",
      "Epoch 568/1000: L(Train): 0.3140251040458679; L(Test): 0.3144908547401428\n",
      "Epoch 569/1000: L(Train): 0.3188275098800659; L(Test): 0.3144558370113373\n",
      "Epoch 570/1000: L(Train): 0.31372973322868347; L(Test): 0.3144208788871765\n",
      "Epoch 571/1000: L(Train): 0.31688085198402405; L(Test): 0.3143858015537262\n",
      "Epoch 572/1000: L(Train): 0.3180367350578308; L(Test): 0.31435084342956543\n",
      "Epoch 573/1000: L(Train): 0.3146377503871918; L(Test): 0.314316064119339\n",
      "Epoch 574/1000: L(Train): 0.3172474205493927; L(Test): 0.31428098678588867\n",
      "Epoch 575/1000: L(Train): 0.3145045340061188; L(Test): 0.3142463266849518\n",
      "Epoch 576/1000: L(Train): 0.3123750388622284; L(Test): 0.31421181559562683\n",
      "Epoch 577/1000: L(Train): 0.31103768944740295; L(Test): 0.31417736411094666\n",
      "Epoch 578/1000: L(Train): 0.31055948138237; L(Test): 0.3141433000564575\n",
      "Epoch 579/1000: L(Train): 0.31426218152046204; L(Test): 0.3141094148159027\n",
      "Epoch 580/1000: L(Train): 0.3146803677082062; L(Test): 0.31407561898231506\n",
      "Epoch 581/1000: L(Train): 0.3162297010421753; L(Test): 0.31404176354408264\n",
      "Epoch 582/1000: L(Train): 0.3148990869522095; L(Test): 0.31400811672210693\n",
      "Epoch 583/1000: L(Train): 0.31545597314834595; L(Test): 0.3139744997024536\n",
      "Epoch 584/1000: L(Train): 0.3102762699127197; L(Test): 0.3139410614967346\n",
      "Epoch 585/1000: L(Train): 0.31671106815338135; L(Test): 0.31390753388404846\n",
      "Epoch 586/1000: L(Train): 0.31293433904647827; L(Test): 0.3138740062713623\n",
      "Epoch 587/1000: L(Train): 0.31463631987571716; L(Test): 0.3138403594493866\n",
      "Epoch 588/1000: L(Train): 0.31600072979927063; L(Test): 0.31380656361579895\n",
      "Epoch 589/1000: L(Train): 0.3166205585002899; L(Test): 0.31377294659614563\n",
      "Epoch 590/1000: L(Train): 0.31683430075645447; L(Test): 0.31373944878578186\n",
      "Epoch 591/1000: L(Train): 0.31485456228256226; L(Test): 0.3137059509754181\n",
      "Epoch 592/1000: L(Train): 0.3122422993183136; L(Test): 0.31367263197898865\n",
      "Epoch 593/1000: L(Train): 0.31451448798179626; L(Test): 0.3136395215988159\n",
      "Epoch 594/1000: L(Train): 0.3114732503890991; L(Test): 0.3136065602302551\n",
      "Epoch 595/1000: L(Train): 0.3107336163520813; L(Test): 0.31357356905937195\n",
      "Epoch 596/1000: L(Train): 0.3130165934562683; L(Test): 0.3135407269001007\n",
      "Epoch 597/1000: L(Train): 0.3149881958961487; L(Test): 0.31350794434547424\n",
      "Epoch 598/1000: L(Train): 0.3134011924266815; L(Test): 0.3134753704071045\n",
      "Epoch 599/1000: L(Train): 0.3127155601978302; L(Test): 0.31344303488731384\n",
      "Epoch 600/1000: L(Train): 0.3146158456802368; L(Test): 0.3134106993675232\n",
      "Epoch 601/1000: L(Train): 0.31166017055511475; L(Test): 0.31337857246398926\n",
      "Epoch 602/1000: L(Train): 0.3117850422859192; L(Test): 0.3133464455604553\n",
      "Epoch 603/1000: L(Train): 0.31109878420829773; L(Test): 0.3133147358894348\n",
      "Epoch 604/1000: L(Train): 0.31816205382347107; L(Test): 0.3132832646369934\n",
      "Epoch 605/1000: L(Train): 0.3117322623729706; L(Test): 0.3132518529891968\n",
      "Epoch 606/1000: L(Train): 0.31397032737731934; L(Test): 0.3132205307483673\n",
      "Epoch 607/1000: L(Train): 0.3129867911338806; L(Test): 0.31318914890289307\n",
      "Epoch 608/1000: L(Train): 0.3139570951461792; L(Test): 0.31315791606903076\n",
      "Epoch 609/1000: L(Train): 0.3125484883785248; L(Test): 0.313126802444458\n",
      "Epoch 610/1000: L(Train): 0.30921033024787903; L(Test): 0.3130958676338196\n",
      "Epoch 611/1000: L(Train): 0.3137184977531433; L(Test): 0.31306514143943787\n",
      "Epoch 612/1000: L(Train): 0.3142356276512146; L(Test): 0.31303438544273376\n",
      "Epoch 613/1000: L(Train): 0.31428977847099304; L(Test): 0.31300365924835205\n",
      "Epoch 614/1000: L(Train): 0.3130800127983093; L(Test): 0.3129732608795166\n",
      "Epoch 615/1000: L(Train): 0.31359902024269104; L(Test): 0.31294289231300354\n",
      "Epoch 616/1000: L(Train): 0.314071923494339; L(Test): 0.3129127025604248\n",
      "Epoch 617/1000: L(Train): 0.30973729491233826; L(Test): 0.3128826320171356\n",
      "Epoch 618/1000: L(Train): 0.31255364418029785; L(Test): 0.31285277009010315\n",
      "Epoch 619/1000: L(Train): 0.31165915727615356; L(Test): 0.312823086977005\n",
      "Epoch 620/1000: L(Train): 0.3134573996067047; L(Test): 0.312793493270874\n",
      "Epoch 621/1000: L(Train): 0.31477150321006775; L(Test): 0.3127637803554535\n",
      "Epoch 622/1000: L(Train): 0.3122824728488922; L(Test): 0.31273436546325684\n",
      "Epoch 623/1000: L(Train): 0.3169926702976227; L(Test): 0.31270503997802734\n",
      "Epoch 624/1000: L(Train): 0.3117692768573761; L(Test): 0.3126756548881531\n",
      "Epoch 625/1000: L(Train): 0.31426629424095154; L(Test): 0.31264635920524597\n",
      "Epoch 626/1000: L(Train): 0.3166654109954834; L(Test): 0.3126169443130493\n",
      "Epoch 627/1000: L(Train): 0.3131197690963745; L(Test): 0.3125876188278198\n",
      "Epoch 628/1000: L(Train): 0.31142938137054443; L(Test): 0.31255829334259033\n",
      "Epoch 629/1000: L(Train): 0.3096761703491211; L(Test): 0.3125288486480713\n",
      "Epoch 630/1000: L(Train): 0.3151929974555969; L(Test): 0.3124995529651642\n",
      "Epoch 631/1000: L(Train): 0.31583699584007263; L(Test): 0.3124701976776123\n",
      "Epoch 632/1000: L(Train): 0.31448888778686523; L(Test): 0.3124411106109619\n",
      "Epoch 633/1000: L(Train): 0.31050753593444824; L(Test): 0.31241199374198914\n",
      "Epoch 634/1000: L(Train): 0.31376853585243225; L(Test): 0.3123829960823059\n",
      "Epoch 635/1000: L(Train): 0.3102133870124817; L(Test): 0.31235402822494507\n",
      "Epoch 636/1000: L(Train): 0.3124493956565857; L(Test): 0.3123251795768738\n",
      "Epoch 637/1000: L(Train): 0.31481584906578064; L(Test): 0.31229645013809204\n",
      "Epoch 638/1000: L(Train): 0.3116634786128998; L(Test): 0.3122677206993103\n",
      "Epoch 639/1000: L(Train): 0.31364330649375916; L(Test): 0.3122391104698181\n",
      "Epoch 640/1000: L(Train): 0.3103712499141693; L(Test): 0.31221044063568115\n",
      "Epoch 641/1000: L(Train): 0.3115217983722687; L(Test): 0.31218159198760986\n",
      "Epoch 642/1000: L(Train): 0.31128519773483276; L(Test): 0.31215280294418335\n",
      "Epoch 643/1000: L(Train): 0.3137257993221283; L(Test): 0.31212398409843445\n",
      "Epoch 644/1000: L(Train): 0.3106880187988281; L(Test): 0.31209510564804077\n",
      "Epoch 645/1000: L(Train): 0.31058984994888306; L(Test): 0.31206652522087097\n",
      "Epoch 646/1000: L(Train): 0.31285297870635986; L(Test): 0.312037855386734\n",
      "Epoch 647/1000: L(Train): 0.3133237957954407; L(Test): 0.3120090663433075\n",
      "Epoch 648/1000: L(Train): 0.31120532751083374; L(Test): 0.31198054552078247\n",
      "Epoch 649/1000: L(Train): 0.3116110861301422; L(Test): 0.311952143907547\n",
      "Epoch 650/1000: L(Train): 0.3109436631202698; L(Test): 0.311924010515213\n",
      "Epoch 651/1000: L(Train): 0.31285563111305237; L(Test): 0.3118959367275238\n",
      "Epoch 652/1000: L(Train): 0.31152814626693726; L(Test): 0.311867892742157\n",
      "Epoch 653/1000: L(Train): 0.31155744194984436; L(Test): 0.3118399679660797\n",
      "Epoch 654/1000: L(Train): 0.3115861117839813; L(Test): 0.3118121922016144\n",
      "Epoch 655/1000: L(Train): 0.31265994906425476; L(Test): 0.31178441643714905\n",
      "Epoch 656/1000: L(Train): 0.3084855377674103; L(Test): 0.3117566704750061\n",
      "Epoch 657/1000: L(Train): 0.30954304337501526; L(Test): 0.3117290735244751\n",
      "Epoch 658/1000: L(Train): 0.3124023973941803; L(Test): 0.31170153617858887\n",
      "Epoch 659/1000: L(Train): 0.3138848841190338; L(Test): 0.3116741180419922\n",
      "Epoch 660/1000: L(Train): 0.309705525636673; L(Test): 0.3116469085216522\n",
      "Epoch 661/1000: L(Train): 0.3132515847682953; L(Test): 0.31161966919898987\n",
      "Epoch 662/1000: L(Train): 0.31041666865348816; L(Test): 0.31159257888793945\n",
      "Epoch 663/1000: L(Train): 0.31462204456329346; L(Test): 0.3115656077861786\n",
      "Epoch 664/1000: L(Train): 0.31248700618743896; L(Test): 0.31153884530067444\n",
      "Epoch 665/1000: L(Train): 0.3111627697944641; L(Test): 0.3115120530128479\n",
      "Epoch 666/1000: L(Train): 0.3142109513282776; L(Test): 0.3114851415157318\n",
      "Epoch 667/1000: L(Train): 0.3085024058818817; L(Test): 0.3114582300186157\n",
      "Epoch 668/1000: L(Train): 0.3088361918926239; L(Test): 0.311431348323822\n",
      "Epoch 669/1000: L(Train): 0.3124353587627411; L(Test): 0.31140434741973877\n",
      "Epoch 670/1000: L(Train): 0.30899062752723694; L(Test): 0.3113774359226227\n",
      "Epoch 671/1000: L(Train): 0.3127496540546417; L(Test): 0.31135037541389465\n",
      "Epoch 672/1000: L(Train): 0.31129807233810425; L(Test): 0.3113234043121338\n",
      "Epoch 673/1000: L(Train): 0.3085196316242218; L(Test): 0.3112964332103729\n",
      "Epoch 674/1000: L(Train): 0.3069819211959839; L(Test): 0.3112695813179016\n",
      "Epoch 675/1000: L(Train): 0.30848029255867004; L(Test): 0.3112424612045288\n",
      "Epoch 676/1000: L(Train): 0.30845046043395996; L(Test): 0.3112155795097351\n",
      "Epoch 677/1000: L(Train): 0.3117526173591614; L(Test): 0.31118887662887573\n",
      "Epoch 678/1000: L(Train): 0.31103309988975525; L(Test): 0.3111620843410492\n",
      "Epoch 679/1000: L(Train): 0.31090670824050903; L(Test): 0.31113553047180176\n",
      "Epoch 680/1000: L(Train): 0.3132888972759247; L(Test): 0.3111089766025543\n",
      "Epoch 681/1000: L(Train): 0.3094273507595062; L(Test): 0.31108254194259644\n",
      "Epoch 682/1000: L(Train): 0.3115479648113251; L(Test): 0.31105607748031616\n",
      "Epoch 683/1000: L(Train): 0.31261828541755676; L(Test): 0.3110298216342926\n",
      "Epoch 684/1000: L(Train): 0.31478437781333923; L(Test): 0.31100383400917053\n",
      "Epoch 685/1000: L(Train): 0.31126269698143005; L(Test): 0.3109777271747589\n",
      "Epoch 686/1000: L(Train): 0.31224045157432556; L(Test): 0.31095194816589355\n",
      "Epoch 687/1000: L(Train): 0.30983734130859375; L(Test): 0.31092649698257446\n",
      "Epoch 688/1000: L(Train): 0.3098682761192322; L(Test): 0.31090089678764343\n",
      "Epoch 689/1000: L(Train): 0.31183579564094543; L(Test): 0.31087538599967957\n",
      "Epoch 690/1000: L(Train): 0.3133421838283539; L(Test): 0.3108499348163605\n",
      "Epoch 691/1000: L(Train): 0.30755048990249634; L(Test): 0.31082454323768616\n",
      "Epoch 692/1000: L(Train): 0.3110848367214203; L(Test): 0.31079941987991333\n",
      "Epoch 693/1000: L(Train): 0.3077515959739685; L(Test): 0.3107742369174957\n",
      "Epoch 694/1000: L(Train): 0.30796071887016296; L(Test): 0.3107492923736572\n",
      "Epoch 695/1000: L(Train): 0.3107188940048218; L(Test): 0.310724675655365\n",
      "Epoch 696/1000: L(Train): 0.31003865599632263; L(Test): 0.3107001483440399\n",
      "Epoch 697/1000: L(Train): 0.3102738559246063; L(Test): 0.31067559123039246\n",
      "Epoch 698/1000: L(Train): 0.3086599111557007; L(Test): 0.310651034116745\n",
      "Epoch 699/1000: L(Train): 0.30856844782829285; L(Test): 0.31062638759613037\n",
      "Epoch 700/1000: L(Train): 0.3089865446090698; L(Test): 0.3106022775173187\n",
      "Epoch 701/1000: L(Train): 0.3106224238872528; L(Test): 0.31057846546173096\n",
      "Epoch 702/1000: L(Train): 0.310852974653244; L(Test): 0.3105540871620178\n",
      "Epoch 703/1000: L(Train): 0.3080710768699646; L(Test): 0.3105296492576599\n",
      "Epoch 704/1000: L(Train): 0.31124866008758545; L(Test): 0.3105050325393677\n",
      "Epoch 705/1000: L(Train): 0.31148484349250793; L(Test): 0.31048011779785156\n",
      "Epoch 706/1000: L(Train): 0.30989596247673035; L(Test): 0.3104550540447235\n",
      "Epoch 707/1000: L(Train): 0.31084924936294556; L(Test): 0.31043002009391785\n",
      "Epoch 708/1000: L(Train): 0.3077298104763031; L(Test): 0.3104049563407898\n",
      "Epoch 709/1000: L(Train): 0.31079918146133423; L(Test): 0.3103802800178528\n",
      "Epoch 710/1000: L(Train): 0.3101600706577301; L(Test): 0.3103558421134949\n",
      "Epoch 711/1000: L(Train): 0.3118869960308075; L(Test): 0.31033140420913696\n",
      "Epoch 712/1000: L(Train): 0.3121921718120575; L(Test): 0.31030726432800293\n",
      "Epoch 713/1000: L(Train): 0.3101396858692169; L(Test): 0.31028324365615845\n",
      "Epoch 714/1000: L(Train): 0.31116607785224915; L(Test): 0.3102594017982483\n",
      "Epoch 715/1000: L(Train): 0.3080972135066986; L(Test): 0.31023597717285156\n",
      "Epoch 716/1000: L(Train): 0.3101922273635864; L(Test): 0.31021276116371155\n",
      "Epoch 717/1000: L(Train): 0.31026914715766907; L(Test): 0.31018972396850586\n",
      "Epoch 718/1000: L(Train): 0.3124067187309265; L(Test): 0.31016677618026733\n",
      "Epoch 719/1000: L(Train): 0.3108943700790405; L(Test): 0.3101438879966736\n",
      "Epoch 720/1000: L(Train): 0.31108197569847107; L(Test): 0.31012120842933655\n",
      "Epoch 721/1000: L(Train): 0.31456565856933594; L(Test): 0.3100984990596771\n",
      "Epoch 722/1000: L(Train): 0.31245511770248413; L(Test): 0.31007587909698486\n",
      "Epoch 723/1000: L(Train): 0.30991485714912415; L(Test): 0.310053288936615\n",
      "Epoch 724/1000: L(Train): 0.308684378862381; L(Test): 0.31003063917160034\n",
      "Epoch 725/1000: L(Train): 0.31080207228660583; L(Test): 0.31000837683677673\n",
      "Epoch 726/1000: L(Train): 0.3092258870601654; L(Test): 0.3099863529205322\n",
      "Epoch 727/1000: L(Train): 0.30481934547424316; L(Test): 0.30996352434158325\n",
      "Epoch 728/1000: L(Train): 0.3059621751308441; L(Test): 0.30994096398353577\n",
      "Epoch 729/1000: L(Train): 0.3069536089897156; L(Test): 0.30991828441619873\n",
      "Epoch 730/1000: L(Train): 0.30720990896224976; L(Test): 0.30989497900009155\n",
      "Epoch 731/1000: L(Train): 0.3085092008113861; L(Test): 0.3098718523979187\n",
      "Epoch 732/1000: L(Train): 0.30858731269836426; L(Test): 0.3098476827144623\n",
      "Epoch 733/1000: L(Train): 0.30862635374069214; L(Test): 0.3098238408565521\n",
      "Epoch 734/1000: L(Train): 0.3087010383605957; L(Test): 0.3097999691963196\n",
      "Epoch 735/1000: L(Train): 0.3094622790813446; L(Test): 0.3097764253616333\n",
      "Epoch 736/1000: L(Train): 0.3094472289085388; L(Test): 0.30975306034088135\n",
      "Epoch 737/1000: L(Train): 0.3101634979248047; L(Test): 0.3097292482852936\n",
      "Epoch 738/1000: L(Train): 0.31011369824409485; L(Test): 0.30970558524131775\n",
      "Epoch 739/1000: L(Train): 0.3056648075580597; L(Test): 0.30968210101127625\n",
      "Epoch 740/1000: L(Train): 0.310098260641098; L(Test): 0.3096581995487213\n",
      "Epoch 741/1000: L(Train): 0.3154338002204895; L(Test): 0.30963456630706787\n",
      "Epoch 742/1000: L(Train): 0.3099200427532196; L(Test): 0.30961117148399353\n",
      "Epoch 743/1000: L(Train): 0.31095898151397705; L(Test): 0.3095881938934326\n",
      "Epoch 744/1000: L(Train): 0.3145817518234253; L(Test): 0.30956539511680603\n",
      "Epoch 745/1000: L(Train): 0.3105235993862152; L(Test): 0.3095426857471466\n",
      "Epoch 746/1000: L(Train): 0.31317976117134094; L(Test): 0.3095201253890991\n",
      "Epoch 747/1000: L(Train): 0.30782702565193176; L(Test): 0.30949726700782776\n",
      "Epoch 748/1000: L(Train): 0.3073001205921173; L(Test): 0.3094744086265564\n",
      "Epoch 749/1000: L(Train): 0.30774185061454773; L(Test): 0.3094511032104492\n",
      "Epoch 750/1000: L(Train): 0.30684223771095276; L(Test): 0.3094281256198883\n",
      "Epoch 751/1000: L(Train): 0.30646592378616333; L(Test): 0.3094055652618408\n",
      "Epoch 752/1000: L(Train): 0.3118428587913513; L(Test): 0.3093832731246948\n",
      "Epoch 753/1000: L(Train): 0.31089362502098083; L(Test): 0.30936139822006226\n",
      "Epoch 754/1000: L(Train): 0.31081223487854004; L(Test): 0.3093394935131073\n",
      "Epoch 755/1000: L(Train): 0.3100791573524475; L(Test): 0.30931729078292847\n",
      "Epoch 756/1000: L(Train): 0.3083728551864624; L(Test): 0.30929580330848694\n",
      "Epoch 757/1000: L(Train): 0.31072649359703064; L(Test): 0.30927449464797974\n",
      "Epoch 758/1000: L(Train): 0.30775824189186096; L(Test): 0.3092527389526367\n",
      "Epoch 759/1000: L(Train): 0.31132903695106506; L(Test): 0.3092312514781952\n",
      "Epoch 760/1000: L(Train): 0.30736586451530457; L(Test): 0.3092101812362671\n",
      "Epoch 761/1000: L(Train): 0.30695098638534546; L(Test): 0.3091889023780823\n",
      "Epoch 762/1000: L(Train): 0.30677956342697144; L(Test): 0.3091665506362915\n",
      "Epoch 763/1000: L(Train): 0.3108241558074951; L(Test): 0.30914345383644104\n",
      "Epoch 764/1000: L(Train): 0.30571219325065613; L(Test): 0.3091205954551697\n",
      "Epoch 765/1000: L(Train): 0.30625250935554504; L(Test): 0.3090977668762207\n",
      "Epoch 766/1000: L(Train): 0.3083514869213104; L(Test): 0.30907440185546875\n",
      "Epoch 767/1000: L(Train): 0.3069240152835846; L(Test): 0.3090517222881317\n",
      "Epoch 768/1000: L(Train): 0.30882102251052856; L(Test): 0.3090291917324066\n",
      "Epoch 769/1000: L(Train): 0.3085079789161682; L(Test): 0.3090069890022278\n",
      "Epoch 770/1000: L(Train): 0.30742889642715454; L(Test): 0.3089849352836609\n",
      "Epoch 771/1000: L(Train): 0.3106994926929474; L(Test): 0.3089631497859955\n",
      "Epoch 772/1000: L(Train): 0.3071035146713257; L(Test): 0.308940589427948\n",
      "Epoch 773/1000: L(Train): 0.30784872174263; L(Test): 0.3089183568954468\n",
      "Epoch 774/1000: L(Train): 0.3038802444934845; L(Test): 0.30889591574668884\n",
      "Epoch 775/1000: L(Train): 0.3074590265750885; L(Test): 0.3088732659816742\n",
      "Epoch 776/1000: L(Train): 0.30720603466033936; L(Test): 0.3088502883911133\n",
      "Epoch 777/1000: L(Train): 0.30959585309028625; L(Test): 0.3088277578353882\n",
      "Epoch 778/1000: L(Train): 0.3119339048862457; L(Test): 0.30880457162857056\n",
      "Epoch 779/1000: L(Train): 0.30792713165283203; L(Test): 0.30878135561943054\n",
      "Epoch 780/1000: L(Train): 0.3045620322227478; L(Test): 0.30875858664512634\n",
      "Epoch 781/1000: L(Train): 0.3083236515522003; L(Test): 0.30873608589172363\n",
      "Epoch 782/1000: L(Train): 0.3079074025154114; L(Test): 0.30871307849884033\n",
      "Epoch 783/1000: L(Train): 0.3090360462665558; L(Test): 0.3086903989315033\n",
      "Epoch 784/1000: L(Train): 0.30773428082466125; L(Test): 0.3086674213409424\n",
      "Epoch 785/1000: L(Train): 0.3107563555240631; L(Test): 0.308644562959671\n",
      "Epoch 786/1000: L(Train): 0.31040748953819275; L(Test): 0.3086220324039459\n",
      "Epoch 787/1000: L(Train): 0.3074004352092743; L(Test): 0.30859971046447754\n",
      "Epoch 788/1000: L(Train): 0.3098877966403961; L(Test): 0.3085775077342987\n",
      "Epoch 789/1000: L(Train): 0.3064647614955902; L(Test): 0.30855512619018555\n",
      "Epoch 790/1000: L(Train): 0.307224839925766; L(Test): 0.30853271484375\n",
      "Epoch 791/1000: L(Train): 0.3083333969116211; L(Test): 0.30851104855537415\n",
      "Epoch 792/1000: L(Train): 0.3076701760292053; L(Test): 0.3084891438484192\n",
      "Epoch 793/1000: L(Train): 0.3088552951812744; L(Test): 0.30846765637397766\n",
      "Epoch 794/1000: L(Train): 0.3065842092037201; L(Test): 0.3084465563297272\n",
      "Epoch 795/1000: L(Train): 0.3038034737110138; L(Test): 0.30842575430870056\n",
      "Epoch 796/1000: L(Train): 0.30876630544662476; L(Test): 0.3084050714969635\n",
      "Epoch 797/1000: L(Train): 0.31031107902526855; L(Test): 0.30838483572006226\n",
      "Epoch 798/1000: L(Train): 0.309321790933609; L(Test): 0.30836495757102966\n",
      "Epoch 799/1000: L(Train): 0.3088386058807373; L(Test): 0.308345228433609\n",
      "Epoch 800/1000: L(Train): 0.3065539300441742; L(Test): 0.3083251118659973\n",
      "Epoch 801/1000: L(Train): 0.3111605644226074; L(Test): 0.308305561542511\n",
      "Epoch 802/1000: L(Train): 0.3080374300479889; L(Test): 0.30828604102134705\n",
      "Epoch 803/1000: L(Train): 0.3075079321861267; L(Test): 0.30826640129089355\n",
      "Epoch 804/1000: L(Train): 0.3052317798137665; L(Test): 0.3082462549209595\n",
      "Epoch 805/1000: L(Train): 0.30592450499534607; L(Test): 0.30822625756263733\n",
      "Epoch 806/1000: L(Train): 0.3085261583328247; L(Test): 0.30820584297180176\n",
      "Epoch 807/1000: L(Train): 0.30730193853378296; L(Test): 0.30818548798561096\n",
      "Epoch 808/1000: L(Train): 0.3059394955635071; L(Test): 0.30816537141799927\n",
      "Epoch 809/1000: L(Train): 0.30729806423187256; L(Test): 0.30814501643180847\n",
      "Epoch 810/1000: L(Train): 0.30846989154815674; L(Test): 0.30812469124794006\n",
      "Epoch 811/1000: L(Train): 0.3047903776168823; L(Test): 0.3081044852733612\n",
      "Epoch 812/1000: L(Train): 0.3062150478363037; L(Test): 0.3080843389034271\n",
      "Epoch 813/1000: L(Train): 0.3099159300327301; L(Test): 0.3080648183822632\n",
      "Epoch 814/1000: L(Train): 0.30917951464653015; L(Test): 0.30804529786109924\n",
      "Epoch 815/1000: L(Train): 0.30631834268569946; L(Test): 0.308025598526001\n",
      "Epoch 816/1000: L(Train): 0.30573973059654236; L(Test): 0.30800575017929077\n",
      "Epoch 817/1000: L(Train): 0.3095019459724426; L(Test): 0.30798566341400146\n",
      "Epoch 818/1000: L(Train): 0.3107210099697113; L(Test): 0.30796536803245544\n",
      "Epoch 819/1000: L(Train): 0.307643860578537; L(Test): 0.30794522166252136\n",
      "Epoch 820/1000: L(Train): 0.30891942977905273; L(Test): 0.3079259991645813\n",
      "Epoch 821/1000: L(Train): 0.3100605010986328; L(Test): 0.30790650844573975\n",
      "Epoch 822/1000: L(Train): 0.3093637526035309; L(Test): 0.3078865110874176\n",
      "Epoch 823/1000: L(Train): 0.304557204246521; L(Test): 0.3078671991825104\n",
      "Epoch 824/1000: L(Train): 0.30846551060676575; L(Test): 0.3078485131263733\n",
      "Epoch 825/1000: L(Train): 0.3132888972759247; L(Test): 0.30782896280288696\n",
      "Epoch 826/1000: L(Train): 0.3086622953414917; L(Test): 0.3078102469444275\n",
      "Epoch 827/1000: L(Train): 0.3065257668495178; L(Test): 0.30779165029525757\n",
      "Epoch 828/1000: L(Train): 0.30509448051452637; L(Test): 0.3077729046344757\n",
      "Epoch 829/1000: L(Train): 0.3079143464565277; L(Test): 0.3077544569969177\n",
      "Epoch 830/1000: L(Train): 0.30890148878097534; L(Test): 0.3077355623245239\n",
      "Epoch 831/1000: L(Train): 0.3092910945415497; L(Test): 0.30771616101264954\n",
      "Epoch 832/1000: L(Train): 0.3057653605937958; L(Test): 0.3076969087123871\n",
      "Epoch 833/1000: L(Train): 0.3051735460758209; L(Test): 0.30767762660980225\n",
      "Epoch 834/1000: L(Train): 0.3049086928367615; L(Test): 0.30765843391418457\n",
      "Epoch 835/1000: L(Train): 0.30640530586242676; L(Test): 0.30763953924179077\n",
      "Epoch 836/1000: L(Train): 0.30659085512161255; L(Test): 0.30762040615081787\n",
      "Epoch 837/1000: L(Train): 0.3042573034763336; L(Test): 0.30760157108306885\n",
      "Epoch 838/1000: L(Train): 0.3105125427246094; L(Test): 0.3075830042362213\n",
      "Epoch 839/1000: L(Train): 0.30719032883644104; L(Test): 0.30756470561027527\n",
      "Epoch 840/1000: L(Train): 0.30605047941207886; L(Test): 0.3075462281703949\n",
      "Epoch 841/1000: L(Train): 0.30908581614494324; L(Test): 0.30752813816070557\n",
      "Epoch 842/1000: L(Train): 0.30799826979637146; L(Test): 0.30750924348831177\n",
      "Epoch 843/1000: L(Train): 0.30613476037979126; L(Test): 0.3074895739555359\n",
      "Epoch 844/1000: L(Train): 0.3049829304218292; L(Test): 0.30746990442276\n",
      "Epoch 845/1000: L(Train): 0.3078286647796631; L(Test): 0.30745038390159607\n",
      "Epoch 846/1000: L(Train): 0.3085496127605438; L(Test): 0.3074306845664978\n",
      "Epoch 847/1000: L(Train): 0.30533623695373535; L(Test): 0.3074111342430115\n",
      "Epoch 848/1000: L(Train): 0.307647168636322; L(Test): 0.30739179253578186\n",
      "Epoch 849/1000: L(Train): 0.3077166974544525; L(Test): 0.3073729872703552\n",
      "Epoch 850/1000: L(Train): 0.3066045939922333; L(Test): 0.3073546588420868\n",
      "Epoch 851/1000: L(Train): 0.3123478293418884; L(Test): 0.3073371350765228\n",
      "Epoch 852/1000: L(Train): 0.3059353232383728; L(Test): 0.3073197603225708\n",
      "Epoch 853/1000: L(Train): 0.30795344710350037; L(Test): 0.30730271339416504\n",
      "Epoch 854/1000: L(Train): 0.30838558077812195; L(Test): 0.3072856068611145\n",
      "Epoch 855/1000: L(Train): 0.3065081536769867; L(Test): 0.30726808309555054\n",
      "Epoch 856/1000: L(Train): 0.305115282535553; L(Test): 0.3072507083415985\n",
      "Epoch 857/1000: L(Train): 0.30751165747642517; L(Test): 0.30723294615745544\n",
      "Epoch 858/1000: L(Train): 0.30556392669677734; L(Test): 0.3072158098220825\n",
      "Epoch 859/1000: L(Train): 0.305433064699173; L(Test): 0.307199090719223\n",
      "Epoch 860/1000: L(Train): 0.3059869408607483; L(Test): 0.30718231201171875\n",
      "Epoch 861/1000: L(Train): 0.3077549934387207; L(Test): 0.3071662485599518\n",
      "Epoch 862/1000: L(Train): 0.3077529966831207; L(Test): 0.30715101957321167\n",
      "Epoch 863/1000: L(Train): 0.3067762553691864; L(Test): 0.30713582038879395\n",
      "Epoch 864/1000: L(Train): 0.3087626099586487; L(Test): 0.30711984634399414\n",
      "Epoch 865/1000: L(Train): 0.3071536421775818; L(Test): 0.3071037828922272\n",
      "Epoch 866/1000: L(Train): 0.3039763271808624; L(Test): 0.30708709359169006\n",
      "Epoch 867/1000: L(Train): 0.3044355511665344; L(Test): 0.3070698380470276\n",
      "Epoch 868/1000: L(Train): 0.3077360987663269; L(Test): 0.30705249309539795\n",
      "Epoch 869/1000: L(Train): 0.3066459000110626; L(Test): 0.3070344030857086\n",
      "Epoch 870/1000: L(Train): 0.3086729645729065; L(Test): 0.3070155084133148\n",
      "Epoch 871/1000: L(Train): 0.31075185537338257; L(Test): 0.30699723958969116\n",
      "Epoch 872/1000: L(Train): 0.3082467317581177; L(Test): 0.306979238986969\n",
      "Epoch 873/1000: L(Train): 0.3061540722846985; L(Test): 0.30696040391921997\n",
      "Epoch 874/1000: L(Train): 0.30333876609802246; L(Test): 0.30694085359573364\n",
      "Epoch 875/1000: L(Train): 0.3079278767108917; L(Test): 0.3069213926792145\n",
      "Epoch 876/1000: L(Train): 0.30716148018836975; L(Test): 0.3069015443325043\n",
      "Epoch 877/1000: L(Train): 0.31090521812438965; L(Test): 0.30688217282295227\n",
      "Epoch 878/1000: L(Train): 0.30916860699653625; L(Test): 0.3068622052669525\n",
      "Epoch 879/1000: L(Train): 0.3034987151622772; L(Test): 0.3068419098854065\n",
      "Epoch 880/1000: L(Train): 0.30945995450019836; L(Test): 0.3068215250968933\n",
      "Epoch 881/1000: L(Train): 0.30430102348327637; L(Test): 0.30680179595947266\n",
      "Epoch 882/1000: L(Train): 0.30375608801841736; L(Test): 0.30678239464759827\n",
      "Epoch 883/1000: L(Train): 0.307425320148468; L(Test): 0.3067634701728821\n",
      "Epoch 884/1000: L(Train): 0.3066285252571106; L(Test): 0.3067440986633301\n",
      "Epoch 885/1000: L(Train): 0.30706775188446045; L(Test): 0.30672574043273926\n",
      "Epoch 886/1000: L(Train): 0.30610930919647217; L(Test): 0.30670785903930664\n",
      "Epoch 887/1000: L(Train): 0.30585697293281555; L(Test): 0.30668947100639343\n",
      "Epoch 888/1000: L(Train): 0.30779558420181274; L(Test): 0.3066712021827698\n",
      "Epoch 889/1000: L(Train): 0.3042091131210327; L(Test): 0.30665332078933716\n",
      "Epoch 890/1000: L(Train): 0.305459201335907; L(Test): 0.30663561820983887\n",
      "Epoch 891/1000: L(Train): 0.3061787188053131; L(Test): 0.3066180944442749\n",
      "Epoch 892/1000: L(Train): 0.30404409766197205; L(Test): 0.30660057067871094\n",
      "Epoch 893/1000: L(Train): 0.30838295817375183; L(Test): 0.30658337473869324\n",
      "Epoch 894/1000: L(Train): 0.3054770827293396; L(Test): 0.30656617879867554\n",
      "Epoch 895/1000: L(Train): 0.30605727434158325; L(Test): 0.3065486550331116\n",
      "Epoch 896/1000: L(Train): 0.3066255450248718; L(Test): 0.3065311312675476\n",
      "Epoch 897/1000: L(Train): 0.3070968687534332; L(Test): 0.3065137267112732\n",
      "Epoch 898/1000: L(Train): 0.306764155626297; L(Test): 0.3064967393875122\n",
      "Epoch 899/1000: L(Train): 0.3064413368701935; L(Test): 0.3064797520637512\n",
      "Epoch 900/1000: L(Train): 0.3070218563079834; L(Test): 0.30646276473999023\n",
      "Epoch 901/1000: L(Train): 0.3093883991241455; L(Test): 0.3064456582069397\n",
      "Epoch 902/1000: L(Train): 0.30476024746894836; L(Test): 0.3064285218715668\n",
      "Epoch 903/1000: L(Train): 0.3072975277900696; L(Test): 0.3064116835594177\n",
      "Epoch 904/1000: L(Train): 0.30096185207366943; L(Test): 0.3063947558403015\n",
      "Epoch 905/1000: L(Train): 0.3096659481525421; L(Test): 0.3063780963420868\n",
      "Epoch 906/1000: L(Train): 0.3048688769340515; L(Test): 0.3063613474369049\n",
      "Epoch 907/1000: L(Train): 0.31224364042282104; L(Test): 0.30634424090385437\n",
      "Epoch 908/1000: L(Train): 0.305904358625412; L(Test): 0.3063269555568695\n",
      "Epoch 909/1000: L(Train): 0.3034267723560333; L(Test): 0.30630987882614136\n",
      "Epoch 910/1000: L(Train): 0.3045937716960907; L(Test): 0.3062928318977356\n",
      "Epoch 911/1000: L(Train): 0.308368980884552; L(Test): 0.30627599358558655\n",
      "Epoch 912/1000: L(Train): 0.306418776512146; L(Test): 0.3062592148780823\n",
      "Epoch 913/1000: L(Train): 0.3031427562236786; L(Test): 0.30624231696128845\n",
      "Epoch 914/1000: L(Train): 0.3074414134025574; L(Test): 0.3062257170677185\n",
      "Epoch 915/1000: L(Train): 0.3094845712184906; L(Test): 0.30620935559272766\n",
      "Epoch 916/1000: L(Train): 0.3062182664871216; L(Test): 0.3061930239200592\n",
      "Epoch 917/1000: L(Train): 0.3080419600009918; L(Test): 0.3061768412590027\n",
      "Epoch 918/1000: L(Train): 0.3054471015930176; L(Test): 0.30616065859794617\n",
      "Epoch 919/1000: L(Train): 0.3065211772918701; L(Test): 0.3061445653438568\n",
      "Epoch 920/1000: L(Train): 0.3088846206665039; L(Test): 0.3061285614967346\n",
      "Epoch 921/1000: L(Train): 0.30827391147613525; L(Test): 0.306112676858902\n",
      "Epoch 922/1000: L(Train): 0.30929216742515564; L(Test): 0.3060970902442932\n",
      "Epoch 923/1000: L(Train): 0.30547192692756653; L(Test): 0.3060818314552307\n",
      "Epoch 924/1000: L(Train): 0.3054051399230957; L(Test): 0.30606669187545776\n",
      "Epoch 925/1000: L(Train): 0.308125376701355; L(Test): 0.3060514032840729\n",
      "Epoch 926/1000: L(Train): 0.30727607011795044; L(Test): 0.3060362637042999\n",
      "Epoch 927/1000: L(Train): 0.30767300724983215; L(Test): 0.30602094531059265\n",
      "Epoch 928/1000: L(Train): 0.30872371792793274; L(Test): 0.30600589513778687\n",
      "Epoch 929/1000: L(Train): 0.3047553598880768; L(Test): 0.3059903681278229\n",
      "Epoch 930/1000: L(Train): 0.3040197193622589; L(Test): 0.305974543094635\n",
      "Epoch 931/1000: L(Train): 0.3054715394973755; L(Test): 0.30595844984054565\n",
      "Epoch 932/1000: L(Train): 0.3067094683647156; L(Test): 0.3059425950050354\n",
      "Epoch 933/1000: L(Train): 0.30491289496421814; L(Test): 0.3059269189834595\n",
      "Epoch 934/1000: L(Train): 0.30560827255249023; L(Test): 0.30591145157814026\n",
      "Epoch 935/1000: L(Train): 0.30820268392562866; L(Test): 0.3058960437774658\n",
      "Epoch 936/1000: L(Train): 0.3076121211051941; L(Test): 0.3058808445930481\n",
      "Epoch 937/1000: L(Train): 0.3110645115375519; L(Test): 0.305865079164505\n",
      "Epoch 938/1000: L(Train): 0.3081202805042267; L(Test): 0.3058494031429291\n",
      "Epoch 939/1000: L(Train): 0.30534595251083374; L(Test): 0.3058340847492218\n",
      "Epoch 940/1000: L(Train): 0.3054520785808563; L(Test): 0.3058188557624817\n",
      "Epoch 941/1000: L(Train): 0.3028910458087921; L(Test): 0.3058035969734192\n",
      "Epoch 942/1000: L(Train): 0.30518078804016113; L(Test): 0.30578818917274475\n",
      "Epoch 943/1000: L(Train): 0.30616772174835205; L(Test): 0.305772989988327\n",
      "Epoch 944/1000: L(Train): 0.30603697896003723; L(Test): 0.3057577610015869\n",
      "Epoch 945/1000: L(Train): 0.30818572640419006; L(Test): 0.3057425618171692\n",
      "Epoch 946/1000: L(Train): 0.3058963119983673; L(Test): 0.3057273030281067\n",
      "Epoch 947/1000: L(Train): 0.30565616488456726; L(Test): 0.30571213364601135\n",
      "Epoch 948/1000: L(Train): 0.3055914044380188; L(Test): 0.3056965172290802\n",
      "Epoch 949/1000: L(Train): 0.3025716543197632; L(Test): 0.3056808412075043\n",
      "Epoch 950/1000: L(Train): 0.30943214893341064; L(Test): 0.30566561222076416\n",
      "Epoch 951/1000: L(Train): 0.3063007593154907; L(Test): 0.30565017461776733\n",
      "Epoch 952/1000: L(Train): 0.3023298680782318; L(Test): 0.305635005235672\n",
      "Epoch 953/1000: L(Train): 0.3078436851501465; L(Test): 0.30562064051628113\n",
      "Epoch 954/1000: L(Train): 0.3054073750972748; L(Test): 0.3056063950061798\n",
      "Epoch 955/1000: L(Train): 0.3055521249771118; L(Test): 0.3055915832519531\n",
      "Epoch 956/1000: L(Train): 0.30621838569641113; L(Test): 0.30557721853256226\n",
      "Epoch 957/1000: L(Train): 0.30626237392425537; L(Test): 0.3055630922317505\n",
      "Epoch 958/1000: L(Train): 0.3064534068107605; L(Test): 0.3055485486984253\n",
      "Epoch 959/1000: L(Train): 0.30749228596687317; L(Test): 0.3055337071418762\n",
      "Epoch 960/1000: L(Train): 0.3041852116584778; L(Test): 0.3055187463760376\n",
      "Epoch 961/1000: L(Train): 0.3047948479652405; L(Test): 0.30550405383110046\n",
      "Epoch 962/1000: L(Train): 0.30711016058921814; L(Test): 0.305489182472229\n",
      "Epoch 963/1000: L(Train): 0.30282020568847656; L(Test): 0.30547353625297546\n",
      "Epoch 964/1000: L(Train): 0.3063344657421112; L(Test): 0.3054574728012085\n",
      "Epoch 965/1000: L(Train): 0.3078692853450775; L(Test): 0.3054417073726654\n",
      "Epoch 966/1000: L(Train): 0.30436086654663086; L(Test): 0.30542629957199097\n",
      "Epoch 967/1000: L(Train): 0.30660581588745117; L(Test): 0.30541089177131653\n",
      "Epoch 968/1000: L(Train): 0.30504608154296875; L(Test): 0.30539560317993164\n",
      "Epoch 969/1000: L(Train): 0.3077974319458008; L(Test): 0.3053807020187378\n",
      "Epoch 970/1000: L(Train): 0.30727946758270264; L(Test): 0.3053660988807678\n",
      "Epoch 971/1000: L(Train): 0.30583953857421875; L(Test): 0.3053516149520874\n",
      "Epoch 972/1000: L(Train): 0.305663526058197; L(Test): 0.30533716082572937\n",
      "Epoch 973/1000: L(Train): 0.3060527443885803; L(Test): 0.3053224980831146\n",
      "Epoch 974/1000: L(Train): 0.30695948004722595; L(Test): 0.30530738830566406\n",
      "Epoch 975/1000: L(Train): 0.3002908527851105; L(Test): 0.3052922189235687\n",
      "Epoch 976/1000: L(Train): 0.3017677664756775; L(Test): 0.30527710914611816\n",
      "Epoch 977/1000: L(Train): 0.3049662709236145; L(Test): 0.3052622079849243\n",
      "Epoch 978/1000: L(Train): 0.30453407764434814; L(Test): 0.30524739623069763\n",
      "Epoch 979/1000: L(Train): 0.3049169182777405; L(Test): 0.3052332103252411\n",
      "Epoch 980/1000: L(Train): 0.30886849761009216; L(Test): 0.3052194118499756\n",
      "Epoch 981/1000: L(Train): 0.3064473867416382; L(Test): 0.3052058219909668\n",
      "Epoch 982/1000: L(Train): 0.3053513765335083; L(Test): 0.3051920235157013\n",
      "Epoch 983/1000: L(Train): 0.30773600935935974; L(Test): 0.30517813563346863\n",
      "Epoch 984/1000: L(Train): 0.30409982800483704; L(Test): 0.3051648437976837\n",
      "Epoch 985/1000: L(Train): 0.30604666471481323; L(Test): 0.3051515221595764\n",
      "Epoch 986/1000: L(Train): 0.30286359786987305; L(Test): 0.3051376938819885\n",
      "Epoch 987/1000: L(Train): 0.30447709560394287; L(Test): 0.30512359738349915\n",
      "Epoch 988/1000: L(Train): 0.30727460980415344; L(Test): 0.30510929226875305\n",
      "Epoch 989/1000: L(Train): 0.30784130096435547; L(Test): 0.30509471893310547\n",
      "Epoch 990/1000: L(Train): 0.30321669578552246; L(Test): 0.3050800561904907\n",
      "Epoch 991/1000: L(Train): 0.30594077706336975; L(Test): 0.30506598949432373\n",
      "Epoch 992/1000: L(Train): 0.30605772137641907; L(Test): 0.3050518333911896\n",
      "Epoch 993/1000: L(Train): 0.30128762125968933; L(Test): 0.3050377368927002\n",
      "Epoch 994/1000: L(Train): 0.30515995621681213; L(Test): 0.30502307415008545\n",
      "Epoch 995/1000: L(Train): 0.30588027834892273; L(Test): 0.3050086796283722\n",
      "Epoch 996/1000: L(Train): 0.3065854012966156; L(Test): 0.3049940764904022\n",
      "Epoch 997/1000: L(Train): 0.30313682556152344; L(Test): 0.3049798607826233\n",
      "Epoch 998/1000: L(Train): 0.3059765100479126; L(Test): 0.3049652576446533\n",
      "Epoch 999/1000: L(Train): 0.30770641565322876; L(Test): 0.30495020747184753\n",
      "Epoch 1000/1000: L(Train): 0.30392730236053467; L(Test): 0.30493536591529846\n"
     ]
    }
   ],
   "source": [
    "mvt = training(\n",
    "    gru=mvt,\n",
    "    optimizer=optimizer,\n",
    "    epochs=epochs,\n",
    "    dataset_train=dataset,\n",
    "    dataset_test=dataset,\n",
    "    device=torch.device('cpu'),\n",
    ")\n",
    "\n",
    "torch.save(mvt.state_dict(), path_mvt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvt.load_state_dict(torch.load(path_mvt))\n",
    "mvt_agent = AgentNetwork(mvt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted parameters:\n",
      "\n",
      "Alpha\n",
      "tensor([0.3407, 0.1255, 0.3739, 0.2537, 0.0412, 0.2567, 0.2282, 0.0847, 0.0100,\n",
      "        0.5686, 0.6103, 0.2755, 0.0730, 0.1246, 0.1330, 0.9314, 0.3499, 0.2282,\n",
      "        0.3803, 0.1973, 0.0752, 0.5314, 0.9242, 0.1805, 0.2448, 0.1240, 0.0100,\n",
      "        0.2014, 0.6940, 0.8867, 0.0412, 0.3079, 0.1423, 0.0100, 0.2088, 0.1170,\n",
      "        0.0100, 0.0100, 0.1179, 0.2375, 0.2180, 0.9752, 0.3192, 0.0491, 0.1163,\n",
      "        0.1505, 0.1851, 0.0100, 0.2909, 0.0100, 0.2105, 0.1042, 0.4473, 0.3790,\n",
      "        0.0561, 0.3352, 0.3260, 0.2186, 0.6505, 0.0443, 0.6244, 0.2081, 0.3203,\n",
      "        0.4529, 0.5281, 0.8817, 0.1729, 0.3259, 0.0532, 0.2649, 0.1156, 0.0454,\n",
      "        0.1328, 0.0100, 0.2118, 0.0100, 0.3532, 0.1741, 0.1421, 0.0100, 0.1827,\n",
      "        0.1508, 0.0559, 0.5989, 0.2039, 0.4308, 0.1285, 0.2196, 0.5030, 0.2719,\n",
      "        0.1501, 0.3935, 0.1319, 0.1128, 0.3272, 0.0963, 0.4051, 0.0622, 0.3459,\n",
      "        0.1455, 0.0644, 0.1288, 0.3236, 0.0766, 0.1154, 0.1620, 0.2783, 0.3198,\n",
      "        0.6088, 0.1113, 0.0615, 0.2393, 0.0100, 0.1669, 0.0100, 0.0850, 0.0618,\n",
      "        0.2464, 0.2911, 0.6377, 0.0582, 0.1412, 0.0734, 0.1588, 0.0766, 0.0683,\n",
      "        0.1496, 0.1685, 0.0719, 0.9269, 0.0100, 0.6345, 0.1848, 0.1080, 0.0776,\n",
      "        0.1872, 0.3363, 0.0100, 0.3159, 0.0799, 0.1172, 0.4085, 0.1231, 0.2283,\n",
      "        0.0955, 0.2052, 0.1241, 0.9412, 0.0100, 0.2111, 0.2141, 0.3222, 0.0575,\n",
      "        0.0905, 0.0100, 0.2409, 0.5433, 0.9752, 0.7996, 0.2837, 0.0578, 0.0867,\n",
      "        0.1593, 0.5036, 0.0100, 0.1249, 0.0934, 0.0614, 0.1528, 0.2661, 0.2157,\n",
      "        0.0769, 0.0711, 0.9680, 0.1186, 0.2779, 0.0858, 0.1404, 0.8055, 0.5832,\n",
      "        0.4059, 0.0792, 0.2107, 0.7040, 0.1275, 0.1008, 0.0860, 0.2292, 0.0100,\n",
      "        0.0257, 0.1791, 0.0100, 0.2197, 0.9319, 0.1327, 0.1187, 0.3191, 0.2274,\n",
      "        0.0828, 0.0100, 0.3070, 0.0100, 0.0100, 0.4950, 0.2725, 0.0100, 0.1145,\n",
      "        0.3197, 0.1907, 0.1559, 0.2320, 0.0783, 0.4057, 0.0100, 0.0100, 0.0100,\n",
      "        0.1630, 0.3284, 0.0544, 0.0100, 0.1006, 0.0100, 0.1346, 0.1696, 0.0100,\n",
      "        0.0100, 0.0486, 0.2583, 0.2180, 0.3436, 0.1973, 0.1744, 0.5704, 0.0964,\n",
      "        0.2251, 0.0100, 0.1655, 0.2986, 0.0100, 0.1169, 0.0414, 0.0153, 0.0100,\n",
      "        0.1434, 0.1667, 0.3820, 0.2660, 0.1950, 0.2739, 0.0694],\n",
      "       grad_fn=<ClampBackward1>)\n",
      "\n",
      "Beta\n",
      "tensor([4.3790, 5.8484, 6.2185, 5.8385, 5.6735, 5.5463, 5.5921, 6.2666, 6.1226,\n",
      "        2.8977, 1.7248, 6.1311, 6.0124, 5.4872, 6.0486, 5.5255, 6.0596, 5.6669,\n",
      "        5.4233, 6.2045, 3.2402, 4.0205, 3.7330, 5.2557, 3.6374, 6.2410, 5.1139,\n",
      "        5.2512, 2.5734, 4.9677, 5.5141, 6.0121, 4.8940, 4.2320, 5.7027, 6.1079,\n",
      "        5.4401, 3.9515, 4.3038, 6.0043, 5.2637, 3.5007, 6.2796, 5.6188, 6.2023,\n",
      "        6.0725, 6.3794, 5.8921, 5.9921, 5.6693, 6.2699, 5.4035, 5.1362, 5.0883,\n",
      "        5.6367, 3.5724, 5.9248, 5.4294, 5.2293, 5.2554, 4.7509, 5.6565, 5.1950,\n",
      "        4.6876, 5.9952, 4.2208, 6.1315, 5.7826, 4.8603, 5.3645, 5.3822, 5.6416,\n",
      "        6.2405, 5.8249, 5.4879, 3.8088, 5.5337, 5.9563, 5.6375, 5.5028, 6.2238,\n",
      "        4.2402, 5.7217, 5.9541, 5.8449, 4.6738, 5.8746, 5.9968, 4.3344, 6.0779,\n",
      "        5.6890, 6.1084, 6.1093, 6.0761, 6.0055, 5.1194, 4.2377, 5.5350, 5.1362,\n",
      "        5.8141, 3.2407, 6.0428, 5.6711, 5.8842, 5.8640, 6.2273, 5.3570, 6.0535,\n",
      "        5.5156, 6.1795, 5.9047, 5.8873, 5.8041, 5.8397, 5.6954, 4.7154, 5.6411,\n",
      "        5.6901, 1.4516, 0.9557, 5.7637, 6.0754, 6.2012, 6.1974, 5.4608, 5.9774,\n",
      "        5.5330, 5.3841, 5.9375, 4.9145, 5.1621, 0.6399, 6.1949, 5.5878, 6.0147,\n",
      "        6.2203, 5.0991, 1.1632, 6.0210, 6.1077, 5.9233, 5.8144, 5.2280, 4.4658,\n",
      "        6.2242, 5.6419, 5.8569, 4.5447, 4.4662, 6.2241, 5.6635, 6.2354, 5.6244,\n",
      "        5.4371, 5.3991, 6.1287, 4.7968, 5.8891, 4.7698, 5.9344, 6.1963, 6.0679,\n",
      "        6.2828, 5.0593, 5.5954, 5.7208, 6.0722, 5.5260, 5.8929, 6.0740, 6.0493,\n",
      "        5.7807, 6.0823, 3.0389, 6.2108, 5.6500, 5.6444, 5.3399, 3.8063, 6.3956,\n",
      "        4.8230, 4.6137, 5.6586, 5.5297, 5.4116, 5.8205, 5.2342, 5.6449, 4.2682,\n",
      "        3.2782, 6.3900, 5.5921, 6.3473, 5.2004, 5.5576, 5.7192, 4.1460, 5.9423,\n",
      "        5.9721, 5.3576, 6.1549, 6.2203, 5.6798, 5.1008, 5.3445, 3.2485, 6.2315,\n",
      "        6.0453, 5.9156, 5.8970, 5.7514, 6.1847, 6.5071, 6.4584, 2.3321, 5.5274,\n",
      "        5.4616, 5.9861, 5.8734, 3.1769, 6.1531, 5.2861, 5.9073, 5.8926, 4.4068,\n",
      "        5.3516, 5.2253, 2.2030, 3.3982, 5.4256, 5.9484, 5.5991, 5.7139, 5.5326,\n",
      "        5.9710, 5.4750, 6.1093, 6.0314, 5.8717, 5.7988, 5.4445, 0.9692, 5.6424,\n",
      "        4.6694, 6.3973, 5.7691, 5.9941, 5.9722, 5.8540, 5.6590],\n",
      "       grad_fn=<ClampBackward1>)\n",
      "\n",
      "C\n",
      "tensor([ 1.6569,  2.1044,  1.2929,  1.5931,  2.5033,  1.6363,  1.6919,  2.2096,\n",
      "        -1.3683,  1.7558,  1.9053,  1.5743,  2.3381,  2.3941,  2.0303,  1.0802,\n",
      "         1.3829,  1.7187,  1.4230,  1.7335,  2.3130,  1.3934,  1.2276,  1.9316,\n",
      "         2.1633,  2.0816,  2.5453,  1.8879,  1.6046,  1.1220,  2.4645,  1.4246,\n",
      "         2.1573,  2.9932,  1.7210,  2.0548,  2.3353,  2.6027,  2.2004,  1.7079,\n",
      "         1.7124,  1.2712,  1.4361,  2.4462,  2.1730,  2.0395,  1.7658,  2.5289,\n",
      "         1.4371,  2.8433,  1.7564,  2.2383,  1.3688,  1.6049,  2.4347,  1.4921,\n",
      "         1.4265,  1.8091,  1.1259,  2.4545,  1.2602,  1.7700,  1.5773,  1.3576,\n",
      "         1.1586,  1.0705,  1.8800,  1.4333,  2.4701,  1.6944,  2.2529,  2.3888,\n",
      "         2.0034,  2.7140,  1.8107,  2.3662,  1.4281,  1.8989,  1.9894,  2.4410,\n",
      "         1.8105,  2.1598,  2.3650,  1.0281,  1.8176,  1.3532,  2.1065,  1.6993,\n",
      "         0.9453,  1.6080,  2.0916,  1.3084,  2.0702,  2.1290,  1.4022,  2.3573,\n",
      "         1.4850,  2.3910,  1.5440,  2.0203,  2.5879,  2.0669,  1.5095,  2.3421,\n",
      "         2.2053,  1.9039,  1.7761,  1.3997,  1.0795,  2.1724,  2.4349,  1.6133,\n",
      "         2.4902,  1.9031,  2.4237,  2.3349,  2.3936,  1.8357,  2.1447,  1.8656,\n",
      "         2.3725,  1.9420,  2.3570,  1.9300,  2.3845,  2.3902,  2.0182,  1.9887,\n",
      "         2.3526,  1.1317,  2.8987,  3.2357,  1.7928,  2.2107,  2.2487,  1.7874,\n",
      "         1.5125,  0.0431,  1.4373,  2.2965,  2.1661,  1.2715,  2.1924,  2.0249,\n",
      "         2.2568,  1.7557,  2.1517,  1.3188,  2.6759,  1.6955,  1.7948,  1.3691,\n",
      "         2.3980,  2.2843,  2.6057,  1.6265,  1.2483,  0.8501,  1.2600,  1.5234,\n",
      "         2.4105,  2.2423,  1.9476,  1.2145,  2.3239,  2.0479,  2.2541,  2.3493,\n",
      "         2.0009,  1.5302,  1.7271,  2.2875,  2.3531,  2.1134,  2.1473,  1.5874,\n",
      "         2.2980,  2.0844,  1.0913,  0.9772,  1.4894,  2.4140,  1.8787,  0.7912,\n",
      "         2.3838,  2.1982,  2.5464,  1.7185,  2.5180,  2.3076,  1.8231,  2.6449,\n",
      "         1.6101,  0.7901,  2.0987,  2.1519,  1.7160,  1.8316,  2.2545,  2.4910,\n",
      "         1.4868, -1.5972,  2.6757,  1.5940,  1.6547,  0.3069,  2.0967,  1.3962,\n",
      "         1.8480,  2.0351,  1.7623,  2.3122,  1.1736, -1.6798,  3.0696,  2.4573,\n",
      "         2.0701,  1.3838,  2.4206,  3.0103,  2.2334,  2.6352,  2.1043,  1.8872,\n",
      "        -0.9779,  2.8724,  2.3861,  1.7991,  1.4293,  1.3740,  1.8131,  1.9764,\n",
      "         1.1079,  2.2526,  1.6893,  2.5151,  1.9128,  1.4394,  2.3778,  2.1722,\n",
      "         2.4758,  3.1318,  2.5486,  2.0584,  1.6902,  1.3054,  1.5068,  1.8172,\n",
      "         1.5990,  2.3389], grad_fn=<ClampBackward1>)\n",
      "\n",
      "Baseline Gain\n",
      "tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1329, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1068, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1275, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1718, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1800, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1579, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.2061, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "       grad_fn=<ClampBackward1>)\n",
      "\n",
      "Depletion\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.2511, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<ClampBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitted parameters:\")\n",
    "print(\"\\nAlpha\")\n",
    "print(mvt.alpha_env)\n",
    "print(\"\\nBeta\")\n",
    "print(mvt.beta)\n",
    "print(\"\\nC\")\n",
    "print(mvt.c)\n",
    "print(\"\\nBaseline Gain\")\n",
    "print(mvt.baseline_gain)\n",
    "print(\"\\nDepletion\")\n",
    "print(mvt.depletion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../..')\n",
    "from weinhardt2025.benchmarking.benchmarking_gru import GRU, training, setup_agent_gru\n",
    "\n",
    "gru = GRU(n_actions).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "epochs = 1000\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(gru.parameters(), lr=0.01)\n",
    "\n",
    "path_gru = '../../weinhardt2025/params/bustamante2023/gru_bustamante2023.pkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000: L(Train): 0.7161166667938232; L(Test): 0.47229355573654175\n",
      "Epoch 2/1000: L(Train): 0.4765810966491699; L(Test): 0.37618812918663025\n",
      "Epoch 3/1000: L(Train): 0.3779475688934326; L(Test): 0.36393970251083374\n",
      "Epoch 4/1000: L(Train): 0.36273038387298584; L(Test): 0.38288426399230957\n",
      "Epoch 5/1000: L(Train): 0.38493612408638; L(Test): 0.3947180509567261\n",
      "Epoch 6/1000: L(Train): 0.39147648215293884; L(Test): 0.3930591940879822\n",
      "Epoch 7/1000: L(Train): 0.39858609437942505; L(Test): 0.38186413049697876\n",
      "Epoch 8/1000: L(Train): 0.38475459814071655; L(Test): 0.36771348118782043\n",
      "Epoch 9/1000: L(Train): 0.3699730634689331; L(Test): 0.35727158188819885\n",
      "Epoch 10/1000: L(Train): 0.3610268235206604; L(Test): 0.35526126623153687\n",
      "Epoch 11/1000: L(Train): 0.35285648703575134; L(Test): 0.360530823469162\n",
      "Epoch 12/1000: L(Train): 0.3646722137928009; L(Test): 0.3655615746974945\n",
      "Epoch 13/1000: L(Train): 0.36735743284225464; L(Test): 0.3644333481788635\n",
      "Epoch 14/1000: L(Train): 0.3677738308906555; L(Test): 0.3588416278362274\n",
      "Epoch 15/1000: L(Train): 0.36275148391723633; L(Test): 0.35331085324287415\n",
      "Epoch 16/1000: L(Train): 0.35603058338165283; L(Test): 0.3507177233695984\n",
      "Epoch 17/1000: L(Train): 0.35231924057006836; L(Test): 0.35117024183273315\n",
      "Epoch 18/1000: L(Train): 0.35570451617240906; L(Test): 0.35294023156166077\n",
      "Epoch 19/1000: L(Train): 0.3561630845069885; L(Test): 0.35413244366645813\n",
      "Epoch 20/1000: L(Train): 0.3553842008113861; L(Test): 0.3537321090698242\n",
      "Epoch 21/1000: L(Train): 0.3612397611141205; L(Test): 0.3515201508998871\n",
      "Epoch 22/1000: L(Train): 0.3544256091117859; L(Test): 0.34836187958717346\n",
      "Epoch 23/1000: L(Train): 0.35239142179489136; L(Test): 0.3453559875488281\n",
      "Epoch 24/1000: L(Train): 0.3466046154499054; L(Test): 0.34347113966941833\n",
      "Epoch 25/1000: L(Train): 0.34534940123558044; L(Test): 0.34287360310554504\n",
      "Epoch 26/1000: L(Train): 0.3437497019767761; L(Test): 0.34283456206321716\n",
      "Epoch 27/1000: L(Train): 0.3492409288883209; L(Test): 0.34233030676841736\n",
      "Epoch 28/1000: L(Train): 0.34654152393341064; L(Test): 0.3406074643135071\n",
      "Epoch 29/1000: L(Train): 0.34327900409698486; L(Test): 0.33801206946372986\n",
      "Epoch 30/1000: L(Train): 0.3379058837890625; L(Test): 0.3356594443321228\n",
      "Epoch 31/1000: L(Train): 0.3361555337905884; L(Test): 0.33428364992141724\n",
      "Epoch 32/1000: L(Train): 0.3400034010410309; L(Test): 0.3333033621311188\n",
      "Epoch 33/1000: L(Train): 0.3341403901576996; L(Test): 0.33178579807281494\n",
      "Epoch 34/1000: L(Train): 0.33888009190559387; L(Test): 0.3291873633861542\n",
      "Epoch 35/1000: L(Train): 0.33353614807128906; L(Test): 0.3264753818511963\n",
      "Epoch 36/1000: L(Train): 0.32700663805007935; L(Test): 0.3247435986995697\n",
      "Epoch 37/1000: L(Train): 0.32863128185272217; L(Test): 0.32346588373184204\n",
      "Epoch 38/1000: L(Train): 0.32368195056915283; L(Test): 0.32148200273513794\n",
      "Epoch 39/1000: L(Train): 0.322065532207489; L(Test): 0.31914210319519043\n",
      "Epoch 40/1000: L(Train): 0.3238773047924042; L(Test): 0.31736913323402405\n",
      "Epoch 41/1000: L(Train): 0.3212448060512543; L(Test): 0.3159669041633606\n",
      "Epoch 42/1000: L(Train): 0.31923094391822815; L(Test): 0.3137347996234894\n",
      "Epoch 43/1000: L(Train): 0.3165140450000763; L(Test): 0.31087037920951843\n",
      "Epoch 44/1000: L(Train): 0.3146904408931732; L(Test): 0.3080039620399475\n",
      "Epoch 45/1000: L(Train): 0.3128856122493744; L(Test): 0.30481061339378357\n",
      "Epoch 46/1000: L(Train): 0.3100869655609131; L(Test): 0.30034637451171875\n",
      "Epoch 47/1000: L(Train): 0.3104807436466217; L(Test): 0.2953309118747711\n",
      "Epoch 48/1000: L(Train): 0.3003022372722626; L(Test): 0.28991997241973877\n",
      "Epoch 49/1000: L(Train): 0.29409727454185486; L(Test): 0.28353822231292725\n",
      "Epoch 50/1000: L(Train): 0.2929166257381439; L(Test): 0.27672794461250305\n",
      "Epoch 51/1000: L(Train): 0.2828306257724762; L(Test): 0.2710990905761719\n",
      "Epoch 52/1000: L(Train): 0.2781752645969391; L(Test): 0.26682958006858826\n",
      "Epoch 53/1000: L(Train): 0.27168262004852295; L(Test): 0.2633441090583801\n",
      "Epoch 54/1000: L(Train): 0.27107664942741394; L(Test): 0.26012396812438965\n",
      "Epoch 55/1000: L(Train): 0.26604434847831726; L(Test): 0.2566811144351959\n",
      "Epoch 56/1000: L(Train): 0.25953635573387146; L(Test): 0.2533399760723114\n",
      "Epoch 57/1000: L(Train): 0.2576581835746765; L(Test): 0.25073808431625366\n",
      "Epoch 58/1000: L(Train): 0.2585475444793701; L(Test): 0.2487574815750122\n",
      "Epoch 59/1000: L(Train): 0.2536117136478424; L(Test): 0.24640683829784393\n",
      "Epoch 60/1000: L(Train): 0.2521112263202667; L(Test): 0.24418801069259644\n",
      "Epoch 61/1000: L(Train): 0.25034099817276; L(Test): 0.2414306402206421\n",
      "Epoch 62/1000: L(Train): 0.24466274678707123; L(Test): 0.23916245996952057\n",
      "Epoch 63/1000: L(Train): 0.2473091036081314; L(Test): 0.23752610385417938\n",
      "Epoch 64/1000: L(Train): 0.23953433334827423; L(Test): 0.23522508144378662\n",
      "Epoch 65/1000: L(Train): 0.23718196153640747; L(Test): 0.2336527705192566\n",
      "Epoch 66/1000: L(Train): 0.23688678443431854; L(Test): 0.23072931170463562\n",
      "Epoch 67/1000: L(Train): 0.2368277609348297; L(Test): 0.2291354238986969\n",
      "Epoch 68/1000: L(Train): 0.23553158342838287; L(Test): 0.22830450534820557\n",
      "Epoch 69/1000: L(Train): 0.2342236191034317; L(Test): 0.2258516252040863\n",
      "Epoch 70/1000: L(Train): 0.22976315021514893; L(Test): 0.22427496314048767\n",
      "Epoch 71/1000: L(Train): 0.23049597442150116; L(Test): 0.22315147519111633\n",
      "Epoch 72/1000: L(Train): 0.23346887528896332; L(Test): 0.22216364741325378\n",
      "Epoch 73/1000: L(Train): 0.22921229898929596; L(Test): 0.221328005194664\n",
      "Epoch 74/1000: L(Train): 0.2275746464729309; L(Test): 0.22327640652656555\n",
      "Epoch 75/1000: L(Train): 0.22804836928844452; L(Test): 0.21920424699783325\n",
      "Epoch 76/1000: L(Train): 0.2252415269613266; L(Test): 0.21852965652942657\n",
      "Epoch 77/1000: L(Train): 0.22701530158519745; L(Test): 0.22086358070373535\n",
      "Epoch 78/1000: L(Train): 0.22736255824565887; L(Test): 0.21694596111774445\n",
      "Epoch 79/1000: L(Train): 0.2276371866464615; L(Test): 0.2161928415298462\n",
      "Epoch 80/1000: L(Train): 0.22059807181358337; L(Test): 0.21743999421596527\n",
      "Epoch 81/1000: L(Train): 0.22350826859474182; L(Test): 0.2150404006242752\n",
      "Epoch 82/1000: L(Train): 0.2205199897289276; L(Test): 0.2144104689359665\n",
      "Epoch 83/1000: L(Train): 0.22123409807682037; L(Test): 0.21451336145401\n",
      "Epoch 84/1000: L(Train): 0.22024531662464142; L(Test): 0.2139362245798111\n",
      "Epoch 85/1000: L(Train): 0.2205401062965393; L(Test): 0.21315838396549225\n",
      "Epoch 86/1000: L(Train): 0.21952250599861145; L(Test): 0.21328623592853546\n",
      "Epoch 87/1000: L(Train): 0.21718193590641022; L(Test): 0.21309992671012878\n",
      "Epoch 88/1000: L(Train): 0.2172623723745346; L(Test): 0.2121763974428177\n",
      "Epoch 89/1000: L(Train): 0.2183980494737625; L(Test): 0.21190690994262695\n",
      "Epoch 90/1000: L(Train): 0.21560288965702057; L(Test): 0.21163935959339142\n",
      "Epoch 91/1000: L(Train): 0.21702145040035248; L(Test): 0.21116633713245392\n",
      "Epoch 92/1000: L(Train): 0.2202133685350418; L(Test): 0.21104460954666138\n",
      "Epoch 93/1000: L(Train): 0.21582545340061188; L(Test): 0.2105681300163269\n",
      "Epoch 94/1000: L(Train): 0.21858759224414825; L(Test): 0.21024920046329498\n",
      "Epoch 95/1000: L(Train): 0.21420760452747345; L(Test): 0.21012423932552338\n",
      "Epoch 96/1000: L(Train): 0.21879220008850098; L(Test): 0.20983248949050903\n",
      "Epoch 97/1000: L(Train): 0.21419578790664673; L(Test): 0.20982472598552704\n",
      "Epoch 98/1000: L(Train): 0.21098192036151886; L(Test): 0.20916132628917694\n",
      "Epoch 99/1000: L(Train): 0.21475866436958313; L(Test): 0.20887179672718048\n",
      "Epoch 100/1000: L(Train): 0.21597795188426971; L(Test): 0.21082773804664612\n",
      "Epoch 101/1000: L(Train): 0.21676278114318848; L(Test): 0.2085537165403366\n",
      "Epoch 102/1000: L(Train): 0.21542423963546753; L(Test): 0.20833630859851837\n",
      "Epoch 103/1000: L(Train): 0.2095167338848114; L(Test): 0.2094414234161377\n",
      "Epoch 104/1000: L(Train): 0.21430043876171112; L(Test): 0.2077845185995102\n",
      "Epoch 105/1000: L(Train): 0.2132960557937622; L(Test): 0.20754094421863556\n",
      "Epoch 106/1000: L(Train): 0.21234247088432312; L(Test): 0.20827022194862366\n",
      "Epoch 107/1000: L(Train): 0.2127871960401535; L(Test): 0.20711813867092133\n",
      "Epoch 108/1000: L(Train): 0.21333640813827515; L(Test): 0.2069200724363327\n",
      "Epoch 109/1000: L(Train): 0.21228082478046417; L(Test): 0.2070828676223755\n",
      "Epoch 110/1000: L(Train): 0.21009691059589386; L(Test): 0.20674307644367218\n",
      "Epoch 111/1000: L(Train): 0.21137529611587524; L(Test): 0.20640024542808533\n",
      "Epoch 112/1000: L(Train): 0.20965127646923065; L(Test): 0.2066011279821396\n",
      "Epoch 113/1000: L(Train): 0.21163617074489594; L(Test): 0.20629294216632843\n",
      "Epoch 114/1000: L(Train): 0.21037748456001282; L(Test): 0.20571061968803406\n",
      "Epoch 115/1000: L(Train): 0.2125299721956253; L(Test): 0.20556314289569855\n",
      "Epoch 116/1000: L(Train): 0.210485577583313; L(Test): 0.20596827566623688\n",
      "Epoch 117/1000: L(Train): 0.21161533892154694; L(Test): 0.20519475638866425\n",
      "Epoch 118/1000: L(Train): 0.20838765799999237; L(Test): 0.20493857562541962\n",
      "Epoch 119/1000: L(Train): 0.21245089173316956; L(Test): 0.2051309198141098\n",
      "Epoch 120/1000: L(Train): 0.21087563037872314; L(Test): 0.2047191858291626\n",
      "Epoch 121/1000: L(Train): 0.21137158572673798; L(Test): 0.20443010330200195\n",
      "Epoch 122/1000: L(Train): 0.2074413150548935; L(Test): 0.20457535982131958\n",
      "Epoch 123/1000: L(Train): 0.2087840884923935; L(Test): 0.2041706144809723\n",
      "Epoch 124/1000: L(Train): 0.20918144285678864; L(Test): 0.20402637124061584\n",
      "Epoch 125/1000: L(Train): 0.20909541845321655; L(Test): 0.20392313599586487\n",
      "Epoch 126/1000: L(Train): 0.2085750699043274; L(Test): 0.20366738736629486\n",
      "Epoch 127/1000: L(Train): 0.20894746482372284; L(Test): 0.20372222363948822\n",
      "Epoch 128/1000: L(Train): 0.20603102445602417; L(Test): 0.20356686413288116\n",
      "Epoch 129/1000: L(Train): 0.20733818411827087; L(Test): 0.20325833559036255\n",
      "Epoch 130/1000: L(Train): 0.20727966725826263; L(Test): 0.20319947600364685\n",
      "Epoch 131/1000: L(Train): 0.21173255145549774; L(Test): 0.2028668075799942\n",
      "Epoch 132/1000: L(Train): 0.20784412324428558; L(Test): 0.20325569808483124\n",
      "Epoch 133/1000: L(Train): 0.20811887085437775; L(Test): 0.20276972651481628\n",
      "Epoch 134/1000: L(Train): 0.21025988459587097; L(Test): 0.2024659663438797\n",
      "Epoch 135/1000: L(Train): 0.20866671204566956; L(Test): 0.20297670364379883\n",
      "Epoch 136/1000: L(Train): 0.20516376197338104; L(Test): 0.20216025412082672\n",
      "Epoch 137/1000: L(Train): 0.20644550025463104; L(Test): 0.20210354030132294\n",
      "Epoch 138/1000: L(Train): 0.20538146793842316; L(Test): 0.2022308111190796\n",
      "Epoch 139/1000: L(Train): 0.20385493338108063; L(Test): 0.20180930197238922\n",
      "Epoch 140/1000: L(Train): 0.20524607598781586; L(Test): 0.20203736424446106\n",
      "Epoch 141/1000: L(Train): 0.20420017838478088; L(Test): 0.20158186554908752\n",
      "Epoch 142/1000: L(Train): 0.20661917328834534; L(Test): 0.20137746632099152\n",
      "Epoch 143/1000: L(Train): 0.2052099108695984; L(Test): 0.2014581710100174\n",
      "Epoch 144/1000: L(Train): 0.20527370274066925; L(Test): 0.20111225545406342\n",
      "Epoch 145/1000: L(Train): 0.20811006426811218; L(Test): 0.20098519325256348\n",
      "Epoch 146/1000: L(Train): 0.20379920303821564; L(Test): 0.20121818780899048\n",
      "Epoch 147/1000: L(Train): 0.20576123893260956; L(Test): 0.20063833892345428\n",
      "Epoch 148/1000: L(Train): 0.20149284601211548; L(Test): 0.2009001076221466\n",
      "Epoch 149/1000: L(Train): 0.20465365052223206; L(Test): 0.2006053328514099\n",
      "Epoch 150/1000: L(Train): 0.20723508298397064; L(Test): 0.20045924186706543\n",
      "Epoch 151/1000: L(Train): 0.20338177680969238; L(Test): 0.20181967318058014\n",
      "Epoch 152/1000: L(Train): 0.20633774995803833; L(Test): 0.19991257786750793\n",
      "Epoch 153/1000: L(Train): 0.20490442216396332; L(Test): 0.19983729720115662\n",
      "Epoch 154/1000: L(Train): 0.20088040828704834; L(Test): 0.20125533640384674\n",
      "Epoch 155/1000: L(Train): 0.20662912726402283; L(Test): 0.19976799190044403\n",
      "Epoch 156/1000: L(Train): 0.2076425552368164; L(Test): 0.1994549185037613\n",
      "Epoch 157/1000: L(Train): 0.20237930119037628; L(Test): 0.20021115243434906\n",
      "Epoch 158/1000: L(Train): 0.205064594745636; L(Test): 0.199203222990036\n",
      "Epoch 159/1000: L(Train): 0.20255382359027863; L(Test): 0.1990804672241211\n",
      "Epoch 160/1000: L(Train): 0.20508351922035217; L(Test): 0.1992989033460617\n",
      "Epoch 161/1000: L(Train): 0.20339316129684448; L(Test): 0.1989147663116455\n",
      "Epoch 162/1000: L(Train): 0.20290446281433105; L(Test): 0.1990499347448349\n",
      "Epoch 163/1000: L(Train): 0.2030595988035202; L(Test): 0.1987878531217575\n",
      "Epoch 164/1000: L(Train): 0.20471397042274475; L(Test): 0.19867102801799774\n",
      "Epoch 165/1000: L(Train): 0.20103499293327332; L(Test): 0.19866825640201569\n",
      "Epoch 166/1000: L(Train): 0.20117288827896118; L(Test): 0.19903014600276947\n",
      "Epoch 167/1000: L(Train): 0.2069581300020218; L(Test): 0.19904294610023499\n",
      "Epoch 168/1000: L(Train): 0.20463740825653076; L(Test): 0.1987055242061615\n",
      "Epoch 169/1000: L(Train): 0.20291800796985626; L(Test): 0.19866809248924255\n",
      "Epoch 170/1000: L(Train): 0.2050495743751526; L(Test): 0.19816188514232635\n",
      "Epoch 171/1000: L(Train): 0.20400147140026093; L(Test): 0.19829729199409485\n",
      "Epoch 172/1000: L(Train): 0.20617005228996277; L(Test): 0.1982288807630539\n",
      "Epoch 173/1000: L(Train): 0.20610728859901428; L(Test): 0.1979994922876358\n",
      "Epoch 174/1000: L(Train): 0.2016955316066742; L(Test): 0.1984073519706726\n",
      "Epoch 175/1000: L(Train): 0.2014637291431427; L(Test): 0.19787253439426422\n",
      "Epoch 176/1000: L(Train): 0.2026003897190094; L(Test): 0.19781555235385895\n",
      "Epoch 177/1000: L(Train): 0.2011314183473587; L(Test): 0.19837647676467896\n",
      "Epoch 178/1000: L(Train): 0.20177392661571503; L(Test): 0.19765928387641907\n",
      "Epoch 179/1000: L(Train): 0.2019520401954651; L(Test): 0.19762296974658966\n",
      "Epoch 180/1000: L(Train): 0.20315031707286835; L(Test): 0.19913232326507568\n",
      "Epoch 181/1000: L(Train): 0.20201443135738373; L(Test): 0.19756178557872772\n",
      "Epoch 182/1000: L(Train): 0.20436793565750122; L(Test): 0.19751660525798798\n",
      "Epoch 183/1000: L(Train): 0.20197424292564392; L(Test): 0.19861073791980743\n",
      "Epoch 184/1000: L(Train): 0.20329977571964264; L(Test): 0.197261780500412\n",
      "Epoch 185/1000: L(Train): 0.20070740580558777; L(Test): 0.19733992218971252\n",
      "Epoch 186/1000: L(Train): 0.20117448270320892; L(Test): 0.19821543991565704\n",
      "Epoch 187/1000: L(Train): 0.20356440544128418; L(Test): 0.1970950812101364\n",
      "Epoch 188/1000: L(Train): 0.20322956144809723; L(Test): 0.19713222980499268\n",
      "Epoch 189/1000: L(Train): 0.2016768753528595; L(Test): 0.19783708453178406\n",
      "Epoch 190/1000: L(Train): 0.1997685432434082; L(Test): 0.19708552956581116\n",
      "Epoch 191/1000: L(Train): 0.20287084579467773; L(Test): 0.19697219133377075\n",
      "Epoch 192/1000: L(Train): 0.2009143978357315; L(Test): 0.19726522266864777\n",
      "Epoch 193/1000: L(Train): 0.20076608657836914; L(Test): 0.1967894434928894\n",
      "Epoch 194/1000: L(Train): 0.201852947473526; L(Test): 0.19712965190410614\n",
      "Epoch 195/1000: L(Train): 0.20219053328037262; L(Test): 0.19665589928627014\n",
      "Epoch 196/1000: L(Train): 0.19893115758895874; L(Test): 0.1967073678970337\n",
      "Epoch 197/1000: L(Train): 0.19890475273132324; L(Test): 0.1972155123949051\n",
      "Epoch 198/1000: L(Train): 0.2022605538368225; L(Test): 0.1966831535100937\n",
      "Epoch 199/1000: L(Train): 0.20200033485889435; L(Test): 0.1967620551586151\n",
      "Epoch 200/1000: L(Train): 0.19662807881832123; L(Test): 0.1971474140882492\n",
      "Epoch 201/1000: L(Train): 0.1996629387140274; L(Test): 0.1965504139661789\n",
      "Epoch 202/1000: L(Train): 0.20043601095676422; L(Test): 0.19711710512638092\n",
      "Epoch 203/1000: L(Train): 0.19724468886852264; L(Test): 0.19663210213184357\n",
      "Epoch 204/1000: L(Train): 0.20318184792995453; L(Test): 0.19668111205101013\n",
      "Epoch 205/1000: L(Train): 0.1980915665626526; L(Test): 0.19838860630989075\n",
      "Epoch 206/1000: L(Train): 0.20013952255249023; L(Test): 0.19629190862178802\n",
      "Epoch 207/1000: L(Train): 0.20022419095039368; L(Test): 0.1968776285648346\n",
      "Epoch 208/1000: L(Train): 0.20019866526126862; L(Test): 0.19813846051692963\n",
      "Epoch 209/1000: L(Train): 0.20340321958065033; L(Test): 0.19647109508514404\n",
      "Epoch 210/1000: L(Train): 0.20116814970970154; L(Test): 0.19721388816833496\n",
      "Epoch 211/1000: L(Train): 0.20323744416236877; L(Test): 0.19780051708221436\n",
      "Epoch 212/1000: L(Train): 0.2029886245727539; L(Test): 0.19703546166419983\n",
      "Epoch 213/1000: L(Train): 0.19918939471244812; L(Test): 0.19652260839939117\n",
      "Epoch 214/1000: L(Train): 0.20294983685016632; L(Test): 0.19627904891967773\n",
      "Epoch 215/1000: L(Train): 0.20039981603622437; L(Test): 0.19741395115852356\n",
      "Epoch 216/1000: L(Train): 0.2033841907978058; L(Test): 0.19616810977458954\n",
      "Epoch 217/1000: L(Train): 0.2015618085861206; L(Test): 0.19641318917274475\n",
      "Epoch 218/1000: L(Train): 0.19878838956356049; L(Test): 0.1963575780391693\n",
      "Epoch 219/1000: L(Train): 0.19970549643039703; L(Test): 0.1969957798719406\n",
      "Epoch 220/1000: L(Train): 0.20064446330070496; L(Test): 0.19629886746406555\n",
      "Epoch 221/1000: L(Train): 0.20199453830718994; L(Test): 0.1959834098815918\n",
      "Epoch 222/1000: L(Train): 0.1975095421075821; L(Test): 0.19686706364154816\n",
      "Epoch 223/1000: L(Train): 0.20081336796283722; L(Test): 0.1960797756910324\n",
      "Epoch 224/1000: L(Train): 0.2038528174161911; L(Test): 0.1959393471479416\n",
      "Epoch 225/1000: L(Train): 0.20058396458625793; L(Test): 0.19622179865837097\n",
      "Epoch 226/1000: L(Train): 0.19844362139701843; L(Test): 0.1960867941379547\n",
      "Epoch 227/1000: L(Train): 0.2015324831008911; L(Test): 0.19585958123207092\n",
      "Epoch 228/1000: L(Train): 0.20032942295074463; L(Test): 0.19597043097019196\n",
      "Epoch 229/1000: L(Train): 0.1995811015367508; L(Test): 0.19600743055343628\n",
      "Epoch 230/1000: L(Train): 0.1981632262468338; L(Test): 0.19586557149887085\n",
      "Epoch 231/1000: L(Train): 0.19834771752357483; L(Test): 0.1957695186138153\n",
      "Epoch 232/1000: L(Train): 0.20190580189228058; L(Test): 0.19576948881149292\n",
      "Epoch 233/1000: L(Train): 0.19851186871528625; L(Test): 0.19581109285354614\n",
      "Epoch 234/1000: L(Train): 0.20063884556293488; L(Test): 0.1958274245262146\n",
      "Epoch 235/1000: L(Train): 0.19943949580192566; L(Test): 0.1955891102552414\n",
      "Epoch 236/1000: L(Train): 0.20098605751991272; L(Test): 0.19559481739997864\n",
      "Epoch 237/1000: L(Train): 0.1993551254272461; L(Test): 0.1963396966457367\n",
      "Epoch 238/1000: L(Train): 0.20058564841747284; L(Test): 0.1957775056362152\n",
      "Epoch 239/1000: L(Train): 0.19931872189044952; L(Test): 0.1956852674484253\n",
      "Epoch 240/1000: L(Train): 0.19846512377262115; L(Test): 0.19582869112491608\n",
      "Epoch 241/1000: L(Train): 0.2010890543460846; L(Test): 0.19599202275276184\n",
      "Epoch 242/1000: L(Train): 0.19625671207904816; L(Test): 0.19546137750148773\n",
      "Epoch 243/1000: L(Train): 0.19996468722820282; L(Test): 0.19560682773590088\n",
      "Epoch 244/1000: L(Train): 0.20086845755577087; L(Test): 0.1959877759218216\n",
      "Epoch 245/1000: L(Train): 0.20189842581748962; L(Test): 0.1953524500131607\n",
      "Epoch 246/1000: L(Train): 0.1959681659936905; L(Test): 0.1952897012233734\n",
      "Epoch 247/1000: L(Train): 0.1984786093235016; L(Test): 0.1957540363073349\n",
      "Epoch 248/1000: L(Train): 0.20035578310489655; L(Test): 0.19525907933712006\n",
      "Epoch 249/1000: L(Train): 0.1989912986755371; L(Test): 0.19519789516925812\n",
      "Epoch 250/1000: L(Train): 0.19974958896636963; L(Test): 0.19544756412506104\n",
      "Epoch 251/1000: L(Train): 0.19920413196086884; L(Test): 0.19523926079273224\n",
      "Epoch 252/1000: L(Train): 0.19874976575374603; L(Test): 0.1952291876077652\n",
      "Epoch 253/1000: L(Train): 0.2010820209980011; L(Test): 0.1954822987318039\n",
      "Epoch 254/1000: L(Train): 0.2002590298652649; L(Test): 0.19526870548725128\n",
      "Epoch 255/1000: L(Train): 0.19444391131401062; L(Test): 0.1952051818370819\n",
      "Epoch 256/1000: L(Train): 0.20012806355953217; L(Test): 0.19526131451129913\n",
      "Epoch 257/1000: L(Train): 0.19843140244483948; L(Test): 0.19529937207698822\n",
      "Epoch 258/1000: L(Train): 0.19663743674755096; L(Test): 0.19519992172718048\n",
      "Epoch 259/1000: L(Train): 0.19917896389961243; L(Test): 0.19516094028949738\n",
      "Epoch 260/1000: L(Train): 0.1984577775001526; L(Test): 0.19511720538139343\n",
      "Epoch 261/1000: L(Train): 0.19907139241695404; L(Test): 0.19505789875984192\n",
      "Epoch 262/1000: L(Train): 0.20201830565929413; L(Test): 0.19499382376670837\n",
      "Epoch 263/1000: L(Train): 0.19715987145900726; L(Test): 0.1951104700565338\n",
      "Epoch 264/1000: L(Train): 0.2004055231809616; L(Test): 0.19503068923950195\n",
      "Epoch 265/1000: L(Train): 0.19827871024608612; L(Test): 0.19521918892860413\n",
      "Epoch 266/1000: L(Train): 0.2036965936422348; L(Test): 0.19497980177402496\n",
      "Epoch 267/1000: L(Train): 0.19971735775470734; L(Test): 0.1952238231897354\n",
      "Epoch 268/1000: L(Train): 0.19937297701835632; L(Test): 0.19514581561088562\n",
      "Epoch 269/1000: L(Train): 0.19933904707431793; L(Test): 0.19503523409366608\n",
      "Epoch 270/1000: L(Train): 0.1988137662410736; L(Test): 0.195248082280159\n",
      "Epoch 271/1000: L(Train): 0.19769002497196198; L(Test): 0.19506505131721497\n",
      "Epoch 272/1000: L(Train): 0.19805340468883514; L(Test): 0.19485989212989807\n",
      "Epoch 273/1000: L(Train): 0.19626985490322113; L(Test): 0.19526013731956482\n",
      "Epoch 274/1000: L(Train): 0.19677267968654633; L(Test): 0.19492892920970917\n",
      "Epoch 275/1000: L(Train): 0.19938510656356812; L(Test): 0.19478240609169006\n",
      "Epoch 276/1000: L(Train): 0.19601847231388092; L(Test): 0.19563263654708862\n",
      "Epoch 277/1000: L(Train): 0.1975165158510208; L(Test): 0.1947636604309082\n",
      "Epoch 278/1000: L(Train): 0.2023801952600479; L(Test): 0.19477565586566925\n",
      "Epoch 279/1000: L(Train): 0.19930076599121094; L(Test): 0.19520168006420135\n",
      "Epoch 280/1000: L(Train): 0.2004491537809372; L(Test): 0.19479352235794067\n",
      "Epoch 281/1000: L(Train): 0.1961963027715683; L(Test): 0.19487689435482025\n",
      "Epoch 282/1000: L(Train): 0.19913645088672638; L(Test): 0.19483312964439392\n",
      "Epoch 283/1000: L(Train): 0.201180100440979; L(Test): 0.1947711855173111\n",
      "Epoch 284/1000: L(Train): 0.20099642872810364; L(Test): 0.19499291479587555\n",
      "Epoch 285/1000: L(Train): 0.1990414559841156; L(Test): 0.19459106028079987\n",
      "Epoch 286/1000: L(Train): 0.20021553337574005; L(Test): 0.19454869627952576\n",
      "Epoch 287/1000: L(Train): 0.19599121809005737; L(Test): 0.19517800211906433\n",
      "Epoch 288/1000: L(Train): 0.19929005205631256; L(Test): 0.19455909729003906\n",
      "Epoch 289/1000: L(Train): 0.1947903335094452; L(Test): 0.1945103406906128\n",
      "Epoch 290/1000: L(Train): 0.1983177810907364; L(Test): 0.19474631547927856\n",
      "Epoch 291/1000: L(Train): 0.19967487454414368; L(Test): 0.1945994645357132\n",
      "Epoch 292/1000: L(Train): 0.19373705983161926; L(Test): 0.19464407861232758\n",
      "Epoch 293/1000: L(Train): 0.19773317873477936; L(Test): 0.19487181305885315\n",
      "Epoch 294/1000: L(Train): 0.19688034057617188; L(Test): 0.19448605179786682\n",
      "Epoch 295/1000: L(Train): 0.19879217445850372; L(Test): 0.19440816342830658\n",
      "Epoch 296/1000: L(Train): 0.19713479280471802; L(Test): 0.19474394619464874\n",
      "Epoch 297/1000: L(Train): 0.19720657169818878; L(Test): 0.19440574944019318\n",
      "Epoch 298/1000: L(Train): 0.19739845395088196; L(Test): 0.19432756304740906\n",
      "Epoch 299/1000: L(Train): 0.19714109599590302; L(Test): 0.19460415840148926\n",
      "Epoch 300/1000: L(Train): 0.19800551235675812; L(Test): 0.1943133920431137\n",
      "Epoch 301/1000: L(Train): 0.20008298754692078; L(Test): 0.1947373002767563\n",
      "Epoch 302/1000: L(Train): 0.1988147348165512; L(Test): 0.19429689645767212\n",
      "Epoch 303/1000: L(Train): 0.19784826040267944; L(Test): 0.1943126618862152\n",
      "Epoch 304/1000: L(Train): 0.19656437635421753; L(Test): 0.19446426630020142\n",
      "Epoch 305/1000: L(Train): 0.19862550497055054; L(Test): 0.19424040615558624\n",
      "Epoch 306/1000: L(Train): 0.1999668926000595; L(Test): 0.19433388113975525\n",
      "Epoch 307/1000: L(Train): 0.19654588401317596; L(Test): 0.19418558478355408\n",
      "Epoch 308/1000: L(Train): 0.19889169931411743; L(Test): 0.19426329433918\n",
      "Epoch 309/1000: L(Train): 0.19747526943683624; L(Test): 0.19410890340805054\n",
      "Epoch 310/1000: L(Train): 0.19528384506702423; L(Test): 0.19444282352924347\n",
      "Epoch 311/1000: L(Train): 0.1959381103515625; L(Test): 0.19425177574157715\n",
      "Epoch 312/1000: L(Train): 0.19608160853385925; L(Test): 0.19417762756347656\n",
      "Epoch 313/1000: L(Train): 0.1974755823612213; L(Test): 0.19415995478630066\n",
      "Epoch 314/1000: L(Train): 0.1992620825767517; L(Test): 0.19423775374889374\n",
      "Epoch 315/1000: L(Train): 0.19426856935024261; L(Test): 0.19429191946983337\n",
      "Epoch 316/1000: L(Train): 0.19785210490226746; L(Test): 0.1942882388830185\n",
      "Epoch 317/1000: L(Train): 0.19669072329998016; L(Test): 0.19549235701560974\n",
      "Epoch 318/1000: L(Train): 0.19875489175319672; L(Test): 0.1946294754743576\n",
      "Epoch 319/1000: L(Train): 0.19849993288516998; L(Test): 0.19440291821956635\n",
      "Epoch 320/1000: L(Train): 0.19595816731452942; L(Test): 0.19457505643367767\n",
      "Epoch 321/1000: L(Train): 0.19759050011634827; L(Test): 0.19416023790836334\n",
      "Epoch 322/1000: L(Train): 0.19556021690368652; L(Test): 0.1945061832666397\n",
      "Epoch 323/1000: L(Train): 0.19740918278694153; L(Test): 0.19417165219783783\n",
      "Epoch 324/1000: L(Train): 0.19369332492351532; L(Test): 0.19431932270526886\n",
      "Epoch 325/1000: L(Train): 0.1965414136648178; L(Test): 0.1942378580570221\n",
      "Epoch 326/1000: L(Train): 0.19803951680660248; L(Test): 0.19394463300704956\n",
      "Epoch 327/1000: L(Train): 0.1980963498353958; L(Test): 0.1946718692779541\n",
      "Epoch 328/1000: L(Train): 0.19721533358097076; L(Test): 0.19387324154376984\n",
      "Epoch 329/1000: L(Train): 0.19626137614250183; L(Test): 0.194219172000885\n",
      "Epoch 330/1000: L(Train): 0.19834861159324646; L(Test): 0.19469134509563446\n",
      "Epoch 331/1000: L(Train): 0.1990274041891098; L(Test): 0.1940608024597168\n",
      "Epoch 332/1000: L(Train): 0.19830822944641113; L(Test): 0.19395339488983154\n",
      "Epoch 333/1000: L(Train): 0.1953626573085785; L(Test): 0.19429616630077362\n",
      "Epoch 334/1000: L(Train): 0.1971554160118103; L(Test): 0.19399690628051758\n",
      "Epoch 335/1000: L(Train): 0.19688671827316284; L(Test): 0.19410322606563568\n",
      "Epoch 336/1000: L(Train): 0.19698794186115265; L(Test): 0.19384290277957916\n",
      "Epoch 337/1000: L(Train): 0.19644953310489655; L(Test): 0.19373644888401031\n",
      "Epoch 338/1000: L(Train): 0.19538792967796326; L(Test): 0.1943855881690979\n",
      "Epoch 339/1000: L(Train): 0.1942588835954666; L(Test): 0.19380512833595276\n",
      "Epoch 340/1000: L(Train): 0.19597569108009338; L(Test): 0.19385920464992523\n",
      "Epoch 341/1000: L(Train): 0.20028311014175415; L(Test): 0.1946442425251007\n",
      "Epoch 342/1000: L(Train): 0.19645634293556213; L(Test): 0.19373950362205505\n",
      "Epoch 343/1000: L(Train): 0.19580714404582977; L(Test): 0.1941554993391037\n",
      "Epoch 344/1000: L(Train): 0.1999984234571457; L(Test): 0.19450220465660095\n",
      "Epoch 345/1000: L(Train): 0.19414812326431274; L(Test): 0.19391779601573944\n",
      "Epoch 346/1000: L(Train): 0.19737404584884644; L(Test): 0.19453762471675873\n",
      "Epoch 347/1000: L(Train): 0.19792242348194122; L(Test): 0.19622847437858582\n",
      "Epoch 348/1000: L(Train): 0.198982372879982; L(Test): 0.19379326701164246\n",
      "Epoch 349/1000: L(Train): 0.19411402940750122; L(Test): 0.19446183741092682\n",
      "Epoch 350/1000: L(Train): 0.198702871799469; L(Test): 0.19465044140815735\n",
      "Epoch 351/1000: L(Train): 0.1980476975440979; L(Test): 0.19385159015655518\n",
      "Epoch 352/1000: L(Train): 0.20119774341583252; L(Test): 0.19497525691986084\n",
      "Epoch 353/1000: L(Train): 0.19836287200450897; L(Test): 0.1946275532245636\n",
      "Epoch 354/1000: L(Train): 0.1971825212240219; L(Test): 0.19443972408771515\n",
      "Epoch 355/1000: L(Train): 0.19729070365428925; L(Test): 0.19508929550647736\n",
      "Epoch 356/1000: L(Train): 0.2000761777162552; L(Test): 0.1937110871076584\n",
      "Epoch 357/1000: L(Train): 0.19729869067668915; L(Test): 0.19570888578891754\n",
      "Epoch 358/1000: L(Train): 0.20159265398979187; L(Test): 0.19369877874851227\n",
      "Epoch 359/1000: L(Train): 0.19713211059570312; L(Test): 0.19438126683235168\n",
      "Epoch 360/1000: L(Train): 0.19681450724601746; L(Test): 0.1951371133327484\n",
      "Epoch 361/1000: L(Train): 0.19991564750671387; L(Test): 0.19469161331653595\n",
      "Epoch 362/1000: L(Train): 0.19559386372566223; L(Test): 0.19426366686820984\n",
      "Epoch 363/1000: L(Train): 0.19552239775657654; L(Test): 0.19376778602600098\n",
      "Epoch 364/1000: L(Train): 0.19777002930641174; L(Test): 0.19500575959682465\n",
      "Epoch 365/1000: L(Train): 0.19646137952804565; L(Test): 0.19403254985809326\n",
      "Epoch 366/1000: L(Train): 0.1964326947927475; L(Test): 0.1939733475446701\n",
      "Epoch 367/1000: L(Train): 0.1956152319908142; L(Test): 0.1935414969921112\n",
      "Epoch 368/1000: L(Train): 0.19661150872707367; L(Test): 0.1944514960050583\n",
      "Epoch 369/1000: L(Train): 0.19625531136989594; L(Test): 0.19377881288528442\n",
      "Epoch 370/1000: L(Train): 0.1964351385831833; L(Test): 0.19394995272159576\n",
      "Epoch 371/1000: L(Train): 0.19880901277065277; L(Test): 0.19352923333644867\n",
      "Epoch 372/1000: L(Train): 0.19672457873821259; L(Test): 0.1939656138420105\n",
      "Epoch 373/1000: L(Train): 0.20098094642162323; L(Test): 0.19348867237567902\n",
      "Epoch 374/1000: L(Train): 0.1959535926580429; L(Test): 0.19385606050491333\n",
      "Epoch 375/1000: L(Train): 0.19599656760692596; L(Test): 0.19360430538654327\n",
      "Epoch 376/1000: L(Train): 0.19552664458751678; L(Test): 0.1945926547050476\n",
      "Epoch 377/1000: L(Train): 0.1996295005083084; L(Test): 0.19354033470153809\n",
      "Epoch 378/1000: L(Train): 0.19803602993488312; L(Test): 0.1938580870628357\n",
      "Epoch 379/1000: L(Train): 0.19596272706985474; L(Test): 0.1937829852104187\n",
      "Epoch 380/1000: L(Train): 0.19736908376216888; L(Test): 0.1941642463207245\n",
      "Epoch 381/1000: L(Train): 0.19605307281017303; L(Test): 0.193447083234787\n",
      "Epoch 382/1000: L(Train): 0.19862931966781616; L(Test): 0.19338174164295197\n",
      "Epoch 383/1000: L(Train): 0.19569680094718933; L(Test): 0.19353410601615906\n",
      "Epoch 384/1000: L(Train): 0.19757477939128876; L(Test): 0.19347260892391205\n",
      "Epoch 385/1000: L(Train): 0.1963953822851181; L(Test): 0.19319163262844086\n",
      "Epoch 386/1000: L(Train): 0.1967938244342804; L(Test): 0.19317878782749176\n",
      "Epoch 387/1000: L(Train): 0.19763611257076263; L(Test): 0.19349969923496246\n",
      "Epoch 388/1000: L(Train): 0.19497349858283997; L(Test): 0.1933511197566986\n",
      "Epoch 389/1000: L(Train): 0.1966189593076706; L(Test): 0.19320815801620483\n",
      "Epoch 390/1000: L(Train): 0.19487610459327698; L(Test): 0.19315481185913086\n",
      "Epoch 391/1000: L(Train): 0.19589082896709442; L(Test): 0.19334140419960022\n",
      "Epoch 392/1000: L(Train): 0.19591949880123138; L(Test): 0.1932491958141327\n",
      "Epoch 393/1000: L(Train): 0.19376662373542786; L(Test): 0.19313755631446838\n",
      "Epoch 394/1000: L(Train): 0.1951754242181778; L(Test): 0.19310042262077332\n",
      "Epoch 395/1000: L(Train): 0.19634416699409485; L(Test): 0.19304826855659485\n",
      "Epoch 396/1000: L(Train): 0.1976715326309204; L(Test): 0.1929948478937149\n",
      "Epoch 397/1000: L(Train): 0.19674639403820038; L(Test): 0.19308501482009888\n",
      "Epoch 398/1000: L(Train): 0.1936151683330536; L(Test): 0.19299224019050598\n",
      "Epoch 399/1000: L(Train): 0.19511018693447113; L(Test): 0.19303074479103088\n",
      "Epoch 400/1000: L(Train): 0.19748692214488983; L(Test): 0.19301411509513855\n",
      "Epoch 401/1000: L(Train): 0.1989140659570694; L(Test): 0.19302843511104584\n",
      "Epoch 402/1000: L(Train): 0.1966204047203064; L(Test): 0.19328367710113525\n",
      "Epoch 403/1000: L(Train): 0.1962641179561615; L(Test): 0.19291388988494873\n",
      "Epoch 404/1000: L(Train): 0.19678843021392822; L(Test): 0.19293394684791565\n",
      "Epoch 405/1000: L(Train): 0.19499315321445465; L(Test): 0.19306974112987518\n",
      "Epoch 406/1000: L(Train): 0.19790957868099213; L(Test): 0.19292908906936646\n",
      "Epoch 407/1000: L(Train): 0.19794410467147827; L(Test): 0.19296151399612427\n",
      "Epoch 408/1000: L(Train): 0.1959630846977234; L(Test): 0.19294650852680206\n",
      "Epoch 409/1000: L(Train): 0.19507277011871338; L(Test): 0.19328294694423676\n",
      "Epoch 410/1000: L(Train): 0.19468413293361664; L(Test): 0.19287702441215515\n",
      "Epoch 411/1000: L(Train): 0.1978864073753357; L(Test): 0.19309522211551666\n",
      "Epoch 412/1000: L(Train): 0.197018563747406; L(Test): 0.1934819519519806\n",
      "Epoch 413/1000: L(Train): 0.19647550582885742; L(Test): 0.19321832060813904\n",
      "Epoch 414/1000: L(Train): 0.19331350922584534; L(Test): 0.19316016137599945\n",
      "Epoch 415/1000: L(Train): 0.1969609409570694; L(Test): 0.19324854016304016\n",
      "Epoch 416/1000: L(Train): 0.1979692131280899; L(Test): 0.19303067028522491\n",
      "Epoch 417/1000: L(Train): 0.19639642536640167; L(Test): 0.1928059458732605\n",
      "Epoch 418/1000: L(Train): 0.1965583711862564; L(Test): 0.19305069744586945\n",
      "Epoch 419/1000: L(Train): 0.197548970580101; L(Test): 0.19297204911708832\n",
      "Epoch 420/1000: L(Train): 0.1933307647705078; L(Test): 0.19305528700351715\n",
      "Epoch 421/1000: L(Train): 0.19575855135917664; L(Test): 0.19295170903205872\n",
      "Epoch 422/1000: L(Train): 0.1939237117767334; L(Test): 0.1934838742017746\n",
      "Epoch 423/1000: L(Train): 0.19441357254981995; L(Test): 0.1929224729537964\n",
      "Epoch 424/1000: L(Train): 0.19476741552352905; L(Test): 0.19294235110282898\n",
      "Epoch 425/1000: L(Train): 0.196268692612648; L(Test): 0.19286803901195526\n",
      "Epoch 426/1000: L(Train): 0.1943950206041336; L(Test): 0.19337162375450134\n",
      "Epoch 427/1000: L(Train): 0.19392716884613037; L(Test): 0.19277074933052063\n",
      "Epoch 428/1000: L(Train): 0.1944018006324768; L(Test): 0.192615807056427\n",
      "Epoch 429/1000: L(Train): 0.1951926201581955; L(Test): 0.19334019720554352\n",
      "Epoch 430/1000: L(Train): 0.19645807147026062; L(Test): 0.19270800054073334\n",
      "Epoch 431/1000: L(Train): 0.19730232656002045; L(Test): 0.1928602010011673\n",
      "Epoch 432/1000: L(Train): 0.19781941175460815; L(Test): 0.19283485412597656\n",
      "Epoch 433/1000: L(Train): 0.1959228366613388; L(Test): 0.1929459273815155\n",
      "Epoch 434/1000: L(Train): 0.1953435093164444; L(Test): 0.19276635348796844\n",
      "Epoch 435/1000: L(Train): 0.19758746027946472; L(Test): 0.19260884821414948\n",
      "Epoch 436/1000: L(Train): 0.1964883655309677; L(Test): 0.1928127408027649\n",
      "Epoch 437/1000: L(Train): 0.19584335386753082; L(Test): 0.19261907041072845\n",
      "Epoch 438/1000: L(Train): 0.19705389440059662; L(Test): 0.19286341965198517\n",
      "Epoch 439/1000: L(Train): 0.19766832888126373; L(Test): 0.1927308589220047\n",
      "Epoch 440/1000: L(Train): 0.1983463317155838; L(Test): 0.19305089116096497\n",
      "Epoch 441/1000: L(Train): 0.19488196074962616; L(Test): 0.19255563616752625\n",
      "Epoch 442/1000: L(Train): 0.19717128574848175; L(Test): 0.19290877878665924\n",
      "Epoch 443/1000: L(Train): 0.1962110549211502; L(Test): 0.1929081529378891\n",
      "Epoch 444/1000: L(Train): 0.19591188430786133; L(Test): 0.19261550903320312\n",
      "Epoch 445/1000: L(Train): 0.19542743265628815; L(Test): 0.1926877796649933\n",
      "Epoch 446/1000: L(Train): 0.19632844626903534; L(Test): 0.19273075461387634\n",
      "Epoch 447/1000: L(Train): 0.19463662803173065; L(Test): 0.19289806485176086\n",
      "Epoch 448/1000: L(Train): 0.19710879027843475; L(Test): 0.19244202971458435\n",
      "Epoch 449/1000: L(Train): 0.19344615936279297; L(Test): 0.19281408190727234\n",
      "Epoch 450/1000: L(Train): 0.19572319090366364; L(Test): 0.19247131049633026\n",
      "Epoch 451/1000: L(Train): 0.19968067109584808; L(Test): 0.19257478415966034\n",
      "Epoch 452/1000: L(Train): 0.19791914522647858; L(Test): 0.19242730736732483\n",
      "Epoch 453/1000: L(Train): 0.19499169290065765; L(Test): 0.19273371994495392\n",
      "Epoch 454/1000: L(Train): 0.19469347596168518; L(Test): 0.1925320327281952\n",
      "Epoch 455/1000: L(Train): 0.1967305690050125; L(Test): 0.19289539754390717\n",
      "Epoch 456/1000: L(Train): 0.1963104009628296; L(Test): 0.1928434669971466\n",
      "Epoch 457/1000: L(Train): 0.19572164118289948; L(Test): 0.19239361584186554\n",
      "Epoch 458/1000: L(Train): 0.19375087320804596; L(Test): 0.19273395836353302\n",
      "Epoch 459/1000: L(Train): 0.197346031665802; L(Test): 0.19236791133880615\n",
      "Epoch 460/1000: L(Train): 0.1943739354610443; L(Test): 0.1924905776977539\n",
      "Epoch 461/1000: L(Train): 0.1931825876235962; L(Test): 0.19266943633556366\n",
      "Epoch 462/1000: L(Train): 0.19570545852184296; L(Test): 0.19227997958660126\n",
      "Epoch 463/1000: L(Train): 0.19642063975334167; L(Test): 0.19242101907730103\n",
      "Epoch 464/1000: L(Train): 0.19213546812534332; L(Test): 0.1928393393754959\n",
      "Epoch 465/1000: L(Train): 0.1953481137752533; L(Test): 0.1925245076417923\n",
      "Epoch 466/1000: L(Train): 0.1974630206823349; L(Test): 0.19240042567253113\n",
      "Epoch 467/1000: L(Train): 0.1958213746547699; L(Test): 0.19332006573677063\n",
      "Epoch 468/1000: L(Train): 0.19513194262981415; L(Test): 0.19243954122066498\n",
      "Epoch 469/1000: L(Train): 0.19439303874969482; L(Test): 0.1926545798778534\n",
      "Epoch 470/1000: L(Train): 0.1943734884262085; L(Test): 0.19290974736213684\n",
      "Epoch 471/1000: L(Train): 0.1940971165895462; L(Test): 0.19306524097919464\n",
      "Epoch 472/1000: L(Train): 0.1958298683166504; L(Test): 0.19253526628017426\n",
      "Epoch 473/1000: L(Train): 0.19814792275428772; L(Test): 0.19230708479881287\n",
      "Epoch 474/1000: L(Train): 0.19461002945899963; L(Test): 0.19315198063850403\n",
      "Epoch 475/1000: L(Train): 0.1981774866580963; L(Test): 0.19208334386348724\n",
      "Epoch 476/1000: L(Train): 0.19995826482772827; L(Test): 0.1927657425403595\n",
      "Epoch 477/1000: L(Train): 0.19520944356918335; L(Test): 0.1935049444437027\n",
      "Epoch 478/1000: L(Train): 0.19296589493751526; L(Test): 0.19256356358528137\n",
      "Epoch 479/1000: L(Train): 0.1953831911087036; L(Test): 0.1931265890598297\n",
      "Epoch 480/1000: L(Train): 0.19707293808460236; L(Test): 0.19257062673568726\n",
      "Epoch 481/1000: L(Train): 0.19501639902591705; L(Test): 0.19350166618824005\n",
      "Epoch 482/1000: L(Train): 0.19496433436870575; L(Test): 0.19224807620048523\n",
      "Epoch 483/1000: L(Train): 0.19454868137836456; L(Test): 0.1926453858613968\n",
      "Epoch 484/1000: L(Train): 0.1990005522966385; L(Test): 0.19255675375461578\n",
      "Epoch 485/1000: L(Train): 0.1941680908203125; L(Test): 0.1927570253610611\n",
      "Epoch 486/1000: L(Train): 0.19470813870429993; L(Test): 0.19261950254440308\n",
      "Epoch 487/1000: L(Train): 0.19474099576473236; L(Test): 0.19208762049674988\n",
      "Epoch 488/1000: L(Train): 0.19564513862133026; L(Test): 0.1925722062587738\n",
      "Epoch 489/1000: L(Train): 0.19528111815452576; L(Test): 0.1921846866607666\n",
      "Epoch 490/1000: L(Train): 0.19416511058807373; L(Test): 0.192125141620636\n",
      "Epoch 491/1000: L(Train): 0.1956096589565277; L(Test): 0.19223059713840485\n",
      "Epoch 492/1000: L(Train): 0.19549457728862762; L(Test): 0.19209304451942444\n",
      "Epoch 493/1000: L(Train): 0.19487962126731873; L(Test): 0.19210226833820343\n",
      "Epoch 494/1000: L(Train): 0.1976119726896286; L(Test): 0.19195561110973358\n",
      "Epoch 495/1000: L(Train): 0.19510556757450104; L(Test): 0.19203530251979828\n",
      "Epoch 496/1000: L(Train): 0.19327616691589355; L(Test): 0.19200550019741058\n",
      "Epoch 497/1000: L(Train): 0.19322456419467926; L(Test): 0.1919221580028534\n",
      "Epoch 498/1000: L(Train): 0.19531767070293427; L(Test): 0.19193731248378754\n",
      "Epoch 499/1000: L(Train): 0.19273129105567932; L(Test): 0.19197587668895721\n",
      "Epoch 500/1000: L(Train): 0.19522063434123993; L(Test): 0.1919485628604889\n",
      "Epoch 501/1000: L(Train): 0.19393585622310638; L(Test): 0.19189919531345367\n",
      "Epoch 502/1000: L(Train): 0.19672682881355286; L(Test): 0.19192494451999664\n",
      "Epoch 503/1000: L(Train): 0.1948908269405365; L(Test): 0.1919097602367401\n",
      "Epoch 504/1000: L(Train): 0.19766616821289062; L(Test): 0.19198796153068542\n",
      "Epoch 505/1000: L(Train): 0.19675689935684204; L(Test): 0.1918984353542328\n",
      "Epoch 506/1000: L(Train): 0.19628365337848663; L(Test): 0.19186082482337952\n",
      "Epoch 507/1000: L(Train): 0.19718435406684875; L(Test): 0.19197435677051544\n",
      "Epoch 508/1000: L(Train): 0.19602403044700623; L(Test): 0.19187995791435242\n",
      "Epoch 509/1000: L(Train): 0.1929282248020172; L(Test): 0.19182877242565155\n",
      "Epoch 510/1000: L(Train): 0.19709496200084686; L(Test): 0.1918448805809021\n",
      "Epoch 511/1000: L(Train): 0.19621041417121887; L(Test): 0.19190272688865662\n",
      "Epoch 512/1000: L(Train): 0.19698168337345123; L(Test): 0.19182763993740082\n",
      "Epoch 513/1000: L(Train): 0.19236676394939423; L(Test): 0.19181254506111145\n",
      "Epoch 514/1000: L(Train): 0.19322797656059265; L(Test): 0.19206959009170532\n",
      "Epoch 515/1000: L(Train): 0.19256868958473206; L(Test): 0.19190460443496704\n",
      "Epoch 516/1000: L(Train): 0.19534441828727722; L(Test): 0.19179533421993256\n",
      "Epoch 517/1000: L(Train): 0.19382885098457336; L(Test): 0.19190430641174316\n",
      "Epoch 518/1000: L(Train): 0.19269992411136627; L(Test): 0.19191674888134003\n",
      "Epoch 519/1000: L(Train): 0.19723102450370789; L(Test): 0.1919928938150406\n",
      "Epoch 520/1000: L(Train): 0.1965106576681137; L(Test): 0.19251133501529694\n",
      "Epoch 521/1000: L(Train): 0.19626681506633759; L(Test): 0.19170354306697845\n",
      "Epoch 522/1000: L(Train): 0.19734671711921692; L(Test): 0.19194994866847992\n",
      "Epoch 523/1000: L(Train): 0.19495147466659546; L(Test): 0.19287894666194916\n",
      "Epoch 524/1000: L(Train): 0.19594354927539825; L(Test): 0.19178399443626404\n",
      "Epoch 525/1000: L(Train): 0.19257454574108124; L(Test): 0.19193768501281738\n",
      "Epoch 526/1000: L(Train): 0.19863976538181305; L(Test): 0.19229714572429657\n",
      "Epoch 527/1000: L(Train): 0.19347622990608215; L(Test): 0.19205926358699799\n",
      "Epoch 528/1000: L(Train): 0.1980414241552353; L(Test): 0.1921926587820053\n",
      "Epoch 529/1000: L(Train): 0.1965317577123642; L(Test): 0.19185857474803925\n",
      "Epoch 530/1000: L(Train): 0.19410568475723267; L(Test): 0.19219201803207397\n",
      "Epoch 531/1000: L(Train): 0.19724413752555847; L(Test): 0.19187919795513153\n",
      "Epoch 532/1000: L(Train): 0.19871455430984497; L(Test): 0.19164733588695526\n",
      "Epoch 533/1000: L(Train): 0.1932070553302765; L(Test): 0.19268231093883514\n",
      "Epoch 534/1000: L(Train): 0.19592128694057465; L(Test): 0.19165657460689545\n",
      "Epoch 535/1000: L(Train): 0.19507722556591034; L(Test): 0.19187138974666595\n",
      "Epoch 536/1000: L(Train): 0.19823020696640015; L(Test): 0.1919480413198471\n",
      "Epoch 537/1000: L(Train): 0.19661669433116913; L(Test): 0.19179439544677734\n",
      "Epoch 538/1000: L(Train): 0.19582068920135498; L(Test): 0.1916818469762802\n",
      "Epoch 539/1000: L(Train): 0.19800859689712524; L(Test): 0.19170953333377838\n",
      "Epoch 540/1000: L(Train): 0.19442926347255707; L(Test): 0.1920541375875473\n",
      "Epoch 541/1000: L(Train): 0.197824165225029; L(Test): 0.19159196317195892\n",
      "Epoch 542/1000: L(Train): 0.19460885226726532; L(Test): 0.19157324731349945\n",
      "Epoch 543/1000: L(Train): 0.19699139893054962; L(Test): 0.19169503450393677\n",
      "Epoch 544/1000: L(Train): 0.1932917982339859; L(Test): 0.19163191318511963\n",
      "Epoch 545/1000: L(Train): 0.1967267543077469; L(Test): 0.1915591061115265\n",
      "Epoch 546/1000: L(Train): 0.19733130931854248; L(Test): 0.19153867661952972\n",
      "Epoch 547/1000: L(Train): 0.19480182230472565; L(Test): 0.1919150948524475\n",
      "Epoch 548/1000: L(Train): 0.1960451751947403; L(Test): 0.1915881186723709\n",
      "Epoch 549/1000: L(Train): 0.19464527070522308; L(Test): 0.19172298908233643\n",
      "Epoch 550/1000: L(Train): 0.19223923981189728; L(Test): 0.1919572502374649\n",
      "Epoch 551/1000: L(Train): 0.1935955286026001; L(Test): 0.19157449901103973\n",
      "Epoch 552/1000: L(Train): 0.1934574842453003; L(Test): 0.19152794778347015\n",
      "Epoch 553/1000: L(Train): 0.19555655121803284; L(Test): 0.19148856401443481\n",
      "Epoch 554/1000: L(Train): 0.1943240612745285; L(Test): 0.19158127903938293\n",
      "Epoch 555/1000: L(Train): 0.19488494098186493; L(Test): 0.19144587218761444\n",
      "Epoch 556/1000: L(Train): 0.19375289976596832; L(Test): 0.19149301946163177\n",
      "Epoch 557/1000: L(Train): 0.19468288123607635; L(Test): 0.19167006015777588\n",
      "Epoch 558/1000: L(Train): 0.195421501994133; L(Test): 0.19141587615013123\n",
      "Epoch 559/1000: L(Train): 0.1948097050189972; L(Test): 0.19139155745506287\n",
      "Epoch 560/1000: L(Train): 0.19279587268829346; L(Test): 0.19170928001403809\n",
      "Epoch 561/1000: L(Train): 0.1929311901330948; L(Test): 0.19140730798244476\n",
      "Epoch 562/1000: L(Train): 0.19170430302619934; L(Test): 0.1914229393005371\n",
      "Epoch 563/1000: L(Train): 0.1951574981212616; L(Test): 0.19159619510173798\n",
      "Epoch 564/1000: L(Train): 0.1954507678747177; L(Test): 0.19138340651988983\n",
      "Epoch 565/1000: L(Train): 0.19220609962940216; L(Test): 0.19135698676109314\n",
      "Epoch 566/1000: L(Train): 0.19446836411952972; L(Test): 0.19153176248073578\n",
      "Epoch 567/1000: L(Train): 0.19468064606189728; L(Test): 0.19142678380012512\n",
      "Epoch 568/1000: L(Train): 0.1942499577999115; L(Test): 0.19132991135120392\n",
      "Epoch 569/1000: L(Train): 0.19377337396144867; L(Test): 0.19138465821743011\n",
      "Epoch 570/1000: L(Train): 0.19840991497039795; L(Test): 0.1913260817527771\n",
      "Epoch 571/1000: L(Train): 0.19614189863204956; L(Test): 0.19129665195941925\n",
      "Epoch 572/1000: L(Train): 0.19556036591529846; L(Test): 0.19160307943820953\n",
      "Epoch 573/1000: L(Train): 0.19318978488445282; L(Test): 0.19129498302936554\n",
      "Epoch 574/1000: L(Train): 0.19791600108146667; L(Test): 0.19140484929084778\n",
      "Epoch 575/1000: L(Train): 0.1948224902153015; L(Test): 0.1925216019153595\n",
      "Epoch 576/1000: L(Train): 0.19289623200893402; L(Test): 0.1914704591035843\n",
      "Epoch 577/1000: L(Train): 0.19539320468902588; L(Test): 0.19149498641490936\n",
      "Epoch 578/1000: L(Train): 0.19374796748161316; L(Test): 0.19185517728328705\n",
      "Epoch 579/1000: L(Train): 0.19144275784492493; L(Test): 0.1914006918668747\n",
      "Epoch 580/1000: L(Train): 0.19605912268161774; L(Test): 0.19129136204719543\n",
      "Epoch 581/1000: L(Train): 0.19575005769729614; L(Test): 0.1914021074771881\n",
      "Epoch 582/1000: L(Train): 0.195312961935997; L(Test): 0.19116975367069244\n",
      "Epoch 583/1000: L(Train): 0.1937469094991684; L(Test): 0.19140441715717316\n",
      "Epoch 584/1000: L(Train): 0.193846195936203; L(Test): 0.19121894240379333\n",
      "Epoch 585/1000: L(Train): 0.19405300915241241; L(Test): 0.19136394560337067\n",
      "Epoch 586/1000: L(Train): 0.1931879222393036; L(Test): 0.19224300980567932\n",
      "Epoch 587/1000: L(Train): 0.19461578130722046; L(Test): 0.1913640797138214\n",
      "Epoch 588/1000: L(Train): 0.1933353692293167; L(Test): 0.19126054644584656\n",
      "Epoch 589/1000: L(Train): 0.1943829208612442; L(Test): 0.19166743755340576\n",
      "Epoch 590/1000: L(Train): 0.1928129941225052; L(Test): 0.1912253350019455\n",
      "Epoch 591/1000: L(Train): 0.19216713309288025; L(Test): 0.19122324883937836\n",
      "Epoch 592/1000: L(Train): 0.1935425102710724; L(Test): 0.19180986285209656\n",
      "Epoch 593/1000: L(Train): 0.19448566436767578; L(Test): 0.1913101226091385\n",
      "Epoch 594/1000: L(Train): 0.19431984424591064; L(Test): 0.1912369430065155\n",
      "Epoch 595/1000: L(Train): 0.19619245827198029; L(Test): 0.19150063395500183\n",
      "Epoch 596/1000: L(Train): 0.19464583694934845; L(Test): 0.19125621020793915\n",
      "Epoch 597/1000: L(Train): 0.1945895552635193; L(Test): 0.19131650030612946\n",
      "Epoch 598/1000: L(Train): 0.19562114775180817; L(Test): 0.1911691278219223\n",
      "Epoch 599/1000: L(Train): 0.1958818882703781; L(Test): 0.19127057492733002\n",
      "Epoch 600/1000: L(Train): 0.19309331476688385; L(Test): 0.1912107616662979\n",
      "Epoch 601/1000: L(Train): 0.19353614747524261; L(Test): 0.19122402369976044\n",
      "Epoch 602/1000: L(Train): 0.1945004016160965; L(Test): 0.19116510450839996\n",
      "Epoch 603/1000: L(Train): 0.192332923412323; L(Test): 0.19108451902866364\n",
      "Epoch 604/1000: L(Train): 0.19269725680351257; L(Test): 0.19128940999507904\n",
      "Epoch 605/1000: L(Train): 0.194877490401268; L(Test): 0.19111168384552002\n",
      "Epoch 606/1000: L(Train): 0.19518965482711792; L(Test): 0.19111330807209015\n",
      "Epoch 607/1000: L(Train): 0.19512881338596344; L(Test): 0.1911754459142685\n",
      "Epoch 608/1000: L(Train): 0.19284085929393768; L(Test): 0.19108377397060394\n",
      "Epoch 609/1000: L(Train): 0.19470973312854767; L(Test): 0.19113023579120636\n",
      "Epoch 610/1000: L(Train): 0.19429455697536469; L(Test): 0.19103023409843445\n",
      "Epoch 611/1000: L(Train): 0.19365185499191284; L(Test): 0.19116272032260895\n",
      "Epoch 612/1000: L(Train): 0.19325906038284302; L(Test): 0.19101865589618683\n",
      "Epoch 613/1000: L(Train): 0.19455675780773163; L(Test): 0.19127602875232697\n",
      "Epoch 614/1000: L(Train): 0.1946886032819748; L(Test): 0.1911194771528244\n",
      "Epoch 615/1000: L(Train): 0.19072102010250092; L(Test): 0.19112049043178558\n",
      "Epoch 616/1000: L(Train): 0.1934731900691986; L(Test): 0.1910136342048645\n",
      "Epoch 617/1000: L(Train): 0.19314995408058167; L(Test): 0.19120846688747406\n",
      "Epoch 618/1000: L(Train): 0.1971200704574585; L(Test): 0.1911047250032425\n",
      "Epoch 619/1000: L(Train): 0.19662557542324066; L(Test): 0.19098006188869476\n",
      "Epoch 620/1000: L(Train): 0.1918543428182602; L(Test): 0.19181135296821594\n",
      "Epoch 621/1000: L(Train): 0.1940920054912567; L(Test): 0.19159074127674103\n",
      "Epoch 622/1000: L(Train): 0.19435231387615204; L(Test): 0.19245687127113342\n",
      "Epoch 623/1000: L(Train): 0.19788211584091187; L(Test): 0.1912166327238083\n",
      "Epoch 624/1000: L(Train): 0.19511546194553375; L(Test): 0.19105766713619232\n",
      "Epoch 625/1000: L(Train): 0.19505555927753448; L(Test): 0.1916169971227646\n",
      "Epoch 626/1000: L(Train): 0.194930762052536; L(Test): 0.19094103574752808\n",
      "Epoch 627/1000: L(Train): 0.19286435842514038; L(Test): 0.19098441302776337\n",
      "Epoch 628/1000: L(Train): 0.19442008435726166; L(Test): 0.19146667420864105\n",
      "Epoch 629/1000: L(Train): 0.1921505481004715; L(Test): 0.19091451168060303\n",
      "Epoch 630/1000: L(Train): 0.1947954148054123; L(Test): 0.19129346311092377\n",
      "Epoch 631/1000: L(Train): 0.1937360018491745; L(Test): 0.1926131248474121\n",
      "Epoch 632/1000: L(Train): 0.19424642622470856; L(Test): 0.19114112854003906\n",
      "Epoch 633/1000: L(Train): 0.1940908432006836; L(Test): 0.19196544587612152\n",
      "Epoch 634/1000: L(Train): 0.19350719451904297; L(Test): 0.1926572173833847\n",
      "Epoch 635/1000: L(Train): 0.19422508776187897; L(Test): 0.19124585390090942\n",
      "Epoch 636/1000: L(Train): 0.19261227548122406; L(Test): 0.19252276420593262\n",
      "Epoch 637/1000: L(Train): 0.19597774744033813; L(Test): 0.19139675796031952\n",
      "Epoch 638/1000: L(Train): 0.19505111873149872; L(Test): 0.1922360062599182\n",
      "Epoch 639/1000: L(Train): 0.19467706978321075; L(Test): 0.19140265882015228\n",
      "Epoch 640/1000: L(Train): 0.19341261684894562; L(Test): 0.19118474423885345\n",
      "Epoch 641/1000: L(Train): 0.1948985457420349; L(Test): 0.19176477193832397\n",
      "Epoch 642/1000: L(Train): 0.19208383560180664; L(Test): 0.19097477197647095\n",
      "Epoch 643/1000: L(Train): 0.19388897716999054; L(Test): 0.1911906599998474\n",
      "Epoch 644/1000: L(Train): 0.1953936666250229; L(Test): 0.1915973424911499\n",
      "Epoch 645/1000: L(Train): 0.1930219531059265; L(Test): 0.19134695827960968\n",
      "Epoch 646/1000: L(Train): 0.19305431842803955; L(Test): 0.19123193621635437\n",
      "Epoch 647/1000: L(Train): 0.19775782525539398; L(Test): 0.1911318302154541\n",
      "Epoch 648/1000: L(Train): 0.1950090527534485; L(Test): 0.19156424701213837\n",
      "Epoch 649/1000: L(Train): 0.19636443257331848; L(Test): 0.19107678532600403\n",
      "Epoch 650/1000: L(Train): 0.19316771626472473; L(Test): 0.19100478291511536\n",
      "Epoch 651/1000: L(Train): 0.1927787959575653; L(Test): 0.19110697507858276\n",
      "Epoch 652/1000: L(Train): 0.19324062764644623; L(Test): 0.1908939927816391\n",
      "Epoch 653/1000: L(Train): 0.19561707973480225; L(Test): 0.19083969295024872\n",
      "Epoch 654/1000: L(Train): 0.1928456425666809; L(Test): 0.1911301463842392\n",
      "Epoch 655/1000: L(Train): 0.1931561529636383; L(Test): 0.19088102877140045\n",
      "Epoch 656/1000: L(Train): 0.19488804042339325; L(Test): 0.19091111421585083\n",
      "Epoch 657/1000: L(Train): 0.1938469409942627; L(Test): 0.1911557912826538\n",
      "Epoch 658/1000: L(Train): 0.19434621930122375; L(Test): 0.19083015620708466\n",
      "Epoch 659/1000: L(Train): 0.1915162354707718; L(Test): 0.19082427024841309\n",
      "Epoch 660/1000: L(Train): 0.19496293365955353; L(Test): 0.19091975688934326\n",
      "Epoch 661/1000: L(Train): 0.19271710515022278; L(Test): 0.19088920950889587\n",
      "Epoch 662/1000: L(Train): 0.19599519670009613; L(Test): 0.19092096388339996\n",
      "Epoch 663/1000: L(Train): 0.19195407629013062; L(Test): 0.19084949791431427\n",
      "Epoch 664/1000: L(Train): 0.19116759300231934; L(Test): 0.19086134433746338\n",
      "Epoch 665/1000: L(Train): 0.19427980482578278; L(Test): 0.19077634811401367\n",
      "Epoch 666/1000: L(Train): 0.19541418552398682; L(Test): 0.19087249040603638\n",
      "Epoch 667/1000: L(Train): 0.19144515693187714; L(Test): 0.1909118890762329\n",
      "Epoch 668/1000: L(Train): 0.1927163004875183; L(Test): 0.19077357649803162\n",
      "Epoch 669/1000: L(Train): 0.1960257887840271; L(Test): 0.1907251477241516\n",
      "Epoch 670/1000: L(Train): 0.19048255681991577; L(Test): 0.19102223217487335\n",
      "Epoch 671/1000: L(Train): 0.1914263218641281; L(Test): 0.1908084750175476\n",
      "Epoch 672/1000: L(Train): 0.19197750091552734; L(Test): 0.19066648185253143\n",
      "Epoch 673/1000: L(Train): 0.1917302906513214; L(Test): 0.19161058962345123\n",
      "Epoch 674/1000: L(Train): 0.19571799039840698; L(Test): 0.19068074226379395\n",
      "Epoch 675/1000: L(Train): 0.19300614297389984; L(Test): 0.19082383811473846\n",
      "Epoch 676/1000: L(Train): 0.19454815983772278; L(Test): 0.1912134736776352\n",
      "Epoch 677/1000: L(Train): 0.19666920602321625; L(Test): 0.19056656956672668\n",
      "Epoch 678/1000: L(Train): 0.1944812685251236; L(Test): 0.19124749302864075\n",
      "Epoch 679/1000: L(Train): 0.1950158327817917; L(Test): 0.19179658591747284\n",
      "Epoch 680/1000: L(Train): 0.19467465579509735; L(Test): 0.1908501386642456\n",
      "Epoch 681/1000: L(Train): 0.19579315185546875; L(Test): 0.19227677583694458\n",
      "Epoch 682/1000: L(Train): 0.19778817892074585; L(Test): 0.19143547117710114\n",
      "Epoch 683/1000: L(Train): 0.19653865694999695; L(Test): 0.19139325618743896\n",
      "Epoch 684/1000: L(Train): 0.1958407461643219; L(Test): 0.19141638278961182\n",
      "Epoch 685/1000: L(Train): 0.1954934298992157; L(Test): 0.19077035784721375\n",
      "Epoch 686/1000: L(Train): 0.19448111951351166; L(Test): 0.19151964783668518\n",
      "Epoch 687/1000: L(Train): 0.19246605038642883; L(Test): 0.19071319699287415\n",
      "Epoch 688/1000: L(Train): 0.19338928163051605; L(Test): 0.19140949845314026\n",
      "Epoch 689/1000: L(Train): 0.19573575258255005; L(Test): 0.1911250650882721\n",
      "Epoch 690/1000: L(Train): 0.1913909912109375; L(Test): 0.1914103925228119\n",
      "Epoch 691/1000: L(Train): 0.19370447099208832; L(Test): 0.19089427590370178\n",
      "Epoch 692/1000: L(Train): 0.1946018934249878; L(Test): 0.1908082813024521\n",
      "Epoch 693/1000: L(Train): 0.1909705251455307; L(Test): 0.19146546721458435\n",
      "Epoch 694/1000: L(Train): 0.19545672833919525; L(Test): 0.1908041536808014\n",
      "Epoch 695/1000: L(Train): 0.18957751989364624; L(Test): 0.19112426042556763\n",
      "Epoch 696/1000: L(Train): 0.19716496765613556; L(Test): 0.1906830370426178\n",
      "Epoch 697/1000: L(Train): 0.19291670620441437; L(Test): 0.1911744326353073\n",
      "Epoch 698/1000: L(Train): 0.19634626805782318; L(Test): 0.19065657258033752\n",
      "Epoch 699/1000: L(Train): 0.19510820508003235; L(Test): 0.19075173139572144\n",
      "Epoch 700/1000: L(Train): 0.1926109790802002; L(Test): 0.1916520595550537\n",
      "Epoch 701/1000: L(Train): 0.195083886384964; L(Test): 0.1908046007156372\n",
      "Epoch 702/1000: L(Train): 0.19395577907562256; L(Test): 0.19143302738666534\n",
      "Epoch 703/1000: L(Train): 0.19347698986530304; L(Test): 0.1906691938638687\n",
      "Epoch 704/1000: L(Train): 0.1947866976261139; L(Test): 0.1915723830461502\n",
      "Epoch 705/1000: L(Train): 0.19517940282821655; L(Test): 0.19053137302398682\n",
      "Epoch 706/1000: L(Train): 0.1885804682970047; L(Test): 0.19078201055526733\n",
      "Epoch 707/1000: L(Train): 0.1921164095401764; L(Test): 0.19082243740558624\n",
      "Epoch 708/1000: L(Train): 0.1953672170639038; L(Test): 0.19071921706199646\n",
      "Epoch 709/1000: L(Train): 0.19255226850509644; L(Test): 0.19044815003871918\n",
      "Epoch 710/1000: L(Train): 0.1925215870141983; L(Test): 0.19060315191745758\n",
      "Epoch 711/1000: L(Train): 0.19359196722507477; L(Test): 0.19086499512195587\n",
      "Epoch 712/1000: L(Train): 0.19493022561073303; L(Test): 0.19049809873104095\n",
      "Epoch 713/1000: L(Train): 0.19156980514526367; L(Test): 0.1905367225408554\n",
      "Epoch 714/1000: L(Train): 0.1951456218957901; L(Test): 0.1906243860721588\n",
      "Epoch 715/1000: L(Train): 0.19432774186134338; L(Test): 0.1905643492937088\n",
      "Epoch 716/1000: L(Train): 0.1923155039548874; L(Test): 0.19039595127105713\n",
      "Epoch 717/1000: L(Train): 0.193174809217453; L(Test): 0.19038085639476776\n",
      "Epoch 718/1000: L(Train): 0.19025877118110657; L(Test): 0.19057290256023407\n",
      "Epoch 719/1000: L(Train): 0.1915232539176941; L(Test): 0.19044220447540283\n",
      "Epoch 720/1000: L(Train): 0.19612814486026764; L(Test): 0.1905066967010498\n",
      "Epoch 721/1000: L(Train): 0.19221706688404083; L(Test): 0.19040729105472565\n",
      "Epoch 722/1000: L(Train): 0.19365820288658142; L(Test): 0.1908295750617981\n",
      "Epoch 723/1000: L(Train): 0.19587740302085876; L(Test): 0.1903771162033081\n",
      "Epoch 724/1000: L(Train): 0.19311420619487762; L(Test): 0.1903742253780365\n",
      "Epoch 725/1000: L(Train): 0.19118863344192505; L(Test): 0.19084306061267853\n",
      "Epoch 726/1000: L(Train): 0.19226859509944916; L(Test): 0.19032205641269684\n",
      "Epoch 727/1000: L(Train): 0.191532164812088; L(Test): 0.19035911560058594\n",
      "Epoch 728/1000: L(Train): 0.19242806732654572; L(Test): 0.1905439794063568\n",
      "Epoch 729/1000: L(Train): 0.19667716324329376; L(Test): 0.19035246968269348\n",
      "Epoch 730/1000: L(Train): 0.189693883061409; L(Test): 0.1903320848941803\n",
      "Epoch 731/1000: L(Train): 0.19424164295196533; L(Test): 0.19034576416015625\n",
      "Epoch 732/1000: L(Train): 0.19267188012599945; L(Test): 0.19034193456172943\n",
      "Epoch 733/1000: L(Train): 0.19397591054439545; L(Test): 0.1902865767478943\n",
      "Epoch 734/1000: L(Train): 0.19366350769996643; L(Test): 0.19030597805976868\n",
      "Epoch 735/1000: L(Train): 0.19508561491966248; L(Test): 0.1903684139251709\n",
      "Epoch 736/1000: L(Train): 0.19242113828659058; L(Test): 0.19019943475723267\n",
      "Epoch 737/1000: L(Train): 0.1918189525604248; L(Test): 0.19023962318897247\n",
      "Epoch 738/1000: L(Train): 0.19272460043430328; L(Test): 0.19030556082725525\n",
      "Epoch 739/1000: L(Train): 0.19588029384613037; L(Test): 0.19027060270309448\n",
      "Epoch 740/1000: L(Train): 0.19225433468818665; L(Test): 0.19072815775871277\n",
      "Epoch 741/1000: L(Train): 0.19211344420909882; L(Test): 0.1904585361480713\n",
      "Epoch 742/1000: L(Train): 0.19131538271903992; L(Test): 0.19040465354919434\n",
      "Epoch 743/1000: L(Train): 0.19369558990001678; L(Test): 0.19045300781726837\n",
      "Epoch 744/1000: L(Train): 0.19212143123149872; L(Test): 0.19020316004753113\n",
      "Epoch 745/1000: L(Train): 0.19074474275112152; L(Test): 0.1902712881565094\n",
      "Epoch 746/1000: L(Train): 0.19385121762752533; L(Test): 0.19023378193378448\n",
      "Epoch 747/1000: L(Train): 0.19207119941711426; L(Test): 0.19023188948631287\n",
      "Epoch 748/1000: L(Train): 0.19146372377872467; L(Test): 0.19030971825122833\n",
      "Epoch 749/1000: L(Train): 0.1946105808019638; L(Test): 0.19018979370594025\n",
      "Epoch 750/1000: L(Train): 0.1963394731283188; L(Test): 0.19017356634140015\n",
      "Epoch 751/1000: L(Train): 0.19369475543498993; L(Test): 0.190155491232872\n",
      "Epoch 752/1000: L(Train): 0.19600261747837067; L(Test): 0.19012098014354706\n",
      "Epoch 753/1000: L(Train): 0.19486895203590393; L(Test): 0.19011692702770233\n",
      "Epoch 754/1000: L(Train): 0.19395406544208527; L(Test): 0.1901288777589798\n",
      "Epoch 755/1000: L(Train): 0.19420334696769714; L(Test): 0.19028693437576294\n",
      "Epoch 756/1000: L(Train): 0.19322054088115692; L(Test): 0.19021764397621155\n",
      "Epoch 757/1000: L(Train): 0.19200894236564636; L(Test): 0.1903388500213623\n",
      "Epoch 758/1000: L(Train): 0.19353465735912323; L(Test): 0.19008606672286987\n",
      "Epoch 759/1000: L(Train): 0.19135400652885437; L(Test): 0.1901177167892456\n",
      "Epoch 760/1000: L(Train): 0.1919161081314087; L(Test): 0.19055978953838348\n",
      "Epoch 761/1000: L(Train): 0.1928078532218933; L(Test): 0.1900452822446823\n",
      "Epoch 762/1000: L(Train): 0.1896074116230011; L(Test): 0.1900675892829895\n",
      "Epoch 763/1000: L(Train): 0.19310380518436432; L(Test): 0.19034218788146973\n",
      "Epoch 764/1000: L(Train): 0.19503000378608704; L(Test): 0.19016876816749573\n",
      "Epoch 765/1000: L(Train): 0.19298091530799866; L(Test): 0.19008280336856842\n",
      "Epoch 766/1000: L(Train): 0.19325675070285797; L(Test): 0.19024771451950073\n",
      "Epoch 767/1000: L(Train): 0.19136804342269897; L(Test): 0.18995630741119385\n",
      "Epoch 768/1000: L(Train): 0.19556409120559692; L(Test): 0.19009007513523102\n",
      "Epoch 769/1000: L(Train): 0.1955140233039856; L(Test): 0.1900113970041275\n",
      "Epoch 770/1000: L(Train): 0.1917356699705124; L(Test): 0.1900227963924408\n",
      "Epoch 771/1000: L(Train): 0.19271312654018402; L(Test): 0.18992573022842407\n",
      "Epoch 772/1000: L(Train): 0.19003675878047943; L(Test): 0.19012533128261566\n",
      "Epoch 773/1000: L(Train): 0.19111809134483337; L(Test): 0.18998482823371887\n",
      "Epoch 774/1000: L(Train): 0.1936970353126526; L(Test): 0.18994106352329254\n",
      "Epoch 775/1000: L(Train): 0.19463875889778137; L(Test): 0.19028478860855103\n",
      "Epoch 776/1000: L(Train): 0.19440853595733643; L(Test): 0.19003811478614807\n",
      "Epoch 777/1000: L(Train): 0.19220009446144104; L(Test): 0.18994714319705963\n",
      "Epoch 778/1000: L(Train): 0.1914624273777008; L(Test): 0.18996001780033112\n",
      "Epoch 779/1000: L(Train): 0.19345346093177795; L(Test): 0.19010621309280396\n",
      "Epoch 780/1000: L(Train): 0.1901564747095108; L(Test): 0.19012869894504547\n",
      "Epoch 781/1000: L(Train): 0.19261078536510468; L(Test): 0.19014327228069305\n",
      "Epoch 782/1000: L(Train): 0.19424954056739807; L(Test): 0.19047650694847107\n",
      "Epoch 783/1000: L(Train): 0.19375662505626678; L(Test): 0.19007162749767303\n",
      "Epoch 784/1000: L(Train): 0.19312025606632233; L(Test): 0.19011832773685455\n",
      "Epoch 785/1000: L(Train): 0.19158890843391418; L(Test): 0.19016516208648682\n",
      "Epoch 786/1000: L(Train): 0.19564515352249146; L(Test): 0.19014696776866913\n",
      "Epoch 787/1000: L(Train): 0.19391438364982605; L(Test): 0.19012963771820068\n",
      "Epoch 788/1000: L(Train): 0.19134576618671417; L(Test): 0.1901199221611023\n",
      "Epoch 789/1000: L(Train): 0.1901305615901947; L(Test): 0.1899918168783188\n",
      "Epoch 790/1000: L(Train): 0.1928708255290985; L(Test): 0.19034360349178314\n",
      "Epoch 791/1000: L(Train): 0.19188053905963898; L(Test): 0.19056864082813263\n",
      "Epoch 792/1000: L(Train): 0.1933155208826065; L(Test): 0.1899898648262024\n",
      "Epoch 793/1000: L(Train): 0.19338122010231018; L(Test): 0.18997283279895782\n",
      "Epoch 794/1000: L(Train): 0.1930309683084488; L(Test): 0.19028343260288239\n",
      "Epoch 795/1000: L(Train): 0.193293958902359; L(Test): 0.1899218112230301\n",
      "Epoch 796/1000: L(Train): 0.19661945104599; L(Test): 0.190279021859169\n",
      "Epoch 797/1000: L(Train): 0.19241109490394592; L(Test): 0.19157953560352325\n",
      "Epoch 798/1000: L(Train): 0.19393298029899597; L(Test): 0.18979273736476898\n",
      "Epoch 799/1000: L(Train): 0.19288459420204163; L(Test): 0.19146795570850372\n",
      "Epoch 800/1000: L(Train): 0.19275283813476562; L(Test): 0.19277149438858032\n",
      "Epoch 801/1000: L(Train): 0.1976367086172104; L(Test): 0.19084790349006653\n",
      "Epoch 802/1000: L(Train): 0.19055286049842834; L(Test): 0.19225174188613892\n",
      "Epoch 803/1000: L(Train): 0.19439230859279633; L(Test): 0.19035601615905762\n",
      "Epoch 804/1000: L(Train): 0.19493317604064941; L(Test): 0.19113078713417053\n",
      "Epoch 805/1000: L(Train): 0.19304496049880981; L(Test): 0.19014230370521545\n",
      "Epoch 806/1000: L(Train): 0.19314205646514893; L(Test): 0.19099456071853638\n",
      "Epoch 807/1000: L(Train): 0.19277644157409668; L(Test): 0.19060561060905457\n",
      "Epoch 808/1000: L(Train): 0.19284778833389282; L(Test): 0.19066432118415833\n",
      "Epoch 809/1000: L(Train): 0.18918129801750183; L(Test): 0.19035381078720093\n",
      "Epoch 810/1000: L(Train): 0.1950235664844513; L(Test): 0.19005711376667023\n",
      "Epoch 811/1000: L(Train): 0.1921864002943039; L(Test): 0.1906910389661789\n",
      "Epoch 812/1000: L(Train): 0.19316010177135468; L(Test): 0.19027505815029144\n",
      "Epoch 813/1000: L(Train): 0.19107568264007568; L(Test): 0.19008725881576538\n",
      "Epoch 814/1000: L(Train): 0.19511860609054565; L(Test): 0.19017210602760315\n",
      "Epoch 815/1000: L(Train): 0.19518069922924042; L(Test): 0.1901993751525879\n",
      "Epoch 816/1000: L(Train): 0.1948109120130539; L(Test): 0.19024212658405304\n",
      "Epoch 817/1000: L(Train): 0.19491292536258698; L(Test): 0.19002805650234222\n",
      "Epoch 818/1000: L(Train): 0.19204920530319214; L(Test): 0.19019746780395508\n",
      "Epoch 819/1000: L(Train): 0.1931440830230713; L(Test): 0.1904158890247345\n",
      "Epoch 820/1000: L(Train): 0.1919478327035904; L(Test): 0.18989349901676178\n",
      "Epoch 821/1000: L(Train): 0.19487068057060242; L(Test): 0.19067463278770447\n",
      "Epoch 822/1000: L(Train): 0.19295264780521393; L(Test): 0.19094419479370117\n",
      "Epoch 823/1000: L(Train): 0.191796213388443; L(Test): 0.19009362161159515\n",
      "Epoch 824/1000: L(Train): 0.19121573865413666; L(Test): 0.19056262075901031\n",
      "Epoch 825/1000: L(Train): 0.19225537776947021; L(Test): 0.1905868947505951\n",
      "Epoch 826/1000: L(Train): 0.1943209320306778; L(Test): 0.19065211713314056\n",
      "Epoch 827/1000: L(Train): 0.1931813657283783; L(Test): 0.18998152017593384\n",
      "Epoch 828/1000: L(Train): 0.19454869627952576; L(Test): 0.19030103087425232\n",
      "Epoch 829/1000: L(Train): 0.19368618726730347; L(Test): 0.1901087909936905\n",
      "Epoch 830/1000: L(Train): 0.19584998488426208; L(Test): 0.19014492630958557\n",
      "Epoch 831/1000: L(Train): 0.1945962756872177; L(Test): 0.19026929140090942\n",
      "Epoch 832/1000: L(Train): 0.1914474368095398; L(Test): 0.1898341178894043\n",
      "Epoch 833/1000: L(Train): 0.19159288704395294; L(Test): 0.19028757512569427\n",
      "Epoch 834/1000: L(Train): 0.19385316967964172; L(Test): 0.18978959321975708\n",
      "Epoch 835/1000: L(Train): 0.19026629626750946; L(Test): 0.18990616500377655\n",
      "Epoch 836/1000: L(Train): 0.19102148711681366; L(Test): 0.1898551732301712\n",
      "Epoch 837/1000: L(Train): 0.19385382533073425; L(Test): 0.18991468846797943\n",
      "Epoch 838/1000: L(Train): 0.19196569919586182; L(Test): 0.19016562402248383\n",
      "Epoch 839/1000: L(Train): 0.19078144431114197; L(Test): 0.1897125542163849\n",
      "Epoch 840/1000: L(Train): 0.192642942070961; L(Test): 0.19056302309036255\n",
      "Epoch 841/1000: L(Train): 0.19343601167201996; L(Test): 0.18981420993804932\n",
      "Epoch 842/1000: L(Train): 0.19184330105781555; L(Test): 0.18988047540187836\n",
      "Epoch 843/1000: L(Train): 0.19471658766269684; L(Test): 0.189878448843956\n",
      "Epoch 844/1000: L(Train): 0.19136977195739746; L(Test): 0.19016854465007782\n",
      "Epoch 845/1000: L(Train): 0.19073310494422913; L(Test): 0.18960736691951752\n",
      "Epoch 846/1000: L(Train): 0.19270730018615723; L(Test): 0.19010867178440094\n",
      "Epoch 847/1000: L(Train): 0.19142282009124756; L(Test): 0.18981753289699554\n",
      "Epoch 848/1000: L(Train): 0.191959947347641; L(Test): 0.18986758589744568\n",
      "Epoch 849/1000: L(Train): 0.19060440361499786; L(Test): 0.18981803953647614\n",
      "Epoch 850/1000: L(Train): 0.19208069145679474; L(Test): 0.18947061896324158\n",
      "Epoch 851/1000: L(Train): 0.191635861992836; L(Test): 0.19008970260620117\n",
      "Epoch 852/1000: L(Train): 0.19464175403118134; L(Test): 0.18947136402130127\n",
      "Epoch 853/1000: L(Train): 0.1939719319343567; L(Test): 0.1895464062690735\n",
      "Epoch 854/1000: L(Train): 0.1927025467157364; L(Test): 0.18965411186218262\n",
      "Epoch 855/1000: L(Train): 0.1937423050403595; L(Test): 0.18952061235904694\n",
      "Epoch 856/1000: L(Train): 0.19046948850154877; L(Test): 0.18950121104717255\n",
      "Epoch 857/1000: L(Train): 0.19356632232666016; L(Test): 0.189527690410614\n",
      "Epoch 858/1000: L(Train): 0.19084295630455017; L(Test): 0.18944193422794342\n",
      "Epoch 859/1000: L(Train): 0.19107860326766968; L(Test): 0.18939071893692017\n",
      "Epoch 860/1000: L(Train): 0.19228523969650269; L(Test): 0.1894204020500183\n",
      "Epoch 861/1000: L(Train): 0.18988299369812012; L(Test): 0.18962600827217102\n",
      "Epoch 862/1000: L(Train): 0.19078296422958374; L(Test): 0.18944312632083893\n",
      "Epoch 863/1000: L(Train): 0.19117259979248047; L(Test): 0.18941132724285126\n",
      "Epoch 864/1000: L(Train): 0.19341100752353668; L(Test): 0.1895396113395691\n",
      "Epoch 865/1000: L(Train): 0.1925296038389206; L(Test): 0.18964222073554993\n",
      "Epoch 866/1000: L(Train): 0.19259332120418549; L(Test): 0.18928872048854828\n",
      "Epoch 867/1000: L(Train): 0.1909184455871582; L(Test): 0.18932756781578064\n",
      "Epoch 868/1000: L(Train): 0.19334036111831665; L(Test): 0.18935039639472961\n",
      "Epoch 869/1000: L(Train): 0.193842813372612; L(Test): 0.18938232958316803\n",
      "Epoch 870/1000: L(Train): 0.19292838871479034; L(Test): 0.189707413315773\n",
      "Epoch 871/1000: L(Train): 0.18995584547519684; L(Test): 0.18948213756084442\n",
      "Epoch 872/1000: L(Train): 0.19389060139656067; L(Test): 0.18954068422317505\n",
      "Epoch 873/1000: L(Train): 0.19056813418865204; L(Test): 0.18949316442012787\n",
      "Epoch 874/1000: L(Train): 0.1930188685655594; L(Test): 0.18971946835517883\n",
      "Epoch 875/1000: L(Train): 0.19144409894943237; L(Test): 0.18948984146118164\n",
      "Epoch 876/1000: L(Train): 0.19605904817581177; L(Test): 0.18939359486103058\n",
      "Epoch 877/1000: L(Train): 0.19227486848831177; L(Test): 0.18987661600112915\n",
      "Epoch 878/1000: L(Train): 0.19227322936058044; L(Test): 0.18930886685848236\n",
      "Epoch 879/1000: L(Train): 0.18985113501548767; L(Test): 0.18951736390590668\n",
      "Epoch 880/1000: L(Train): 0.1934303194284439; L(Test): 0.18970420956611633\n",
      "Epoch 881/1000: L(Train): 0.1953633725643158; L(Test): 0.18961240351200104\n",
      "Epoch 882/1000: L(Train): 0.19493255019187927; L(Test): 0.18992498517036438\n",
      "Epoch 883/1000: L(Train): 0.1904968023300171; L(Test): 0.18955405056476593\n",
      "Epoch 884/1000: L(Train): 0.19059433043003082; L(Test): 0.190058633685112\n",
      "Epoch 885/1000: L(Train): 0.19373196363449097; L(Test): 0.1896064728498459\n",
      "Epoch 886/1000: L(Train): 0.19405996799468994; L(Test): 0.18952617049217224\n",
      "Epoch 887/1000: L(Train): 0.19537396728992462; L(Test): 0.18994338810443878\n",
      "Epoch 888/1000: L(Train): 0.19134151935577393; L(Test): 0.18936672806739807\n",
      "Epoch 889/1000: L(Train): 0.1899557262659073; L(Test): 0.1894623041152954\n",
      "Epoch 890/1000: L(Train): 0.18967145681381226; L(Test): 0.18917028605937958\n",
      "Epoch 891/1000: L(Train): 0.19181300699710846; L(Test): 0.190087229013443\n",
      "Epoch 892/1000: L(Train): 0.19522032141685486; L(Test): 0.18916365504264832\n",
      "Epoch 893/1000: L(Train): 0.1904592514038086; L(Test): 0.189673513174057\n",
      "Epoch 894/1000: L(Train): 0.19311276078224182; L(Test): 0.1896386444568634\n",
      "Epoch 895/1000: L(Train): 0.190941721200943; L(Test): 0.18950146436691284\n",
      "Epoch 896/1000: L(Train): 0.1936885118484497; L(Test): 0.1901462823152542\n",
      "Epoch 897/1000: L(Train): 0.19047555327415466; L(Test): 0.18943607807159424\n",
      "Epoch 898/1000: L(Train): 0.19426977634429932; L(Test): 0.19027628004550934\n",
      "Epoch 899/1000: L(Train): 0.1925354301929474; L(Test): 0.1893012523651123\n",
      "Epoch 900/1000: L(Train): 0.19285838305950165; L(Test): 0.18973878026008606\n",
      "Epoch 901/1000: L(Train): 0.19143953919410706; L(Test): 0.18941651284694672\n",
      "Epoch 902/1000: L(Train): 0.1915024071931839; L(Test): 0.18963907659053802\n",
      "Epoch 903/1000: L(Train): 0.19427652657032013; L(Test): 0.18961133062839508\n",
      "Epoch 904/1000: L(Train): 0.1900377869606018; L(Test): 0.1892591118812561\n",
      "Epoch 905/1000: L(Train): 0.1926979422569275; L(Test): 0.189634770154953\n",
      "Epoch 906/1000: L(Train): 0.19341972470283508; L(Test): 0.18912911415100098\n",
      "Epoch 907/1000: L(Train): 0.1925317943096161; L(Test): 0.1893487274646759\n",
      "Epoch 908/1000: L(Train): 0.1949186772108078; L(Test): 0.18921932578086853\n",
      "Epoch 909/1000: L(Train): 0.19204549491405487; L(Test): 0.18947109580039978\n",
      "Epoch 910/1000: L(Train): 0.19226200878620148; L(Test): 0.18909095227718353\n",
      "Epoch 911/1000: L(Train): 0.19235438108444214; L(Test): 0.1891891062259674\n",
      "Epoch 912/1000: L(Train): 0.18870174884796143; L(Test): 0.18919485807418823\n",
      "Epoch 913/1000: L(Train): 0.19487592577934265; L(Test): 0.18917222321033478\n",
      "Epoch 914/1000: L(Train): 0.19208768010139465; L(Test): 0.18910270929336548\n",
      "Epoch 915/1000: L(Train): 0.19253720343112946; L(Test): 0.18928693234920502\n",
      "Epoch 916/1000: L(Train): 0.18946246802806854; L(Test): 0.1891607642173767\n",
      "Epoch 917/1000: L(Train): 0.1937480866909027; L(Test): 0.18892893195152283\n",
      "Epoch 918/1000: L(Train): 0.19059446454048157; L(Test): 0.18900059163570404\n",
      "Epoch 919/1000: L(Train): 0.19397468864917755; L(Test): 0.18909910321235657\n",
      "Epoch 920/1000: L(Train): 0.1889767348766327; L(Test): 0.18896545469760895\n",
      "Epoch 921/1000: L(Train): 0.19308717548847198; L(Test): 0.18900656700134277\n",
      "Epoch 922/1000: L(Train): 0.19093859195709229; L(Test): 0.18898765742778778\n",
      "Epoch 923/1000: L(Train): 0.18981224298477173; L(Test): 0.1889888197183609\n",
      "Epoch 924/1000: L(Train): 0.19253657758235931; L(Test): 0.18882650136947632\n",
      "Epoch 925/1000: L(Train): 0.19281278550624847; L(Test): 0.18890562653541565\n",
      "Epoch 926/1000: L(Train): 0.19192032516002655; L(Test): 0.18902869522571564\n",
      "Epoch 927/1000: L(Train): 0.19304904341697693; L(Test): 0.1890602558851242\n",
      "Epoch 928/1000: L(Train): 0.1916155368089676; L(Test): 0.1889907419681549\n",
      "Epoch 929/1000: L(Train): 0.19205766916275024; L(Test): 0.18904957175254822\n",
      "Epoch 930/1000: L(Train): 0.19482073187828064; L(Test): 0.18891267478466034\n",
      "Epoch 931/1000: L(Train): 0.1913970559835434; L(Test): 0.18886584043502808\n",
      "Epoch 932/1000: L(Train): 0.19356843829154968; L(Test): 0.18903453648090363\n",
      "Epoch 933/1000: L(Train): 0.19545963406562805; L(Test): 0.18879587948322296\n",
      "Epoch 934/1000: L(Train): 0.19000457227230072; L(Test): 0.18879103660583496\n",
      "Epoch 935/1000: L(Train): 0.19506298005580902; L(Test): 0.1888454258441925\n",
      "Epoch 936/1000: L(Train): 0.1909017264842987; L(Test): 0.18903480470180511\n",
      "Epoch 937/1000: L(Train): 0.1910809874534607; L(Test): 0.18895117938518524\n",
      "Epoch 938/1000: L(Train): 0.19071809947490692; L(Test): 0.18886572122573853\n",
      "Epoch 939/1000: L(Train): 0.1938638836145401; L(Test): 0.18885579705238342\n",
      "Epoch 940/1000: L(Train): 0.1925361305475235; L(Test): 0.18886658549308777\n",
      "Epoch 941/1000: L(Train): 0.1914025843143463; L(Test): 0.1890338957309723\n",
      "Epoch 942/1000: L(Train): 0.19251056015491486; L(Test): 0.18890272080898285\n",
      "Epoch 943/1000: L(Train): 0.1911119669675827; L(Test): 0.18881765007972717\n",
      "Epoch 944/1000: L(Train): 0.19198033213615417; L(Test): 0.18884047865867615\n",
      "Epoch 945/1000: L(Train): 0.1936643421649933; L(Test): 0.18870232999324799\n",
      "Epoch 946/1000: L(Train): 0.18578767776489258; L(Test): 0.18893644213676453\n",
      "Epoch 947/1000: L(Train): 0.1927747130393982; L(Test): 0.18903270363807678\n",
      "Epoch 948/1000: L(Train): 0.19589348137378693; L(Test): 0.18889600038528442\n",
      "Epoch 949/1000: L(Train): 0.19529536366462708; L(Test): 0.18887324631214142\n",
      "Epoch 950/1000: L(Train): 0.19263802468776703; L(Test): 0.1888519823551178\n",
      "Epoch 951/1000: L(Train): 0.19216445088386536; L(Test): 0.18868976831436157\n",
      "Epoch 952/1000: L(Train): 0.19094690680503845; L(Test): 0.1886504590511322\n",
      "Epoch 953/1000: L(Train): 0.19263990223407745; L(Test): 0.1888343095779419\n",
      "Epoch 954/1000: L(Train): 0.19199822843074799; L(Test): 0.188777893781662\n",
      "Epoch 955/1000: L(Train): 0.19013337790966034; L(Test): 0.18866096436977386\n",
      "Epoch 956/1000: L(Train): 0.19310353696346283; L(Test): 0.18863902986049652\n",
      "Epoch 957/1000: L(Train): 0.19043266773223877; L(Test): 0.18864265084266663\n",
      "Epoch 958/1000: L(Train): 0.19180205464363098; L(Test): 0.18859277665615082\n",
      "Epoch 959/1000: L(Train): 0.19208824634552002; L(Test): 0.18863317370414734\n",
      "Epoch 960/1000: L(Train): 0.19210746884346008; L(Test): 0.18868228793144226\n",
      "Epoch 961/1000: L(Train): 0.19396498799324036; L(Test): 0.1886410415172577\n",
      "Epoch 962/1000: L(Train): 0.1926591396331787; L(Test): 0.1887599527835846\n",
      "Epoch 963/1000: L(Train): 0.19357432425022125; L(Test): 0.1886993646621704\n",
      "Epoch 964/1000: L(Train): 0.1889958381652832; L(Test): 0.18875983357429504\n",
      "Epoch 965/1000: L(Train): 0.1895633488893509; L(Test): 0.18872006237506866\n",
      "Epoch 966/1000: L(Train): 0.1929486095905304; L(Test): 0.18864712119102478\n",
      "Epoch 967/1000: L(Train): 0.19144149124622345; L(Test): 0.18872784078121185\n",
      "Epoch 968/1000: L(Train): 0.19016197323799133; L(Test): 0.18891747295856476\n",
      "Epoch 969/1000: L(Train): 0.19236153364181519; L(Test): 0.18867167830467224\n",
      "Epoch 970/1000: L(Train): 0.19024643301963806; L(Test): 0.1885535717010498\n",
      "Epoch 971/1000: L(Train): 0.19243527948856354; L(Test): 0.1887405961751938\n",
      "Epoch 972/1000: L(Train): 0.19067203998565674; L(Test): 0.18890434503555298\n",
      "Epoch 973/1000: L(Train): 0.19348707795143127; L(Test): 0.18971474468708038\n",
      "Epoch 974/1000: L(Train): 0.1910521239042282; L(Test): 0.1888258010149002\n",
      "Epoch 975/1000: L(Train): 0.19163791835308075; L(Test): 0.1895092874765396\n",
      "Epoch 976/1000: L(Train): 0.1927746832370758; L(Test): 0.18942828476428986\n",
      "Epoch 977/1000: L(Train): 0.19456221163272858; L(Test): 0.188986137509346\n",
      "Epoch 978/1000: L(Train): 0.19147458672523499; L(Test): 0.19003936648368835\n",
      "Epoch 979/1000: L(Train): 0.19445784389972687; L(Test): 0.19019527733325958\n",
      "Epoch 980/1000: L(Train): 0.19322679936885834; L(Test): 0.1897924244403839\n",
      "Epoch 981/1000: L(Train): 0.19350223243236542; L(Test): 0.18929031491279602\n",
      "Epoch 982/1000: L(Train): 0.19588088989257812; L(Test): 0.189880833029747\n",
      "Epoch 983/1000: L(Train): 0.19307363033294678; L(Test): 0.18937727808952332\n",
      "Epoch 984/1000: L(Train): 0.19271446764469147; L(Test): 0.18934814631938934\n",
      "Epoch 985/1000: L(Train): 0.1907450258731842; L(Test): 0.18938139081001282\n",
      "Epoch 986/1000: L(Train): 0.19398243725299835; L(Test): 0.18889567255973816\n",
      "Epoch 987/1000: L(Train): 0.1927897036075592; L(Test): 0.18971890211105347\n",
      "Epoch 988/1000: L(Train): 0.19176918268203735; L(Test): 0.18882185220718384\n",
      "Epoch 989/1000: L(Train): 0.19136135280132294; L(Test): 0.1895335465669632\n",
      "Epoch 990/1000: L(Train): 0.19360335171222687; L(Test): 0.18882809579372406\n",
      "Epoch 991/1000: L(Train): 0.19036376476287842; L(Test): 0.1892799586057663\n",
      "Epoch 992/1000: L(Train): 0.19391196966171265; L(Test): 0.18934698402881622\n",
      "Epoch 993/1000: L(Train): 0.19084428250789642; L(Test): 0.18852511048316956\n",
      "Epoch 994/1000: L(Train): 0.19191890954971313; L(Test): 0.18878167867660522\n",
      "Epoch 995/1000: L(Train): 0.19389890134334564; L(Test): 0.18864186108112335\n",
      "Epoch 996/1000: L(Train): 0.19234497845172882; L(Test): 0.18873417377471924\n",
      "Epoch 997/1000: L(Train): 0.1865701526403427; L(Test): 0.188790962100029\n",
      "Epoch 998/1000: L(Train): 0.19271238148212433; L(Test): 0.1885818988084793\n",
      "Epoch 999/1000: L(Train): 0.19031696021556854; L(Test): 0.1887858510017395\n",
      "Epoch 1000/1000: L(Train): 0.19133006036281586; L(Test): 0.18875978887081146\n"
     ]
    }
   ],
   "source": [
    "gru = training(\n",
    "    gru=gru,\n",
    "    optimizer=optimizer,\n",
    "    dataset_train=dataset,\n",
    "    dataset_test=dataset,\n",
    "    epochs=epochs,\n",
    "    )\n",
    "\n",
    "torch.save(gru.state_dict(), path_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_agent = setup_agent_gru(path_gru)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot SPICE against benchmark models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_stay[t+1] = 0.085 1 + 0.712 value_stay[t] + 0.455 reward + 0.085 harvest_duration + -0.287 value_stay*harvest_duration + 0.455 reward*harvest_duration + 0.085 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting\n",
    "participant_id = 7\n",
    "\n",
    "estimator.print_spice_model(participant_id)\n",
    "\n",
    "agents = {\n",
    "    'mvt': mvt_agent,\n",
    "    'rnn': estimator.rnn_agent,\n",
    "    'spice': estimator.spice_agent,\n",
    "    'gru': gru_agent,\n",
    "}\n",
    "\n",
    "fig, axs = plot_session(agents, dataset.xs[participant_id], signals_to_plot=[])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "spice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
