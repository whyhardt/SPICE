{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tf7jlYw4NA0v",
    "outputId": "0969ca34-675d-422e-cbfb-7387d9bcd8ad"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/whyhardt/SPICE.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oXIbg826NS5i",
    "outputId": "3825864a-cb2d-4ad5-f2e5-79a4e81dfc3e"
   },
   "outputs": [],
   "source": [
    "# !pip install -e SPICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "f0uVlABYznR5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from spice import SpiceEstimator, SpiceConfig, convert_dataset, BaseRNN, plot_session\n",
    "\n",
    "# For custom RNN\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data first with the `convert_dataset` method. This method returns a `SpiceDataset` object which we can use right away "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: torch.Size([1997, 112, 9])\n",
      "Number of participants: 250\n",
      "Number of actions in dataset: 2\n",
      "Number of additional inputs: 2\n"
     ]
    }
   ],
   "source": [
    "# Load your data\n",
    "file = '../data/bustamante2023/bustamante2023_processed.csv'\n",
    "dataset = convert_dataset(\n",
    "    file = file,\n",
    "    df_participant_id='subject_id',\n",
    "    df_choice='decision',\n",
    "    df_reward='reward',\n",
    "    df_block='overall_round',\n",
    "    additional_inputs=['harvest_duration', 'travel_duration'],\n",
    "    timeshift_additional_inputs=False,\n",
    "    )\n",
    "\n",
    "# structure of dataset:\n",
    "# dataset has two main attributes: xs -> inputs; ys -> targets (next action)\n",
    "# shape: (n_participants*n_blocks*n_experiments, n_timesteps, features)\n",
    "# features are (n_actions * action, n_actions * reward, n_additional_inputs * additional_input, block_number, experiment_id, participant_id)\n",
    "\n",
    "# in order to set up the participant embedding we have to compute the number of unique participants in our data \n",
    "# to get the number of participants n_participants we do:\n",
    "n_participants = len(dataset.xs[..., -1].unique())\n",
    "\n",
    "print(f\"Shape of dataset: {dataset.xs.shape}\")\n",
    "print(f\"Number of participants: {n_participants}\")\n",
    "n_actions = dataset.ys.shape[-1]\n",
    "print(f\"Number of actions in dataset: {n_actions}\")\n",
    "print(f\"Number of additional inputs: {dataset.xs.shape[-1]-2*n_actions-3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.7561,    nan, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.6859,    nan, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 1.0000,    nan, 0.0510, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.7515,    nan, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.6407,    nan, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.5662,    nan, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 1.0000,    nan, 0.0510, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.8706,    nan, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [1.0000, 0.0000, 0.7226,    nan, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 1.0000,    nan, 0.0510, 2.0000, 8.3333, 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect dataset\n",
    "dataset.xs[0, :10, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPICE Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to define the configuration for SPICE with a `SpiceConfig` object.\n",
    "\n",
    "The `SpiceConfig` takes as arguments \n",
    "1. `library_setup (dict)`: Defining the variable names of each module.\n",
    "2. `memory_state (dict)`: Defining the memory state variables and their initial values.\n",
    "3. `states_in_logit (list)`: Defining which of the memory state variables are used later for the logit computation. This is necessary for some background processes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spice_config = SpiceConfig(\n",
    "    library_setup={\n",
    "        'value_stay': ['reward', 'harvest_duration'],\n",
    "        'value_exit': ['travel_duration'],\n",
    "    },\n",
    "    \n",
    "    memory_state={\n",
    "            'value': 0.,\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we are going to define the SPICE model which is a child of the `BaseRNN` and `torch.nn.Module` class and takes as required arguments:\n",
    "1. `spice_config (SpiceConfig)`: previously defined SpiceConfig object\n",
    "2. `n_actions (int)`: number of possible actions in your dataset (including non-displayed ones if applicable).\n",
    "3. `n_participants (int)`: number of participants in your dataset.\n",
    "\n",
    "As usual for a `torch.nn.Module` we have to define at least the `__init__` method and the `forward` method.\n",
    "The `forward` method gets called when computing a forward pass through the model and takes as inputs `(inputs (SpiceDataset.xs), prev_state (dict, default: None), batch_first (bool, default: False))` and returns `(logits (torch.Tensor, shape: (n_participants*n_blocks*n_experiments, timesteps, n_actions)), updated_state (dict))`. Two necessary method calls inside the forward pass are:\n",
    "1. `self.init_forward_pass(inputs, prev_state, batch_first) -> SpiceSignals`: returns a `SpiceSignals` object which carries all relevant information already processed.\n",
    "2. `self.post_forward_pass(SpiceSignals, batch_first) -> SpiceSignals`: does some re-arranging of the logits to adhere to `batch_first`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z0kOR2Qgz0FZ"
   },
   "outputs": [],
   "source": [
    "class SPICERNN(BaseRNN):\n",
    "    \n",
    "    def __init__(self, spice_config, **kwargs):\n",
    "        super().__init__(spice_config=spice_config, **kwargs)\n",
    "        \n",
    "        # participant embedding\n",
    "        self.participant_embedding = self.setup_embedding(num_embeddings=n_participants, embedding_size=self.embedding_size, dropout=0.)\n",
    "        \n",
    "        # computing summary statistics as additional inputs to modules\n",
    "        # reward_volatility = ... --> Tracking the start reward variance\n",
    "        # cum_reward = ... --> Basic reward module (last n rewards) // block vs patch vs last n timesteps\n",
    "        # depletion_rate = ... --> reward differences\n",
    "        # cum_time_block = ... -->\n",
    "        # cum_time_patch = ... --> \n",
    "        # ...\n",
    "        \n",
    "        # include also effort types --> start with just low effort\n",
    "        \n",
    "        # set up the submodules\n",
    "        self.setup_module(key_module='value_reward', input_size=2+self.embedding_size)\n",
    "        self.setup_module(key_module='value_depletion', input_size=2+self.embedding_size)\n",
    "        self.setup_module(key_module='value_choice', input_size=2+self.embedding_size)\n",
    "        \n",
    "        # logit module that tracks overall time and scales different mechanisms\n",
    "        # logit-module <- f(value_reward, value_depletion, value_choice, overall_time)\n",
    "        \n",
    "        # self.setup_module(key_module='value_exit', input_size=1+self.embedding_size)\n",
    "        \n",
    "    def forward(self, inputs, prev_state, batch_first=False):\n",
    "        \n",
    "        spice_signals = self.init_forward_pass(inputs, prev_state, batch_first)\n",
    "        \n",
    "        harvest_duration = spice_signals.additional_inputs[..., 0].unsqueeze(-1).repeat(1, 1, self.n_actions)\n",
    "        travel_duration = spice_signals.additional_inputs[..., 1].unsqueeze(-1).repeat(1, 1, self.n_actions)\n",
    "        rewards_chosen = (spice_signals.actions * spice_signals.rewards).sum(dim=-1, keepdim=True).repeat(1, 1, self.n_actions)\n",
    "        \n",
    "        # time-invariant participant features\n",
    "        participant_embeddings = self.participant_embedding(spice_signals.participant_ids)\n",
    "        mask_stay = torch.tensor((1,0)).reshape(1, self.n_actions).repeat(rewards_chosen.shape[1], 1)\n",
    "        mask_exit = torch.tensor((0,1)).reshape(1, self.n_actions).repeat(rewards_chosen.shape[1], 1)\n",
    "        \n",
    "        for timestep in spice_signals.timesteps:\n",
    "            \n",
    "            # update chosen value\n",
    "            self.call_module(\n",
    "                key_module='value_stay',\n",
    "                key_state='value',\n",
    "                action_mask=mask_stay,\n",
    "                inputs=(\n",
    "                    rewards_chosen[timestep], \n",
    "                    harvest_duration[timestep], \n",
    "                    ),\n",
    "                participant_index=spice_signals.participant_ids,\n",
    "                participant_embedding=participant_embeddings,\n",
    "            )\n",
    "            \n",
    "            # update not chosen value\n",
    "            self.call_module(\n",
    "                key_module='value_exit',\n",
    "                key_state='value',\n",
    "                action_mask=mask_exit,\n",
    "                inputs=(\n",
    "                    travel_duration[timestep], \n",
    "                    ),\n",
    "                participant_index=spice_signals.participant_ids,\n",
    "                participant_embedding=participant_embeddings,\n",
    "            )\n",
    "            \n",
    "            # transform logits from item-space to action-space\n",
    "            spice_signals.logits[timestep] = self.state['value_reward'] + self.state['value_choice']\n",
    "            \n",
    "        spice_signals = self.post_forward_pass(spice_signals, batch_first)\n",
    "        \n",
    "        return spice_signals.logits, self.get_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's setup now the `SpiceEstimator` object and fit it to the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_spice = '../params/bustamante2023/spice_bustamante2023.pkl'\n",
    "estimator = SpiceEstimator(\n",
    "        # model paramaeters\n",
    "        rnn_class=SPICERNN,\n",
    "        spice_config=spice_config,\n",
    "        n_actions=2,\n",
    "        n_participants=n_participants,\n",
    "        n_experiments=1,\n",
    "        \n",
    "        # rnn training parameters\n",
    "        epochs=1000,\n",
    "        warmup_steps=200,\n",
    "        learning_rate=0.01,\n",
    "        \n",
    "        # sindy fitting parameters\n",
    "        # sindy fitting parameters\n",
    "        sindy_weight=0.1,\n",
    "        sindy_pruning_threshold=0.05,\n",
    "        sindy_pruning_frequency=1,\n",
    "        sindy_pruning_terms=1,\n",
    "        sindy_pruning_patience=100,\n",
    "        sindy_epochs=1000,\n",
    "        sindy_l2_lambda=0.0001,\n",
    "        sindy_library_polynomial_degree=2,\n",
    "        ensemble_size=1,\n",
    "        \n",
    "        # additional generalization parameters\n",
    "        batch_size=1024,\n",
    "        bagging=True,\n",
    "        scheduler=True,\n",
    "        \n",
    "        verbose=True,\n",
    "        save_path_spice=path_spice,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "id": "3EnmDiUMWq6e",
    "outputId": "e53b1bbd-4173-4d2c-bcdc-15832bc31bd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training on cpu...\n",
      "================================================================================\n",
      "\n",
      "Training the RNN...\n",
      "================================================================================\n",
      "Epoch 1/1000 --- L(Train): 0.5092973 --- L(Val, RNN): 0.3817756 --- L(Val, SINDy): 3.8043301 --- Time: 1.18s; --- Convergence: 8.09e-01; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.002 1 + 1.001 value_stay[t] + 0.002 reward + -0.0 harvest_duration + -0.0 value_stay^2 + 0.001 value_stay*reward + -0.001 value_stay*harvest_duration + 0.002 reward^2 + 0.004 reward*harvest_duration + -0.001 harvest_duration^2 \n",
      "value_exit[t+1] = 0.011 1 + 1.011 value_exit[t] + -0.01 travel_duration + 0.01 value_exit^2 + -0.009 value_exit*travel_duration + -0.009 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 2/1000 --- L(Train): 0.3793685 --- L(Val, RNN): 0.3679760 --- L(Val, SINDy): 2.1244578 --- Time: 0.84s; --- Convergence: 4.11e-01; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = -0.001 1 + 0.998 value_stay[t] + 0.005 reward + -0.004 harvest_duration + -0.001 value_stay^2 + -0.0 value_stay*reward + -0.005 value_stay*harvest_duration + 0.005 reward^2 + 0.008 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = 0.005 1 + 1.019 value_exit[t] + -0.002 travel_duration + 0.003 value_exit^2 + -0.016 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 3/1000 --- L(Train): 0.3648787 --- L(Val, RNN): 0.3639058 --- L(Val, SINDy): 2.9112027 --- Time: 0.85s; --- Convergence: 2.08e-01; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.005 1 + 1.001 value_stay[t] + 0.011 reward + 0.003 harvest_duration + -0.001 value_stay^2 + 0.002 value_stay*reward + -0.002 value_stay*harvest_duration + 0.011 reward^2 + 0.015 reward*harvest_duration + 0.001 harvest_duration^2 \n",
      "value_exit[t+1] = -0.003 1 + 1.026 value_exit[t] + -0.003 travel_duration + -0.005 value_exit^2 + -0.016 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 4/1000 --- L(Train): 0.3651667 --- L(Val, RNN): 0.3619312 --- L(Val, SINDy): 2.7944717 --- Time: 0.91s; --- Convergence: 1.05e-01; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.001 1 + 0.996 value_stay[t] + 0.009 reward + -0.001 harvest_duration + -0.006 value_stay^2 + -0.003 value_stay*reward + -0.007 value_stay*harvest_duration + 0.01 reward^2 + 0.012 reward*harvest_duration + -0.003 harvest_duration^2 \n",
      "value_exit[t+1] = -0.011 1 + 1.035 value_exit[t] + -0.005 travel_duration + -0.013 value_exit^2 + -0.014 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 5/1000 --- L(Train): 0.3651251 --- L(Val, RNN): 0.3609214 --- L(Val, SINDy): 2.1436307 --- Time: 0.90s; --- Convergence: 5.29e-02; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = -0.002 1 + 0.99 value_stay[t] + 0.009 reward + -0.004 harvest_duration + -0.011 value_stay^2 + -0.008 value_stay*reward + -0.013 value_stay*harvest_duration + 0.011 reward^2 + 0.012 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.018 1 + 1.043 value_exit[t] + -0.001 travel_duration + -0.021 value_exit^2 + -0.019 value_exit*travel_duration + 0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 6/1000 --- L(Train): 0.3547129 --- L(Val, RNN): 0.3601073 --- L(Val, SINDy): 2.4822361 --- Time: 1.04s; --- Convergence: 2.69e-02; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.0 1 + 0.989 value_stay[t] + 0.013 reward + -0.001 harvest_duration + -0.014 value_stay^2 + -0.008 value_stay*reward + -0.014 value_stay*harvest_duration + 0.016 reward^2 + 0.017 reward*harvest_duration + -0.003 harvest_duration^2 \n",
      "value_exit[t+1] = -0.022 1 + 1.046 value_exit[t] + -0.001 travel_duration + -0.025 value_exit^2 + -0.019 value_exit*travel_duration + -0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 7/1000 --- L(Train): 0.3625765 --- L(Val, RNN): 0.3593431 --- L(Val, SINDy): 2.3013320 --- Time: 0.92s; --- Convergence: 1.38e-02; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.003 1 + 0.987 value_stay[t] + 0.018 reward + 0.001 harvest_duration + -0.019 value_stay^2 + -0.009 value_stay*reward + -0.016 value_stay*harvest_duration + 0.022 reward^2 + 0.021 reward*harvest_duration + -0.001 harvest_duration^2 \n",
      "value_exit[t+1] = -0.022 1 + 1.046 value_exit[t] + -0.003 travel_duration + -0.024 value_exit^2 + -0.019 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 8/1000 --- L(Train): 0.3621267 --- L(Val, RNN): 0.3586418 --- L(Val, SINDy): 1.9201562 --- Time: 0.93s; --- Convergence: 7.26e-03; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.002 1 + 0.981 value_stay[t] + 0.019 reward + -0.0 harvest_duration + -0.024 value_stay^2 + -0.014 value_stay*reward + -0.022 value_stay*harvest_duration + 0.026 reward^2 + 0.023 reward*harvest_duration + -0.002 harvest_duration^2 \n",
      "value_exit[t+1] = -0.019 1 + 1.042 value_exit[t] + -0.003 travel_duration + -0.02 value_exit^2 + -0.02 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 9/1000 --- L(Train): 0.3643481 --- L(Val, RNN): 0.3580105 --- L(Val, SINDy): 1.7091841 --- Time: 1.04s; --- Convergence: 3.95e-03; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = -0.0 1 + 0.976 value_stay[t] + 0.021 reward + -0.002 harvest_duration + -0.031 value_stay^2 + -0.019 value_stay*reward + -0.028 value_stay*harvest_duration + 0.029 reward^2 + 0.025 reward*harvest_duration + -0.004 harvest_duration^2 \n",
      "value_exit[t+1] = -0.014 1 + 1.038 value_exit[t] + -0.003 travel_duration + -0.016 value_exit^2 + -0.022 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 10/1000 --- L(Train): 0.3589939 --- L(Val, RNN): 0.3574351 --- L(Val, SINDy): 1.7028474 --- Time: 1.20s; --- Convergence: 2.26e-03; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = -0.001 1 + 0.971 value_stay[t] + 0.023 reward + -0.003 harvest_duration + -0.036 value_stay^2 + -0.024 value_stay*reward + -0.033 value_stay*harvest_duration + 0.033 reward^2 + 0.027 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.01 1 + 1.033 value_exit[t] + -0.003 travel_duration + -0.011 value_exit^2 + -0.022 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 11/1000 --- L(Train): 0.3504592 --- L(Val, RNN): 0.3569107 --- L(Val, SINDy): 1.6265451 --- Time: 1.02s; --- Convergence: 1.39e-03; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.002 1 + 0.967 value_stay[t] + 0.028 reward + -0.0 harvest_duration + -0.042 value_stay^2 + -0.026 value_stay*reward + -0.037 value_stay*harvest_duration + 0.039 reward^2 + 0.032 reward*harvest_duration + -0.002 harvest_duration^2 \n",
      "value_exit[t+1] = -0.004 1 + 1.028 value_exit[t] + -0.006 travel_duration + -0.006 value_exit^2 + -0.022 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 12/1000 --- L(Train): 0.3554625 --- L(Val, RNN): 0.3564256 --- L(Val, SINDy): 1.4239779 --- Time: 0.95s; --- Convergence: 9.39e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.004 1 + 0.962 value_stay[t] + 0.033 reward + 0.001 harvest_duration + -0.05 value_stay^2 + -0.031 value_stay*reward + -0.042 value_stay*harvest_duration + 0.045 reward^2 + 0.036 reward*harvest_duration + -0.001 harvest_duration^2 \n",
      "value_exit[t+1] = 0.001 1 + 1.023 value_exit[t] + -0.005 travel_duration + -0.001 value_exit^2 + -0.025 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 13/1000 --- L(Train): 0.3545506 --- L(Val, RNN): 0.3559832 --- L(Val, SINDy): 1.2815711 --- Time: 0.86s; --- Convergence: 6.91e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.004 1 + 0.956 value_stay[t] + 0.035 reward + 0.001 harvest_duration + -0.057 value_stay^2 + -0.037 value_stay*reward + -0.049 value_stay*harvest_duration + 0.049 reward^2 + 0.039 reward*harvest_duration + -0.001 harvest_duration^2 \n",
      "value_exit[t+1] = 0.006 1 + 1.018 value_exit[t] + -0.004 travel_duration + 0.003 value_exit^2 + -0.027 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 14/1000 --- L(Train): 0.3567459 --- L(Val, RNN): 0.3555698 --- L(Val, SINDy): 1.2378467 --- Time: 0.87s; --- Convergence: 5.52e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.004 1 + 0.949 value_stay[t] + 0.037 reward + -0.001 harvest_duration + -0.065 value_stay^2 + -0.043 value_stay*reward + -0.056 value_stay*harvest_duration + 0.052 reward^2 + 0.041 reward*harvest_duration + -0.003 harvest_duration^2 \n",
      "value_exit[t+1] = 0.011 1 + 1.014 value_exit[t] + -0.005 travel_duration + 0.007 value_exit^2 + -0.028 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 15/1000 --- L(Train): 0.3576899 --- L(Val, RNN): 0.3551616 --- L(Val, SINDy): 1.1921587 --- Time: 0.91s; --- Convergence: 4.80e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.003 1 + 0.942 value_stay[t] + 0.038 reward + -0.002 harvest_duration + -0.074 value_stay^2 + -0.05 value_stay*reward + -0.064 value_stay*harvest_duration + 0.055 reward^2 + 0.042 reward*harvest_duration + -0.004 harvest_duration^2 \n",
      "value_exit[t+1] = 0.014 1 + 1.01 value_exit[t] + -0.007 travel_duration + 0.01 value_exit^2 + -0.027 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 16/1000 --- L(Train): 0.3524729 --- L(Val, RNN): 0.3547637 --- L(Val, SINDy): 1.1914911 --- Time: 1.22s; --- Convergence: 4.39e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.004 1 + 0.935 value_stay[t] + 0.04 reward + -0.003 harvest_duration + -0.082 value_stay^2 + -0.058 value_stay*reward + -0.072 value_stay*harvest_duration + 0.059 reward^2 + 0.044 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = 0.017 1 + 1.007 value_exit[t] + -0.008 travel_duration + 0.014 value_exit^2 + -0.029 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 17/1000 --- L(Train): 0.3564253 --- L(Val, RNN): 0.3543943 --- L(Val, SINDy): 1.0955262 --- Time: 1.08s; --- Convergence: 4.04e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.006 1 + 0.927 value_stay[t] + 0.043 reward + -0.003 harvest_duration + -0.091 value_stay^2 + -0.066 value_stay*reward + -0.08 value_stay*harvest_duration + 0.063 reward^2 + 0.047 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = 0.02 1 + 1.004 value_exit[t] + -0.006 travel_duration + 0.016 value_exit^2 + -0.032 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 18/1000 --- L(Train): 0.3524169 --- L(Val, RNN): 0.3540142 --- L(Val, SINDy): 1.0033200 --- Time: 0.85s; --- Convergence: 3.92e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.008 1 + 0.918 value_stay[t] + 0.045 reward + -0.003 harvest_duration + -0.101 value_stay^2 + -0.075 value_stay*reward + -0.089 value_stay*harvest_duration + 0.067 reward^2 + 0.049 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = 0.02 1 + 1.001 value_exit[t] + -0.009 travel_duration + 0.019 value_exit^2 + -0.031 value_exit*travel_duration + -0.007 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 19/1000 --- L(Train): 0.3635609 --- L(Val, RNN): 0.3536410 --- L(Val, SINDy): 0.8910270 --- Time: 0.87s; --- Convergence: 3.83e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.009 1 + 0.91 value_stay[t] + 0.046 reward + -0.004 harvest_duration + -0.111 value_stay^2 + -0.084 value_stay*reward + -0.098 value_stay*harvest_duration + 0.07 reward^2 + 0.05 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = 0.021 1 + 0.999 value_exit[t] + -0.009 travel_duration + 0.021 value_exit^2 + -0.033 value_exit*travel_duration + -0.008 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 20/1000 --- L(Train): 0.3525239 --- L(Val, RNN): 0.3532653 --- L(Val, SINDy): 0.7905875 --- Time: 1.28s; --- Convergence: 3.79e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.011 1 + 0.901 value_stay[t] + 0.047 reward + -0.004 harvest_duration + -0.12 value_stay^2 + -0.093 value_stay*reward + -0.107 value_stay*harvest_duration + 0.072 reward^2 + 0.051 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = 0.021 1 + 0.997 value_exit[t] + -0.009 travel_duration + 0.023 value_exit^2 + -0.035 value_exit*travel_duration + -0.008 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 21/1000 --- L(Train): 0.3500310 --- L(Val, RNN): 0.3528956 --- L(Val, SINDy): 0.6875381 --- Time: 0.89s; --- Convergence: 3.74e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.014 1 + 0.893 value_stay[t] + 0.048 reward + -0.003 harvest_duration + -0.129 value_stay^2 + -0.103 value_stay*reward + -0.116 value_stay*harvest_duration + 0.075 reward^2 + 0.052 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = 0.021 1 + 0.996 value_exit[t] + -0.008 travel_duration + 0.025 value_exit^2 + -0.038 value_exit*travel_duration + -0.007 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 22/1000 --- L(Train): 0.3568775 --- L(Val, RNN): 0.3525400 --- L(Val, SINDy): 0.7034635 --- Time: 0.93s; --- Convergence: 3.65e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.017 1 + 0.884 value_stay[t] + 0.048 reward + -0.003 harvest_duration + -0.139 value_stay^2 + -0.113 value_stay*reward + -0.125 value_stay*harvest_duration + 0.077 reward^2 + 0.052 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = 0.02 1 + 0.994 value_exit[t] + -0.009 travel_duration + 0.027 value_exit^2 + -0.038 value_exit*travel_duration + -0.008 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 23/1000 --- L(Train): 0.3557719 --- L(Val, RNN): 0.3522120 --- L(Val, SINDy): 0.6536233 --- Time: 0.87s; --- Convergence: 3.47e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.021 1 + 0.875 value_stay[t] + 0.05 reward + -0.001 harvest_duration + -0.149 value_stay^2 + -0.122 value_stay*reward + -0.135 value_stay*harvest_duration + 0.08 reward^2 + 0.054 reward*harvest_duration + -0.003 harvest_duration^2 \n",
      "value_exit[t+1] = 0.017 1 + 0.994 value_exit[t] + -0.011 travel_duration + 0.028 value_exit^2 + -0.039 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 24/1000 --- L(Train): 0.3575087 --- L(Val, RNN): 0.3519222 --- L(Val, SINDy): 0.6478154 --- Time: 1.14s; --- Convergence: 3.18e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.023 1 + 0.865 value_stay[t] + 0.05 reward + -0.001 harvest_duration + -0.159 value_stay^2 + -0.133 value_stay*reward + -0.145 value_stay*harvest_duration + 0.082 reward^2 + 0.054 reward*harvest_duration + -0.003 harvest_duration^2 \n",
      "value_exit[t+1] = 0.015 1 + 0.993 value_exit[t] + -0.009 travel_duration + 0.029 value_exit^2 + -0.042 value_exit*travel_duration + -0.008 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 25/1000 --- L(Train): 0.3548397 --- L(Val, RNN): 0.3516714 --- L(Val, SINDy): 0.5933520 --- Time: 1.02s; --- Convergence: 2.84e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.026 1 + 0.855 value_stay[t] + 0.05 reward + -0.0 harvest_duration + -0.169 value_stay^2 + -0.143 value_stay*reward + -0.155 value_stay*harvest_duration + 0.084 reward^2 + 0.054 reward*harvest_duration + -0.002 harvest_duration^2 \n",
      "value_exit[t+1] = 0.012 1 + 0.992 value_exit[t] + -0.009 travel_duration + 0.03 value_exit^2 + -0.044 value_exit*travel_duration + -0.008 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 26/1000 --- L(Train): 0.3529368 --- L(Val, RNN): 0.3514187 --- L(Val, SINDy): 0.6199722 --- Time: 1.07s; --- Convergence: 2.69e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.031 1 + 0.845 value_stay[t] + 0.053 reward + 0.003 harvest_duration + -0.18 value_stay^2 + -0.154 value_stay*reward + -0.165 value_stay*harvest_duration + 0.088 reward^2 + 0.057 reward*harvest_duration + 0.001 harvest_duration^2 \n",
      "value_exit[t+1] = 0.007 1 + 0.993 value_exit[t] + -0.013 travel_duration + 0.031 value_exit^2 + -0.042 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 27/1000 --- L(Train): 0.3510900 --- L(Val, RNN): 0.3511938 --- L(Val, SINDy): 0.6046557 --- Time: 0.97s; --- Convergence: 2.47e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.031 1 + 0.834 value_stay[t] + 0.053 reward + 0.003 harvest_duration + -0.191 value_stay^2 + -0.166 value_stay*reward + -0.176 value_stay*harvest_duration + 0.091 reward^2 + 0.057 reward*harvest_duration + 0.001 harvest_duration^2 \n",
      "value_exit[t+1] = 0.004 1 + 0.993 value_exit[t] + -0.01 travel_duration + 0.032 value_exit^2 + -0.046 value_exit*travel_duration + -0.009 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 28/1000 --- L(Train): 0.3570781 --- L(Val, RNN): 0.3509254 --- L(Val, SINDy): 0.5531638 --- Time: 1.16s; --- Convergence: 2.58e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.032 1 + 0.824 value_stay[t] + 0.055 reward + 0.003 harvest_duration + -0.202 value_stay^2 + -0.176 value_stay*reward + -0.186 value_stay*harvest_duration + 0.095 reward^2 + 0.059 reward*harvest_duration + 0.001 harvest_duration^2 \n",
      "value_exit[t+1] = 0.001 1 + 0.993 value_exit[t] + -0.009 travel_duration + 0.033 value_exit^2 + -0.049 value_exit*travel_duration + -0.007 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 29/1000 --- L(Train): 0.3575248 --- L(Val, RNN): 0.3506469 --- L(Val, SINDy): 0.5077839 --- Time: 0.94s; --- Convergence: 2.68e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.036 1 + 0.815 value_stay[t] + 0.06 reward + 0.007 harvest_duration + -0.212 value_stay^2 + -0.186 value_stay*reward + -0.196 value_stay*harvest_duration + 0.102 reward^2 + 0.064 reward*harvest_duration + 0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.003 1 + 0.993 value_exit[t] + -0.009 travel_duration + 0.033 value_exit^2 + -0.05 value_exit*travel_duration + -0.008 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 30/1000 --- L(Train): 0.3566967 --- L(Val, RNN): 0.3503599 --- L(Val, SINDy): 0.4736639 --- Time: 1.04s; --- Convergence: 2.78e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.805 value_stay[t] + 0.067 reward + 0.011 harvest_duration + -0.223 value_stay^2 + -0.196 value_stay*reward + -0.205 value_stay*harvest_duration + 0.11 reward^2 + 0.07 reward*harvest_duration + 0.009 harvest_duration^2 \n",
      "value_exit[t+1] = -0.01 1 + 0.995 value_exit[t] + -0.012 travel_duration + 0.034 value_exit^2 + -0.048 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 31/1000 --- L(Train): 0.3506030 --- L(Val, RNN): 0.3500711 --- L(Val, SINDy): 0.4739839 --- Time: 0.95s; --- Convergence: 2.83e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.795 value_stay[t] + 0.071 reward + 0.013 harvest_duration + -0.235 value_stay^2 + -0.207 value_stay*reward + -0.216 value_stay*harvest_duration + 0.116 reward^2 + 0.075 reward*harvest_duration + 0.011 harvest_duration^2 \n",
      "value_exit[t+1] = -0.015 1 + 0.996 value_exit[t] + -0.014 travel_duration + 0.034 value_exit^2 + -0.047 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 32/1000 --- L(Train): 0.3505533 --- L(Val, RNN): 0.3497564 --- L(Val, SINDy): 0.4693975 --- Time: 1.28s; --- Convergence: 2.99e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.784 value_stay[t] + 0.075 reward + 0.013 harvest_duration + -0.247 value_stay^2 + -0.217 value_stay*reward + -0.227 value_stay*harvest_duration + 0.122 reward^2 + 0.079 reward*harvest_duration + 0.011 harvest_duration^2 \n",
      "value_exit[t+1] = -0.019 1 + 0.997 value_exit[t] + -0.014 travel_duration + 0.034 value_exit^2 + -0.048 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 33/1000 --- L(Train): 0.3538852 --- L(Val, RNN): 0.3494076 --- L(Val, SINDy): 0.4455453 --- Time: 0.85s; --- Convergence: 3.24e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.773 value_stay[t] + 0.078 reward + 0.011 harvest_duration + -0.258 value_stay^2 + -0.229 value_stay*reward + -0.238 value_stay*harvest_duration + 0.128 reward^2 + 0.082 reward*harvest_duration + 0.009 harvest_duration^2 \n",
      "value_exit[t+1] = -0.02 1 + 0.997 value_exit[t] + -0.011 travel_duration + 0.035 value_exit^2 + -0.053 value_exit*travel_duration + -0.009 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 34/1000 --- L(Train): 0.3527975 --- L(Val, RNN): 0.3490729 --- L(Val, SINDy): 0.4368377 --- Time: 0.91s; --- Convergence: 3.29e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.762 value_stay[t] + 0.083 reward + 0.01 harvest_duration + -0.27 value_stay^2 + -0.239 value_stay*reward + -0.249 value_stay*harvest_duration + 0.135 reward^2 + 0.087 reward*harvest_duration + 0.008 harvest_duration^2 \n",
      "value_exit[t+1] = -0.021 1 + 0.997 value_exit[t] + -0.008 travel_duration + 0.035 value_exit^2 + -0.056 value_exit*travel_duration + -0.007 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 35/1000 --- L(Train): 0.3520170 --- L(Val, RNN): 0.3487906 --- L(Val, SINDy): 0.4361921 --- Time: 1.14s; --- Convergence: 3.06e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.752 value_stay[t] + 0.091 reward + 0.013 harvest_duration + -0.282 value_stay^2 + -0.249 value_stay*reward + -0.259 value_stay*harvest_duration + 0.145 reward^2 + 0.095 reward*harvest_duration + 0.011 harvest_duration^2 \n",
      "value_exit[t+1] = -0.027 1 + 0.999 value_exit[t] + -0.01 travel_duration + 0.035 value_exit^2 + -0.054 value_exit*travel_duration + -0.009 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 36/1000 --- L(Train): 0.3490347 --- L(Val, RNN): 0.3484930 --- L(Val, SINDy): 0.4278950 --- Time: 1.15s; --- Convergence: 3.02e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.741 value_stay[t] + 0.095 reward + 0.012 harvest_duration + -0.294 value_stay^2 + -0.26 value_stay*reward + -0.271 value_stay*harvest_duration + 0.151 reward^2 + 0.099 reward*harvest_duration + 0.01 harvest_duration^2 \n",
      "value_exit[t+1] = -0.033 1 + 1.001 value_exit[t] + -0.014 travel_duration + 0.035 value_exit^2 + -0.052 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 37/1000 --- L(Train): 0.3562283 --- L(Val, RNN): 0.3481841 --- L(Val, SINDy): 0.4156739 --- Time: 0.89s; --- Convergence: 3.05e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.729 value_stay[t] + 0.096 reward + 0.007 harvest_duration + -0.307 value_stay^2 + -0.271 value_stay*reward + -0.283 value_stay*harvest_duration + 0.155 reward^2 + 0.1 reward*harvest_duration + 0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.036 1 + 1.003 value_exit[t] + -0.014 travel_duration + 0.035 value_exit^2 + -0.052 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 38/1000 --- L(Train): 0.3536738 --- L(Val, RNN): 0.3478884 --- L(Val, SINDy): 0.4162408 --- Time: 1.08s; --- Convergence: 3.01e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.718 value_stay[t] + 0.098 reward + 0.003 harvest_duration + -0.319 value_stay^2 + -0.282 value_stay*reward + -0.294 value_stay*harvest_duration + 0.159 reward^2 + 0.102 reward*harvest_duration + 0.001 harvest_duration^2 \n",
      "value_exit[t+1] = -0.039 1 + 1.004 value_exit[t] + -0.014 travel_duration + 0.035 value_exit^2 + -0.053 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 39/1000 --- L(Train): 0.3504746 --- L(Val, RNN): 0.3475860 --- L(Val, SINDy): 0.4062343 --- Time: 1.12s; --- Convergence: 3.01e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.707 value_stay[t] + 0.101 reward + 0.002 harvest_duration + -0.331 value_stay^2 + -0.293 value_stay*reward + -0.305 value_stay*harvest_duration + 0.164 reward^2 + 0.105 reward*harvest_duration + -0.0 harvest_duration^2 \n",
      "value_exit[t+1] = -0.04 1 + 1.004 value_exit[t] + -0.012 travel_duration + 0.035 value_exit^2 + -0.056 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 40/1000 --- L(Train): 0.3540649 --- L(Val, RNN): 0.3472151 --- L(Val, SINDy): 0.4050747 --- Time: 0.86s; --- Convergence: 3.36e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.697 value_stay[t] + 0.106 reward + 0.002 harvest_duration + -0.343 value_stay^2 + -0.303 value_stay*reward + -0.315 value_stay*harvest_duration + 0.171 reward^2 + 0.11 reward*harvest_duration + 0.0 harvest_duration^2 \n",
      "value_exit[t+1] = -0.04 1 + 1.004 value_exit[t] + -0.009 travel_duration + 0.036 value_exit^2 + -0.059 value_exit*travel_duration + -0.008 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 41/1000 --- L(Train): 0.3426217 --- L(Val, RNN): 0.3468423 --- L(Val, SINDy): 0.3944792 --- Time: 0.89s; --- Convergence: 3.54e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.686 value_stay[t] + 0.109 reward + 0.002 harvest_duration + -0.355 value_stay^2 + -0.314 value_stay*reward + -0.326 value_stay*harvest_duration + 0.176 reward^2 + 0.113 reward*harvest_duration + 0.0 harvest_duration^2 \n",
      "value_exit[t+1] = -0.043 1 + 1.005 value_exit[t] + -0.009 travel_duration + 0.036 value_exit^2 + -0.06 value_exit*travel_duration + -0.008 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 42/1000 --- L(Train): 0.3422602 --- L(Val, RNN): 0.3465401 --- L(Val, SINDy): 0.3996658 --- Time: 0.86s; --- Convergence: 3.28e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.675 value_stay[t] + 0.11 reward + -0.0 harvest_duration + -0.367 value_stay^2 + -0.326 value_stay*reward + -0.337 value_stay*harvest_duration + 0.179 reward^2 + 0.114 reward*harvest_duration + -0.002 harvest_duration^2 \n",
      "value_exit[t+1] = -0.047 1 + 1.007 value_exit[t] + -0.011 travel_duration + 0.035 value_exit^2 + -0.059 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 43/1000 --- L(Train): 0.3462494 --- L(Val, RNN): 0.3460844 --- L(Val, SINDy): 0.3920983 --- Time: 0.92s; --- Convergence: 3.92e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.664 value_stay[t] + 0.11 reward + -0.002 harvest_duration + -0.379 value_stay^2 + -0.338 value_stay*reward + -0.349 value_stay*harvest_duration + 0.182 reward^2 + 0.114 reward*harvest_duration + -0.004 harvest_duration^2 \n",
      "value_exit[t+1] = -0.052 1 + 1.009 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.058 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 44/1000 --- L(Train): 0.3527253 --- L(Val, RNN): 0.3457117 --- L(Val, SINDy): 0.3909274 --- Time: 1.11s; --- Convergence: 3.82e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.653 value_stay[t] + 0.112 reward + -0.003 harvest_duration + -0.391 value_stay^2 + -0.349 value_stay*reward + -0.359 value_stay*harvest_duration + 0.185 reward^2 + 0.116 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.055 1 + 1.01 value_exit[t] + -0.014 travel_duration + 0.035 value_exit^2 + -0.057 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 45/1000 --- L(Train): 0.3512395 --- L(Val, RNN): 0.3453275 --- L(Val, SINDy): 0.3882940 --- Time: 1.22s; --- Convergence: 3.83e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.644 value_stay[t] + 0.113 reward + -0.004 harvest_duration + -0.401 value_stay^2 + -0.359 value_stay*reward + -0.369 value_stay*harvest_duration + 0.188 reward^2 + 0.117 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.058 1 + 1.012 value_exit[t] + -0.015 travel_duration + 0.035 value_exit^2 + -0.057 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 46/1000 --- L(Train): 0.3444504 --- L(Val, RNN): 0.3449175 --- L(Val, SINDy): 0.3779397 --- Time: 1.33s; --- Convergence: 3.97e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.635 value_stay[t] + 0.114 reward + -0.004 harvest_duration + -0.411 value_stay^2 + -0.368 value_stay*reward + -0.378 value_stay*harvest_duration + 0.191 reward^2 + 0.119 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.06 1 + 1.012 value_exit[t] + -0.015 travel_duration + 0.035 value_exit^2 + -0.058 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 47/1000 --- L(Train): 0.3441795 --- L(Val, RNN): 0.3444341 --- L(Val, SINDy): 0.3814792 --- Time: 1.07s; --- Convergence: 4.40e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.626 value_stay[t] + 0.115 reward + -0.005 harvest_duration + -0.42 value_stay^2 + -0.377 value_stay*reward + -0.386 value_stay*harvest_duration + 0.193 reward^2 + 0.119 reward*harvest_duration + -0.007 harvest_duration^2 \n",
      "value_exit[t+1] = -0.06 1 + 1.012 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.06 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 48/1000 --- L(Train): 0.3467800 --- L(Val, RNN): 0.3439369 --- L(Val, SINDy): 0.3791466 --- Time: 0.95s; --- Convergence: 4.69e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.617 value_stay[t] + 0.114 reward + -0.006 harvest_duration + -0.429 value_stay^2 + -0.387 value_stay*reward + -0.395 value_stay*harvest_duration + 0.194 reward^2 + 0.118 reward*harvest_duration + -0.008 harvest_duration^2 \n",
      "value_exit[t+1] = -0.06 1 + 1.012 value_exit[t] + -0.011 travel_duration + 0.035 value_exit^2 + -0.063 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 49/1000 --- L(Train): 0.3483420 --- L(Val, RNN): 0.3434385 --- L(Val, SINDy): 0.3782424 --- Time: 1.11s; --- Convergence: 4.84e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.608 value_stay[t] + 0.115 reward + -0.004 harvest_duration + -0.438 value_stay^2 + -0.396 value_stay*reward + -0.404 value_stay*harvest_duration + 0.196 reward^2 + 0.119 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.061 1 + 1.012 value_exit[t] + -0.01 travel_duration + 0.035 value_exit^2 + -0.064 value_exit*travel_duration + -0.009 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 50/1000 --- L(Train): 0.3501617 --- L(Val, RNN): 0.3428674 --- L(Val, SINDy): 0.3696032 --- Time: 1.05s; --- Convergence: 5.27e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.6 value_stay[t] + 0.117 reward + -0.002 harvest_duration + -0.447 value_stay^2 + -0.405 value_stay*reward + -0.412 value_stay*harvest_duration + 0.199 reward^2 + 0.121 reward*harvest_duration + -0.004 harvest_duration^2 \n",
      "value_exit[t+1] = -0.063 1 + 1.013 value_exit[t] + -0.011 travel_duration + 0.035 value_exit^2 + -0.065 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 51/1000 --- L(Train): 0.3495021 --- L(Val, RNN): 0.3423029 --- L(Val, SINDy): 0.3668642 --- Time: 1.15s; --- Convergence: 5.46e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.05 1 + 0.592 value_stay[t] + 0.119 reward + 0.002 harvest_duration + -0.454 value_stay^2 + -0.412 value_stay*reward + -0.418 value_stay*harvest_duration + 0.204 reward^2 + 0.123 reward*harvest_duration + -0.0 harvest_duration^2 \n",
      "value_exit[t+1] = -0.066 1 + 1.014 value_exit[t] + -0.012 travel_duration + 0.035 value_exit^2 + -0.064 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 52/1000 --- L(Train): 0.3510835 --- L(Val, RNN): 0.3417113 --- L(Val, SINDy): 0.3673845 --- Time: 0.87s; --- Convergence: 5.69e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.053 1 + 0.585 value_stay[t] + 0.122 reward + 0.005 harvest_duration + -0.46 value_stay^2 + -0.418 value_stay*reward + -0.424 value_stay*harvest_duration + 0.208 reward^2 + 0.126 reward*harvest_duration + 0.003 harvest_duration^2 \n",
      "value_exit[t+1] = -0.068 1 + 1.015 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.064 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 53/1000 --- L(Train): 0.3417630 --- L(Val, RNN): 0.3410207 --- L(Val, SINDy): 0.3655974 --- Time: 1.10s; --- Convergence: 6.30e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.056 1 + 0.579 value_stay[t] + 0.127 reward + 0.008 harvest_duration + -0.464 value_stay^2 + -0.422 value_stay*reward + -0.429 value_stay*harvest_duration + 0.215 reward^2 + 0.131 reward*harvest_duration + 0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.069 1 + 1.015 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.065 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 54/1000 --- L(Train): 0.3466619 --- L(Val, RNN): 0.3402878 --- L(Val, SINDy): 0.3620326 --- Time: 1.15s; --- Convergence: 6.81e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.06 1 + 0.575 value_stay[t] + 0.133 reward + 0.012 harvest_duration + -0.465 value_stay^2 + -0.422 value_stay*reward + -0.432 value_stay*harvest_duration + 0.224 reward^2 + 0.137 reward*harvest_duration + 0.01 harvest_duration^2 \n",
      "value_exit[t+1] = -0.07 1 + 1.015 value_exit[t] + -0.012 travel_duration + 0.035 value_exit^2 + -0.066 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 55/1000 --- L(Train): 0.3463366 --- L(Val, RNN): 0.3394898 --- L(Val, SINDy): 0.3630628 --- Time: 1.21s; --- Convergence: 7.40e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.062 1 + 0.573 value_stay[t] + 0.141 reward + 0.015 harvest_duration + -0.462 value_stay^2 + -0.419 value_stay*reward + -0.433 value_stay*harvest_duration + 0.233 reward^2 + 0.145 reward*harvest_duration + 0.013 harvest_duration^2 \n",
      "value_exit[t+1] = -0.07 1 + 1.015 value_exit[t] + -0.011 travel_duration + 0.035 value_exit^2 + -0.067 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 56/1000 --- L(Train): 0.3468562 --- L(Val, RNN): 0.3387275 --- L(Val, SINDy): 0.3614927 --- Time: 1.08s; --- Convergence: 7.51e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.061 1 + 0.572 value_stay[t] + 0.147 reward + 0.014 harvest_duration + -0.457 value_stay^2 + -0.414 value_stay*reward + -0.433 value_stay*harvest_duration + 0.243 reward^2 + 0.151 reward*harvest_duration + 0.012 harvest_duration^2 \n",
      "value_exit[t+1] = -0.071 1 + 1.016 value_exit[t] + -0.012 travel_duration + 0.035 value_exit^2 + -0.068 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 57/1000 --- L(Train): 0.3445237 --- L(Val, RNN): 0.3378399 --- L(Val, SINDy): 0.3604084 --- Time: 0.96s; --- Convergence: 8.19e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.057 1 + 0.57 value_stay[t] + 0.153 reward + 0.01 harvest_duration + -0.45 value_stay^2 + -0.407 value_stay*reward + -0.432 value_stay*harvest_duration + 0.254 reward^2 + 0.157 reward*harvest_duration + 0.008 harvest_duration^2 \n",
      "value_exit[t+1] = -0.073 1 + 1.016 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.068 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 58/1000 --- L(Train): 0.3453823 --- L(Val, RNN): 0.3368942 --- L(Val, SINDy): 0.3605940 --- Time: 0.89s; --- Convergence: 8.83e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.055 1 + 0.573 value_stay[t] + 0.162 reward + 0.009 harvest_duration + -0.44 value_stay^2 + -0.397 value_stay*reward + -0.426 value_stay*harvest_duration + 0.266 reward^2 + 0.166 reward*harvest_duration + 0.007 harvest_duration^2 \n",
      "value_exit[t+1] = -0.074 1 + 1.016 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.068 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 59/1000 --- L(Train): 0.3413489 --- L(Val, RNN): 0.3359607 --- L(Val, SINDy): 0.3616739 --- Time: 1.13s; --- Convergence: 9.08e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.06 1 + 0.581 value_stay[t] + 0.173 reward + 0.013 harvest_duration + -0.428 value_stay^2 + -0.386 value_stay*reward + -0.417 value_stay*harvest_duration + 0.279 reward^2 + 0.177 reward*harvest_duration + 0.011 harvest_duration^2 \n",
      "value_exit[t+1] = -0.075 1 + 1.016 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.069 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 60/1000 --- L(Train): 0.3419703 --- L(Val, RNN): 0.3349842 --- L(Val, SINDy): 0.3587418 --- Time: 0.88s; --- Convergence: 9.42e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.065 1 + 0.59 value_stay[t] + 0.185 reward + 0.018 harvest_duration + -0.416 value_stay^2 + -0.373 value_stay*reward + -0.406 value_stay*harvest_duration + 0.293 reward^2 + 0.189 reward*harvest_duration + 0.016 harvest_duration^2 \n",
      "value_exit[t+1] = -0.075 1 + 1.016 value_exit[t] + -0.012 travel_duration + 0.035 value_exit^2 + -0.07 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 61/1000 --- L(Train): 0.3459201 --- L(Val, RNN): 0.3339262 --- L(Val, SINDy): 0.3547858 --- Time: 1.02s; --- Convergence: 1.00e-03; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.061 1 + 0.595 value_stay[t] + 0.192 reward + 0.014 harvest_duration + -0.402 value_stay^2 + -0.359 value_stay*reward + -0.398 value_stay*harvest_duration + 0.306 reward^2 + 0.196 reward*harvest_duration + 0.012 harvest_duration^2 \n",
      "value_exit[t+1] = -0.076 1 + 1.016 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.071 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 62/1000 --- L(Train): 0.3440435 --- L(Val, RNN): 0.3328950 --- L(Val, SINDy): 0.3550497 --- Time: 0.93s; --- Convergence: 1.02e-03; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.056 1 + 0.604 value_stay[t] + 0.201 reward + 0.008 harvest_duration + -0.387 value_stay^2 + -0.345 value_stay*reward + -0.387 value_stay*harvest_duration + 0.32 reward^2 + 0.205 reward*harvest_duration + 0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 1.016 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.072 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 63/1000 --- L(Train): 0.3428254 --- L(Val, RNN): 0.3320184 --- L(Val, SINDy): 0.3563865 --- Time: 0.88s; --- Convergence: 9.46e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.055 1 + 0.614 value_stay[t] + 0.212 reward + 0.006 harvest_duration + -0.372 value_stay^2 + -0.33 value_stay*reward + -0.375 value_stay*harvest_duration + 0.334 reward^2 + 0.216 reward*harvest_duration + 0.004 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 1.015 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.073 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 64/1000 --- L(Train): 0.3454114 --- L(Val, RNN): 0.3311209 --- L(Val, SINDy): 0.3521585 --- Time: 0.85s; --- Convergence: 9.22e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.056 1 + 0.626 value_stay[t] + 0.225 reward + 0.006 harvest_duration + -0.357 value_stay^2 + -0.314 value_stay*reward + -0.361 value_stay*harvest_duration + 0.35 reward^2 + 0.229 reward*harvest_duration + 0.004 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 1.015 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.074 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 65/1000 --- L(Train): 0.3415206 --- L(Val, RNN): 0.3302599 --- L(Val, SINDy): 0.3514231 --- Time: 0.92s; --- Convergence: 8.91e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.06 1 + 0.64 value_stay[t] + 0.239 reward + 0.009 harvest_duration + -0.341 value_stay^2 + -0.298 value_stay*reward + -0.347 value_stay*harvest_duration + 0.366 reward^2 + 0.243 reward*harvest_duration + 0.007 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 1.015 value_exit[t] + -0.013 travel_duration + 0.035 value_exit^2 + -0.075 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 66/1000 --- L(Train): 0.3388797 --- L(Val, RNN): 0.3296049 --- L(Val, SINDy): 0.3527990 --- Time: 1.03s; --- Convergence: 7.73e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.062 1 + 0.652 value_stay[t] + 0.251 reward + 0.009 harvest_duration + -0.325 value_stay^2 + -0.283 value_stay*reward + -0.333 value_stay*harvest_duration + 0.381 reward^2 + 0.255 reward*harvest_duration + 0.007 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 1.014 value_exit[t] + -0.014 travel_duration + 0.035 value_exit^2 + -0.076 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 67/1000 --- L(Train): 0.3406454 --- L(Val, RNN): 0.3288473 --- L(Val, SINDy): 0.3509893 --- Time: 0.95s; --- Convergence: 7.65e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.061 1 + 0.661 value_stay[t] + 0.262 reward + 0.007 harvest_duration + -0.311 value_stay^2 + -0.268 value_stay*reward + -0.323 value_stay*harvest_duration + 0.394 reward^2 + 0.266 reward*harvest_duration + 0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 1.014 value_exit[t] + -0.014 travel_duration + 0.035 value_exit^2 + -0.076 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 68/1000 --- L(Train): 0.3396269 --- L(Val, RNN): 0.3283428 --- L(Val, SINDy): 0.3483960 --- Time: 1.05s; --- Convergence: 6.35e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.057 1 + 0.666 value_stay[t] + 0.269 reward + 0.002 harvest_duration + -0.3 value_stay^2 + -0.256 value_stay*reward + -0.316 value_stay*harvest_duration + 0.405 reward^2 + 0.274 reward*harvest_duration + -0.0 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 1.013 value_exit[t] + -0.014 travel_duration + 0.036 value_exit^2 + -0.077 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 69/1000 --- L(Train): 0.3375436 --- L(Val, RNN): 0.3281747 --- L(Val, SINDy): 0.3474358 --- Time: 1.22s; --- Convergence: 4.02e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.661 value_stay[t] + 0.265 reward + -0.008 harvest_duration + -0.298 value_stay^2 + -0.254 value_stay*reward + -0.32 value_stay*harvest_duration + 0.405 reward^2 + 0.269 reward*harvest_duration + -0.01 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 1.013 value_exit[t] + -0.014 travel_duration + 0.036 value_exit^2 + -0.079 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 70/1000 --- L(Train): 0.3446465 --- L(Val, RNN): 0.3269562 --- L(Val, SINDy): 0.3474319 --- Time: 1.00s; --- Convergence: 8.10e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.656 value_stay[t] + 0.261 reward + -0.017 harvest_duration + -0.296 value_stay^2 + -0.253 value_stay*reward + -0.324 value_stay*harvest_duration + 0.404 reward^2 + 0.266 reward*harvest_duration + -0.019 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 1.012 value_exit[t] + -0.014 travel_duration + 0.036 value_exit^2 + -0.08 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 71/1000 --- L(Train): 0.3426362 --- L(Val, RNN): 0.3267430 --- L(Val, SINDy): 0.3497319 --- Time: 1.06s; --- Convergence: 5.12e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.032 1 + 0.652 value_stay[t] + 0.259 reward + -0.024 harvest_duration + -0.291 value_stay^2 + -0.249 value_stay*reward + -0.327 value_stay*harvest_duration + 0.405 reward^2 + 0.264 reward*harvest_duration + -0.026 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 1.012 value_exit[t] + -0.015 travel_duration + 0.036 value_exit^2 + -0.08 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 72/1000 --- L(Train): 0.3441774 --- L(Val, RNN): 0.3263136 --- L(Val, SINDy): 0.3490880 --- Time: 2.56s; --- Convergence: 4.71e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.027 1 + 0.65 value_stay[t] + 0.26 reward + -0.03 harvest_duration + -0.285 value_stay^2 + -0.244 value_stay*reward + -0.327 value_stay*harvest_duration + 0.409 reward^2 + 0.264 reward*harvest_duration + -0.032 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 1.011 value_exit[t] + -0.015 travel_duration + 0.036 value_exit^2 + -0.081 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 73/1000 --- L(Train): 0.3390588 --- L(Val, RNN): 0.3254374 --- L(Val, SINDy): 0.3470588 --- Time: 3.92s; --- Convergence: 6.73e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.025 1 + 0.652 value_stay[t] + 0.262 reward + -0.033 harvest_duration + -0.276 value_stay^2 + -0.236 value_stay*reward + -0.324 value_stay*harvest_duration + 0.416 reward^2 + 0.267 reward*harvest_duration + -0.035 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 1.011 value_exit[t] + -0.014 travel_duration + 0.036 value_exit^2 + -0.083 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 74/1000 --- L(Train): 0.3372434 --- L(Val, RNN): 0.3248359 --- L(Val, SINDy): 0.3453377 --- Time: 6.66s; --- Convergence: 6.37e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.025 1 + 0.654 value_stay[t] + 0.266 reward + -0.034 harvest_duration + -0.267 value_stay^2 + -0.228 value_stay*reward + -0.32 value_stay*harvest_duration + 0.423 reward^2 + 0.271 reward*harvest_duration + -0.036 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 1.01 value_exit[t] + -0.014 travel_duration + 0.036 value_exit^2 + -0.084 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 75/1000 --- L(Train): 0.3409837 --- L(Val, RNN): 0.3240981 --- L(Val, SINDy): 0.3449801 --- Time: 4.08s; --- Convergence: 6.88e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.026 1 + 0.657 value_stay[t] + 0.271 reward + -0.034 harvest_duration + -0.257 value_stay^2 + -0.219 value_stay*reward + -0.316 value_stay*harvest_duration + 0.431 reward^2 + 0.276 reward*harvest_duration + -0.036 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 1.01 value_exit[t] + -0.015 travel_duration + 0.036 value_exit^2 + -0.084 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 76/1000 --- L(Train): 0.3402959 --- L(Val, RNN): 0.3237267 --- L(Val, SINDy): 0.3450522 --- Time: 3.54s; --- Convergence: 5.29e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.028 1 + 0.661 value_stay[t] + 0.277 reward + -0.032 harvest_duration + -0.247 value_stay^2 + -0.21 value_stay*reward + -0.31 value_stay*harvest_duration + 0.44 reward^2 + 0.282 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 1.01 value_exit[t] + -0.016 travel_duration + 0.036 value_exit^2 + -0.085 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 77/1000 --- L(Train): 0.3391602 --- L(Val, RNN): 0.3231411 --- L(Val, SINDy): 0.3455248 --- Time: 1.91s; --- Convergence: 5.58e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.033 1 + 0.668 value_stay[t] + 0.286 reward + -0.028 harvest_duration + -0.234 value_stay^2 + -0.198 value_stay*reward + -0.301 value_stay*harvest_duration + 0.451 reward^2 + 0.291 reward*harvest_duration + -0.03 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 1.008 value_exit[t] + -0.013 travel_duration + 0.037 value_exit^2 + -0.088 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 78/1000 --- L(Train): 0.3365828 --- L(Val, RNN): 0.3229696 --- L(Val, SINDy): 0.3479059 --- Time: 2.94s; --- Convergence: 3.64e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.676 value_stay[t] + 0.296 reward + -0.022 harvest_duration + -0.22 value_stay^2 + -0.185 value_stay*reward + -0.292 value_stay*harvest_duration + 0.464 reward^2 + 0.3 reward*harvest_duration + -0.024 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 1.009 value_exit[t] + -0.015 travel_duration + 0.036 value_exit^2 + -0.087 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 79/1000 --- L(Train): 0.3364283 --- L(Val, RNN): 0.3219639 --- L(Val, SINDy): 0.3514905 --- Time: 2.97s; --- Convergence: 6.85e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.683 value_stay[t] + 0.305 reward + -0.018 harvest_duration + -0.207 value_stay^2 + -0.173 value_stay*reward + -0.283 value_stay*harvest_duration + 0.476 reward^2 + 0.309 reward*harvest_duration + -0.02 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 1.01 value_exit[t] + -0.017 travel_duration + 0.036 value_exit^2 + -0.086 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 80/1000 --- L(Train): 0.3407446 --- L(Val, RNN): 0.3220393 --- L(Val, SINDy): 0.3496934 --- Time: 1.61s; --- Convergence: 3.80e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.687 value_stay[t] + 0.312 reward + -0.016 harvest_duration + -0.197 value_stay^2 + -0.164 value_stay*reward + -0.278 value_stay*harvest_duration + 0.485 reward^2 + 0.316 reward*harvest_duration + -0.018 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 1.009 value_exit[t] + -0.016 travel_duration + 0.037 value_exit^2 + -0.088 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 81/1000 --- L(Train): 0.3352766 --- L(Val, RNN): 0.3208854 --- L(Val, SINDy): 0.3485561 --- Time: 2.00s; --- Convergence: 7.67e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.686 value_stay[t] + 0.314 reward + -0.018 harvest_duration + -0.19 value_stay^2 + -0.158 value_stay*reward + -0.277 value_stay*harvest_duration + 0.491 reward^2 + 0.319 reward*harvest_duration + -0.02 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 1.007 value_exit[t] + -0.014 travel_duration + 0.037 value_exit^2 + -0.091 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 82/1000 --- L(Train): 0.3329794 --- L(Val, RNN): 0.3205969 --- L(Val, SINDy): 0.3481927 --- Time: 3.66s; --- Convergence: 5.28e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.679 value_stay[t] + 0.312 reward + -0.024 harvest_duration + -0.189 value_stay^2 + -0.158 value_stay*reward + -0.281 value_stay*harvest_duration + 0.492 reward^2 + 0.316 reward*harvest_duration + -0.026 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.01 value_exit[t] + -0.018 travel_duration + 0.036 value_exit^2 + -0.088 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 83/1000 --- L(Train): 0.3393174 --- L(Val, RNN): 0.3201086 --- L(Val, SINDy): 0.3479555 --- Time: 2.93s; --- Convergence: 5.08e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.034 1 + 0.671 value_stay[t] + 0.308 reward + -0.032 harvest_duration + -0.189 value_stay^2 + -0.159 value_stay*reward + -0.287 value_stay*harvest_duration + 0.492 reward^2 + 0.312 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 1.007 value_exit[t] + -0.016 travel_duration + 0.037 value_exit^2 + -0.091 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 84/1000 --- L(Train): 0.3390567 --- L(Val, RNN): 0.3196678 --- L(Val, SINDy): 0.3459640 --- Time: 4.26s; --- Convergence: 4.74e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.029 1 + 0.663 value_stay[t] + 0.306 reward + -0.039 harvest_duration + -0.187 value_stay^2 + -0.159 value_stay*reward + -0.292 value_stay*harvest_duration + 0.494 reward^2 + 0.31 reward*harvest_duration + -0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 1.006 value_exit[t] + -0.015 travel_duration + 0.037 value_exit^2 + -0.093 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 85/1000 --- L(Train): 0.3421928 --- L(Val, RNN): 0.3199960 --- L(Val, SINDy): 0.3454741 --- Time: 2.63s; --- Convergence: 4.01e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.024 1 + 0.656 value_stay[t] + 0.304 reward + -0.044 harvest_duration + -0.184 value_stay^2 + -0.157 value_stay*reward + -0.296 value_stay*harvest_duration + 0.498 reward^2 + 0.309 reward*harvest_duration + -0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.007 value_exit[t] + -0.016 travel_duration + 0.037 value_exit^2 + -0.092 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 86/1000 --- L(Train): 0.3487736 --- L(Val, RNN): 0.3195281 --- L(Val, SINDy): 0.3464850 --- Time: 2.48s; --- Convergence: 4.35e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.02 1 + 0.649 value_stay[t] + 0.303 reward + -0.049 harvest_duration + -0.181 value_stay^2 + -0.156 value_stay*reward + -0.301 value_stay*harvest_duration + 0.501 reward^2 + 0.308 reward*harvest_duration + -0.051 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.008 value_exit[t] + -0.017 travel_duration + 0.037 value_exit^2 + -0.091 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 87/1000 --- L(Train): 0.3400750 --- L(Val, RNN): 0.3196983 --- L(Val, SINDy): 0.3495249 --- Time: 2.54s; --- Convergence: 3.02e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.017 1 + 0.642 value_stay[t] + 0.303 reward + -0.053 harvest_duration + -0.179 value_stay^2 + -0.155 value_stay*reward + -0.305 value_stay*harvest_duration + 0.505 reward^2 + 0.307 reward*harvest_duration + -0.055 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.007 value_exit[t] + -0.016 travel_duration + 0.037 value_exit^2 + -0.093 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 88/1000 --- L(Train): 0.3444048 --- L(Val, RNN): 0.3201163 --- L(Val, SINDy): 0.3482822 --- Time: 2.18s; --- Convergence: 3.60e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.018 1 + 0.637 value_stay[t] + 0.305 reward + -0.053 harvest_duration + -0.173 value_stay^2 + -0.152 value_stay*reward + -0.307 value_stay*harvest_duration + 0.512 reward^2 + 0.31 reward*harvest_duration + -0.055 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.007 value_exit[t] + -0.015 travel_duration + 0.037 value_exit^2 + -0.095 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 89/1000 --- L(Train): 0.3427295 --- L(Val, RNN): 0.3194780 --- L(Val, SINDy): 0.3461807 --- Time: 2.28s; --- Convergence: 4.99e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.021 1 + 0.635 value_stay[t] + 0.31 reward + -0.052 harvest_duration + -0.165 value_stay^2 + -0.146 value_stay*reward + -0.307 value_stay*harvest_duration + 0.52 reward^2 + 0.314 reward*harvest_duration + -0.054 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.008 value_exit[t] + -0.016 travel_duration + 0.037 value_exit^2 + -0.095 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 90/1000 --- L(Train): 0.3470559 --- L(Val, RNN): 0.3198629 --- L(Val, SINDy): 0.3443653 --- Time: 2.61s; --- Convergence: 4.42e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.024 1 + 0.631 value_stay[t] + 0.314 reward + -0.05 harvest_duration + -0.159 value_stay^2 + -0.142 value_stay*reward + -0.307 value_stay*harvest_duration + 0.528 reward^2 + 0.318 reward*harvest_duration + -0.052 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.01 value_exit[t] + -0.018 travel_duration + 0.036 value_exit^2 + -0.094 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 91/1000 --- L(Train): 0.3406839 --- L(Val, RNN): 0.3208330 --- L(Val, SINDy): 0.3436926 --- Time: 2.41s; --- Convergence: 7.06e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.026 1 + 0.627 value_stay[t] + 0.315 reward + -0.049 harvest_duration + -0.154 value_stay^2 + -0.14 value_stay*reward + -0.309 value_stay*harvest_duration + 0.534 reward^2 + 0.32 reward*harvest_duration + -0.051 harvest_duration^2 \n",
      "value_exit[t+1] = -0.092 1 + 1.011 value_exit[t] + -0.017 travel_duration + 0.036 value_exit^2 + -0.094 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 92/1000 --- L(Train): 0.3457157 --- L(Val, RNN): 0.3194764 --- L(Val, SINDy): 0.3432645 --- Time: 3.19s; --- Convergence: 1.03e-03; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.027 1 + 0.622 value_stay[t] + 0.317 reward + -0.049 harvest_duration + -0.15 value_stay^2 + -0.138 value_stay*reward + -0.311 value_stay*harvest_duration + 0.539 reward^2 + 0.321 reward*harvest_duration + -0.051 harvest_duration^2 \n",
      "value_exit[t+1] = -0.092 1 + 1.011 value_exit[t] + -0.016 travel_duration + 0.036 value_exit^2 + -0.096 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 93/1000 --- L(Train): 0.3494869 --- L(Val, RNN): 0.3189677 --- L(Val, SINDy): 0.3427914 --- Time: 1.85s; --- Convergence: 7.70e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.029 1 + 0.619 value_stay[t] + 0.319 reward + -0.048 harvest_duration + -0.146 value_stay^2 + -0.136 value_stay*reward + -0.313 value_stay*harvest_duration + 0.545 reward^2 + 0.323 reward*harvest_duration + -0.05 harvest_duration^2 \n",
      "value_exit[t+1] = -0.093 1 + 1.012 value_exit[t] + -0.016 travel_duration + 0.035 value_exit^2 + -0.096 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 94/1000 --- L(Train): 0.3455680 --- L(Val, RNN): 0.3187747 --- L(Val, SINDy): 0.3438128 --- Time: 2.07s; --- Convergence: 4.82e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.031 1 + 0.614 value_stay[t] + 0.32 reward + -0.047 harvest_duration + -0.142 value_stay^2 + -0.134 value_stay*reward + -0.315 value_stay*harvest_duration + 0.55 reward^2 + 0.324 reward*harvest_duration + -0.049 harvest_duration^2 \n",
      "value_exit[t+1] = -0.096 1 + 1.014 value_exit[t] + -0.017 travel_duration + 0.035 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 95/1000 --- L(Train): 0.3483471 --- L(Val, RNN): 0.3199693 --- L(Val, SINDy): 0.3424125 --- Time: 1.24s; --- Convergence: 8.38e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.032 1 + 0.609 value_stay[t] + 0.32 reward + -0.047 harvest_duration + -0.138 value_stay^2 + -0.133 value_stay*reward + -0.318 value_stay*harvest_duration + 0.554 reward^2 + 0.324 reward*harvest_duration + -0.049 harvest_duration^2 \n",
      "value_exit[t+1] = -0.097 1 + 1.015 value_exit[t] + -0.017 travel_duration + 0.034 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 96/1000 --- L(Train): 0.3507940 --- L(Val, RNN): 0.3188273 --- L(Val, SINDy): 0.3409331 --- Time: 1.05s; --- Convergence: 9.90e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.034 1 + 0.605 value_stay[t] + 0.321 reward + -0.046 harvest_duration + -0.133 value_stay^2 + -0.131 value_stay*reward + -0.32 value_stay*harvest_duration + 0.558 reward^2 + 0.325 reward*harvest_duration + -0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.098 1 + 1.016 value_exit[t] + -0.016 travel_duration + 0.034 value_exit^2 + -0.097 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 97/1000 --- L(Train): 0.3424662 --- L(Val, RNN): 0.3183057 --- L(Val, SINDy): 0.3427114 --- Time: 0.85s; --- Convergence: 7.56e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.604 value_stay[t] + 0.324 reward + -0.043 harvest_duration + -0.125 value_stay^2 + -0.125 value_stay*reward + -0.318 value_stay*harvest_duration + 0.565 reward^2 + 0.328 reward*harvest_duration + -0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.1 1 + 1.017 value_exit[t] + -0.016 travel_duration + 0.034 value_exit^2 + -0.097 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 98/1000 --- L(Train): 0.3504297 --- L(Val, RNN): 0.3183243 --- L(Val, SINDy): 0.3423878 --- Time: 1.03s; --- Convergence: 3.87e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.604 value_stay[t] + 0.327 reward + -0.04 harvest_duration + -0.116 value_stay^2 + -0.119 value_stay*reward + -0.315 value_stay*harvest_duration + 0.572 reward^2 + 0.331 reward*harvest_duration + -0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.101 1 + 1.018 value_exit[t] + -0.017 travel_duration + 0.033 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 99/1000 --- L(Train): 0.3496413 --- L(Val, RNN): 0.3183845 --- L(Val, SINDy): 0.3417611 --- Time: 1.16s; --- Convergence: 2.24e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.606 value_stay[t] + 0.331 reward + -0.036 harvest_duration + -0.106 value_stay^2 + -0.112 value_stay*reward + -0.312 value_stay*harvest_duration + 0.58 reward^2 + 0.335 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.102 1 + 1.019 value_exit[t] + -0.017 travel_duration + 0.033 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 100/1000 --- L(Train): 0.3490184 --- L(Val, RNN): 0.3190697 --- L(Val, SINDy): 0.3418972 --- Time: 1.02s; --- Convergence: 4.54e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.051 1 + 0.607 value_stay[t] + 0.334 reward + -0.033 harvest_duration + -0.095 value_stay^2 + -0.104 value_stay*reward + -0.308 value_stay*harvest_duration + 0.587 reward^2 + 0.338 reward*harvest_duration + -0.035 harvest_duration^2 \n",
      "value_exit[t+1] = -0.102 1 + 1.019 value_exit[t] + -0.016 travel_duration + 0.033 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 101/1000 --- L(Train): 0.3504912 --- L(Val, RNN): 0.3184176 --- L(Val, SINDy): 0.3434471 --- Time: 0.92s; --- Convergence: 5.53e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.054 1 + 0.608 value_stay[t] + 0.336 reward + -0.032 harvest_duration + -0.086 value_stay^2 + -0.097 value_stay*reward + -0.305 value_stay*harvest_duration + 0.593 reward^2 + 0.34 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.102 1 + 1.019 value_exit[t] + -0.016 travel_duration + 0.033 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 102/1000 --- L(Train): 0.3507538 --- L(Val, RNN): 0.3177734 --- L(Val, SINDy): 0.3441548 --- Time: 1.22s; --- Convergence: 5.99e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.054 1 + 0.606 value_stay[t] + 0.335 reward + -0.032 harvest_duration + -0.079 value_stay^2 + -0.093 value_stay*reward + -0.305 value_stay*harvest_duration + 0.597 reward^2 + 0.339 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.102 1 + 1.019 value_exit[t] + -0.016 travel_duration + 0.033 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 103/1000 --- L(Train): 0.3520292 --- L(Val, RNN): 0.3182232 --- L(Val, SINDy): 0.3420197 --- Time: 1.17s; --- Convergence: 5.24e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.051 1 + 0.601 value_stay[t] + 0.331 reward + -0.036 harvest_duration + -0.075 value_stay^2 + -0.092 value_stay*reward + -0.308 value_stay*harvest_duration + 0.597 reward^2 + 0.336 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.102 1 + 1.019 value_exit[t] + -0.017 travel_duration + 0.033 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 104/1000 --- L(Train): 0.3564698 --- L(Val, RNN): 0.3190125 --- L(Val, SINDy): 0.3394367 --- Time: 0.93s; --- Convergence: 6.57e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.597 value_stay[t] + 0.328 reward + -0.04 harvest_duration + -0.069 value_stay^2 + -0.089 value_stay*reward + -0.31 value_stay*harvest_duration + 0.598 reward^2 + 0.332 reward*harvest_duration + -0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.1 1 + 1.017 value_exit[t] + -0.015 travel_duration + 0.034 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 105/1000 --- L(Train): 0.3507742 --- L(Val, RNN): 0.3181209 --- L(Val, SINDy): 0.3386493 --- Time: 1.04s; --- Convergence: 7.74e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.596 value_stay[t] + 0.327 reward + -0.041 harvest_duration + -0.06 value_stay^2 + -0.083 value_stay*reward + -0.309 value_stay*harvest_duration + 0.602 reward^2 + 0.331 reward*harvest_duration + -0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.099 1 + 1.016 value_exit[t] + -0.016 travel_duration + 0.034 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 106/1000 --- L(Train): 0.3468998 --- L(Val, RNN): 0.3183652 --- L(Val, SINDy): 0.3416104 --- Time: 1.15s; --- Convergence: 5.09e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.052 1 + 0.599 value_stay[t] + 0.329 reward + -0.039 harvest_duration + -0.048 value_stay^2 + -0.074 value_stay*reward + -0.303 value_stay*harvest_duration + 0.609 reward^2 + 0.334 reward*harvest_duration + -0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.1 1 + 1.017 value_exit[t] + -0.018 travel_duration + 0.034 value_exit^2 + -0.096 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 107/1000 --- L(Train): 0.3521019 --- L(Val, RNN): 0.3184474 --- L(Val, SINDy): 0.3424486 --- Time: 1.81s; --- Convergence: 2.96e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.056 1 + 0.603 value_stay[t] + 0.333 reward + -0.037 harvest_duration + -0.036 value_stay^2 + -0.063 value_stay*reward + -0.297 value_stay*harvest_duration + 0.617 reward^2 + 0.337 reward*harvest_duration + -0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.093 1 + 1.01 value_exit[t] + -0.013 travel_duration + 0.036 value_exit^2 + -0.101 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 108/1000 --- L(Train): 0.3484773 --- L(Val, RNN): 0.3188996 --- L(Val, SINDy): 0.3421502 --- Time: 1.72s; --- Convergence: 3.74e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.058 1 + 0.604 value_stay[t] + 0.335 reward + -0.036 harvest_duration + -0.026 value_stay^2 + -0.053 value_stay*reward + -0.293 value_stay*harvest_duration + 0.623 reward^2 + 0.339 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.093 1 + 1.01 value_exit[t] + -0.014 travel_duration + 0.036 value_exit^2 + -0.1 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 109/1000 --- L(Train): 0.3570294 --- L(Val, RNN): 0.3181408 --- L(Val, SINDy): 0.3392879 --- Time: 1.30s; --- Convergence: 5.66e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.057 1 + 0.6 value_stay[t] + 0.334 reward + -0.039 harvest_duration + -0.02 value_stay^2 + -0.047 value_stay*reward + -0.294 value_stay*harvest_duration + 0.626 reward^2 + 0.338 reward*harvest_duration + -0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.098 1 + 1.015 value_exit[t] + -0.021 travel_duration + 0.034 value_exit^2 + -0.093 value_exit*travel_duration + -0.02 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 110/1000 --- L(Train): 0.3545318 --- L(Val, RNN): 0.3178687 --- L(Val, SINDy): 0.3407318 --- Time: 1.09s; --- Convergence: 4.19e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.053 1 + 0.592 value_stay[t] + 0.329 reward + -0.045 harvest_duration + -0.019 value_stay^2 + -0.046 value_stay*reward + -0.299 value_stay*harvest_duration + 0.627 reward^2 + 0.333 reward*harvest_duration + -0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.094 1 + 1.011 value_exit[t] + -0.018 travel_duration + 0.037 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 111/1000 --- L(Train): 0.3512340 --- L(Val, RNN): 0.3181413 --- L(Val, SINDy): 0.3422728 --- Time: 0.79s; --- Convergence: 3.46e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.05 1 + 0.584 value_stay[t] + 0.324 reward + -0.05 harvest_duration + -0.018 value_stay^2 + -0.044 value_stay*reward + -0.304 value_stay*harvest_duration + 0.627 reward^2 + 0.329 reward*harvest_duration + -0.052 harvest_duration^2 \n",
      "value_exit[t+1] = -0.09 1 + 1.006 value_exit[t] + -0.014 travel_duration + 0.039 value_exit^2 + -0.1 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 112/1000 --- L(Train): 0.3534231 --- L(Val, RNN): 0.3186450 --- L(Val, SINDy): 0.3405035 --- Time: 1.00s; --- Convergence: 4.25e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.051 1 + 0.581 value_stay[t] + 0.324 reward + -0.05 harvest_duration + -0.013 value_stay^2 + -0.039 value_stay*reward + -0.305 value_stay*harvest_duration + 0.631 reward^2 + 0.328 reward*harvest_duration + -0.052 harvest_duration^2 \n",
      "value_exit[t+1] = -0.092 1 + 1.008 value_exit[t] + -0.016 travel_duration + 0.038 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 113/1000 --- L(Train): 0.3610145 --- L(Val, RNN): 0.3182284 --- L(Val, SINDy): 0.3394031 --- Time: 1.05s; --- Convergence: 4.21e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.057 1 + 0.582 value_stay[t] + 0.329 reward + -0.046 harvest_duration + -0.003 value_stay^2 + -0.03 value_stay*reward + -0.301 value_stay*harvest_duration + 0.639 reward^2 + 0.333 reward*harvest_duration + -0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.094 1 + 1.01 value_exit[t] + -0.019 travel_duration + 0.037 value_exit^2 + -0.095 value_exit*travel_duration + -0.018 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 114/1000 --- L(Train): 0.3556114 --- L(Val, RNN): 0.3178515 --- L(Val, SINDy): 0.3387427 --- Time: 0.91s; --- Convergence: 3.99e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.063 1 + 0.581 value_stay[t] + 0.332 reward + -0.042 harvest_duration + 0.005 value_stay^2 + -0.022 value_stay*reward + -0.299 value_stay*harvest_duration + 0.647 reward^2 + 0.336 reward*harvest_duration + -0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.007 value_exit[t] + -0.017 travel_duration + 0.039 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 115/1000 --- L(Train): 0.3580656 --- L(Val, RNN): 0.3178938 --- L(Val, SINDy): 0.3391317 --- Time: 1.11s; --- Convergence: 2.21e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.066 1 + 0.577 value_stay[t] + 0.332 reward + -0.041 harvest_duration + 0.01 value_stay^2 + -0.017 value_stay*reward + -0.299 value_stay*harvest_duration + 0.652 reward^2 + 0.337 reward*harvest_duration + -0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.005 value_exit[t] + -0.014 travel_duration + 0.041 value_exit^2 + -0.1 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 116/1000 --- L(Train): 0.3500769 --- L(Val, RNN): 0.3184628 --- L(Val, SINDy): 0.3385895 --- Time: 1.26s; --- Convergence: 3.95e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.066 1 + 0.571 value_stay[t] + 0.329 reward + -0.043 harvest_duration + 0.011 value_stay^2 + -0.016 value_stay*reward + -0.303 value_stay*harvest_duration + 0.653 reward^2 + 0.333 reward*harvest_duration + -0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.005 value_exit[t] + -0.015 travel_duration + 0.041 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 117/1000 --- L(Train): 0.3564915 --- L(Val, RNN): 0.3185722 --- L(Val, SINDy): 0.3379352 --- Time: 1.14s; --- Convergence: 2.52e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.065 1 + 0.563 value_stay[t] + 0.325 reward + -0.046 harvest_duration + 0.012 value_stay^2 + -0.016 value_stay*reward + -0.309 value_stay*harvest_duration + 0.653 reward^2 + 0.329 reward*harvest_duration + -0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.007 value_exit[t] + -0.018 travel_duration + 0.039 value_exit^2 + -0.096 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 118/1000 --- L(Train): 0.3624997 --- L(Val, RNN): 0.3182514 --- L(Val, SINDy): 0.3376493 --- Time: 0.84s; --- Convergence: 2.86e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.065 1 + 0.557 value_stay[t] + 0.321 reward + -0.048 harvest_duration + 0.013 value_stay^2 + -0.015 value_stay*reward + -0.313 value_stay*harvest_duration + 0.654 reward^2 + 0.325 reward*harvest_duration + -0.05 harvest_duration^2 \n",
      "value_exit[t+1] = -0.092 1 + 1.008 value_exit[t] + -0.018 travel_duration + 0.039 value_exit^2 + -0.096 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 119/1000 --- L(Train): 0.3559091 --- L(Val, RNN): 0.3180479 --- L(Val, SINDy): 0.3374208 --- Time: 0.93s; --- Convergence: 2.45e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.067 1 + 0.551 value_stay[t] + 0.319 reward + -0.048 harvest_duration + 0.016 value_stay^2 + -0.013 value_stay*reward + -0.316 value_stay*harvest_duration + 0.656 reward^2 + 0.323 reward*harvest_duration + -0.05 harvest_duration^2 \n",
      "value_exit[t+1] = -0.09 1 + 1.006 value_exit[t] + -0.017 travel_duration + 0.04 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 120/1000 --- L(Train): 0.3552007 --- L(Val, RNN): 0.3182454 --- L(Val, SINDy): 0.3377611 --- Time: 1.29s; --- Convergence: 2.21e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.07 1 + 0.548 value_stay[t] + 0.319 reward + -0.047 harvest_duration + 0.02 value_stay^2 + -0.009 value_stay*reward + -0.318 value_stay*harvest_duration + 0.66 reward^2 + 0.323 reward*harvest_duration + -0.049 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.005 value_exit[t] + -0.015 travel_duration + 0.041 value_exit^2 + -0.098 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 121/1000 --- L(Train): 0.3587048 --- L(Val, RNN): 0.3185634 --- L(Val, SINDy): 0.3392268 --- Time: 1.24s; --- Convergence: 2.70e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.073 1 + 0.546 value_stay[t] + 0.319 reward + -0.045 harvest_duration + 0.026 value_stay^2 + -0.004 value_stay*reward + -0.318 value_stay*harvest_duration + 0.664 reward^2 + 0.323 reward*harvest_duration + -0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.004 value_exit[t] + -0.015 travel_duration + 0.042 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 122/1000 --- L(Train): 0.3668035 --- L(Val, RNN): 0.3187285 --- L(Val, SINDy): 0.3379600 --- Time: 0.93s; --- Convergence: 2.17e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.077 1 + 0.544 value_stay[t] + 0.32 reward + -0.043 harvest_duration + 0.031 value_stay^2 + 0.0 value_stay*reward + -0.318 value_stay*harvest_duration + 0.668 reward^2 + 0.324 reward*harvest_duration + -0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.004 value_exit[t] + -0.015 travel_duration + 0.042 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 123/1000 --- L(Train): 0.3620897 --- L(Val, RNN): 0.3187662 --- L(Val, SINDy): 0.3382119 --- Time: 1.11s; --- Convergence: 1.28e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.08 1 + 0.542 value_stay[t] + 0.319 reward + -0.042 harvest_duration + 0.035 value_stay^2 + 0.004 value_stay*reward + -0.319 value_stay*harvest_duration + 0.671 reward^2 + 0.323 reward*harvest_duration + -0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.006 value_exit[t] + -0.016 travel_duration + 0.041 value_exit^2 + -0.097 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 124/1000 --- L(Train): 0.3604553 --- L(Val, RNN): 0.3189983 --- L(Val, SINDy): 0.3383479 --- Time: 1.32s; --- Convergence: 1.80e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.08 1 + 0.537 value_stay[t] + 0.316 reward + -0.043 harvest_duration + 0.036 value_stay^2 + 0.004 value_stay*reward + -0.322 value_stay*harvest_duration + 0.672 reward^2 + 0.32 reward*harvest_duration + -0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.007 value_exit[t] + -0.018 travel_duration + 0.04 value_exit^2 + -0.096 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 125/1000 --- L(Train): 0.3586362 --- L(Val, RNN): 0.3192618 --- L(Val, SINDy): 0.3371812 --- Time: 0.86s; --- Convergence: 2.22e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.08 1 + 0.531 value_stay[t] + 0.312 reward + -0.045 harvest_duration + 0.037 value_stay^2 + 0.005 value_stay*reward + -0.326 value_stay*harvest_duration + 0.672 reward^2 + 0.317 reward*harvest_duration + -0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.007 value_exit[t] + -0.018 travel_duration + 0.04 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 126/1000 --- L(Train): 0.3613584 --- L(Val, RNN): 0.3192604 --- L(Val, SINDy): 0.3376358 --- Time: 1.09s; --- Convergence: 1.12e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.081 1 + 0.526 value_stay[t] + 0.31 reward + -0.046 harvest_duration + 0.039 value_stay^2 + 0.006 value_stay*reward + -0.329 value_stay*harvest_duration + 0.673 reward^2 + 0.314 reward*harvest_duration + -0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.005 value_exit[t] + -0.016 travel_duration + 0.041 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 127/1000 --- L(Train): 0.3645270 --- L(Val, RNN): 0.3196726 --- L(Val, SINDy): 0.3398442 --- Time: 1.13s; --- Convergence: 2.62e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.082 1 + 0.523 value_stay[t] + 0.308 reward + -0.046 harvest_duration + 0.041 value_stay^2 + 0.008 value_stay*reward + -0.332 value_stay*harvest_duration + 0.675 reward^2 + 0.312 reward*harvest_duration + -0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.004 value_exit[t] + -0.014 travel_duration + 0.042 value_exit^2 + -0.099 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 128/1000 --- L(Train): 0.3657410 --- L(Val, RNN): 0.3202441 --- L(Val, SINDy): 0.3401618 --- Time: 0.90s; --- Convergence: 4.17e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.083 1 + 0.519 value_stay[t] + 0.306 reward + -0.045 harvest_duration + 0.044 value_stay^2 + 0.011 value_stay*reward + -0.333 value_stay*harvest_duration + 0.677 reward^2 + 0.311 reward*harvest_duration + -0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.004 value_exit[t] + -0.015 travel_duration + 0.042 value_exit^2 + -0.099 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 129/1000 --- L(Train): 0.3619585 --- L(Val, RNN): 0.3202040 --- L(Val, SINDy): 0.3411242 --- Time: 0.93s; --- Convergence: 2.28e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.086 1 + 0.517 value_stay[t] + 0.306 reward + -0.044 harvest_duration + 0.048 value_stay^2 + 0.015 value_stay*reward + -0.333 value_stay*harvest_duration + 0.68 reward^2 + 0.31 reward*harvest_duration + -0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.007 value_exit[t] + -0.017 travel_duration + 0.04 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 130/1000 --- L(Train): 0.3605959 --- L(Val, RNN): 0.3202021 --- L(Val, SINDy): 0.3404817 --- Time: 0.86s; --- Convergence: 1.15e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.089 1 + 0.515 value_stay[t] + 0.306 reward + -0.042 harvest_duration + 0.051 value_stay^2 + 0.019 value_stay*reward + -0.334 value_stay*harvest_duration + 0.683 reward^2 + 0.31 reward*harvest_duration + -0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.092 1 + 1.008 value_exit[t] + -0.019 travel_duration + 0.039 value_exit^2 + -0.095 value_exit*travel_duration + -0.018 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 131/1000 --- L(Train): 0.3557698 --- L(Val, RNN): 0.3204004 --- L(Val, SINDy): 0.3389804 --- Time: 0.81s; --- Convergence: 1.57e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.091 1 + 0.512 value_stay[t] + 0.304 reward + -0.041 harvest_duration + 0.055 value_stay^2 + 0.022 value_stay*reward + -0.335 value_stay*harvest_duration + 0.686 reward^2 + 0.309 reward*harvest_duration + -0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.007 value_exit[t] + -0.018 travel_duration + 0.039 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 132/1000 --- L(Train): 0.3705032 --- L(Val, RNN): 0.3205675 --- L(Val, SINDy): 0.3382632 --- Time: 0.99s; --- Convergence: 1.62e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.093 1 + 0.51 value_stay[t] + 0.303 reward + -0.04 harvest_duration + 0.058 value_stay^2 + 0.025 value_stay*reward + -0.335 value_stay*harvest_duration + 0.688 reward^2 + 0.308 reward*harvest_duration + -0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.006 value_exit[t] + -0.016 travel_duration + 0.041 value_exit^2 + -0.097 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 133/1000 --- L(Train): 0.3702162 --- L(Val, RNN): 0.3208049 --- L(Val, SINDy): 0.3364748 --- Time: 1.03s; --- Convergence: 2.00e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.095 1 + 0.508 value_stay[t] + 0.302 reward + -0.04 harvest_duration + 0.061 value_stay^2 + 0.028 value_stay*reward + -0.336 value_stay*harvest_duration + 0.69 reward^2 + 0.306 reward*harvest_duration + -0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.005 value_exit[t] + -0.015 travel_duration + 0.041 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 134/1000 --- L(Train): 0.3584071 --- L(Val, RNN): 0.3207325 --- L(Val, SINDy): 0.3359192 --- Time: 0.91s; --- Convergence: 1.36e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.097 1 + 0.506 value_stay[t] + 0.3 reward + -0.039 harvest_duration + 0.064 value_stay^2 + 0.03 value_stay*reward + -0.337 value_stay*harvest_duration + 0.691 reward^2 + 0.304 reward*harvest_duration + -0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.005 value_exit[t] + -0.015 travel_duration + 0.041 value_exit^2 + -0.098 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 135/1000 --- L(Train): 0.3589655 --- L(Val, RNN): 0.3210141 --- L(Val, SINDy): 0.3367481 --- Time: 1.05s; --- Convergence: 2.09e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.098 1 + 0.503 value_stay[t] + 0.297 reward + -0.04 harvest_duration + 0.067 value_stay^2 + 0.033 value_stay*reward + -0.338 value_stay*harvest_duration + 0.692 reward^2 + 0.302 reward*harvest_duration + -0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.006 value_exit[t] + -0.016 travel_duration + 0.041 value_exit^2 + -0.097 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 136/1000 --- L(Train): 0.3773002 --- L(Val, RNN): 0.3214541 --- L(Val, SINDy): 0.3381172 --- Time: 1.06s; --- Convergence: 3.24e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.1 1 + 0.501 value_stay[t] + 0.295 reward + -0.039 harvest_duration + 0.07 value_stay^2 + 0.035 value_stay*reward + -0.339 value_stay*harvest_duration + 0.693 reward^2 + 0.299 reward*harvest_duration + -0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.09 1 + 1.007 value_exit[t] + -0.017 travel_duration + 0.04 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 137/1000 --- L(Train): 0.3679981 --- L(Val, RNN): 0.3217641 --- L(Val, SINDy): 0.3395804 --- Time: 0.92s; --- Convergence: 3.17e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.101 1 + 0.499 value_stay[t] + 0.294 reward + -0.039 harvest_duration + 0.072 value_stay^2 + 0.038 value_stay*reward + -0.34 value_stay*harvest_duration + 0.695 reward^2 + 0.298 reward*harvest_duration + -0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.007 value_exit[t] + -0.018 travel_duration + 0.04 value_exit^2 + -0.096 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 138/1000 --- L(Train): 0.3678401 --- L(Val, RNN): 0.3216742 --- L(Val, SINDy): 0.3400463 --- Time: 1.26s; --- Convergence: 2.04e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.103 1 + 0.498 value_stay[t] + 0.292 reward + -0.038 harvest_duration + 0.075 value_stay^2 + 0.04 value_stay*reward + -0.34 value_stay*harvest_duration + 0.697 reward^2 + 0.297 reward*harvest_duration + -0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.007 value_exit[t] + -0.018 travel_duration + 0.04 value_exit^2 + -0.096 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 139/1000 --- L(Train): 0.3676948 --- L(Val, RNN): 0.3214630 --- L(Val, SINDy): 0.3422829 --- Time: 0.93s; --- Convergence: 2.07e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.107 1 + 0.499 value_stay[t] + 0.293 reward + -0.036 harvest_duration + 0.08 value_stay^2 + 0.045 value_stay*reward + -0.339 value_stay*harvest_duration + 0.699 reward^2 + 0.297 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.005 value_exit[t] + -0.016 travel_duration + 0.041 value_exit^2 + -0.097 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 140/1000 --- L(Train): 0.3764676 --- L(Val, RNN): 0.3218382 --- L(Val, SINDy): 0.3409794 --- Time: 1.15s; --- Convergence: 2.91e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.11 1 + 0.5 value_stay[t] + 0.293 reward + -0.034 harvest_duration + 0.085 value_stay^2 + 0.049 value_stay*reward + -0.337 value_stay*harvest_duration + 0.702 reward^2 + 0.297 reward*harvest_duration + -0.036 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.004 value_exit[t] + -0.014 travel_duration + 0.042 value_exit^2 + -0.099 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 141/1000 --- L(Train): 0.3816854 --- L(Val, RNN): 0.3224647 --- L(Val, SINDy): 0.3385123 --- Time: 1.40s; --- Convergence: 4.59e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.114 1 + 0.501 value_stay[t] + 0.293 reward + -0.032 harvest_duration + 0.09 value_stay^2 + 0.053 value_stay*reward + -0.336 value_stay*harvest_duration + 0.705 reward^2 + 0.297 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.014 travel_duration + 0.042 value_exit^2 + -0.099 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 142/1000 --- L(Train): 0.3720662 --- L(Val, RNN): 0.3224407 --- L(Val, SINDy): 0.3375566 --- Time: 0.97s; --- Convergence: 2.41e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.116 1 + 0.501 value_stay[t] + 0.292 reward + -0.032 harvest_duration + 0.093 value_stay^2 + 0.056 value_stay*reward + -0.335 value_stay*harvest_duration + 0.706 reward^2 + 0.296 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.004 value_exit[t] + -0.015 travel_duration + 0.042 value_exit^2 + -0.098 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 143/1000 --- L(Train): 0.3794422 --- L(Val, RNN): 0.3222483 --- L(Val, SINDy): 0.3381962 --- Time: 0.99s; --- Convergence: 2.17e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.118 1 + 0.5 value_stay[t] + 0.289 reward + -0.032 harvest_duration + 0.096 value_stay^2 + 0.057 value_stay*reward + -0.336 value_stay*harvest_duration + 0.707 reward^2 + 0.293 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.006 value_exit[t] + -0.017 travel_duration + 0.041 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 144/1000 --- L(Train): 0.3851089 --- L(Val, RNN): 0.3225189 --- L(Val, SINDy): 0.3386226 --- Time: 1.15s; --- Convergence: 2.44e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.118 1 + 0.497 value_stay[t] + 0.286 reward + -0.034 harvest_duration + 0.096 value_stay^2 + 0.059 value_stay*reward + -0.338 value_stay*harvest_duration + 0.706 reward^2 + 0.29 reward*harvest_duration + -0.036 harvest_duration^2 \n",
      "value_exit[t+1] = -0.09 1 + 1.006 value_exit[t] + -0.018 travel_duration + 0.04 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 145/1000 --- L(Train): 0.3859713 --- L(Val, RNN): 0.3229151 --- L(Val, SINDy): 0.3385253 --- Time: 1.10s; --- Convergence: 3.20e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.118 1 + 0.494 value_stay[t] + 0.283 reward + -0.036 harvest_duration + 0.097 value_stay^2 + 0.059 value_stay*reward + -0.341 value_stay*harvest_duration + 0.706 reward^2 + 0.287 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.005 value_exit[t] + -0.017 travel_duration + 0.041 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 146/1000 --- L(Train): 0.3801723 --- L(Val, RNN): 0.3232304 --- L(Val, SINDy): 0.3396293 --- Time: 1.30s; --- Convergence: 3.18e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.119 1 + 0.493 value_stay[t] + 0.28 reward + -0.037 harvest_duration + 0.099 value_stay^2 + 0.061 value_stay*reward + -0.342 value_stay*harvest_duration + 0.706 reward^2 + 0.285 reward*harvest_duration + -0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.015 travel_duration + 0.042 value_exit^2 + -0.098 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 147/1000 --- L(Train): 0.3625561 --- L(Val, RNN): 0.3234298 --- L(Val, SINDy): 0.3399337 --- Time: 0.90s; --- Convergence: 2.59e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.121 1 + 0.492 value_stay[t] + 0.279 reward + -0.037 harvest_duration + 0.102 value_stay^2 + 0.063 value_stay*reward + -0.343 value_stay*harvest_duration + 0.707 reward^2 + 0.283 reward*harvest_duration + -0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.002 value_exit[t] + -0.014 travel_duration + 0.043 value_exit^2 + -0.099 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 148/1000 --- L(Train): 0.3800977 --- L(Val, RNN): 0.3235027 --- L(Val, SINDy): 0.3399130 --- Time: 1.21s; --- Convergence: 1.66e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.124 1 + 0.493 value_stay[t] + 0.278 reward + -0.037 harvest_duration + 0.106 value_stay^2 + 0.067 value_stay*reward + -0.342 value_stay*harvest_duration + 0.709 reward^2 + 0.282 reward*harvest_duration + -0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.003 value_exit[t] + -0.015 travel_duration + 0.043 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 149/1000 --- L(Train): 0.3868265 --- L(Val, RNN): 0.3235816 --- L(Val, SINDy): 0.3392246 --- Time: 0.93s; --- Convergence: 1.22e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.129 1 + 0.496 value_stay[t] + 0.279 reward + -0.034 harvest_duration + 0.112 value_stay^2 + 0.072 value_stay*reward + -0.34 value_stay*harvest_duration + 0.712 reward^2 + 0.283 reward*harvest_duration + -0.036 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.005 value_exit[t] + -0.017 travel_duration + 0.041 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 150/1000 --- L(Train): 0.3915248 --- L(Val, RNN): 0.3238239 --- L(Val, SINDy): 0.3383423 --- Time: 0.95s; --- Convergence: 1.82e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.133 1 + 0.498 value_stay[t] + 0.279 reward + -0.033 harvest_duration + 0.117 value_stay^2 + 0.077 value_stay*reward + -0.338 value_stay*harvest_duration + 0.715 reward^2 + 0.283 reward*harvest_duration + -0.035 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.005 value_exit[t] + -0.017 travel_duration + 0.041 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 151/1000 --- L(Train): 0.3771703 --- L(Val, RNN): 0.3239193 --- L(Val, SINDy): 0.3375174 --- Time: 0.98s; --- Convergence: 1.39e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.136 1 + 0.499 value_stay[t] + 0.277 reward + -0.032 harvest_duration + 0.12 value_stay^2 + 0.08 value_stay*reward + -0.338 value_stay*harvest_duration + 0.716 reward^2 + 0.282 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.016 travel_duration + 0.042 value_exit^2 + -0.097 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 152/1000 --- L(Train): 0.3857234 --- L(Val, RNN): 0.3241553 --- L(Val, SINDy): 0.3378377 --- Time: 0.92s; --- Convergence: 1.87e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.136 1 + 0.496 value_stay[t] + 0.274 reward + -0.035 harvest_duration + 0.121 value_stay^2 + 0.081 value_stay*reward + -0.341 value_stay*harvest_duration + 0.715 reward^2 + 0.278 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.002 value_exit[t] + -0.014 travel_duration + 0.044 value_exit^2 + -0.099 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 153/1000 --- L(Train): 0.3878178 --- L(Val, RNN): 0.3244281 --- L(Val, SINDy): 0.3390090 --- Time: 1.76s; --- Convergence: 2.30e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.136 1 + 0.493 value_stay[t] + 0.269 reward + -0.038 harvest_duration + 0.12 value_stay^2 + 0.081 value_stay*reward + -0.345 value_stay*harvest_duration + 0.714 reward^2 + 0.273 reward*harvest_duration + -0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.002 value_exit[t] + -0.015 travel_duration + 0.043 value_exit^2 + -0.098 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 154/1000 --- L(Train): 0.3906905 --- L(Val, RNN): 0.3247790 --- L(Val, SINDy): 0.3381380 --- Time: 2.35s; --- Convergence: 2.91e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.137 1 + 0.49 value_stay[t] + 0.266 reward + -0.04 harvest_duration + 0.121 value_stay^2 + 0.082 value_stay*reward + -0.348 value_stay*harvest_duration + 0.713 reward^2 + 0.27 reward*harvest_duration + -0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.016 travel_duration + 0.043 value_exit^2 + -0.097 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 155/1000 --- L(Train): 0.3895659 --- L(Val, RNN): 0.3249811 --- L(Val, SINDy): 0.3378260 --- Time: 3.64s; --- Convergence: 2.46e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.138 1 + 0.489 value_stay[t] + 0.263 reward + -0.042 harvest_duration + 0.122 value_stay^2 + 0.083 value_stay*reward + -0.35 value_stay*harvest_duration + 0.712 reward^2 + 0.267 reward*harvest_duration + -0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.004 value_exit[t] + -0.017 travel_duration + 0.042 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 156/1000 --- L(Train): 0.3780435 --- L(Val, RNN): 0.3250820 --- L(Val, SINDy): 0.3396377 --- Time: 5.51s; --- Convergence: 1.74e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.142 1 + 0.49 value_stay[t] + 0.262 reward + -0.041 harvest_duration + 0.125 value_stay^2 + 0.086 value_stay*reward + -0.35 value_stay*harvest_duration + 0.714 reward^2 + 0.266 reward*harvest_duration + -0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.017 travel_duration + 0.043 value_exit^2 + -0.097 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 157/1000 --- L(Train): 0.3843363 --- L(Val, RNN): 0.3252389 --- L(Val, SINDy): 0.3434076 --- Time: 3.79s; --- Convergence: 1.65e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.148 1 + 0.493 value_stay[t] + 0.263 reward + -0.037 harvest_duration + 0.13 value_stay^2 + 0.091 value_stay*reward + -0.347 value_stay*harvest_duration + 0.718 reward^2 + 0.268 reward*harvest_duration + -0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 1.001 value_exit[t] + -0.015 travel_duration + 0.044 value_exit^2 + -0.099 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 158/1000 --- L(Train): 0.3957593 --- L(Val, RNN): 0.3254926 --- L(Val, SINDy): 0.3415511 --- Time: 3.11s; --- Convergence: 2.09e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.153 1 + 0.496 value_stay[t] + 0.265 reward + -0.034 harvest_duration + 0.135 value_stay^2 + 0.096 value_stay*reward + -0.344 value_stay*harvest_duration + 0.721 reward^2 + 0.269 reward*harvest_duration + -0.036 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 1.0 value_exit[t] + -0.014 travel_duration + 0.045 value_exit^2 + -0.1 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 159/1000 --- L(Train): 0.3976619 --- L(Val, RNN): 0.3258745 --- L(Val, SINDy): 0.3398752 --- Time: 3.68s; --- Convergence: 2.96e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.159 1 + 0.499 value_stay[t] + 0.265 reward + -0.032 harvest_duration + 0.14 value_stay^2 + 0.1 value_stay*reward + -0.343 value_stay*harvest_duration + 0.724 reward^2 + 0.27 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 1.0 value_exit[t] + -0.014 travel_duration + 0.045 value_exit^2 + -0.1 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 160/1000 --- L(Train): 0.3910590 --- L(Val, RNN): 0.3260571 --- L(Val, SINDy): 0.3400107 --- Time: 6.47s; --- Convergence: 2.39e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.161 1 + 0.499 value_stay[t] + 0.264 reward + -0.031 harvest_duration + 0.142 value_stay^2 + 0.102 value_stay*reward + -0.343 value_stay*harvest_duration + 0.725 reward^2 + 0.268 reward*harvest_duration + -0.033 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.002 value_exit[t] + -0.016 travel_duration + 0.044 value_exit^2 + -0.098 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 161/1000 --- L(Train): 0.3898806 --- L(Val, RNN): 0.3260823 --- L(Val, SINDy): 0.3412288 --- Time: 5.19s; --- Convergence: 1.32e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.162 1 + 0.497 value_stay[t] + 0.261 reward + -0.032 harvest_duration + 0.141 value_stay^2 + 0.102 value_stay*reward + -0.346 value_stay*harvest_duration + 0.724 reward^2 + 0.265 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.017 travel_duration + 0.043 value_exit^2 + -0.096 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 162/1000 --- L(Train): 0.4051255 --- L(Val, RNN): 0.3263068 --- L(Val, SINDy): 0.3408326 --- Time: 3.70s; --- Convergence: 1.78e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.161 1 + 0.493 value_stay[t] + 0.257 reward + -0.035 harvest_duration + 0.139 value_stay^2 + 0.1 value_stay*reward + -0.35 value_stay*harvest_duration + 0.721 reward^2 + 0.261 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.018 travel_duration + 0.042 value_exit^2 + -0.096 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 163/1000 --- L(Train): 0.3977874 --- L(Val, RNN): 0.3267061 --- L(Val, SINDy): 0.3388878 --- Time: 2.56s; --- Convergence: 2.89e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.159 1 + 0.487 value_stay[t] + 0.251 reward + -0.039 harvest_duration + 0.136 value_stay^2 + 0.097 value_stay*reward + -0.356 value_stay*harvest_duration + 0.718 reward^2 + 0.255 reward*harvest_duration + -0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 1.0 value_exit[t] + -0.015 travel_duration + 0.045 value_exit^2 + -0.099 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 164/1000 --- L(Train): 0.3998370 --- L(Val, RNN): 0.3270072 --- L(Val, SINDy): 0.3385317 --- Time: 2.90s; --- Convergence: 2.95e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.158 1 + 0.483 value_stay[t] + 0.246 reward + -0.042 harvest_duration + 0.134 value_stay^2 + 0.094 value_stay*reward + -0.36 value_stay*harvest_duration + 0.715 reward^2 + 0.25 reward*harvest_duration + -0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.998 value_exit[t] + -0.012 travel_duration + 0.047 value_exit^2 + -0.102 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 165/1000 --- L(Train): 0.3992549 --- L(Val, RNN): 0.3271177 --- L(Val, SINDy): 0.3396792 --- Time: 1.87s; --- Convergence: 2.03e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.162 1 + 0.485 value_stay[t] + 0.246 reward + -0.04 harvest_duration + 0.138 value_stay^2 + 0.098 value_stay*reward + -0.359 value_stay*harvest_duration + 0.717 reward^2 + 0.251 reward*harvest_duration + -0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 1.001 value_exit[t] + -0.015 travel_duration + 0.045 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 166/1000 --- L(Train): 0.3949247 --- L(Val, RNN): 0.3269964 --- L(Val, SINDy): 0.3406721 --- Time: 2.94s; --- Convergence: 1.62e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.167 1 + 0.489 value_stay[t] + 0.248 reward + -0.038 harvest_duration + 0.143 value_stay^2 + 0.102 value_stay*reward + -0.357 value_stay*harvest_duration + 0.72 reward^2 + 0.252 reward*harvest_duration + -0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.018 travel_duration + 0.042 value_exit^2 + -0.096 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 167/1000 --- L(Train): 0.3963901 --- L(Val, RNN): 0.3270382 --- L(Val, SINDy): 0.3401881 --- Time: 1.83s; --- Convergence: 1.02e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.171 1 + 0.491 value_stay[t] + 0.249 reward + -0.035 harvest_duration + 0.147 value_stay^2 + 0.107 value_stay*reward + -0.355 value_stay*harvest_duration + 0.723 reward^2 + 0.254 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.005 value_exit[t] + -0.02 travel_duration + 0.041 value_exit^2 + -0.094 value_exit*travel_duration + -0.019 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 168/1000 --- L(Train): 0.4219224 --- L(Val, RNN): 0.3273104 --- L(Val, SINDy): 0.3390715 --- Time: 1.59s; --- Convergence: 1.87e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.174 1 + 0.493 value_stay[t] + 0.25 reward + -0.033 harvest_duration + 0.15 value_stay^2 + 0.11 value_stay*reward + -0.353 value_stay*harvest_duration + 0.726 reward^2 + 0.254 reward*harvest_duration + -0.035 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.004 value_exit[t] + -0.019 travel_duration + 0.042 value_exit^2 + -0.095 value_exit*travel_duration + -0.018 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 169/1000 --- L(Train): 0.4172429 --- L(Val, RNN): 0.3276533 --- L(Val, SINDy): 0.3374776 --- Time: 0.95s; --- Convergence: 2.65e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.175 1 + 0.493 value_stay[t] + 0.249 reward + -0.034 harvest_duration + 0.152 value_stay^2 + 0.112 value_stay*reward + -0.354 value_stay*harvest_duration + 0.726 reward^2 + 0.253 reward*harvest_duration + -0.036 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.001 value_exit[t] + -0.016 travel_duration + 0.045 value_exit^2 + -0.098 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 170/1000 --- L(Train): 0.3941471 --- L(Val, RNN): 0.3277910 --- L(Val, SINDy): 0.3372464 --- Time: 1.17s; --- Convergence: 2.01e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.174 1 + 0.491 value_stay[t] + 0.246 reward + -0.036 harvest_duration + 0.151 value_stay^2 + 0.111 value_stay*reward + -0.357 value_stay*harvest_duration + 0.725 reward^2 + 0.25 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.998 value_exit[t] + -0.013 travel_duration + 0.047 value_exit^2 + -0.101 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 171/1000 --- L(Train): 0.3950651 --- L(Val, RNN): 0.3278462 --- L(Val, SINDy): 0.3382113 --- Time: 0.85s; --- Convergence: 1.28e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.173 1 + 0.487 value_stay[t] + 0.242 reward + -0.038 harvest_duration + 0.149 value_stay^2 + 0.11 value_stay*reward + -0.36 value_stay*harvest_duration + 0.723 reward^2 + 0.246 reward*harvest_duration + -0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.999 value_exit[t] + -0.013 travel_duration + 0.046 value_exit^2 + -0.101 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 172/1000 --- L(Train): 0.4054131 --- L(Val, RNN): 0.3279414 --- L(Val, SINDy): 0.3396854 --- Time: 0.90s; --- Convergence: 1.12e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.174 1 + 0.487 value_stay[t] + 0.241 reward + -0.038 harvest_duration + 0.15 value_stay^2 + 0.112 value_stay*reward + -0.361 value_stay*harvest_duration + 0.723 reward^2 + 0.245 reward*harvest_duration + -0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.018 travel_duration + 0.043 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 173/1000 --- L(Train): 0.4119178 --- L(Val, RNN): 0.3281453 --- L(Val, SINDy): 0.3396498 --- Time: 0.81s; --- Convergence: 1.58e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.177 1 + 0.487 value_stay[t] + 0.241 reward + -0.037 harvest_duration + 0.152 value_stay^2 + 0.115 value_stay*reward + -0.361 value_stay*harvest_duration + 0.725 reward^2 + 0.245 reward*harvest_duration + -0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.088 1 + 1.004 value_exit[t] + -0.019 travel_duration + 0.042 value_exit^2 + -0.095 value_exit*travel_duration + -0.018 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 174/1000 --- L(Train): 0.3892592 --- L(Val, RNN): 0.3282237 --- L(Val, SINDy): 0.3401778 --- Time: 0.84s; --- Convergence: 1.18e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.179 1 + 0.488 value_stay[t] + 0.241 reward + -0.035 harvest_duration + 0.154 value_stay^2 + 0.117 value_stay*reward + -0.36 value_stay*harvest_duration + 0.727 reward^2 + 0.246 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.002 value_exit[t] + -0.018 travel_duration + 0.043 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 175/1000 --- L(Train): 0.3996973 --- L(Val, RNN): 0.3283603 --- L(Val, SINDy): 0.3410309 --- Time: 1.06s; --- Convergence: 1.27e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.181 1 + 0.488 value_stay[t] + 0.241 reward + -0.035 harvest_duration + 0.156 value_stay^2 + 0.12 value_stay*reward + -0.36 value_stay*harvest_duration + 0.728 reward^2 + 0.246 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 1.0 value_exit[t] + -0.015 travel_duration + 0.045 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 176/1000 --- L(Train): 0.4106077 --- L(Val, RNN): 0.3285976 --- L(Val, SINDy): 0.3399905 --- Time: 1.17s; --- Convergence: 1.82e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.182 1 + 0.487 value_stay[t] + 0.24 reward + -0.035 harvest_duration + 0.155 value_stay^2 + 0.12 value_stay*reward + -0.362 value_stay*harvest_duration + 0.728 reward^2 + 0.244 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.999 value_exit[t] + -0.014 travel_duration + 0.047 value_exit^2 + -0.101 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 177/1000 --- L(Train): 0.4110871 --- L(Val, RNN): 0.3288158 --- L(Val, SINDy): 0.3373711 --- Time: 0.98s; --- Convergence: 2.00e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.182 1 + 0.484 value_stay[t] + 0.237 reward + -0.036 harvest_duration + 0.154 value_stay^2 + 0.12 value_stay*reward + -0.364 value_stay*harvest_duration + 0.728 reward^2 + 0.242 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.999 value_exit[t] + -0.014 travel_duration + 0.046 value_exit^2 + -0.1 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 178/1000 --- L(Train): 0.4193509 --- L(Val, RNN): 0.3289137 --- L(Val, SINDy): 0.3375634 --- Time: 1.17s; --- Convergence: 1.49e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.181 1 + 0.482 value_stay[t] + 0.235 reward + -0.036 harvest_duration + 0.153 value_stay^2 + 0.12 value_stay*reward + -0.367 value_stay*harvest_duration + 0.727 reward^2 + 0.239 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.001 value_exit[t] + -0.016 travel_duration + 0.044 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 179/1000 --- L(Train): 0.4000045 --- L(Val, RNN): 0.3289104 --- L(Val, SINDy): 0.3370635 --- Time: 0.99s; --- Convergence: 7.62e-05; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.181 1 + 0.479 value_stay[t] + 0.233 reward + -0.037 harvest_duration + 0.152 value_stay^2 + 0.12 value_stay*reward + -0.369 value_stay*harvest_duration + 0.726 reward^2 + 0.237 reward*harvest_duration + -0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.003 value_exit[t] + -0.018 travel_duration + 0.043 value_exit^2 + -0.096 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 180/1000 --- L(Train): 0.3963223 --- L(Val, RNN): 0.3290032 --- L(Val, SINDy): 0.3376008 --- Time: 1.00s; --- Convergence: 8.45e-05; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.182 1 + 0.478 value_stay[t] + 0.232 reward + -0.037 harvest_duration + 0.151 value_stay^2 + 0.12 value_stay*reward + -0.371 value_stay*harvest_duration + 0.726 reward^2 + 0.236 reward*harvest_duration + -0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.002 value_exit[t] + -0.018 travel_duration + 0.043 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 181/1000 --- L(Train): 0.4198335 --- L(Val, RNN): 0.3292559 --- L(Val, SINDy): 0.3373412 --- Time: 1.02s; --- Convergence: 1.69e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.183 1 + 0.477 value_stay[t] + 0.231 reward + -0.036 harvest_duration + 0.151 value_stay^2 + 0.122 value_stay*reward + -0.372 value_stay*harvest_duration + 0.727 reward^2 + 0.236 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + -0.016 travel_duration + 0.045 value_exit^2 + -0.099 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 182/1000 --- L(Train): 0.4334241 --- L(Val, RNN): 0.3296250 --- L(Val, SINDy): 0.3371840 --- Time: 0.83s; --- Convergence: 2.69e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.184 1 + 0.476 value_stay[t] + 0.231 reward + -0.036 harvest_duration + 0.15 value_stay^2 + 0.124 value_stay*reward + -0.372 value_stay*harvest_duration + 0.728 reward^2 + 0.235 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.999 value_exit[t] + -0.014 travel_duration + 0.046 value_exit^2 + -0.1 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 183/1000 --- L(Train): 0.4184193 --- L(Val, RNN): 0.3299550 --- L(Val, SINDy): 0.3379574 --- Time: 0.84s; --- Convergence: 2.99e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.184 1 + 0.474 value_stay[t] + 0.23 reward + -0.035 harvest_duration + 0.15 value_stay^2 + 0.125 value_stay*reward + -0.373 value_stay*harvest_duration + 0.728 reward^2 + 0.234 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.999 value_exit[t] + -0.014 travel_duration + 0.047 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 184/1000 --- L(Train): 0.4123039 --- L(Val, RNN): 0.3300574 --- L(Val, SINDy): 0.3385688 --- Time: 0.84s; --- Convergence: 2.01e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.184 1 + 0.472 value_stay[t] + 0.228 reward + -0.035 harvest_duration + 0.149 value_stay^2 + 0.125 value_stay*reward + -0.375 value_stay*harvest_duration + 0.728 reward^2 + 0.233 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 1.0 value_exit[t] + -0.015 travel_duration + 0.046 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 185/1000 --- L(Train): 0.3994339 --- L(Val, RNN): 0.3300838 --- L(Val, SINDy): 0.3390663 --- Time: 0.88s; --- Convergence: 1.14e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.184 1 + 0.47 value_stay[t] + 0.227 reward + -0.035 harvest_duration + 0.148 value_stay^2 + 0.126 value_stay*reward + -0.376 value_stay*harvest_duration + 0.727 reward^2 + 0.231 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.001 value_exit[t] + -0.017 travel_duration + 0.045 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 186/1000 --- L(Train): 0.4804729 --- L(Val, RNN): 0.3301141 --- L(Val, SINDy): 0.3391569 --- Time: 0.89s; --- Convergence: 7.20e-05; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.185 1 + 0.469 value_stay[t] + 0.226 reward + -0.034 harvest_duration + 0.147 value_stay^2 + 0.127 value_stay*reward + -0.377 value_stay*harvest_duration + 0.728 reward^2 + 0.23 reward*harvest_duration + -0.036 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.002 value_exit[t] + -0.017 travel_duration + 0.044 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 187/1000 --- L(Train): 0.4674323 --- L(Val, RNN): 0.3303348 --- L(Val, SINDy): 0.3376388 --- Time: 0.79s; --- Convergence: 1.46e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.186 1 + 0.468 value_stay[t] + 0.225 reward + -0.033 harvest_duration + 0.147 value_stay^2 + 0.129 value_stay*reward + -0.377 value_stay*harvest_duration + 0.728 reward^2 + 0.23 reward*harvest_duration + -0.035 harvest_duration^2 \n",
      "value_exit[t+1] = -0.087 1 + 1.002 value_exit[t] + -0.018 travel_duration + 0.044 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 188/1000 --- L(Train): 0.4357972 --- L(Val, RNN): 0.3305675 --- L(Val, SINDy): 0.3372146 --- Time: 0.84s; --- Convergence: 1.90e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.187 1 + 0.468 value_stay[t] + 0.225 reward + -0.032 harvest_duration + 0.147 value_stay^2 + 0.13 value_stay*reward + -0.377 value_stay*harvest_duration + 0.729 reward^2 + 0.229 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.001 value_exit[t] + -0.017 travel_duration + 0.044 value_exit^2 + -0.098 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 189/1000 --- L(Train): 0.4300498 --- L(Val, RNN): 0.3307293 --- L(Val, SINDy): 0.3379092 --- Time: 1.00s; --- Convergence: 1.76e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.188 1 + 0.467 value_stay[t] + 0.224 reward + -0.031 harvest_duration + 0.147 value_stay^2 + 0.131 value_stay*reward + -0.377 value_stay*harvest_duration + 0.729 reward^2 + 0.228 reward*harvest_duration + -0.033 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + -0.016 travel_duration + 0.045 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 190/1000 --- L(Train): 0.4416681 --- L(Val, RNN): 0.3309361 --- L(Val, SINDy): 0.3381314 --- Time: 0.87s; --- Convergence: 1.91e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.189 1 + 0.466 value_stay[t] + 0.223 reward + -0.031 harvest_duration + 0.146 value_stay^2 + 0.132 value_stay*reward + -0.378 value_stay*harvest_duration + 0.729 reward^2 + 0.227 reward*harvest_duration + -0.033 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.999 value_exit[t] + -0.014 travel_duration + 0.046 value_exit^2 + -0.1 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 191/1000 --- L(Train): 0.4738328 --- L(Val, RNN): 0.3311182 --- L(Val, SINDy): 0.3381907 --- Time: 0.82s; --- Convergence: 1.87e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.189 1 + 0.465 value_stay[t] + 0.222 reward + -0.031 harvest_duration + 0.145 value_stay^2 + 0.132 value_stay*reward + -0.379 value_stay*harvest_duration + 0.728 reward^2 + 0.226 reward*harvest_duration + -0.033 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.998 value_exit[t] + -0.014 travel_duration + 0.047 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 192/1000 --- L(Train): 0.4482856 --- L(Val, RNN): 0.3313543 --- L(Val, SINDy): 0.3388438 --- Time: 1.10s; --- Convergence: 2.11e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.188 1 + 0.463 value_stay[t] + 0.219 reward + -0.031 harvest_duration + 0.144 value_stay^2 + 0.132 value_stay*reward + -0.381 value_stay*harvest_duration + 0.726 reward^2 + 0.223 reward*harvest_duration + -0.033 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 0.999 value_exit[t] + -0.015 travel_duration + 0.046 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 193/1000 --- L(Train): 0.4541990 --- L(Val, RNN): 0.3316438 --- L(Val, SINDy): 0.3387214 --- Time: 0.87s; --- Convergence: 2.50e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.189 1 + 0.462 value_stay[t] + 0.217 reward + -0.031 harvest_duration + 0.144 value_stay^2 + 0.133 value_stay*reward + -0.381 value_stay*harvest_duration + 0.725 reward^2 + 0.222 reward*harvest_duration + -0.033 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.001 value_exit[t] + -0.017 travel_duration + 0.045 value_exit^2 + -0.098 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 194/1000 --- L(Train): 0.4646768 --- L(Val, RNN): 0.3316591 --- L(Val, SINDy): 0.3386627 --- Time: 0.90s; --- Convergence: 1.33e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.191 1 + 0.463 value_stay[t] + 0.216 reward + -0.03 harvest_duration + 0.144 value_stay^2 + 0.134 value_stay*reward + -0.381 value_stay*harvest_duration + 0.725 reward^2 + 0.221 reward*harvest_duration + -0.032 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.002 value_exit[t] + -0.017 travel_duration + 0.044 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 195/1000 --- L(Train): 0.4486984 --- L(Val, RNN): 0.3317057 --- L(Val, SINDy): 0.3383778 --- Time: 1.00s; --- Convergence: 8.97e-05; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.193 1 + 0.463 value_stay[t] + 0.216 reward + -0.028 harvest_duration + 0.145 value_stay^2 + 0.135 value_stay*reward + -0.38 value_stay*harvest_duration + 0.725 reward^2 + 0.22 reward*harvest_duration + -0.03 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.001 value_exit[t] + -0.016 travel_duration + 0.045 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 196/1000 --- L(Train): 0.4498152 --- L(Val, RNN): 0.3318886 --- L(Val, SINDy): 0.3382736 --- Time: 1.30s; --- Convergence: 1.36e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.195 1 + 0.464 value_stay[t] + 0.215 reward + -0.027 harvest_duration + 0.146 value_stay^2 + 0.137 value_stay*reward + -0.38 value_stay*harvest_duration + 0.725 reward^2 + 0.219 reward*harvest_duration + -0.029 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 0.999 value_exit[t] + -0.015 travel_duration + 0.046 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 197/1000 --- L(Train): 0.4610845 --- L(Val, RNN): 0.3319443 --- L(Val, SINDy): 0.3380778 --- Time: 0.85s; --- Convergence: 9.60e-05; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.197 1 + 0.465 value_stay[t] + 0.214 reward + -0.026 harvest_duration + 0.146 value_stay^2 + 0.138 value_stay*reward + -0.38 value_stay*harvest_duration + 0.724 reward^2 + 0.218 reward*harvest_duration + -0.028 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.998 value_exit[t] + -0.014 travel_duration + 0.047 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 198/1000 --- L(Train): 0.4591763 --- L(Val, RNN): 0.3320583 --- L(Val, SINDy): 0.3380427 --- Time: 0.93s; --- Convergence: 1.05e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.198 1 + 0.464 value_stay[t] + 0.212 reward + -0.026 harvest_duration + 0.146 value_stay^2 + 0.138 value_stay*reward + -0.38 value_stay*harvest_duration + 0.723 reward^2 + 0.216 reward*harvest_duration + -0.028 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.998 value_exit[t] + -0.014 travel_duration + 0.047 value_exit^2 + -0.1 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 199/1000 --- L(Train): 0.4608829 --- L(Val, RNN): 0.3322850 --- L(Val, SINDy): 0.3381572 --- Time: 0.84s; --- Convergence: 1.66e-04; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.198 1 + 0.463 value_stay[t] + 0.209 reward + -0.027 harvest_duration + 0.145 value_stay^2 + 0.138 value_stay*reward + -0.382 value_stay*harvest_duration + 0.721 reward^2 + 0.213 reward*harvest_duration + -0.029 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 0.999 value_exit[t] + -0.015 travel_duration + 0.046 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\n",
      ">>> Warmup complete (epoch 200). Reset optimizer state for 2 SINDy parameters (fresh start at full regularization strength).\n",
      "\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 200/1000 --- L(Train): 0.4484673 --- L(Val, RNN): 0.3324696 --- L(Val, SINDy): 0.3384752 --- Time: 0.93s; --- Convergence: 1.75e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.198 1 + 0.462 value_stay[t] + 0.206 reward + -0.028 harvest_duration + 0.144 value_stay^2 + 0.138 value_stay*reward + -0.383 value_stay*harvest_duration + 0.719 reward^2 + 0.211 reward*harvest_duration + -0.03 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + -0.016 travel_duration + 0.045 value_exit^2 + -0.098 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 1, 0, 0, 0, 0, 0, 1\n",
      "value_exit: 0, 1, 1, 1, 0, 1\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 201/1000 --- L(Train): 0.4447877 --- L(Val, RNN): 0.3326565 --- L(Val, SINDy): 0.4140917 --- Time: 0.88s; --- Convergence: 1.81e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 1/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.208 1 + 0.472 value_stay[t] + 0.216 reward + -0.018 harvest_duration + 0.154 value_stay^2 + 0.148 value_stay*reward + -0.373 value_stay*harvest_duration + 0.729 reward^2 + 0.221 reward*harvest_duration + -0.02 harvest_duration^2 \n",
      "value_exit[t+1] = -0.075 1 + 0.99 value_exit[t] + -0.006 travel_duration + 0.055 value_exit^2 + -0.108 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 2, 0, 0, 0, 0, 0, 2\n",
      "value_exit: 0, 2, 2, 0, 0, 2\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 202/1000 --- L(Train): 3.1607802 --- L(Val, RNN): 0.3335262 --- L(Val, SINDy): 0.3742627 --- Time: 1.15s; --- Convergence: 5.25e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 2/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.212 1 + 0.477 value_stay[t] + 0.22 reward + -0.014 harvest_duration + 0.158 value_stay^2 + 0.153 value_stay*reward + -0.369 value_stay*harvest_duration + 0.732 reward^2 + 0.224 reward*harvest_duration + -0.016 harvest_duration^2 \n",
      "value_exit[t+1] = -0.071 1 + 0.986 value_exit[t] + -0.002 travel_duration + 0.059 value_exit^2 + -0.112 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 3, 0, 0, 0, 0, 0, 3\n",
      "value_exit: 0, 3, 3, 0, 0, 3\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 203/1000 --- L(Train): 1.9332011 --- L(Val, RNN): 0.3344940 --- L(Val, SINDy): 0.3566760 --- Time: 0.86s; --- Convergence: 7.47e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 3/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.209 1 + 0.473 value_stay[t] + 0.214 reward + -0.019 harvest_duration + 0.154 value_stay^2 + 0.15 value_stay*reward + -0.373 value_stay*harvest_duration + 0.727 reward^2 + 0.219 reward*harvest_duration + -0.021 harvest_duration^2 \n",
      "value_exit[t+1] = -0.076 1 + 0.991 value_exit[t] + -0.007 travel_duration + 0.055 value_exit^2 + -0.108 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 4, 0, 0, 0, 0, 0, 4\n",
      "value_exit: 0, 4, 4, 0, 0, 4\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 204/1000 --- L(Train): 1.4744061 --- L(Val, RNN): 0.3351893 --- L(Val, SINDy): 0.3581871 --- Time: 0.89s; --- Convergence: 7.21e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 4/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.205 1 + 0.469 value_stay[t] + 0.209 reward + -0.025 harvest_duration + 0.149 value_stay^2 + 0.147 value_stay*reward + -0.378 value_stay*harvest_duration + 0.722 reward^2 + 0.213 reward*harvest_duration + -0.027 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.996 value_exit[t] + -0.012 travel_duration + 0.05 value_exit^2 + -0.103 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 5, 0, 0, 0, 0, 0, 5\n",
      "value_exit: 0, 5, 5, 1, 0, 5\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 205/1000 --- L(Train): 1.5572056 --- L(Val, RNN): 0.3357444 --- L(Val, SINDy): 0.3562026 --- Time: 1.02s; --- Convergence: 6.38e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 5/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.201 1 + 0.465 value_stay[t] + 0.203 reward + -0.03 harvest_duration + 0.145 value_stay^2 + 0.144 value_stay*reward + -0.383 value_stay*harvest_duration + 0.717 reward^2 + 0.208 reward*harvest_duration + -0.032 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.002 value_exit[t] + -0.018 travel_duration + 0.044 value_exit^2 + -0.097 value_exit*travel_duration + -0.017 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 6, 0, 0, 0, 0, 0, 6\n",
      "value_exit: 0, 6, 6, 2, 0, 6\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 206/1000 --- L(Train): 1.4218611 --- L(Val, RNN): 0.3360967 --- L(Val, SINDy): 0.3555548 --- Time: 0.93s; --- Convergence: 4.95e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 6/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.198 1 + 0.462 value_stay[t] + 0.199 reward + -0.034 harvest_duration + 0.141 value_stay^2 + 0.142 value_stay*reward + -0.386 value_stay*harvest_duration + 0.712 reward^2 + 0.203 reward*harvest_duration + -0.036 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.006 value_exit[t] + -0.022 travel_duration + 0.04 value_exit^2 + -0.093 value_exit*travel_duration + -0.021 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 7, 0, 0, 0, 0, 0, 7\n",
      "value_exit: 0, 7, 7, 3, 0, 7\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 207/1000 --- L(Train): 1.0544778 --- L(Val, RNN): 0.3363020 --- L(Val, SINDy): 0.3596557 --- Time: 0.88s; --- Convergence: 3.50e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 7/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.197 1 + 0.461 value_stay[t] + 0.197 reward + -0.036 harvest_duration + 0.14 value_stay^2 + 0.142 value_stay*reward + -0.388 value_stay*harvest_duration + 0.711 reward^2 + 0.202 reward*harvest_duration + -0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.092 1 + 1.007 value_exit[t] + -0.024 travel_duration + 0.038 value_exit^2 + -0.091 value_exit*travel_duration + -0.023 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 8, 0, 0, 0, 0, 0, 8\n",
      "value_exit: 0, 8, 8, 4, 0, 8\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 208/1000 --- L(Train): 0.8520912 --- L(Val, RNN): 0.3365931 --- L(Val, SINDy): 0.3643555 --- Time: 0.85s; --- Convergence: 3.21e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 8/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.199 1 + 0.463 value_stay[t] + 0.198 reward + -0.035 harvest_duration + 0.142 value_stay^2 + 0.144 value_stay*reward + -0.386 value_stay*harvest_duration + 0.712 reward^2 + 0.202 reward*harvest_duration + -0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.091 1 + 1.006 value_exit[t] + -0.023 travel_duration + 0.039 value_exit^2 + -0.092 value_exit*travel_duration + -0.022 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 9, 0, 0, 0, 0, 0, 9\n",
      "value_exit: 0, 9, 9, 5, 0, 9\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 209/1000 --- L(Train): 0.9432642 --- L(Val, RNN): 0.3370097 --- L(Val, SINDy): 0.3638059 --- Time: 0.75s; --- Convergence: 3.69e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 9/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.202 1 + 0.465 value_stay[t] + 0.2 reward + -0.033 harvest_duration + 0.144 value_stay^2 + 0.147 value_stay*reward + -0.384 value_stay*harvest_duration + 0.713 reward^2 + 0.204 reward*harvest_duration + -0.035 harvest_duration^2 \n",
      "value_exit[t+1] = -0.089 1 + 1.004 value_exit[t] + -0.021 travel_duration + 0.041 value_exit^2 + -0.094 value_exit*travel_duration + -0.019 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 10, 0, 0, 0, 0, 0, 10\n",
      "value_exit: 0, 10, 10, 6, 0, 10\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 210/1000 --- L(Train): 0.9578822 --- L(Val, RNN): 0.3375063 --- L(Val, SINDy): 0.3599927 --- Time: 0.91s; --- Convergence: 4.33e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 10/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.205 1 + 0.468 value_stay[t] + 0.202 reward + -0.031 harvest_duration + 0.147 value_stay^2 + 0.15 value_stay*reward + -0.382 value_stay*harvest_duration + 0.715 reward^2 + 0.206 reward*harvest_duration + -0.033 harvest_duration^2 \n",
      "value_exit[t+1] = -0.086 1 + 1.001 value_exit[t] + -0.017 travel_duration + 0.044 value_exit^2 + -0.097 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 11, 0, 0, 0, 0, 0, 11\n",
      "value_exit: 0, 11, 11, 7, 0, 11\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 211/1000 --- L(Train): 0.9274210 --- L(Val, RNN): 0.3380558 --- L(Val, SINDy): 0.3571654 --- Time: 1.01s; --- Convergence: 4.91e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 11/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.208 1 + 0.471 value_stay[t] + 0.204 reward + -0.028 harvest_duration + 0.149 value_stay^2 + 0.153 value_stay*reward + -0.379 value_stay*harvest_duration + 0.717 reward^2 + 0.208 reward*harvest_duration + -0.03 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.998 value_exit[t] + -0.014 travel_duration + 0.047 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 12, 0, 0, 0, 0, 0, 12\n",
      "value_exit: 0, 12, 12, 8, 0, 12\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 212/1000 --- L(Train): 0.8633414 --- L(Val, RNN): 0.3386598 --- L(Val, SINDy): 0.3523088 --- Time: 1.26s; --- Convergence: 5.47e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 12/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.209 1 + 0.473 value_stay[t] + 0.205 reward + -0.027 harvest_duration + 0.15 value_stay^2 + 0.155 value_stay*reward + -0.378 value_stay*harvest_duration + 0.718 reward^2 + 0.209 reward*harvest_duration + -0.029 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.995 value_exit[t] + -0.011 travel_duration + 0.05 value_exit^2 + -0.103 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 13, 0, 0, 0, 0, 0, 13\n",
      "value_exit: 0, 13, 13, 0, 0, 13\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 213/1000 --- L(Train): 0.7515696 --- L(Val, RNN): 0.3391999 --- L(Val, SINDy): 0.3476968 --- Time: 0.84s; --- Convergence: 5.44e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 13/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.209 1 + 0.471 value_stay[t] + 0.203 reward + -0.028 harvest_duration + 0.149 value_stay^2 + 0.154 value_stay*reward + -0.38 value_stay*harvest_duration + 0.716 reward^2 + 0.207 reward*harvest_duration + -0.03 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.994 value_exit[t] + -0.01 travel_duration + 0.051 value_exit^2 + -0.104 value_exit*travel_duration + -0.009 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 14, 0, 0, 0, 0, 0, 14\n",
      "value_exit: 0, 14, 14, 0, 0, 14\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 214/1000 --- L(Train): 0.6936690 --- L(Val, RNN): 0.3396359 --- L(Val, SINDy): 0.3457995 --- Time: 1.02s; --- Convergence: 4.90e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 14/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.207 1 + 0.47 value_stay[t] + 0.2 reward + -0.03 harvest_duration + 0.147 value_stay^2 + 0.152 value_stay*reward + -0.382 value_stay*harvest_duration + 0.713 reward^2 + 0.204 reward*harvest_duration + -0.032 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.994 value_exit[t] + -0.01 travel_duration + 0.051 value_exit^2 + -0.104 value_exit*travel_duration + -0.009 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 15, 0, 0, 0, 0, 0, 15\n",
      "value_exit: 0, 15, 15, 0, 0, 15\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 215/1000 --- L(Train): 0.6556407 --- L(Val, RNN): 0.3398949 --- L(Val, SINDy): 0.3463714 --- Time: 0.98s; --- Convergence: 3.74e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 15/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.206 1 + 0.467 value_stay[t] + 0.197 reward + -0.032 harvest_duration + 0.144 value_stay^2 + 0.15 value_stay*reward + -0.384 value_stay*harvest_duration + 0.71 reward^2 + 0.201 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.995 value_exit[t] + -0.012 travel_duration + 0.05 value_exit^2 + -0.103 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 16, 0, 0, 0, 0, 0, 16\n",
      "value_exit: 0, 16, 16, 0, 0, 16\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 216/1000 --- L(Train): 0.6325753 --- L(Val, RNN): 0.3400549 --- L(Val, SINDy): 0.3492553 --- Time: 1.25s; --- Convergence: 2.67e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 16/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.204 1 + 0.465 value_stay[t] + 0.194 reward + -0.033 harvest_duration + 0.142 value_stay^2 + 0.148 value_stay*reward + -0.386 value_stay*harvest_duration + 0.707 reward^2 + 0.198 reward*harvest_duration + -0.035 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.014 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 17, 0, 0, 0, 0, 0, 17\n",
      "value_exit: 0, 17, 17, 1, 0, 17\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 217/1000 --- L(Train): 0.6362990 --- L(Val, RNN): 0.3401966 --- L(Val, SINDy): 0.3540957 --- Time: 2.04s; --- Convergence: 2.04e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 17/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.204 1 + 0.464 value_stay[t] + 0.192 reward + -0.033 harvest_duration + 0.141 value_stay^2 + 0.147 value_stay*reward + -0.387 value_stay*harvest_duration + 0.706 reward^2 + 0.196 reward*harvest_duration + -0.035 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.998 value_exit[t] + -0.016 travel_duration + 0.047 value_exit^2 + -0.099 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 18, 0, 0, 0, 0, 0, 18\n",
      "value_exit: 0, 18, 18, 2, 0, 18\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 218/1000 --- L(Train): 0.5982640 --- L(Val, RNN): 0.3404363 --- L(Val, SINDy): 0.3567891 --- Time: 5.11s; --- Convergence: 2.22e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 18/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.205 1 + 0.464 value_stay[t] + 0.191 reward + -0.032 harvest_duration + 0.14 value_stay^2 + 0.147 value_stay*reward + -0.387 value_stay*harvest_duration + 0.705 reward^2 + 0.196 reward*harvest_duration + -0.034 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + -0.017 travel_duration + 0.046 value_exit^2 + -0.098 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 19, 0, 0, 0, 0, 0, 19\n",
      "value_exit: 0, 19, 19, 3, 0, 19\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 219/1000 --- L(Train): 0.5860381 --- L(Val, RNN): 0.3407426 --- L(Val, SINDy): 0.3560641 --- Time: 5.89s; --- Convergence: 2.64e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 19/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.207 1 + 0.465 value_stay[t] + 0.192 reward + -0.03 harvest_duration + 0.141 value_stay^2 + 0.148 value_stay*reward + -0.386 value_stay*harvest_duration + 0.705 reward^2 + 0.196 reward*harvest_duration + -0.032 harvest_duration^2 \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + -0.017 travel_duration + 0.046 value_exit^2 + -0.098 value_exit*travel_duration + -0.016 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 20, 0, 0, 0, 0, 0, 20\n",
      "value_exit: 0, 20, 20, 4, 0, 20\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 220/1000 --- L(Train): 0.5970812 --- L(Val, RNN): 0.3411337 --- L(Val, SINDy): 0.3530634 --- Time: 2.71s; --- Convergence: 3.28e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 20/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.21 1 + 0.466 value_stay[t] + 0.193 reward + -0.027 harvest_duration + 0.142 value_stay^2 + 0.149 value_stay*reward + -0.384 value_stay*harvest_duration + 0.707 reward^2 + 0.197 reward*harvest_duration + -0.029 harvest_duration^2 \n",
      "value_exit[t+1] = -0.084 1 + 0.999 value_exit[t] + -0.017 travel_duration + 0.047 value_exit^2 + -0.099 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 21, 0, 0, 0, 0, 0, 21\n",
      "value_exit: 0, 21, 21, 5, 0, 21\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 221/1000 --- L(Train): 0.5584361 --- L(Val, RNN): 0.3415103 --- L(Val, SINDy): 0.3498115 --- Time: 2.25s; --- Convergence: 3.52e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 21/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.213 1 + 0.468 value_stay[t] + 0.194 reward + -0.024 harvest_duration + 0.143 value_stay^2 + 0.151 value_stay*reward + -0.383 value_stay*harvest_duration + 0.708 reward^2 + 0.198 reward*harvest_duration + -0.026 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.998 value_exit[t] + -0.016 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 22, 0, 0, 0, 0, 0, 22\n",
      "value_exit: 0, 22, 22, 6, 0, 22\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 222/1000 --- L(Train): 0.5047039 --- L(Val, RNN): 0.3417369 --- L(Val, SINDy): 0.3491075 --- Time: 2.27s; --- Convergence: 2.89e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 22/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.215 1 + 0.469 value_stay[t] + 0.195 reward + -0.021 harvest_duration + 0.144 value_stay^2 + 0.152 value_stay*reward + -0.381 value_stay*harvest_duration + 0.709 reward^2 + 0.199 reward*harvest_duration + -0.023 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.996 value_exit[t] + -0.014 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 23, 0, 0, 0, 0, 0, 23\n",
      "value_exit: 0, 23, 23, 7, 0, 23\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 223/1000 --- L(Train): 0.5085118 --- L(Val, RNN): 0.3417372 --- L(Val, SINDy): 0.3487705 --- Time: 2.34s; --- Convergence: 1.45e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 23/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.215 1 + 0.468 value_stay[t] + 0.194 reward + -0.021 harvest_duration + 0.143 value_stay^2 + 0.151 value_stay*reward + -0.382 value_stay*harvest_duration + 0.707 reward^2 + 0.198 reward*harvest_duration + -0.023 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.995 value_exit[t] + -0.013 travel_duration + 0.051 value_exit^2 + -0.102 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 24, 0, 0, 0, 0, 0, 24\n",
      "value_exit: 0, 24, 24, 0, 0, 24\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 224/1000 --- L(Train): 0.5148552 --- L(Val, RNN): 0.3416036 --- L(Val, SINDy): 0.3485470 --- Time: 2.92s; --- Convergence: 1.39e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 24/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.214 1 + 0.466 value_stay[t] + 0.191 reward + -0.022 harvest_duration + 0.14 value_stay^2 + 0.148 value_stay*reward + -0.384 value_stay*harvest_duration + 0.704 reward^2 + 0.195 reward*harvest_duration + -0.024 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.994 value_exit[t] + -0.012 travel_duration + 0.052 value_exit^2 + -0.103 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 25, 0, 0, 0, 0, 0, 25\n",
      "value_exit: 0, 25, 25, 0, 0, 25\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 225/1000 --- L(Train): 0.5211936 --- L(Val, RNN): 0.3416046 --- L(Val, SINDy): 0.3476354 --- Time: 2.35s; --- Convergence: 7.01e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 25/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.213 1 + 0.463 value_stay[t] + 0.188 reward + -0.023 harvest_duration + 0.138 value_stay^2 + 0.146 value_stay*reward + -0.387 value_stay*harvest_duration + 0.702 reward^2 + 0.192 reward*harvest_duration + -0.025 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.993 value_exit[t] + -0.011 travel_duration + 0.052 value_exit^2 + -0.104 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 26, 0, 0, 0, 0, 0, 26\n",
      "value_exit: 0, 26, 26, 0, 0, 26\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 226/1000 --- L(Train): 0.4919272 --- L(Val, RNN): 0.3416593 --- L(Val, SINDy): 0.3483410 --- Time: 2.70s; --- Convergence: 6.24e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 26/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.213 1 + 0.463 value_stay[t] + 0.187 reward + -0.023 harvest_duration + 0.136 value_stay^2 + 0.145 value_stay*reward + -0.387 value_stay*harvest_duration + 0.701 reward^2 + 0.191 reward*harvest_duration + -0.025 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.993 value_exit[t] + -0.012 travel_duration + 0.052 value_exit^2 + -0.103 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 27, 0, 0, 0, 0, 0, 27\n",
      "value_exit: 0, 27, 27, 0, 0, 27\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 227/1000 --- L(Train): 0.4713509 --- L(Val, RNN): 0.3416198 --- L(Val, SINDy): 0.3495976 --- Time: 1.81s; --- Convergence: 5.10e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 27/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.215 1 + 0.464 value_stay[t] + 0.188 reward + -0.021 harvest_duration + 0.138 value_stay^2 + 0.147 value_stay*reward + -0.386 value_stay*harvest_duration + 0.702 reward^2 + 0.192 reward*harvest_duration + -0.023 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.995 value_exit[t] + -0.014 travel_duration + 0.05 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 28, 0, 0, 0, 0, 0, 28\n",
      "value_exit: 0, 28, 28, 0, 0, 28\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 228/1000 --- L(Train): 0.4704758 --- L(Val, RNN): 0.3414546 --- L(Val, SINDy): 0.3502482 --- Time: 2.54s; --- Convergence: 1.08e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 28/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.218 1 + 0.466 value_stay[t] + 0.189 reward + -0.019 harvest_duration + 0.139 value_stay^2 + 0.149 value_stay*reward + -0.384 value_stay*harvest_duration + 0.703 reward^2 + 0.193 reward*harvest_duration + -0.021 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.016 travel_duration + 0.049 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 29, 0, 0, 0, 0, 0, 29\n",
      "value_exit: 0, 29, 29, 1, 0, 29\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 229/1000 --- L(Train): 0.4700187 --- L(Val, RNN): 0.3414069 --- L(Val, SINDy): 0.3488831 --- Time: 2.02s; --- Convergence: 7.79e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 29/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.22 1 + 0.467 value_stay[t] + 0.189 reward + -0.018 harvest_duration + 0.14 value_stay^2 + 0.151 value_stay*reward + -0.384 value_stay*harvest_duration + 0.704 reward^2 + 0.193 reward*harvest_duration + -0.02 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.996 value_exit[t] + -0.016 travel_duration + 0.049 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 30, 0, 0, 0, 0, 0, 30\n",
      "value_exit: 0, 30, 30, 2, 0, 30\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 230/1000 --- L(Train): 0.4533333 --- L(Val, RNN): 0.3413812 --- L(Val, SINDy): 0.3468323 --- Time: 1.88s; --- Convergence: 5.18e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 30/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.219 1 + 0.465 value_stay[t] + 0.187 reward + -0.019 harvest_duration + 0.138 value_stay^2 + 0.15 value_stay*reward + -0.385 value_stay*harvest_duration + 0.702 reward^2 + 0.191 reward*harvest_duration + -0.021 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.995 value_exit[t] + -0.014 travel_duration + 0.051 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 31, 0, 0, 0, 0, 0, 31\n",
      "value_exit: 0, 31, 31, 0, 0, 31\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 231/1000 --- L(Train): 0.4477691 --- L(Val, RNN): 0.3412105 --- L(Val, SINDy): 0.3463387 --- Time: 1.85s; --- Convergence: 1.11e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 31/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.218 1 + 0.464 value_stay[t] + 0.184 reward + -0.02 harvest_duration + 0.137 value_stay^2 + 0.149 value_stay*reward + -0.387 value_stay*harvest_duration + 0.7 reward^2 + 0.189 reward*harvest_duration + -0.022 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.993 value_exit[t] + -0.013 travel_duration + 0.052 value_exit^2 + -0.103 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 32, 0, 0, 0, 0, 0, 32\n",
      "value_exit: 0, 32, 32, 0, 0, 32\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 232/1000 --- L(Train): 0.4516536 --- L(Val, RNN): 0.3410363 --- L(Val, SINDy): 0.3468645 --- Time: 2.58s; --- Convergence: 1.43e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 32/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.217 1 + 0.462 value_stay[t] + 0.182 reward + -0.022 harvest_duration + 0.135 value_stay^2 + 0.148 value_stay*reward + -0.389 value_stay*harvest_duration + 0.697 reward^2 + 0.186 reward*harvest_duration + -0.024 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 0.992 value_exit[t] + -0.012 travel_duration + 0.054 value_exit^2 + -0.104 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 33, 0, 0, 0, 0, 0, 33\n",
      "value_exit: 0, 33, 33, 0, 0, 33\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 233/1000 --- L(Train): 0.4683941 --- L(Val, RNN): 0.3409162 --- L(Val, SINDy): 0.3478959 --- Time: 1.36s; --- Convergence: 1.31e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 33/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.217 1 + 0.461 value_stay[t] + 0.18 reward + -0.023 harvest_duration + 0.134 value_stay^2 + 0.147 value_stay*reward + -0.391 value_stay*harvest_duration + 0.696 reward^2 + 0.184 reward*harvest_duration + -0.025 harvest_duration^2 \n",
      "value_exit[t+1] = -0.076 1 + 0.991 value_exit[t] + -0.011 travel_duration + 0.054 value_exit^2 + -0.104 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 34, 0, 0, 0, 0, 0, 34\n",
      "value_exit: 0, 34, 34, 0, 0, 34\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 234/1000 --- L(Train): 0.4588708 --- L(Val, RNN): 0.3408676 --- L(Val, SINDy): 0.3485125 --- Time: 0.93s; --- Convergence: 9.00e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 34/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.218 1 + 0.462 value_stay[t] + 0.18 reward + -0.022 harvest_duration + 0.134 value_stay^2 + 0.149 value_stay*reward + -0.39 value_stay*harvest_duration + 0.696 reward^2 + 0.185 reward*harvest_duration + -0.024 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 0.992 value_exit[t] + -0.012 travel_duration + 0.053 value_exit^2 + -0.103 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 35, 0, 0, 0, 0, 0, 35\n",
      "value_exit: 0, 35, 35, 0, 0, 35\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 235/1000 --- L(Train): 0.4448075 --- L(Val, RNN): 0.3408245 --- L(Val, SINDy): 0.3480214 --- Time: 1.27s; --- Convergence: 6.66e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 35/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.22 1 + 0.463 value_stay[t] + 0.181 reward + -0.02 harvest_duration + 0.136 value_stay^2 + 0.15 value_stay*reward + -0.389 value_stay*harvest_duration + 0.697 reward^2 + 0.185 reward*harvest_duration + -0.022 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.993 value_exit[t] + -0.014 travel_duration + 0.053 value_exit^2 + -0.102 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 36, 0, 0, 0, 0, 0, 36\n",
      "value_exit: 0, 36, 36, 0, 0, 36\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 236/1000 --- L(Train): 0.4349307 --- L(Val, RNN): 0.3408145 --- L(Val, SINDy): 0.3466058 --- Time: 1.18s; --- Convergence: 3.83e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 36/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.223 1 + 0.464 value_stay[t] + 0.182 reward + -0.018 harvest_duration + 0.137 value_stay^2 + 0.152 value_stay*reward + -0.388 value_stay*harvest_duration + 0.699 reward^2 + 0.186 reward*harvest_duration + -0.02 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.994 value_exit[t] + -0.015 travel_duration + 0.052 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 37, 0, 0, 0, 0, 0, 37\n",
      "value_exit: 0, 37, 37, 0, 0, 37\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 237/1000 --- L(Train): 0.4441873 --- L(Val, RNN): 0.3407576 --- L(Val, SINDy): 0.3444271 --- Time: 1.13s; --- Convergence: 4.76e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 37/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.224 1 + 0.465 value_stay[t] + 0.182 reward + -0.017 harvest_duration + 0.137 value_stay^2 + 0.153 value_stay*reward + -0.387 value_stay*harvest_duration + 0.699 reward^2 + 0.186 reward*harvest_duration + -0.019 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.994 value_exit[t] + -0.015 travel_duration + 0.052 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 38, 0, 0, 0, 0, 0, 38\n",
      "value_exit: 0, 38, 38, 0, 0, 38\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 238/1000 --- L(Train): 0.4413984 --- L(Val, RNN): 0.3405870 --- L(Val, SINDy): 0.3431724 --- Time: 1.05s; --- Convergence: 1.09e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 38/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.225 1 + 0.465 value_stay[t] + 0.181 reward + -0.017 harvest_duration + 0.137 value_stay^2 + 0.153 value_stay*reward + -0.387 value_stay*harvest_duration + 0.699 reward^2 + 0.185 reward*harvest_duration + -0.019 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.994 value_exit[t] + -0.015 travel_duration + 0.052 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 39, 0, 0, 0, 0, 0, 39\n",
      "value_exit: 0, 39, 39, 0, 0, 39\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 239/1000 --- L(Train): 0.4399113 --- L(Val, RNN): 0.3402090 --- L(Val, SINDy): 0.3435743 --- Time: 0.88s; --- Convergence: 2.44e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 39/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.224 1 + 0.463 value_stay[t] + 0.179 reward + -0.017 harvest_duration + 0.136 value_stay^2 + 0.153 value_stay*reward + -0.389 value_stay*harvest_duration + 0.698 reward^2 + 0.184 reward*harvest_duration + -0.019 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.992 value_exit[t] + -0.014 travel_duration + 0.053 value_exit^2 + -0.102 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 40, 0, 0, 0, 0, 0, 40\n",
      "value_exit: 0, 40, 40, 0, 0, 40\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 240/1000 --- L(Train): 0.4256577 --- L(Val, RNN): 0.3397526 --- L(Val, SINDy): 0.3443553 --- Time: 1.10s; --- Convergence: 3.50e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 40/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.224 1 + 0.462 value_stay[t] + 0.178 reward + -0.018 harvest_duration + 0.135 value_stay^2 + 0.152 value_stay*reward + -0.39 value_stay*harvest_duration + 0.696 reward^2 + 0.182 reward*harvest_duration + -0.02 harvest_duration^2 \n",
      "value_exit[t+1] = -0.076 1 + 0.991 value_exit[t] + -0.013 travel_duration + 0.054 value_exit^2 + -0.103 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 41, 0, 0, 0, 0, 0, 41\n",
      "value_exit: 0, 41, 41, 0, 0, 41\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 241/1000 --- L(Train): 0.4417495 --- L(Val, RNN): 0.3392924 --- L(Val, SINDy): 0.3455099 --- Time: 0.90s; --- Convergence: 4.05e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 41/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.225 1 + 0.462 value_stay[t] + 0.177 reward + -0.018 harvest_duration + 0.134 value_stay^2 + 0.151 value_stay*reward + -0.391 value_stay*harvest_duration + 0.696 reward^2 + 0.181 reward*harvest_duration + -0.02 harvest_duration^2 \n",
      "value_exit[t+1] = -0.076 1 + 0.99 value_exit[t] + -0.012 travel_duration + 0.055 value_exit^2 + -0.104 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 42, 0, 0, 0, 0, 0, 42\n",
      "value_exit: 0, 42, 42, 0, 0, 42\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 242/1000 --- L(Train): 0.4323932 --- L(Val, RNN): 0.3389630 --- L(Val, SINDy): 0.3457211 --- Time: 0.85s; --- Convergence: 3.67e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 42/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.225 1 + 0.461 value_stay[t] + 0.176 reward + -0.017 harvest_duration + 0.133 value_stay^2 + 0.151 value_stay*reward + -0.392 value_stay*harvest_duration + 0.695 reward^2 + 0.18 reward*harvest_duration + -0.019 harvest_duration^2 \n",
      "value_exit[t+1] = -0.075 1 + 0.989 value_exit[t] + -0.011 travel_duration + 0.056 value_exit^2 + -0.104 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 43, 0, 0, 0, 0, 0, 43\n",
      "value_exit: 0, 43, 43, 0, 0, 43\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 243/1000 --- L(Train): 0.4378382 --- L(Val, RNN): 0.3388860 --- L(Val, SINDy): 0.3450460 --- Time: 0.97s; --- Convergence: 2.22e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 43/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.226 1 + 0.461 value_stay[t] + 0.175 reward + -0.017 harvest_duration + 0.133 value_stay^2 + 0.151 value_stay*reward + -0.392 value_stay*harvest_duration + 0.695 reward^2 + 0.179 reward*harvest_duration + -0.019 harvest_duration^2 \n",
      "value_exit[t+1] = -0.075 1 + 0.989 value_exit[t] + -0.011 travel_duration + 0.056 value_exit^2 + -0.104 value_exit*travel_duration + -0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 44, 0, 0, 0, 0, 0, 44\n",
      "value_exit: 0, 44, 44, 0, 0, 44\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 244/1000 --- L(Train): 0.4199235 --- L(Val, RNN): 0.3387924 --- L(Val, SINDy): 0.3438163 --- Time: 1.09s; --- Convergence: 1.58e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 44/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.227 1 + 0.461 value_stay[t] + 0.175 reward + -0.016 harvest_duration + 0.133 value_stay^2 + 0.152 value_stay*reward + -0.392 value_stay*harvest_duration + 0.695 reward^2 + 0.179 reward*harvest_duration + -0.018 harvest_duration^2 \n",
      "value_exit[t+1] = -0.075 1 + 0.99 value_exit[t] + -0.012 travel_duration + 0.055 value_exit^2 + -0.104 value_exit*travel_duration + -0.011 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 45, 0, 0, 0, 0, 0, 45\n",
      "value_exit: 0, 45, 45, 0, 0, 45\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 245/1000 --- L(Train): 0.4334109 --- L(Val, RNN): 0.3387683 --- L(Val, SINDy): 0.3424699 --- Time: 0.83s; --- Convergence: 9.10e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 45/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.229 1 + 0.462 value_stay[t] + 0.176 reward + -0.014 harvest_duration + 0.134 value_stay^2 + 0.153 value_stay*reward + -0.391 value_stay*harvest_duration + 0.697 reward^2 + 0.18 reward*harvest_duration + -0.016 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 0.991 value_exit[t] + -0.014 travel_duration + 0.054 value_exit^2 + -0.102 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 46, 0, 0, 0, 0, 0, 46\n",
      "value_exit: 0, 46, 46, 0, 0, 46\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 246/1000 --- L(Train): 0.4161119 --- L(Val, RNN): 0.3384843 --- L(Val, SINDy): 0.3422161 --- Time: 0.93s; --- Convergence: 1.87e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 46/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.231 1 + 0.463 value_stay[t] + 0.176 reward + -0.013 harvest_duration + 0.135 value_stay^2 + 0.154 value_stay*reward + -0.39 value_stay*harvest_duration + 0.698 reward^2 + 0.181 reward*harvest_duration + -0.015 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.993 value_exit[t] + -0.015 travel_duration + 0.052 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 47, 0, 0, 0, 0, 0, 47\n",
      "value_exit: 0, 47, 47, 0, 0, 47\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 247/1000 --- L(Train): 0.4267038 --- L(Val, RNN): 0.3383148 --- L(Val, SINDy): 0.3421980 --- Time: 1.06s; --- Convergence: 1.78e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 47/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.233 1 + 0.463 value_stay[t] + 0.176 reward + -0.012 harvest_duration + 0.135 value_stay^2 + 0.155 value_stay*reward + -0.39 value_stay*harvest_duration + 0.698 reward^2 + 0.18 reward*harvest_duration + -0.014 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.994 value_exit[t] + -0.016 travel_duration + 0.052 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 48, 0, 0, 0, 0, 0, 48\n",
      "value_exit: 0, 48, 48, 0, 0, 48\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 248/1000 --- L(Train): 0.4255576 --- L(Val, RNN): 0.3381517 --- L(Val, SINDy): 0.3419876 --- Time: 1.01s; --- Convergence: 1.71e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 48/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.233 1 + 0.463 value_stay[t] + 0.175 reward + -0.012 harvest_duration + 0.135 value_stay^2 + 0.155 value_stay*reward + -0.391 value_stay*harvest_duration + 0.697 reward^2 + 0.18 reward*harvest_duration + -0.014 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.993 value_exit[t] + -0.016 travel_duration + 0.052 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 49, 0, 0, 0, 0, 0, 49\n",
      "value_exit: 0, 49, 49, 0, 0, 49\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 249/1000 --- L(Train): 0.4095676 --- L(Val, RNN): 0.3377096 --- L(Val, SINDy): 0.3418244 --- Time: 1.08s; --- Convergence: 3.06e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 49/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.233 1 + 0.462 value_stay[t] + 0.174 reward + -0.012 harvest_duration + 0.134 value_stay^2 + 0.154 value_stay*reward + -0.392 value_stay*harvest_duration + 0.697 reward^2 + 0.179 reward*harvest_duration + -0.014 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.992 value_exit[t] + -0.015 travel_duration + 0.053 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 50, 0, 0, 0, 0, 0, 50\n",
      "value_exit: 0, 50, 50, 0, 0, 50\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 250/1000 --- L(Train): 0.4053139 --- L(Val, RNN): 0.3373820 --- L(Val, SINDy): 0.3416665 --- Time: 0.84s; --- Convergence: 3.17e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 50/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.234 1 + 0.462 value_stay[t] + 0.174 reward + -0.012 harvest_duration + 0.133 value_stay^2 + 0.154 value_stay*reward + -0.393 value_stay*harvest_duration + 0.697 reward^2 + 0.178 reward*harvest_duration + -0.014 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 0.991 value_exit[t] + -0.014 travel_duration + 0.054 value_exit^2 + -0.103 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 51, 0, 0, 0, 0, 0, 51\n",
      "value_exit: 0, 51, 51, 0, 0, 51\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 251/1000 --- L(Train): 0.4160195 --- L(Val, RNN): 0.3371405 --- L(Val, SINDy): 0.3410721 --- Time: 1.06s; --- Convergence: 2.79e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 51/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.235 1 + 0.461 value_stay[t] + 0.173 reward + -0.012 harvest_duration + 0.133 value_stay^2 + 0.154 value_stay*reward + -0.393 value_stay*harvest_duration + 0.696 reward^2 + 0.177 reward*harvest_duration + -0.014 harvest_duration^2 \n",
      "value_exit[t+1] = -0.076 1 + 0.99 value_exit[t] + -0.013 travel_duration + 0.055 value_exit^2 + -0.103 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 52, 0, 0, 0, 0, 0, 52\n",
      "value_exit: 0, 52, 52, 0, 0, 52\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 252/1000 --- L(Train): 0.4128440 --- L(Val, RNN): 0.3368619 --- L(Val, SINDy): 0.3409139 --- Time: 1.00s; --- Convergence: 2.79e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 52/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.236 1 + 0.461 value_stay[t] + 0.172 reward + -0.012 harvest_duration + 0.133 value_stay^2 + 0.154 value_stay*reward + -0.394 value_stay*harvest_duration + 0.696 reward^2 + 0.177 reward*harvest_duration + -0.014 harvest_duration^2 \n",
      "value_exit[t+1] = -0.076 1 + 0.99 value_exit[t] + -0.013 travel_duration + 0.055 value_exit^2 + -0.103 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 53, 0, 0, 0, 0, 0, 53\n",
      "value_exit: 0, 53, 53, 0, 0, 53\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 253/1000 --- L(Train): 0.4012853 --- L(Val, RNN): 0.3366408 --- L(Val, SINDy): 0.3406148 --- Time: 0.95s; --- Convergence: 2.50e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 53/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.238 1 + 0.463 value_stay[t] + 0.173 reward + -0.01 harvest_duration + 0.134 value_stay^2 + 0.156 value_stay*reward + -0.393 value_stay*harvest_duration + 0.697 reward^2 + 0.177 reward*harvest_duration + -0.012 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 0.992 value_exit[t] + -0.014 travel_duration + 0.053 value_exit^2 + -0.102 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 54, 0, 0, 0, 0, 0, 54\n",
      "value_exit: 0, 54, 54, 0, 0, 54\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 254/1000 --- L(Train): 0.3974013 --- L(Val, RNN): 0.3366806 --- L(Val, SINDy): 0.3400703 --- Time: 0.90s; --- Convergence: 1.45e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 54/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.24 1 + 0.463 value_stay[t] + 0.173 reward + -0.009 harvest_duration + 0.135 value_stay^2 + 0.157 value_stay*reward + -0.393 value_stay*harvest_duration + 0.698 reward^2 + 0.177 reward*harvest_duration + -0.011 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.993 value_exit[t] + -0.016 travel_duration + 0.052 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 55, 0, 0, 0, 0, 0, 55\n",
      "value_exit: 0, 55, 55, 0, 0, 55\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 255/1000 --- L(Train): 0.3951344 --- L(Val, RNN): 0.3366409 --- L(Val, SINDy): 0.3402516 --- Time: 0.82s; --- Convergence: 9.23e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 55/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.241 1 + 0.464 value_stay[t] + 0.172 reward + -0.009 harvest_duration + 0.135 value_stay^2 + 0.157 value_stay*reward + -0.393 value_stay*harvest_duration + 0.697 reward^2 + 0.176 reward*harvest_duration + -0.011 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.993 value_exit[t] + -0.016 travel_duration + 0.052 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 56, 0, 0, 0, 0, 0, 56\n",
      "value_exit: 0, 56, 56, 0, 0, 56\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 256/1000 --- L(Train): 0.4093504 --- L(Val, RNN): 0.3367124 --- L(Val, SINDy): 0.3402778 --- Time: 0.93s; --- Convergence: 8.20e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 56/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.242 1 + 0.464 value_stay[t] + 0.171 reward + -0.009 harvest_duration + 0.135 value_stay^2 + 0.157 value_stay*reward + -0.394 value_stay*harvest_duration + 0.697 reward^2 + 0.176 reward*harvest_duration + -0.011 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.993 value_exit[t] + -0.016 travel_duration + 0.052 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 57, 0, 0, 0, 0, 0, 57\n",
      "value_exit: 0, 57, 57, 0, 0, 57\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 257/1000 --- L(Train): 0.4095838 --- L(Val, RNN): 0.3367396 --- L(Val, SINDy): 0.3400997 --- Time: 0.88s; --- Convergence: 5.46e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 57/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.243 1 + 0.464 value_stay[t] + 0.171 reward + -0.009 harvest_duration + 0.135 value_stay^2 + 0.158 value_stay*reward + -0.394 value_stay*harvest_duration + 0.698 reward^2 + 0.175 reward*harvest_duration + -0.011 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.993 value_exit[t] + -0.015 travel_duration + 0.052 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 58, 0, 0, 0, 0, 0, 58\n",
      "value_exit: 0, 58, 58, 0, 0, 58\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 258/1000 --- L(Train): 0.3910172 --- L(Val, RNN): 0.3365801 --- L(Val, SINDy): 0.3400141 --- Time: 0.92s; --- Convergence: 1.07e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 58/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.244 1 + 0.464 value_stay[t] + 0.17 reward + -0.01 harvest_duration + 0.135 value_stay^2 + 0.158 value_stay*reward + -0.395 value_stay*harvest_duration + 0.698 reward^2 + 0.175 reward*harvest_duration + -0.012 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 0.991 value_exit[t] + -0.014 travel_duration + 0.054 value_exit^2 + -0.103 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 59, 0, 0, 0, 0, 0, 59\n",
      "value_exit: 0, 59, 59, 0, 0, 59\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 259/1000 --- L(Train): 0.3974985 --- L(Val, RNN): 0.3364162 --- L(Val, SINDy): 0.3401904 --- Time: 0.90s; --- Convergence: 1.35e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 59/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.246 1 + 0.465 value_stay[t] + 0.171 reward + -0.009 harvest_duration + 0.136 value_stay^2 + 0.161 value_stay*reward + -0.395 value_stay*harvest_duration + 0.699 reward^2 + 0.176 reward*harvest_duration + -0.011 harvest_duration^2 \n",
      "value_exit[t+1] = -0.077 1 + 0.992 value_exit[t] + -0.014 travel_duration + 0.054 value_exit^2 + -0.102 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 60, 0, 0, 0, 0, 0, 60\n",
      "value_exit: 0, 60, 60, 0, 0, 60\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 260/1000 --- L(Train): 0.4178391 --- L(Val, RNN): 0.3361446 --- L(Val, SINDy): 0.3402289 --- Time: 0.79s; --- Convergence: 2.04e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 60/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.246 1 + 0.463 value_stay[t] + 0.17 reward + -0.01 harvest_duration + 0.135 value_stay^2 + 0.161 value_stay*reward + -0.397 value_stay*harvest_duration + 0.699 reward^2 + 0.175 reward*harvest_duration + -0.012 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.993 value_exit[t] + -0.015 travel_duration + 0.052 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 61, 0, 0, 0, 0, 0, 61\n",
      "value_exit: 0, 61, 61, 0, 0, 61\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 261/1000 --- L(Train): 0.4142573 --- L(Val, RNN): 0.3359531 --- L(Val, SINDy): 0.3400510 --- Time: 1.13s; --- Convergence: 1.98e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 61/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.245 1 + 0.461 value_stay[t] + 0.169 reward + -0.011 harvest_duration + 0.133 value_stay^2 + 0.16 value_stay*reward + -0.399 value_stay*harvest_duration + 0.698 reward^2 + 0.173 reward*harvest_duration + -0.013 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.994 value_exit[t] + -0.015 travel_duration + 0.051 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 62, 0, 0, 0, 0, 0, 62\n",
      "value_exit: 0, 62, 62, 0, 0, 62\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 262/1000 --- L(Train): 0.3982800 --- L(Val, RNN): 0.3360634 --- L(Val, SINDy): 0.3401947 --- Time: 0.88s; --- Convergence: 1.54e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 62/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.246 1 + 0.46 value_stay[t] + 0.169 reward + -0.011 harvest_duration + 0.132 value_stay^2 + 0.161 value_stay*reward + -0.4 value_stay*harvest_duration + 0.699 reward^2 + 0.173 reward*harvest_duration + -0.013 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.993 value_exit[t] + -0.015 travel_duration + 0.052 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 63, 0, 0, 0, 0, 0, 63\n",
      "value_exit: 0, 63, 63, 0, 0, 63\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 263/1000 --- L(Train): 0.3953603 --- L(Val, RNN): 0.3360024 --- L(Val, SINDy): 0.3398199 --- Time: 1.09s; --- Convergence: 1.07e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 63/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.246 1 + 0.459 value_stay[t] + 0.168 reward + -0.011 harvest_duration + 0.13 value_stay^2 + 0.161 value_stay*reward + -0.402 value_stay*harvest_duration + 0.699 reward^2 + 0.172 reward*harvest_duration + -0.013 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.992 value_exit[t] + -0.014 travel_duration + 0.053 value_exit^2 + -0.102 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 64, 0, 0, 0, 0, 0, 64\n",
      "value_exit: 0, 64, 64, 0, 0, 64\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 264/1000 --- L(Train): 0.4097185 --- L(Val, RNN): 0.3359258 --- L(Val, SINDy): 0.3394373 --- Time: 0.94s; --- Convergence: 9.20e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 64/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.247 1 + 0.458 value_stay[t] + 0.168 reward + -0.01 harvest_duration + 0.13 value_stay^2 + 0.162 value_stay*reward + -0.402 value_stay*harvest_duration + 0.7 reward^2 + 0.172 reward*harvest_duration + -0.012 harvest_duration^2 \n",
      "value_exit[t+1] = -0.078 1 + 0.992 value_exit[t] + -0.014 travel_duration + 0.053 value_exit^2 + -0.102 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 65, 0, 0, 0, 0, 0, 65\n",
      "value_exit: 0, 65, 65, 0, 0, 65\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 265/1000 --- L(Train): 0.4087511 --- L(Val, RNN): 0.3358991 --- L(Val, SINDy): 0.3392429 --- Time: 0.84s; --- Convergence: 5.94e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 65/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.249 1 + 0.459 value_stay[t] + 0.169 reward + -0.008 harvest_duration + 0.131 value_stay^2 + 0.164 value_stay*reward + -0.401 value_stay*harvest_duration + 0.702 reward^2 + 0.174 reward*harvest_duration + -0.01 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.994 value_exit[t] + -0.015 travel_duration + 0.051 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 66, 0, 0, 0, 0, 0, 66\n",
      "value_exit: 0, 66, 66, 0, 0, 66\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 266/1000 --- L(Train): 0.4072311 --- L(Val, RNN): 0.3357196 --- L(Val, SINDy): 0.3395881 --- Time: 1.16s; --- Convergence: 1.19e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 66/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.25 1 + 0.459 value_stay[t] + 0.17 reward + -0.006 harvest_duration + 0.131 value_stay^2 + 0.165 value_stay*reward + -0.401 value_stay*harvest_duration + 0.703 reward^2 + 0.174 reward*harvest_duration + -0.008 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.995 value_exit[t] + -0.016 travel_duration + 0.05 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 67, 0, 0, 0, 0, 0, 67\n",
      "value_exit: 0, 67, 67, 1, 0, 67\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 267/1000 --- L(Train): 0.3912229 --- L(Val, RNN): 0.3357886 --- L(Val, SINDy): 0.3386891 --- Time: 0.90s; --- Convergence: 9.42e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 67/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.251 1 + 0.458 value_stay[t] + 0.17 reward + -0.005 harvest_duration + 0.13 value_stay^2 + 0.166 value_stay*reward + -0.401 value_stay*harvest_duration + 0.704 reward^2 + 0.174 reward*harvest_duration + -0.007 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.996 value_exit[t] + -0.016 travel_duration + 0.049 value_exit^2 + -0.099 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 68, 0, 0, 0, 0, 0, 68\n",
      "value_exit: 0, 68, 68, 2, 0, 68\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 268/1000 --- L(Train): 0.4034178 --- L(Val, RNN): 0.3357879 --- L(Val, SINDy): 0.3385125 --- Time: 1.03s; --- Convergence: 4.75e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 68/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.25 1 + 0.456 value_stay[t] + 0.168 reward + -0.005 harvest_duration + 0.128 value_stay^2 + 0.165 value_stay*reward + -0.403 value_stay*harvest_duration + 0.703 reward^2 + 0.172 reward*harvest_duration + -0.007 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.995 value_exit[t] + -0.015 travel_duration + 0.05 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 69, 0, 0, 0, 0, 0, 69\n",
      "value_exit: 0, 69, 69, 0, 0, 69\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 269/1000 --- L(Train): 0.3969114 --- L(Val, RNN): 0.3356634 --- L(Val, SINDy): 0.3389864 --- Time: 1.05s; --- Convergence: 8.60e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 69/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.247 1 + 0.451 value_stay[t] + 0.164 reward + -0.008 harvest_duration + 0.123 value_stay^2 + 0.162 value_stay*reward + -0.407 value_stay*harvest_duration + 0.7 reward^2 + 0.168 reward*harvest_duration + -0.01 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.993 value_exit[t] + -0.013 travel_duration + 0.052 value_exit^2 + -0.102 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 70, 0, 0, 0, 0, 0, 70\n",
      "value_exit: 0, 70, 70, 0, 0, 70\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 270/1000 --- L(Train): 0.3909675 --- L(Val, RNN): 0.3354580 --- L(Val, SINDy): 0.3395458 --- Time: 1.02s; --- Convergence: 1.46e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 70/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.248 1 + 0.451 value_stay[t] + 0.164 reward + -0.007 harvest_duration + 0.123 value_stay^2 + 0.164 value_stay*reward + -0.407 value_stay*harvest_duration + 0.701 reward^2 + 0.168 reward*harvest_duration + -0.009 harvest_duration^2 \n",
      "value_exit[t+1] = -0.079 1 + 0.993 value_exit[t] + -0.013 travel_duration + 0.052 value_exit^2 + -0.102 value_exit*travel_duration + -0.012 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 71, 0, 0, 0, 0, 0, 71\n",
      "value_exit: 0, 71, 71, 0, 0, 71\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 271/1000 --- L(Train): 0.3883924 --- L(Val, RNN): 0.3353890 --- L(Val, SINDy): 0.3393134 --- Time: 0.86s; --- Convergence: 1.07e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 71/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.25 1 + 0.452 value_stay[t] + 0.166 reward + -0.005 harvest_duration + 0.124 value_stay^2 + 0.167 value_stay*reward + -0.405 value_stay*harvest_duration + 0.703 reward^2 + 0.17 reward*harvest_duration + -0.007 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.995 value_exit[t] + -0.015 travel_duration + 0.05 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 72, 0, 0, 0, 0, 0, 72\n",
      "value_exit: 0, 72, 72, 0, 0, 72\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 272/1000 --- L(Train): 0.3950132 --- L(Val, RNN): 0.3353010 --- L(Val, SINDy): 0.3390819 --- Time: 1.11s; --- Convergence: 9.77e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 72/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.252 1 + 0.453 value_stay[t] + 0.166 reward + -0.003 harvest_duration + 0.125 value_stay^2 + 0.169 value_stay*reward + -0.404 value_stay*harvest_duration + 0.704 reward^2 + 0.17 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.996 value_exit[t] + -0.016 travel_duration + 0.049 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 73, 0, 0, 0, 0, 0, 73\n",
      "value_exit: 0, 73, 73, 1, 0, 73\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 273/1000 --- L(Train): 0.3924995 --- L(Val, RNN): 0.3352695 --- L(Val, SINDy): 0.3387547 --- Time: 0.98s; --- Convergence: 6.46e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 73/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.252 1 + 0.452 value_stay[t] + 0.166 reward + -0.003 harvest_duration + 0.124 value_stay^2 + 0.17 value_stay*reward + -0.404 value_stay*harvest_duration + 0.704 reward^2 + 0.17 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.016 travel_duration + 0.049 value_exit^2 + -0.099 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 74, 0, 0, 0, 0, 0, 74\n",
      "value_exit: 0, 74, 74, 2, 0, 74\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 274/1000 --- L(Train): 0.3953518 --- L(Val, RNN): 0.3350610 --- L(Val, SINDy): 0.3390274 --- Time: 0.80s; --- Convergence: 1.37e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 74/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.251 1 + 0.45 value_stay[t] + 0.164 reward + -0.004 harvest_duration + 0.123 value_stay^2 + 0.169 value_stay*reward + -0.406 value_stay*harvest_duration + 0.703 reward^2 + 0.168 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.995 value_exit[t] + -0.015 travel_duration + 0.05 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 75, 0, 0, 0, 0, 0, 75\n",
      "value_exit: 0, 75, 75, 3, 0, 75\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 275/1000 --- L(Train): 0.3966038 --- L(Val, RNN): 0.3350385 --- L(Val, SINDy): 0.3376936 --- Time: 0.89s; --- Convergence: 7.95e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 75/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.25 1 + 0.448 value_stay[t] + 0.162 reward + -0.005 harvest_duration + 0.121 value_stay^2 + 0.168 value_stay*reward + -0.408 value_stay*harvest_duration + 0.702 reward^2 + 0.166 reward*harvest_duration + -0.007 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.994 value_exit[t] + -0.014 travel_duration + 0.051 value_exit^2 + -0.102 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 76, 0, 0, 0, 0, 0, 76\n",
      "value_exit: 0, 76, 76, 0, 0, 76\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 276/1000 --- L(Train): 0.3907987 --- L(Val, RNN): 0.3348608 --- L(Val, SINDy): 0.3378172 --- Time: 1.58s; --- Convergence: 1.29e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 76/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.249 1 + 0.447 value_stay[t] + 0.16 reward + -0.006 harvest_duration + 0.12 value_stay^2 + 0.168 value_stay*reward + -0.409 value_stay*harvest_duration + 0.7 reward^2 + 0.164 reward*harvest_duration + -0.008 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.995 value_exit[t] + -0.014 travel_duration + 0.05 value_exit^2 + -0.102 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 77, 0, 0, 0, 0, 0, 77\n",
      "value_exit: 0, 77, 77, 0, 0, 77\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 277/1000 --- L(Train): 0.3966623 --- L(Val, RNN): 0.3346118 --- L(Val, SINDy): 0.3383250 --- Time: 1.58s; --- Convergence: 1.89e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 77/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.249 1 + 0.446 value_stay[t] + 0.159 reward + -0.005 harvest_duration + 0.12 value_stay^2 + 0.169 value_stay*reward + -0.409 value_stay*harvest_duration + 0.7 reward^2 + 0.163 reward*harvest_duration + -0.007 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.996 value_exit[t] + -0.015 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 78, 0, 0, 0, 0, 0, 78\n",
      "value_exit: 0, 78, 78, 1, 0, 78\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 278/1000 --- L(Train): 0.3937236 --- L(Val, RNN): 0.3346241 --- L(Val, SINDy): 0.3381226 --- Time: 4.97s; --- Convergence: 1.01e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 78/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.251 1 + 0.448 value_stay[t] + 0.16 reward + -0.004 harvest_duration + 0.122 value_stay^2 + 0.172 value_stay*reward + -0.408 value_stay*harvest_duration + 0.702 reward^2 + 0.164 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.016 travel_duration + 0.049 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 79, 0, 0, 0, 0, 0, 79\n",
      "value_exit: 0, 79, 79, 2, 0, 79\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 279/1000 --- L(Train): 0.3813202 --- L(Val, RNN): 0.3347065 --- L(Val, SINDy): 0.3381020 --- Time: 5.31s; --- Convergence: 9.15e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 79/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.252 1 + 0.448 value_stay[t] + 0.16 reward + -0.003 harvest_duration + 0.123 value_stay^2 + 0.174 value_stay*reward + -0.407 value_stay*harvest_duration + 0.702 reward^2 + 0.164 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.996 value_exit[t] + -0.015 travel_duration + 0.049 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 80, 0, 0, 0, 0, 0, 80\n",
      "value_exit: 0, 80, 80, 3, 0, 80\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 280/1000 --- L(Train): 0.3823008 --- L(Val, RNN): 0.3347776 --- L(Val, SINDy): 0.3381369 --- Time: 3.78s; --- Convergence: 8.13e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 80/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.252 1 + 0.448 value_stay[t] + 0.159 reward + -0.003 harvest_duration + 0.123 value_stay^2 + 0.175 value_stay*reward + -0.407 value_stay*harvest_duration + 0.702 reward^2 + 0.163 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.996 value_exit[t] + -0.014 travel_duration + 0.05 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 81, 0, 0, 0, 0, 0, 81\n",
      "value_exit: 0, 81, 81, 4, 0, 81\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 281/1000 --- L(Train): 0.3869972 --- L(Val, RNN): 0.3346428 --- L(Val, SINDy): 0.3377096 --- Time: 3.67s; --- Convergence: 1.08e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 81/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.251 1 + 0.447 value_stay[t] + 0.157 reward + -0.004 harvest_duration + 0.122 value_stay^2 + 0.175 value_stay*reward + -0.408 value_stay*harvest_duration + 0.701 reward^2 + 0.161 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.995 value_exit[t] + -0.014 travel_duration + 0.05 value_exit^2 + -0.102 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 82, 0, 0, 0, 0, 0, 82\n",
      "value_exit: 0, 82, 82, 0, 0, 82\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 282/1000 --- L(Train): 0.3909203 --- L(Val, RNN): 0.3345253 --- L(Val, SINDy): 0.3388458 --- Time: 2.74s; --- Convergence: 1.13e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 82/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.251 1 + 0.447 value_stay[t] + 0.156 reward + -0.004 harvest_duration + 0.122 value_stay^2 + 0.176 value_stay*reward + -0.408 value_stay*harvest_duration + 0.701 reward^2 + 0.16 reward*harvest_duration + -0.006 harvest_duration^2 \n",
      "value_exit[t+1] = -0.08 1 + 0.995 value_exit[t] + -0.014 travel_duration + 0.05 value_exit^2 + -0.102 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 83, 0, 0, 0, 0, 0, 83\n",
      "value_exit: 0, 83, 83, 0, 0, 83\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 283/1000 --- L(Train): 0.3836643 --- L(Val, RNN): 0.3345347 --- L(Val, SINDy): 0.3386226 --- Time: 2.12s; --- Convergence: 6.11e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 83/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.253 1 + 0.448 value_stay[t] + 0.156 reward + -0.003 harvest_duration + 0.124 value_stay^2 + 0.178 value_stay*reward + -0.407 value_stay*harvest_duration + 0.702 reward^2 + 0.161 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.996 value_exit[t] + -0.015 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 84, 0, 0, 0, 0, 0, 84\n",
      "value_exit: 0, 84, 84, 1, 0, 84\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 284/1000 --- L(Train): 0.3834963 --- L(Val, RNN): 0.3343023 --- L(Val, SINDy): 0.3379078 --- Time: 2.45s; --- Convergence: 1.47e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 84/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.252 1 + 0.447 value_stay[t] + 0.155 reward + -0.003 harvest_duration + 0.124 value_stay^2 + 0.178 value_stay*reward + -0.408 value_stay*harvest_duration + 0.701 reward^2 + 0.159 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.997 value_exit[t] + -0.016 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 85, 0, 0, 0, 0, 0, 85\n",
      "value_exit: 0, 85, 85, 2, 0, 85\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 285/1000 --- L(Train): 0.3842850 --- L(Val, RNN): 0.3345172 --- L(Val, SINDy): 0.3382327 --- Time: 3.86s; --- Convergence: 1.81e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 85/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.252 1 + 0.447 value_stay[t] + 0.154 reward + -0.003 harvest_duration + 0.124 value_stay^2 + 0.179 value_stay*reward + -0.408 value_stay*harvest_duration + 0.7 reward^2 + 0.158 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.997 value_exit[t] + -0.016 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.015 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 86, 0, 0, 0, 0, 0, 86\n",
      "value_exit: 0, 86, 86, 3, 0, 86\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 286/1000 --- L(Train): 0.3910502 --- L(Val, RNN): 0.3346549 --- L(Val, SINDy): 0.3379798 --- Time: 3.08s; --- Convergence: 1.59e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 86/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.252 1 + 0.446 value_stay[t] + 0.153 reward + -0.003 harvest_duration + 0.123 value_stay^2 + 0.179 value_stay*reward + -0.408 value_stay*harvest_duration + 0.7 reward^2 + 0.157 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.997 value_exit[t] + -0.016 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 87, 0, 0, 0, 0, 0, 87\n",
      "value_exit: 0, 87, 87, 4, 0, 87\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 287/1000 --- L(Train): 0.3877548 --- L(Val, RNN): 0.3343971 --- L(Val, SINDy): 0.3379901 --- Time: 3.38s; --- Convergence: 2.09e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 87/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.252 1 + 0.445 value_stay[t] + 0.152 reward + -0.003 harvest_duration + 0.123 value_stay^2 + 0.179 value_stay*reward + -0.408 value_stay*harvest_duration + 0.699 reward^2 + 0.156 reward*harvest_duration + -0.005 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.015 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 88, 0, 0, 0, 0, 0, 88\n",
      "value_exit: 0, 88, 88, 5, 0, 88\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 288/1000 --- L(Train): 0.3922175 --- L(Val, RNN): 0.3343978 --- L(Val, SINDy): 0.3375506 --- Time: 2.40s; --- Convergence: 1.05e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 88/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.254 1 + 0.446 value_stay[t] + 0.152 reward + -0.001 harvest_duration + 0.125 value_stay^2 + 0.181 value_stay*reward + -0.407 value_stay*harvest_duration + 0.7 reward^2 + 0.156 reward*harvest_duration + -0.003 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.996 value_exit[t] + -0.015 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 89, 0, 0, 0, 0, 0, 89\n",
      "value_exit: 0, 89, 89, 6, 0, 89\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 289/1000 --- L(Train): 0.3916637 --- L(Val, RNN): 0.3345414 --- L(Val, SINDy): 0.3386424 --- Time: 2.55s; --- Convergence: 1.24e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 89/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.255 1 + 0.448 value_stay[t] + 0.153 reward + 0.0 harvest_duration + 0.126 value_stay^2 + 0.183 value_stay*reward + -0.406 value_stay*harvest_duration + 0.702 reward^2 + 0.157 reward*harvest_duration + -0.002 harvest_duration^2 \n",
      "value_exit[t+1] = -0.081 1 + 0.996 value_exit[t] + -0.014 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 90, 0, 0, 0, 0, 0, 90\n",
      "value_exit: 0, 90, 90, 7, 0, 90\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 290/1000 --- L(Train): 0.3904198 --- L(Val, RNN): 0.3345659 --- L(Val, SINDy): 0.3376216 --- Time: 2.77s; --- Convergence: 7.43e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 90/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.256 1 + 0.448 value_stay[t] + 0.154 reward + 0.001 harvest_duration + 0.127 value_stay^2 + 0.185 value_stay*reward + -0.405 value_stay*harvest_duration + 0.703 reward^2 + 0.158 reward*harvest_duration + -0.001 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.996 value_exit[t] + -0.015 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 91, 0, 0, 0, 0, 0, 91\n",
      "value_exit: 0, 91, 91, 8, 0, 91\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 291/1000 --- L(Train): 0.3851419 --- L(Val, RNN): 0.3344281 --- L(Val, SINDy): 0.3374900 --- Time: 2.19s; --- Convergence: 1.06e-04; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 91/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.257 1 + 0.448 value_stay[t] + 0.153 reward + 0.002 harvest_duration + 0.127 value_stay^2 + 0.186 value_stay*reward + -0.405 value_stay*harvest_duration + 0.703 reward^2 + 0.157 reward*harvest_duration + -0.0 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.015 travel_duration + 0.048 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 92, 0, 0, 0, 0, 0, 92\n",
      "value_exit: 0, 92, 92, 9, 0, 92\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 292/1000 --- L(Train): 0.3836258 --- L(Val, RNN): 0.3343716 --- L(Val, SINDy): 0.3382090 --- Time: 1.01s; --- Convergence: 8.13e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 92/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.256 1 + 0.446 value_stay[t] + 0.151 reward + 0.0 harvest_duration + 0.126 value_stay^2 + 0.185 value_stay*reward + -0.406 value_stay*harvest_duration + 0.702 reward^2 + 0.155 reward*harvest_duration + -0.002 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.015 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 93, 0, 0, 0, 0, 0, 93\n",
      "value_exit: 0, 93, 93, 10, 0, 93\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 293/1000 --- L(Train): 0.3974268 --- L(Val, RNN): 0.3342558 --- L(Val, SINDy): 0.3383515 --- Time: 1.19s; --- Convergence: 9.86e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 93/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.254 1 + 0.444 value_stay[t] + 0.149 reward + -0.001 harvest_duration + 0.124 value_stay^2 + 0.184 value_stay*reward + -0.408 value_stay*harvest_duration + 0.7 reward^2 + 0.153 reward*harvest_duration + -0.003 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.997 value_exit[t] + -0.015 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 94, 0, 0, 0, 0, 0, 94\n",
      "value_exit: 0, 94, 94, 11, 0, 94\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 294/1000 --- L(Train): 0.3940150 --- L(Val, RNN): 0.3342577 --- L(Val, SINDy): 0.3377537 --- Time: 1.11s; --- Convergence: 5.03e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 94/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.254 1 + 0.444 value_stay[t] + 0.148 reward + -0.001 harvest_duration + 0.124 value_stay^2 + 0.184 value_stay*reward + -0.409 value_stay*harvest_duration + 0.7 reward^2 + 0.152 reward*harvest_duration + -0.003 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.015 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 95, 0, 0, 0, 0, 0, 95\n",
      "value_exit: 0, 95, 95, 12, 0, 95\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 295/1000 --- L(Train): 0.3884927 --- L(Val, RNN): 0.3341983 --- L(Val, SINDy): 0.3385646 --- Time: 0.97s; --- Convergence: 5.48e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 95/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.256 1 + 0.445 value_stay[t] + 0.149 reward + 0.0 harvest_duration + 0.126 value_stay^2 + 0.187 value_stay*reward + -0.407 value_stay*harvest_duration + 0.702 reward^2 + 0.154 reward*harvest_duration + -0.002 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.015 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 96, 0, 0, 0, 0, 0, 96\n",
      "value_exit: 0, 96, 96, 13, 0, 96\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 296/1000 --- L(Train): 0.3879983 --- L(Val, RNN): 0.3341958 --- L(Val, SINDy): 0.3381571 --- Time: 1.27s; --- Convergence: 2.87e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 96/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.258 1 + 0.447 value_stay[t] + 0.151 reward + 0.002 harvest_duration + 0.128 value_stay^2 + 0.189 value_stay*reward + -0.406 value_stay*harvest_duration + 0.704 reward^2 + 0.155 reward*harvest_duration + -0.0 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.996 value_exit[t] + -0.015 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.013 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 97, 0, 0, 0, 0, 0, 97\n",
      "value_exit: 0, 97, 97, 14, 0, 97\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 297/1000 --- L(Train): 0.3982072 --- L(Val, RNN): 0.3343278 --- L(Val, SINDy): 0.3374274 --- Time: 0.99s; --- Convergence: 8.04e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 97/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.257 1 + 0.446 value_stay[t] + 0.15 reward + 0.0 harvest_duration + 0.127 value_stay^2 + 0.189 value_stay*reward + -0.407 value_stay*harvest_duration + 0.704 reward^2 + 0.154 reward*harvest_duration + -0.002 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.015 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 98, 0, 0, 0, 0, 0, 98\n",
      "value_exit: 0, 98, 98, 15, 0, 98\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 298/1000 --- L(Train): 0.4078288 --- L(Val, RNN): 0.3342167 --- L(Val, SINDy): 0.3377714 --- Time: 0.98s; --- Convergence: 9.57e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 98/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.256 1 + 0.444 value_stay[t] + 0.148 reward + -0.002 harvest_duration + 0.125 value_stay^2 + 0.189 value_stay*reward + -0.409 value_stay*harvest_duration + 0.702 reward^2 + 0.152 reward*harvest_duration + -0.004 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 0.997 value_exit[t] + -0.015 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 99, 0, 0, 0, 0, 0, 99\n",
      "value_exit: 0, 99, 99, 16, 0, 99\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 299/1000 --- L(Train): 0.3983968 --- L(Val, RNN): 0.3341685 --- L(Val, SINDy): 0.3374518 --- Time: 1.10s; --- Convergence: 7.20e-05; LR: 1.00e-02; Metric: 0.3324696; Bad epochs: 99/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 15):\n",
      "value_stay[t+1] = 0.256 1 + 0.444 value_stay[t] + 0.148 reward + 0.126 value_stay^2 + 0.19 value_stay*reward + -0.409 value_stay*harvest_duration + 0.703 reward^2 + 0.152 reward*harvest_duration + -0.004 harvest_duration^2 \n",
      "value_exit[t+1] = -0.083 1 + 0.997 value_exit[t] + -0.015 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, 100\n",
      "value_exit: 0, 100, 100, 17, 0, 100\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 300/1000 --- L(Train): 1.1520814 --- L(Val, RNN): 0.3352242 --- L(Val, SINDy): 0.3553483 --- Time: 0.83s; --- Convergence: 5.64e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 14):\n",
      "value_stay[t+1] = 0.257 1 + 0.445 value_stay[t] + 0.148 reward + 0.127 value_stay^2 + 0.192 value_stay*reward + -0.408 value_stay*harvest_duration + 0.704 reward^2 + 0.152 reward*harvest_duration + -0.003 harvest_duration^2 \n",
      "value_exit[t+1] = -0.082 1 + 1.0 value_exit[t] + -0.015 travel_duration + 0.048 value_exit^2 + -0.1 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, 101\n",
      "value_exit: 0, -, 101, 18, 0, 101\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 301/1000 --- L(Train): 2.3231125 --- L(Val, RNN): 0.3360482 --- L(Val, SINDy): 0.3984447 --- Time: 0.85s; --- Convergence: 6.94e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 1/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 13):\n",
      "value_stay[t+1] = 0.258 1 + 0.446 value_stay[t] + 0.149 reward + 0.129 value_stay^2 + 0.194 value_stay*reward + -0.407 value_stay*harvest_duration + 0.705 reward^2 + 0.153 reward*harvest_duration \n",
      "value_exit[t+1] = -0.082 1 + 1.0 value_exit[t] + -0.015 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration + -0.014 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, 102, 19, 0, 102\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 302/1000 --- L(Train): 2.6778023 --- L(Val, RNN): 0.3368646 --- L(Val, SINDy): 0.4243608 --- Time: 1.10s; --- Convergence: 7.55e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 2/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_stay[t+1] = 0.259 1 + 0.447 value_stay[t] + 0.15 reward + 0.13 value_stay^2 + 0.196 value_stay*reward + -0.406 value_stay*harvest_duration + 0.707 reward^2 + 0.154 reward*harvest_duration \n",
      "value_exit[t+1] = -0.081 1 + 1.0 value_exit[t] + -0.014 travel_duration + 0.049 value_exit^2 + -0.101 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, 103, 20, 0, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 303/1000 --- L(Train): 2.7547169 --- L(Val, RNN): 0.3375870 --- L(Val, SINDy): 0.4403746 --- Time: 0.98s; --- Convergence: 7.39e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 3/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 11):\n",
      "value_stay[t+1] = 0.26 1 + 0.447 value_stay[t] + 0.15 reward + 0.131 value_stay^2 + 0.198 value_stay*reward + -0.406 value_stay*harvest_duration + 0.708 reward^2 + 0.154 reward*harvest_duration \n",
      "value_exit[t+1] = -0.087 1 + 1.0 value_exit[t] + 0.044 value_exit^2 + -0.096 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 21, 0, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 304/1000 --- L(Train): 2.2402971 --- L(Val, RNN): 0.3383176 --- L(Val, SINDy): 0.4382166 --- Time: 0.91s; --- Convergence: 7.35e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 4/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 11):\n",
      "value_stay[t+1] = 0.261 1 + 0.448 value_stay[t] + 0.151 reward + 0.132 value_stay^2 + 0.2 value_stay*reward + -0.405 value_stay*harvest_duration + 0.709 reward^2 + 0.156 reward*harvest_duration \n",
      "value_exit[t+1] = -0.096 1 + 1.0 value_exit[t] + 0.035 value_exit^2 + -0.087 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 22, 0, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 305/1000 --- L(Train): 1.7055143 --- L(Val, RNN): 0.3392475 --- L(Val, SINDy): 0.4323960 --- Time: 1.02s; --- Convergence: 8.32e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 5/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 11):\n",
      "value_stay[t+1] = 0.262 1 + 0.449 value_stay[t] + 0.154 reward + 0.134 value_stay^2 + 0.204 value_stay*reward + -0.404 value_stay*harvest_duration + 0.712 reward^2 + 0.158 reward*harvest_duration \n",
      "value_exit[t+1] = -0.108 1 + 1.0 value_exit[t] + 0.024 value_exit^2 + -0.075 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 23, 0, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 306/1000 --- L(Train): 1.2679596 --- L(Val, RNN): 0.3406608 --- L(Val, SINDy): 0.4221447 --- Time: 0.96s; --- Convergence: 1.12e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 6/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.264 1 + 0.451 value_stay[t] + 0.156 reward + 0.137 value_stay^2 + 0.208 value_stay*reward + -0.402 value_stay*harvest_duration + 0.715 reward^2 + 0.16 reward*harvest_duration \n",
      "value_exit[t+1] = -0.122 1 + 1.0 value_exit[t] + 0.01 value_exit^2 + -0.061 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 24, 0, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 307/1000 --- L(Train): 0.9231516 --- L(Val, RNN): 0.3421144 --- L(Val, SINDy): 0.4473107 --- Time: 1.02s; --- Convergence: 1.29e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 7/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.262 1 + 0.45 value_stay[t] + 0.157 reward + 0.136 value_stay^2 + 0.211 value_stay*reward + -0.401 value_stay*harvest_duration + 0.716 reward^2 + 0.161 reward*harvest_duration \n",
      "value_exit[t+1] = -0.138 1 + 1.0 value_exit[t] + -0.004 value_exit^2 + -0.045 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 25, 1, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 308/1000 --- L(Train): 0.6688848 --- L(Val, RNN): 0.3434555 --- L(Val, SINDy): 0.5171546 --- Time: 0.99s; --- Convergence: 1.31e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 8/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.257 1 + 0.444 value_stay[t] + 0.154 reward + 0.132 value_stay^2 + 0.209 value_stay*reward + -0.405 value_stay*harvest_duration + 0.714 reward^2 + 0.158 reward*harvest_duration \n",
      "value_exit[t+1] = -0.155 1 + 1.0 value_exit[t] + -0.02 value_exit^2 + -0.028 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 26, 2, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 309/1000 --- L(Train): 0.5472672 --- L(Val, RNN): 0.3459631 --- L(Val, SINDy): 0.6779090 --- Time: 1.10s; --- Convergence: 1.91e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 9/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.254 1 + 0.443 value_stay[t] + 0.155 reward + 0.131 value_stay^2 + 0.212 value_stay*reward + -0.405 value_stay*harvest_duration + 0.715 reward^2 + 0.159 reward*harvest_duration \n",
      "value_exit[t+1] = -0.17 1 + 1.0 value_exit[t] + -0.034 value_exit^2 + -0.012 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 27, 3, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 310/1000 --- L(Train): 0.5296525 --- L(Val, RNN): 0.3457997 --- L(Val, SINDy): 0.8174689 --- Time: 0.92s; --- Convergence: 1.04e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 10/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.245 1 + 0.433 value_stay[t] + 0.146 reward + 0.122 value_stay^2 + 0.205 value_stay*reward + -0.414 value_stay*harvest_duration + 0.708 reward^2 + 0.151 reward*harvest_duration \n",
      "value_exit[t+1] = -0.176 1 + 1.0 value_exit[t] + -0.041 value_exit^2 + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 28, 4, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 311/1000 --- L(Train): 0.5662240 --- L(Val, RNN): 0.3496209 --- L(Val, SINDy): 0.9165456 --- Time: 0.87s; --- Convergence: 2.43e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 11/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.24 1 + 0.428 value_stay[t] + 0.142 reward + 0.118 value_stay^2 + 0.202 value_stay*reward + -0.418 value_stay*harvest_duration + 0.703 reward^2 + 0.147 reward*harvest_duration \n",
      "value_exit[t+1] = -0.18 1 + 1.0 value_exit[t] + -0.047 value_exit^2 + 0.009 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 29, 5, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 312/1000 --- L(Train): 0.6074606 --- L(Val, RNN): 0.3504353 --- L(Val, SINDy): 0.9122661 --- Time: 1.10s; --- Convergence: 1.62e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 12/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.242 1 + 0.43 value_stay[t] + 0.144 reward + 0.12 value_stay^2 + 0.206 value_stay*reward + -0.415 value_stay*harvest_duration + 0.705 reward^2 + 0.149 reward*harvest_duration \n",
      "value_exit[t+1] = -0.179 1 + 1.0 value_exit[t] + -0.047 value_exit^2 + 0.014 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 30, 6, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 313/1000 --- L(Train): 0.6215689 --- L(Val, RNN): 0.3504556 --- L(Val, SINDy): 0.8462824 --- Time: 0.88s; --- Convergence: 8.21e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 13/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.247 1 + 0.435 value_stay[t] + 0.149 reward + 0.125 value_stay^2 + 0.212 value_stay*reward + -0.409 value_stay*harvest_duration + 0.71 reward^2 + 0.154 reward*harvest_duration \n",
      "value_exit[t+1] = -0.171 1 + 1.0 value_exit[t] + -0.042 value_exit^2 + 0.012 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 31, 7, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 314/1000 --- L(Train): 0.6109530 --- L(Val, RNN): 0.3519282 --- L(Val, SINDy): 0.7780113 --- Time: 0.96s; --- Convergence: 1.15e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 14/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.256 1 + 0.444 value_stay[t] + 0.158 reward + 0.134 value_stay^2 + 0.221 value_stay*reward + -0.4 value_stay*harvest_duration + 0.718 reward^2 + 0.162 reward*harvest_duration \n",
      "value_exit[t+1] = -0.159 1 + 1.0 value_exit[t] + -0.034 value_exit^2 + 0.006 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 32, 8, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 315/1000 --- L(Train): 0.5885673 --- L(Val, RNN): 0.3552010 --- L(Val, SINDy): 0.7124249 --- Time: 0.84s; --- Convergence: 2.21e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 15/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.26 1 + 0.448 value_stay[t] + 0.162 reward + 0.137 value_stay^2 + 0.226 value_stay*reward + -0.395 value_stay*harvest_duration + 0.721 reward^2 + 0.166 reward*harvest_duration \n",
      "value_exit[t+1] = -0.147 1 + 1.0 value_exit[t] + -0.024 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 33, 9, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 316/1000 --- L(Train): 0.5366163 --- L(Val, RNN): 0.3575165 --- L(Val, SINDy): 0.6485744 --- Time: 0.94s; --- Convergence: 2.26e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 16/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.256 1 + 0.443 value_stay[t] + 0.156 reward + 0.132 value_stay^2 + 0.221 value_stay*reward + -0.4 value_stay*harvest_duration + 0.715 reward^2 + 0.16 reward*harvest_duration \n",
      "value_exit[t+1] = -0.133 1 + 1.0 value_exit[t] + -0.014 value_exit^2 + -0.01 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 34, 10, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 317/1000 --- L(Train): 0.5060468 --- L(Val, RNN): 0.3575545 --- L(Val, SINDy): 0.5771055 --- Time: 0.91s; --- Convergence: 1.15e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 17/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.249 1 + 0.435 value_stay[t] + 0.148 reward + 0.124 value_stay^2 + 0.213 value_stay*reward + -0.407 value_stay*harvest_duration + 0.706 reward^2 + 0.152 reward*harvest_duration \n",
      "value_exit[t+1] = -0.119 1 + 1.0 value_exit[t] + -0.003 value_exit^2 + -0.019 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 35, 11, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 318/1000 --- L(Train): 0.4826047 --- L(Val, RNN): 0.3586328 --- L(Val, SINDy): 0.5412547 --- Time: 0.91s; --- Convergence: 1.11e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 18/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.245 1 + 0.431 value_stay[t] + 0.143 reward + 0.12 value_stay^2 + 0.21 value_stay*reward + -0.411 value_stay*harvest_duration + 0.7 reward^2 + 0.147 reward*harvest_duration \n",
      "value_exit[t+1] = -0.106 1 + 1.0 value_exit[t] + 0.006 value_exit^2 + -0.027 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 36, 12, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 319/1000 --- L(Train): 0.4718719 --- L(Val, RNN): 0.3611810 --- L(Val, SINDy): 0.5337070 --- Time: 0.80s; --- Convergence: 1.83e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 19/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.245 1 + 0.432 value_stay[t] + 0.143 reward + 0.12 value_stay^2 + 0.21 value_stay*reward + -0.41 value_stay*harvest_duration + 0.699 reward^2 + 0.147 reward*harvest_duration \n",
      "value_exit[t+1] = -0.094 1 + 1.0 value_exit[t] + 0.015 value_exit^2 + -0.033 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 37, 13, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 320/1000 --- L(Train): 0.4638515 --- L(Val, RNN): 0.3635511 --- L(Val, SINDy): 0.5147980 --- Time: 0.81s; --- Convergence: 2.10e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 20/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.25 1 + 0.436 value_stay[t] + 0.146 reward + 0.125 value_stay^2 + 0.215 value_stay*reward + -0.405 value_stay*harvest_duration + 0.702 reward^2 + 0.15 reward*harvest_duration \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + 0.022 value_exit^2 + -0.037 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 38, 14, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 321/1000 --- L(Train): 0.4639621 --- L(Val, RNN): 0.3643679 --- L(Val, SINDy): 0.5056142 --- Time: 0.96s; --- Convergence: 1.46e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 21/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.253 1 + 0.44 value_stay[t] + 0.149 reward + 0.128 value_stay^2 + 0.219 value_stay*reward + -0.4 value_stay*harvest_duration + 0.704 reward^2 + 0.153 reward*harvest_duration \n",
      "value_exit[t+1] = -0.078 1 + 1.0 value_exit[t] + 0.028 value_exit^2 + -0.04 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 39, 15, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 322/1000 --- L(Train): 0.4566699 --- L(Val, RNN): 0.3649165 --- L(Val, SINDy): 0.5046097 --- Time: 1.17s; --- Convergence: 1.00e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 22/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.257 1 + 0.443 value_stay[t] + 0.152 reward + 0.132 value_stay^2 + 0.222 value_stay*reward + -0.396 value_stay*harvest_duration + 0.706 reward^2 + 0.156 reward*harvest_duration \n",
      "value_exit[t+1] = -0.072 1 + 1.0 value_exit[t] + 0.033 value_exit^2 + -0.042 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 40, 16, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 323/1000 --- L(Train): 0.4557136 --- L(Val, RNN): 0.3665542 --- L(Val, SINDy): 0.4979204 --- Time: 0.89s; --- Convergence: 1.32e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 23/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.261 1 + 0.447 value_stay[t] + 0.156 reward + 0.135 value_stay^2 + 0.226 value_stay*reward + -0.392 value_stay*harvest_duration + 0.709 reward^2 + 0.16 reward*harvest_duration \n",
      "value_exit[t+1] = -0.068 1 + 1.0 value_exit[t] + 0.037 value_exit^2 + -0.042 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 41, 17, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 324/1000 --- L(Train): 0.4534968 --- L(Val, RNN): 0.3689851 --- L(Val, SINDy): 0.4669539 --- Time: 1.13s; --- Convergence: 1.88e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 24/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.264 1 + 0.449 value_stay[t] + 0.158 reward + 0.136 value_stay^2 + 0.229 value_stay*reward + -0.389 value_stay*harvest_duration + 0.71 reward^2 + 0.162 reward*harvest_duration \n",
      "value_exit[t+1] = -0.066 1 + 1.0 value_exit[t] + 0.04 value_exit^2 + -0.041 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 42, 18, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 325/1000 --- L(Train): 0.4423286 --- L(Val, RNN): 0.3699670 --- L(Val, SINDy): 0.4570677 --- Time: 1.18s; --- Convergence: 1.43e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 25/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.263 1 + 0.448 value_stay[t] + 0.157 reward + 0.134 value_stay^2 + 0.228 value_stay*reward + -0.39 value_stay*harvest_duration + 0.708 reward^2 + 0.161 reward*harvest_duration \n",
      "value_exit[t+1] = -0.066 1 + 1.0 value_exit[t] + 0.041 value_exit^2 + -0.039 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 43, 19, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 326/1000 --- L(Train): 0.4407564 --- L(Val, RNN): 0.3698279 --- L(Val, SINDy): 0.4570597 --- Time: 1.29s; --- Convergence: 7.84e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 26/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.261 1 + 0.444 value_stay[t] + 0.154 reward + 0.13 value_stay^2 + 0.224 value_stay*reward + -0.392 value_stay*harvest_duration + 0.704 reward^2 + 0.158 reward*harvest_duration \n",
      "value_exit[t+1] = -0.067 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.035 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 44, 20, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 327/1000 --- L(Train): 0.4419249 --- L(Val, RNN): 0.3706358 --- L(Val, SINDy): 0.4636413 --- Time: 0.87s; --- Convergence: 7.96e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 27/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.258 1 + 0.44 value_stay[t] + 0.15 reward + 0.126 value_stay^2 + 0.22 value_stay*reward + -0.395 value_stay*harvest_duration + 0.7 reward^2 + 0.154 reward*harvest_duration \n",
      "value_exit[t+1] = -0.068 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.032 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 45, 21, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 328/1000 --- L(Train): 0.4299424 --- L(Val, RNN): 0.3725477 --- L(Val, SINDy): 0.4653551 --- Time: 0.90s; --- Convergence: 1.35e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 28/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.256 1 + 0.437 value_stay[t] + 0.148 reward + 0.122 value_stay^2 + 0.217 value_stay*reward + -0.398 value_stay*harvest_duration + 0.697 reward^2 + 0.152 reward*harvest_duration \n",
      "value_exit[t+1] = -0.071 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.028 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 46, 22, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 329/1000 --- L(Train): 0.4351868 --- L(Val, RNN): 0.3738073 --- L(Val, SINDy): 0.4677475 --- Time: 0.96s; --- Convergence: 1.31e-03; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 29/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.256 1 + 0.436 value_stay[t] + 0.147 reward + 0.12 value_stay^2 + 0.216 value_stay*reward + -0.398 value_stay*harvest_duration + 0.695 reward^2 + 0.151 reward*harvest_duration \n",
      "value_exit[t+1] = -0.074 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.023 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 47, 23, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 330/1000 --- L(Train): 0.4309554 --- L(Val, RNN): 0.3739759 --- L(Val, SINDy): 0.4691229 --- Time: 1.00s; --- Convergence: 7.38e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 30/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.258 1 + 0.436 value_stay[t] + 0.148 reward + 0.119 value_stay^2 + 0.216 value_stay*reward + -0.397 value_stay*harvest_duration + 0.695 reward^2 + 0.152 reward*harvest_duration \n",
      "value_exit[t+1] = -0.077 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.018 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 48, 24, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 331/1000 --- L(Train): 0.4220161 --- L(Val, RNN): 0.3743378 --- L(Val, SINDy): 0.4666590 --- Time: 1.00s; --- Convergence: 5.50e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 31/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.261 1 + 0.438 value_stay[t] + 0.151 reward + 0.119 value_stay^2 + 0.218 value_stay*reward + -0.394 value_stay*harvest_duration + 0.697 reward^2 + 0.155 reward*harvest_duration \n",
      "value_exit[t+1] = -0.08 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.014 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 49, 25, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 332/1000 --- L(Train): 0.4227268 --- L(Val, RNN): 0.3750714 --- L(Val, SINDy): 0.4695570 --- Time: 0.98s; --- Convergence: 6.42e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 32/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.265 1 + 0.44 value_stay[t] + 0.154 reward + 0.121 value_stay^2 + 0.22 value_stay*reward + -0.391 value_stay*harvest_duration + 0.699 reward^2 + 0.158 reward*harvest_duration \n",
      "value_exit[t+1] = -0.082 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.01 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 50, 26, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 333/1000 --- L(Train): 0.4213771 --- L(Val, RNN): 0.3757006 --- L(Val, SINDy): 0.4769077 --- Time: 1.30s; --- Convergence: 6.35e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 33/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.27 1 + 0.444 value_stay[t] + 0.158 reward + 0.124 value_stay^2 + 0.224 value_stay*reward + -0.387 value_stay*harvest_duration + 0.703 reward^2 + 0.162 reward*harvest_duration \n",
      "value_exit[t+1] = -0.084 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.007 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 51, 27, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 334/1000 --- L(Train): 0.4166925 --- L(Val, RNN): 0.3759897 --- L(Val, SINDy): 0.4919677 --- Time: 0.96s; --- Convergence: 4.62e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 34/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.275 1 + 0.447 value_stay[t] + 0.162 reward + 0.125 value_stay^2 + 0.226 value_stay*reward + -0.383 value_stay*harvest_duration + 0.706 reward^2 + 0.166 reward*harvest_duration \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 52, 28, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 335/1000 --- L(Train): 0.4182623 --- L(Val, RNN): 0.3756913 --- L(Val, SINDy): 0.4963505 --- Time: 0.97s; --- Convergence: 3.80e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 35/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.279 1 + 0.45 value_stay[t] + 0.166 reward + 0.127 value_stay^2 + 0.229 value_stay*reward + -0.38 value_stay*harvest_duration + 0.709 reward^2 + 0.17 reward*harvest_duration \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 53, 29, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 336/1000 --- L(Train): 0.4148588 --- L(Val, RNN): 0.3756020 --- L(Val, SINDy): 0.4960997 --- Time: 1.08s; --- Convergence: 2.35e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 36/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.282 1 + 0.451 value_stay[t] + 0.167 reward + 0.127 value_stay^2 + 0.229 value_stay*reward + -0.378 value_stay*harvest_duration + 0.709 reward^2 + 0.171 reward*harvest_duration \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + 0.043 value_exit^2 + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 54, 30, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 337/1000 --- L(Train): 0.4138311 --- L(Val, RNN): 0.3757301 --- L(Val, SINDy): 0.4933369 --- Time: 0.96s; --- Convergence: 1.81e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 37/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.282 1 + 0.45 value_stay[t] + 0.167 reward + 0.125 value_stay^2 + 0.228 value_stay*reward + -0.378 value_stay*harvest_duration + 0.709 reward^2 + 0.171 reward*harvest_duration \n",
      "value_exit[t+1] = -0.085 1 + 1.0 value_exit[t] + 0.044 value_exit^2 + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 55, 31, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 338/1000 --- L(Train): 0.4087628 --- L(Val, RNN): 0.3757549 --- L(Val, SINDy): 0.4896396 --- Time: 0.92s; --- Convergence: 1.03e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 38/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.283 1 + 0.448 value_stay[t] + 0.167 reward + 0.122 value_stay^2 + 0.226 value_stay*reward + -0.379 value_stay*harvest_duration + 0.707 reward^2 + 0.171 reward*harvest_duration \n",
      "value_exit[t+1] = -0.083 1 + 1.0 value_exit[t] + 0.045 value_exit^2 + 0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 56, 32, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 339/1000 --- L(Train): 0.4105177 --- L(Val, RNN): 0.3754927 --- L(Val, SINDy): 0.4892283 --- Time: 1.11s; --- Convergence: 1.83e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 39/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.283 1 + 0.447 value_stay[t] + 0.167 reward + 0.12 value_stay^2 + 0.225 value_stay*reward + -0.38 value_stay*harvest_duration + 0.707 reward^2 + 0.171 reward*harvest_duration \n",
      "value_exit[t+1] = -0.082 1 + 1.0 value_exit[t] + 0.046 value_exit^2 + 0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 57, 33, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 340/1000 --- L(Train): 0.4113697 --- L(Val, RNN): 0.3750161 --- L(Val, SINDy): 0.4873317 --- Time: 2.24s; --- Convergence: 3.30e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 40/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.284 1 + 0.446 value_stay[t] + 0.168 reward + 0.118 value_stay^2 + 0.225 value_stay*reward + -0.38 value_stay*harvest_duration + 0.707 reward^2 + 0.172 reward*harvest_duration \n",
      "value_exit[t+1] = -0.078 1 + 1.0 value_exit[t] + 0.047 value_exit^2 + 0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 58, 34, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 341/1000 --- L(Train): 0.4055852 --- L(Val, RNN): 0.3744906 --- L(Val, SINDy): 0.4837913 --- Time: 4.67s; --- Convergence: 4.28e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 41/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.285 1 + 0.445 value_stay[t] + 0.168 reward + 0.115 value_stay^2 + 0.224 value_stay*reward + -0.381 value_stay*harvest_duration + 0.708 reward^2 + 0.173 reward*harvest_duration \n",
      "value_exit[t+1] = -0.075 1 + 1.0 value_exit[t] + 0.048 value_exit^2 + 0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 59, 35, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 342/1000 --- L(Train): 0.4025204 --- L(Val, RNN): 0.3738575 --- L(Val, SINDy): 0.4817400 --- Time: 4.44s; --- Convergence: 5.30e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 42/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.285 1 + 0.443 value_stay[t] + 0.168 reward + 0.112 value_stay^2 + 0.222 value_stay*reward + -0.382 value_stay*harvest_duration + 0.707 reward^2 + 0.173 reward*harvest_duration \n",
      "value_exit[t+1] = -0.071 1 + 1.0 value_exit[t] + 0.05 value_exit^2 + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 60, 36, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 343/1000 --- L(Train): 0.4058847 --- L(Val, RNN): 0.3733142 --- L(Val, SINDy): 0.4795115 --- Time: 3.44s; --- Convergence: 5.37e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 43/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.285 1 + 0.441 value_stay[t] + 0.169 reward + 0.108 value_stay^2 + 0.221 value_stay*reward + -0.384 value_stay*harvest_duration + 0.706 reward^2 + 0.173 reward*harvest_duration \n",
      "value_exit[t+1] = -0.066 1 + 1.0 value_exit[t] + 0.051 value_exit^2 + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 0, 37, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 344/1000 --- L(Train): 0.4047338 --- L(Val, RNN): 0.3728246 --- L(Val, SINDy): 0.4785167 --- Time: 3.67s; --- Convergence: 5.13e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 44/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.286 1 + 0.44 value_stay[t] + 0.17 reward + 0.106 value_stay^2 + 0.221 value_stay*reward + -0.384 value_stay*harvest_duration + 0.707 reward^2 + 0.174 reward*harvest_duration \n",
      "value_exit[t+1] = -0.061 1 + 1.0 value_exit[t] + 0.053 value_exit^2 + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 0, 38, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 345/1000 --- L(Train): 0.4064340 --- L(Val, RNN): 0.3721532 --- L(Val, SINDy): 0.4783028 --- Time: 5.11s; --- Convergence: 5.92e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 45/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.287 1 + 0.439 value_stay[t] + 0.171 reward + 0.104 value_stay^2 + 0.222 value_stay*reward + -0.384 value_stay*harvest_duration + 0.708 reward^2 + 0.176 reward*harvest_duration \n",
      "value_exit[t+1] = -0.056 1 + 1.0 value_exit[t] + 0.055 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 0, 39, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 346/1000 --- L(Train): 0.3986992 --- L(Val, RNN): 0.3713073 --- L(Val, SINDy): 0.4767755 --- Time: 2.63s; --- Convergence: 7.19e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 46/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.289 1 + 0.439 value_stay[t] + 0.173 reward + 0.103 value_stay^2 + 0.222 value_stay*reward + -0.383 value_stay*harvest_duration + 0.709 reward^2 + 0.178 reward*harvest_duration \n",
      "value_exit[t+1] = -0.051 1 + 1.0 value_exit[t] + 0.056 value_exit^2 + -0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 0, -, -, 0, 40, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 347/1000 --- L(Train): 0.3984274 --- L(Val, RNN): 0.3705930 --- L(Val, SINDy): 0.4751840 --- Time: 1.80s; --- Convergence: 7.17e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 47/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.292 1 + 0.44 value_stay[t] + 0.175 reward + 0.102 value_stay^2 + 0.224 value_stay*reward + -0.382 value_stay*harvest_duration + 0.71 reward^2 + 0.18 reward*harvest_duration \n",
      "value_exit[t+1] = -0.046 1 + 1.0 value_exit[t] + 0.058 value_exit^2 + -0.005 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 1, -, -, 0, 41, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 348/1000 --- L(Train): 0.3987691 --- L(Val, RNN): 0.3698566 --- L(Val, SINDy): 0.4734010 --- Time: 2.40s; --- Convergence: 7.27e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 48/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.293 1 + 0.44 value_stay[t] + 0.177 reward + 0.1 value_stay^2 + 0.224 value_stay*reward + -0.382 value_stay*harvest_duration + 0.711 reward^2 + 0.181 reward*harvest_duration \n",
      "value_exit[t+1] = -0.042 1 + 1.0 value_exit[t] + 0.06 value_exit^2 + -0.007 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 2, -, -, 0, 42, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 349/1000 --- L(Train): 0.3988968 --- L(Val, RNN): 0.3693002 --- L(Val, SINDy): 0.4722442 --- Time: 3.77s; --- Convergence: 6.41e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 49/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.295 1 + 0.44 value_stay[t] + 0.178 reward + 0.099 value_stay^2 + 0.225 value_stay*reward + -0.381 value_stay*harvest_duration + 0.712 reward^2 + 0.183 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.061 value_exit^2 + -0.008 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 3, -, -, 0, 43, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 350/1000 --- L(Train): 0.3948970 --- L(Val, RNN): 0.3690347 --- L(Val, SINDy): 0.4713446 --- Time: 2.87s; --- Convergence: 4.54e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 50/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.297 1 + 0.44 value_stay[t] + 0.18 reward + 0.098 value_stay^2 + 0.225 value_stay*reward + -0.381 value_stay*harvest_duration + 0.712 reward^2 + 0.184 reward*harvest_duration \n",
      "value_exit[t+1] = -0.034 1 + 1.0 value_exit[t] + 0.062 value_exit^2 + -0.009 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 4, -, -, 0, 44, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 351/1000 --- L(Train): 0.3972763 --- L(Val, RNN): 0.3685449 --- L(Val, SINDy): 0.4713044 --- Time: 1.62s; --- Convergence: 4.72e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 51/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.297 1 + 0.439 value_stay[t] + 0.18 reward + 0.095 value_stay^2 + 0.224 value_stay*reward + -0.382 value_stay*harvest_duration + 0.712 reward^2 + 0.184 reward*harvest_duration \n",
      "value_exit[t+1] = -0.031 1 + 1.0 value_exit[t] + 0.063 value_exit^2 + -0.01 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 5, -, -, 0, 45, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 352/1000 --- L(Train): 0.3957275 --- L(Val, RNN): 0.3677547 --- L(Val, SINDy): 0.4699499 --- Time: 2.61s; --- Convergence: 6.31e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 52/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.297 1 + 0.437 value_stay[t] + 0.179 reward + 0.092 value_stay^2 + 0.223 value_stay*reward + -0.383 value_stay*harvest_duration + 0.711 reward^2 + 0.183 reward*harvest_duration \n",
      "value_exit[t+1] = -0.028 1 + 1.0 value_exit[t] + 0.064 value_exit^2 + -0.011 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 6, -, -, 0, 46, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 353/1000 --- L(Train): 0.3956258 --- L(Val, RNN): 0.3669232 --- L(Val, SINDy): 0.4677081 --- Time: 2.21s; --- Convergence: 7.31e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 53/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.299 1 + 0.437 value_stay[t] + 0.18 reward + 0.09 value_stay^2 + 0.222 value_stay*reward + -0.383 value_stay*harvest_duration + 0.71 reward^2 + 0.184 reward*harvest_duration \n",
      "value_exit[t+1] = -0.027 1 + 1.0 value_exit[t] + 0.065 value_exit^2 + -0.011 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 7, -, -, 0, 47, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 354/1000 --- L(Train): 0.3940746 --- L(Val, RNN): 0.3665599 --- L(Val, SINDy): 0.4646212 --- Time: 2.25s; --- Convergence: 5.47e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 54/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.302 1 + 0.439 value_stay[t] + 0.181 reward + 0.091 value_stay^2 + 0.224 value_stay*reward + -0.381 value_stay*harvest_duration + 0.711 reward^2 + 0.186 reward*harvest_duration \n",
      "value_exit[t+1] = -0.025 1 + 1.0 value_exit[t] + 0.066 value_exit^2 + -0.011 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 8, -, -, 0, 48, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 355/1000 --- L(Train): 0.3960564 --- L(Val, RNN): 0.3660711 --- L(Val, SINDy): 0.4619758 --- Time: 2.08s; --- Convergence: 5.18e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 55/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.305 1 + 0.441 value_stay[t] + 0.183 reward + 0.091 value_stay^2 + 0.225 value_stay*reward + -0.379 value_stay*harvest_duration + 0.712 reward^2 + 0.188 reward*harvest_duration \n",
      "value_exit[t+1] = -0.025 1 + 1.0 value_exit[t] + 0.066 value_exit^2 + -0.011 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 9, -, -, 0, 49, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 356/1000 --- L(Train): 0.3917784 --- L(Val, RNN): 0.3654449 --- L(Val, SINDy): 0.4591423 --- Time: 1.07s; --- Convergence: 5.72e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 56/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.308 1 + 0.442 value_stay[t] + 0.184 reward + 0.09 value_stay^2 + 0.225 value_stay*reward + -0.378 value_stay*harvest_duration + 0.712 reward^2 + 0.188 reward*harvest_duration \n",
      "value_exit[t+1] = -0.025 1 + 1.0 value_exit[t] + 0.066 value_exit^2 + -0.01 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 10, -, -, 0, 50, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 357/1000 --- L(Train): 0.3914028 --- L(Val, RNN): 0.3644816 --- L(Val, SINDy): 0.4567034 --- Time: 0.91s; --- Convergence: 7.68e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 57/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.31 1 + 0.441 value_stay[t] + 0.184 reward + 0.088 value_stay^2 + 0.224 value_stay*reward + -0.379 value_stay*harvest_duration + 0.71 reward^2 + 0.188 reward*harvest_duration \n",
      "value_exit[t+1] = -0.026 1 + 1.0 value_exit[t] + 0.066 value_exit^2 + -0.009 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 11, -, -, 0, 51, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 358/1000 --- L(Train): 0.3884457 --- L(Val, RNN): 0.3638746 --- L(Val, SINDy): 0.4540978 --- Time: 0.91s; --- Convergence: 6.87e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 58/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.312 1 + 0.441 value_stay[t] + 0.183 reward + 0.086 value_stay^2 + 0.223 value_stay*reward + -0.378 value_stay*harvest_duration + 0.709 reward^2 + 0.188 reward*harvest_duration \n",
      "value_exit[t+1] = -0.027 1 + 1.0 value_exit[t] + 0.066 value_exit^2 + -0.008 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 12, -, -, 0, 52, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 359/1000 --- L(Train): 0.3890775 --- L(Val, RNN): 0.3636337 --- L(Val, SINDy): 0.4525570 --- Time: 0.86s; --- Convergence: 4.64e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 59/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.313 1 + 0.441 value_stay[t] + 0.183 reward + 0.084 value_stay^2 + 0.222 value_stay*reward + -0.379 value_stay*harvest_duration + 0.708 reward^2 + 0.188 reward*harvest_duration \n",
      "value_exit[t+1] = -0.028 1 + 1.0 value_exit[t] + 0.065 value_exit^2 + -0.006 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 13, -, -, 0, 53, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 360/1000 --- L(Train): 0.3886282 --- L(Val, RNN): 0.3628688 --- L(Val, SINDy): 0.4511923 --- Time: 0.99s; --- Convergence: 6.15e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 60/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.315 1 + 0.442 value_stay[t] + 0.184 reward + 0.083 value_stay^2 + 0.222 value_stay*reward + -0.378 value_stay*harvest_duration + 0.707 reward^2 + 0.188 reward*harvest_duration \n",
      "value_exit[t+1] = -0.029 1 + 1.0 value_exit[t] + 0.065 value_exit^2 + -0.005 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 14, -, -, 0, 54, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 361/1000 --- L(Train): 0.3918735 --- L(Val, RNN): 0.3619251 --- L(Val, SINDy): 0.4510588 --- Time: 1.01s; --- Convergence: 7.79e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 61/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.318 1 + 0.442 value_stay[t] + 0.184 reward + 0.082 value_stay^2 + 0.222 value_stay*reward + -0.378 value_stay*harvest_duration + 0.707 reward^2 + 0.189 reward*harvest_duration \n",
      "value_exit[t+1] = -0.03 1 + 1.0 value_exit[t] + 0.065 value_exit^2 + -0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 15, -, -, 0, 55, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 362/1000 --- L(Train): 0.3881640 --- L(Val, RNN): 0.3614249 --- L(Val, SINDy): 0.4519139 --- Time: 1.18s; --- Convergence: 6.40e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 62/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.321 1 + 0.444 value_stay[t] + 0.186 reward + 0.083 value_stay^2 + 0.224 value_stay*reward + -0.375 value_stay*harvest_duration + 0.708 reward^2 + 0.19 reward*harvest_duration \n",
      "value_exit[t+1] = -0.031 1 + 1.0 value_exit[t] + 0.065 value_exit^2 + -0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 16, -, -, 0, 56, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 363/1000 --- L(Train): 0.3891884 --- L(Val, RNN): 0.3612573 --- L(Val, SINDy): 0.4510693 --- Time: 0.88s; --- Convergence: 4.04e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 63/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.325 1 + 0.446 value_stay[t] + 0.188 reward + 0.083 value_stay^2 + 0.225 value_stay*reward + -0.373 value_stay*harvest_duration + 0.709 reward^2 + 0.192 reward*harvest_duration \n",
      "value_exit[t+1] = -0.032 1 + 1.0 value_exit[t] + 0.064 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 17, -, -, 0, 57, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 364/1000 --- L(Train): 0.3833376 --- L(Val, RNN): 0.3607487 --- L(Val, SINDy): 0.4489166 --- Time: 1.02s; --- Convergence: 4.56e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 64/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.327 1 + 0.448 value_stay[t] + 0.189 reward + 0.083 value_stay^2 + 0.226 value_stay*reward + -0.372 value_stay*harvest_duration + 0.709 reward^2 + 0.193 reward*harvest_duration \n",
      "value_exit[t+1] = -0.033 1 + 1.0 value_exit[t] + 0.064 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 18, -, -, 0, 58, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 365/1000 --- L(Train): 0.3844191 --- L(Val, RNN): 0.3599393 --- L(Val, SINDy): 0.4468477 --- Time: 0.96s; --- Convergence: 6.33e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 65/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.329 1 + 0.448 value_stay[t] + 0.189 reward + 0.081 value_stay^2 + 0.226 value_stay*reward + -0.371 value_stay*harvest_duration + 0.708 reward^2 + 0.193 reward*harvest_duration \n",
      "value_exit[t+1] = -0.034 1 + 1.0 value_exit[t] + 0.064 value_exit^2 + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 19, -, -, 0, 59, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 366/1000 --- L(Train): 0.3863412 --- L(Val, RNN): 0.3594700 --- L(Val, SINDy): 0.4461243 --- Time: 1.04s; --- Convergence: 5.51e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 66/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.33 1 + 0.447 value_stay[t] + 0.188 reward + 0.079 value_stay^2 + 0.224 value_stay*reward + -0.372 value_stay*harvest_duration + 0.707 reward^2 + 0.193 reward*harvest_duration \n",
      "value_exit[t+1] = -0.035 1 + 1.0 value_exit[t] + 0.064 value_exit^2 + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 20, -, -, 0, 60, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 367/1000 --- L(Train): 0.3815255 --- L(Val, RNN): 0.3592374 --- L(Val, SINDy): 0.4449315 --- Time: 0.87s; --- Convergence: 3.92e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 67/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.332 1 + 0.447 value_stay[t] + 0.188 reward + 0.077 value_stay^2 + 0.223 value_stay*reward + -0.371 value_stay*harvest_duration + 0.705 reward^2 + 0.193 reward*harvest_duration \n",
      "value_exit[t+1] = -0.035 1 + 1.0 value_exit[t] + 0.064 value_exit^2 + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 21, -, -, 0, 61, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 368/1000 --- L(Train): 0.3855280 --- L(Val, RNN): 0.3589957 --- L(Val, SINDy): 0.4448040 --- Time: 0.84s; --- Convergence: 3.17e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 68/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.334 1 + 0.447 value_stay[t] + 0.189 reward + 0.076 value_stay^2 + 0.223 value_stay*reward + -0.37 value_stay*harvest_duration + 0.705 reward^2 + 0.193 reward*harvest_duration \n",
      "value_exit[t+1] = -0.035 1 + 1.0 value_exit[t] + 0.064 value_exit^2 + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 22, -, -, 0, 62, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 369/1000 --- L(Train): 0.3839014 --- L(Val, RNN): 0.3582517 --- L(Val, SINDy): 0.4438934 --- Time: 1.11s; --- Convergence: 5.30e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 69/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.336 1 + 0.448 value_stay[t] + 0.189 reward + 0.075 value_stay^2 + 0.223 value_stay*reward + -0.37 value_stay*harvest_duration + 0.704 reward^2 + 0.193 reward*harvest_duration \n",
      "value_exit[t+1] = -0.035 1 + 1.0 value_exit[t] + 0.065 value_exit^2 + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 23, -, -, 0, 63, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 370/1000 --- L(Train): 0.3810094 --- L(Val, RNN): 0.3576827 --- L(Val, SINDy): 0.4435016 --- Time: 1.34s; --- Convergence: 5.50e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 70/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.338 1 + 0.448 value_stay[t] + 0.189 reward + 0.074 value_stay^2 + 0.223 value_stay*reward + -0.368 value_stay*harvest_duration + 0.704 reward^2 + 0.194 reward*harvest_duration \n",
      "value_exit[t+1] = -0.035 1 + 1.0 value_exit[t] + 0.065 value_exit^2 + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 24, -, -, 0, 64, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 371/1000 --- L(Train): 0.3850397 --- L(Val, RNN): 0.3574932 --- L(Val, SINDy): 0.4433270 --- Time: 1.47s; --- Convergence: 3.70e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 71/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.34 1 + 0.449 value_stay[t] + 0.19 reward + 0.073 value_stay^2 + 0.224 value_stay*reward + -0.367 value_stay*harvest_duration + 0.704 reward^2 + 0.195 reward*harvest_duration \n",
      "value_exit[t+1] = -0.035 1 + 1.0 value_exit[t] + 0.065 value_exit^2 + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 25, -, -, 0, 65, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 372/1000 --- L(Train): 0.3804282 --- L(Val, RNN): 0.3571743 --- L(Val, SINDy): 0.4429793 --- Time: 0.89s; --- Convergence: 3.44e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 72/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.343 1 + 0.451 value_stay[t] + 0.192 reward + 0.074 value_stay^2 + 0.225 value_stay*reward + -0.365 value_stay*harvest_duration + 0.705 reward^2 + 0.196 reward*harvest_duration \n",
      "value_exit[t+1] = -0.035 1 + 1.0 value_exit[t] + 0.066 value_exit^2 + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 26, -, -, 0, 66, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 373/1000 --- L(Train): 0.3835864 --- L(Val, RNN): 0.3565357 --- L(Val, SINDy): 0.4418430 --- Time: 1.25s; --- Convergence: 4.91e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 73/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.345 1 + 0.452 value_stay[t] + 0.193 reward + 0.073 value_stay^2 + 0.226 value_stay*reward + -0.364 value_stay*harvest_duration + 0.705 reward^2 + 0.197 reward*harvest_duration \n",
      "value_exit[t+1] = -0.034 1 + 1.0 value_exit[t] + 0.066 value_exit^2 + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 27, -, -, 0, 67, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 374/1000 --- L(Train): 0.3826292 --- L(Val, RNN): 0.3560379 --- L(Val, SINDy): 0.4409771 --- Time: 0.93s; --- Convergence: 4.95e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 74/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.346 1 + 0.451 value_stay[t] + 0.193 reward + 0.071 value_stay^2 + 0.225 value_stay*reward + -0.364 value_stay*harvest_duration + 0.704 reward^2 + 0.197 reward*harvest_duration \n",
      "value_exit[t+1] = -0.034 1 + 1.0 value_exit[t] + 0.067 value_exit^2 + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 28, -, -, 0, 68, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 375/1000 --- L(Train): 0.3822999 --- L(Val, RNN): 0.3558404 --- L(Val, SINDy): 0.4399580 --- Time: 0.87s; --- Convergence: 3.46e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 75/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.346 1 + 0.448 value_stay[t] + 0.192 reward + 0.066 value_stay^2 + 0.223 value_stay*reward + -0.366 value_stay*harvest_duration + 0.702 reward^2 + 0.196 reward*harvest_duration \n",
      "value_exit[t+1] = -0.033 1 + 1.0 value_exit[t] + 0.067 value_exit^2 + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 29, -, -, 0, 69, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 376/1000 --- L(Train): 0.3795273 --- L(Val, RNN): 0.3555544 --- L(Val, SINDy): 0.4386193 --- Time: 0.92s; --- Convergence: 3.16e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 76/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.345 1 + 0.446 value_stay[t] + 0.191 reward + 0.061 value_stay^2 + 0.222 value_stay*reward + -0.367 value_stay*harvest_duration + 0.7 reward^2 + 0.195 reward*harvest_duration \n",
      "value_exit[t+1] = -0.032 1 + 1.0 value_exit[t] + 0.068 value_exit^2 + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 30, -, -, 0, 70, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 377/1000 --- L(Train): 0.3778847 --- L(Val, RNN): 0.3550833 --- L(Val, SINDy): 0.4380585 --- Time: 0.98s; --- Convergence: 3.94e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 77/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.346 1 + 0.445 value_stay[t] + 0.191 reward + 0.059 value_stay^2 + 0.222 value_stay*reward + -0.368 value_stay*harvest_duration + 0.7 reward^2 + 0.195 reward*harvest_duration \n",
      "value_exit[t+1] = -0.031 1 + 1.0 value_exit[t] + 0.068 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 31, -, -, 0, 71, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 378/1000 --- L(Train): 0.3823486 --- L(Val, RNN): 0.3546937 --- L(Val, SINDy): 0.4376440 --- Time: 0.97s; --- Convergence: 3.92e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 78/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.348 1 + 0.446 value_stay[t] + 0.193 reward + 0.059 value_stay^2 + 0.223 value_stay*reward + -0.366 value_stay*harvest_duration + 0.7 reward^2 + 0.197 reward*harvest_duration \n",
      "value_exit[t+1] = -0.031 1 + 1.0 value_exit[t] + 0.069 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 32, -, -, 0, 72, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 379/1000 --- L(Train): 0.3809029 --- L(Val, RNN): 0.3544349 --- L(Val, SINDy): 0.4372691 --- Time: 1.12s; --- Convergence: 3.25e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 79/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.352 1 + 0.448 value_stay[t] + 0.195 reward + 0.06 value_stay^2 + 0.226 value_stay*reward + -0.363 value_stay*harvest_duration + 0.702 reward^2 + 0.199 reward*harvest_duration \n",
      "value_exit[t+1] = -0.03 1 + 1.0 value_exit[t] + 0.069 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 33, -, -, 0, 73, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 380/1000 --- L(Train): 0.3829245 --- L(Val, RNN): 0.3541735 --- L(Val, SINDy): 0.4363851 --- Time: 1.15s; --- Convergence: 2.93e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 80/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.354 1 + 0.45 value_stay[t] + 0.197 reward + 0.06 value_stay^2 + 0.228 value_stay*reward + -0.361 value_stay*harvest_duration + 0.703 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.03 1 + 1.0 value_exit[t] + 0.07 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 34, -, -, 0, 74, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 381/1000 --- L(Train): 0.3823634 --- L(Val, RNN): 0.3538725 --- L(Val, SINDy): 0.4355955 --- Time: 1.15s; --- Convergence: 2.97e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 81/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.356 1 + 0.45 value_stay[t] + 0.197 reward + 0.059 value_stay^2 + 0.227 value_stay*reward + -0.361 value_stay*harvest_duration + 0.702 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.03 1 + 1.0 value_exit[t] + 0.07 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 35, -, -, 0, 75, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 382/1000 --- L(Train): 0.3882413 --- L(Val, RNN): 0.3535313 --- L(Val, SINDy): 0.4349793 --- Time: 1.04s; --- Convergence: 3.19e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 82/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.357 1 + 0.45 value_stay[t] + 0.197 reward + 0.057 value_stay^2 + 0.227 value_stay*reward + -0.36 value_stay*harvest_duration + 0.701 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.03 1 + 1.0 value_exit[t] + 0.07 value_exit^2 + -0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 36, -, -, 0, 76, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 383/1000 --- L(Train): 0.3758229 --- L(Val, RNN): 0.3532594 --- L(Val, SINDy): 0.4342207 --- Time: 0.82s; --- Convergence: 2.96e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 83/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.359 1 + 0.45 value_stay[t] + 0.197 reward + 0.056 value_stay^2 + 0.227 value_stay*reward + -0.36 value_stay*harvest_duration + 0.7 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.03 1 + 1.0 value_exit[t] + 0.07 value_exit^2 + -0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 37, -, -, 0, 77, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 384/1000 --- L(Train): 0.3778823 --- L(Val, RNN): 0.3530051 --- L(Val, SINDy): 0.4334933 --- Time: 1.02s; --- Convergence: 2.75e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 84/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.36 1 + 0.45 value_stay[t] + 0.196 reward + 0.055 value_stay^2 + 0.226 value_stay*reward + -0.359 value_stay*harvest_duration + 0.699 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.03 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 38, -, -, 0, 78, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 385/1000 --- L(Train): 0.3807187 --- L(Val, RNN): 0.3527064 --- L(Val, SINDy): 0.4328265 --- Time: 1.24s; --- Convergence: 2.87e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 85/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.361 1 + 0.449 value_stay[t] + 0.195 reward + 0.052 value_stay^2 + 0.225 value_stay*reward + -0.36 value_stay*harvest_duration + 0.697 reward^2 + 0.2 reward*harvest_duration \n",
      "value_exit[t+1] = -0.03 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 39, -, -, 0, 79, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 386/1000 --- L(Train): 0.3775881 --- L(Val, RNN): 0.3525140 --- L(Val, SINDy): 0.4320050 --- Time: 1.20s; --- Convergence: 2.40e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 86/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.361 1 + 0.448 value_stay[t] + 0.194 reward + 0.05 value_stay^2 + 0.223 value_stay*reward + -0.36 value_stay*harvest_duration + 0.694 reward^2 + 0.198 reward*harvest_duration \n",
      "value_exit[t+1] = -0.031 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 1, 0, 0, 0, 0, -\n",
      "value_exit: 40, -, -, 0, 80, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 387/1000 --- L(Train): 0.3784277 --- L(Val, RNN): 0.3523140 --- L(Val, SINDy): 0.4312381 --- Time: 0.90s; --- Convergence: 2.20e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 87/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.363 1 + 0.449 value_stay[t] + 0.194 reward + 0.049 value_stay^2 + 0.222 value_stay*reward + -0.359 value_stay*harvest_duration + 0.693 reward^2 + 0.198 reward*harvest_duration \n",
      "value_exit[t+1] = -0.032 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 2, 0, 0, 0, 0, -\n",
      "value_exit: 41, -, -, 0, 81, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 388/1000 --- L(Train): 0.3793118 --- L(Val, RNN): 0.3519314 --- L(Val, SINDy): 0.4306388 --- Time: 1.03s; --- Convergence: 3.01e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 88/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.368 1 + 0.453 value_stay[t] + 0.196 reward + 0.052 value_stay^2 + 0.225 value_stay*reward + -0.356 value_stay*harvest_duration + 0.694 reward^2 + 0.2 reward*harvest_duration \n",
      "value_exit[t+1] = -0.032 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 42, -, -, 0, 82, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 389/1000 --- L(Train): 0.3796552 --- L(Val, RNN): 0.3517359 --- L(Val, SINDy): 0.4299800 --- Time: 0.88s; --- Convergence: 2.48e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 89/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.372 1 + 0.457 value_stay[t] + 0.198 reward + 0.055 value_stay^2 + 0.227 value_stay*reward + -0.351 value_stay*harvest_duration + 0.695 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.033 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 43, -, -, 0, 83, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 390/1000 --- L(Train): 0.3796007 --- L(Val, RNN): 0.3516094 --- L(Val, SINDy): 0.4292380 --- Time: 1.06s; --- Convergence: 1.87e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 90/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.376 1 + 0.459 value_stay[t] + 0.199 reward + 0.056 value_stay^2 + 0.228 value_stay*reward + -0.349 value_stay*harvest_duration + 0.695 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.034 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 44, -, -, 0, 84, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 391/1000 --- L(Train): 0.3745319 --- L(Val, RNN): 0.3512953 --- L(Val, SINDy): 0.4286235 --- Time: 0.83s; --- Convergence: 2.51e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 91/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.376 1 + 0.459 value_stay[t] + 0.197 reward + 0.054 value_stay^2 + 0.226 value_stay*reward + -0.349 value_stay*harvest_duration + 0.693 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.035 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 45, -, -, 0, 85, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 392/1000 --- L(Train): 0.3777174 --- L(Val, RNN): 0.3509279 --- L(Val, SINDy): 0.4280448 --- Time: 1.07s; --- Convergence: 3.09e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 92/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.376 1 + 0.457 value_stay[t] + 0.195 reward + 0.051 value_stay^2 + 0.224 value_stay*reward + -0.351 value_stay*harvest_duration + 0.69 reward^2 + 0.199 reward*harvest_duration \n",
      "value_exit[t+1] = -0.036 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 0, 0, 0, 0, 0, -\n",
      "value_exit: 46, -, -, 0, 86, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 393/1000 --- L(Train): 0.3787279 --- L(Val, RNN): 0.3508641 --- L(Val, SINDy): 0.4273395 --- Time: 0.88s; --- Convergence: 1.86e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 93/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.377 1 + 0.456 value_stay[t] + 0.194 reward + 0.048 value_stay^2 + 0.221 value_stay*reward + -0.352 value_stay*harvest_duration + 0.687 reward^2 + 0.198 reward*harvest_duration \n",
      "value_exit[t+1] = -0.036 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 1, 0, 0, 0, 0, -\n",
      "value_exit: 47, -, -, 0, 87, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 394/1000 --- L(Train): 0.3797129 --- L(Val, RNN): 0.3507236 --- L(Val, SINDy): 0.4266005 --- Time: 0.88s; --- Convergence: 1.63e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 94/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.378 1 + 0.456 value_stay[t] + 0.193 reward + 0.047 value_stay^2 + 0.221 value_stay*reward + -0.351 value_stay*harvest_duration + 0.686 reward^2 + 0.197 reward*harvest_duration \n",
      "value_exit[t+1] = -0.037 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 2, 0, 0, 0, 0, -\n",
      "value_exit: 48, -, -, 0, 88, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 395/1000 --- L(Train): 0.3840516 --- L(Val, RNN): 0.3504306 --- L(Val, SINDy): 0.4259879 --- Time: 1.03s; --- Convergence: 2.28e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 95/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.38 1 + 0.457 value_stay[t] + 0.193 reward + 0.047 value_stay^2 + 0.22 value_stay*reward + -0.35 value_stay*harvest_duration + 0.685 reward^2 + 0.197 reward*harvest_duration \n",
      "value_exit[t+1] = -0.037 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 3, 0, 0, 0, 0, -\n",
      "value_exit: 49, -, -, 0, 89, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 396/1000 --- L(Train): 0.3815412 --- L(Val, RNN): 0.3501771 --- L(Val, SINDy): 0.4254302 --- Time: 0.95s; --- Convergence: 2.41e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 96/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.382 1 + 0.458 value_stay[t] + 0.193 reward + 0.047 value_stay^2 + 0.22 value_stay*reward + -0.349 value_stay*harvest_duration + 0.685 reward^2 + 0.198 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 4, 0, 0, 0, 0, -\n",
      "value_exit: 50, -, -, 0, 90, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 397/1000 --- L(Train): 0.3798553 --- L(Val, RNN): 0.3500863 --- L(Val, SINDy): 0.4249040 --- Time: 0.90s; --- Convergence: 1.66e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 97/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.384 1 + 0.459 value_stay[t] + 0.194 reward + 0.047 value_stay^2 + 0.221 value_stay*reward + -0.348 value_stay*harvest_duration + 0.685 reward^2 + 0.199 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 5, 0, 0, 0, 0, -\n",
      "value_exit: 51, -, -, 0, 91, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 398/1000 --- L(Train): 0.3771397 --- L(Val, RNN): 0.3499930 --- L(Val, SINDy): 0.4244349 --- Time: 0.91s; --- Convergence: 1.30e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 98/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.385 1 + 0.46 value_stay[t] + 0.195 reward + 0.047 value_stay^2 + 0.222 value_stay*reward + -0.347 value_stay*harvest_duration + 0.685 reward^2 + 0.199 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.071 value_exit^2 + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 6, 0, 0, 0, 0, -\n",
      "value_exit: 52, -, -, 0, 92, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 399/1000 --- L(Train): 0.3795062 --- L(Val, RNN): 0.3498028 --- L(Val, SINDy): 0.4239236 --- Time: 1.01s; --- Convergence: 1.60e-04; LR: 5.00e-03; Metric: 0.3324696; Bad epochs: 99/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.387 1 + 0.461 value_stay[t] + 0.197 reward + 0.047 value_stay^2 + 0.223 value_stay*reward + -0.345 value_stay*harvest_duration + 0.686 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.072 value_exit^2 + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 7, 0, 0, 0, 0, -\n",
      "value_exit: 53, -, -, 0, 93, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 400/1000 --- L(Train): 0.3763884 --- L(Val, RNN): 0.3495343 --- L(Val, SINDy): 0.4233840 --- Time: 1.02s; --- Convergence: 2.14e-04; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.389 1 + 0.461 value_stay[t] + 0.198 reward + 0.047 value_stay^2 + 0.225 value_stay*reward + -0.345 value_stay*harvest_duration + 0.687 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.072 value_exit^2 + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 8, 0, 0, 0, 0, -\n",
      "value_exit: 54, -, -, 0, 94, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 401/1000 --- L(Train): 0.3817411 --- L(Val, RNN): 0.3494411 --- L(Val, SINDy): 0.4225146 --- Time: 1.62s; --- Convergence: 1.54e-04; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 1/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.388 1 + 0.459 value_stay[t] + 0.198 reward + 0.043 value_stay^2 + 0.224 value_stay*reward + -0.347 value_stay*harvest_duration + 0.686 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.072 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 9, 0, 0, 0, 0, -\n",
      "value_exit: 55, -, -, 0, 95, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 402/1000 --- L(Train): 0.3813535 --- L(Val, RNN): 0.3494253 --- L(Val, SINDy): 0.4219857 --- Time: 3.27s; --- Convergence: 8.48e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 2/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.387 1 + 0.456 value_stay[t] + 0.197 reward + 0.038 value_stay^2 + 0.222 value_stay*reward + -0.349 value_stay*harvest_duration + 0.685 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.073 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 10, 0, 0, 0, 0, -\n",
      "value_exit: 56, -, -, 0, 96, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 403/1000 --- L(Train): 0.3774808 --- L(Val, RNN): 0.3493804 --- L(Val, SINDy): 0.4215022 --- Time: 3.88s; --- Convergence: 6.48e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 3/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.386 1 + 0.453 value_stay[t] + 0.196 reward + 0.034 value_stay^2 + 0.221 value_stay*reward + -0.351 value_stay*harvest_duration + 0.684 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.073 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 11, 0, 0, 0, 0, -\n",
      "value_exit: 57, -, -, 0, 97, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 404/1000 --- L(Train): 0.3795100 --- L(Val, RNN): 0.3492528 --- L(Val, SINDy): 0.4208545 --- Time: 3.69s; --- Convergence: 9.62e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 4/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.386 1 + 0.452 value_stay[t] + 0.197 reward + 0.031 value_stay^2 + 0.221 value_stay*reward + -0.352 value_stay*harvest_duration + 0.684 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.074 value_exit^2 + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 12, 0, 0, 0, 0, -\n",
      "value_exit: 58, -, -, 0, 98, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 405/1000 --- L(Train): 0.3786492 --- L(Val, RNN): 0.3490922 --- L(Val, SINDy): 0.4197773 --- Time: 5.24s; --- Convergence: 1.28e-04; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 5/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.387 1 + 0.451 value_stay[t] + 0.197 reward + 0.029 value_stay^2 + 0.221 value_stay*reward + -0.352 value_stay*harvest_duration + 0.684 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.074 value_exit^2 + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 13, 0, 0, 0, 0, -\n",
      "value_exit: 59, -, -, 0, 99, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 406/1000 --- L(Train): 0.3789916 --- L(Val, RNN): 0.3489975 --- L(Val, SINDy): 0.4183827 --- Time: 4.61s; --- Convergence: 1.12e-04; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 6/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.389 1 + 0.452 value_stay[t] + 0.199 reward + 0.03 value_stay^2 + 0.223 value_stay*reward + -0.351 value_stay*harvest_duration + 0.685 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.074 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 14, 0, 0, 0, 0, -\n",
      "value_exit: 60, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 407/1000 --- L(Train): 0.3735381 --- L(Val, RNN): 0.3489585 --- L(Val, SINDy): 0.4167441 --- Time: 8.08s; --- Convergence: 7.53e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 7/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.392 1 + 0.454 value_stay[t] + 0.202 reward + 0.032 value_stay^2 + 0.227 value_stay*reward + -0.348 value_stay*harvest_duration + 0.687 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.075 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 15, 0, 0, 0, 0, -\n",
      "value_exit: 61, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 408/1000 --- L(Train): 0.3734650 --- L(Val, RNN): 0.3489278 --- L(Val, SINDy): 0.4159847 --- Time: 3.56s; --- Convergence: 5.30e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 8/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.394 1 + 0.456 value_stay[t] + 0.204 reward + 0.033 value_stay^2 + 0.23 value_stay*reward + -0.345 value_stay*harvest_duration + 0.689 reward^2 + 0.208 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.075 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 16, 0, 0, 0, 0, -\n",
      "value_exit: 62, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 409/1000 --- L(Train): 0.3800357 --- L(Val, RNN): 0.3488278 --- L(Val, SINDy): 0.4160467 --- Time: 3.57s; --- Convergence: 7.65e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 9/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.396 1 + 0.458 value_stay[t] + 0.206 reward + 0.034 value_stay^2 + 0.232 value_stay*reward + -0.343 value_stay*harvest_duration + 0.69 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.076 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 17, 0, 0, 0, 0, -\n",
      "value_exit: 63, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 410/1000 --- L(Train): 0.3746231 --- L(Val, RNN): 0.3487060 --- L(Val, SINDy): 0.4159558 --- Time: 5.91s; --- Convergence: 9.91e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 10/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.397 1 + 0.457 value_stay[t] + 0.206 reward + 0.033 value_stay^2 + 0.232 value_stay*reward + -0.343 value_stay*harvest_duration + 0.69 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.076 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 18, 0, 0, 0, 0, -\n",
      "value_exit: 64, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 411/1000 --- L(Train): 0.3746335 --- L(Val, RNN): 0.3485884 --- L(Val, SINDy): 0.4161132 --- Time: 4.71s; --- Convergence: 1.08e-04; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 11/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.397 1 + 0.456 value_stay[t] + 0.205 reward + 0.03 value_stay^2 + 0.231 value_stay*reward + -0.344 value_stay*harvest_duration + 0.688 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.076 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 19, 0, 0, 0, 0, -\n",
      "value_exit: 65, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 412/1000 --- L(Train): 0.3717536 --- L(Val, RNN): 0.3485264 --- L(Val, SINDy): 0.4164698 --- Time: 1.12s; --- Convergence: 8.52e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 12/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.397 1 + 0.454 value_stay[t] + 0.203 reward + 0.027 value_stay^2 + 0.23 value_stay*reward + -0.345 value_stay*harvest_duration + 0.686 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.077 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 20, 0, 0, 0, 0, -\n",
      "value_exit: 66, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 413/1000 --- L(Train): 0.3695362 --- L(Val, RNN): 0.3484888 --- L(Val, SINDy): 0.4178076 --- Time: 0.98s; --- Convergence: 6.14e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 13/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.396 1 + 0.453 value_stay[t] + 0.202 reward + 0.025 value_stay^2 + 0.228 value_stay*reward + -0.347 value_stay*harvest_duration + 0.684 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.077 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 21, 0, 0, 0, 0, -\n",
      "value_exit: 67, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 414/1000 --- L(Train): 0.3773001 --- L(Val, RNN): 0.3484398 --- L(Val, SINDy): 0.4186694 --- Time: 0.86s; --- Convergence: 5.52e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 14/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.397 1 + 0.452 value_stay[t] + 0.201 reward + 0.023 value_stay^2 + 0.227 value_stay*reward + -0.347 value_stay*harvest_duration + 0.683 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.078 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 22, 0, 0, 0, 0, -\n",
      "value_exit: 68, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 415/1000 --- L(Train): 0.3719016 --- L(Val, RNN): 0.3483388 --- L(Val, SINDy): 0.4200667 --- Time: 0.96s; --- Convergence: 7.81e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 15/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.398 1 + 0.453 value_stay[t] + 0.201 reward + 0.024 value_stay^2 + 0.228 value_stay*reward + -0.346 value_stay*harvest_duration + 0.682 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.078 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 23, 0, 0, 0, 0, -\n",
      "value_exit: 69, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 416/1000 --- L(Train): 0.3790147 --- L(Val, RNN): 0.3482241 --- L(Val, SINDy): 0.4214403 --- Time: 1.38s; --- Convergence: 9.64e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 16/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.401 1 + 0.456 value_stay[t] + 0.201 reward + 0.026 value_stay^2 + 0.23 value_stay*reward + -0.344 value_stay*harvest_duration + 0.682 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.079 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 24, 0, 0, 0, 0, -\n",
      "value_exit: 70, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 417/1000 --- L(Train): 0.3715467 --- L(Val, RNN): 0.3481454 --- L(Val, SINDy): 0.4228951 --- Time: 1.03s; --- Convergence: 8.75e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 17/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.403 1 + 0.458 value_stay[t] + 0.202 reward + 0.027 value_stay^2 + 0.231 value_stay*reward + -0.342 value_stay*harvest_duration + 0.682 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.079 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 25, 0, 0, 0, 0, -\n",
      "value_exit: 71, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 418/1000 --- L(Train): 0.3738428 --- L(Val, RNN): 0.3481345 --- L(Val, SINDy): 0.4245373 --- Time: 1.13s; --- Convergence: 4.92e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 18/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.405 1 + 0.459 value_stay[t] + 0.202 reward + 0.028 value_stay^2 + 0.232 value_stay*reward + -0.341 value_stay*harvest_duration + 0.682 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.08 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 26, 0, 0, 0, 0, -\n",
      "value_exit: 72, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 419/1000 --- L(Train): 0.3770886 --- L(Val, RNN): 0.3480780 --- L(Val, SINDy): 0.4259552 --- Time: 0.87s; --- Convergence: 5.29e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 19/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.406 1 + 0.459 value_stay[t] + 0.202 reward + 0.027 value_stay^2 + 0.232 value_stay*reward + -0.342 value_stay*harvest_duration + 0.68 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = -0.037 1 + 1.0 value_exit[t] + 0.08 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 27, 0, 0, 0, 0, -\n",
      "value_exit: 73, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 420/1000 --- L(Train): 0.3669173 --- L(Val, RNN): 0.3479397 --- L(Val, SINDy): 0.4122423 --- Time: 0.86s; --- Convergence: 9.56e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 20/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.406 1 + 0.458 value_stay[t] + 0.201 reward + 0.025 value_stay^2 + 0.232 value_stay*reward + -0.343 value_stay*harvest_duration + 0.679 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = -0.037 1 + 1.0 value_exit[t] + 0.081 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 28, 0, 0, 0, 0, -\n",
      "value_exit: 74, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 421/1000 --- L(Train): 0.3759782 --- L(Val, RNN): 0.3478089 --- L(Val, SINDy): 0.4139423 --- Time: 0.90s; --- Convergence: 1.13e-04; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 21/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.407 1 + 0.458 value_stay[t] + 0.2 reward + 0.024 value_stay^2 + 0.231 value_stay*reward + -0.343 value_stay*harvest_duration + 0.677 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = -0.037 1 + 1.0 value_exit[t] + 0.081 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 29, 0, 0, 0, 0, -\n",
      "value_exit: 75, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 422/1000 --- L(Train): 0.3750668 --- L(Val, RNN): 0.3477551 --- L(Val, SINDy): 0.4154533 --- Time: 1.11s; --- Convergence: 8.35e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 22/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.408 1 + 0.458 value_stay[t] + 0.2 reward + 0.023 value_stay^2 + 0.231 value_stay*reward + -0.343 value_stay*harvest_duration + 0.676 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.081 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 30, 0, 0, 0, 0, -\n",
      "value_exit: 76, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 423/1000 --- L(Train): 0.3744653 --- L(Val, RNN): 0.3477734 --- L(Val, SINDy): 0.4163147 --- Time: 0.94s; --- Convergence: 5.09e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 23/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.409 1 + 0.458 value_stay[t] + 0.199 reward + 0.021 value_stay^2 + 0.231 value_stay*reward + -0.344 value_stay*harvest_duration + 0.675 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.082 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 31, 0, 0, 0, 0, -\n",
      "value_exit: 77, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 424/1000 --- L(Train): 0.3799876 --- L(Val, RNN): 0.3477749 --- L(Val, SINDy): 0.4165060 --- Time: 1.13s; --- Convergence: 2.62e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 24/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.409 1 + 0.457 value_stay[t] + 0.198 reward + 0.02 value_stay^2 + 0.231 value_stay*reward + -0.344 value_stay*harvest_duration + 0.673 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.082 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 32, 0, 0, 0, 0, -\n",
      "value_exit: 78, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 425/1000 --- L(Train): 0.3717726 --- L(Val, RNN): 0.3476925 --- L(Val, SINDy): 0.4166583 --- Time: 1.01s; --- Convergence: 5.43e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 25/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.41 1 + 0.457 value_stay[t] + 0.197 reward + 0.018 value_stay^2 + 0.23 value_stay*reward + -0.344 value_stay*harvest_duration + 0.672 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.083 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 33, 0, 0, 0, 0, -\n",
      "value_exit: 79, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 426/1000 --- L(Train): 0.3751509 --- L(Val, RNN): 0.3475934 --- L(Val, SINDy): 0.4165919 --- Time: 1.19s; --- Convergence: 7.67e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 26/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.41 1 + 0.457 value_stay[t] + 0.197 reward + 0.018 value_stay^2 + 0.23 value_stay*reward + -0.345 value_stay*harvest_duration + 0.671 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.083 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 34, 0, 0, 0, 0, -\n",
      "value_exit: 80, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 427/1000 --- L(Train): 0.3819354 --- L(Val, RNN): 0.3475345 --- L(Val, SINDy): 0.4167605 --- Time: 0.89s; --- Convergence: 6.78e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 27/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.412 1 + 0.458 value_stay[t] + 0.198 reward + 0.018 value_stay^2 + 0.232 value_stay*reward + -0.343 value_stay*harvest_duration + 0.671 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.084 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 35, 0, 0, 0, 0, -\n",
      "value_exit: 81, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 428/1000 --- L(Train): 0.3729434 --- L(Val, RNN): 0.3475198 --- L(Val, SINDy): 0.4163536 --- Time: 1.17s; --- Convergence: 4.13e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 28/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.414 1 + 0.459 value_stay[t] + 0.199 reward + 0.019 value_stay^2 + 0.235 value_stay*reward + -0.341 value_stay*harvest_duration + 0.672 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = -0.038 1 + 1.0 value_exit[t] + 0.084 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 36, 0, 0, 0, 0, -\n",
      "value_exit: 82, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 429/1000 --- L(Train): 0.3692357 --- L(Val, RNN): 0.3474933 --- L(Val, SINDy): 0.4155027 --- Time: 0.88s; --- Convergence: 3.39e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 29/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.414 1 + 0.458 value_stay[t] + 0.199 reward + 0.017 value_stay^2 + 0.236 value_stay*reward + -0.342 value_stay*harvest_duration + 0.672 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = -0.039 1 + 1.0 value_exit[t] + 0.085 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 37, 0, 0, 0, 0, -\n",
      "value_exit: 83, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 430/1000 --- L(Train): 0.3698045 --- L(Val, RNN): 0.3474045 --- L(Val, SINDy): 0.4151246 --- Time: 1.05s; --- Convergence: 6.13e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 30/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.414 1 + 0.457 value_stay[t] + 0.199 reward + 0.015 value_stay^2 + 0.236 value_stay*reward + -0.342 value_stay*harvest_duration + 0.671 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.039 1 + 1.0 value_exit[t] + 0.085 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 38, 0, 0, 0, 0, -\n",
      "value_exit: 84, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 431/1000 --- L(Train): 0.3730584 --- L(Val, RNN): 0.3473240 --- L(Val, SINDy): 0.4144312 --- Time: 0.92s; --- Convergence: 7.09e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 31/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.414 1 + 0.456 value_stay[t] + 0.199 reward + 0.014 value_stay^2 + 0.236 value_stay*reward + -0.343 value_stay*harvest_duration + 0.67 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.039 1 + 1.0 value_exit[t] + 0.085 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 39, 0, 0, 0, 0, -\n",
      "value_exit: 85, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 432/1000 --- L(Train): 0.3748904 --- L(Val, RNN): 0.3472565 --- L(Val, SINDy): 0.4136215 --- Time: 1.12s; --- Convergence: 6.92e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 32/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.415 1 + 0.455 value_stay[t] + 0.198 reward + 0.013 value_stay^2 + 0.237 value_stay*reward + -0.343 value_stay*harvest_duration + 0.669 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.039 1 + 1.0 value_exit[t] + 0.086 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 40, 0, 0, 0, 0, -\n",
      "value_exit: 86, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 433/1000 --- L(Train): 0.3776133 --- L(Val, RNN): 0.3472238 --- L(Val, SINDy): 0.4130865 --- Time: 1.01s; --- Convergence: 5.10e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 33/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.415 1 + 0.455 value_stay[t] + 0.198 reward + 0.012 value_stay^2 + 0.238 value_stay*reward + -0.342 value_stay*harvest_duration + 0.669 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.04 1 + 1.0 value_exit[t] + 0.086 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 41, 0, 0, 0, 0, -\n",
      "value_exit: 87, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 434/1000 --- L(Train): 0.3719390 --- L(Val, RNN): 0.3471946 --- L(Val, SINDy): 0.4121572 --- Time: 0.95s; --- Convergence: 4.01e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 34/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.416 1 + 0.455 value_stay[t] + 0.198 reward + 0.012 value_stay^2 + 0.239 value_stay*reward + -0.342 value_stay*harvest_duration + 0.668 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.04 1 + 1.0 value_exit[t] + 0.087 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 42, 0, 0, 0, 0, -\n",
      "value_exit: 88, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 435/1000 --- L(Train): 0.3706002 --- L(Val, RNN): 0.3471297 --- L(Val, SINDy): 0.4115404 --- Time: 0.97s; --- Convergence: 5.25e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 35/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.416 1 + 0.455 value_stay[t] + 0.198 reward + 0.011 value_stay^2 + 0.239 value_stay*reward + -0.342 value_stay*harvest_duration + 0.667 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.04 1 + 1.0 value_exit[t] + 0.087 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 43, 0, 0, 0, 0, -\n",
      "value_exit: 89, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 436/1000 --- L(Train): 0.3758097 --- L(Val, RNN): 0.3470839 --- L(Val, SINDy): 0.4106090 --- Time: 1.14s; --- Convergence: 4.91e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 36/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.417 1 + 0.456 value_stay[t] + 0.198 reward + 0.011 value_stay^2 + 0.24 value_stay*reward + -0.341 value_stay*harvest_duration + 0.667 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.04 1 + 1.0 value_exit[t] + 0.087 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 44, 0, 0, 0, 0, -\n",
      "value_exit: 90, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 437/1000 --- L(Train): 0.3773444 --- L(Val, RNN): 0.3470285 --- L(Val, SINDy): 0.4102717 --- Time: 1.33s; --- Convergence: 5.23e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 37/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.418 1 + 0.456 value_stay[t] + 0.198 reward + 0.01 value_stay^2 + 0.24 value_stay*reward + -0.341 value_stay*harvest_duration + 0.666 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.041 1 + 1.0 value_exit[t] + 0.088 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 45, 0, 0, 0, 0, -\n",
      "value_exit: 91, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 438/1000 --- L(Train): 0.3740463 --- L(Val, RNN): 0.3469730 --- L(Val, SINDy): 0.4099302 --- Time: 0.92s; --- Convergence: 5.39e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 38/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.42 1 + 0.456 value_stay[t] + 0.198 reward + 0.01 value_stay^2 + 0.242 value_stay*reward + -0.34 value_stay*harvest_duration + 0.666 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.041 1 + 1.0 value_exit[t] + 0.088 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 46, 0, 0, 0, 0, -\n",
      "value_exit: 92, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 439/1000 --- L(Train): 0.3798763 --- L(Val, RNN): 0.3469125 --- L(Val, SINDy): 0.4101532 --- Time: 0.86s; --- Convergence: 5.72e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 39/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.421 1 + 0.457 value_stay[t] + 0.199 reward + 0.011 value_stay^2 + 0.243 value_stay*reward + -0.339 value_stay*harvest_duration + 0.667 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = -0.041 1 + 1.0 value_exit[t] + 0.089 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 47, 0, 0, 0, 0, -\n",
      "value_exit: 93, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 440/1000 --- L(Train): 0.3744872 --- L(Val, RNN): 0.3468626 --- L(Val, SINDy): 0.4101725 --- Time: 1.08s; --- Convergence: 5.36e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 40/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.423 1 + 0.458 value_stay[t] + 0.2 reward + 0.011 value_stay^2 + 0.245 value_stay*reward + -0.338 value_stay*harvest_duration + 0.667 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = -0.041 1 + 1.0 value_exit[t] + 0.089 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 48, 0, 0, 0, 0, -\n",
      "value_exit: 94, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 441/1000 --- L(Train): 0.3768109 --- L(Val, RNN): 0.3468042 --- L(Val, SINDy): 0.4102109 --- Time: 0.90s; --- Convergence: 5.60e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 41/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.424 1 + 0.459 value_stay[t] + 0.2 reward + 0.011 value_stay^2 + 0.245 value_stay*reward + -0.338 value_stay*harvest_duration + 0.666 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = -0.041 1 + 1.0 value_exit[t] + 0.089 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 49, 0, 0, 0, 0, -\n",
      "value_exit: 95, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 442/1000 --- L(Train): 0.3769868 --- L(Val, RNN): 0.3467458 --- L(Val, SINDy): 0.4104244 --- Time: 0.87s; --- Convergence: 5.72e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 42/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.425 1 + 0.458 value_stay[t] + 0.199 reward + 0.01 value_stay^2 + 0.245 value_stay*reward + -0.338 value_stay*harvest_duration + 0.665 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = -0.041 1 + 1.0 value_exit[t] + 0.09 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 50, 0, 0, 0, 0, -\n",
      "value_exit: 96, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 443/1000 --- L(Train): 0.3713870 --- L(Val, RNN): 0.3467261 --- L(Val, SINDy): 0.4104598 --- Time: 0.95s; --- Convergence: 3.85e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 43/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.426 1 + 0.458 value_stay[t] + 0.199 reward + 0.009 value_stay^2 + 0.245 value_stay*reward + -0.339 value_stay*harvest_duration + 0.664 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.042 1 + 1.0 value_exit[t] + 0.09 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 51, 0, 0, 0, 0, -\n",
      "value_exit: 97, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 444/1000 --- L(Train): 0.3732224 --- L(Val, RNN): 0.3466872 --- L(Val, SINDy): 0.4107773 --- Time: 1.02s; --- Convergence: 3.87e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 44/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.427 1 + 0.458 value_stay[t] + 0.198 reward + 0.008 value_stay^2 + 0.245 value_stay*reward + -0.339 value_stay*harvest_duration + 0.663 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = -0.042 1 + 1.0 value_exit[t] + 0.09 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 52, 0, 0, 0, 0, -\n",
      "value_exit: 98, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 445/1000 --- L(Train): 0.3741748 --- L(Val, RNN): 0.3466274 --- L(Val, SINDy): 0.4110738 --- Time: 0.93s; --- Convergence: 4.92e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 45/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.428 1 + 0.458 value_stay[t] + 0.198 reward + 0.008 value_stay^2 + 0.245 value_stay*reward + -0.339 value_stay*harvest_duration + 0.663 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = -0.042 1 + 1.0 value_exit[t] + 0.091 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 53, 0, 0, 0, 0, -\n",
      "value_exit: 99, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 446/1000 --- L(Train): 0.3735318 --- L(Val, RNN): 0.3465526 --- L(Val, SINDy): 0.4113401 --- Time: 1.45s; --- Convergence: 6.20e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 46/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.429 1 + 0.458 value_stay[t] + 0.198 reward + 0.008 value_stay^2 + 0.244 value_stay*reward + -0.339 value_stay*harvest_duration + 0.662 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.091 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 54, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 447/1000 --- L(Train): 0.3735065 --- L(Val, RNN): 0.3464987 --- L(Val, SINDy): 0.4119343 --- Time: 1.01s; --- Convergence: 5.80e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 47/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.429 1 + 0.458 value_stay[t] + 0.197 reward + 0.007 value_stay^2 + 0.244 value_stay*reward + -0.339 value_stay*harvest_duration + 0.661 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.091 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 55, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 448/1000 --- L(Train): 0.3695376 --- L(Val, RNN): 0.3464519 --- L(Val, SINDy): 0.4121370 --- Time: 1.00s; --- Convergence: 5.24e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 48/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.43 1 + 0.458 value_stay[t] + 0.197 reward + 0.006 value_stay^2 + 0.245 value_stay*reward + -0.338 value_stay*harvest_duration + 0.661 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.091 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 56, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 449/1000 --- L(Train): 0.3709962 --- L(Val, RNN): 0.3464325 --- L(Val, SINDy): 0.4122249 --- Time: 0.92s; --- Convergence: 3.59e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 49/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.432 1 + 0.459 value_stay[t] + 0.198 reward + 0.007 value_stay^2 + 0.246 value_stay*reward + -0.337 value_stay*harvest_duration + 0.661 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.09 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 57, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 450/1000 --- L(Train): 0.3655441 --- L(Val, RNN): 0.3463890 --- L(Val, SINDy): 0.4122800 --- Time: 0.93s; --- Convergence: 3.97e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 50/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.434 1 + 0.461 value_stay[t] + 0.199 reward + 0.008 value_stay^2 + 0.248 value_stay*reward + -0.336 value_stay*harvest_duration + 0.662 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.089 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 58, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 451/1000 --- L(Train): 0.3739131 --- L(Val, RNN): 0.3463371 --- L(Val, SINDy): 0.4122140 --- Time: 0.88s; --- Convergence: 4.58e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 51/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.436 1 + 0.462 value_stay[t] + 0.2 reward + 0.009 value_stay^2 + 0.25 value_stay*reward + -0.334 value_stay*harvest_duration + 0.663 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.088 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 59, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 452/1000 --- L(Train): 0.3746315 --- L(Val, RNN): 0.3462571 --- L(Val, SINDy): 0.4120743 --- Time: 0.86s; --- Convergence: 6.29e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 52/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.437 1 + 0.462 value_stay[t] + 0.2 reward + 0.008 value_stay^2 + 0.25 value_stay*reward + -0.334 value_stay*harvest_duration + 0.663 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.086 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 60, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 453/1000 --- L(Train): 0.3678398 --- L(Val, RNN): 0.3461992 --- L(Val, SINDy): 0.4118743 --- Time: 1.08s; --- Convergence: 6.04e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 53/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.436 1 + 0.46 value_stay[t] + 0.199 reward + 0.006 value_stay^2 + 0.249 value_stay*reward + -0.335 value_stay*harvest_duration + 0.661 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.085 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 61, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 454/1000 --- L(Train): 0.3705787 --- L(Val, RNN): 0.3462073 --- L(Val, SINDy): 0.4114251 --- Time: 0.92s; --- Convergence: 3.42e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 54/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.436 1 + 0.458 value_stay[t] + 0.197 reward + 0.003 value_stay^2 + 0.247 value_stay*reward + -0.337 value_stay*harvest_duration + 0.659 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.083 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 62, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 455/1000 --- L(Train): 0.3716637 --- L(Val, RNN): 0.3461912 --- L(Val, SINDy): 0.4112168 --- Time: 1.17s; --- Convergence: 2.52e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 55/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.436 1 + 0.457 value_stay[t] + 0.196 reward + 0.001 value_stay^2 + 0.247 value_stay*reward + -0.337 value_stay*harvest_duration + 0.658 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.081 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 63, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 456/1000 --- L(Train): 0.3712626 --- L(Val, RNN): 0.3461170 --- L(Val, SINDy): 0.4110893 --- Time: 1.20s; --- Convergence: 4.97e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 56/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.437 1 + 0.457 value_stay[t] + 0.197 reward + 0.001 value_stay^2 + 0.247 value_stay*reward + -0.337 value_stay*harvest_duration + 0.657 reward^2 + 0.201 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.079 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 64, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 457/1000 --- L(Train): 0.3713816 --- L(Val, RNN): 0.3460170 --- L(Val, SINDy): 0.4110021 --- Time: 0.85s; --- Convergence: 7.48e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 57/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.439 1 + 0.459 value_stay[t] + 0.198 reward + 0.002 value_stay^2 + 0.249 value_stay*reward + -0.335 value_stay*harvest_duration + 0.658 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.077 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 65, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 458/1000 --- L(Train): 0.3679925 --- L(Val, RNN): 0.3459736 --- L(Val, SINDy): 0.4107817 --- Time: 1.14s; --- Convergence: 5.91e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 58/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.442 1 + 0.461 value_stay[t] + 0.2 reward + 0.005 value_stay^2 + 0.252 value_stay*reward + -0.332 value_stay*harvest_duration + 0.66 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.075 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 66, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 459/1000 --- L(Train): 0.3718669 --- L(Val, RNN): 0.3459518 --- L(Val, SINDy): 0.4103137 --- Time: 1.14s; --- Convergence: 4.05e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 59/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.444 1 + 0.462 value_stay[t] + 0.201 reward + 0.006 value_stay^2 + 0.254 value_stay*reward + -0.33 value_stay*harvest_duration + 0.661 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.073 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 67, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 460/1000 --- L(Train): 0.3742196 --- L(Val, RNN): 0.3459013 --- L(Val, SINDy): 0.4101378 --- Time: 0.89s; --- Convergence: 4.55e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 60/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.444 1 + 0.462 value_stay[t] + 0.201 reward + 0.005 value_stay^2 + 0.254 value_stay*reward + -0.33 value_stay*harvest_duration + 0.661 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.071 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 68, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 461/1000 --- L(Train): 0.3711054 --- L(Val, RNN): 0.3458448 --- L(Val, SINDy): 0.4098079 --- Time: 0.91s; --- Convergence: 5.10e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 61/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.444 1 + 0.461 value_stay[t] + 0.2 reward + 0.003 value_stay^2 + 0.253 value_stay*reward + -0.332 value_stay*harvest_duration + 0.66 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.068 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 69, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 462/1000 --- L(Train): 0.3689216 --- L(Val, RNN): 0.3457913 --- L(Val, SINDy): 0.4096112 --- Time: 1.01s; --- Convergence: 5.23e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 62/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.444 1 + 0.459 value_stay[t] + 0.199 reward + 0.001 value_stay^2 + 0.252 value_stay*reward + -0.333 value_stay*harvest_duration + 0.659 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.066 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 70, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 463/1000 --- L(Train): 0.3662840 --- L(Val, RNN): 0.3457596 --- L(Val, SINDy): 0.4090571 --- Time: 0.98s; --- Convergence: 4.20e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 63/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.445 1 + 0.459 value_stay[t] + 0.199 reward + 0.0 value_stay^2 + 0.253 value_stay*reward + -0.333 value_stay*harvest_duration + 0.658 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.064 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 71, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 464/1000 --- L(Train): 0.3730666 --- L(Val, RNN): 0.3457141 --- L(Val, SINDy): 0.4087892 --- Time: 0.96s; --- Convergence: 4.37e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 64/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.446 1 + 0.459 value_stay[t] + 0.2 reward + 0.0 value_stay^2 + 0.253 value_stay*reward + -0.332 value_stay*harvest_duration + 0.659 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.062 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 72, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 465/1000 --- L(Train): 0.3707382 --- L(Val, RNN): 0.3456525 --- L(Val, SINDy): 0.4084393 --- Time: 1.18s; --- Convergence: 5.27e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 65/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.448 1 + 0.46 value_stay[t] + 0.2 reward + 0.0 value_stay^2 + 0.255 value_stay*reward + -0.331 value_stay*harvest_duration + 0.659 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.059 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 73, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 466/1000 --- L(Train): 0.3750858 --- L(Val, RNN): 0.3456040 --- L(Val, SINDy): 0.4079603 --- Time: 2.18s; --- Convergence: 5.06e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 66/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.449 1 + 0.46 value_stay[t] + 0.201 reward + 0.0 value_stay^2 + 0.256 value_stay*reward + -0.331 value_stay*harvest_duration + 0.66 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.057 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 74, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 467/1000 --- L(Train): 0.3737274 --- L(Val, RNN): 0.3455559 --- L(Val, SINDy): 0.4073479 --- Time: 3.63s; --- Convergence: 4.93e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 67/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.45 1 + 0.46 value_stay[t] + 0.201 reward + -0.001 value_stay^2 + 0.256 value_stay*reward + -0.331 value_stay*harvest_duration + 0.66 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.054 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 75, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 468/1000 --- L(Train): 0.3654805 --- L(Val, RNN): 0.3455361 --- L(Val, SINDy): 0.4066587 --- Time: 4.42s; --- Convergence: 3.46e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 68/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.451 1 + 0.459 value_stay[t] + 0.202 reward + -0.002 value_stay^2 + 0.257 value_stay*reward + -0.331 value_stay*harvest_duration + 0.66 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.052 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 76, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 0, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 469/1000 --- L(Train): 0.3705725 --- L(Val, RNN): 0.3454995 --- L(Val, SINDy): 0.4059586 --- Time: 3.83s; --- Convergence: 3.56e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 69/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.452 1 + 0.459 value_stay[t] + 0.202 reward + -0.002 value_stay^2 + 0.258 value_stay*reward + -0.331 value_stay*harvest_duration + 0.66 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.05 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 77, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 1, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 470/1000 --- L(Train): 0.3657854 --- L(Val, RNN): 0.3454361 --- L(Val, SINDy): 0.4051760 --- Time: 3.93s; --- Convergence: 4.95e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 70/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.452 1 + 0.459 value_stay[t] + 0.203 reward + -0.003 value_stay^2 + 0.259 value_stay*reward + -0.331 value_stay*harvest_duration + 0.66 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.047 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 78, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 2, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 471/1000 --- L(Train): 0.3681871 --- L(Val, RNN): 0.3453911 --- L(Val, SINDy): 0.4043032 --- Time: 3.93s; --- Convergence: 4.72e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 71/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.453 1 + 0.458 value_stay[t] + 0.203 reward + -0.005 value_stay^2 + 0.259 value_stay*reward + -0.331 value_stay*harvest_duration + 0.66 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.045 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 79, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 3, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 472/1000 --- L(Train): 0.3692430 --- L(Val, RNN): 0.3453498 --- L(Val, SINDy): 0.4033465 --- Time: 2.96s; --- Convergence: 4.43e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 72/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.453 1 + 0.457 value_stay[t] + 0.202 reward + -0.006 value_stay^2 + 0.259 value_stay*reward + -0.332 value_stay*harvest_duration + 0.66 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.043 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 80, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 4, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 473/1000 --- L(Train): 0.3734902 --- L(Val, RNN): 0.3453241 --- L(Val, SINDy): 0.4025129 --- Time: 4.54s; --- Convergence: 3.50e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 73/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.454 1 + 0.457 value_stay[t] + 0.202 reward + -0.007 value_stay^2 + 0.259 value_stay*reward + -0.333 value_stay*harvest_duration + 0.659 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.041 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 81, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 5, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 474/1000 --- L(Train): 0.3730217 --- L(Val, RNN): 0.3452972 --- L(Val, SINDy): 0.4016408 --- Time: 3.14s; --- Convergence: 3.10e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 74/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.455 1 + 0.457 value_stay[t] + 0.202 reward + -0.007 value_stay^2 + 0.26 value_stay*reward + -0.332 value_stay*harvest_duration + 0.659 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.039 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 82, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 6, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 475/1000 --- L(Train): 0.3726875 --- L(Val, RNN): 0.3452435 --- L(Val, SINDy): 0.4008093 --- Time: 3.91s; --- Convergence: 4.23e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 75/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.457 1 + 0.458 value_stay[t] + 0.202 reward + -0.007 value_stay^2 + 0.261 value_stay*reward + -0.331 value_stay*harvest_duration + 0.659 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.037 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 83, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 7, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 476/1000 --- L(Train): 0.3737390 --- L(Val, RNN): 0.3451929 --- L(Val, SINDy): 0.3998232 --- Time: 4.82s; --- Convergence: 4.64e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 76/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.458 1 + 0.458 value_stay[t] + 0.203 reward + -0.007 value_stay^2 + 0.262 value_stay*reward + -0.331 value_stay*harvest_duration + 0.659 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.035 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 84, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 8, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 477/1000 --- L(Train): 0.3669684 --- L(Val, RNN): 0.3451518 --- L(Val, SINDy): 0.3987162 --- Time: 1.92s; --- Convergence: 4.38e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 77/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.459 1 + 0.459 value_stay[t] + 0.203 reward + -0.007 value_stay^2 + 0.262 value_stay*reward + -0.331 value_stay*harvest_duration + 0.659 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.033 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 85, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 9, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 478/1000 --- L(Train): 0.3701122 --- L(Val, RNN): 0.3450897 --- L(Val, SINDy): 0.3974814 --- Time: 1.85s; --- Convergence: 5.30e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 78/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.46 1 + 0.459 value_stay[t] + 0.203 reward + -0.006 value_stay^2 + 0.263 value_stay*reward + -0.331 value_stay*harvest_duration + 0.659 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.032 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 86, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 10, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 479/1000 --- L(Train): 0.3705098 --- L(Val, RNN): 0.3450239 --- L(Val, SINDy): 0.3902108 --- Time: 1.92s; --- Convergence: 5.94e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 79/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.461 1 + 0.46 value_stay[t] + 0.203 reward + -0.006 value_stay^2 + 0.264 value_stay*reward + -0.331 value_stay*harvest_duration + 0.658 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.03 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 87, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 11, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 480/1000 --- L(Train): 0.3678575 --- L(Val, RNN): 0.3449965 --- L(Val, SINDy): 0.3899887 --- Time: 1.51s; --- Convergence: 4.34e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 80/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.462 1 + 0.46 value_stay[t] + 0.203 reward + -0.006 value_stay^2 + 0.264 value_stay*reward + -0.331 value_stay*harvest_duration + 0.658 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.028 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 88, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 12, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 481/1000 --- L(Train): 0.3726833 --- L(Val, RNN): 0.3449732 --- L(Val, SINDy): 0.3896952 --- Time: 1.38s; --- Convergence: 3.33e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 81/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.463 1 + 0.461 value_stay[t] + 0.203 reward + -0.006 value_stay^2 + 0.265 value_stay*reward + -0.33 value_stay*harvest_duration + 0.658 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.027 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 89, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 13, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 482/1000 --- L(Train): 0.3689084 --- L(Val, RNN): 0.3449326 --- L(Val, SINDy): 0.3895976 --- Time: 1.09s; --- Convergence: 3.70e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 82/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.464 1 + 0.461 value_stay[t] + 0.202 reward + -0.006 value_stay^2 + 0.265 value_stay*reward + -0.331 value_stay*harvest_duration + 0.657 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.026 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 90, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 14, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 483/1000 --- L(Train): 0.3714116 --- L(Val, RNN): 0.3448871 --- L(Val, SINDy): 0.3893574 --- Time: 0.85s; --- Convergence: 4.12e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 83/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.465 1 + 0.46 value_stay[t] + 0.202 reward + -0.007 value_stay^2 + 0.264 value_stay*reward + -0.331 value_stay*harvest_duration + 0.656 reward^2 + 0.206 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.024 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 91, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 15, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 484/1000 --- L(Train): 0.3697670 --- L(Val, RNN): 0.3448431 --- L(Val, SINDy): 0.3892559 --- Time: 1.06s; --- Convergence: 4.26e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 84/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.465 1 + 0.46 value_stay[t] + 0.201 reward + -0.008 value_stay^2 + 0.264 value_stay*reward + -0.332 value_stay*harvest_duration + 0.655 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.023 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 92, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 16, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 485/1000 --- L(Train): 0.3691989 --- L(Val, RNN): 0.3448027 --- L(Val, SINDy): 0.3893646 --- Time: 0.88s; --- Convergence: 4.15e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 85/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.466 1 + 0.46 value_stay[t] + 0.2 reward + -0.009 value_stay^2 + 0.263 value_stay*reward + -0.332 value_stay*harvest_duration + 0.654 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.022 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 93, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 17, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 486/1000 --- L(Train): 0.3722007 --- L(Val, RNN): 0.3448082 --- L(Val, SINDy): 0.3890905 --- Time: 1.00s; --- Convergence: 2.35e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 86/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.467 1 + 0.46 value_stay[t] + 0.2 reward + -0.009 value_stay^2 + 0.264 value_stay*reward + -0.332 value_stay*harvest_duration + 0.654 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.021 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 94, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 18, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 487/1000 --- L(Train): 0.3701658 --- L(Val, RNN): 0.3447977 --- L(Val, SINDy): 0.3887752 --- Time: 1.04s; --- Convergence: 1.70e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 87/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.468 1 + 0.461 value_stay[t] + 0.2 reward + -0.008 value_stay^2 + 0.265 value_stay*reward + -0.331 value_stay*harvest_duration + 0.654 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.02 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 95, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 19, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 488/1000 --- L(Train): 0.3726661 --- L(Val, RNN): 0.3447084 --- L(Val, SINDy): 0.3885655 --- Time: 0.83s; --- Convergence: 5.32e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 88/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.469 1 + 0.462 value_stay[t] + 0.2 reward + -0.007 value_stay^2 + 0.265 value_stay*reward + -0.329 value_stay*harvest_duration + 0.653 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.019 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 96, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 20, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 489/1000 --- L(Train): 0.3666119 --- L(Val, RNN): 0.3446021 --- L(Val, SINDy): 0.3884603 --- Time: 0.89s; --- Convergence: 7.97e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 89/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.47 1 + 0.463 value_stay[t] + 0.2 reward + -0.006 value_stay^2 + 0.266 value_stay*reward + -0.328 value_stay*harvest_duration + 0.653 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.018 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 97, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 21, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 490/1000 --- L(Train): 0.3691347 --- L(Val, RNN): 0.3445840 --- L(Val, SINDy): 0.3881683 --- Time: 0.99s; --- Convergence: 4.89e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 90/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.471 1 + 0.463 value_stay[t] + 0.2 reward + -0.006 value_stay^2 + 0.266 value_stay*reward + -0.328 value_stay*harvest_duration + 0.653 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.017 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 98, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 22, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 491/1000 --- L(Train): 0.3701485 --- L(Val, RNN): 0.3446094 --- L(Val, SINDy): 0.3878242 --- Time: 0.89s; --- Convergence: 3.71e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 91/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.471 1 + 0.463 value_stay[t] + 0.199 reward + -0.006 value_stay^2 + 0.267 value_stay*reward + -0.327 value_stay*harvest_duration + 0.652 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.016 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, 99, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 23, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 492/1000 --- L(Train): 0.3743506 --- L(Val, RNN): 0.3445883 --- L(Val, SINDy): 0.3876110 --- Time: 1.05s; --- Convergence: 2.91e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 92/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.472 1 + 0.462 value_stay[t] + 0.199 reward + 0.267 value_stay*reward + -0.327 value_stay*harvest_duration + 0.652 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.015 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 24, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 493/1000 --- L(Train): 0.3665832 --- L(Val, RNN): 0.3444941 --- L(Val, SINDy): 0.3875657 --- Time: 0.88s; --- Convergence: 6.17e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 93/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.472 1 + 0.462 value_stay[t] + 0.199 reward + 0.267 value_stay*reward + -0.327 value_stay*harvest_duration + 0.651 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.014 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 25, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 494/1000 --- L(Train): 0.3660432 --- L(Val, RNN): 0.3444289 --- L(Val, SINDy): 0.3874678 --- Time: 1.16s; --- Convergence: 6.34e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 94/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.472 1 + 0.461 value_stay[t] + 0.198 reward + 0.267 value_stay*reward + -0.327 value_stay*harvest_duration + 0.651 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.013 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 26, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 495/1000 --- L(Train): 0.3665302 --- L(Val, RNN): 0.3444220 --- L(Val, SINDy): 0.3872454 --- Time: 0.91s; --- Convergence: 3.52e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 95/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.472 1 + 0.461 value_stay[t] + 0.198 reward + 0.267 value_stay*reward + -0.327 value_stay*harvest_duration + 0.65 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.013 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 27, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 496/1000 --- L(Train): 0.3711646 --- L(Val, RNN): 0.3444180 --- L(Val, SINDy): 0.3870362 --- Time: 0.85s; --- Convergence: 1.95e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 96/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.473 1 + 0.46 value_stay[t] + 0.198 reward + 0.267 value_stay*reward + -0.327 value_stay*harvest_duration + 0.65 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.012 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 28, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 497/1000 --- L(Train): 0.3633914 --- L(Val, RNN): 0.3443672 --- L(Val, SINDy): 0.3869735 --- Time: 0.85s; --- Convergence: 3.52e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 97/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.473 1 + 0.459 value_stay[t] + 0.197 reward + 0.266 value_stay*reward + -0.327 value_stay*harvest_duration + 0.649 reward^2 + 0.202 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.011 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 29, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 498/1000 --- L(Train): 0.3652858 --- L(Val, RNN): 0.3442998 --- L(Val, SINDy): 0.3869306 --- Time: 0.99s; --- Convergence: 5.13e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 98/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.474 1 + 0.46 value_stay[t] + 0.199 reward + 0.268 value_stay*reward + -0.325 value_stay*harvest_duration + 0.65 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.011 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 30, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 499/1000 --- L(Train): 0.3694041 --- L(Val, RNN): 0.3442630 --- L(Val, SINDy): 0.3867461 --- Time: 1.01s; --- Convergence: 4.41e-05; LR: 2.50e-03; Metric: 0.3324696; Bad epochs: 99/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.477 1 + 0.462 value_stay[t] + 0.201 reward + 0.271 value_stay*reward + -0.322 value_stay*harvest_duration + 0.653 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.01 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 31, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 500/1000 --- L(Train): 0.3692845 --- L(Val, RNN): 0.3442353 --- L(Val, SINDy): 0.3866070 --- Time: 1.10s; --- Convergence: 3.58e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.479 1 + 0.464 value_stay[t] + 0.203 reward + 0.273 value_stay*reward + -0.32 value_stay*harvest_duration + 0.654 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.009 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 32, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 501/1000 --- L(Train): 0.3647441 --- L(Val, RNN): 0.3441973 --- L(Val, SINDy): 0.3864539 --- Time: 0.92s; --- Convergence: 3.69e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 1/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.481 1 + 0.465 value_stay[t] + 0.204 reward + 0.274 value_stay*reward + -0.319 value_stay*harvest_duration + 0.655 reward^2 + 0.208 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.009 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 33, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 502/1000 --- L(Train): 0.3705634 --- L(Val, RNN): 0.3441466 --- L(Val, SINDy): 0.3869449 --- Time: 0.92s; --- Convergence: 4.38e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 2/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.482 1 + 0.464 value_stay[t] + 0.204 reward + 0.274 value_stay*reward + -0.319 value_stay*harvest_duration + 0.655 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.008 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 34, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 503/1000 --- L(Train): 0.3646459 --- L(Val, RNN): 0.3441068 --- L(Val, SINDy): 0.3867967 --- Time: 0.85s; --- Convergence: 4.18e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 3/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.48 1 + 0.461 value_stay[t] + 0.202 reward + 0.271 value_stay*reward + -0.322 value_stay*harvest_duration + 0.653 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.008 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 35, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 504/1000 --- L(Train): 0.3636296 --- L(Val, RNN): 0.3440905 --- L(Val, SINDy): 0.3864077 --- Time: 0.78s; --- Convergence: 2.91e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 4/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.478 1 + 0.457 value_stay[t] + 0.2 reward + 0.268 value_stay*reward + -0.326 value_stay*harvest_duration + 0.65 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.007 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 36, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 505/1000 --- L(Train): 0.3610073 --- L(Val, RNN): 0.3440702 --- L(Val, SINDy): 0.3860923 --- Time: 0.88s; --- Convergence: 2.47e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 5/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.477 1 + 0.454 value_stay[t] + 0.199 reward + 0.266 value_stay*reward + -0.328 value_stay*harvest_duration + 0.649 reward^2 + 0.203 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.007 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 37, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 506/1000 --- L(Train): 0.3718454 --- L(Val, RNN): 0.3440401 --- L(Val, SINDy): 0.3859821 --- Time: 1.01s; --- Convergence: 2.74e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 6/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.479 1 + 0.455 value_stay[t] + 0.2 reward + 0.267 value_stay*reward + -0.328 value_stay*harvest_duration + 0.65 reward^2 + 0.204 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.007 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 38, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 507/1000 --- L(Train): 0.3618016 --- L(Val, RNN): 0.3439894 --- L(Val, SINDy): 0.3860320 --- Time: 0.92s; --- Convergence: 3.90e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 7/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.48 1 + 0.456 value_stay[t] + 0.201 reward + 0.268 value_stay*reward + -0.327 value_stay*harvest_duration + 0.651 reward^2 + 0.205 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.006 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 39, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 508/1000 --- L(Train): 0.3642789 --- L(Val, RNN): 0.3439571 --- L(Val, SINDy): 0.3861868 --- Time: 0.99s; --- Convergence: 3.57e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 8/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.482 1 + 0.456 value_stay[t] + 0.203 reward + 0.269 value_stay*reward + -0.326 value_stay*harvest_duration + 0.652 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.006 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 40, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 509/1000 --- L(Train): 0.3629949 --- L(Val, RNN): 0.3439481 --- L(Val, SINDy): 0.3861590 --- Time: 0.77s; --- Convergence: 2.24e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 9/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.483 1 + 0.457 value_stay[t] + 0.204 reward + 0.271 value_stay*reward + -0.325 value_stay*harvest_duration + 0.653 reward^2 + 0.208 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.005 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 41, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 510/1000 --- L(Train): 0.3639279 --- L(Val, RNN): 0.3439304 --- L(Val, SINDy): 0.3861838 --- Time: 0.83s; --- Convergence: 2.00e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 10/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.485 1 + 0.457 value_stay[t] + 0.205 reward + 0.272 value_stay*reward + -0.325 value_stay*harvest_duration + 0.653 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.005 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 42, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 511/1000 --- L(Train): 0.3659389 --- L(Val, RNN): 0.3438947 --- L(Val, SINDy): 0.3862823 --- Time: 0.87s; --- Convergence: 2.78e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 11/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.486 1 + 0.457 value_stay[t] + 0.205 reward + 0.272 value_stay*reward + -0.324 value_stay*harvest_duration + 0.654 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.005 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 43, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 512/1000 --- L(Train): 0.3694316 --- L(Val, RNN): 0.3438468 --- L(Val, SINDy): 0.3865724 --- Time: 0.85s; --- Convergence: 3.79e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 12/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.486 1 + 0.457 value_stay[t] + 0.205 reward + 0.272 value_stay*reward + -0.324 value_stay*harvest_duration + 0.654 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.005 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 44, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 513/1000 --- L(Train): 0.3613293 --- L(Val, RNN): 0.3438208 --- L(Val, SINDy): 0.3865302 --- Time: 1.18s; --- Convergence: 3.19e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 13/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.487 1 + 0.456 value_stay[t] + 0.205 reward + 0.271 value_stay*reward + -0.325 value_stay*harvest_duration + 0.653 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.004 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 45, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 514/1000 --- L(Train): 0.3642024 --- L(Val, RNN): 0.3438081 --- L(Val, SINDy): 0.3864008 --- Time: 0.94s; --- Convergence: 2.24e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 14/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.487 1 + 0.455 value_stay[t] + 0.205 reward + 0.271 value_stay*reward + -0.325 value_stay*harvest_duration + 0.653 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.004 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 46, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 515/1000 --- L(Train): 0.3647425 --- L(Val, RNN): 0.3437966 --- L(Val, SINDy): 0.3863511 --- Time: 0.99s; --- Convergence: 1.69e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 15/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.487 1 + 0.454 value_stay[t] + 0.204 reward + 0.27 value_stay*reward + -0.326 value_stay*harvest_duration + 0.652 reward^2 + 0.208 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.004 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 47, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 516/1000 --- L(Train): 0.3695446 --- L(Val, RNN): 0.3437771 --- L(Val, SINDy): 0.3863072 --- Time: 1.26s; --- Convergence: 1.82e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 16/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.487 1 + 0.454 value_stay[t] + 0.204 reward + 0.269 value_stay*reward + -0.327 value_stay*harvest_duration + 0.651 reward^2 + 0.208 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.004 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 48, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 517/1000 --- L(Train): 0.3653282 --- L(Val, RNN): 0.3437473 --- L(Val, SINDy): 0.3862334 --- Time: 1.70s; --- Convergence: 2.40e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 17/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.489 1 + 0.454 value_stay[t] + 0.205 reward + 0.27 value_stay*reward + -0.326 value_stay*harvest_duration + 0.652 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.003 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 49, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 518/1000 --- L(Train): 0.3693472 --- L(Val, RNN): 0.3437114 --- L(Val, SINDy): 0.3861579 --- Time: 1.15s; --- Convergence: 2.99e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 18/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.491 1 + 0.456 value_stay[t] + 0.206 reward + 0.272 value_stay*reward + -0.324 value_stay*harvest_duration + 0.653 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.003 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 50, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 519/1000 --- L(Train): 0.3669060 --- L(Val, RNN): 0.3436812 --- L(Val, SINDy): 0.3857056 --- Time: 0.91s; --- Convergence: 3.01e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 19/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.493 1 + 0.458 value_stay[t] + 0.207 reward + 0.274 value_stay*reward + -0.322 value_stay*harvest_duration + 0.654 reward^2 + 0.211 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.003 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 51, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 520/1000 --- L(Train): 0.3634162 --- L(Val, RNN): 0.3436606 --- L(Val, SINDy): 0.3854290 --- Time: 1.11s; --- Convergence: 2.53e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 20/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.495 1 + 0.459 value_stay[t] + 0.208 reward + 0.275 value_stay*reward + -0.321 value_stay*harvest_duration + 0.654 reward^2 + 0.212 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.003 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 52, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 521/1000 --- L(Train): 0.3652404 --- L(Val, RNN): 0.3436430 --- L(Val, SINDy): 0.3852577 --- Time: 0.99s; --- Convergence: 2.15e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 21/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.495 1 + 0.458 value_stay[t] + 0.208 reward + 0.274 value_stay*reward + -0.321 value_stay*harvest_duration + 0.653 reward^2 + 0.212 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.003 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 53, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 522/1000 --- L(Train): 0.3649713 --- L(Val, RNN): 0.3436220 --- L(Val, SINDy): 0.3852593 --- Time: 0.95s; --- Convergence: 2.12e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 22/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.495 1 + 0.456 value_stay[t] + 0.206 reward + 0.272 value_stay*reward + -0.323 value_stay*harvest_duration + 0.651 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 54, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 523/1000 --- L(Train): 0.3637085 --- L(Val, RNN): 0.3436047 --- L(Val, SINDy): 0.3852507 --- Time: 1.17s; --- Convergence: 1.93e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 23/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.494 1 + 0.455 value_stay[t] + 0.205 reward + 0.27 value_stay*reward + -0.325 value_stay*harvest_duration + 0.65 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 55, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 524/1000 --- L(Train): 0.3690872 --- L(Val, RNN): 0.3435935 --- L(Val, SINDy): 0.3852004 --- Time: 0.83s; --- Convergence: 1.52e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 24/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.494 1 + 0.453 value_stay[t] + 0.203 reward + 0.269 value_stay*reward + -0.326 value_stay*harvest_duration + 0.648 reward^2 + 0.208 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 56, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 525/1000 --- L(Train): 0.3629631 --- L(Val, RNN): 0.3435710 --- L(Val, SINDy): 0.3851233 --- Time: 0.81s; --- Convergence: 1.89e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 25/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.494 1 + 0.452 value_stay[t] + 0.203 reward + 0.268 value_stay*reward + -0.327 value_stay*harvest_duration + 0.647 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 57, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 526/1000 --- L(Train): 0.3687652 --- L(Val, RNN): 0.3435443 --- L(Val, SINDy): 0.3850049 --- Time: 1.14s; --- Convergence: 2.28e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 26/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.496 1 + 0.453 value_stay[t] + 0.203 reward + 0.269 value_stay*reward + -0.326 value_stay*harvest_duration + 0.647 reward^2 + 0.208 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 58, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 527/1000 --- L(Train): 0.3659714 --- L(Val, RNN): 0.3435265 --- L(Val, SINDy): 0.3849169 --- Time: 1.15s; --- Convergence: 2.03e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 27/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.498 1 + 0.455 value_stay[t] + 0.205 reward + 0.271 value_stay*reward + -0.324 value_stay*harvest_duration + 0.648 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 59, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 528/1000 --- L(Train): 0.3661322 --- L(Val, RNN): 0.3435068 --- L(Val, SINDy): 0.3848862 --- Time: 0.90s; --- Convergence: 2.00e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 28/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.5 1 + 0.457 value_stay[t] + 0.206 reward + 0.273 value_stay*reward + -0.322 value_stay*harvest_duration + 0.649 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 60, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 529/1000 --- L(Train): 0.3642037 --- L(Val, RNN): 0.3434909 --- L(Val, SINDy): 0.3848641 --- Time: 1.02s; --- Convergence: 1.79e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 29/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.501 1 + 0.458 value_stay[t] + 0.207 reward + 0.274 value_stay*reward + -0.321 value_stay*harvest_duration + 0.65 reward^2 + 0.211 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 61, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 530/1000 --- L(Train): 0.3683787 --- L(Val, RNN): 0.3434753 --- L(Val, SINDy): 0.3847640 --- Time: 1.19s; --- Convergence: 1.68e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 30/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.502 1 + 0.458 value_stay[t] + 0.208 reward + 0.275 value_stay*reward + -0.321 value_stay*harvest_duration + 0.65 reward^2 + 0.212 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 62, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 531/1000 --- L(Train): 0.3622389 --- L(Val, RNN): 0.3434475 --- L(Val, SINDy): 0.3846807 --- Time: 1.28s; --- Convergence: 2.23e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 31/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.503 1 + 0.458 value_stay[t] + 0.208 reward + 0.276 value_stay*reward + -0.32 value_stay*harvest_duration + 0.651 reward^2 + 0.212 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 63, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 532/1000 --- L(Train): 0.3625254 --- L(Val, RNN): 0.3434214 --- L(Val, SINDy): 0.3845554 --- Time: 1.12s; --- Convergence: 2.42e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 32/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.503 1 + 0.457 value_stay[t] + 0.208 reward + 0.276 value_stay*reward + -0.321 value_stay*harvest_duration + 0.65 reward^2 + 0.212 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 64, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 533/1000 --- L(Train): 0.3665890 --- L(Val, RNN): 0.3433937 --- L(Val, SINDy): 0.3844197 --- Time: 1.20s; --- Convergence: 2.60e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 33/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.502 1 + 0.456 value_stay[t] + 0.207 reward + 0.275 value_stay*reward + -0.322 value_stay*harvest_duration + 0.649 reward^2 + 0.211 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 65, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 534/1000 --- L(Train): 0.3659846 --- L(Val, RNN): 0.3433613 --- L(Val, SINDy): 0.3843498 --- Time: 1.25s; --- Convergence: 2.92e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 34/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.501 1 + 0.454 value_stay[t] + 0.206 reward + 0.273 value_stay*reward + -0.324 value_stay*harvest_duration + 0.647 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 66, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 535/1000 --- L(Train): 0.3679020 --- L(Val, RNN): 0.3433402 --- L(Val, SINDy): 0.3842421 --- Time: 1.36s; --- Convergence: 2.51e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 35/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.501 1 + 0.452 value_stay[t] + 0.205 reward + 0.272 value_stay*reward + -0.325 value_stay*harvest_duration + 0.646 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 67, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 536/1000 --- L(Train): 0.3651432 --- L(Val, RNN): 0.3433251 --- L(Val, SINDy): 0.3840971 --- Time: 1.59s; --- Convergence: 2.01e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 36/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.501 1 + 0.452 value_stay[t] + 0.205 reward + 0.273 value_stay*reward + -0.324 value_stay*harvest_duration + 0.645 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 68, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 537/1000 --- L(Train): 0.3637676 --- L(Val, RNN): 0.3432965 --- L(Val, SINDy): 0.3840265 --- Time: 1.12s; --- Convergence: 2.44e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 37/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.502 1 + 0.453 value_stay[t] + 0.205 reward + 0.274 value_stay*reward + -0.323 value_stay*harvest_duration + 0.646 reward^2 + 0.209 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 69, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 538/1000 --- L(Train): 0.3680082 --- L(Val, RNN): 0.3432626 --- L(Val, SINDy): 0.3839793 --- Time: 1.28s; --- Convergence: 2.91e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 38/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.504 1 + 0.455 value_stay[t] + 0.207 reward + 0.276 value_stay*reward + -0.32 value_stay*harvest_duration + 0.646 reward^2 + 0.211 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 70, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 539/1000 --- L(Train): 0.3681235 --- L(Val, RNN): 0.3432288 --- L(Val, SINDy): 0.3839189 --- Time: 1.42s; --- Convergence: 3.14e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 39/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.506 1 + 0.456 value_stay[t] + 0.207 reward + 0.277 value_stay*reward + -0.318 value_stay*harvest_duration + 0.647 reward^2 + 0.212 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 71, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 540/1000 --- L(Train): 0.3663154 --- L(Val, RNN): 0.3431999 --- L(Val, SINDy): 0.3838030 --- Time: 1.98s; --- Convergence: 3.02e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 40/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.507 1 + 0.457 value_stay[t] + 0.208 reward + 0.278 value_stay*reward + -0.317 value_stay*harvest_duration + 0.647 reward^2 + 0.212 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 72, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 541/1000 --- L(Train): 0.3654511 --- L(Val, RNN): 0.3431812 --- L(Val, SINDy): 0.3836257 --- Time: 2.58s; --- Convergence: 2.44e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 41/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.508 1 + 0.457 value_stay[t] + 0.208 reward + 0.278 value_stay*reward + -0.317 value_stay*harvest_duration + 0.646 reward^2 + 0.212 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 73, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 542/1000 --- L(Train): 0.3617485 --- L(Val, RNN): 0.3431684 --- L(Val, SINDy): 0.3834546 --- Time: 3.88s; --- Convergence: 1.86e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 42/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.507 1 + 0.456 value_stay[t] + 0.207 reward + 0.277 value_stay*reward + -0.317 value_stay*harvest_duration + 0.645 reward^2 + 0.211 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 74, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 543/1000 --- L(Train): 0.3657504 --- L(Val, RNN): 0.3431467 --- L(Val, SINDy): 0.3833325 --- Time: 4.12s; --- Convergence: 2.02e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 43/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.506 1 + 0.453 value_stay[t] + 0.206 reward + 0.276 value_stay*reward + -0.319 value_stay*harvest_duration + 0.644 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 75, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 544/1000 --- L(Train): 0.3663920 --- L(Val, RNN): 0.3431181 --- L(Val, SINDy): 0.3832791 --- Time: 2.55s; --- Convergence: 2.44e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 44/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.506 1 + 0.451 value_stay[t] + 0.205 reward + 0.275 value_stay*reward + -0.321 value_stay*harvest_duration + 0.643 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 76, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 545/1000 --- L(Train): 0.3630203 --- L(Val, RNN): 0.3430866 --- L(Val, SINDy): 0.3832024 --- Time: 2.45s; --- Convergence: 2.80e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 45/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.506 1 + 0.451 value_stay[t] + 0.205 reward + 0.275 value_stay*reward + -0.321 value_stay*harvest_duration + 0.642 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 77, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 546/1000 --- L(Train): 0.3658516 --- L(Val, RNN): 0.3430578 --- L(Val, SINDy): 0.3831146 --- Time: 2.43s; --- Convergence: 2.84e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 46/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.507 1 + 0.451 value_stay[t] + 0.206 reward + 0.276 value_stay*reward + -0.321 value_stay*harvest_duration + 0.642 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 78, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 547/1000 --- L(Train): 0.3640478 --- L(Val, RNN): 0.3430391 --- L(Val, SINDy): 0.3830053 --- Time: 2.30s; --- Convergence: 2.36e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 47/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.507 1 + 0.45 value_stay[t] + 0.206 reward + 0.276 value_stay*reward + -0.321 value_stay*harvest_duration + 0.642 reward^2 + 0.21 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 79, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 548/1000 --- L(Train): 0.3640516 --- L(Val, RNN): 0.3430222 --- L(Val, SINDy): 0.3829255 --- Time: 3.09s; --- Convergence: 2.02e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 48/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.509 1 + 0.451 value_stay[t] + 0.207 reward + 0.277 value_stay*reward + -0.32 value_stay*harvest_duration + 0.643 reward^2 + 0.211 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 80, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 549/1000 --- L(Train): 0.3586763 --- L(Val, RNN): 0.3430047 --- L(Val, SINDy): 0.3828850 --- Time: 2.86s; --- Convergence: 1.88e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 49/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.51 1 + 0.451 value_stay[t] + 0.208 reward + 0.278 value_stay*reward + -0.319 value_stay*harvest_duration + 0.643 reward^2 + 0.212 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 81, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 550/1000 --- L(Train): 0.3705635 --- L(Val, RNN): 0.3429877 --- L(Val, SINDy): 0.3828650 --- Time: 1.94s; --- Convergence: 1.79e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 50/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.511 1 + 0.452 value_stay[t] + 0.209 reward + 0.279 value_stay*reward + -0.318 value_stay*harvest_duration + 0.644 reward^2 + 0.213 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 82, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 551/1000 --- L(Train): 0.3663258 --- L(Val, RNN): 0.3429645 --- L(Val, SINDy): 0.3828220 --- Time: 1.66s; --- Convergence: 2.06e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 51/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.511 1 + 0.451 value_stay[t] + 0.209 reward + 0.28 value_stay*reward + -0.319 value_stay*harvest_duration + 0.643 reward^2 + 0.213 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 83, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 552/1000 --- L(Train): 0.3666076 --- L(Val, RNN): 0.3429381 --- L(Val, SINDy): 0.3827398 --- Time: 2.88s; --- Convergence: 2.35e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 52/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.512 1 + 0.45 value_stay[t] + 0.209 reward + 0.279 value_stay*reward + -0.319 value_stay*harvest_duration + 0.643 reward^2 + 0.213 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 84, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 553/1000 --- L(Train): 0.3660104 --- L(Val, RNN): 0.3429167 --- L(Val, SINDy): 0.3826372 --- Time: 4.12s; --- Convergence: 2.24e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 53/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.512 1 + 0.449 value_stay[t] + 0.209 reward + 0.279 value_stay*reward + -0.32 value_stay*harvest_duration + 0.643 reward^2 + 0.213 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 85, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 554/1000 --- L(Train): 0.3609335 --- L(Val, RNN): 0.3429018 --- L(Val, SINDy): 0.3824848 --- Time: 5.14s; --- Convergence: 1.87e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 54/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.512 1 + 0.448 value_stay[t] + 0.209 reward + 0.279 value_stay*reward + -0.321 value_stay*harvest_duration + 0.642 reward^2 + 0.213 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 86, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 555/1000 --- L(Train): 0.3621766 --- L(Val, RNN): 0.3428927 --- L(Val, SINDy): 0.3824051 --- Time: 5.45s; --- Convergence: 1.39e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 55/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.512 1 + 0.448 value_stay[t] + 0.209 reward + 0.279 value_stay*reward + -0.321 value_stay*harvest_duration + 0.642 reward^2 + 0.213 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 87, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 556/1000 --- L(Train): 0.3623827 --- L(Val, RNN): 0.3428798 --- L(Val, SINDy): 0.3823571 --- Time: 2.13s; --- Convergence: 1.34e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 56/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.512 1 + 0.447 value_stay[t] + 0.209 reward + 0.279 value_stay*reward + -0.322 value_stay*harvest_duration + 0.642 reward^2 + 0.213 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 88, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 557/1000 --- L(Train): 0.3650373 --- L(Val, RNN): 0.3428560 --- L(Val, SINDy): 0.3823522 --- Time: 1.23s; --- Convergence: 1.86e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 57/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.513 1 + 0.447 value_stay[t] + 0.21 reward + 0.28 value_stay*reward + -0.322 value_stay*harvest_duration + 0.642 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 89, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 558/1000 --- L(Train): 0.3576426 --- L(Val, RNN): 0.3428297 --- L(Val, SINDy): 0.3823220 --- Time: 1.12s; --- Convergence: 2.25e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 58/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.514 1 + 0.447 value_stay[t] + 0.21 reward + 0.281 value_stay*reward + -0.322 value_stay*harvest_duration + 0.643 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 90, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 559/1000 --- L(Train): 0.3609682 --- L(Val, RNN): 0.3428059 --- L(Val, SINDy): 0.3822565 --- Time: 1.17s; --- Convergence: 2.31e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 59/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.515 1 + 0.447 value_stay[t] + 0.211 reward + 0.282 value_stay*reward + -0.321 value_stay*harvest_duration + 0.643 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 91, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 560/1000 --- L(Train): 0.3640748 --- L(Val, RNN): 0.3427873 --- L(Val, SINDy): 0.3821236 --- Time: 1.00s; --- Convergence: 2.09e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 60/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.516 1 + 0.448 value_stay[t] + 0.212 reward + 0.283 value_stay*reward + -0.321 value_stay*harvest_duration + 0.643 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 92, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 561/1000 --- L(Train): 0.3621508 --- L(Val, RNN): 0.3427744 --- L(Val, SINDy): 0.3819216 --- Time: 0.95s; --- Convergence: 1.69e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 61/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.517 1 + 0.448 value_stay[t] + 0.212 reward + 0.283 value_stay*reward + -0.32 value_stay*harvest_duration + 0.643 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 93, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 562/1000 --- L(Train): 0.3636276 --- L(Val, RNN): 0.3427622 --- L(Val, SINDy): 0.3817240 --- Time: 0.93s; --- Convergence: 1.45e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 62/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.517 1 + 0.447 value_stay[t] + 0.211 reward + 0.283 value_stay*reward + -0.321 value_stay*harvest_duration + 0.642 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 94, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 563/1000 --- L(Train): 0.3613627 --- L(Val, RNN): 0.3427342 --- L(Val, SINDy): 0.3816149 --- Time: 0.97s; --- Convergence: 2.13e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 63/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.517 1 + 0.446 value_stay[t] + 0.21 reward + 0.283 value_stay*reward + -0.322 value_stay*harvest_duration + 0.641 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 95, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 564/1000 --- L(Train): 0.3626023 --- L(Val, RNN): 0.3427013 --- L(Val, SINDy): 0.3815654 --- Time: 1.16s; --- Convergence: 2.71e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 64/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.517 1 + 0.446 value_stay[t] + 0.21 reward + 0.283 value_stay*reward + -0.322 value_stay*harvest_duration + 0.64 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 96, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 565/1000 --- L(Train): 0.3620121 --- L(Val, RNN): 0.3426766 --- L(Val, SINDy): 0.3815646 --- Time: 1.37s; --- Convergence: 2.59e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 65/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.518 1 + 0.446 value_stay[t] + 0.211 reward + 0.284 value_stay*reward + -0.322 value_stay*harvest_duration + 0.64 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 97, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 566/1000 --- L(Train): 0.3628227 --- L(Val, RNN): 0.3426652 --- L(Val, SINDy): 0.3814716 --- Time: 1.04s; --- Convergence: 1.86e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 66/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.519 1 + 0.447 value_stay[t] + 0.211 reward + 0.285 value_stay*reward + -0.321 value_stay*harvest_duration + 0.64 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 98, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 567/1000 --- L(Train): 0.3608483 --- L(Val, RNN): 0.3426556 --- L(Val, SINDy): 0.3812990 --- Time: 1.03s; --- Convergence: 1.41e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 67/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.521 1 + 0.448 value_stay[t] + 0.212 reward + 0.287 value_stay*reward + -0.32 value_stay*harvest_duration + 0.64 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, 99, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 568/1000 --- L(Train): 0.3623815 --- L(Val, RNN): 0.3426216 --- L(Val, SINDy): 0.3811940 --- Time: 1.11s; --- Convergence: 2.41e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 68/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.522 1 + 0.449 value_stay[t] + 0.213 reward + 0.288 value_stay*reward + -0.32 value_stay*harvest_duration + 0.64 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 569/1000 --- L(Train): 0.3661499 --- L(Val, RNN): 0.3425831 --- L(Val, SINDy): 0.3811698 --- Time: 0.92s; --- Convergence: 3.12e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 69/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.521 1 + 0.447 value_stay[t] + 0.212 reward + 0.286 value_stay*reward + -0.321 value_stay*harvest_duration + 0.639 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 570/1000 --- L(Train): 0.3606897 --- L(Val, RNN): 0.3425637 --- L(Val, SINDy): 0.3811240 --- Time: 1.05s; --- Convergence: 2.54e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 70/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.521 1 + 0.446 value_stay[t] + 0.21 reward + 0.285 value_stay*reward + -0.323 value_stay*harvest_duration + 0.637 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 571/1000 --- L(Train): 0.3633547 --- L(Val, RNN): 0.3425567 --- L(Val, SINDy): 0.3810612 --- Time: 0.94s; --- Convergence: 1.62e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 71/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.521 1 + 0.444 value_stay[t] + 0.21 reward + 0.285 value_stay*reward + -0.324 value_stay*harvest_duration + 0.636 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 572/1000 --- L(Train): 0.3672169 --- L(Val, RNN): 0.3425515 --- L(Val, SINDy): 0.3809696 --- Time: 0.92s; --- Convergence: 1.07e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 72/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.522 1 + 0.445 value_stay[t] + 0.21 reward + 0.286 value_stay*reward + -0.323 value_stay*harvest_duration + 0.636 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 573/1000 --- L(Train): 0.3642777 --- L(Val, RNN): 0.3425333 --- L(Val, SINDy): 0.3808821 --- Time: 0.84s; --- Convergence: 1.44e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 73/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.524 1 + 0.446 value_stay[t] + 0.211 reward + 0.288 value_stay*reward + -0.321 value_stay*harvest_duration + 0.636 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 574/1000 --- L(Train): 0.3642775 --- L(Val, RNN): 0.3425005 --- L(Val, SINDy): 0.3808663 --- Time: 0.93s; --- Convergence: 2.36e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 74/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.525 1 + 0.446 value_stay[t] + 0.211 reward + 0.288 value_stay*reward + -0.321 value_stay*harvest_duration + 0.636 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 575/1000 --- L(Train): 0.3624990 --- L(Val, RNN): 0.3424727 --- L(Val, SINDy): 0.3808321 --- Time: 0.95s; --- Convergence: 2.57e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 75/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.525 1 + 0.446 value_stay[t] + 0.211 reward + 0.289 value_stay*reward + -0.321 value_stay*harvest_duration + 0.635 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 576/1000 --- L(Train): 0.3577339 --- L(Val, RNN): 0.3424709 --- L(Val, SINDy): 0.3806777 --- Time: 1.17s; --- Convergence: 1.38e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 76/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.526 1 + 0.445 value_stay[t] + 0.211 reward + 0.289 value_stay*reward + -0.321 value_stay*harvest_duration + 0.634 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 577/1000 --- L(Train): 0.3622602 --- L(Val, RNN): 0.3424700 --- L(Val, SINDy): 0.3805240 --- Time: 0.89s; --- Convergence: 7.31e-06; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 77/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.526 1 + 0.444 value_stay[t] + 0.21 reward + 0.288 value_stay*reward + -0.322 value_stay*harvest_duration + 0.633 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 578/1000 --- L(Train): 0.3660682 --- L(Val, RNN): 0.3424579 --- L(Val, SINDy): 0.3804989 --- Time: 0.89s; --- Convergence: 9.75e-06; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 78/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.526 1 + 0.443 value_stay[t] + 0.21 reward + 0.288 value_stay*reward + -0.322 value_stay*harvest_duration + 0.631 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 579/1000 --- L(Train): 0.3619913 --- L(Val, RNN): 0.3424436 --- L(Val, SINDy): 0.3805393 --- Time: 1.24s; --- Convergence: 1.20e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 79/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.526 1 + 0.442 value_stay[t] + 0.21 reward + 0.288 value_stay*reward + -0.322 value_stay*harvest_duration + 0.63 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 580/1000 --- L(Train): 0.3619173 --- L(Val, RNN): 0.3424174 --- L(Val, SINDy): 0.3805666 --- Time: 1.18s; --- Convergence: 1.91e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 80/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.527 1 + 0.442 value_stay[t] + 0.21 reward + 0.289 value_stay*reward + -0.322 value_stay*harvest_duration + 0.63 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 581/1000 --- L(Train): 0.3659081 --- L(Val, RNN): 0.3423817 --- L(Val, SINDy): 0.3805253 --- Time: 1.13s; --- Convergence: 2.74e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 81/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.527 1 + 0.442 value_stay[t] + 0.21 reward + 0.29 value_stay*reward + -0.322 value_stay*harvest_duration + 0.63 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 582/1000 --- L(Train): 0.3644541 --- L(Val, RNN): 0.3423732 --- L(Val, SINDy): 0.3803266 --- Time: 1.20s; --- Convergence: 1.80e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 82/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.528 1 + 0.442 value_stay[t] + 0.211 reward + 0.291 value_stay*reward + -0.322 value_stay*harvest_duration + 0.63 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 583/1000 --- L(Train): 0.3615425 --- L(Val, RNN): 0.3423684 --- L(Val, SINDy): 0.3801395 --- Time: 1.23s; --- Convergence: 1.14e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 83/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.529 1 + 0.442 value_stay[t] + 0.211 reward + 0.292 value_stay*reward + -0.322 value_stay*harvest_duration + 0.63 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 584/1000 --- L(Train): 0.3658529 --- L(Val, RNN): 0.3423447 --- L(Val, SINDy): 0.3800513 --- Time: 0.87s; --- Convergence: 1.75e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 84/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.529 1 + 0.441 value_stay[t] + 0.211 reward + 0.292 value_stay*reward + -0.323 value_stay*harvest_duration + 0.629 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 585/1000 --- L(Train): 0.3599625 --- L(Val, RNN): 0.3423179 --- L(Val, SINDy): 0.3800439 --- Time: 0.87s; --- Convergence: 2.22e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 85/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.529 1 + 0.44 value_stay[t] + 0.211 reward + 0.293 value_stay*reward + -0.323 value_stay*harvest_duration + 0.628 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 586/1000 --- L(Train): 0.3605773 --- L(Val, RNN): 0.3423015 --- L(Val, SINDy): 0.3799653 --- Time: 0.90s; --- Convergence: 1.93e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 86/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.53 1 + 0.439 value_stay[t] + 0.211 reward + 0.293 value_stay*reward + -0.323 value_stay*harvest_duration + 0.628 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 587/1000 --- L(Train): 0.3604962 --- L(Val, RNN): 0.3422893 --- L(Val, SINDy): 0.3798243 --- Time: 0.98s; --- Convergence: 1.58e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 87/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.531 1 + 0.439 value_stay[t] + 0.212 reward + 0.294 value_stay*reward + -0.323 value_stay*harvest_duration + 0.627 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 588/1000 --- L(Train): 0.3681714 --- L(Val, RNN): 0.3422758 --- L(Val, SINDy): 0.3796985 --- Time: 0.92s; --- Convergence: 1.46e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 88/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.531 1 + 0.438 value_stay[t] + 0.212 reward + 0.295 value_stay*reward + -0.323 value_stay*harvest_duration + 0.627 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 589/1000 --- L(Train): 0.3643793 --- L(Val, RNN): 0.3422542 --- L(Val, SINDy): 0.3796640 --- Time: 0.97s; --- Convergence: 1.81e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 89/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.532 1 + 0.438 value_stay[t] + 0.212 reward + 0.295 value_stay*reward + -0.323 value_stay*harvest_duration + 0.627 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 590/1000 --- L(Train): 0.3615069 --- L(Val, RNN): 0.3422268 --- L(Val, SINDy): 0.3796621 --- Time: 1.06s; --- Convergence: 2.28e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 90/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.533 1 + 0.438 value_stay[t] + 0.212 reward + 0.296 value_stay*reward + -0.323 value_stay*harvest_duration + 0.627 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 591/1000 --- L(Train): 0.3656744 --- L(Val, RNN): 0.3422016 --- L(Val, SINDy): 0.3795224 --- Time: 0.90s; --- Convergence: 2.40e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 91/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.533 1 + 0.437 value_stay[t] + 0.212 reward + 0.296 value_stay*reward + -0.323 value_stay*harvest_duration + 0.626 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 592/1000 --- L(Train): 0.3643988 --- L(Val, RNN): 0.3421845 --- L(Val, SINDy): 0.3795120 --- Time: 1.02s; --- Convergence: 2.05e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 92/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.533 1 + 0.437 value_stay[t] + 0.212 reward + 0.296 value_stay*reward + -0.323 value_stay*harvest_duration + 0.625 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 593/1000 --- L(Train): 0.3698106 --- L(Val, RNN): 0.3421700 --- L(Val, SINDy): 0.3794172 --- Time: 1.04s; --- Convergence: 1.75e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 93/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.534 1 + 0.436 value_stay[t] + 0.211 reward + 0.295 value_stay*reward + -0.323 value_stay*harvest_duration + 0.624 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 594/1000 --- L(Train): 0.3619542 --- L(Val, RNN): 0.3421596 --- L(Val, SINDy): 0.3793224 --- Time: 1.09s; --- Convergence: 1.39e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 94/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.534 1 + 0.435 value_stay[t] + 0.211 reward + 0.295 value_stay*reward + -0.324 value_stay*harvest_duration + 0.623 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 595/1000 --- L(Train): 0.3608983 --- L(Val, RNN): 0.3421503 --- L(Val, SINDy): 0.3792485 --- Time: 1.22s; --- Convergence: 1.16e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 95/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.534 1 + 0.435 value_stay[t] + 0.21 reward + 0.295 value_stay*reward + -0.324 value_stay*harvest_duration + 0.622 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 596/1000 --- L(Train): 0.3583156 --- L(Val, RNN): 0.3421380 --- L(Val, SINDy): 0.3792336 --- Time: 1.02s; --- Convergence: 1.20e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 96/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.535 1 + 0.435 value_stay[t] + 0.21 reward + 0.295 value_stay*reward + -0.323 value_stay*harvest_duration + 0.621 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 597/1000 --- L(Train): 0.3661791 --- L(Val, RNN): 0.3421132 --- L(Val, SINDy): 0.3792148 --- Time: 0.91s; --- Convergence: 1.84e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 97/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.535 1 + 0.435 value_stay[t] + 0.21 reward + 0.295 value_stay*reward + -0.322 value_stay*harvest_duration + 0.62 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 598/1000 --- L(Train): 0.3616232 --- L(Val, RNN): 0.3420779 --- L(Val, SINDy): 0.3791458 --- Time: 0.95s; --- Convergence: 2.68e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 98/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.536 1 + 0.436 value_stay[t] + 0.21 reward + 0.296 value_stay*reward + -0.321 value_stay*harvest_duration + 0.62 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 599/1000 --- L(Train): 0.3621583 --- L(Val, RNN): 0.3420607 --- L(Val, SINDy): 0.3789503 --- Time: 0.86s; --- Convergence: 2.20e-05; LR: 1.25e-03; Metric: 0.3324696; Bad epochs: 99/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.537 1 + 0.436 value_stay[t] + 0.211 reward + 0.297 value_stay*reward + -0.32 value_stay*harvest_duration + 0.62 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 600/1000 --- L(Train): 0.3589615 --- L(Val, RNN): 0.3420403 --- L(Val, SINDy): 0.3787663 --- Time: 1.04s; --- Convergence: 2.12e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.538 1 + 0.437 value_stay[t] + 0.211 reward + 0.298 value_stay*reward + -0.319 value_stay*harvest_duration + 0.62 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 601/1000 --- L(Train): 0.3620219 --- L(Val, RNN): 0.3420265 --- L(Val, SINDy): 0.3787298 --- Time: 0.94s; --- Convergence: 1.75e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 1/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.539 1 + 0.437 value_stay[t] + 0.211 reward + 0.298 value_stay*reward + -0.319 value_stay*harvest_duration + 0.62 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 602/1000 --- L(Train): 0.3634082 --- L(Val, RNN): 0.3420174 --- L(Val, SINDy): 0.3786880 --- Time: 0.95s; --- Convergence: 1.33e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 2/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.54 1 + 0.436 value_stay[t] + 0.211 reward + 0.299 value_stay*reward + -0.319 value_stay*harvest_duration + 0.619 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 603/1000 --- L(Train): 0.3645284 --- L(Val, RNN): 0.3420129 --- L(Val, SINDy): 0.3786290 --- Time: 1.00s; --- Convergence: 8.93e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 3/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.54 1 + 0.436 value_stay[t] + 0.211 reward + 0.298 value_stay*reward + -0.319 value_stay*harvest_duration + 0.618 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 604/1000 --- L(Train): 0.3642260 --- L(Val, RNN): 0.3420009 --- L(Val, SINDy): 0.3786610 --- Time: 1.09s; --- Convergence: 1.04e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 4/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.541 1 + 0.435 value_stay[t] + 0.211 reward + 0.298 value_stay*reward + -0.319 value_stay*harvest_duration + 0.618 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 605/1000 --- L(Train): 0.3574764 --- L(Val, RNN): 0.3419888 --- L(Val, SINDy): 0.3786747 --- Time: 1.03s; --- Convergence: 1.13e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 5/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.541 1 + 0.435 value_stay[t] + 0.211 reward + 0.298 value_stay*reward + -0.319 value_stay*harvest_duration + 0.617 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 606/1000 --- L(Train): 0.3643435 --- L(Val, RNN): 0.3419784 --- L(Val, SINDy): 0.3786298 --- Time: 1.14s; --- Convergence: 1.09e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 6/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.542 1 + 0.434 value_stay[t] + 0.211 reward + 0.298 value_stay*reward + -0.32 value_stay*harvest_duration + 0.616 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 607/1000 --- L(Train): 0.3567380 --- L(Val, RNN): 0.3419709 --- L(Val, SINDy): 0.3785442 --- Time: 0.80s; --- Convergence: 9.19e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 7/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.542 1 + 0.434 value_stay[t] + 0.211 reward + 0.299 value_stay*reward + -0.319 value_stay*harvest_duration + 0.616 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 608/1000 --- L(Train): 0.3588273 --- L(Val, RNN): 0.3419652 --- L(Val, SINDy): 0.3784112 --- Time: 0.83s; --- Convergence: 7.41e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 8/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.543 1 + 0.434 value_stay[t] + 0.212 reward + 0.3 value_stay*reward + -0.319 value_stay*harvest_duration + 0.617 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 609/1000 --- L(Train): 0.3619881 --- L(Val, RNN): 0.3419586 --- L(Val, SINDy): 0.3783429 --- Time: 0.97s; --- Convergence: 7.03e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 9/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.544 1 + 0.434 value_stay[t] + 0.212 reward + 0.3 value_stay*reward + -0.319 value_stay*harvest_duration + 0.617 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 610/1000 --- L(Train): 0.3657564 --- L(Val, RNN): 0.3419466 --- L(Val, SINDy): 0.3783420 --- Time: 0.88s; --- Convergence: 9.52e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 10/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.545 1 + 0.434 value_stay[t] + 0.213 reward + 0.301 value_stay*reward + -0.319 value_stay*harvest_duration + 0.617 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 611/1000 --- L(Train): 0.3663440 --- L(Val, RNN): 0.3419330 --- L(Val, SINDy): 0.3783582 --- Time: 0.92s; --- Convergence: 1.15e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 11/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.545 1 + 0.433 value_stay[t] + 0.213 reward + 0.301 value_stay*reward + -0.319 value_stay*harvest_duration + 0.617 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 612/1000 --- L(Train): 0.3650921 --- L(Val, RNN): 0.3419230 --- L(Val, SINDy): 0.3783421 --- Time: 0.86s; --- Convergence: 1.08e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 12/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.545 1 + 0.433 value_stay[t] + 0.213 reward + 0.301 value_stay*reward + -0.32 value_stay*harvest_duration + 0.616 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 613/1000 --- L(Train): 0.3624527 --- L(Val, RNN): 0.3419205 --- L(Val, SINDy): 0.3782842 --- Time: 0.82s; --- Convergence: 6.65e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 13/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.545 1 + 0.432 value_stay[t] + 0.213 reward + 0.302 value_stay*reward + -0.32 value_stay*harvest_duration + 0.616 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 614/1000 --- L(Train): 0.3618668 --- L(Val, RNN): 0.3419220 --- L(Val, SINDy): 0.3782052 --- Time: 1.02s; --- Convergence: 4.10e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 14/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.546 1 + 0.431 value_stay[t] + 0.213 reward + 0.302 value_stay*reward + -0.321 value_stay*harvest_duration + 0.616 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 615/1000 --- L(Train): 0.3629475 --- L(Val, RNN): 0.3419182 --- L(Val, SINDy): 0.3781466 --- Time: 0.84s; --- Convergence: 3.94e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 15/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.546 1 + 0.43 value_stay[t] + 0.213 reward + 0.302 value_stay*reward + -0.322 value_stay*harvest_duration + 0.615 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 616/1000 --- L(Train): 0.3676503 --- L(Val, RNN): 0.3419096 --- L(Val, SINDy): 0.3780737 --- Time: 0.99s; --- Convergence: 6.31e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 16/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.546 1 + 0.43 value_stay[t] + 0.213 reward + 0.302 value_stay*reward + -0.322 value_stay*harvest_duration + 0.615 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 617/1000 --- L(Train): 0.3621689 --- L(Val, RNN): 0.3418997 --- L(Val, SINDy): 0.3780175 --- Time: 1.19s; --- Convergence: 8.09e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 17/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.547 1 + 0.43 value_stay[t] + 0.214 reward + 0.303 value_stay*reward + -0.322 value_stay*harvest_duration + 0.615 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 618/1000 --- L(Train): 0.3588872 --- L(Val, RNN): 0.3418910 --- L(Val, SINDy): 0.3780015 --- Time: 1.12s; --- Convergence: 8.38e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 18/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.548 1 + 0.43 value_stay[t] + 0.214 reward + 0.304 value_stay*reward + -0.321 value_stay*harvest_duration + 0.615 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 619/1000 --- L(Train): 0.3660077 --- L(Val, RNN): 0.3418856 --- L(Val, SINDy): 0.3780595 --- Time: 1.33s; --- Convergence: 6.89e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 19/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.549 1 + 0.431 value_stay[t] + 0.214 reward + 0.304 value_stay*reward + -0.32 value_stay*harvest_duration + 0.614 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 620/1000 --- L(Train): 0.3615175 --- L(Val, RNN): 0.3418836 --- L(Val, SINDy): 0.3780865 --- Time: 3.26s; --- Convergence: 4.46e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 20/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.55 1 + 0.431 value_stay[t] + 0.214 reward + 0.304 value_stay*reward + -0.319 value_stay*harvest_duration + 0.613 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 621/1000 --- L(Train): 0.3642443 --- L(Val, RNN): 0.3418860 --- L(Val, SINDy): 0.3780331 --- Time: 1.99s; --- Convergence: 3.44e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 21/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.55 1 + 0.43 value_stay[t] + 0.213 reward + 0.303 value_stay*reward + -0.32 value_stay*harvest_duration + 0.612 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 622/1000 --- L(Train): 0.3612081 --- L(Val, RNN): 0.3418823 --- L(Val, SINDy): 0.3779435 --- Time: 4.06s; --- Convergence: 3.57e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 22/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.55 1 + 0.429 value_stay[t] + 0.212 reward + 0.302 value_stay*reward + -0.321 value_stay*harvest_duration + 0.61 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 623/1000 --- L(Train): 0.3656524 --- L(Val, RNN): 0.3418749 --- L(Val, SINDy): 0.3778699 --- Time: 3.32s; --- Convergence: 5.51e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 23/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.55 1 + 0.428 value_stay[t] + 0.212 reward + 0.302 value_stay*reward + -0.321 value_stay*harvest_duration + 0.609 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 624/1000 --- L(Train): 0.3598296 --- L(Val, RNN): 0.3418649 --- L(Val, SINDy): 0.3778403 --- Time: 2.09s; --- Convergence: 7.75e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 24/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.551 1 + 0.427 value_stay[t] + 0.212 reward + 0.303 value_stay*reward + -0.321 value_stay*harvest_duration + 0.609 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 625/1000 --- L(Train): 0.3591668 --- L(Val, RNN): 0.3418538 --- L(Val, SINDy): 0.3778292 --- Time: 2.29s; --- Convergence: 9.43e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 25/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.551 1 + 0.427 value_stay[t] + 0.212 reward + 0.304 value_stay*reward + -0.321 value_stay*harvest_duration + 0.609 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 626/1000 --- L(Train): 0.3616627 --- L(Val, RNN): 0.3418486 --- L(Val, SINDy): 0.3777905 --- Time: 3.55s; --- Convergence: 7.29e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 26/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.552 1 + 0.428 value_stay[t] + 0.213 reward + 0.305 value_stay*reward + -0.32 value_stay*harvest_duration + 0.609 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 627/1000 --- L(Train): 0.3562533 --- L(Val, RNN): 0.3418441 --- L(Val, SINDy): 0.3777660 --- Time: 1.87s; --- Convergence: 5.90e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 27/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.554 1 + 0.428 value_stay[t] + 0.214 reward + 0.307 value_stay*reward + -0.318 value_stay*harvest_duration + 0.609 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 628/1000 --- L(Train): 0.3664028 --- L(Val, RNN): 0.3418393 --- L(Val, SINDy): 0.3777508 --- Time: 2.75s; --- Convergence: 5.38e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 28/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.554 1 + 0.428 value_stay[t] + 0.214 reward + 0.307 value_stay*reward + -0.318 value_stay*harvest_duration + 0.608 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 629/1000 --- L(Train): 0.3591440 --- L(Val, RNN): 0.3418280 --- L(Val, SINDy): 0.3777277 --- Time: 2.46s; --- Convergence: 8.31e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 29/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.555 1 + 0.428 value_stay[t] + 0.213 reward + 0.308 value_stay*reward + -0.318 value_stay*harvest_duration + 0.607 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 630/1000 --- L(Train): 0.3659040 --- L(Val, RNN): 0.3418100 --- L(Val, SINDy): 0.3776730 --- Time: 2.92s; --- Convergence: 1.32e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 30/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.555 1 + 0.426 value_stay[t] + 0.213 reward + 0.307 value_stay*reward + -0.319 value_stay*harvest_duration + 0.606 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 631/1000 --- L(Train): 0.3611558 --- L(Val, RNN): 0.3417903 --- L(Val, SINDy): 0.3776374 --- Time: 2.68s; --- Convergence: 1.64e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 31/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.555 1 + 0.425 value_stay[t] + 0.212 reward + 0.307 value_stay*reward + -0.319 value_stay*harvest_duration + 0.605 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 632/1000 --- L(Train): 0.3613176 --- L(Val, RNN): 0.3417744 --- L(Val, SINDy): 0.3775899 --- Time: 2.49s; --- Convergence: 1.61e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 32/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.555 1 + 0.424 value_stay[t] + 0.212 reward + 0.307 value_stay*reward + -0.32 value_stay*harvest_duration + 0.604 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 633/1000 --- L(Train): 0.3632334 --- L(Val, RNN): 0.3417686 --- L(Val, SINDy): 0.3774695 --- Time: 2.16s; --- Convergence: 1.10e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 33/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.555 1 + 0.423 value_stay[t] + 0.212 reward + 0.307 value_stay*reward + -0.32 value_stay*harvest_duration + 0.603 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 634/1000 --- L(Train): 0.3653057 --- L(Val, RNN): 0.3417658 --- L(Val, SINDy): 0.3773617 --- Time: 2.85s; --- Convergence: 6.91e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 34/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.556 1 + 0.423 value_stay[t] + 0.212 reward + 0.308 value_stay*reward + -0.32 value_stay*harvest_duration + 0.603 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 635/1000 --- L(Train): 0.3574790 --- L(Val, RNN): 0.3417650 --- L(Val, SINDy): 0.3772391 --- Time: 3.38s; --- Convergence: 3.83e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 35/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.557 1 + 0.424 value_stay[t] + 0.213 reward + 0.31 value_stay*reward + -0.319 value_stay*harvest_duration + 0.604 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 636/1000 --- L(Train): 0.3648139 --- L(Val, RNN): 0.3417566 --- L(Val, SINDy): 0.3772228 --- Time: 3.39s; --- Convergence: 6.14e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 36/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.559 1 + 0.425 value_stay[t] + 0.214 reward + 0.312 value_stay*reward + -0.317 value_stay*harvest_duration + 0.604 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 637/1000 --- L(Train): 0.3590020 --- L(Val, RNN): 0.3417400 --- L(Val, SINDy): 0.3772922 --- Time: 1.77s; --- Convergence: 1.14e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 37/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.56 1 + 0.425 value_stay[t] + 0.215 reward + 0.312 value_stay*reward + -0.317 value_stay*harvest_duration + 0.604 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 638/1000 --- L(Train): 0.3648155 --- L(Val, RNN): 0.3417270 --- L(Val, SINDy): 0.3772949 --- Time: 2.30s; --- Convergence: 1.22e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 38/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.561 1 + 0.425 value_stay[t] + 0.215 reward + 0.313 value_stay*reward + -0.317 value_stay*harvest_duration + 0.603 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 639/1000 --- L(Train): 0.3640892 --- L(Val, RNN): 0.3417230 --- L(Val, SINDy): 0.3771772 --- Time: 2.10s; --- Convergence: 8.09e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 39/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.56 1 + 0.423 value_stay[t] + 0.214 reward + 0.312 value_stay*reward + -0.318 value_stay*harvest_duration + 0.601 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 640/1000 --- L(Train): 0.3602675 --- L(Val, RNN): 0.3417216 --- L(Val, SINDy): 0.3770520 --- Time: 1.91s; --- Convergence: 4.76e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 40/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.56 1 + 0.421 value_stay[t] + 0.212 reward + 0.31 value_stay*reward + -0.32 value_stay*harvest_duration + 0.6 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 641/1000 --- L(Train): 0.3576217 --- L(Val, RNN): 0.3417166 --- L(Val, SINDy): 0.3769947 --- Time: 0.88s; --- Convergence: 4.85e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 41/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.56 1 + 0.421 value_stay[t] + 0.212 reward + 0.31 value_stay*reward + -0.321 value_stay*harvest_duration + 0.599 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 642/1000 --- L(Train): 0.3660133 --- L(Val, RNN): 0.3417084 --- L(Val, SINDy): 0.3770321 --- Time: 0.90s; --- Convergence: 6.52e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 42/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.561 1 + 0.42 value_stay[t] + 0.212 reward + 0.311 value_stay*reward + -0.321 value_stay*harvest_duration + 0.598 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 643/1000 --- L(Train): 0.3546817 --- L(Val, RNN): 0.3417006 --- L(Val, SINDy): 0.3771248 --- Time: 1.20s; --- Convergence: 7.20e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 43/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.562 1 + 0.421 value_stay[t] + 0.213 reward + 0.313 value_stay*reward + -0.319 value_stay*harvest_duration + 0.598 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 644/1000 --- L(Train): 0.3588096 --- L(Val, RNN): 0.3416958 --- L(Val, SINDy): 0.3770957 --- Time: 1.14s; --- Convergence: 5.95e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 44/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.564 1 + 0.423 value_stay[t] + 0.214 reward + 0.314 value_stay*reward + -0.318 value_stay*harvest_duration + 0.598 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 645/1000 --- L(Train): 0.3636984 --- L(Val, RNN): 0.3416950 --- L(Val, SINDy): 0.3770362 --- Time: 1.03s; --- Convergence: 3.39e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 45/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.565 1 + 0.423 value_stay[t] + 0.215 reward + 0.316 value_stay*reward + -0.317 value_stay*harvest_duration + 0.598 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 646/1000 --- L(Train): 0.3630505 --- L(Val, RNN): 0.3416893 --- L(Val, SINDy): 0.3768636 --- Time: 1.22s; --- Convergence: 4.53e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 46/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.566 1 + 0.423 value_stay[t] + 0.214 reward + 0.316 value_stay*reward + -0.316 value_stay*harvest_duration + 0.597 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 647/1000 --- L(Train): 0.3605965 --- L(Val, RNN): 0.3416797 --- L(Val, SINDy): 0.3768050 --- Time: 0.90s; --- Convergence: 7.11e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 47/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.566 1 + 0.422 value_stay[t] + 0.213 reward + 0.314 value_stay*reward + -0.318 value_stay*harvest_duration + 0.595 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 648/1000 --- L(Train): 0.3639513 --- L(Val, RNN): 0.3416632 --- L(Val, SINDy): 0.3768978 --- Time: 0.90s; --- Convergence: 1.18e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 48/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.565 1 + 0.42 value_stay[t] + 0.211 reward + 0.313 value_stay*reward + -0.319 value_stay*harvest_duration + 0.593 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 649/1000 --- L(Train): 0.3573262 --- L(Val, RNN): 0.3416502 --- L(Val, SINDy): 0.3770624 --- Time: 0.90s; --- Convergence: 1.24e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 49/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.565 1 + 0.419 value_stay[t] + 0.21 reward + 0.311 value_stay*reward + -0.32 value_stay*harvest_duration + 0.591 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 650/1000 --- L(Train): 0.3599604 --- L(Val, RNN): 0.3416466 --- L(Val, SINDy): 0.3770877 --- Time: 0.92s; --- Convergence: 8.01e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 50/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.566 1 + 0.419 value_stay[t] + 0.21 reward + 0.312 value_stay*reward + -0.319 value_stay*harvest_duration + 0.591 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 651/1000 --- L(Train): 0.3624707 --- L(Val, RNN): 0.3416475 --- L(Val, SINDy): 0.3769781 --- Time: 1.17s; --- Convergence: 4.45e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 51/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.567 1 + 0.42 value_stay[t] + 0.211 reward + 0.313 value_stay*reward + -0.317 value_stay*harvest_duration + 0.591 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 652/1000 --- L(Train): 0.3636895 --- L(Val, RNN): 0.3416509 --- L(Val, SINDy): 0.3767871 --- Time: 1.03s; --- Convergence: 3.92e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 52/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.568 1 + 0.421 value_stay[t] + 0.211 reward + 0.314 value_stay*reward + -0.316 value_stay*harvest_duration + 0.591 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 653/1000 --- L(Train): 0.3607150 --- L(Val, RNN): 0.3416485 --- L(Val, SINDy): 0.3766414 --- Time: 0.88s; --- Convergence: 3.17e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 53/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.569 1 + 0.421 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.315 value_stay*harvest_duration + 0.59 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 654/1000 --- L(Train): 0.3557492 --- L(Val, RNN): 0.3416319 --- L(Val, SINDy): 0.3766315 --- Time: 1.29s; --- Convergence: 9.88e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 54/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.57 1 + 0.421 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.315 value_stay*harvest_duration + 0.59 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 655/1000 --- L(Train): 0.3625109 --- L(Val, RNN): 0.3416095 --- L(Val, SINDy): 0.3767032 --- Time: 1.44s; --- Convergence: 1.61e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 55/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.57 1 + 0.42 value_stay[t] + 0.212 reward + 0.316 value_stay*reward + -0.315 value_stay*harvest_duration + 0.59 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 656/1000 --- L(Train): 0.3608837 --- L(Val, RNN): 0.3415927 --- L(Val, SINDy): 0.3767112 --- Time: 1.62s; --- Convergence: 1.65e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 56/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.571 1 + 0.42 value_stay[t] + 0.212 reward + 0.316 value_stay*reward + -0.314 value_stay*harvest_duration + 0.59 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 657/1000 --- L(Train): 0.3625047 --- L(Val, RNN): 0.3415880 --- L(Val, SINDy): 0.3766240 --- Time: 1.19s; --- Convergence: 1.06e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 57/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.571 1 + 0.419 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.315 value_stay*harvest_duration + 0.589 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 658/1000 --- L(Train): 0.3610261 --- L(Val, RNN): 0.3415899 --- L(Val, SINDy): 0.3765411 --- Time: 1.14s; --- Convergence: 6.21e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 58/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.571 1 + 0.417 value_stay[t] + 0.211 reward + 0.314 value_stay*reward + -0.316 value_stay*harvest_duration + 0.588 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 659/1000 --- L(Train): 0.3572452 --- L(Val, RNN): 0.3415890 --- L(Val, SINDy): 0.3764585 --- Time: 1.04s; --- Convergence: 3.52e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 59/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.57 1 + 0.416 value_stay[t] + 0.21 reward + 0.313 value_stay*reward + -0.317 value_stay*harvest_duration + 0.587 reward^2 + 0.214 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 660/1000 --- L(Train): 0.3606377 --- L(Val, RNN): 0.3415786 --- L(Val, SINDy): 0.3764251 --- Time: 0.94s; --- Convergence: 6.98e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 60/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.571 1 + 0.416 value_stay[t] + 0.21 reward + 0.314 value_stay*reward + -0.316 value_stay*harvest_duration + 0.586 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 661/1000 --- L(Train): 0.3598684 --- L(Val, RNN): 0.3415594 --- L(Val, SINDy): 0.3763767 --- Time: 1.07s; --- Convergence: 1.31e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 61/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.573 1 + 0.416 value_stay[t] + 0.211 reward + 0.314 value_stay*reward + -0.316 value_stay*harvest_duration + 0.587 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 662/1000 --- L(Train): 0.3643670 --- L(Val, RNN): 0.3415404 --- L(Val, SINDy): 0.3764144 --- Time: 1.29s; --- Convergence: 1.60e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 62/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.574 1 + 0.417 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.314 value_stay*harvest_duration + 0.587 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 663/1000 --- L(Train): 0.3637523 --- L(Val, RNN): 0.3415310 --- L(Val, SINDy): 0.3763593 --- Time: 1.01s; --- Convergence: 1.27e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 63/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.575 1 + 0.418 value_stay[t] + 0.212 reward + 0.316 value_stay*reward + -0.313 value_stay*harvest_duration + 0.587 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 664/1000 --- L(Train): 0.3600869 --- L(Val, RNN): 0.3415297 --- L(Val, SINDy): 0.3762352 --- Time: 0.97s; --- Convergence: 7.04e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 64/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.576 1 + 0.418 value_stay[t] + 0.212 reward + 0.316 value_stay*reward + -0.313 value_stay*harvest_duration + 0.587 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 665/1000 --- L(Train): 0.3585068 --- L(Val, RNN): 0.3415238 --- L(Val, SINDy): 0.3761833 --- Time: 1.16s; --- Convergence: 6.47e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 65/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.576 1 + 0.417 value_stay[t] + 0.212 reward + 0.316 value_stay*reward + -0.313 value_stay*harvest_duration + 0.586 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 666/1000 --- L(Train): 0.3579481 --- L(Val, RNN): 0.3415175 --- L(Val, SINDy): 0.3761733 --- Time: 1.24s; --- Convergence: 6.38e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 66/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.576 1 + 0.416 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.314 value_stay*harvest_duration + 0.586 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 667/1000 --- L(Train): 0.3649154 --- L(Val, RNN): 0.3415122 --- L(Val, SINDy): 0.3761111 --- Time: 1.18s; --- Convergence: 5.81e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 67/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.577 1 + 0.415 value_stay[t] + 0.211 reward + 0.314 value_stay*reward + -0.314 value_stay*harvest_duration + 0.585 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 668/1000 --- L(Train): 0.3626155 --- L(Val, RNN): 0.3415118 --- L(Val, SINDy): 0.3760544 --- Time: 1.24s; --- Convergence: 3.13e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 68/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.577 1 + 0.415 value_stay[t] + 0.211 reward + 0.314 value_stay*reward + -0.314 value_stay*harvest_duration + 0.585 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 669/1000 --- L(Train): 0.3628088 --- L(Val, RNN): 0.3415109 --- L(Val, SINDy): 0.3760453 --- Time: 1.01s; --- Convergence: 2.01e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 69/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.578 1 + 0.414 value_stay[t] + 0.211 reward + 0.314 value_stay*reward + -0.314 value_stay*harvest_duration + 0.584 reward^2 + 0.215 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 670/1000 --- L(Train): 0.3598355 --- L(Val, RNN): 0.3415110 --- L(Val, SINDy): 0.3760951 --- Time: 1.02s; --- Convergence: 1.04e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 70/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.579 1 + 0.415 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.313 value_stay*harvest_duration + 0.585 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 671/1000 --- L(Train): 0.3649501 --- L(Val, RNN): 0.3415113 --- L(Val, SINDy): 0.3761322 --- Time: 1.16s; --- Convergence: 7.12e-07; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 71/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.58 1 + 0.415 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.312 value_stay*harvest_duration + 0.585 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 672/1000 --- L(Train): 0.3583632 --- L(Val, RNN): 0.3415067 --- L(Val, SINDy): 0.3761136 --- Time: 1.13s; --- Convergence: 2.68e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 72/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.581 1 + 0.415 value_stay[t] + 0.212 reward + 0.316 value_stay*reward + -0.311 value_stay*harvest_duration + 0.585 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 673/1000 --- L(Train): 0.3589538 --- L(Val, RNN): 0.3414986 --- L(Val, SINDy): 0.3760851 --- Time: 0.98s; --- Convergence: 5.39e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 73/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.582 1 + 0.415 value_stay[t] + 0.212 reward + 0.316 value_stay*reward + -0.311 value_stay*harvest_duration + 0.585 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 674/1000 --- L(Train): 0.3595826 --- L(Val, RNN): 0.3414883 --- L(Val, SINDy): 0.3760397 --- Time: 0.93s; --- Convergence: 7.82e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 74/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.582 1 + 0.415 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.311 value_stay*harvest_duration + 0.584 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 675/1000 --- L(Train): 0.3609232 --- L(Val, RNN): 0.3414819 --- L(Val, SINDy): 0.3759878 --- Time: 0.98s; --- Convergence: 7.13e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 75/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.583 1 + 0.415 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.311 value_stay*harvest_duration + 0.584 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 676/1000 --- L(Train): 0.3568865 --- L(Val, RNN): 0.3414816 --- L(Val, SINDy): 0.3759101 --- Time: 1.19s; --- Convergence: 3.71e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 76/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.583 1 + 0.414 value_stay[t] + 0.212 reward + 0.314 value_stay*reward + -0.311 value_stay*harvest_duration + 0.583 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 677/1000 --- L(Train): 0.3592932 --- L(Val, RNN): 0.3414803 --- L(Val, SINDy): 0.3758247 --- Time: 0.95s; --- Convergence: 2.53e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 77/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.583 1 + 0.413 value_stay[t] + 0.212 reward + 0.314 value_stay*reward + -0.312 value_stay*harvest_duration + 0.583 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 678/1000 --- L(Train): 0.3604621 --- L(Val, RNN): 0.3414704 --- L(Val, SINDy): 0.3757730 --- Time: 1.13s; --- Convergence: 6.20e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 78/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.584 1 + 0.413 value_stay[t] + 0.212 reward + 0.314 value_stay*reward + -0.312 value_stay*harvest_duration + 0.583 reward^2 + 0.216 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 679/1000 --- L(Train): 0.3585027 --- L(Val, RNN): 0.3414547 --- L(Val, SINDy): 0.3757894 --- Time: 0.97s; --- Convergence: 1.09e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 79/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.584 1 + 0.413 value_stay[t] + 0.212 reward + 0.315 value_stay*reward + -0.312 value_stay*harvest_duration + 0.583 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 680/1000 --- L(Train): 0.3581427 --- L(Val, RNN): 0.3414408 --- L(Val, SINDy): 0.3757972 --- Time: 0.96s; --- Convergence: 1.24e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 80/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.585 1 + 0.413 value_stay[t] + 0.213 reward + 0.316 value_stay*reward + -0.312 value_stay*harvest_duration + 0.584 reward^2 + 0.217 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 681/1000 --- L(Train): 0.3588038 --- L(Val, RNN): 0.3414340 --- L(Val, SINDy): 0.3757443 --- Time: 1.09s; --- Convergence: 9.60e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 81/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.586 1 + 0.413 value_stay[t] + 0.214 reward + 0.317 value_stay*reward + -0.312 value_stay*harvest_duration + 0.585 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 682/1000 --- L(Train): 0.3685688 --- L(Val, RNN): 0.3414296 --- L(Val, SINDy): 0.3756595 --- Time: 0.91s; --- Convergence: 7.01e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 82/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.586 1 + 0.412 value_stay[t] + 0.214 reward + 0.317 value_stay*reward + -0.312 value_stay*harvest_duration + 0.585 reward^2 + 0.218 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 683/1000 --- L(Train): 0.3618478 --- L(Val, RNN): 0.3414228 --- L(Val, SINDy): 0.3755871 --- Time: 1.26s; --- Convergence: 6.90e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 83/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.586 1 + 0.412 value_stay[t] + 0.214 reward + 0.318 value_stay*reward + -0.312 value_stay*harvest_duration + 0.585 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 684/1000 --- L(Train): 0.3588219 --- L(Val, RNN): 0.3414117 --- L(Val, SINDy): 0.3755218 --- Time: 0.96s; --- Convergence: 9.01e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 84/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.587 1 + 0.412 value_stay[t] + 0.215 reward + 0.318 value_stay*reward + -0.312 value_stay*harvest_duration + 0.585 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 685/1000 --- L(Train): 0.3667223 --- L(Val, RNN): 0.3413967 --- L(Val, SINDy): 0.3755517 --- Time: 0.89s; --- Convergence: 1.20e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 85/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.587 1 + 0.411 value_stay[t] + 0.215 reward + 0.319 value_stay*reward + -0.313 value_stay*harvest_duration + 0.585 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 686/1000 --- L(Train): 0.3570832 --- L(Val, RNN): 0.3413818 --- L(Val, SINDy): 0.3755606 --- Time: 0.98s; --- Convergence: 1.35e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 86/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.588 1 + 0.411 value_stay[t] + 0.215 reward + 0.32 value_stay*reward + -0.314 value_stay*harvest_duration + 0.585 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 687/1000 --- L(Train): 0.3603348 --- L(Val, RNN): 0.3413779 --- L(Val, SINDy): 0.3754926 --- Time: 1.15s; --- Convergence: 8.71e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 87/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.588 1 + 0.41 value_stay[t] + 0.216 reward + 0.32 value_stay*reward + -0.314 value_stay*harvest_duration + 0.585 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 688/1000 --- L(Train): 0.3593707 --- L(Val, RNN): 0.3413732 --- L(Val, SINDy): 0.3753872 --- Time: 0.93s; --- Convergence: 6.69e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 88/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.589 1 + 0.41 value_stay[t] + 0.216 reward + 0.321 value_stay*reward + -0.314 value_stay*harvest_duration + 0.584 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 689/1000 --- L(Train): 0.3586486 --- L(Val, RNN): 0.3413670 --- L(Val, SINDy): 0.3753463 --- Time: 0.85s; --- Convergence: 6.45e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 89/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.589 1 + 0.41 value_stay[t] + 0.216 reward + 0.321 value_stay*reward + -0.314 value_stay*harvest_duration + 0.584 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 690/1000 --- L(Train): 0.3627514 --- L(Val, RNN): 0.3413566 --- L(Val, SINDy): 0.3753290 --- Time: 1.05s; --- Convergence: 8.41e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 90/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.59 1 + 0.41 value_stay[t] + 0.216 reward + 0.322 value_stay*reward + -0.315 value_stay*harvest_duration + 0.583 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 691/1000 --- L(Train): 0.3606988 --- L(Val, RNN): 0.3413469 --- L(Val, SINDy): 0.3752808 --- Time: 1.04s; --- Convergence: 9.03e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 91/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.59 1 + 0.409 value_stay[t] + 0.216 reward + 0.322 value_stay*reward + -0.315 value_stay*harvest_duration + 0.583 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 692/1000 --- L(Train): 0.3638946 --- L(Val, RNN): 0.3413372 --- L(Val, SINDy): 0.3752518 --- Time: 0.85s; --- Convergence: 9.40e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 92/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.591 1 + 0.409 value_stay[t] + 0.216 reward + 0.323 value_stay*reward + -0.315 value_stay*harvest_duration + 0.582 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 693/1000 --- L(Train): 0.3663177 --- L(Val, RNN): 0.3413325 --- L(Val, SINDy): 0.3751965 --- Time: 0.96s; --- Convergence: 7.03e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 93/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.591 1 + 0.409 value_stay[t] + 0.216 reward + 0.323 value_stay*reward + -0.315 value_stay*harvest_duration + 0.581 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 694/1000 --- L(Train): 0.3607577 --- L(Val, RNN): 0.3413276 --- L(Val, SINDy): 0.3751430 --- Time: 0.94s; --- Convergence: 5.97e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 94/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.592 1 + 0.409 value_stay[t] + 0.215 reward + 0.323 value_stay*reward + -0.315 value_stay*harvest_duration + 0.581 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 695/1000 --- L(Train): 0.3553823 --- L(Val, RNN): 0.3413230 --- L(Val, SINDy): 0.3751180 --- Time: 0.86s; --- Convergence: 5.28e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 95/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.592 1 + 0.409 value_stay[t] + 0.215 reward + 0.323 value_stay*reward + -0.315 value_stay*harvest_duration + 0.58 reward^2 + 0.219 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 696/1000 --- L(Train): 0.3597292 --- L(Val, RNN): 0.3413173 --- L(Val, SINDy): 0.3751266 --- Time: 1.03s; --- Convergence: 5.50e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 96/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.593 1 + 0.409 value_stay[t] + 0.215 reward + 0.324 value_stay*reward + -0.315 value_stay*harvest_duration + 0.58 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 697/1000 --- L(Train): 0.3615157 --- L(Val, RNN): 0.3413113 --- L(Val, SINDy): 0.3751179 --- Time: 0.96s; --- Convergence: 5.76e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 97/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.593 1 + 0.408 value_stay[t] + 0.216 reward + 0.325 value_stay*reward + -0.315 value_stay*harvest_duration + 0.579 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 698/1000 --- L(Train): 0.3601859 --- L(Val, RNN): 0.3412984 --- L(Val, SINDy): 0.3751273 --- Time: 0.86s; --- Convergence: 9.32e-06; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 98/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.593 1 + 0.408 value_stay[t] + 0.216 reward + 0.326 value_stay*reward + -0.315 value_stay*harvest_duration + 0.579 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 699/1000 --- L(Train): 0.3565252 --- L(Val, RNN): 0.3412854 --- L(Val, SINDy): 0.3750554 --- Time: 0.96s; --- Convergence: 1.12e-05; LR: 6.25e-04; Metric: 0.3324696; Bad epochs: 99/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.593 1 + 0.407 value_stay[t] + 0.216 reward + 0.327 value_stay*reward + -0.315 value_stay*harvest_duration + 0.579 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 700/1000 --- L(Train): 0.3655179 --- L(Val, RNN): 0.3412765 --- L(Val, SINDy): 0.3749119 --- Time: 1.13s; --- Convergence: 1.00e-05; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.594 1 + 0.407 value_stay[t] + 0.216 reward + 0.327 value_stay*reward + -0.316 value_stay*harvest_duration + 0.578 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 701/1000 --- L(Train): 0.3644591 --- L(Val, RNN): 0.3412745 --- L(Val, SINDy): 0.3747798 --- Time: 1.44s; --- Convergence: 6.02e-06; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 1/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.594 1 + 0.406 value_stay[t] + 0.216 reward + 0.328 value_stay*reward + -0.316 value_stay*harvest_duration + 0.578 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 702/1000 --- L(Train): 0.3581049 --- L(Val, RNN): 0.3412731 --- L(Val, SINDy): 0.3747279 --- Time: 1.57s; --- Convergence: 3.69e-06; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 2/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.594 1 + 0.406 value_stay[t] + 0.216 reward + 0.329 value_stay*reward + -0.316 value_stay*harvest_duration + 0.577 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 703/1000 --- L(Train): 0.3628161 --- L(Val, RNN): 0.3412689 --- L(Val, SINDy): 0.3748184 --- Time: 1.87s; --- Convergence: 3.98e-06; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 3/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.594 1 + 0.405 value_stay[t] + 0.216 reward + 0.329 value_stay*reward + -0.316 value_stay*harvest_duration + 0.577 reward^2 + 0.221 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 704/1000 --- L(Train): 0.3592226 --- L(Val, RNN): 0.3412651 --- L(Val, SINDy): 0.3748671 --- Time: 4.17s; --- Convergence: 3.87e-06; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 4/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.594 1 + 0.405 value_stay[t] + 0.216 reward + 0.33 value_stay*reward + -0.317 value_stay*harvest_duration + 0.576 reward^2 + 0.221 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 705/1000 --- L(Train): 0.3589009 --- L(Val, RNN): 0.3412605 --- L(Val, SINDy): 0.3748213 --- Time: 5.31s; --- Convergence: 4.23e-06; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 5/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.594 1 + 0.404 value_stay[t] + 0.216 reward + 0.331 value_stay*reward + -0.317 value_stay*harvest_duration + 0.576 reward^2 + 0.221 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 706/1000 --- L(Train): 0.3600669 --- L(Val, RNN): 0.3412542 --- L(Val, SINDy): 0.3747756 --- Time: 5.91s; --- Convergence: 5.27e-06; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 6/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.594 1 + 0.403 value_stay[t] + 0.217 reward + 0.332 value_stay*reward + -0.318 value_stay*harvest_duration + 0.576 reward^2 + 0.221 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 707/1000 --- L(Train): 0.3615042 --- L(Val, RNN): 0.3412496 --- L(Val, SINDy): 0.3747495 --- Time: 5.94s; --- Convergence: 4.93e-06; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 7/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.595 1 + 0.403 value_stay[t] + 0.217 reward + 0.334 value_stay*reward + -0.318 value_stay*harvest_duration + 0.575 reward^2 + 0.221 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 708/1000 --- L(Train): 0.3549580 --- L(Val, RNN): 0.3412451 --- L(Val, SINDy): 0.3747332 --- Time: 2.09s; --- Convergence: 4.75e-06; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 8/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.596 1 + 0.404 value_stay[t] + 0.218 reward + 0.336 value_stay*reward + -0.317 value_stay*harvest_duration + 0.575 reward^2 + 0.222 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 709/1000 --- L(Train): 0.3633988 --- L(Val, RNN): 0.3412420 --- L(Val, SINDy): 0.3747146 --- Time: 3.94s; --- Convergence: 3.88e-06; LR: 3.13e-04; Metric: 0.3324696; Bad epochs: 9/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.596 1 + 0.404 value_stay[t] + 0.218 reward + 0.337 value_stay*reward + -0.317 value_stay*harvest_duration + 0.575 reward^2 + 0.222 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, -, -, 0, 0, 0, 0, -\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\n",
      "Training interrupted. Continuing with further operations...\n",
      "\n",
      "================================================================================\n",
      "Starting second stage SINDy fitting (threshold=0.05, single model)\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 1/1000 --- L(Train): 0.0679438 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.01 1 + 0.991 value_stay[t] + 0.009 reward + 0.01 harvest_duration + -0.011 value_stay^2 + -0.009 value_stay*reward + -0.01 value_stay*harvest_duration + 0.011 reward^2 + 0.009 reward*harvest_duration + 0.01 harvest_duration^2 \n",
      "value_exit[t+1] = 0.009 1 + 0.991 value_exit[t] + 0.01 travel_duration + 0.01 value_exit^2 + -0.011 value_exit*travel_duration + 0.01 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 2/1000 --- L(Train): 0.3698150 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.008 1 + 0.981 value_stay[t] + 0.019 reward + 0.009 harvest_duration + -0.021 value_stay^2 + -0.019 value_stay*reward + -0.02 value_stay*harvest_duration + 0.021 reward^2 + 0.019 reward*harvest_duration + 0.009 harvest_duration^2 \n",
      "value_exit[t+1] = 0.001 1 + 0.998 value_exit[t] + 0.002 travel_duration + 0.003 value_exit^2 + -0.004 value_exit*travel_duration + 0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 3/1000 --- L(Train): 0.0769846 --- L(Val, SINDy): 0.0000000 --- Time: 0.27s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.011 1 + 0.971 value_stay[t] + 0.028 reward + 0.011 harvest_duration + -0.031 value_stay^2 + -0.026 value_stay*reward + -0.03 value_stay*harvest_duration + 0.031 reward^2 + 0.029 reward*harvest_duration + 0.012 harvest_duration^2 \n",
      "value_exit[t+1] = -0.006 1 + 1.006 value_exit[t] + -0.005 travel_duration + -0.004 value_exit^2 + 0.003 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 4/1000 --- L(Train): 0.1222406 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.017 1 + 0.961 value_stay[t] + 0.038 reward + 0.017 harvest_duration + -0.041 value_stay^2 + -0.03 value_stay*reward + -0.04 value_stay*harvest_duration + 0.041 reward^2 + 0.039 reward*harvest_duration + 0.017 harvest_duration^2 \n",
      "value_exit[t+1] = -0.009 1 + 1.008 value_exit[t] + -0.008 travel_duration + -0.007 value_exit^2 + 0.006 value_exit*travel_duration + -0.008 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 5/1000 --- L(Train): 0.2250931 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.023 1 + 0.952 value_stay[t] + 0.048 reward + 0.023 harvest_duration + -0.05 value_stay^2 + -0.031 value_stay*reward + -0.049 value_stay*harvest_duration + 0.051 reward^2 + 0.049 reward*harvest_duration + 0.023 harvest_duration^2 \n",
      "value_exit[t+1] = -0.008 1 + 1.007 value_exit[t] + -0.007 travel_duration + -0.006 value_exit^2 + 0.005 value_exit*travel_duration + -0.007 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 6/1000 --- L(Train): 0.1682639 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.028 1 + 0.943 value_stay[t] + 0.058 reward + 0.028 harvest_duration + -0.06 value_stay^2 + -0.032 value_stay*reward + -0.059 value_stay*harvest_duration + 0.061 reward^2 + 0.058 reward*harvest_duration + 0.028 harvest_duration^2 \n",
      "value_exit[t+1] = -0.005 1 + 1.004 value_exit[t] + -0.004 travel_duration + -0.003 value_exit^2 + 0.002 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 7/1000 --- L(Train): 0.0702509 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.031 1 + 0.933 value_stay[t] + 0.068 reward + 0.031 harvest_duration + -0.07 value_stay^2 + -0.033 value_stay*reward + -0.068 value_stay*harvest_duration + 0.071 reward^2 + 0.068 reward*harvest_duration + 0.031 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 1.0 value_exit[t] + -0.0 travel_duration + 0.001 value_exit^2 + -0.002 value_exit*travel_duration + 0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 8/1000 --- L(Train): 0.0426422 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.033 1 + 0.923 value_stay[t] + 0.078 reward + 0.033 harvest_duration + -0.079 value_stay^2 + -0.034 value_stay*reward + -0.078 value_stay*harvest_duration + 0.08 reward^2 + 0.078 reward*harvest_duration + 0.033 harvest_duration^2 \n",
      "value_exit[t+1] = 0.002 1 + 0.997 value_exit[t] + 0.003 travel_duration + 0.004 value_exit^2 + -0.005 value_exit*travel_duration + 0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 9/1000 --- L(Train): 0.0864310 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.035 1 + 0.914 value_stay[t] + 0.087 reward + 0.035 harvest_duration + -0.088 value_stay^2 + -0.032 value_stay*reward + -0.087 value_stay*harvest_duration + 0.09 reward^2 + 0.087 reward*harvest_duration + 0.035 harvest_duration^2 \n",
      "value_exit[t+1] = 0.004 1 + 0.995 value_exit[t] + 0.005 travel_duration + 0.006 value_exit^2 + -0.007 value_exit*travel_duration + 0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 10/1000 --- L(Train): 0.1216199 --- L(Val, SINDy): 0.0000000 --- Time: 0.28s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.905 value_stay[t] + 0.097 reward + 0.038 harvest_duration + -0.097 value_stay^2 + -0.029 value_stay*reward + -0.096 value_stay*harvest_duration + 0.1 reward^2 + 0.097 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = 0.004 1 + 0.995 value_exit[t] + 0.005 travel_duration + 0.006 value_exit^2 + -0.007 value_exit*travel_duration + 0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 11/1000 --- L(Train): 0.1028378 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.896 value_stay[t] + 0.106 reward + 0.042 harvest_duration + -0.106 value_stay^2 + -0.023 value_stay*reward + -0.105 value_stay*harvest_duration + 0.109 reward^2 + 0.107 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.002 1 + 0.996 value_exit[t] + 0.003 travel_duration + 0.005 value_exit^2 + -0.006 value_exit*travel_duration + 0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 12/1000 --- L(Train): 0.0567309 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.887 value_stay[t] + 0.116 reward + 0.045 harvest_duration + -0.114 value_stay^2 + -0.017 value_stay*reward + -0.114 value_stay*harvest_duration + 0.119 reward^2 + 0.116 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.998 value_exit[t] + 0.001 travel_duration + 0.003 value_exit^2 + -0.004 value_exit*travel_duration + 0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 13/1000 --- L(Train): 0.0295713 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.879 value_stay[t] + 0.126 reward + 0.048 harvest_duration + -0.123 value_stay^2 + -0.01 value_stay*reward + -0.122 value_stay*harvest_duration + 0.129 reward^2 + 0.126 reward*harvest_duration + 0.049 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 1.0 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.002 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 14/1000 --- L(Train): 0.0386319 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.05 1 + 0.87 value_stay[t] + 0.135 reward + 0.05 harvest_duration + -0.131 value_stay^2 + -0.003 value_stay*reward + -0.131 value_stay*harvest_duration + 0.138 reward^2 + 0.135 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = -0.004 1 + 1.002 value_exit[t] + -0.003 travel_duration + -0.001 value_exit^2 + -0.0 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 15/1000 --- L(Train): 0.0618805 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.051 1 + 0.862 value_stay[t] + 0.144 reward + 0.051 harvest_duration + -0.139 value_stay^2 + 0.005 value_stay*reward + -0.139 value_stay*harvest_duration + 0.147 reward^2 + 0.144 reward*harvest_duration + 0.051 harvest_duration^2 \n",
      "value_exit[t+1] = -0.005 1 + 1.003 value_exit[t] + -0.004 travel_duration + -0.002 value_exit^2 + 0.001 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 16/1000 --- L(Train): 0.0681846 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.052 1 + 0.854 value_stay[t] + 0.153 reward + 0.052 harvest_duration + -0.146 value_stay^2 + 0.013 value_stay*reward + -0.147 value_stay*harvest_duration + 0.156 reward^2 + 0.154 reward*harvest_duration + 0.052 harvest_duration^2 \n",
      "value_exit[t+1] = -0.005 1 + 1.003 value_exit[t] + -0.004 travel_duration + -0.002 value_exit^2 + 0.0 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 17/1000 --- L(Train): 0.0511231 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.054 1 + 0.846 value_stay[t] + 0.162 reward + 0.054 harvest_duration + -0.153 value_stay^2 + 0.021 value_stay*reward + -0.155 value_stay*harvest_duration + 0.165 reward^2 + 0.163 reward*harvest_duration + 0.054 harvest_duration^2 \n",
      "value_exit[t+1] = -0.004 1 + 1.001 value_exit[t] + -0.003 travel_duration + -0.001 value_exit^2 + -0.001 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 18/1000 --- L(Train): 0.0289331 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.056 1 + 0.839 value_stay[t] + 0.171 reward + 0.056 harvest_duration + -0.16 value_stay^2 + 0.03 value_stay*reward + -0.162 value_stay*harvest_duration + 0.174 reward^2 + 0.172 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.999 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.003 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 19/1000 --- L(Train): 0.0210141 --- L(Val, SINDy): 0.0000000 --- Time: 0.29s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.058 1 + 0.832 value_stay[t] + 0.18 reward + 0.058 harvest_duration + -0.166 value_stay^2 + 0.039 value_stay*reward + -0.169 value_stay*harvest_duration + 0.183 reward^2 + 0.18 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.997 value_exit[t] + 0.001 travel_duration + 0.003 value_exit^2 + -0.005 value_exit*travel_duration + 0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 20/1000 --- L(Train): 0.0292556 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.06 1 + 0.825 value_stay[t] + 0.189 reward + 0.06 harvest_duration + -0.172 value_stay^2 + 0.049 value_stay*reward + -0.176 value_stay*harvest_duration + 0.192 reward^2 + 0.189 reward*harvest_duration + 0.06 harvest_duration^2 \n",
      "value_exit[t+1] = 0.001 1 + 0.996 value_exit[t] + 0.002 travel_duration + 0.005 value_exit^2 + -0.006 value_exit*travel_duration + 0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 21/1000 --- L(Train): 0.0395570 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.06 1 + 0.819 value_stay[t] + 0.197 reward + 0.06 harvest_duration + -0.178 value_stay^2 + 0.058 value_stay*reward + -0.183 value_stay*harvest_duration + 0.2 reward^2 + 0.198 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = 0.002 1 + 0.995 value_exit[t] + 0.002 travel_duration + 0.005 value_exit^2 + -0.007 value_exit*travel_duration + 0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 22/1000 --- L(Train): 0.0389137 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.06 1 + 0.812 value_stay[t] + 0.206 reward + 0.06 harvest_duration + -0.183 value_stay^2 + 0.067 value_stay*reward + -0.189 value_stay*harvest_duration + 0.208 reward^2 + 0.206 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = 0.001 1 + 0.995 value_exit[t] + 0.002 travel_duration + 0.005 value_exit^2 + -0.007 value_exit*travel_duration + 0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 23/1000 --- L(Train): 0.0281515 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.06 1 + 0.806 value_stay[t] + 0.214 reward + 0.06 harvest_duration + -0.188 value_stay^2 + 0.077 value_stay*reward + -0.195 value_stay*harvest_duration + 0.217 reward^2 + 0.214 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.996 value_exit[t] + 0.001 travel_duration + 0.004 value_exit^2 + -0.006 value_exit*travel_duration + 0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 24/1000 --- L(Train): 0.0180971 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.061 1 + 0.801 value_stay[t] + 0.222 reward + 0.061 harvest_duration + -0.193 value_stay^2 + 0.086 value_stay*reward + -0.201 value_stay*harvest_duration + 0.224 reward^2 + 0.222 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.997 value_exit[t] + 0.0 travel_duration + 0.003 value_exit^2 + -0.005 value_exit*travel_duration + 0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 25/1000 --- L(Train): 0.0168013 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.061 1 + 0.796 value_stay[t] + 0.23 reward + 0.061 harvest_duration + -0.197 value_stay^2 + 0.096 value_stay*reward + -0.206 value_stay*harvest_duration + 0.232 reward^2 + 0.23 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.998 value_exit[t] + -0.001 travel_duration + 0.002 value_exit^2 + -0.004 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 26/1000 --- L(Train): 0.0221422 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.062 1 + 0.791 value_stay[t] + 0.237 reward + 0.062 harvest_duration + -0.2 value_stay^2 + 0.107 value_stay*reward + -0.21 value_stay*harvest_duration + 0.24 reward^2 + 0.238 reward*harvest_duration + 0.062 harvest_duration^2 \n",
      "value_exit[t+1] = -0.003 1 + 0.999 value_exit[t] + -0.002 travel_duration + 0.001 value_exit^2 + -0.003 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 27/1000 --- L(Train): 0.0259015 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.062 1 + 0.786 value_stay[t] + 0.245 reward + 0.062 harvest_duration + -0.203 value_stay^2 + 0.117 value_stay*reward + -0.215 value_stay*harvest_duration + 0.247 reward^2 + 0.245 reward*harvest_duration + 0.062 harvest_duration^2 \n",
      "value_exit[t+1] = -0.004 1 + 0.999 value_exit[t] + -0.003 travel_duration + 0.0 value_exit^2 + -0.003 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 28/1000 --- L(Train): 0.0232896 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.061 1 + 0.782 value_stay[t] + 0.252 reward + 0.062 harvest_duration + -0.206 value_stay^2 + 0.126 value_stay*reward + -0.219 value_stay*harvest_duration + 0.254 reward^2 + 0.252 reward*harvest_duration + 0.062 harvest_duration^2 \n",
      "value_exit[t+1] = -0.003 1 + 0.999 value_exit[t] + -0.002 travel_duration + 0.001 value_exit^2 + -0.004 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 29/1000 --- L(Train): 0.0171324 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.06 1 + 0.778 value_stay[t] + 0.259 reward + 0.06 harvest_duration + -0.209 value_stay^2 + 0.136 value_stay*reward + -0.223 value_stay*harvest_duration + 0.261 reward^2 + 0.259 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.998 value_exit[t] + -0.002 travel_duration + 0.001 value_exit^2 + -0.005 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 30/1000 --- L(Train): 0.0134005 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.059 1 + 0.774 value_stay[t] + 0.266 reward + 0.06 harvest_duration + -0.211 value_stay^2 + 0.146 value_stay*reward + -0.227 value_stay*harvest_duration + 0.268 reward^2 + 0.266 reward*harvest_duration + 0.06 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.997 value_exit[t] + -0.001 travel_duration + 0.002 value_exit^2 + -0.006 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 31/1000 --- L(Train): 0.0144461 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.059 1 + 0.771 value_stay[t] + 0.272 reward + 0.059 harvest_duration + -0.213 value_stay^2 + 0.155 value_stay*reward + -0.231 value_stay*harvest_duration + 0.274 reward^2 + 0.273 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.995 value_exit[t] + 0.0 travel_duration + 0.003 value_exit^2 + -0.007 value_exit*travel_duration + 0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 32/1000 --- L(Train): 0.0172947 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.058 1 + 0.768 value_stay[t] + 0.278 reward + 0.058 harvest_duration + -0.214 value_stay^2 + 0.165 value_stay*reward + -0.234 value_stay*harvest_duration + 0.28 reward^2 + 0.279 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.995 value_exit[t] + 0.001 travel_duration + 0.004 value_exit^2 + -0.008 value_exit*travel_duration + 0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 33/1000 --- L(Train): 0.0177888 --- L(Val, SINDy): 0.0000000 --- Time: 0.28s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.058 1 + 0.765 value_stay[t] + 0.284 reward + 0.058 harvest_duration + -0.215 value_stay^2 + 0.175 value_stay*reward + -0.236 value_stay*harvest_duration + 0.286 reward^2 + 0.285 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.995 value_exit[t] + 0.001 travel_duration + 0.003 value_exit^2 + -0.008 value_exit*travel_duration + 0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 34/1000 --- L(Train): 0.0151986 --- L(Val, SINDy): 0.0000000 --- Time: 0.27s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.057 1 + 0.763 value_stay[t] + 0.29 reward + 0.057 harvest_duration + -0.216 value_stay^2 + 0.184 value_stay*reward + -0.239 value_stay*harvest_duration + 0.291 reward^2 + 0.291 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.995 value_exit[t] + 0.001 travel_duration + 0.003 value_exit^2 + -0.008 value_exit*travel_duration + 0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 35/1000 --- L(Train): 0.0122926 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.055 1 + 0.76 value_stay[t] + 0.296 reward + 0.056 harvest_duration + -0.217 value_stay^2 + 0.192 value_stay*reward + -0.241 value_stay*harvest_duration + 0.297 reward^2 + 0.296 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.995 value_exit[t] + -0.0 travel_duration + 0.002 value_exit^2 + -0.007 value_exit*travel_duration + -0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 36/1000 --- L(Train): 0.0116654 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.054 1 + 0.758 value_stay[t] + 0.301 reward + 0.054 harvest_duration + -0.217 value_stay^2 + 0.201 value_stay*reward + -0.243 value_stay*harvest_duration + 0.301 reward^2 + 0.301 reward*harvest_duration + 0.054 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.996 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.007 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 37/1000 --- L(Train): 0.0129875 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.053 1 + 0.756 value_stay[t] + 0.306 reward + 0.053 harvest_duration + -0.218 value_stay^2 + 0.209 value_stay*reward + -0.245 value_stay*harvest_duration + 0.306 reward^2 + 0.306 reward*harvest_duration + 0.053 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.997 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.006 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 38/1000 --- L(Train): 0.0139412 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.052 1 + 0.755 value_stay[t] + 0.31 reward + 0.052 harvest_duration + -0.218 value_stay^2 + 0.217 value_stay*reward + -0.247 value_stay*harvest_duration + 0.311 reward^2 + 0.311 reward*harvest_duration + 0.052 harvest_duration^2 \n",
      "value_exit[t+1] = -0.003 1 + 0.997 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.006 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 39/1000 --- L(Train): 0.0131458 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.051 1 + 0.753 value_stay[t] + 0.315 reward + 0.051 harvest_duration + -0.218 value_stay^2 + 0.224 value_stay*reward + -0.249 value_stay*harvest_duration + 0.315 reward^2 + 0.315 reward*harvest_duration + 0.051 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.996 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.007 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 40/1000 --- L(Train): 0.0114825 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.05 1 + 0.752 value_stay[t] + 0.319 reward + 0.05 harvest_duration + -0.218 value_stay^2 + 0.231 value_stay*reward + -0.25 value_stay*harvest_duration + 0.319 reward^2 + 0.319 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.996 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.007 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 41/1000 --- L(Train): 0.0106504 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.75 value_stay[t] + 0.323 reward + 0.049 harvest_duration + -0.217 value_stay^2 + 0.237 value_stay*reward + -0.251 value_stay*harvest_duration + 0.322 reward^2 + 0.323 reward*harvest_duration + 0.049 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.995 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.008 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 42/1000 --- L(Train): 0.0111004 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.749 value_stay[t] + 0.326 reward + 0.048 harvest_duration + -0.217 value_stay^2 + 0.243 value_stay*reward + -0.252 value_stay*harvest_duration + 0.325 reward^2 + 0.326 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.994 value_exit[t] + -0.0 travel_duration + 0.001 value_exit^2 + -0.009 value_exit*travel_duration + -0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 43/1000 --- L(Train): 0.0117764 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.748 value_stay[t] + 0.329 reward + 0.047 harvest_duration + -0.217 value_stay^2 + 0.248 value_stay*reward + -0.254 value_stay*harvest_duration + 0.328 reward^2 + 0.33 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.994 value_exit[t] + 0.0 travel_duration + 0.002 value_exit^2 + -0.009 value_exit*travel_duration + 0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 44/1000 --- L(Train): 0.0116133 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.747 value_stay[t] + 0.332 reward + 0.046 harvest_duration + -0.216 value_stay^2 + 0.252 value_stay*reward + -0.254 value_stay*harvest_duration + 0.331 reward^2 + 0.333 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.994 value_exit[t] + 0.0 travel_duration + 0.002 value_exit^2 + -0.01 value_exit*travel_duration + 0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 45/1000 --- L(Train): 0.0107543 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.746 value_stay[t] + 0.335 reward + 0.045 harvest_duration + -0.216 value_stay^2 + 0.256 value_stay*reward + -0.255 value_stay*harvest_duration + 0.333 reward^2 + 0.335 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.994 value_exit[t] + -0.0 travel_duration + 0.001 value_exit^2 + -0.01 value_exit*travel_duration + -0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 46/1000 --- L(Train): 0.0101362 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.746 value_stay[t] + 0.337 reward + 0.045 harvest_duration + -0.215 value_stay^2 + 0.26 value_stay*reward + -0.256 value_stay*harvest_duration + 0.336 reward^2 + 0.338 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.994 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.009 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 47/1000 --- L(Train): 0.0102401 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.34 reward + 0.044 harvest_duration + -0.215 value_stay^2 + 0.263 value_stay*reward + -0.257 value_stay*harvest_duration + 0.338 reward^2 + 0.34 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.995 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.009 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 48/1000 --- L(Train): 0.0106155 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.744 value_stay[t] + 0.342 reward + 0.043 harvest_duration + -0.214 value_stay^2 + 0.265 value_stay*reward + -0.257 value_stay*harvest_duration + 0.339 reward^2 + 0.342 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.995 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.009 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 49/1000 --- L(Train): 0.0105971 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.744 value_stay[t] + 0.343 reward + 0.043 harvest_duration + -0.214 value_stay^2 + 0.266 value_stay*reward + -0.258 value_stay*harvest_duration + 0.341 reward^2 + 0.344 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.995 value_exit[t] + -0.001 travel_duration + -0.001 value_exit^2 + -0.009 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 50/1000 --- L(Train): 0.0101414 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.743 value_stay[t] + 0.345 reward + 0.042 harvest_duration + -0.213 value_stay^2 + 0.267 value_stay*reward + -0.259 value_stay*harvest_duration + 0.342 reward^2 + 0.345 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.002 1 + 0.995 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.01 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 51/1000 --- L(Train): 0.0097495 --- L(Val, SINDy): 0.0000000 --- Time: 0.28s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.743 value_stay[t] + 0.346 reward + 0.042 harvest_duration + -0.212 value_stay^2 + 0.268 value_stay*reward + -0.259 value_stay*harvest_duration + 0.343 reward^2 + 0.346 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.994 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.01 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 52/1000 --- L(Train): 0.0097491 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.742 value_stay[t] + 0.347 reward + 0.042 harvest_duration + -0.212 value_stay^2 + 0.268 value_stay*reward + -0.259 value_stay*harvest_duration + 0.344 reward^2 + 0.348 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.994 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.011 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 53/1000 --- L(Train): 0.0099314 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.742 value_stay[t] + 0.348 reward + 0.042 harvest_duration + -0.211 value_stay^2 + 0.267 value_stay*reward + -0.26 value_stay*harvest_duration + 0.344 reward^2 + 0.348 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.993 value_exit[t] + -0.0 travel_duration + 0.001 value_exit^2 + -0.011 value_exit*travel_duration + -0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 54/1000 --- L(Train): 0.0099134 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.741 value_stay[t] + 0.349 reward + 0.042 harvest_duration + -0.211 value_stay^2 + 0.266 value_stay*reward + -0.26 value_stay*harvest_duration + 0.345 reward^2 + 0.349 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.993 value_exit[t] + -0.0 travel_duration + 0.001 value_exit^2 + -0.012 value_exit*travel_duration + -0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 55/1000 --- L(Train): 0.0096457 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.741 value_stay[t] + 0.349 reward + 0.042 harvest_duration + -0.211 value_stay^2 + 0.264 value_stay*reward + -0.261 value_stay*harvest_duration + 0.345 reward^2 + 0.35 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.993 value_exit[t] + -0.0 travel_duration + 0.001 value_exit^2 + -0.012 value_exit*travel_duration + -0.0 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 56/1000 --- L(Train): 0.0094074 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.741 value_stay[t] + 0.35 reward + 0.042 harvest_duration + -0.21 value_stay^2 + 0.263 value_stay*reward + -0.261 value_stay*harvest_duration + 0.345 reward^2 + 0.35 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.993 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.012 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 57/1000 --- L(Train): 0.0093887 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.74 value_stay[t] + 0.35 reward + 0.042 harvest_duration + -0.209 value_stay^2 + 0.261 value_stay*reward + -0.261 value_stay*harvest_duration + 0.345 reward^2 + 0.35 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.993 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.012 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 58/1000 --- L(Train): 0.0094670 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.74 value_stay[t] + 0.35 reward + 0.043 harvest_duration + -0.209 value_stay^2 + 0.258 value_stay*reward + -0.261 value_stay*harvest_duration + 0.345 reward^2 + 0.351 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.993 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.012 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 59/1000 --- L(Train): 0.0094267 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.74 value_stay[t] + 0.35 reward + 0.043 harvest_duration + -0.208 value_stay^2 + 0.255 value_stay*reward + -0.262 value_stay*harvest_duration + 0.345 reward^2 + 0.351 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.993 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.012 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 60/1000 --- L(Train): 0.0092531 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.74 value_stay[t] + 0.35 reward + 0.043 harvest_duration + -0.208 value_stay^2 + 0.252 value_stay*reward + -0.262 value_stay*harvest_duration + 0.345 reward^2 + 0.351 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.993 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.012 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 61/1000 --- L(Train): 0.0091118 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.74 value_stay[t] + 0.35 reward + 0.043 harvest_duration + -0.207 value_stay^2 + 0.249 value_stay*reward + -0.262 value_stay*harvest_duration + 0.344 reward^2 + 0.35 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.993 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.013 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 62/1000 --- L(Train): 0.0090960 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.74 value_stay[t] + 0.35 reward + 0.043 harvest_duration + -0.207 value_stay^2 + 0.246 value_stay*reward + -0.262 value_stay*harvest_duration + 0.344 reward^2 + 0.35 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.013 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 63/1000 --- L(Train): 0.0091191 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.74 value_stay[t] + 0.35 reward + 0.044 harvest_duration + -0.206 value_stay^2 + 0.243 value_stay*reward + -0.262 value_stay*harvest_duration + 0.343 reward^2 + 0.35 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.014 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 64/1000 --- L(Train): 0.0090649 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.74 value_stay[t] + 0.349 reward + 0.044 harvest_duration + -0.205 value_stay^2 + 0.24 value_stay*reward + -0.262 value_stay*harvest_duration + 0.342 reward^2 + 0.35 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.014 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 65/1000 --- L(Train): 0.0089476 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.74 value_stay[t] + 0.349 reward + 0.044 harvest_duration + -0.205 value_stay^2 + 0.236 value_stay*reward + -0.262 value_stay*harvest_duration + 0.342 reward^2 + 0.349 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.014 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 66/1000 --- L(Train): 0.0088654 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.74 value_stay[t] + 0.349 reward + 0.044 harvest_duration + -0.204 value_stay^2 + 0.233 value_stay*reward + -0.262 value_stay*harvest_duration + 0.341 reward^2 + 0.349 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.014 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 67/1000 --- L(Train): 0.0088527 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.74 value_stay[t] + 0.348 reward + 0.045 harvest_duration + -0.203 value_stay^2 + 0.229 value_stay*reward + -0.262 value_stay*harvest_duration + 0.34 reward^2 + 0.348 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.014 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 68/1000 --- L(Train): 0.0088459 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.74 value_stay[t] + 0.348 reward + 0.045 harvest_duration + -0.202 value_stay^2 + 0.226 value_stay*reward + -0.262 value_stay*harvest_duration + 0.339 reward^2 + 0.348 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.014 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 69/1000 --- L(Train): 0.0087893 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.74 value_stay[t] + 0.347 reward + 0.045 harvest_duration + -0.201 value_stay^2 + 0.223 value_stay*reward + -0.261 value_stay*harvest_duration + 0.339 reward^2 + 0.348 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.015 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 70/1000 --- L(Train): 0.0087093 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.74 value_stay[t] + 0.347 reward + 0.045 harvest_duration + -0.2 value_stay^2 + 0.22 value_stay*reward + -0.261 value_stay*harvest_duration + 0.338 reward^2 + 0.347 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.015 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 71/1000 --- L(Train): 0.0086626 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.741 value_stay[t] + 0.346 reward + 0.045 harvest_duration + -0.199 value_stay^2 + 0.216 value_stay*reward + -0.261 value_stay*harvest_duration + 0.337 reward^2 + 0.347 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.015 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 72/1000 --- L(Train): 0.0086504 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.741 value_stay[t] + 0.346 reward + 0.045 harvest_duration + -0.198 value_stay^2 + 0.213 value_stay*reward + -0.261 value_stay*harvest_duration + 0.336 reward^2 + 0.346 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.016 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 73/1000 --- L(Train): 0.0086275 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.741 value_stay[t] + 0.345 reward + 0.045 harvest_duration + -0.197 value_stay^2 + 0.211 value_stay*reward + -0.26 value_stay*harvest_duration + 0.336 reward^2 + 0.346 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.016 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 74/1000 --- L(Train): 0.0085758 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.741 value_stay[t] + 0.345 reward + 0.046 harvest_duration + -0.196 value_stay^2 + 0.208 value_stay*reward + -0.26 value_stay*harvest_duration + 0.335 reward^2 + 0.345 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.016 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 75/1000 --- L(Train): 0.0085237 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.742 value_stay[t] + 0.345 reward + 0.045 harvest_duration + -0.195 value_stay^2 + 0.205 value_stay*reward + -0.26 value_stay*harvest_duration + 0.334 reward^2 + 0.345 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.016 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 76/1000 --- L(Train): 0.0084957 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.742 value_stay[t] + 0.344 reward + 0.045 harvest_duration + -0.193 value_stay^2 + 0.202 value_stay*reward + -0.26 value_stay*harvest_duration + 0.333 reward^2 + 0.345 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.991 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.017 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 77/1000 --- L(Train): 0.0084790 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.742 value_stay[t] + 0.344 reward + 0.045 harvest_duration + -0.192 value_stay^2 + 0.2 value_stay*reward + -0.259 value_stay*harvest_duration + 0.333 reward^2 + 0.344 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.991 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.017 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 78/1000 --- L(Train): 0.0084492 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.743 value_stay[t] + 0.344 reward + 0.045 harvest_duration + -0.191 value_stay^2 + 0.197 value_stay*reward + -0.259 value_stay*harvest_duration + 0.332 reward^2 + 0.344 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.001 1 + 0.991 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.017 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 79/1000 --- L(Train): 0.0084070 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.743 value_stay[t] + 0.344 reward + 0.045 harvest_duration + -0.19 value_stay^2 + 0.195 value_stay*reward + -0.259 value_stay*harvest_duration + 0.332 reward^2 + 0.344 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.017 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 80/1000 --- L(Train): 0.0083719 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.743 value_stay[t] + 0.343 reward + 0.045 harvest_duration + -0.189 value_stay^2 + 0.192 value_stay*reward + -0.258 value_stay*harvest_duration + 0.331 reward^2 + 0.344 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.018 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 81/1000 --- L(Train): 0.0083509 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.744 value_stay[t] + 0.343 reward + 0.045 harvest_duration + -0.187 value_stay^2 + 0.19 value_stay*reward + -0.258 value_stay*harvest_duration + 0.33 reward^2 + 0.344 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.018 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 82/1000 --- L(Train): 0.0083299 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.744 value_stay[t] + 0.343 reward + 0.045 harvest_duration + -0.186 value_stay^2 + 0.188 value_stay*reward + -0.258 value_stay*harvest_duration + 0.33 reward^2 + 0.344 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.018 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 83/1000 --- L(Train): 0.0082983 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.744 value_stay[t] + 0.343 reward + 0.045 harvest_duration + -0.185 value_stay^2 + 0.186 value_stay*reward + -0.257 value_stay*harvest_duration + 0.329 reward^2 + 0.343 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.019 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 84/1000 --- L(Train): 0.0082640 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.744 value_stay[t] + 0.343 reward + 0.045 harvest_duration + -0.184 value_stay^2 + 0.184 value_stay*reward + -0.257 value_stay*harvest_duration + 0.329 reward^2 + 0.343 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.019 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 85/1000 --- L(Train): 0.0082392 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.343 reward + 0.044 harvest_duration + -0.182 value_stay^2 + 0.181 value_stay*reward + -0.257 value_stay*harvest_duration + 0.329 reward^2 + 0.343 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.019 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 86/1000 --- L(Train): 0.0082196 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.343 reward + 0.044 harvest_duration + -0.181 value_stay^2 + 0.179 value_stay*reward + -0.257 value_stay*harvest_duration + 0.328 reward^2 + 0.344 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.019 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 87/1000 --- L(Train): 0.0081944 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.343 reward + 0.044 harvest_duration + -0.18 value_stay^2 + 0.177 value_stay*reward + -0.257 value_stay*harvest_duration + 0.328 reward^2 + 0.344 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.02 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 88/1000 --- L(Train): 0.0081642 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.343 reward + 0.044 harvest_duration + -0.179 value_stay^2 + 0.175 value_stay*reward + -0.257 value_stay*harvest_duration + 0.328 reward^2 + 0.344 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.02 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 89/1000 --- L(Train): 0.0081379 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.344 reward + 0.044 harvest_duration + -0.178 value_stay^2 + 0.173 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.344 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.02 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 90/1000 --- L(Train): 0.0081171 --- L(Val, SINDy): 0.0000000 --- Time: 0.28s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.344 reward + 0.044 harvest_duration + -0.177 value_stay^2 + 0.171 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.344 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.021 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 91/1000 --- L(Train): 0.0080955 --- L(Val, SINDy): 0.0000000 --- Time: 0.27s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.344 reward + 0.044 harvest_duration + -0.176 value_stay^2 + 0.169 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.344 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.021 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 92/1000 --- L(Train): 0.0080700 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.344 reward + 0.044 harvest_duration + -0.175 value_stay^2 + 0.167 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.345 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.021 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 93/1000 --- L(Train): 0.0080443 --- L(Val, SINDy): 0.0000000 --- Time: 0.28s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.345 reward + 0.044 harvest_duration + -0.174 value_stay^2 + 0.165 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.345 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.021 value_exit*travel_duration + -0.001 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 94/1000 --- L(Train): 0.0080229 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.345 reward + 0.044 harvest_duration + -0.173 value_stay^2 + 0.163 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.345 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.022 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 95/1000 --- L(Train): 0.0080031 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.345 reward + 0.044 harvest_duration + -0.172 value_stay^2 + 0.161 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.346 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.022 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 96/1000 --- L(Train): 0.0079800 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.745 value_stay[t] + 0.346 reward + 0.044 harvest_duration + -0.171 value_stay^2 + 0.159 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.346 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.022 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 97/1000 --- L(Train): 0.0079553 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.745 value_stay[t] + 0.346 reward + 0.044 harvest_duration + -0.17 value_stay^2 + 0.157 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.346 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.022 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 98/1000 --- L(Train): 0.0079336 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.744 value_stay[t] + 0.347 reward + 0.044 harvest_duration + -0.169 value_stay^2 + 0.155 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.347 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.023 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 99/1000 --- L(Train): 0.0079138 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.744 value_stay[t] + 0.347 reward + 0.044 harvest_duration + -0.169 value_stay^2 + 0.154 value_stay*reward + -0.257 value_stay*harvest_duration + 0.327 reward^2 + 0.347 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.023 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 100/1000 --- L(Train): 0.0078920 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.744 value_stay[t] + 0.347 reward + 0.044 harvest_duration + -0.168 value_stay^2 + 0.152 value_stay*reward + -0.258 value_stay*harvest_duration + 0.327 reward^2 + 0.348 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.023 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 101/1000 --- L(Train): 0.0078692 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.744 value_stay[t] + 0.348 reward + 0.043 harvest_duration + -0.167 value_stay^2 + 0.15 value_stay*reward + -0.258 value_stay*harvest_duration + 0.327 reward^2 + 0.348 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.024 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 102/1000 --- L(Train): 0.0078481 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.744 value_stay[t] + 0.348 reward + 0.043 harvest_duration + -0.166 value_stay^2 + 0.148 value_stay*reward + -0.258 value_stay*harvest_duration + 0.327 reward^2 + 0.349 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.024 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 103/1000 --- L(Train): 0.0078283 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.744 value_stay[t] + 0.349 reward + 0.043 harvest_duration + -0.165 value_stay^2 + 0.146 value_stay*reward + -0.258 value_stay*harvest_duration + 0.327 reward^2 + 0.349 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.024 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 104/1000 --- L(Train): 0.0078079 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.743 value_stay[t] + 0.35 reward + 0.043 harvest_duration + -0.164 value_stay^2 + 0.144 value_stay*reward + -0.258 value_stay*harvest_duration + 0.327 reward^2 + 0.35 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.024 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 105/1000 --- L(Train): 0.0077873 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.743 value_stay[t] + 0.35 reward + 0.043 harvest_duration + -0.164 value_stay^2 + 0.142 value_stay*reward + -0.259 value_stay*harvest_duration + 0.327 reward^2 + 0.35 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.025 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 106/1000 --- L(Train): 0.0077673 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.743 value_stay[t] + 0.351 reward + 0.043 harvest_duration + -0.163 value_stay^2 + 0.14 value_stay*reward + -0.259 value_stay*harvest_duration + 0.327 reward^2 + 0.351 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.025 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 107/1000 --- L(Train): 0.0077475 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.743 value_stay[t] + 0.351 reward + 0.043 harvest_duration + -0.162 value_stay^2 + 0.139 value_stay*reward + -0.259 value_stay*harvest_duration + 0.327 reward^2 + 0.352 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.025 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 108/1000 --- L(Train): 0.0077274 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.742 value_stay[t] + 0.352 reward + 0.043 harvest_duration + -0.161 value_stay^2 + 0.137 value_stay*reward + -0.259 value_stay*harvest_duration + 0.327 reward^2 + 0.352 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.026 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 109/1000 --- L(Train): 0.0077075 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.742 value_stay[t] + 0.352 reward + 0.043 harvest_duration + -0.16 value_stay^2 + 0.135 value_stay*reward + -0.259 value_stay*harvest_duration + 0.327 reward^2 + 0.353 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.026 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 110/1000 --- L(Train): 0.0076875 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.742 value_stay[t] + 0.353 reward + 0.043 harvest_duration + -0.159 value_stay^2 + 0.133 value_stay*reward + -0.26 value_stay*harvest_duration + 0.327 reward^2 + 0.353 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.026 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 111/1000 --- L(Train): 0.0076684 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.742 value_stay[t] + 0.353 reward + 0.043 harvest_duration + -0.158 value_stay^2 + 0.132 value_stay*reward + -0.26 value_stay*harvest_duration + 0.328 reward^2 + 0.354 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.026 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 112/1000 --- L(Train): 0.0076495 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.742 value_stay[t] + 0.354 reward + 0.043 harvest_duration + -0.158 value_stay^2 + 0.13 value_stay*reward + -0.26 value_stay*harvest_duration + 0.328 reward^2 + 0.354 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.027 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 113/1000 --- L(Train): 0.0076303 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.741 value_stay[t] + 0.355 reward + 0.043 harvest_duration + -0.157 value_stay^2 + 0.128 value_stay*reward + -0.26 value_stay*harvest_duration + 0.328 reward^2 + 0.355 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.027 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 114/1000 --- L(Train): 0.0076111 --- L(Val, SINDy): 0.0000000 --- Time: 0.27s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.741 value_stay[t] + 0.355 reward + 0.043 harvest_duration + -0.156 value_stay^2 + 0.126 value_stay*reward + -0.26 value_stay*harvest_duration + 0.328 reward^2 + 0.356 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.027 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 115/1000 --- L(Train): 0.0075930 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.741 value_stay[t] + 0.356 reward + 0.043 harvest_duration + -0.155 value_stay^2 + 0.125 value_stay*reward + -0.261 value_stay*harvest_duration + 0.328 reward^2 + 0.356 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.028 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 116/1000 --- L(Train): 0.0075748 --- L(Val, SINDy): 0.0000000 --- Time: 0.27s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.741 value_stay[t] + 0.356 reward + 0.043 harvest_duration + -0.154 value_stay^2 + 0.123 value_stay*reward + -0.261 value_stay*harvest_duration + 0.328 reward^2 + 0.357 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.028 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 117/1000 --- L(Train): 0.0075561 --- L(Val, SINDy): 0.0000000 --- Time: 0.14s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.741 value_stay[t] + 0.357 reward + 0.043 harvest_duration + -0.153 value_stay^2 + 0.121 value_stay*reward + -0.261 value_stay*harvest_duration + 0.328 reward^2 + 0.357 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.028 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 118/1000 --- L(Train): 0.0075383 --- L(Val, SINDy): 0.0000000 --- Time: 0.09s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.741 value_stay[t] + 0.358 reward + 0.043 harvest_duration + -0.152 value_stay^2 + 0.119 value_stay*reward + -0.261 value_stay*harvest_duration + 0.328 reward^2 + 0.358 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.028 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 119/1000 --- L(Train): 0.0075211 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.74 value_stay[t] + 0.358 reward + 0.042 harvest_duration + -0.151 value_stay^2 + 0.118 value_stay*reward + -0.261 value_stay*harvest_duration + 0.328 reward^2 + 0.358 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.029 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 120/1000 --- L(Train): 0.0075035 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.74 value_stay[t] + 0.359 reward + 0.042 harvest_duration + -0.15 value_stay^2 + 0.116 value_stay*reward + -0.261 value_stay*harvest_duration + 0.328 reward^2 + 0.359 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.029 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 121/1000 --- L(Train): 0.0074857 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.74 value_stay[t] + 0.359 reward + 0.042 harvest_duration + -0.149 value_stay^2 + 0.114 value_stay*reward + -0.262 value_stay*harvest_duration + 0.328 reward^2 + 0.36 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.029 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 122/1000 --- L(Train): 0.0074682 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.74 value_stay[t] + 0.36 reward + 0.042 harvest_duration + -0.148 value_stay^2 + 0.112 value_stay*reward + -0.262 value_stay*harvest_duration + 0.328 reward^2 + 0.36 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.03 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 123/1000 --- L(Train): 0.0074510 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.74 value_stay[t] + 0.36 reward + 0.042 harvest_duration + -0.147 value_stay^2 + 0.111 value_stay*reward + -0.262 value_stay*harvest_duration + 0.328 reward^2 + 0.361 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.03 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 124/1000 --- L(Train): 0.0074348 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.74 value_stay[t] + 0.361 reward + 0.042 harvest_duration + -0.146 value_stay^2 + 0.109 value_stay*reward + -0.262 value_stay*harvest_duration + 0.328 reward^2 + 0.361 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.03 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 125/1000 --- L(Train): 0.0074179 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.739 value_stay[t] + 0.361 reward + 0.042 harvest_duration + -0.145 value_stay^2 + 0.107 value_stay*reward + -0.262 value_stay*harvest_duration + 0.328 reward^2 + 0.362 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.03 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 126/1000 --- L(Train): 0.0074011 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.739 value_stay[t] + 0.362 reward + 0.042 harvest_duration + -0.145 value_stay^2 + 0.105 value_stay*reward + -0.262 value_stay*harvest_duration + 0.328 reward^2 + 0.362 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.031 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 127/1000 --- L(Train): 0.0073850 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.739 value_stay[t] + 0.362 reward + 0.042 harvest_duration + -0.144 value_stay^2 + 0.103 value_stay*reward + -0.263 value_stay*harvest_duration + 0.328 reward^2 + 0.363 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.031 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 128/1000 --- L(Train): 0.0073692 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.739 value_stay[t] + 0.363 reward + 0.042 harvest_duration + -0.143 value_stay^2 + 0.101 value_stay*reward + -0.263 value_stay*harvest_duration + 0.328 reward^2 + 0.363 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.031 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 129/1000 --- L(Train): 0.0073533 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.739 value_stay[t] + 0.363 reward + 0.042 harvest_duration + -0.142 value_stay^2 + 0.099 value_stay*reward + -0.263 value_stay*harvest_duration + 0.328 reward^2 + 0.364 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.032 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 130/1000 --- L(Train): 0.0073370 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.739 value_stay[t] + 0.364 reward + 0.042 harvest_duration + -0.141 value_stay^2 + 0.097 value_stay*reward + -0.263 value_stay*harvest_duration + 0.328 reward^2 + 0.364 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.032 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 131/1000 --- L(Train): 0.0073214 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.739 value_stay[t] + 0.364 reward + 0.042 harvest_duration + -0.14 value_stay^2 + 0.095 value_stay*reward + -0.263 value_stay*harvest_duration + 0.328 reward^2 + 0.365 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.032 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 132/1000 --- L(Train): 0.0073062 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.738 value_stay[t] + 0.365 reward + 0.042 harvest_duration + -0.139 value_stay^2 + 0.094 value_stay*reward + -0.263 value_stay*harvest_duration + 0.328 reward^2 + 0.365 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.033 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 133/1000 --- L(Train): 0.0072915 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.738 value_stay[t] + 0.365 reward + 0.041 harvest_duration + -0.138 value_stay^2 + 0.092 value_stay*reward + -0.263 value_stay*harvest_duration + 0.328 reward^2 + 0.366 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.033 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 134/1000 --- L(Train): 0.0072772 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.738 value_stay[t] + 0.366 reward + 0.041 harvest_duration + -0.137 value_stay^2 + 0.09 value_stay*reward + -0.264 value_stay*harvest_duration + 0.328 reward^2 + 0.366 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.033 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 135/1000 --- L(Train): 0.0072631 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.738 value_stay[t] + 0.366 reward + 0.041 harvest_duration + -0.136 value_stay^2 + 0.088 value_stay*reward + -0.264 value_stay*harvest_duration + 0.328 reward^2 + 0.367 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.033 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 136/1000 --- L(Train): 0.0072486 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.738 value_stay[t] + 0.367 reward + 0.041 harvest_duration + -0.135 value_stay^2 + 0.086 value_stay*reward + -0.264 value_stay*harvest_duration + 0.328 reward^2 + 0.367 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.034 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 137/1000 --- L(Train): 0.0072335 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.738 value_stay[t] + 0.367 reward + 0.041 harvest_duration + -0.134 value_stay^2 + 0.084 value_stay*reward + -0.264 value_stay*harvest_duration + 0.328 reward^2 + 0.368 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.034 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 138/1000 --- L(Train): 0.0072190 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.738 value_stay[t] + 0.368 reward + 0.041 harvest_duration + -0.133 value_stay^2 + 0.082 value_stay*reward + -0.264 value_stay*harvest_duration + 0.327 reward^2 + 0.368 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.034 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 139/1000 --- L(Train): 0.0072052 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.737 value_stay[t] + 0.368 reward + 0.041 harvest_duration + -0.132 value_stay^2 + 0.08 value_stay*reward + -0.264 value_stay*harvest_duration + 0.327 reward^2 + 0.369 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.035 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 140/1000 --- L(Train): 0.0071906 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.737 value_stay[t] + 0.369 reward + 0.041 harvest_duration + -0.131 value_stay^2 + 0.078 value_stay*reward + -0.264 value_stay*harvest_duration + 0.327 reward^2 + 0.369 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.035 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 141/1000 --- L(Train): 0.0071763 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.737 value_stay[t] + 0.369 reward + 0.041 harvest_duration + -0.13 value_stay^2 + 0.076 value_stay*reward + -0.264 value_stay*harvest_duration + 0.327 reward^2 + 0.37 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.035 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 142/1000 --- L(Train): 0.0071629 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.737 value_stay[t] + 0.37 reward + 0.041 harvest_duration + -0.129 value_stay^2 + 0.074 value_stay*reward + -0.265 value_stay*harvest_duration + 0.327 reward^2 + 0.37 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.035 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 143/1000 --- L(Train): 0.0071491 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.737 value_stay[t] + 0.37 reward + 0.041 harvest_duration + -0.128 value_stay^2 + 0.072 value_stay*reward + -0.265 value_stay*harvest_duration + 0.327 reward^2 + 0.371 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.036 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 144/1000 --- L(Train): 0.0071357 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.737 value_stay[t] + 0.371 reward + 0.041 harvest_duration + -0.127 value_stay^2 + 0.07 value_stay*reward + -0.265 value_stay*harvest_duration + 0.327 reward^2 + 0.371 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.036 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 145/1000 --- L(Train): 0.0071231 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.737 value_stay[t] + 0.371 reward + 0.041 harvest_duration + -0.126 value_stay^2 + 0.067 value_stay*reward + -0.265 value_stay*harvest_duration + 0.327 reward^2 + 0.372 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.036 value_exit*travel_duration + -0.002 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\u001b[H\u001b[2J\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 146/1000 --- L(Train): 0.0071100 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.737 value_stay[t] + 0.372 reward + 0.041 harvest_duration + -0.125 value_stay^2 + 0.065 value_stay*reward + -0.265 value_stay*harvest_duration + 0.327 reward^2 + 0.372 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.037 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 147/1000 --- L(Train): 0.0070968 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.736 value_stay[t] + 0.372 reward + 0.041 harvest_duration + -0.124 value_stay^2 + 0.063 value_stay*reward + -0.265 value_stay*harvest_duration + 0.326 reward^2 + 0.373 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.037 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 148/1000 --- L(Train): 0.0070842 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.736 value_stay[t] + 0.373 reward + 0.041 harvest_duration + -0.123 value_stay^2 + 0.061 value_stay*reward + -0.265 value_stay*harvest_duration + 0.326 reward^2 + 0.373 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.037 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 149/1000 --- L(Train): 0.0070712 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.736 value_stay[t] + 0.373 reward + 0.041 harvest_duration + -0.122 value_stay^2 + 0.059 value_stay*reward + -0.265 value_stay*harvest_duration + 0.326 reward^2 + 0.373 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.037 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 150/1000 --- L(Train): 0.0070591 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.736 value_stay[t] + 0.374 reward + 0.04 harvest_duration + -0.121 value_stay^2 + 0.057 value_stay*reward + -0.266 value_stay*harvest_duration + 0.326 reward^2 + 0.374 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.038 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 151/1000 --- L(Train): 0.0070471 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.736 value_stay[t] + 0.374 reward + 0.04 harvest_duration + -0.12 value_stay^2 + 0.055 value_stay*reward + -0.266 value_stay*harvest_duration + 0.326 reward^2 + 0.374 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.038 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 152/1000 --- L(Train): 0.0070345 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.736 value_stay[t] + 0.375 reward + 0.04 harvest_duration + -0.119 value_stay^2 + 0.053 value_stay*reward + -0.266 value_stay*harvest_duration + 0.326 reward^2 + 0.375 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.038 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 153/1000 --- L(Train): 0.0070222 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.736 value_stay[t] + 0.375 reward + 0.04 harvest_duration + -0.118 value_stay^2 + 0.051 value_stay*reward + -0.266 value_stay*harvest_duration + 0.326 reward^2 + 0.375 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.039 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 154/1000 --- L(Train): 0.0070103 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.736 value_stay[t] + 0.376 reward + 0.04 harvest_duration + -0.117 value_stay^2 + 0.049 value_stay*reward + -0.266 value_stay*harvest_duration + 0.325 reward^2 + 0.376 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.039 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 155/1000 --- L(Train): 0.0069985 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.735 value_stay[t] + 0.376 reward + 0.04 harvest_duration + -0.116 value_stay^2 + 0.048 value_stay*reward + -0.266 value_stay*harvest_duration + 0.325 reward^2 + 0.376 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.039 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 156/1000 --- L(Train): 0.0069870 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.735 value_stay[t] + 0.377 reward + 0.04 harvest_duration + -0.115 value_stay^2 + 0.046 value_stay*reward + -0.266 value_stay*harvest_duration + 0.325 reward^2 + 0.377 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.039 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 157/1000 --- L(Train): 0.0069757 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.735 value_stay[t] + 0.377 reward + 0.04 harvest_duration + -0.114 value_stay^2 + 0.044 value_stay*reward + -0.266 value_stay*harvest_duration + 0.325 reward^2 + 0.377 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.04 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 158/1000 --- L(Train): 0.0069645 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.735 value_stay[t] + 0.378 reward + 0.04 harvest_duration + -0.113 value_stay^2 + 0.042 value_stay*reward + -0.267 value_stay*harvest_duration + 0.325 reward^2 + 0.378 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.04 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 159/1000 --- L(Train): 0.0069533 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.735 value_stay[t] + 0.378 reward + 0.04 harvest_duration + -0.113 value_stay^2 + 0.04 value_stay*reward + -0.267 value_stay*harvest_duration + 0.325 reward^2 + 0.378 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.04 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 160/1000 --- L(Train): 0.0069427 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.735 value_stay[t] + 0.379 reward + 0.04 harvest_duration + -0.112 value_stay^2 + 0.038 value_stay*reward + -0.267 value_stay*harvest_duration + 0.325 reward^2 + 0.379 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.041 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 161/1000 --- L(Train): 0.0069316 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.735 value_stay[t] + 0.379 reward + 0.04 harvest_duration + -0.111 value_stay^2 + 0.036 value_stay*reward + -0.267 value_stay*harvest_duration + 0.324 reward^2 + 0.379 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.041 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 162/1000 --- L(Train): 0.0069205 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.735 value_stay[t] + 0.38 reward + 0.04 harvest_duration + -0.11 value_stay^2 + 0.034 value_stay*reward + -0.267 value_stay*harvest_duration + 0.324 reward^2 + 0.38 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.041 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 163/1000 --- L(Train): 0.0069095 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.734 value_stay[t] + 0.38 reward + 0.04 harvest_duration + -0.109 value_stay^2 + 0.032 value_stay*reward + -0.267 value_stay*harvest_duration + 0.324 reward^2 + 0.381 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.041 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 164/1000 --- L(Train): 0.0068990 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.734 value_stay[t] + 0.381 reward + 0.04 harvest_duration + -0.108 value_stay^2 + 0.03 value_stay*reward + -0.267 value_stay*harvest_duration + 0.324 reward^2 + 0.381 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.042 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 165/1000 --- L(Train): 0.0068888 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.734 value_stay[t] + 0.381 reward + 0.039 harvest_duration + -0.107 value_stay^2 + 0.028 value_stay*reward + -0.268 value_stay*harvest_duration + 0.324 reward^2 + 0.382 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.042 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 166/1000 --- L(Train): 0.0068784 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.734 value_stay[t] + 0.382 reward + 0.039 harvest_duration + -0.106 value_stay^2 + 0.026 value_stay*reward + -0.268 value_stay*harvest_duration + 0.324 reward^2 + 0.382 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.042 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 167/1000 --- L(Train): 0.0068684 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.734 value_stay[t] + 0.382 reward + 0.039 harvest_duration + -0.105 value_stay^2 + 0.024 value_stay*reward + -0.268 value_stay*harvest_duration + 0.323 reward^2 + 0.383 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.043 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 168/1000 --- L(Train): 0.0068587 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.734 value_stay[t] + 0.383 reward + 0.039 harvest_duration + -0.104 value_stay^2 + 0.022 value_stay*reward + -0.268 value_stay*harvest_duration + 0.323 reward^2 + 0.383 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.043 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 169/1000 --- L(Train): 0.0068495 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.734 value_stay[t] + 0.383 reward + 0.039 harvest_duration + -0.103 value_stay^2 + 0.02 value_stay*reward + -0.268 value_stay*harvest_duration + 0.323 reward^2 + 0.384 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.043 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 170/1000 --- L(Train): 0.0068402 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.733 value_stay[t] + 0.384 reward + 0.039 harvest_duration + -0.102 value_stay^2 + 0.018 value_stay*reward + -0.268 value_stay*harvest_duration + 0.323 reward^2 + 0.384 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.043 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 171/1000 --- L(Train): 0.0068310 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.733 value_stay[t] + 0.384 reward + 0.039 harvest_duration + -0.101 value_stay^2 + 0.016 value_stay*reward + -0.268 value_stay*harvest_duration + 0.323 reward^2 + 0.385 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.044 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 172/1000 --- L(Train): 0.0068214 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.733 value_stay[t] + 0.385 reward + 0.039 harvest_duration + -0.1 value_stay^2 + 0.014 value_stay*reward + -0.269 value_stay*harvest_duration + 0.323 reward^2 + 0.385 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.044 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 173/1000 --- L(Train): 0.0068115 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.733 value_stay[t] + 0.385 reward + 0.039 harvest_duration + -0.099 value_stay^2 + 0.012 value_stay*reward + -0.269 value_stay*harvest_duration + 0.322 reward^2 + 0.386 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.044 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 174/1000 --- L(Train): 0.0068023 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.733 value_stay[t] + 0.386 reward + 0.039 harvest_duration + -0.098 value_stay^2 + 0.01 value_stay*reward + -0.269 value_stay*harvest_duration + 0.322 reward^2 + 0.386 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.044 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 175/1000 --- L(Train): 0.0067934 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.733 value_stay[t] + 0.387 reward + 0.039 harvest_duration + -0.097 value_stay^2 + 0.008 value_stay*reward + -0.269 value_stay*harvest_duration + 0.322 reward^2 + 0.387 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.045 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 176/1000 --- L(Train): 0.0067844 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.733 value_stay[t] + 0.387 reward + 0.039 harvest_duration + -0.096 value_stay^2 + 0.006 value_stay*reward + -0.269 value_stay*harvest_duration + 0.322 reward^2 + 0.387 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.045 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 177/1000 --- L(Train): 0.0067757 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.732 value_stay[t] + 0.388 reward + 0.039 harvest_duration + -0.095 value_stay^2 + 0.004 value_stay*reward + -0.269 value_stay*harvest_duration + 0.322 reward^2 + 0.388 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.045 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 178/1000 --- L(Train): 0.0067670 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.732 value_stay[t] + 0.388 reward + 0.039 harvest_duration + -0.094 value_stay^2 + 0.002 value_stay*reward + -0.269 value_stay*harvest_duration + 0.321 reward^2 + 0.388 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.046 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 179/1000 --- L(Train): 0.0067582 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.732 value_stay[t] + 0.389 reward + 0.039 harvest_duration + -0.093 value_stay^2 + 0.0 value_stay*reward + -0.27 value_stay*harvest_duration + 0.321 reward^2 + 0.389 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.046 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 180/1000 --- L(Train): 0.0067494 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.732 value_stay[t] + 0.389 reward + 0.039 harvest_duration + -0.092 value_stay^2 + -0.002 value_stay*reward + -0.27 value_stay*harvest_duration + 0.321 reward^2 + 0.389 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.046 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 181/1000 --- L(Train): 0.0067407 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.732 value_stay[t] + 0.39 reward + 0.038 harvest_duration + -0.091 value_stay^2 + -0.003 value_stay*reward + -0.27 value_stay*harvest_duration + 0.321 reward^2 + 0.39 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.046 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 182/1000 --- L(Train): 0.0067320 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.732 value_stay[t] + 0.39 reward + 0.038 harvest_duration + -0.09 value_stay^2 + -0.003 value_stay*reward + -0.27 value_stay*harvest_duration + 0.321 reward^2 + 0.391 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.047 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 183/1000 --- L(Train): 0.0067237 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.732 value_stay[t] + 0.391 reward + 0.038 harvest_duration + -0.089 value_stay^2 + -0.002 value_stay*reward + -0.27 value_stay*harvest_duration + 0.32 reward^2 + 0.391 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.047 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 184/1000 --- L(Train): 0.0067160 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.731 value_stay[t] + 0.391 reward + 0.038 harvest_duration + -0.089 value_stay^2 + -0.0 value_stay*reward + -0.27 value_stay*harvest_duration + 0.32 reward^2 + 0.392 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.047 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 185/1000 --- L(Train): 0.0067082 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.037 1 + 0.731 value_stay[t] + 0.392 reward + 0.037 harvest_duration + -0.088 value_stay^2 + 0.002 value_stay*reward + -0.271 value_stay*harvest_duration + 0.32 reward^2 + 0.392 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.047 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 186/1000 --- L(Train): 0.0067001 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.037 1 + 0.731 value_stay[t] + 0.392 reward + 0.037 harvest_duration + -0.087 value_stay^2 + 0.003 value_stay*reward + -0.271 value_stay*harvest_duration + 0.32 reward^2 + 0.392 reward*harvest_duration + 0.037 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.048 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 187/1000 --- L(Train): 0.0066923 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.037 1 + 0.73 value_stay[t] + 0.393 reward + 0.037 harvest_duration + -0.086 value_stay^2 + 0.004 value_stay*reward + -0.271 value_stay*harvest_duration + 0.319 reward^2 + 0.393 reward*harvest_duration + 0.037 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.048 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 188/1000 --- L(Train): 0.0066845 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.037 1 + 0.73 value_stay[t] + 0.393 reward + 0.037 harvest_duration + -0.086 value_stay^2 + 0.005 value_stay*reward + -0.272 value_stay*harvest_duration + 0.319 reward^2 + 0.393 reward*harvest_duration + 0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.048 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 189/1000 --- L(Train): 0.0066767 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.037 1 + 0.73 value_stay[t] + 0.393 reward + 0.037 harvest_duration + -0.085 value_stay^2 + 0.005 value_stay*reward + -0.272 value_stay*harvest_duration + 0.318 reward^2 + 0.394 reward*harvest_duration + 0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.049 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 190/1000 --- L(Train): 0.0066687 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.037 1 + 0.729 value_stay[t] + 0.394 reward + 0.037 harvest_duration + -0.085 value_stay^2 + 0.004 value_stay*reward + -0.272 value_stay*harvest_duration + 0.318 reward^2 + 0.394 reward*harvest_duration + 0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.049 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 191/1000 --- L(Train): 0.0066605 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.037 1 + 0.729 value_stay[t] + 0.394 reward + 0.037 harvest_duration + -0.084 value_stay^2 + 0.003 value_stay*reward + -0.273 value_stay*harvest_duration + 0.318 reward^2 + 0.394 reward*harvest_duration + 0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.049 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 192/1000 --- L(Train): 0.0066534 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.037 1 + 0.728 value_stay[t] + 0.394 reward + 0.037 harvest_duration + -0.084 value_stay^2 + 0.002 value_stay*reward + -0.273 value_stay*harvest_duration + 0.317 reward^2 + 0.395 reward*harvest_duration + 0.037 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.049 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 193/1000 --- L(Train): 0.0066464 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.728 value_stay[t] + 0.394 reward + 0.038 harvest_duration + -0.083 value_stay^2 + 0.0 value_stay*reward + -0.274 value_stay*harvest_duration + 0.317 reward^2 + 0.395 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.05 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 194/1000 --- L(Train): 0.0066392 --- L(Val, SINDy): 0.0000000 --- Time: 0.11s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.727 value_stay[t] + 0.395 reward + 0.038 harvest_duration + -0.083 value_stay^2 + -0.001 value_stay*reward + -0.274 value_stay*harvest_duration + 0.316 reward^2 + 0.395 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.05 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 195/1000 --- L(Train): 0.0066317 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.727 value_stay[t] + 0.395 reward + 0.038 harvest_duration + -0.082 value_stay^2 + -0.002 value_stay*reward + -0.275 value_stay*harvest_duration + 0.316 reward^2 + 0.395 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.05 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 196/1000 --- L(Train): 0.0066241 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.726 value_stay[t] + 0.395 reward + 0.038 harvest_duration + -0.082 value_stay^2 + -0.002 value_stay*reward + -0.275 value_stay*harvest_duration + 0.315 reward^2 + 0.395 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.05 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 197/1000 --- L(Train): 0.0066166 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.726 value_stay[t] + 0.395 reward + 0.038 harvest_duration + -0.082 value_stay^2 + -0.002 value_stay*reward + -0.276 value_stay*harvest_duration + 0.314 reward^2 + 0.396 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.051 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 198/1000 --- L(Train): 0.0066099 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.726 value_stay[t] + 0.396 reward + 0.038 harvest_duration + -0.081 value_stay^2 + -0.0 value_stay*reward + -0.276 value_stay*harvest_duration + 0.314 reward^2 + 0.396 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.051 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 199/1000 --- L(Train): 0.0066029 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.725 value_stay[t] + 0.396 reward + 0.038 harvest_duration + -0.081 value_stay^2 + 0.001 value_stay*reward + -0.277 value_stay*harvest_duration + 0.313 reward^2 + 0.396 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.051 value_exit*travel_duration + -0.003 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 200/1000 --- L(Train): 0.0065958 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.725 value_stay[t] + 0.396 reward + 0.038 harvest_duration + -0.08 value_stay^2 + 0.003 value_stay*reward + -0.277 value_stay*harvest_duration + 0.313 reward^2 + 0.396 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.051 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 201/1000 --- L(Train): 0.0065888 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.724 value_stay[t] + 0.396 reward + 0.038 harvest_duration + -0.08 value_stay^2 + 0.004 value_stay*reward + -0.278 value_stay*harvest_duration + 0.312 reward^2 + 0.396 reward*harvest_duration + 0.038 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.052 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 202/1000 --- L(Train): 0.0065817 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.724 value_stay[t] + 0.396 reward + 0.038 harvest_duration + -0.079 value_stay^2 + 0.004 value_stay*reward + -0.278 value_stay*harvest_duration + 0.311 reward^2 + 0.396 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.052 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 203/1000 --- L(Train): 0.0065753 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.038 1 + 0.723 value_stay[t] + 0.396 reward + 0.039 harvest_duration + -0.079 value_stay^2 + 0.004 value_stay*reward + -0.278 value_stay*harvest_duration + 0.311 reward^2 + 0.396 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.052 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 204/1000 --- L(Train): 0.0065690 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.723 value_stay[t] + 0.396 reward + 0.039 harvest_duration + -0.078 value_stay^2 + 0.003 value_stay*reward + -0.279 value_stay*harvest_duration + 0.31 reward^2 + 0.397 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.053 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 205/1000 --- L(Train): 0.0065626 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.723 value_stay[t] + 0.396 reward + 0.039 harvest_duration + -0.078 value_stay^2 + 0.002 value_stay*reward + -0.279 value_stay*harvest_duration + 0.309 reward^2 + 0.397 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.053 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 206/1000 --- L(Train): 0.0065561 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.722 value_stay[t] + 0.396 reward + 0.039 harvest_duration + -0.078 value_stay^2 + 0.001 value_stay*reward + -0.28 value_stay*harvest_duration + 0.308 reward^2 + 0.397 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.053 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 207/1000 --- L(Train): 0.0065496 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.722 value_stay[t] + 0.396 reward + 0.039 harvest_duration + -0.077 value_stay^2 + -0.0 value_stay*reward + -0.28 value_stay*harvest_duration + 0.308 reward^2 + 0.397 reward*harvest_duration + 0.039 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.053 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 208/1000 --- L(Train): 0.0065430 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.721 value_stay[t] + 0.397 reward + 0.039 harvest_duration + -0.076 value_stay^2 + -0.001 value_stay*reward + -0.28 value_stay*harvest_duration + 0.307 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.054 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 209/1000 --- L(Train): 0.0065367 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.721 value_stay[t] + 0.397 reward + 0.039 harvest_duration + -0.076 value_stay^2 + -0.0 value_stay*reward + -0.281 value_stay*harvest_duration + 0.306 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.054 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 210/1000 --- L(Train): 0.0065304 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.721 value_stay[t] + 0.397 reward + 0.039 harvest_duration + -0.075 value_stay^2 + 0.001 value_stay*reward + -0.281 value_stay*harvest_duration + 0.305 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.054 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 211/1000 --- L(Train): 0.0065240 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.72 value_stay[t] + 0.397 reward + 0.039 harvest_duration + -0.075 value_stay^2 + 0.002 value_stay*reward + -0.281 value_stay*harvest_duration + 0.305 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.054 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 212/1000 --- L(Train): 0.0065175 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.72 value_stay[t] + 0.397 reward + 0.039 harvest_duration + -0.074 value_stay^2 + 0.002 value_stay*reward + -0.282 value_stay*harvest_duration + 0.304 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.055 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 213/1000 --- L(Train): 0.0065112 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.039 1 + 0.72 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.074 value_stay^2 + 0.002 value_stay*reward + -0.282 value_stay*harvest_duration + 0.303 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.055 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 214/1000 --- L(Train): 0.0065052 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.72 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.073 value_stay^2 + 0.001 value_stay*reward + -0.282 value_stay*harvest_duration + 0.302 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.055 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 215/1000 --- L(Train): 0.0064995 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.719 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.072 value_stay^2 + 0.0 value_stay*reward + -0.282 value_stay*harvest_duration + 0.302 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.055 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 216/1000 --- L(Train): 0.0064937 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.719 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.072 value_stay^2 + -0.001 value_stay*reward + -0.283 value_stay*harvest_duration + 0.301 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.056 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 217/1000 --- L(Train): 0.0064880 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.719 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.071 value_stay^2 + -0.001 value_stay*reward + -0.283 value_stay*harvest_duration + 0.3 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.056 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 218/1000 --- L(Train): 0.0064820 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.718 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.07 value_stay^2 + -0.0 value_stay*reward + -0.283 value_stay*harvest_duration + 0.299 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.056 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 219/1000 --- L(Train): 0.0064758 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.718 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.07 value_stay^2 + 0.001 value_stay*reward + -0.284 value_stay*harvest_duration + 0.299 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.056 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 220/1000 --- L(Train): 0.0064699 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.718 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.069 value_stay^2 + 0.002 value_stay*reward + -0.284 value_stay*harvest_duration + 0.298 reward^2 + 0.397 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.057 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 221/1000 --- L(Train): 0.0064639 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.717 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.069 value_stay^2 + 0.003 value_stay*reward + -0.284 value_stay*harvest_duration + 0.297 reward^2 + 0.398 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.057 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 222/1000 --- L(Train): 0.0064582 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.717 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.068 value_stay^2 + 0.002 value_stay*reward + -0.285 value_stay*harvest_duration + 0.296 reward^2 + 0.398 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.057 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 223/1000 --- L(Train): 0.0064530 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.717 value_stay[t] + 0.397 reward + 0.04 harvest_duration + -0.067 value_stay^2 + 0.002 value_stay*reward + -0.285 value_stay*harvest_duration + 0.296 reward^2 + 0.398 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.057 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 224/1000 --- L(Train): 0.0064477 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.716 value_stay[t] + 0.398 reward + 0.04 harvest_duration + -0.067 value_stay^2 + 0.001 value_stay*reward + -0.285 value_stay*harvest_duration + 0.295 reward^2 + 0.398 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.058 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 225/1000 --- L(Train): 0.0064424 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.716 value_stay[t] + 0.398 reward + 0.04 harvest_duration + -0.066 value_stay^2 + 0.0 value_stay*reward + -0.286 value_stay*harvest_duration + 0.294 reward^2 + 0.398 reward*harvest_duration + 0.04 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.058 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 226/1000 --- L(Train): 0.0064365 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.716 value_stay[t] + 0.398 reward + 0.04 harvest_duration + -0.066 value_stay^2 + -0.001 value_stay*reward + -0.286 value_stay*harvest_duration + 0.294 reward^2 + 0.398 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.058 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 227/1000 --- L(Train): 0.0064308 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.715 value_stay[t] + 0.398 reward + 0.041 harvest_duration + -0.065 value_stay^2 + -0.002 value_stay*reward + -0.286 value_stay*harvest_duration + 0.293 reward^2 + 0.398 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.058 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 228/1000 --- L(Train): 0.0064249 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.715 value_stay[t] + 0.398 reward + 0.041 harvest_duration + -0.065 value_stay^2 + -0.001 value_stay*reward + -0.287 value_stay*harvest_duration + 0.292 reward^2 + 0.398 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.059 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 229/1000 --- L(Train): 0.0064195 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.715 value_stay[t] + 0.398 reward + 0.041 harvest_duration + -0.064 value_stay^2 + 0.0 value_stay*reward + -0.287 value_stay*harvest_duration + 0.291 reward^2 + 0.398 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.059 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 230/1000 --- L(Train): 0.0064139 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.04 1 + 0.714 value_stay[t] + 0.398 reward + 0.041 harvest_duration + -0.064 value_stay^2 + 0.001 value_stay*reward + -0.287 value_stay*harvest_duration + 0.291 reward^2 + 0.398 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.059 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 231/1000 --- L(Train): 0.0064087 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.714 value_stay[t] + 0.398 reward + 0.041 harvest_duration + -0.063 value_stay^2 + 0.001 value_stay*reward + -0.288 value_stay*harvest_duration + 0.29 reward^2 + 0.399 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.059 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 232/1000 --- L(Train): 0.0064035 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.714 value_stay[t] + 0.398 reward + 0.041 harvest_duration + -0.062 value_stay^2 + 0.001 value_stay*reward + -0.288 value_stay*harvest_duration + 0.289 reward^2 + 0.399 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.059 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 233/1000 --- L(Train): 0.0063982 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.713 value_stay[t] + 0.399 reward + 0.041 harvest_duration + -0.062 value_stay^2 + 0.0 value_stay*reward + -0.289 value_stay*harvest_duration + 0.288 reward^2 + 0.399 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.06 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 234/1000 --- L(Train): 0.0063925 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.713 value_stay[t] + 0.399 reward + 0.041 harvest_duration + -0.061 value_stay^2 + -0.0 value_stay*reward + -0.289 value_stay*harvest_duration + 0.288 reward^2 + 0.399 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.06 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 235/1000 --- L(Train): 0.0063876 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.712 value_stay[t] + 0.399 reward + 0.041 harvest_duration + -0.061 value_stay^2 + -0.0 value_stay*reward + -0.289 value_stay*harvest_duration + 0.287 reward^2 + 0.399 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.06 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 236/1000 --- L(Train): 0.0063828 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.712 value_stay[t] + 0.399 reward + 0.041 harvest_duration + -0.06 value_stay^2 + 0.001 value_stay*reward + -0.29 value_stay*harvest_duration + 0.286 reward^2 + 0.399 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.06 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 237/1000 --- L(Train): 0.0063779 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.712 value_stay[t] + 0.399 reward + 0.041 harvest_duration + -0.06 value_stay^2 + 0.001 value_stay*reward + -0.29 value_stay*harvest_duration + 0.286 reward^2 + 0.399 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.061 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 238/1000 --- L(Train): 0.0063726 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.711 value_stay[t] + 0.399 reward + 0.041 harvest_duration + -0.059 value_stay^2 + 0.001 value_stay*reward + -0.29 value_stay*harvest_duration + 0.285 reward^2 + 0.4 reward*harvest_duration + 0.041 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.061 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 239/1000 --- L(Train): 0.0063673 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.711 value_stay[t] + 0.399 reward + 0.041 harvest_duration + -0.059 value_stay^2 + 0.001 value_stay*reward + -0.291 value_stay*harvest_duration + 0.284 reward^2 + 0.4 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.061 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 240/1000 --- L(Train): 0.0063624 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.711 value_stay[t] + 0.4 reward + 0.041 harvest_duration + -0.058 value_stay^2 + -0.0 value_stay*reward + -0.291 value_stay*harvest_duration + 0.284 reward^2 + 0.4 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.061 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 241/1000 --- L(Train): 0.0063573 --- L(Val, SINDy): 0.0000000 --- Time: 0.09s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.041 1 + 0.71 value_stay[t] + 0.4 reward + 0.041 harvest_duration + -0.057 value_stay^2 + 0.0 value_stay*reward + -0.292 value_stay*harvest_duration + 0.283 reward^2 + 0.4 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.062 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 242/1000 --- L(Train): 0.0063527 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.71 value_stay[t] + 0.4 reward + 0.042 harvest_duration + -0.057 value_stay^2 + -0.0 value_stay*reward + -0.292 value_stay*harvest_duration + 0.282 reward^2 + 0.4 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.062 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 243/1000 --- L(Train): 0.0063482 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.709 value_stay[t] + 0.4 reward + 0.042 harvest_duration + -0.056 value_stay^2 + 0.001 value_stay*reward + -0.292 value_stay*harvest_duration + 0.281 reward^2 + 0.4 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.062 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 244/1000 --- L(Train): 0.0063435 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.709 value_stay[t] + 0.4 reward + 0.042 harvest_duration + -0.056 value_stay^2 + 0.001 value_stay*reward + -0.293 value_stay*harvest_duration + 0.281 reward^2 + 0.4 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.062 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 245/1000 --- L(Train): 0.0063387 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.709 value_stay[t] + 0.4 reward + 0.042 harvest_duration + -0.055 value_stay^2 + 0.001 value_stay*reward + -0.293 value_stay*harvest_duration + 0.28 reward^2 + 0.401 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.981 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.063 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 246/1000 --- L(Train): 0.0063340 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.708 value_stay[t] + 0.4 reward + 0.042 harvest_duration + -0.055 value_stay^2 + 0.0 value_stay*reward + -0.293 value_stay*harvest_duration + 0.279 reward^2 + 0.401 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.063 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 247/1000 --- L(Train): 0.0063299 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.708 value_stay[t] + 0.401 reward + 0.042 harvest_duration + -0.054 value_stay^2 + -0.001 value_stay*reward + -0.294 value_stay*harvest_duration + 0.279 reward^2 + 0.401 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.063 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 248/1000 --- L(Train): 0.0063253 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.708 value_stay[t] + 0.401 reward + 0.042 harvest_duration + -0.054 value_stay^2 + -0.001 value_stay*reward + -0.294 value_stay*harvest_duration + 0.278 reward^2 + 0.401 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.063 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 249/1000 --- L(Train): 0.0063206 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.707 value_stay[t] + 0.401 reward + 0.042 harvest_duration + -0.053 value_stay^2 + 0.0 value_stay*reward + -0.295 value_stay*harvest_duration + 0.277 reward^2 + 0.401 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.063 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 250/1000 --- L(Train): 0.0063160 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.707 value_stay[t] + 0.401 reward + 0.042 harvest_duration + -0.052 value_stay^2 + 0.001 value_stay*reward + -0.295 value_stay*harvest_duration + 0.276 reward^2 + 0.401 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.064 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_exit: 0, 0, 0, 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 251/1000 --- L(Train): 0.0063117 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.706 value_stay[t] + 0.401 reward + 0.042 harvest_duration + -0.052 value_stay^2 + 0.001 value_stay*reward + -0.295 value_stay*harvest_duration + 0.276 reward^2 + 0.401 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.064 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 1, 0, 0, 1, 0, 1, 0, 0, 0, 1\n",
      "value_exit: 1, 1, 1, 1, 0, 1\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 252/1000 --- L(Train): 0.0063072 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.706 value_stay[t] + 0.401 reward + 0.042 harvest_duration + -0.051 value_stay^2 + 0.0 value_stay*reward + -0.296 value_stay*harvest_duration + 0.275 reward^2 + 0.402 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.064 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 2, 0, 0, 2, 0, 2, 0, 0, 0, 2\n",
      "value_exit: 2, 2, 2, 2, 0, 2\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 253/1000 --- L(Train): 0.0063029 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.706 value_stay[t] + 0.401 reward + 0.042 harvest_duration + -0.051 value_stay^2 + -0.0 value_stay*reward + -0.296 value_stay*harvest_duration + 0.274 reward^2 + 0.402 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.064 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 3, 0, 0, 3, 0, 3, 0, 0, 0, 3\n",
      "value_exit: 3, 3, 3, 3, 0, 3\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 254/1000 --- L(Train): 0.0062984 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.705 value_stay[t] + 0.402 reward + 0.042 harvest_duration + -0.05 value_stay^2 + -0.0 value_stay*reward + -0.296 value_stay*harvest_duration + 0.273 reward^2 + 0.402 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.065 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 4, 0, 0, 4, 0, 4, 0, 0, 0, 4\n",
      "value_exit: 4, 4, 4, 4, 0, 4\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 255/1000 --- L(Train): 0.0062942 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.705 value_stay[t] + 0.402 reward + 0.042 harvest_duration + -0.049 value_stay^2 + 0.001 value_stay*reward + -0.297 value_stay*harvest_duration + 0.273 reward^2 + 0.402 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.065 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 5, 0, 0, 5, 1, 5, 0, 0, 0, 5\n",
      "value_exit: 5, 5, 5, 5, 0, 5\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 256/1000 --- L(Train): 0.0062898 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.705 value_stay[t] + 0.402 reward + 0.042 harvest_duration + -0.049 value_stay^2 + 0.001 value_stay*reward + -0.297 value_stay*harvest_duration + 0.272 reward^2 + 0.402 reward*harvest_duration + 0.042 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.065 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 6, 0, 0, 6, 2, 6, 0, 0, 0, 6\n",
      "value_exit: 6, 6, 6, 6, 0, 6\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 257/1000 --- L(Train): 0.0062852 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.042 1 + 0.704 value_stay[t] + 0.402 reward + 0.042 harvest_duration + -0.048 value_stay^2 + 0.001 value_stay*reward + -0.298 value_stay*harvest_duration + 0.271 reward^2 + 0.402 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.065 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 7, 0, 0, 7, 3, 7, 0, 0, 0, 7\n",
      "value_exit: 7, 7, 7, 7, 0, 7\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 258/1000 --- L(Train): 0.0062809 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.704 value_stay[t] + 0.402 reward + 0.043 harvest_duration + -0.048 value_stay^2 + 0.001 value_stay*reward + -0.298 value_stay*harvest_duration + 0.27 reward^2 + 0.402 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.065 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 8, 0, 0, 8, 4, 8, 0, 0, 0, 8\n",
      "value_exit: 8, 8, 8, 8, 0, 8\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 259/1000 --- L(Train): 0.0062765 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.704 value_stay[t] + 0.402 reward + 0.043 harvest_duration + -0.047 value_stay^2 + 0.0 value_stay*reward + -0.298 value_stay*harvest_duration + 0.27 reward^2 + 0.403 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.066 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 9, 0, 0, 9, 5, 9, 0, 0, 0, 9\n",
      "value_exit: 9, 9, 9, 9, 0, 9\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 260/1000 --- L(Train): 0.0062723 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.703 value_stay[t] + 0.402 reward + 0.043 harvest_duration + -0.047 value_stay^2 + -0.001 value_stay*reward + -0.299 value_stay*harvest_duration + 0.269 reward^2 + 0.403 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.066 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 10, 0, 0, 10, 6, 10, 0, 0, 0, 10\n",
      "value_exit: 10, 10, 10, 10, 0, 10\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 261/1000 --- L(Train): 0.0062683 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.703 value_stay[t] + 0.403 reward + 0.043 harvest_duration + -0.046 value_stay^2 + -0.001 value_stay*reward + -0.299 value_stay*harvest_duration + 0.268 reward^2 + 0.403 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.066 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 11, 0, 0, 11, 7, 11, 0, 0, 0, 11\n",
      "value_exit: 11, 11, 11, 11, 0, 11\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 262/1000 --- L(Train): 0.0062642 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.702 value_stay[t] + 0.403 reward + 0.043 harvest_duration + -0.045 value_stay^2 + 0.0 value_stay*reward + -0.299 value_stay*harvest_duration + 0.267 reward^2 + 0.403 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.066 value_exit*travel_duration + -0.004 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 12, 0, 0, 12, 8, 12, 0, 0, 0, 12\n",
      "value_exit: 12, 12, 12, 12, 0, 12\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 263/1000 --- L(Train): 0.0062599 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.702 value_stay[t] + 0.403 reward + 0.043 harvest_duration + -0.045 value_stay^2 + 0.0 value_stay*reward + -0.3 value_stay*harvest_duration + 0.267 reward^2 + 0.403 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.982 value_exit[t] + -0.002 travel_duration + 0.001 value_exit^2 + -0.067 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 13, 0, 0, 13, 9, 13, 0, 0, 0, 13\n",
      "value_exit: 13, 13, 13, 13, 0, 13\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 264/1000 --- L(Train): 0.0062558 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.702 value_stay[t] + 0.403 reward + 0.043 harvest_duration + -0.044 value_stay^2 + 0.0 value_stay*reward + -0.3 value_stay*harvest_duration + 0.266 reward^2 + 0.403 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.067 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 14, 0, 0, 14, 10, 14, 0, 0, 0, 14\n",
      "value_exit: 14, 14, 14, 14, 0, 14\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 265/1000 --- L(Train): 0.0062515 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.701 value_stay[t] + 0.403 reward + 0.043 harvest_duration + -0.044 value_stay^2 + -0.0 value_stay*reward + -0.3 value_stay*harvest_duration + 0.265 reward^2 + 0.403 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.067 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 15, 0, 0, 15, 11, 15, 0, 0, 0, 15\n",
      "value_exit: 15, 15, 15, 15, 0, 15\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 266/1000 --- L(Train): 0.0062476 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.701 value_stay[t] + 0.403 reward + 0.043 harvest_duration + -0.043 value_stay^2 + 0.0 value_stay*reward + -0.301 value_stay*harvest_duration + 0.264 reward^2 + 0.404 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + 0.0 value_exit^2 + -0.067 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 16, 0, 0, 16, 12, 16, 0, 0, 0, 16\n",
      "value_exit: 16, 16, 16, 16, 0, 16\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 267/1000 --- L(Train): 0.0062437 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.701 value_stay[t] + 0.403 reward + 0.043 harvest_duration + -0.043 value_stay^2 + 0.0 value_stay*reward + -0.301 value_stay*harvest_duration + 0.264 reward^2 + 0.404 reward*harvest_duration + 0.043 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.002 travel_duration + -0.0 value_exit^2 + -0.067 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 17, 0, 0, 17, 13, 17, 0, 0, 0, 17\n",
      "value_exit: 17, 17, 17, 17, 0, 17\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 268/1000 --- L(Train): 0.0062395 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.7 value_stay[t] + 0.404 reward + 0.043 harvest_duration + -0.042 value_stay^2 + 0.0 value_stay*reward + -0.302 value_stay*harvest_duration + 0.263 reward^2 + 0.404 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.068 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 18, 0, 0, 18, 14, 18, 0, 0, 0, 18\n",
      "value_exit: 18, 18, 18, 18, 0, 18\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 269/1000 --- L(Train): 0.0062354 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.7 value_stay[t] + 0.404 reward + 0.044 harvest_duration + -0.041 value_stay^2 + -0.001 value_stay*reward + -0.302 value_stay*harvest_duration + 0.262 reward^2 + 0.404 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.068 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 19, 0, 0, 19, 15, 19, 0, 0, 0, 19\n",
      "value_exit: 19, 19, 19, 19, 0, 19\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 270/1000 --- L(Train): 0.0062318 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.699 value_stay[t] + 0.404 reward + 0.044 harvest_duration + -0.041 value_stay^2 + -0.001 value_stay*reward + -0.302 value_stay*harvest_duration + 0.261 reward^2 + 0.404 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.068 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 20, 0, 0, 20, 16, 20, 0, 0, 0, 20\n",
      "value_exit: 20, 20, 20, 20, 0, 20\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 271/1000 --- L(Train): 0.0062279 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.699 value_stay[t] + 0.404 reward + 0.043 harvest_duration + -0.04 value_stay^2 + 0.001 value_stay*reward + -0.303 value_stay*harvest_duration + 0.261 reward^2 + 0.404 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.068 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 21, 0, 0, 21, 17, 21, 0, 0, 0, 21\n",
      "value_exit: 21, 21, 21, 21, 0, 21\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 272/1000 --- L(Train): 0.0062241 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.043 1 + 0.699 value_stay[t] + 0.404 reward + 0.044 harvest_duration + -0.04 value_stay^2 + 0.001 value_stay*reward + -0.303 value_stay*harvest_duration + 0.26 reward^2 + 0.404 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.068 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 22, 0, 0, 22, 18, 22, 0, 0, 0, 22\n",
      "value_exit: 22, 22, 22, 22, 0, 22\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 273/1000 --- L(Train): 0.0062204 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.698 value_stay[t] + 0.404 reward + 0.044 harvest_duration + -0.039 value_stay^2 + 0.001 value_stay*reward + -0.303 value_stay*harvest_duration + 0.259 reward^2 + 0.405 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.069 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 23, 0, 0, 23, 19, 23, 0, 0, 0, 23\n",
      "value_exit: 23, 23, 23, 23, 0, 23\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 274/1000 --- L(Train): 0.0062167 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.698 value_stay[t] + 0.404 reward + 0.044 harvest_duration + -0.039 value_stay^2 + 0.001 value_stay*reward + -0.304 value_stay*harvest_duration + 0.258 reward^2 + 0.405 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.069 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 24, 0, 0, 24, 20, 24, 0, 0, 0, 24\n",
      "value_exit: 24, 24, 24, 24, 0, 24\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 275/1000 --- L(Train): 0.0062132 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.698 value_stay[t] + 0.404 reward + 0.044 harvest_duration + -0.038 value_stay^2 + 0.0 value_stay*reward + -0.304 value_stay*harvest_duration + 0.257 reward^2 + 0.405 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.069 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 25, 0, 0, 25, 21, 25, 0, 0, 0, 25\n",
      "value_exit: 25, 25, 25, 25, 0, 25\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 276/1000 --- L(Train): 0.0062099 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.697 value_stay[t] + 0.405 reward + 0.044 harvest_duration + -0.037 value_stay^2 + -0.001 value_stay*reward + -0.305 value_stay*harvest_duration + 0.257 reward^2 + 0.405 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.983 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.069 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 26, 0, 0, 26, 22, 26, 0, 0, 0, 26\n",
      "value_exit: 26, 26, 26, 26, 0, 26\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 277/1000 --- L(Train): 0.0062065 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.697 value_stay[t] + 0.405 reward + 0.044 harvest_duration + -0.037 value_stay^2 + -0.001 value_stay*reward + -0.305 value_stay*harvest_duration + 0.256 reward^2 + 0.405 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.069 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 27, 0, 0, 27, 23, 27, 0, 0, 0, 27\n",
      "value_exit: 27, 27, 27, 27, 0, 27\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 278/1000 --- L(Train): 0.0062030 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.697 value_stay[t] + 0.405 reward + 0.044 harvest_duration + -0.036 value_stay^2 + 0.0 value_stay*reward + -0.305 value_stay*harvest_duration + 0.255 reward^2 + 0.405 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.07 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 28, 0, 0, 28, 24, 28, 0, 0, 0, 28\n",
      "value_exit: 28, 28, 28, 28, 0, 28\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 279/1000 --- L(Train): 0.0061994 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.696 value_stay[t] + 0.405 reward + 0.044 harvest_duration + -0.036 value_stay^2 + 0.0 value_stay*reward + -0.306 value_stay*harvest_duration + 0.254 reward^2 + 0.405 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.07 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 29, 0, 0, 29, 25, 29, 0, 0, 0, 29\n",
      "value_exit: 29, 29, 29, 29, 0, 29\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 280/1000 --- L(Train): 0.0061952 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.696 value_stay[t] + 0.405 reward + 0.044 harvest_duration + -0.035 value_stay^2 + 0.0 value_stay*reward + -0.306 value_stay*harvest_duration + 0.254 reward^2 + 0.406 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.07 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 30, 0, 0, 30, 26, 30, 0, 0, 0, 30\n",
      "value_exit: 30, 30, 30, 30, 0, 30\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 281/1000 --- L(Train): 0.0061915 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.695 value_stay[t] + 0.405 reward + 0.044 harvest_duration + -0.035 value_stay^2 + -0.0 value_stay*reward + -0.306 value_stay*harvest_duration + 0.253 reward^2 + 0.406 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.07 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 31, 0, 0, 31, 27, 31, 0, 0, 0, 31\n",
      "value_exit: 31, 31, 31, 31, 0, 31\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 282/1000 --- L(Train): 0.0061883 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.695 value_stay[t] + 0.405 reward + 0.044 harvest_duration + -0.034 value_stay^2 + 0.0 value_stay*reward + -0.307 value_stay*harvest_duration + 0.252 reward^2 + 0.406 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.07 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 32, 0, 0, 32, 28, 32, 0, 0, 0, 32\n",
      "value_exit: 32, 32, 32, 32, 0, 32\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 283/1000 --- L(Train): 0.0061851 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.695 value_stay[t] + 0.406 reward + 0.044 harvest_duration + -0.034 value_stay^2 + 0.0 value_stay*reward + -0.307 value_stay*harvest_duration + 0.251 reward^2 + 0.406 reward*harvest_duration + 0.044 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.071 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 33, 0, 0, 33, 29, 33, 0, 0, 0, 33\n",
      "value_exit: 33, 33, 33, 33, 0, 33\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 284/1000 --- L(Train): 0.0061820 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.044 1 + 0.694 value_stay[t] + 0.406 reward + 0.044 harvest_duration + -0.033 value_stay^2 + 0.0 value_stay*reward + -0.308 value_stay*harvest_duration + 0.25 reward^2 + 0.406 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.071 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 34, 0, 0, 34, 30, 34, 0, 0, 0, 34\n",
      "value_exit: 34, 34, 34, 34, 0, 34\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 285/1000 --- L(Train): 0.0061785 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.694 value_stay[t] + 0.406 reward + 0.045 harvest_duration + -0.032 value_stay^2 + -0.001 value_stay*reward + -0.308 value_stay*harvest_duration + 0.25 reward^2 + 0.406 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.071 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 35, 0, 0, 35, 31, 35, 0, 0, 0, 35\n",
      "value_exit: 35, 35, 35, 35, 0, 35\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 286/1000 --- L(Train): 0.0061749 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.694 value_stay[t] + 0.406 reward + 0.045 harvest_duration + -0.032 value_stay^2 + -0.0 value_stay*reward + -0.308 value_stay*harvest_duration + 0.249 reward^2 + 0.406 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.984 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.071 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 36, 0, 0, 36, 32, 36, 0, 0, 0, 36\n",
      "value_exit: 36, 36, 36, 36, 0, 36\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 287/1000 --- L(Train): 0.0061717 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.693 value_stay[t] + 0.406 reward + 0.045 harvest_duration + -0.031 value_stay^2 + 0.001 value_stay*reward + -0.309 value_stay*harvest_duration + 0.248 reward^2 + 0.407 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.071 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 37, 0, 0, 37, 33, 37, 0, 0, 0, 37\n",
      "value_exit: 37, 37, 37, 37, 0, 37\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 288/1000 --- L(Train): 0.0061686 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.693 value_stay[t] + 0.406 reward + 0.045 harvest_duration + -0.031 value_stay^2 + 0.001 value_stay*reward + -0.309 value_stay*harvest_duration + 0.247 reward^2 + 0.407 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.072 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 38, 0, 0, 38, 34, 38, 0, 0, 0, 38\n",
      "value_exit: 38, 38, 38, 38, 0, 38\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 289/1000 --- L(Train): 0.0061654 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.692 value_stay[t] + 0.407 reward + 0.045 harvest_duration + -0.03 value_stay^2 + 0.001 value_stay*reward + -0.309 value_stay*harvest_duration + 0.246 reward^2 + 0.407 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.072 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 39, 0, 0, 39, 35, 39, 0, 0, 0, 39\n",
      "value_exit: 39, 39, 39, 39, 0, 39\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 290/1000 --- L(Train): 0.0061621 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.692 value_stay[t] + 0.407 reward + 0.045 harvest_duration + -0.03 value_stay^2 + 0.001 value_stay*reward + -0.31 value_stay*harvest_duration + 0.246 reward^2 + 0.407 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.072 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 40, 0, 0, 40, 36, 40, 0, 0, 0, 40\n",
      "value_exit: 40, 40, 40, 40, 0, 40\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 291/1000 --- L(Train): 0.0061587 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.692 value_stay[t] + 0.407 reward + 0.045 harvest_duration + -0.029 value_stay^2 + 0.0 value_stay*reward + -0.31 value_stay*harvest_duration + 0.245 reward^2 + 0.407 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.072 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 41, 0, 0, 41, 37, 41, 0, 0, 0, 41\n",
      "value_exit: 41, 41, 41, 41, 0, 41\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 292/1000 --- L(Train): 0.0061552 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.691 value_stay[t] + 0.407 reward + 0.045 harvest_duration + -0.028 value_stay^2 + -0.001 value_stay*reward + -0.311 value_stay*harvest_duration + 0.244 reward^2 + 0.407 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.072 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 42, 0, 0, 42, 38, 42, 0, 0, 0, 42\n",
      "value_exit: 42, 42, 42, 42, 0, 42\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 293/1000 --- L(Train): 0.0061518 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.691 value_stay[t] + 0.407 reward + 0.045 harvest_duration + -0.028 value_stay^2 + -0.001 value_stay*reward + -0.311 value_stay*harvest_duration + 0.243 reward^2 + 0.407 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.073 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 43, 0, 0, 43, 39, 43, 0, 0, 0, 43\n",
      "value_exit: 43, 43, 43, 43, 0, 43\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 294/1000 --- L(Train): 0.0061481 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.691 value_stay[t] + 0.407 reward + 0.045 harvest_duration + -0.027 value_stay^2 + 0.0 value_stay*reward + -0.311 value_stay*harvest_duration + 0.242 reward^2 + 0.408 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.073 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 44, 0, 0, 44, 40, 44, 0, 0, 0, 44\n",
      "value_exit: 44, 44, 44, 44, 0, 44\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 295/1000 --- L(Train): 0.0061451 --- L(Val, SINDy): 0.0000000 --- Time: 0.09s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.69 value_stay[t] + 0.407 reward + 0.045 harvest_duration + -0.027 value_stay^2 + 0.001 value_stay*reward + -0.312 value_stay*harvest_duration + 0.242 reward^2 + 0.408 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.073 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 45, 0, 0, 45, 41, 45, 0, 0, 0, 45\n",
      "value_exit: 45, 45, 45, 45, 0, 45\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 296/1000 --- L(Train): 0.0061426 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.69 value_stay[t] + 0.408 reward + 0.045 harvest_duration + -0.026 value_stay^2 + 0.001 value_stay*reward + -0.312 value_stay*harvest_duration + 0.241 reward^2 + 0.408 reward*harvest_duration + 0.045 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.985 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.073 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 46, 0, 0, 46, 42, 46, 0, 0, 0, 46\n",
      "value_exit: 46, 46, 46, 46, 0, 46\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 297/1000 --- L(Train): 0.0061397 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.689 value_stay[t] + 0.408 reward + 0.045 harvest_duration + -0.026 value_stay^2 + 0.0 value_stay*reward + -0.312 value_stay*harvest_duration + 0.24 reward^2 + 0.408 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.073 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 47, 0, 0, 47, 43, 47, 0, 0, 0, 47\n",
      "value_exit: 47, 47, 47, 47, 0, 47\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 298/1000 --- L(Train): 0.0061365 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.689 value_stay[t] + 0.408 reward + 0.045 harvest_duration + -0.025 value_stay^2 + -0.001 value_stay*reward + -0.313 value_stay*harvest_duration + 0.239 reward^2 + 0.408 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.074 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 48, 0, 0, 48, 44, 48, 0, 0, 0, 48\n",
      "value_exit: 48, 48, 48, 48, 0, 48\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 299/1000 --- L(Train): 0.0061331 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.689 value_stay[t] + 0.408 reward + 0.046 harvest_duration + -0.024 value_stay^2 + -0.0 value_stay*reward + -0.313 value_stay*harvest_duration + 0.239 reward^2 + 0.408 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.074 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 49, 0, 0, 49, 45, 49, 0, 0, 0, 49\n",
      "value_exit: 49, 49, 49, 49, 0, 49\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 300/1000 --- L(Train): 0.0061301 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.688 value_stay[t] + 0.408 reward + 0.046 harvest_duration + -0.024 value_stay^2 + 0.001 value_stay*reward + -0.313 value_stay*harvest_duration + 0.238 reward^2 + 0.408 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.074 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 50, 0, 0, 50, 46, 50, 0, 0, 0, 50\n",
      "value_exit: 50, 50, 50, 50, 0, 50\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 301/1000 --- L(Train): 0.0061274 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.045 1 + 0.688 value_stay[t] + 0.408 reward + 0.045 harvest_duration + -0.023 value_stay^2 + 0.001 value_stay*reward + -0.314 value_stay*harvest_duration + 0.237 reward^2 + 0.409 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.074 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 51, 0, 0, 51, 47, 51, 0, 0, 0, 51\n",
      "value_exit: 51, 51, 51, 51, 0, 51\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 302/1000 --- L(Train): 0.0061248 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.688 value_stay[t] + 0.408 reward + 0.046 harvest_duration + -0.023 value_stay^2 + 0.001 value_stay*reward + -0.314 value_stay*harvest_duration + 0.236 reward^2 + 0.409 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.074 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 52, 0, 0, 52, 48, 52, 0, 0, 0, 52\n",
      "value_exit: 52, 52, 52, 52, 0, 52\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 303/1000 --- L(Train): 0.0061214 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.687 value_stay[t] + 0.409 reward + 0.046 harvest_duration + -0.022 value_stay^2 + 0.001 value_stay*reward + -0.315 value_stay*harvest_duration + 0.235 reward^2 + 0.409 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.074 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 53, 0, 0, 53, 49, 53, 0, 0, 0, 53\n",
      "value_exit: 53, 53, 53, 53, 0, 53\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 304/1000 --- L(Train): 0.0061183 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.687 value_stay[t] + 0.409 reward + 0.046 harvest_duration + -0.022 value_stay^2 + 0.0 value_stay*reward + -0.315 value_stay*harvest_duration + 0.234 reward^2 + 0.409 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.986 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.075 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 54, 0, 0, 54, 50, 54, 0, 0, 0, 54\n",
      "value_exit: 54, 54, 54, 54, 0, 54\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 305/1000 --- L(Train): 0.0061156 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.686 value_stay[t] + 0.409 reward + 0.046 harvest_duration + -0.021 value_stay^2 + -0.001 value_stay*reward + -0.315 value_stay*harvest_duration + 0.234 reward^2 + 0.409 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.075 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 55, 0, 0, 55, 51, 55, 0, 0, 0, 55\n",
      "value_exit: 55, 55, 55, 55, 0, 55\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 306/1000 --- L(Train): 0.0061129 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.686 value_stay[t] + 0.409 reward + 0.046 harvest_duration + -0.02 value_stay^2 + -0.001 value_stay*reward + -0.316 value_stay*harvest_duration + 0.233 reward^2 + 0.409 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.075 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 56, 0, 0, 56, 52, 56, 0, 0, 0, 56\n",
      "value_exit: 56, 56, 56, 56, 0, 56\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 307/1000 --- L(Train): 0.0061098 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.686 value_stay[t] + 0.409 reward + 0.046 harvest_duration + -0.02 value_stay^2 + 0.0 value_stay*reward + -0.316 value_stay*harvest_duration + 0.232 reward^2 + 0.409 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.075 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 57, 0, 0, 57, 53, 57, 0, 0, 0, 57\n",
      "value_exit: 57, 57, 57, 57, 0, 57\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 308/1000 --- L(Train): 0.0061070 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.685 value_stay[t] + 0.409 reward + 0.046 harvest_duration + -0.019 value_stay^2 + 0.001 value_stay*reward + -0.317 value_stay*harvest_duration + 0.231 reward^2 + 0.41 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.075 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 58, 0, 0, 58, 54, 58, 0, 0, 0, 58\n",
      "value_exit: 58, 58, 58, 58, 0, 58\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 309/1000 --- L(Train): 0.0061045 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.685 value_stay[t] + 0.41 reward + 0.046 harvest_duration + -0.019 value_stay^2 + 0.001 value_stay*reward + -0.317 value_stay*harvest_duration + 0.23 reward^2 + 0.41 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.076 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 59, 0, 0, 59, 55, 59, 0, 0, 0, 59\n",
      "value_exit: 59, 59, 59, 59, 0, 59\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 310/1000 --- L(Train): 0.0061018 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.685 value_stay[t] + 0.41 reward + 0.046 harvest_duration + -0.018 value_stay^2 + 0.0 value_stay*reward + -0.317 value_stay*harvest_duration + 0.23 reward^2 + 0.41 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.076 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 60, 0, 0, 60, 56, 60, 0, 0, 0, 60\n",
      "value_exit: 60, 60, 60, 60, 0, 60\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 311/1000 --- L(Train): 0.0060994 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.684 value_stay[t] + 0.41 reward + 0.046 harvest_duration + -0.018 value_stay^2 + -0.001 value_stay*reward + -0.318 value_stay*harvest_duration + 0.229 reward^2 + 0.41 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.076 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 61, 0, 0, 61, 57, 61, 0, 0, 0, 61\n",
      "value_exit: 61, 61, 61, 61, 0, 61\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 312/1000 --- L(Train): 0.0060969 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.684 value_stay[t] + 0.41 reward + 0.047 harvest_duration + -0.017 value_stay^2 + -0.0 value_stay*reward + -0.318 value_stay*harvest_duration + 0.228 reward^2 + 0.41 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.987 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.076 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 62, 0, 0, 62, 58, 62, 0, 0, 0, 62\n",
      "value_exit: 62, 62, 62, 62, 0, 62\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 313/1000 --- L(Train): 0.0060944 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.684 value_stay[t] + 0.41 reward + 0.047 harvest_duration + -0.016 value_stay^2 + 0.001 value_stay*reward + -0.318 value_stay*harvest_duration + 0.227 reward^2 + 0.41 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.076 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 63, 0, 0, 63, 59, 63, 0, 0, 0, 63\n",
      "value_exit: 63, 63, 63, 63, 0, 63\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 314/1000 --- L(Train): 0.0060920 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.683 value_stay[t] + 0.41 reward + 0.046 harvest_duration + -0.016 value_stay^2 + 0.001 value_stay*reward + -0.319 value_stay*harvest_duration + 0.226 reward^2 + 0.411 reward*harvest_duration + 0.046 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.076 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 64, 0, 0, 64, 60, 64, 0, 0, 0, 64\n",
      "value_exit: 64, 64, 64, 64, 0, 64\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 315/1000 --- L(Train): 0.0060899 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.046 1 + 0.683 value_stay[t] + 0.41 reward + 0.047 harvest_duration + -0.015 value_stay^2 + 0.001 value_stay*reward + -0.319 value_stay*harvest_duration + 0.226 reward^2 + 0.411 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.077 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 65, 0, 0, 65, 61, 65, 0, 0, 0, 65\n",
      "value_exit: 65, 65, 65, 65, 0, 65\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 316/1000 --- L(Train): 0.0060870 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.682 value_stay[t] + 0.411 reward + 0.047 harvest_duration + -0.015 value_stay^2 + 0.001 value_stay*reward + -0.319 value_stay*harvest_duration + 0.225 reward^2 + 0.411 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.077 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 66, 0, 0, 66, 62, 66, 0, 0, 0, 66\n",
      "value_exit: 66, 66, 66, 66, 0, 66\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 317/1000 --- L(Train): 0.0060840 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.682 value_stay[t] + 0.411 reward + 0.047 harvest_duration + -0.014 value_stay^2 + 0.0 value_stay*reward + -0.32 value_stay*harvest_duration + 0.224 reward^2 + 0.411 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.077 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 67, 0, 0, 67, 63, 67, 0, 0, 0, 67\n",
      "value_exit: 67, 67, 67, 67, 0, 67\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 318/1000 --- L(Train): 0.0060813 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.682 value_stay[t] + 0.411 reward + 0.047 harvest_duration + -0.014 value_stay^2 + -0.001 value_stay*reward + -0.32 value_stay*harvest_duration + 0.223 reward^2 + 0.411 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.077 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 68, 0, 0, 68, 64, 68, 0, 0, 0, 68\n",
      "value_exit: 68, 68, 68, 68, 0, 68\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 319/1000 --- L(Train): 0.0060791 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.681 value_stay[t] + 0.411 reward + 0.047 harvest_duration + -0.013 value_stay^2 + -0.001 value_stay*reward + -0.32 value_stay*harvest_duration + 0.222 reward^2 + 0.411 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.988 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.077 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 69, 0, 0, 69, 65, 69, 0, 0, 0, 69\n",
      "value_exit: 69, 69, 69, 69, 0, 69\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 320/1000 --- L(Train): 0.0060773 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.681 value_stay[t] + 0.411 reward + 0.047 harvest_duration + -0.012 value_stay^2 + 0.0 value_stay*reward + -0.321 value_stay*harvest_duration + 0.221 reward^2 + 0.412 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.077 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 70, 0, 0, 70, 66, 70, 0, 0, 0, 70\n",
      "value_exit: 70, 70, 70, 70, 0, 70\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 321/1000 --- L(Train): 0.0060753 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.681 value_stay[t] + 0.411 reward + 0.047 harvest_duration + -0.012 value_stay^2 + 0.001 value_stay*reward + -0.321 value_stay*harvest_duration + 0.221 reward^2 + 0.412 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.078 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 71, 0, 0, 71, 67, 71, 0, 0, 0, 71\n",
      "value_exit: 71, 71, 71, 71, 0, 71\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 322/1000 --- L(Train): 0.0060729 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.68 value_stay[t] + 0.412 reward + 0.047 harvest_duration + -0.011 value_stay^2 + 0.001 value_stay*reward + -0.322 value_stay*harvest_duration + 0.22 reward^2 + 0.412 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.078 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 72, 0, 0, 72, 68, 72, 0, 0, 0, 72\n",
      "value_exit: 72, 72, 72, 72, 0, 72\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 323/1000 --- L(Train): 0.0060701 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.68 value_stay[t] + 0.412 reward + 0.047 harvest_duration + -0.011 value_stay^2 + 0.0 value_stay*reward + -0.322 value_stay*harvest_duration + 0.219 reward^2 + 0.412 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.078 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 73, 0, 0, 73, 69, 73, 0, 0, 0, 73\n",
      "value_exit: 73, 73, 73, 73, 0, 73\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 324/1000 --- L(Train): 0.0060674 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.679 value_stay[t] + 0.412 reward + 0.047 harvest_duration + -0.01 value_stay^2 + -0.001 value_stay*reward + -0.322 value_stay*harvest_duration + 0.218 reward^2 + 0.412 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.078 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 74, 0, 0, 74, 70, 74, 0, 0, 0, 74\n",
      "value_exit: 74, 74, 74, 74, 0, 74\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 325/1000 --- L(Train): 0.0060650 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.679 value_stay[t] + 0.412 reward + 0.048 harvest_duration + -0.01 value_stay^2 + -0.0 value_stay*reward + -0.323 value_stay*harvest_duration + 0.217 reward^2 + 0.412 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.989 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.078 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 75, 0, 0, 75, 71, 75, 0, 0, 0, 75\n",
      "value_exit: 75, 75, 75, 75, 0, 75\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 326/1000 --- L(Train): 0.0060629 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.679 value_stay[t] + 0.412 reward + 0.048 harvest_duration + -0.009 value_stay^2 + 0.001 value_stay*reward + -0.323 value_stay*harvest_duration + 0.216 reward^2 + 0.412 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.078 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 76, 0, 0, 76, 72, 76, 0, 0, 0, 76\n",
      "value_exit: 76, 76, 76, 76, 0, 76\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 327/1000 --- L(Train): 0.0060612 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.678 value_stay[t] + 0.412 reward + 0.047 harvest_duration + -0.009 value_stay^2 + 0.001 value_stay*reward + -0.324 value_stay*harvest_duration + 0.216 reward^2 + 0.413 reward*harvest_duration + 0.047 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.079 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 77, 0, 0, 77, 73, 77, 0, 0, 0, 77\n",
      "value_exit: 77, 77, 77, 77, 0, 77\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 328/1000 --- L(Train): 0.0060593 --- L(Val, SINDy): 0.0000000 --- Time: 0.09s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.678 value_stay[t] + 0.412 reward + 0.048 harvest_duration + -0.008 value_stay^2 + 0.002 value_stay*reward + -0.324 value_stay*harvest_duration + 0.215 reward^2 + 0.413 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.079 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 78, 0, 0, 78, 74, 78, 0, 0, 0, 78\n",
      "value_exit: 78, 78, 78, 78, 0, 78\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 329/1000 --- L(Train): 0.0060574 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.678 value_stay[t] + 0.413 reward + 0.048 harvest_duration + -0.007 value_stay^2 + 0.001 value_stay*reward + -0.324 value_stay*harvest_duration + 0.214 reward^2 + 0.413 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.079 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 79, 0, 0, 79, 75, 79, 0, 0, 0, 79\n",
      "value_exit: 79, 79, 79, 79, 0, 79\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 330/1000 --- L(Train): 0.0060554 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.047 1 + 0.677 value_stay[t] + 0.413 reward + 0.047 harvest_duration + -0.007 value_stay^2 + 0.0 value_stay*reward + -0.325 value_stay*harvest_duration + 0.213 reward^2 + 0.413 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.079 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 80, 0, 0, 80, 76, 80, 0, 0, 0, 80\n",
      "value_exit: 80, 80, 80, 80, 0, 80\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 331/1000 --- L(Train): 0.0060533 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.677 value_stay[t] + 0.413 reward + 0.048 harvest_duration + -0.006 value_stay^2 + -0.001 value_stay*reward + -0.325 value_stay*harvest_duration + 0.212 reward^2 + 0.413 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.079 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 81, 0, 0, 81, 77, 81, 0, 0, 0, 81\n",
      "value_exit: 81, 81, 81, 81, 0, 81\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 332/1000 --- L(Train): 0.0060503 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.677 value_stay[t] + 0.413 reward + 0.048 harvest_duration + -0.006 value_stay^2 + -0.0 value_stay*reward + -0.325 value_stay*harvest_duration + 0.211 reward^2 + 0.413 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.99 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.079 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 82, 0, 0, 82, 78, 82, 0, 0, 0, 82\n",
      "value_exit: 82, 82, 82, 82, 0, 82\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 333/1000 --- L(Train): 0.0060475 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.676 value_stay[t] + 0.413 reward + 0.048 harvest_duration + -0.005 value_stay^2 + 0.0 value_stay*reward + -0.326 value_stay*harvest_duration + 0.211 reward^2 + 0.414 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.08 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 83, 0, 0, 83, 79, 83, 0, 0, 0, 83\n",
      "value_exit: 83, 83, 83, 83, 0, 83\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 334/1000 --- L(Train): 0.0060458 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.676 value_stay[t] + 0.413 reward + 0.048 harvest_duration + -0.005 value_stay^2 + 0.001 value_stay*reward + -0.326 value_stay*harvest_duration + 0.21 reward^2 + 0.414 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.08 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 84, 0, 0, 84, 80, 84, 0, 0, 0, 84\n",
      "value_exit: 84, 84, 84, 84, 0, 84\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 335/1000 --- L(Train): 0.0060443 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.675 value_stay[t] + 0.414 reward + 0.048 harvest_duration + -0.004 value_stay^2 + 0.001 value_stay*reward + -0.326 value_stay*harvest_duration + 0.209 reward^2 + 0.414 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + 0.001 value_exit^2 + -0.08 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 85, 0, 0, 85, 81, 85, 0, 0, 0, 85\n",
      "value_exit: 85, 85, 85, 85, 0, 85\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 336/1000 --- L(Train): 0.0060426 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.675 value_stay[t] + 0.414 reward + 0.048 harvest_duration + -0.003 value_stay^2 + 0.0 value_stay*reward + -0.327 value_stay*harvest_duration + 0.208 reward^2 + 0.414 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.08 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 86, 0, 0, 86, 82, 86, 0, 0, 0, 86\n",
      "value_exit: 86, 86, 86, 86, 0, 86\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 337/1000 --- L(Train): 0.0060406 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.675 value_stay[t] + 0.414 reward + 0.048 harvest_duration + -0.003 value_stay^2 + -0.0 value_stay*reward + -0.327 value_stay*harvest_duration + 0.207 reward^2 + 0.414 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.08 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 87, 0, 0, 87, 83, 87, 0, 0, 0, 87\n",
      "value_exit: 87, 87, 87, 87, 0, 87\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 338/1000 --- L(Train): 0.0060383 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.674 value_stay[t] + 0.414 reward + 0.049 harvest_duration + -0.002 value_stay^2 + -0.0 value_stay*reward + -0.328 value_stay*harvest_duration + 0.206 reward^2 + 0.414 reward*harvest_duration + 0.049 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.991 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.08 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 88, 0, 0, 88, 84, 88, 0, 0, 0, 88\n",
      "value_exit: 88, 88, 88, 88, 0, 88\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 339/1000 --- L(Train): 0.0060362 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.674 value_stay[t] + 0.414 reward + 0.048 harvest_duration + -0.002 value_stay^2 + 0.001 value_stay*reward + -0.328 value_stay*harvest_duration + 0.206 reward^2 + 0.415 reward*harvest_duration + 0.049 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.992 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.081 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 89, 0, 0, 89, 85, 89, 0, 0, 0, 89\n",
      "value_exit: 89, 89, 89, 89, 0, 89\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 340/1000 --- L(Train): 0.0060346 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.673 value_stay[t] + 0.414 reward + 0.048 harvest_duration + -0.001 value_stay^2 + 0.002 value_stay*reward + -0.328 value_stay*harvest_duration + 0.205 reward^2 + 0.415 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.992 value_exit[t] + -0.001 travel_duration + -0.001 value_exit^2 + -0.081 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 90, 0, 0, 90, 86, 90, 0, 0, 0, 90\n",
      "value_exit: 90, 90, 90, 90, 0, 90\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 341/1000 --- L(Train): 0.0060329 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.673 value_stay[t] + 0.415 reward + 0.049 harvest_duration + -0.001 value_stay^2 + 0.002 value_stay*reward + -0.329 value_stay*harvest_duration + 0.204 reward^2 + 0.415 reward*harvest_duration + 0.049 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.992 value_exit[t] + -0.001 travel_duration + -0.001 value_exit^2 + -0.081 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 91, 0, 0, 91, 87, 91, 0, 0, 0, 91\n",
      "value_exit: 91, 91, 91, 91, 0, 91\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 342/1000 --- L(Train): 0.0060309 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.673 value_stay[t] + 0.415 reward + 0.049 harvest_duration + 0.0 value_stay^2 + 0.002 value_stay*reward + -0.329 value_stay*harvest_duration + 0.203 reward^2 + 0.415 reward*harvest_duration + 0.049 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.992 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.081 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 92, 0, 0, 92, 88, 92, 0, 0, 0, 92\n",
      "value_exit: 92, 92, 92, 92, 0, 92\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 343/1000 --- L(Train): 0.0060287 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.048 1 + 0.672 value_stay[t] + 0.415 reward + 0.048 harvest_duration + 0.0 value_stay^2 + 0.001 value_stay*reward + -0.33 value_stay*harvest_duration + 0.202 reward^2 + 0.415 reward*harvest_duration + 0.048 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.081 value_exit*travel_duration + -0.005 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 93, 0, 0, 93, 89, 93, 0, 0, 0, 93\n",
      "value_exit: 93, 93, 93, 93, 0, 93\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 344/1000 --- L(Train): 0.0060271 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.672 value_stay[t] + 0.415 reward + 0.049 harvest_duration + 0.0 value_stay^2 + -0.0 value_stay*reward + -0.33 value_stay*harvest_duration + 0.201 reward^2 + 0.415 reward*harvest_duration + 0.049 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.992 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.081 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 94, 0, 0, 94, 90, 94, 0, 0, 0, 94\n",
      "value_exit: 94, 94, 94, 94, 0, 94\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 345/1000 --- L(Train): 0.0060251 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.672 value_stay[t] + 0.415 reward + 0.049 harvest_duration + -0.0 value_stay^2 + -0.0 value_stay*reward + -0.33 value_stay*harvest_duration + 0.2 reward^2 + 0.416 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.993 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.081 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 95, 0, 0, 95, 91, 95, 0, 0, 0, 95\n",
      "value_exit: 95, 95, 95, 95, 0, 95\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 346/1000 --- L(Train): 0.0060231 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.671 value_stay[t] + 0.415 reward + 0.049 harvest_duration + -0.0 value_stay^2 + 0.001 value_stay*reward + -0.331 value_stay*harvest_duration + 0.2 reward^2 + 0.416 reward*harvest_duration + 0.049 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.993 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.082 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 96, 0, 0, 96, 92, 96, 0, 0, 0, 96\n",
      "value_exit: 96, 96, 96, 96, 0, 96\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 347/1000 --- L(Train): 0.0060214 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.671 value_stay[t] + 0.416 reward + 0.049 harvest_duration + -0.001 value_stay^2 + 0.002 value_stay*reward + -0.331 value_stay*harvest_duration + 0.199 reward^2 + 0.416 reward*harvest_duration + 0.049 harvest_duration^2 \n",
      "value_exit[t+1] = 0.0 1 + 0.993 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.082 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 97, 0, 0, 97, 93, 97, 0, 0, 0, 97\n",
      "value_exit: 97, 97, 97, 97, 0, 97\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 348/1000 --- L(Train): 0.0060200 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.05 1 + 0.671 value_stay[t] + 0.416 reward + 0.05 harvest_duration + -0.0 value_stay^2 + 0.002 value_stay*reward + -0.331 value_stay*harvest_duration + 0.198 reward^2 + 0.416 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.993 value_exit[t] + -0.001 travel_duration + -0.0 value_exit^2 + -0.082 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 98, 0, 0, 98, 94, 98, 0, 0, 0, 98\n",
      "value_exit: 98, 98, 98, 98, 0, 98\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 349/1000 --- L(Train): 0.0060184 --- L(Val, SINDy): 0.0000000 --- Time: 0.09s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 16):\n",
      "value_stay[t+1] = 0.049 1 + 0.671 value_stay[t] + 0.416 reward + 0.049 harvest_duration + -0.0 value_stay^2 + 0.002 value_stay*reward + -0.331 value_stay*harvest_duration + 0.197 reward^2 + 0.416 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = -0.0 1 + 0.993 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.082 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 99, 0, 0, 99, 95, 99, 0, 0, 0, 99\n",
      "value_exit: 99, 99, 99, 99, 0, 99\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 350/1000 --- L(Train): 0.0060170 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 15):\n",
      "value_stay[t+1] = 0.049 1 + 0.67 value_stay[t] + 0.416 reward + 0.049 harvest_duration + -0.0 value_stay^2 + 0.001 value_stay*reward + -0.331 value_stay*harvest_duration + 0.196 reward^2 + 0.416 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = 0.994 value_exit[t] + -0.001 travel_duration + 0.0 value_exit^2 + -0.082 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 100, 0, 0, 100, 96, 100, 0, 0, 0, 100\n",
      "value_exit: -, 100, 100, 100, 0, 100\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 351/1000 --- L(Train): 0.0060162 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 14):\n",
      "value_stay[t+1] = 0.05 1 + 0.67 value_stay[t] + 0.416 reward + 0.05 harvest_duration + 0.0 value_stay^2 + 0.001 value_stay*reward + -0.332 value_stay*harvest_duration + 0.195 reward^2 + 0.417 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = 0.994 value_exit[t] + -0.001 travel_duration + -0.082 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 101, 0, 0, 101, 97, 101, 0, 0, 0, 0\n",
      "value_exit: -, 101, 101, -, 0, 101\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 352/1000 --- L(Train): 0.0060145 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 13):\n",
      "value_stay[t+1] = 0.05 1 + 0.67 value_stay[t] + 0.416 reward + 0.05 harvest_duration + 0.0 value_stay^2 + -0.332 value_stay*harvest_duration + 0.195 reward^2 + 0.417 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = 0.994 value_exit[t] + -0.001 travel_duration + -0.083 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 102, 0, 0, 102, 98, -, 0, 0, 0, 1\n",
      "value_exit: -, 102, 102, -, 0, 102\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 353/1000 --- L(Train): 0.0060143 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_stay[t+1] = 0.05 1 + 0.67 value_stay[t] + 0.417 reward + 0.05 harvest_duration + 0.0 value_stay^2 + -0.332 value_stay*harvest_duration + 0.194 reward^2 + 0.417 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = 0.994 value_exit[t] + -0.083 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 103, 0, 0, 103, 99, -, 0, 0, 0, 2\n",
      "value_exit: -, 103, -, -, 0, 103\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 354/1000 --- L(Train): 0.0063723 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 11):\n",
      "value_stay[t+1] = 0.05 1 + 0.67 value_stay[t] + 0.417 reward + 0.05 harvest_duration + -0.332 value_stay*harvest_duration + 0.193 reward^2 + 0.417 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = 0.994 value_exit[t] + -0.083 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 104, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, 104, -, -, 0, 104\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 355/1000 --- L(Train): 0.0171811 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 10):\n",
      "value_stay[t+1] = 0.05 1 + 0.67 value_stay[t] + 0.417 reward + 0.05 harvest_duration + -0.332 value_stay*harvest_duration + 0.192 reward^2 + 0.417 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.083 value_exit*travel_duration + -0.006 travel_duration^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 105, 0, 0, 1, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 0, 105\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 356/1000 --- L(Train): 0.0415292 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 9):\n",
      "value_stay[t+1] = 0.05 1 + 0.67 value_stay[t] + 0.417 reward + 0.05 harvest_duration + -0.332 value_stay*harvest_duration + 0.191 reward^2 + 0.418 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.083 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: 106, 0, 0, 2, -, -, 0, 0, 0, 1\n",
      "value_exit: -, -, -, -, 0, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 357/1000 --- L(Train): 0.0638916 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.418 reward + 0.05 harvest_duration + -0.332 value_stay*harvest_duration + 0.19 reward^2 + 0.418 reward*harvest_duration + 0.05 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.079 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 3, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 0, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 358/1000 --- L(Train): 0.0622400 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.673 value_stay[t] + 0.42 reward + 0.062 harvest_duration + -0.328 value_stay*harvest_duration + 0.191 reward^2 + 0.42 reward*harvest_duration + 0.062 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.071 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 0, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 359/1000 --- L(Train): 0.0535363 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.674 value_stay[t] + 0.42 reward + 0.064 harvest_duration + -0.328 value_stay*harvest_duration + 0.19 reward^2 + 0.42 reward*harvest_duration + 0.064 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.06 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 0, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 360/1000 --- L(Train): 0.0413205 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.419 reward + 0.056 harvest_duration + -0.331 value_stay*harvest_duration + 0.188 reward^2 + 0.419 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.048 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 1, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 361/1000 --- L(Train): 0.0284234 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.418 reward + 0.051 harvest_duration + -0.333 value_stay*harvest_duration + 0.187 reward^2 + 0.418 reward*harvest_duration + 0.051 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.034 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 2, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 362/1000 --- L(Train): 0.0190179 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.419 reward + 0.054 harvest_duration + -0.331 value_stay*harvest_duration + 0.187 reward^2 + 0.419 reward*harvest_duration + 0.054 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.02 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 3, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 363/1000 --- L(Train): 0.0134318 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.673 value_stay[t] + 0.421 reward + 0.061 harvest_duration + -0.329 value_stay*harvest_duration + 0.187 reward^2 + 0.421 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.007 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 4, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 364/1000 --- L(Train): 0.0114087 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.674 value_stay[t] + 0.421 reward + 0.062 harvest_duration + -0.328 value_stay*harvest_duration + 0.186 reward^2 + 0.421 reward*harvest_duration + 0.062 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.006 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 5, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 365/1000 --- L(Train): 0.0125463 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.672 value_stay[t] + 0.42 reward + 0.057 harvest_duration + -0.33 value_stay*harvest_duration + 0.185 reward^2 + 0.42 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.017 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 6, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 366/1000 --- L(Train): 0.0156896 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.419 reward + 0.053 harvest_duration + -0.332 value_stay*harvest_duration + 0.183 reward^2 + 0.42 reward*harvest_duration + 0.053 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.026 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 7, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 367/1000 --- L(Train): 0.0195231 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.42 reward + 0.054 harvest_duration + -0.332 value_stay*harvest_duration + 0.182 reward^2 + 0.42 reward*harvest_duration + 0.054 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.033 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 8, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 368/1000 --- L(Train): 0.0227669 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.672 value_stay[t] + 0.421 reward + 0.058 harvest_duration + -0.33 value_stay*harvest_duration + 0.182 reward^2 + 0.421 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.037 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 9, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 369/1000 --- L(Train): 0.0246113 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.673 value_stay[t] + 0.422 reward + 0.061 harvest_duration + -0.329 value_stay*harvest_duration + 0.182 reward^2 + 0.422 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.039 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 10, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 370/1000 --- L(Train): 0.0247713 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.672 value_stay[t] + 0.422 reward + 0.059 harvest_duration + -0.33 value_stay*harvest_duration + 0.181 reward^2 + 0.422 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.039 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 11, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 371/1000 --- L(Train): 0.0233353 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.421 reward + 0.055 harvest_duration + -0.332 value_stay*harvest_duration + 0.179 reward^2 + 0.421 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.037 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 12, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 372/1000 --- L(Train): 0.0207042 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.421 reward + 0.054 harvest_duration + -0.332 value_stay*harvest_duration + 0.178 reward^2 + 0.421 reward*harvest_duration + 0.054 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.034 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 13, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 373/1000 --- L(Train): 0.0174912 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.421 reward + 0.056 harvest_duration + -0.331 value_stay*harvest_duration + 0.178 reward^2 + 0.422 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.029 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 14, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 374/1000 --- L(Train): 0.0143616 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.672 value_stay[t] + 0.423 reward + 0.059 harvest_duration + -0.33 value_stay*harvest_duration + 0.178 reward^2 + 0.423 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.023 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 15, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 375/1000 --- L(Train): 0.0116628 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.672 value_stay[t] + 0.423 reward + 0.06 harvest_duration + -0.33 value_stay*harvest_duration + 0.177 reward^2 + 0.423 reward*harvest_duration + 0.06 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.016 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 16, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 376/1000 --- L(Train): 0.0097927 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.423 reward + 0.058 harvest_duration + -0.331 value_stay*harvest_duration + 0.176 reward^2 + 0.423 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.01 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 17, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 377/1000 --- L(Train): 0.0088213 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.422 reward + 0.055 harvest_duration + -0.332 value_stay*harvest_duration + 0.174 reward^2 + 0.422 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 18, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 378/1000 --- L(Train): 0.0086743 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.422 reward + 0.055 harvest_duration + -0.332 value_stay*harvest_duration + 0.174 reward^2 + 0.423 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 19, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 379/1000 --- L(Train): 0.0091661 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.423 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.173 reward^2 + 0.423 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.008 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 20, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 380/1000 --- L(Train): 0.0099707 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.672 value_stay[t] + 0.424 reward + 0.059 harvest_duration + -0.33 value_stay*harvest_duration + 0.173 reward^2 + 0.424 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.012 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 21, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 381/1000 --- L(Train): 0.0108111 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.672 value_stay[t] + 0.424 reward + 0.059 harvest_duration + -0.33 value_stay*harvest_duration + 0.172 reward^2 + 0.424 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.015 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 22, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 382/1000 --- L(Train): 0.0114317 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.424 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.171 reward^2 + 0.424 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.018 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 23, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 383/1000 --- L(Train): 0.0117198 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.423 reward + 0.055 harvest_duration + -0.332 value_stay*harvest_duration + 0.17 reward^2 + 0.424 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.019 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 24, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 384/1000 --- L(Train): 0.0115927 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.424 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.169 reward^2 + 0.424 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.019 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 25, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 385/1000 --- L(Train): 0.0111641 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.425 reward + 0.058 harvest_duration + -0.331 value_stay*harvest_duration + 0.169 reward^2 + 0.425 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.018 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 26, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 386/1000 --- L(Train): 0.0104887 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.672 value_stay[t] + 0.425 reward + 0.059 harvest_duration + -0.33 value_stay*harvest_duration + 0.168 reward^2 + 0.425 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.016 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 27, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 387/1000 --- L(Train): 0.0097370 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.425 reward + 0.058 harvest_duration + -0.331 value_stay*harvest_duration + 0.167 reward^2 + 0.426 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.014 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 28, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 388/1000 --- L(Train): 0.0090256 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.425 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.166 reward^2 + 0.425 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.011 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 29, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 389/1000 --- L(Train): 0.0084572 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.425 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.165 reward^2 + 0.425 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.008 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 30, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 390/1000 --- L(Train): 0.0080986 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.425 reward + 0.056 harvest_duration + -0.331 value_stay*harvest_duration + 0.165 reward^2 + 0.426 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.005 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 31, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 391/1000 --- L(Train): 0.0079419 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.426 reward + 0.058 harvest_duration + -0.331 value_stay*harvest_duration + 0.164 reward^2 + 0.426 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 32, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 392/1000 --- L(Train): 0.0079673 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.426 reward + 0.058 harvest_duration + -0.331 value_stay*harvest_duration + 0.163 reward^2 + 0.427 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 33, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 393/1000 --- L(Train): 0.0081084 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.426 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.162 reward^2 + 0.427 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 34, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 394/1000 --- L(Train): 0.0083080 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.426 reward + 0.056 harvest_duration + -0.331 value_stay*harvest_duration + 0.161 reward^2 + 0.427 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.006 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 35, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 395/1000 --- L(Train): 0.0084794 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.427 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.161 reward^2 + 0.427 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.007 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 36, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 396/1000 --- L(Train): 0.0085767 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 8):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.427 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.16 reward^2 + 0.427 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.008 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 37, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 397/1000 --- L(Train): 0.0086012 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.427 reward + 0.058 harvest_duration + -0.331 value_stay*harvest_duration + 0.159 reward^2 + 0.428 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.009 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 38, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 398/1000 --- L(Train): 0.0085266 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.428 reward + 0.058 harvest_duration + -0.331 value_stay*harvest_duration + 0.159 reward^2 + 0.428 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.009 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 39, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 399/1000 --- L(Train): 0.0083880 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.428 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.158 reward^2 + 0.428 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.008 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 40, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 400/1000 --- L(Train): 0.0082139 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.428 reward + 0.056 harvest_duration + -0.331 value_stay*harvest_duration + 0.157 reward^2 + 0.428 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.008 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 41, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 401/1000 --- L(Train): 0.0080382 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.428 reward + 0.056 harvest_duration + -0.331 value_stay*harvest_duration + 0.156 reward^2 + 0.428 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.006 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 42, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 402/1000 --- L(Train): 0.0078863 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.428 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.156 reward^2 + 0.429 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.005 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 43, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 403/1000 --- L(Train): 0.0077706 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.429 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.155 reward^2 + 0.429 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 44, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 404/1000 --- L(Train): 0.0077111 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.429 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.154 reward^2 + 0.429 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 45, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 405/1000 --- L(Train): 0.0076962 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.429 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.153 reward^2 + 0.429 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 46, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 406/1000 --- L(Train): 0.0077245 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.429 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.152 reward^2 + 0.43 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 47, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 407/1000 --- L(Train): 0.0077634 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.43 reward + 0.056 harvest_duration + -0.331 value_stay*harvest_duration + 0.152 reward^2 + 0.43 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 48, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 408/1000 --- L(Train): 0.0078075 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.43 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.151 reward^2 + 0.43 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 49, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 409/1000 --- L(Train): 0.0078412 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.43 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.15 reward^2 + 0.431 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 50, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 410/1000 --- L(Train): 0.0078392 --- L(Val, SINDy): 0.0000000 --- Time: 0.09s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.43 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.149 reward^2 + 0.431 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 51, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 411/1000 --- L(Train): 0.0078330 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.431 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.149 reward^2 + 0.431 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 52, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 412/1000 --- L(Train): 0.0078023 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.431 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.148 reward^2 + 0.431 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 53, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 413/1000 --- L(Train): 0.0077585 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.431 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.147 reward^2 + 0.431 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.004 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 54, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 414/1000 --- L(Train): 0.0077174 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.431 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.146 reward^2 + 0.432 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 55, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 415/1000 --- L(Train): 0.0076680 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.432 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.146 reward^2 + 0.432 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.003 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 56, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 416/1000 --- L(Train): 0.0076519 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.432 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.145 reward^2 + 0.432 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 57, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 417/1000 --- L(Train): 0.0076305 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.432 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.144 reward^2 + 0.432 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 58, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 418/1000 --- L(Train): 0.0076204 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.432 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.143 reward^2 + 0.432 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 59, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 419/1000 --- L(Train): 0.0076278 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.432 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.143 reward^2 + 0.433 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 60, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 420/1000 --- L(Train): 0.0076287 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.433 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.142 reward^2 + 0.433 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 61, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 421/1000 --- L(Train): 0.0076387 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.433 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.141 reward^2 + 0.433 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 62, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 422/1000 --- L(Train): 0.0076439 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.433 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.14 reward^2 + 0.433 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 63, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 423/1000 --- L(Train): 0.0076415 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.433 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.139 reward^2 + 0.434 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 64, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 424/1000 --- L(Train): 0.0076497 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.434 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.139 reward^2 + 0.434 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 65, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 425/1000 --- L(Train): 0.0076399 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.434 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.138 reward^2 + 0.434 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 66, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 426/1000 --- L(Train): 0.0076214 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.434 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.137 reward^2 + 0.434 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 67, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 427/1000 --- L(Train): 0.0076113 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.434 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.136 reward^2 + 0.435 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.002 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 68, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 428/1000 --- L(Train): 0.0075970 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.434 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.136 reward^2 + 0.435 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 69, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 429/1000 --- L(Train): 0.0075857 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.435 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.135 reward^2 + 0.435 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 70, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 430/1000 --- L(Train): 0.0075990 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.435 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.134 reward^2 + 0.435 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 71, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 431/1000 --- L(Train): 0.0075902 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.435 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.133 reward^2 + 0.435 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 72, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 432/1000 --- L(Train): 0.0076027 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.435 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.133 reward^2 + 0.436 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 73, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 433/1000 --- L(Train): 0.0076170 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.436 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.132 reward^2 + 0.436 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 74, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 434/1000 --- L(Train): 0.0076208 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.436 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.131 reward^2 + 0.436 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 75, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 435/1000 --- L(Train): 0.0076091 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.436 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.13 reward^2 + 0.436 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 76, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 436/1000 --- L(Train): 0.0075985 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.436 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.13 reward^2 + 0.437 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 77, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 437/1000 --- L(Train): 0.0076064 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.437 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.129 reward^2 + 0.437 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 78, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 438/1000 --- L(Train): 0.0075865 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.437 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.128 reward^2 + 0.437 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 79, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 439/1000 --- L(Train): 0.0075840 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.437 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.127 reward^2 + 0.437 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 80, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 440/1000 --- L(Train): 0.0075829 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.437 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.127 reward^2 + 0.437 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 81, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 441/1000 --- L(Train): 0.0075801 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.437 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.126 reward^2 + 0.438 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 82, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 442/1000 --- L(Train): 0.0075799 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.438 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.125 reward^2 + 0.438 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 83, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 443/1000 --- L(Train): 0.0075768 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.438 reward + 0.057 harvest_duration + -0.332 value_stay*harvest_duration + 0.124 reward^2 + 0.438 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 84, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 444/1000 --- L(Train): 0.0075894 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.438 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.124 reward^2 + 0.438 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 85, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 445/1000 --- L(Train): 0.0075787 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.438 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.123 reward^2 + 0.439 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 86, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 446/1000 --- L(Train): 0.0075897 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.438 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.122 reward^2 + 0.439 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 87, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 447/1000 --- L(Train): 0.0075664 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.439 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.121 reward^2 + 0.439 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 88, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 448/1000 --- L(Train): 0.0075742 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.439 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.121 reward^2 + 0.439 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 89, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 449/1000 --- L(Train): 0.0075742 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.439 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.12 reward^2 + 0.44 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 90, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 450/1000 --- L(Train): 0.0075570 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.439 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.119 reward^2 + 0.44 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.001 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 91, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 451/1000 --- L(Train): 0.0075621 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.44 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.118 reward^2 + 0.44 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 92, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 452/1000 --- L(Train): 0.0075764 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.44 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.118 reward^2 + 0.44 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 93, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 453/1000 --- L(Train): 0.0075608 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.44 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.117 reward^2 + 0.44 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 94, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 454/1000 --- L(Train): 0.0075641 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.44 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.116 reward^2 + 0.441 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + 0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 95, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 455/1000 --- L(Train): 0.0075598 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.441 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.115 reward^2 + 0.441 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 96, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 456/1000 --- L(Train): 0.0075713 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.441 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.115 reward^2 + 0.441 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 97, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 457/1000 --- L(Train): 0.0075682 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.441 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.114 reward^2 + 0.441 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 98, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 458/1000 --- L(Train): 0.0075665 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 7):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.441 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.113 reward^2 + 0.442 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] + -0.0 value_exit*travel_duration \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, 99, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 459/1000 --- L(Train): 0.0075568 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.441 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.112 reward^2 + 0.442 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 460/1000 --- L(Train): 0.0075530 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.442 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.112 reward^2 + 0.442 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 461/1000 --- L(Train): 0.0075524 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.442 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.111 reward^2 + 0.442 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 462/1000 --- L(Train): 0.0075515 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.442 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.11 reward^2 + 0.442 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 463/1000 --- L(Train): 0.0075651 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.442 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.109 reward^2 + 0.443 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 464/1000 --- L(Train): 0.0075614 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.443 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.109 reward^2 + 0.443 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 465/1000 --- L(Train): 0.0075630 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.443 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.108 reward^2 + 0.443 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 466/1000 --- L(Train): 0.0077042 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.443 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.107 reward^2 + 0.443 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 467/1000 --- L(Train): 0.0076024 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.443 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.106 reward^2 + 0.444 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 468/1000 --- L(Train): 0.0075518 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.443 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.106 reward^2 + 0.444 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 469/1000 --- L(Train): 0.0076344 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.444 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.105 reward^2 + 0.444 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 470/1000 --- L(Train): 0.0076420 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.444 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.104 reward^2 + 0.444 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 471/1000 --- L(Train): 0.0076508 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.444 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.104 reward^2 + 0.444 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 472/1000 --- L(Train): 0.0075902 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.444 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.103 reward^2 + 0.445 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 473/1000 --- L(Train): 0.0075512 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.445 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.102 reward^2 + 0.445 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 474/1000 --- L(Train): 0.0075909 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.445 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.101 reward^2 + 0.445 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 475/1000 --- L(Train): 0.0076384 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.445 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.101 reward^2 + 0.445 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 476/1000 --- L(Train): 0.0076803 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.445 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.1 reward^2 + 0.445 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 477/1000 --- L(Train): 0.0076141 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.445 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.099 reward^2 + 0.446 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 478/1000 --- L(Train): 0.0076397 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.446 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.098 reward^2 + 0.446 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 479/1000 --- L(Train): 0.0075851 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.446 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.098 reward^2 + 0.446 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 480/1000 --- L(Train): 0.0076137 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.446 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.097 reward^2 + 0.446 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 481/1000 --- L(Train): 0.0076335 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.446 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.096 reward^2 + 0.447 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 482/1000 --- L(Train): 0.0076221 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.446 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.095 reward^2 + 0.447 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 483/1000 --- L(Train): 0.0076201 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.447 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.095 reward^2 + 0.447 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 484/1000 --- L(Train): 0.0075723 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.447 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.094 reward^2 + 0.447 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 485/1000 --- L(Train): 0.0075909 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.447 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.093 reward^2 + 0.447 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 486/1000 --- L(Train): 0.0075790 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.447 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.093 reward^2 + 0.448 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 487/1000 --- L(Train): 0.0075936 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.448 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.092 reward^2 + 0.448 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 488/1000 --- L(Train): 0.0075974 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.448 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.091 reward^2 + 0.448 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 489/1000 --- L(Train): 0.0075956 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.448 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.09 reward^2 + 0.448 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 490/1000 --- L(Train): 0.0075825 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.448 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.09 reward^2 + 0.449 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 491/1000 --- L(Train): 0.0076044 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.448 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.089 reward^2 + 0.449 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 492/1000 --- L(Train): 0.0075802 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.449 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.088 reward^2 + 0.449 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 493/1000 --- L(Train): 0.0075647 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.449 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.088 reward^2 + 0.449 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 494/1000 --- L(Train): 0.0075829 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.449 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.087 reward^2 + 0.449 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 495/1000 --- L(Train): 0.0075532 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.67 value_stay[t] + 0.449 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.086 reward^2 + 0.45 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 496/1000 --- L(Train): 0.0075604 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.45 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.085 reward^2 + 0.45 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 497/1000 --- L(Train): 0.0075594 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.45 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.085 reward^2 + 0.45 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 498/1000 --- L(Train): 0.0075484 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.45 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.084 reward^2 + 0.45 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 499/1000 --- L(Train): 0.0075602 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.45 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.083 reward^2 + 0.45 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 500/1000 --- L(Train): 0.0075491 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.45 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.082 reward^2 + 0.451 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 501/1000 --- L(Train): 0.0075389 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.451 reward + 0.056 harvest_duration + -0.332 value_stay*harvest_duration + 0.082 reward^2 + 0.451 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 502/1000 --- L(Train): 0.0075481 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.451 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.081 reward^2 + 0.451 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 503/1000 --- L(Train): 0.0075567 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.451 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.08 reward^2 + 0.451 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 504/1000 --- L(Train): 0.0075358 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.451 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.08 reward^2 + 0.452 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 505/1000 --- L(Train): 0.0075567 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.451 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.079 reward^2 + 0.452 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 506/1000 --- L(Train): 0.0075542 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.452 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.078 reward^2 + 0.452 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 507/1000 --- L(Train): 0.0075357 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.452 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.077 reward^2 + 0.452 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 508/1000 --- L(Train): 0.0075413 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.452 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.077 reward^2 + 0.452 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 509/1000 --- L(Train): 0.0075461 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.452 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.076 reward^2 + 0.453 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 510/1000 --- L(Train): 0.0075356 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.453 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.075 reward^2 + 0.453 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 511/1000 --- L(Train): 0.0075352 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.453 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.075 reward^2 + 0.453 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 512/1000 --- L(Train): 0.0075384 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.453 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.074 reward^2 + 0.453 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 513/1000 --- L(Train): 0.0075360 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.453 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.073 reward^2 + 0.453 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 514/1000 --- L(Train): 0.0075348 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.453 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.073 reward^2 + 0.454 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 515/1000 --- L(Train): 0.0075562 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.454 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.072 reward^2 + 0.454 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 516/1000 --- L(Train): 0.0075515 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.454 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.071 reward^2 + 0.454 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 517/1000 --- L(Train): 0.0075562 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.454 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.07 reward^2 + 0.454 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 518/1000 --- L(Train): 0.0075326 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.454 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.07 reward^2 + 0.455 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 519/1000 --- L(Train): 0.0075506 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.454 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.069 reward^2 + 0.455 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 520/1000 --- L(Train): 0.0075366 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.455 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.068 reward^2 + 0.455 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 521/1000 --- L(Train): 0.0075376 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.455 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.068 reward^2 + 0.455 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 522/1000 --- L(Train): 0.0075589 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.455 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.067 reward^2 + 0.455 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 523/1000 --- L(Train): 0.0075474 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.455 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.066 reward^2 + 0.456 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 524/1000 --- L(Train): 0.0075497 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.455 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.066 reward^2 + 0.456 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 525/1000 --- L(Train): 0.0075405 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.456 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.065 reward^2 + 0.456 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 526/1000 --- L(Train): 0.0075417 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.456 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.064 reward^2 + 0.456 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 527/1000 --- L(Train): 0.0075335 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.456 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.063 reward^2 + 0.456 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 528/1000 --- L(Train): 0.0075424 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.456 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.063 reward^2 + 0.457 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 529/1000 --- L(Train): 0.0075324 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.457 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.062 reward^2 + 0.457 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 530/1000 --- L(Train): 0.0075298 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.457 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.061 reward^2 + 0.457 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 531/1000 --- L(Train): 0.0075375 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.457 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.061 reward^2 + 0.457 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 532/1000 --- L(Train): 0.0075269 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.457 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.06 reward^2 + 0.457 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 533/1000 --- L(Train): 0.0075275 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.457 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.059 reward^2 + 0.458 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 534/1000 --- L(Train): 0.0075318 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.458 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.059 reward^2 + 0.458 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 535/1000 --- L(Train): 0.0075240 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.458 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.058 reward^2 + 0.458 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 536/1000 --- L(Train): 0.0075270 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.458 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.057 reward^2 + 0.458 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 537/1000 --- L(Train): 0.0075294 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.458 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.057 reward^2 + 0.458 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 538/1000 --- L(Train): 0.0075230 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.458 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.056 reward^2 + 0.459 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 539/1000 --- L(Train): 0.0075260 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.459 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.055 reward^2 + 0.459 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 540/1000 --- L(Train): 0.0075277 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.459 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.054 reward^2 + 0.459 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 541/1000 --- L(Train): 0.0075226 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.459 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.054 reward^2 + 0.459 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 542/1000 --- L(Train): 0.0075248 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.459 reward + 0.056 harvest_duration + -0.333 value_stay*harvest_duration + 0.053 reward^2 + 0.46 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 543/1000 --- L(Train): 0.0075258 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.459 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.052 reward^2 + 0.46 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 544/1000 --- L(Train): 0.0075224 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.46 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.052 reward^2 + 0.46 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 545/1000 --- L(Train): 0.0075237 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.46 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.051 reward^2 + 0.46 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 546/1000 --- L(Train): 0.0075246 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.46 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.05 reward^2 + 0.46 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 0, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 547/1000 --- L(Train): 0.0075222 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.46 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.05 reward^2 + 0.461 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 1, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 548/1000 --- L(Train): 0.0075228 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.46 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.049 reward^2 + 0.461 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 2, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 549/1000 --- L(Train): 0.0075230 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.461 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.048 reward^2 + 0.461 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 3, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 550/1000 --- L(Train): 0.0075213 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.461 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.048 reward^2 + 0.461 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 4, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 551/1000 --- L(Train): 0.0075220 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.461 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.047 reward^2 + 0.461 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 5, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 552/1000 --- L(Train): 0.0075222 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.461 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.046 reward^2 + 0.462 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 6, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 553/1000 --- L(Train): 0.0075209 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.461 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.046 reward^2 + 0.462 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 7, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 554/1000 --- L(Train): 0.0075584 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.462 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.045 reward^2 + 0.462 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 8, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 555/1000 --- L(Train): 0.0075276 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.462 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.044 reward^2 + 0.462 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 9, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 556/1000 --- L(Train): 0.0075633 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.462 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.044 reward^2 + 0.462 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 10, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 557/1000 --- L(Train): 0.0075263 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.462 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.043 reward^2 + 0.463 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 11, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 558/1000 --- L(Train): 0.0075379 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.462 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.042 reward^2 + 0.463 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 12, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 559/1000 --- L(Train): 0.0075475 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.463 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.042 reward^2 + 0.463 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 13, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 560/1000 --- L(Train): 0.0075222 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.463 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.041 reward^2 + 0.463 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 14, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 561/1000 --- L(Train): 0.0075346 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.463 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.04 reward^2 + 0.463 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 15, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 562/1000 --- L(Train): 0.0075390 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.463 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.04 reward^2 + 0.464 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 16, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 563/1000 --- L(Train): 0.0075217 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.463 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.039 reward^2 + 0.464 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 17, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 564/1000 --- L(Train): 0.0075290 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.464 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.038 reward^2 + 0.464 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 18, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 565/1000 --- L(Train): 0.0075342 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.464 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.038 reward^2 + 0.464 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 19, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 566/1000 --- L(Train): 0.0075264 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.464 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.037 reward^2 + 0.464 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 20, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 567/1000 --- L(Train): 0.0075306 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.464 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.036 reward^2 + 0.465 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 21, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 568/1000 --- L(Train): 0.0075328 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.464 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.036 reward^2 + 0.465 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 22, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 569/1000 --- L(Train): 0.0075254 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.465 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.035 reward^2 + 0.465 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 23, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 570/1000 --- L(Train): 0.0075245 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.465 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.034 reward^2 + 0.465 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 24, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 571/1000 --- L(Train): 0.0075275 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.465 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.034 reward^2 + 0.465 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 25, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 572/1000 --- L(Train): 0.0075265 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.465 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.033 reward^2 + 0.466 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 26, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 573/1000 --- L(Train): 0.0075192 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.465 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.032 reward^2 + 0.466 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 27, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 574/1000 --- L(Train): 0.0075265 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.466 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.032 reward^2 + 0.466 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 28, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 575/1000 --- L(Train): 0.0075241 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.466 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.031 reward^2 + 0.466 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 29, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 576/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.466 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.03 reward^2 + 0.466 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 30, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 577/1000 --- L(Train): 0.0075239 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.466 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.03 reward^2 + 0.467 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 31, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 578/1000 --- L(Train): 0.0075228 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.669 value_stay[t] + 0.466 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.029 reward^2 + 0.467 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 32, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 579/1000 --- L(Train): 0.0075215 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.467 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.028 reward^2 + 0.467 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 33, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 580/1000 --- L(Train): 0.0075224 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.467 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.028 reward^2 + 0.467 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 34, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 581/1000 --- L(Train): 0.0075231 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.467 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.027 reward^2 + 0.467 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 35, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 582/1000 --- L(Train): 0.0075219 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.467 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.026 reward^2 + 0.468 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 36, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 583/1000 --- L(Train): 0.0075199 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.467 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.026 reward^2 + 0.468 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 37, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 584/1000 --- L(Train): 0.0075218 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.468 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.025 reward^2 + 0.468 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 38, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 585/1000 --- L(Train): 0.0075213 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.468 reward + 0.055 harvest_duration + -0.333 value_stay*harvest_duration + 0.024 reward^2 + 0.468 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 39, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 586/1000 --- L(Train): 0.0075191 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.468 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.024 reward^2 + 0.468 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 40, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 587/1000 --- L(Train): 0.0075207 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.468 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.023 reward^2 + 0.469 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 41, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 588/1000 --- L(Train): 0.0075325 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.468 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.022 reward^2 + 0.469 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 42, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 589/1000 --- L(Train): 0.0075196 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.469 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.022 reward^2 + 0.469 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 43, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 590/1000 --- L(Train): 0.0075315 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.469 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.021 reward^2 + 0.469 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 44, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 591/1000 --- L(Train): 0.0075246 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.469 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.021 reward^2 + 0.469 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 45, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 592/1000 --- L(Train): 0.0075201 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.469 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.02 reward^2 + 0.469 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 46, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 593/1000 --- L(Train): 0.0075280 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.469 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.019 reward^2 + 0.47 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 47, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 594/1000 --- L(Train): 0.0075212 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.47 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.019 reward^2 + 0.47 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 48, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 595/1000 --- L(Train): 0.0075202 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.47 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.018 reward^2 + 0.47 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 49, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 596/1000 --- L(Train): 0.0075246 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.47 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.017 reward^2 + 0.47 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 50, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 597/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.47 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.017 reward^2 + 0.47 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 51, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 598/1000 --- L(Train): 0.0075206 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.47 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.016 reward^2 + 0.471 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 52, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 599/1000 --- L(Train): 0.0075235 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.47 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.015 reward^2 + 0.471 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 53, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 600/1000 --- L(Train): 0.0075202 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.471 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.015 reward^2 + 0.471 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 54, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 601/1000 --- L(Train): 0.0075217 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.471 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.014 reward^2 + 0.471 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 55, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 602/1000 --- L(Train): 0.0075230 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.471 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.014 reward^2 + 0.471 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 56, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 603/1000 --- L(Train): 0.0075191 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.471 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.013 reward^2 + 0.472 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 57, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 604/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.471 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.012 reward^2 + 0.472 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 58, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 605/1000 --- L(Train): 0.0075205 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.472 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.012 reward^2 + 0.472 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 59, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 606/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.472 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.011 reward^2 + 0.472 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 60, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 607/1000 --- L(Train): 0.0075201 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.472 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.01 reward^2 + 0.472 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 61, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 608/1000 --- L(Train): 0.0075208 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.472 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.01 reward^2 + 0.473 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 62, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 609/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.472 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.009 reward^2 + 0.473 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 63, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 610/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.473 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.008 reward^2 + 0.473 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 64, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 611/1000 --- L(Train): 0.0075192 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.473 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.008 reward^2 + 0.473 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 65, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 612/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.473 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.007 reward^2 + 0.473 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 66, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 613/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.473 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.007 reward^2 + 0.473 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 67, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 614/1000 --- L(Train): 0.0075208 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.473 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.006 reward^2 + 0.474 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 68, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 615/1000 --- L(Train): 0.0075201 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.474 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.005 reward^2 + 0.474 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 69, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 616/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.474 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.005 reward^2 + 0.474 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 70, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 617/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.474 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.004 reward^2 + 0.474 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 71, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 618/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.474 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.004 reward^2 + 0.474 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 72, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 619/1000 --- L(Train): 0.0075191 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.474 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.003 reward^2 + 0.475 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 73, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 620/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.474 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.002 reward^2 + 0.475 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 74, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 621/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.475 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.002 reward^2 + 0.475 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 75, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 622/1000 --- L(Train): 0.0075178 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.475 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.001 reward^2 + 0.475 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 76, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 623/1000 --- L(Train): 0.0075177 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.475 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.475 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 77, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 624/1000 --- L(Train): 0.0075179 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.475 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + -0.0 reward^2 + 0.475 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 78, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 625/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.475 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 79, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 626/1000 --- L(Train): 0.0075941 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 80, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 627/1000 --- L(Train): 0.0075545 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 81, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 628/1000 --- L(Train): 0.0075262 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 82, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 629/1000 --- L(Train): 0.0075319 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 83, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 630/1000 --- L(Train): 0.0075547 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 84, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 631/1000 --- L(Train): 0.0075630 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + -0.0 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 85, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 632/1000 --- L(Train): 0.0075499 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 86, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 633/1000 --- L(Train): 0.0075303 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.001 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 87, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 634/1000 --- L(Train): 0.0075219 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.001 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 88, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 635/1000 --- L(Train): 0.0075288 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.001 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 89, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 636/1000 --- L(Train): 0.0075397 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.002 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 90, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 637/1000 --- L(Train): 0.0075427 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.002 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 91, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 638/1000 --- L(Train): 0.0075363 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.001 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 92, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 639/1000 --- L(Train): 0.0075280 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.001 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 93, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 640/1000 --- L(Train): 0.0075240 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.001 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 94, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 641/1000 --- L(Train): 0.0075258 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.001 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 95, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 642/1000 --- L(Train): 0.0075306 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 96, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 643/1000 --- L(Train): 0.0075338 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + -0.0 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 97, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 644/1000 --- L(Train): 0.0075323 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.0 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 98, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 645/1000 --- L(Train): 0.0075272 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.477 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.001 reward^2 + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, 99, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 646/1000 --- L(Train): 0.0075234 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 647/1000 --- L(Train): 0.0075241 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 648/1000 --- L(Train): 0.0075280 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 649/1000 --- L(Train): 0.0075295 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 650/1000 --- L(Train): 0.0075275 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 651/1000 --- L(Train): 0.0075251 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 652/1000 --- L(Train): 0.0075243 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 653/1000 --- L(Train): 0.0075231 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 654/1000 --- L(Train): 0.0075224 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 655/1000 --- L(Train): 0.0075233 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 656/1000 --- L(Train): 0.0075242 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.054 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 657/1000 --- L(Train): 0.0075233 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 658/1000 --- L(Train): 0.0075214 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 659/1000 --- L(Train): 0.0075209 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 660/1000 --- L(Train): 0.0075217 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 661/1000 --- L(Train): 0.0075221 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 662/1000 --- L(Train): 0.0075220 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 663/1000 --- L(Train): 0.0075214 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 664/1000 --- L(Train): 0.0075209 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 665/1000 --- L(Train): 0.0075205 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.476 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 666/1000 --- L(Train): 0.0075206 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 667/1000 --- L(Train): 0.0075211 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 668/1000 --- L(Train): 0.0075216 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 669/1000 --- L(Train): 0.0075217 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 670/1000 --- L(Train): 0.0075214 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 671/1000 --- L(Train): 0.0075214 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 672/1000 --- L(Train): 0.0075219 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 673/1000 --- L(Train): 0.0075219 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 674/1000 --- L(Train): 0.0075219 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 675/1000 --- L(Train): 0.0075219 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 676/1000 --- L(Train): 0.0075217 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 677/1000 --- L(Train): 0.0075217 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 678/1000 --- L(Train): 0.0075218 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 679/1000 --- L(Train): 0.0075210 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 680/1000 --- L(Train): 0.0075206 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 681/1000 --- L(Train): 0.0075208 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 682/1000 --- L(Train): 0.0075213 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 683/1000 --- L(Train): 0.0075211 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 684/1000 --- L(Train): 0.0075203 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 685/1000 --- L(Train): 0.0075199 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 686/1000 --- L(Train): 0.0075204 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 687/1000 --- L(Train): 0.0075205 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 688/1000 --- L(Train): 0.0075202 --- L(Val, SINDy): 0.0000000 --- Time: 0.09s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 689/1000 --- L(Train): 0.0075199 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 690/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 691/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 692/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 693/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 694/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 695/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 696/1000 --- L(Train): 0.0075199 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 697/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 698/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 699/1000 --- L(Train): 0.0075202 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 700/1000 --- L(Train): 0.0075204 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 701/1000 --- L(Train): 0.0075203 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 702/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 703/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 704/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 705/1000 --- L(Train): 0.0075203 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 706/1000 --- L(Train): 0.0075402 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 707/1000 --- L(Train): 0.0075210 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 708/1000 --- L(Train): 0.0075423 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 709/1000 --- L(Train): 0.0075250 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 710/1000 --- L(Train): 0.0075255 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 711/1000 --- L(Train): 0.0075349 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 712/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 713/1000 --- L(Train): 0.0075259 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 714/1000 --- L(Train): 0.0075288 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 715/1000 --- L(Train): 0.0075191 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 716/1000 --- L(Train): 0.0075257 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 717/1000 --- L(Train): 0.0075251 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 718/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 719/1000 --- L(Train): 0.0075243 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 720/1000 --- L(Train): 0.0075234 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 721/1000 --- L(Train): 0.0075191 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 722/1000 --- L(Train): 0.0075231 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 723/1000 --- L(Train): 0.0075220 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 724/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 725/1000 --- L(Train): 0.0075222 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 726/1000 --- L(Train): 0.0075209 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 727/1000 --- L(Train): 0.0075192 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 728/1000 --- L(Train): 0.0075214 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 729/1000 --- L(Train): 0.0075205 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 730/1000 --- L(Train): 0.0075192 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 731/1000 --- L(Train): 0.0075207 --- L(Val, SINDy): 0.0000000 --- Time: 0.08s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 732/1000 --- L(Train): 0.0075198 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 733/1000 --- L(Train): 0.0075190 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 734/1000 --- L(Train): 0.0075203 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 735/1000 --- L(Train): 0.0075196 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 736/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 737/1000 --- L(Train): 0.0075202 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 738/1000 --- L(Train): 0.0075198 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 739/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 740/1000 --- L(Train): 0.0075199 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 741/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 742/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 743/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 744/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 745/1000 --- L(Train): 0.0075188 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 746/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 747/1000 --- L(Train): 0.0075190 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 748/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 749/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 750/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 751/1000 --- L(Train): 0.0075180 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 752/1000 --- L(Train): 0.0075185 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 753/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 754/1000 --- L(Train): 0.0075470 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 755/1000 --- L(Train): 0.0075202 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 756/1000 --- L(Train): 0.0075503 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 757/1000 --- L(Train): 0.0075287 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 758/1000 --- L(Train): 0.0075255 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 759/1000 --- L(Train): 0.0075418 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 760/1000 --- L(Train): 0.0075227 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 761/1000 --- L(Train): 0.0075262 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 762/1000 --- L(Train): 0.0075350 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\u001b[H\u001b[2J\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 763/1000 --- L(Train): 0.0075206 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 764/1000 --- L(Train): 0.0075243 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 765/1000 --- L(Train): 0.0075303 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 766/1000 --- L(Train): 0.0075204 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 767/1000 --- L(Train): 0.0075229 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 768/1000 --- L(Train): 0.0075276 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 769/1000 --- L(Train): 0.0075206 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 770/1000 --- L(Train): 0.0075216 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 771/1000 --- L(Train): 0.0075249 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 772/1000 --- L(Train): 0.0075196 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 773/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 774/1000 --- L(Train): 0.0075225 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 775/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 776/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 777/1000 --- L(Train): 0.0075213 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 778/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.09s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 779/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 780/1000 --- L(Train): 0.0075211 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 781/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 782/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 783/1000 --- L(Train): 0.0075202 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 784/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 785/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 786/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 787/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 788/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 789/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 790/1000 --- L(Train): 0.0075190 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 791/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 792/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 793/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 794/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 795/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 796/1000 --- L(Train): 0.0075188 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 797/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 798/1000 --- L(Train): 0.0075185 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 799/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 800/1000 --- L(Train): 0.0075179 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 801/1000 --- L(Train): 0.0075181 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 802/1000 --- L(Train): 0.0075181 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 803/1000 --- L(Train): 0.0075179 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 804/1000 --- L(Train): 0.0075178 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 805/1000 --- L(Train): 0.0075180 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 806/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 807/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 808/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 809/1000 --- L(Train): 0.0075185 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 810/1000 --- L(Train): 0.0075188 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 811/1000 --- L(Train): 0.0075185 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 812/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 813/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 814/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 815/1000 --- L(Train): 0.0075181 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 816/1000 --- L(Train): 0.0075181 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 817/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 818/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 819/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 820/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 821/1000 --- L(Train): 0.0075181 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 822/1000 --- L(Train): 0.0075180 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 823/1000 --- L(Train): 0.0075181 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 824/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 825/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 826/1000 --- L(Train): 0.0075190 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 827/1000 --- L(Train): 0.0075196 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 828/1000 --- L(Train): 0.0075201 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 829/1000 --- L(Train): 0.0075199 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 830/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 831/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 832/1000 --- L(Train): 0.0075185 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 833/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 834/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.05s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 835/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.12s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 836/1000 --- L(Train): 0.0075192 --- L(Val, SINDy): 0.0000000 --- Time: 0.06s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 837/1000 --- L(Train): 0.0075185 --- L(Val, SINDy): 0.0000000 --- Time: 0.07s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 838/1000 --- L(Train): 0.0075180 --- L(Val, SINDy): 0.0000000 --- Time: 0.09s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 839/1000 --- L(Train): 0.0075181 --- L(Val, SINDy): 0.0000000 --- Time: 0.10s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 840/1000 --- L(Train): 0.0075190 --- L(Val, SINDy): 0.0000000 --- Time: 0.12s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 841/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.12s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 842/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.15s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 843/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.13s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 844/1000 --- L(Train): 0.0075188 --- L(Val, SINDy): 0.0000000 --- Time: 0.14s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 845/1000 --- L(Train): 0.0075190 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 846/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.15s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 847/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 848/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 849/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 850/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 851/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 852/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 853/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 854/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 855/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 856/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 857/1000 --- L(Train): 0.0075179 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 858/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 859/1000 --- L(Train): 0.0075177 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 860/1000 --- L(Train): 0.0075188 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 861/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 862/1000 --- L(Train): 0.0075191 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 863/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 864/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 865/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 866/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 867/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 868/1000 --- L(Train): 0.0075192 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 869/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 870/1000 --- L(Train): 0.0075191 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 871/1000 --- L(Train): 0.0075191 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 872/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 873/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 874/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 875/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 876/1000 --- L(Train): 0.0075199 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 877/1000 --- L(Train): 0.0075205 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 878/1000 --- L(Train): 0.0075208 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 879/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 880/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 881/1000 --- L(Train): 0.0075209 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 882/1000 --- L(Train): 0.0075224 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 883/1000 --- L(Train): 0.0075220 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 884/1000 --- L(Train): 0.0075201 --- L(Val, SINDy): 0.0000000 --- Time: 0.15s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 885/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 886/1000 --- L(Train): 0.0075190 --- L(Val, SINDy): 0.0000000 --- Time: 0.16s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 887/1000 --- L(Train): 0.0075201 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 888/1000 --- L(Train): 0.0075207 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 889/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.14s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 890/1000 --- L(Train): 0.0075190 --- L(Val, SINDy): 0.0000000 --- Time: 0.14s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 891/1000 --- L(Train): 0.0075186 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 892/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 893/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 894/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 895/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 896/1000 --- L(Train): 0.0075188 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 897/1000 --- L(Train): 0.0075192 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 898/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 899/1000 --- L(Train): 0.0075197 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 900/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 901/1000 --- L(Train): 0.0075185 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 902/1000 --- L(Train): 0.0075190 --- L(Val, SINDy): 0.0000000 --- Time: 0.16s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 903/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 904/1000 --- L(Train): 0.0075201 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 905/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 906/1000 --- L(Train): 0.0075196 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 907/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 908/1000 --- L(Train): 0.0075201 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 909/1000 --- L(Train): 0.0075198 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 910/1000 --- L(Train): 0.0075189 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 911/1000 --- L(Train): 0.0075506 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 912/1000 --- L(Train): 0.0075235 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 913/1000 --- L(Train): 0.0075580 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 914/1000 --- L(Train): 0.0075246 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 915/1000 --- L(Train): 0.0075359 --- L(Val, SINDy): 0.0000000 --- Time: 0.28s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 916/1000 --- L(Train): 0.0075412 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 917/1000 --- L(Train): 0.0075194 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 918/1000 --- L(Train): 0.0075364 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 919/1000 --- L(Train): 0.0075308 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 920/1000 --- L(Train): 0.0075188 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 921/1000 --- L(Train): 0.0075324 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 922/1000 --- L(Train): 0.0075258 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 923/1000 --- L(Train): 0.0075196 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 924/1000 --- L(Train): 0.0075287 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 925/1000 --- L(Train): 0.0075223 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 926/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 927/1000 --- L(Train): 0.0075267 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 928/1000 --- L(Train): 0.0075221 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 929/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 930/1000 --- L(Train): 0.0075247 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 931/1000 --- L(Train): 0.0075209 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 932/1000 --- L(Train): 0.0075193 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 933/1000 --- L(Train): 0.0075223 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 934/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 935/1000 --- L(Train): 0.0075184 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 936/1000 --- L(Train): 0.0075211 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 937/1000 --- L(Train): 0.0075196 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 938/1000 --- L(Train): 0.0075188 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 939/1000 --- L(Train): 0.0075206 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 940/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.27s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 941/1000 --- L(Train): 0.0075185 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 942/1000 --- L(Train): 0.0075196 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 943/1000 --- L(Train): 0.0075187 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 944/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 945/1000 --- L(Train): 0.0075200 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 946/1000 --- L(Train): 0.0075198 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 947/1000 --- L(Train): 0.0075195 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 948/1000 --- L(Train): 0.0075206 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 949/1000 --- L(Train): 0.0075196 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 950/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 951/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 952/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 953/1000 --- L(Train): 0.0075183 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 954/1000 --- L(Train): 0.0075185 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 955/1000 --- L(Train): 0.0075178 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 956/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 957/1000 --- L(Train): 0.0075181 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 958/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 959/1000 --- L(Train): 0.0075180 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 960/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 961/1000 --- L(Train): 0.0075179 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 962/1000 --- L(Train): 0.0075178 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 963/1000 --- L(Train): 0.0075181 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 964/1000 --- L(Train): 0.0075176 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 965/1000 --- L(Train): 0.0075171 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 966/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 967/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 968/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 969/1000 --- L(Train): 0.0075176 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 970/1000 --- L(Train): 0.0075171 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 971/1000 --- L(Train): 0.0075173 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 972/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 973/1000 --- L(Train): 0.0075170 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 974/1000 --- L(Train): 0.0075170 --- L(Val, SINDy): 0.0000000 --- Time: 0.22s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 975/1000 --- L(Train): 0.0075171 --- L(Val, SINDy): 0.0000000 --- Time: 0.25s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 976/1000 --- L(Train): 0.0075173 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 977/1000 --- L(Train): 0.0075174 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 978/1000 --- L(Train): 0.0075173 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 979/1000 --- L(Train): 0.0075173 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 980/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 981/1000 --- L(Train): 0.0075177 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 982/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.26s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 983/1000 --- L(Train): 0.0075173 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 984/1000 --- L(Train): 0.0075173 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 985/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.21s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 986/1000 --- L(Train): 0.0075180 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 987/1000 --- L(Train): 0.0075180 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 988/1000 --- L(Train): 0.0075178 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 989/1000 --- L(Train): 0.0075178 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 990/1000 --- L(Train): 0.0075178 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 991/1000 --- L(Train): 0.0075171 --- L(Val, SINDy): 0.0000000 --- Time: 0.23s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 992/1000 --- L(Train): 0.0075168 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 993/1000 --- L(Train): 0.0075173 --- L(Val, SINDy): 0.0000000 --- Time: 0.24s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 994/1000 --- L(Train): 0.0075177 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 995/1000 --- L(Train): 0.0075177 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 996/1000 --- L(Train): 0.0075179 --- L(Val, SINDy): 0.0000000 --- Time: 0.19s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 997/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 998/1000 --- L(Train): 0.0075182 --- L(Val, SINDy): 0.0000000 --- Time: 0.17s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 999/1000 --- L(Train): 0.0075177 --- L(Val, SINDy): 0.0000000 --- Time: 0.18s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 1000/1000 --- L(Train): 0.0075175 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 1001/1000 --- L(Train): 0.0075180 --- L(Val, SINDy): 0.0000000 --- Time: 0.20s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 6):\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_stay: -, 0, 0, 0, -, -, 0, -, 0, 0\n",
      "value_exit: -, -, -, -, -, -\n",
      "================================================================================\n",
      "\n",
      "Training result:\n",
      "L(Train): 0.0000000 --- L(Val, RNN): 0.3412420 --- L(Val, SINDy): 0.3886036 --- LR: 3.1250000e-04\n",
      "\n",
      "RNN training finished.\n",
      "Training took 1158.69 seconds.\n",
      "Saving SPICE model to ../params/bustamante2023/spice_bustamante2023.pkl...\n",
      "================================================================================\n",
      "\n",
      "Training complete!\n",
      "\n",
      "Example SPICE model (participant 0):\n",
      "--------------------------------------------------------------------------------\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nStarting training on {estimator.device}...\")\n",
    "print(\"=\" * 80)\n",
    "estimator.fit(dataset.xs, dataset.ys, dataset.xs, dataset.ys)\n",
    "# estimator.load_spice(args.model)\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nTraining complete!\")\n",
    "\n",
    "# Print example SPICE model for first participant\n",
    "print(\"\\nExample SPICE model (participant 0):\")\n",
    "print(\"-\" * 80)\n",
    "estimator.print_spice_model(participant_id=0)\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.load_spice(path_spice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     participant_id                subject_id  last_reward  relative_optimal  \\\n",
      "0                 0  08aiu2bm6t15qij5826jxz50     8.241283          1.461283   \n",
      "1                 1  09j932f828pn7h7bozp9mpnl     5.344722         -1.435278   \n",
      "2                 2  0ax9htcbhfi3ncsospqzwjx2     8.945571          2.165571   \n",
      "3                 3  0e6zivqly335lojgb4c6606t     7.554696          0.774696   \n",
      "4                 4  0fawro1pivqnh4lem4ayf4o0     3.089682         -3.690318   \n",
      "..              ...                       ...          ...               ...   \n",
      "245             245  fzllq0yp08zefacpmy7dqq0u     9.041866          2.261866   \n",
      "246             246  g2n23l2w8uf3brbllm4sbrcx     8.106489          1.326489   \n",
      "247             247  g9wqksieqbldodjoyuci048q     6.765186         -0.014814   \n",
      "248             248  garkh3hmuozi9loxpee54z20     7.720383          0.940383   \n",
      "249             249  gd6af6pqeo2d0x2dcumwirmy     3.908357         -2.871643   \n",
      "\n",
      "     over_harvester  \n",
      "0                 0  \n",
      "1                 1  \n",
      "2                 0  \n",
      "3                 0  \n",
      "4                 1  \n",
      "..              ...  \n",
      "245               0  \n",
      "246               0  \n",
      "247               1  \n",
      "248               0  \n",
      "249               1  \n",
      "\n",
      "[250 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(file)\n",
    "df['last_reward'] = df.groupby('subject_id')['last_reward'].fillna(method='bfill')\n",
    "df['participant_id'] = pd.factorize(df['subject_id'])[0]\n",
    "exit_df = df[df['decision'] == 1]\n",
    "mean_exit_threshold = exit_df.groupby(['participant_id', 'subject_id'])['last_reward'].mean().reset_index()\n",
    "mean_exit_threshold['relative_optimal'] = mean_exit_threshold['last_reward'] - 6.78 #from Bustamante et al. Table S7, experiment 1\n",
    "mean_exit_threshold['over_harvester'] = np.where(mean_exit_threshold['relative_optimal'] <= 0, 1, 0)\n",
    "print(mean_exit_threshold)\n",
    "overharvesters = mean_exit_threshold[mean_exit_threshold['over_harvester'] == 1]['participant_id'].unique()\n",
    "underharvesters = mean_exit_threshold[mean_exit_threshold['over_harvester'] == 0]['participant_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OVERHARVESTERS\n",
      "Participant number 1\n",
      "value_stay[t+1] = 0.773 value_stay[t] + 0.5 reward + 0.061 harvest_duration + -0.229 value_stay*harvest_duration + 0.496 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 4\n",
      "value_stay[t+1] = 0.164 1 + 0.724 value_stay[t] + 0.249 reward + 0.168 harvest_duration + -0.277 value_stay*harvest_duration + 0.248 reward*harvest_duration + 0.165 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 7\n",
      "value_stay[t+1] = 0.085 1 + 0.712 value_stay[t] + 0.455 reward + 0.085 harvest_duration + -0.287 value_stay*harvest_duration + 0.455 reward*harvest_duration + 0.085 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 12\n",
      "value_stay[t+1] = 0.095 1 + 0.717 value_stay[t] + 0.435 reward + 0.096 harvest_duration + -0.282 value_stay*harvest_duration + 0.434 reward*harvest_duration + 0.093 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 13\n",
      "value_stay[t+1] = 0.096 1 + 0.713 value_stay[t] + 0.443 reward + 0.095 harvest_duration + -0.288 value_stay*harvest_duration + 0.44 reward*harvest_duration + 0.095 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 14\n",
      "value_stay[t+1] = 0.071 1 + 0.699 value_stay[t] + 0.481 reward + 0.071 harvest_duration + -0.3 value_stay*harvest_duration + 0.481 reward*harvest_duration + 0.071 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 20\n",
      "value_stay[t+1] = 0.066 1 + 0.794 value_stay[t] + 0.463 reward + 0.066 harvest_duration + -0.079 value_stay^2 + -0.206 value_stay*harvest_duration + 0.462 reward*harvest_duration + 0.067 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 23\n",
      "value_stay[t+1] = 0.725 value_stay[t] + 0.51 reward + 0.11 harvest_duration + -0.271 value_stay*harvest_duration + 0.506 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 24\n",
      "value_stay[t+1] = 0.063 1 + 0.701 value_stay[t] + 0.499 reward + 0.064 harvest_duration + -0.303 value_stay*harvest_duration + 0.496 reward*harvest_duration + 0.064 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 25\n",
      "value_stay[t+1] = 0.796 value_stay[t] + 0.519 reward + -0.204 value_stay*harvest_duration + 0.52 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 26\n",
      "value_stay[t+1] = 0.128 1 + 0.777 value_stay[t] + 0.245 reward + 0.125 harvest_duration + -0.224 value_stay*harvest_duration + 0.242 reward*harvest_duration + 0.125 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 27\n",
      "value_stay[t+1] = 0.079 1 + 0.712 value_stay[t] + 0.515 reward + 0.08 harvest_duration + -0.288 value_stay*harvest_duration + 0.519 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 30\n",
      "value_stay[t+1] = 0.072 1 + 0.704 value_stay[t] + 0.466 reward + 0.071 harvest_duration + -0.295 value_stay*harvest_duration + 0.466 reward*harvest_duration + 0.072 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 32\n",
      "value_stay[t+1] = 0.076 1 + 0.698 value_stay[t] + 0.483 reward + 0.076 harvest_duration + -0.298 value_stay*harvest_duration + 0.482 reward*harvest_duration + 0.076 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 33\n",
      "value_stay[t+1] = 0.255 1 + 0.731 value_stay[t] + 0.256 harvest_duration + -0.042 value_stay^2 + -0.269 value_stay*harvest_duration + 0.256 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 35\n",
      "value_stay[t+1] = 0.069 1 + 0.706 value_stay[t] + 0.488 reward + 0.07 harvest_duration + -0.297 value_stay*harvest_duration + 0.487 reward*harvest_duration + 0.07 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 36\n",
      "value_stay[t+1] = 0.176 1 + 0.718 value_stay[t] + 0.218 reward + 0.176 harvest_duration + -0.277 value_stay*harvest_duration + 0.218 reward*harvest_duration + 0.177 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 37\n",
      "value_stay[t+1] = 0.268 1 + 0.781 value_stay[t] + 0.267 harvest_duration + -0.13 value_stay^2 + -0.218 value_stay*harvest_duration + 0.267 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 38\n",
      "value_stay[t+1] = 0.813 value_stay[t] + 0.506 reward + -0.09 value_stay^2 + -0.187 value_stay*harvest_duration + 0.507 reward*harvest_duration + 0.065 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 43\n",
      "value_stay[t+1] = 0.4 1 + 0.822 value_stay[t] + 0.35 reward + -0.18 value_stay*harvest_duration + 0.351 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 44\n",
      "value_stay[t+1] = 0.072 1 + 0.703 value_stay[t] + 0.481 reward + 0.072 harvest_duration + -0.298 value_stay*harvest_duration + 0.485 reward*harvest_duration + 0.072 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 45\n",
      "value_stay[t+1] = 0.161 1 + 0.752 value_stay[t] + 0.165 reward + 0.165 harvest_duration + -0.247 value_stay*harvest_duration + 0.165 reward*harvest_duration + 0.166 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 46\n",
      "value_stay[t+1] = 0.084 1 + 0.636 value_stay[t] + 0.083 harvest_duration + -0.367 value_stay*harvest_duration + 0.587 reward^2 + 0.084 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 47\n",
      "value_stay[t+1] = 0.191 1 + 0.743 value_stay[t] + 0.11 reward + 0.192 harvest_duration + -0.257 value_stay*harvest_duration + 0.114 reward*harvest_duration + 0.191 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 49\n",
      "value_stay[t+1] = 0.267 1 + 0.788 value_stay[t] + 0.266 harvest_duration + -0.141 value_stay^2 + -0.212 value_stay*harvest_duration + 0.267 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 51\n",
      "value_stay[t+1] = 0.839 value_stay[t] + 0.474 reward + -0.161 value_stay*harvest_duration + 0.477 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 54\n",
      "value_stay[t+1] = 0.944 value_stay[t] + 0.477 reward + -0.172 value_stay^2 + -0.057 value_stay*harvest_duration + 0.483 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 59\n",
      "value_stay[t+1] = 0.157 1 + 0.721 value_stay[t] + 0.273 reward + 0.157 harvest_duration + -0.276 value_stay*harvest_duration + 0.27 reward*harvest_duration + 0.157 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 66\n",
      "value_stay[t+1] = 0.779 value_stay[t] + 0.508 reward + -0.22 value_stay*harvest_duration + 0.509 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 68\n",
      "value_stay[t+1] = 0.114 1 + 0.749 value_stay[t] + 0.335 reward + 0.114 harvest_duration + -0.25 value_stay*harvest_duration + 0.336 reward*harvest_duration + 0.115 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 70\n",
      "value_stay[t+1] = 0.073 1 + 0.709 value_stay[t] + 0.481 reward + 0.072 harvest_duration + -0.29 value_stay*harvest_duration + 0.478 reward*harvest_duration + 0.072 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 71\n",
      "value_stay[t+1] = 0.064 1 + 0.774 value_stay[t] + 0.428 reward + 0.066 harvest_duration + -0.227 value_stay*harvest_duration + 0.432 reward*harvest_duration + 0.063 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 72\n",
      "value_stay[t+1] = 0.069 1 + 0.701 value_stay[t] + 0.486 reward + 0.068 harvest_duration + -0.299 value_stay*harvest_duration + 0.486 reward*harvest_duration + 0.068 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 73\n",
      "value_stay[t+1] = 0.085 1 + 0.715 value_stay[t] + 0.435 reward + 0.086 harvest_duration + -0.284 value_stay*harvest_duration + 0.435 reward*harvest_duration + 0.086 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 74\n",
      "value_stay[t+1] = 0.817 value_stay[t] + 0.404 reward + -0.183 value_stay*harvest_duration + 0.4 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 75\n",
      "value_stay[t+1] = 0.108 1 + 0.803 value_stay[t] + 0.231 reward + 0.11 harvest_duration + -0.197 value_stay*harvest_duration + 0.232 reward*harvest_duration + 0.109 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 77\n",
      "value_stay[t+1] = 0.724 value_stay[t] + 0.508 reward + -0.275 value_stay*harvest_duration + 0.509 reward*harvest_duration + 0.052 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 78\n",
      "value_stay[t+1] = 0.235 1 + 0.737 value_stay[t] + 0.512 reward + -0.265 value_stay*harvest_duration + 0.515 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 79\n",
      "value_stay[t+1] = 0.195 1 + 0.717 value_stay[t] + 0.176 reward + 0.196 harvest_duration + -0.283 value_stay*harvest_duration + 0.174 reward*harvest_duration + 0.195 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 80\n",
      "value_stay[t+1] = 0.776 value_stay[t] + 0.51 reward + -0.226 value_stay*harvest_duration + 0.509 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 81\n",
      "value_stay[t+1] = 0.081 1 + 0.712 value_stay[t] + 0.509 reward + -0.29 value_stay*harvest_duration + 0.506 reward*harvest_duration + 0.081 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 82\n",
      "value_stay[t+1] = 0.072 1 + 0.813 value_stay[t] + 0.38 reward + -0.187 value_stay*harvest_duration + 0.376 reward*harvest_duration + 0.071 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 84\n",
      "value_stay[t+1] = 0.764 value_stay[t] + 0.51 reward + -0.231 value_stay*harvest_duration + 0.505 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 86\n",
      "value_stay[t+1] = 0.724 value_stay[t] + 0.508 reward + 0.061 harvest_duration + -0.276 value_stay*harvest_duration + 0.504 reward*harvest_duration + 0.062 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 90\n",
      "value_stay[t+1] = 0.147 1 + 0.415 value_stay[t] + 0.149 harvest_duration + -0.588 value_stay*harvest_duration + 0.148 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 92\n",
      "value_stay[t+1] = 0.068 1 + 0.698 value_stay[t] + 0.487 reward + 0.068 harvest_duration + -0.303 value_stay*harvest_duration + 0.487 reward*harvest_duration + 0.069 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 93\n",
      "value_stay[t+1] = 0.073 1 + 0.704 value_stay[t] + 0.481 reward + 0.073 harvest_duration + -0.296 value_stay*harvest_duration + 0.48 reward*harvest_duration + 0.073 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 95\n",
      "value_stay[t+1] = 0.073 1 + 0.754 value_stay[t] + 0.445 reward + 0.072 harvest_duration + -0.248 value_stay*harvest_duration + 0.444 reward*harvest_duration + 0.073 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 97\n",
      "value_stay[t+1] = 0.113 1 + 0.724 value_stay[t] + 0.385 reward + 0.112 harvest_duration + -0.276 value_stay*harvest_duration + 0.388 reward*harvest_duration + 0.112 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 99\n",
      "value_stay[t+1] = 0.065 1 + 0.697 value_stay[t] + 0.497 reward + 0.065 harvest_duration + -0.302 value_stay*harvest_duration + 0.497 reward*harvest_duration + 0.064 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 100\n",
      "value_stay[t+1] = 0.074 1 + 0.684 value_stay[t] + 0.455 reward + 0.074 harvest_duration + -0.318 value_stay*harvest_duration + 0.457 reward*harvest_duration + 0.074 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 101\n",
      "value_stay[t+1] = 0.722 value_stay[t] + 0.501 reward + 0.176 harvest_duration + -0.278 value_stay*harvest_duration + 0.504 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 103\n",
      "value_stay[t+1] = 0.072 1 + 0.77 value_stay[t] + 0.468 reward + -0.231 value_stay*harvest_duration + 0.464 reward*harvest_duration + 0.072 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 104\n",
      "value_stay[t+1] = 0.8 value_stay[t] + 0.522 reward + -0.2 value_stay*harvest_duration + 0.523 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 105\n",
      "value_stay[t+1] = 0.27 1 + 0.804 value_stay[t] + 0.269 harvest_duration + -0.165 value_stay^2 + -0.196 value_stay*harvest_duration + 0.269 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 109\n",
      "value_stay[t+1] = 0.076 1 + 0.729 value_stay[t] + 0.502 reward + -0.274 value_stay*harvest_duration + 0.499 reward*harvest_duration + 0.076 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 110\n",
      "value_stay[t+1] = 0.863 value_stay[t] + 0.438 reward + -0.138 value_stay*harvest_duration + 0.44 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 112\n",
      "value_stay[t+1] = 0.111 1 + 0.792 value_stay[t] + 0.245 reward + 0.111 harvest_duration + -0.205 value_stay*harvest_duration + 0.248 reward*harvest_duration + 0.114 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 113\n",
      "value_stay[t+1] = 0.775 value_stay[t] + 0.51 reward + -0.223 value_stay*harvest_duration + 0.513 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 114\n",
      "value_stay[t+1] = 0.21 1 + 0.708 value_stay[t] + 0.142 reward + 0.208 harvest_duration + -0.285 value_stay*harvest_duration + 0.144 reward*harvest_duration + 0.208 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 115\n",
      "value_stay[t+1] = 0.141 1 + 0.429 value_stay[t] + 0.144 harvest_duration + -0.572 value_stay*harvest_duration + 0.142 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 116\n",
      "value_stay[t+1] = 0.084 1 + 0.741 value_stay[t] + 0.435 reward + 0.083 harvest_duration + -0.261 value_stay*harvest_duration + 0.434 reward*harvest_duration + 0.084 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 120\n",
      "value_stay[t+1] = 0.069 1 + 0.788 value_stay[t] + 0.447 reward + 0.069 harvest_duration + -0.056 value_stay^2 + -0.214 value_stay*harvest_duration + 0.452 reward*harvest_duration + 0.069 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 121\n",
      "value_stay[t+1] = 0.062 1 + 0.694 value_stay[t] + 0.496 reward + 0.062 harvest_duration + -0.303 value_stay*harvest_duration + 0.496 reward*harvest_duration + 0.062 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 122\n",
      "value_stay[t+1] = 0.06 1 + 0.776 value_stay[t] + 0.477 reward + 0.06 harvest_duration + -0.057 value_stay^2 + -0.223 value_stay*harvest_duration + 0.474 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 123\n",
      "value_stay[t+1] = 0.698 value_stay[t] + 0.44 reward + -0.298 value_stay*harvest_duration + 0.11 reward^2 + 0.435 reward*harvest_duration + 0.071 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 124\n",
      "value_stay[t+1] = 0.841 value_stay[t] + 0.49 reward + -0.157 value_stay*harvest_duration + 0.486 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 125\n",
      "value_stay[t+1] = 0.879 value_stay[t] + 0.405 reward + -0.122 value_stay*harvest_duration + 0.408 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 126\n",
      "value_stay[t+1] = 0.726 value_stay[t] + 0.504 reward + -0.27 value_stay*harvest_duration + 0.508 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 127\n",
      "value_stay[t+1] = 0.707 value_stay[t] + 0.508 reward + 0.062 harvest_duration + -0.293 value_stay*harvest_duration + 0.509 reward*harvest_duration + 0.062 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 128\n",
      "value_stay[t+1] = 0.232 1 + 0.793 value_stay[t] + 0.47 reward + -0.207 value_stay*harvest_duration + 0.464 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 130\n",
      "value_stay[t+1] = 0.236 1 + 0.775 value_stay[t] + 0.055 reward + 0.236 harvest_duration + -0.093 value_stay^2 + -0.225 value_stay*harvest_duration + 0.056 reward*harvest_duration + 0.236 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 131\n",
      "value_stay[t+1] = 0.127 1 + 0.496 value_stay[t] + 0.127 harvest_duration + -0.503 value_stay*harvest_duration + 0.128 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 132\n",
      "value_stay[t+1] = 0.772 value_stay[t] + 0.502 reward + -0.225 value_stay*harvest_duration + 0.5 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 133\n",
      "value_stay[t+1] = 0.131 1 + 0.783 value_stay[t] + 0.2 reward + 0.131 harvest_duration + -0.215 value_stay*harvest_duration + 0.199 reward*harvest_duration + 0.131 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 134\n",
      "value_stay[t+1] = 0.826 value_stay[t] + 0.502 reward + -0.173 value_stay*harvest_duration + 0.502 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 135\n",
      "value_stay[t+1] = 0.06 1 + 0.682 value_stay[t] + 0.489 reward + 0.06 harvest_duration + -0.318 value_stay*harvest_duration + 0.49 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 139\n",
      "value_stay[t+1] = 0.837 value_stay[t] + 0.484 reward + -0.164 value_stay*harvest_duration + 0.485 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 140\n",
      "value_stay[t+1] = 0.077 1 + 0.707 value_stay[t] + 0.474 reward + 0.075 harvest_duration + -0.294 value_stay*harvest_duration + 0.472 reward*harvest_duration + 0.076 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 142\n",
      "value_stay[t+1] = 0.302 1 + 0.737 value_stay[t] + 0.506 reward + -0.262 value_stay*harvest_duration + 0.506 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 143\n",
      "value_stay[t+1] = 0.05 1 + 0.701 value_stay[t] + 0.504 reward + 0.051 harvest_duration + -0.301 value_stay*harvest_duration + 0.5 reward*harvest_duration + 0.052 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 144\n",
      "value_stay[t+1] = 0.058 1 + 0.719 value_stay[t] + 0.499 reward + 0.058 harvest_duration + -0.283 value_stay*harvest_duration + 0.499 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 146\n",
      "value_stay[t+1] = 0.061 1 + 0.716 value_stay[t] + 0.5 reward + 0.062 harvest_duration + -0.283 value_stay*harvest_duration + 0.498 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 148\n",
      "value_stay[t+1] = 0.229 1 + 0.715 value_stay[t] + 0.068 reward + 0.228 harvest_duration + -0.282 value_stay*harvest_duration + 0.069 reward*harvest_duration + 0.227 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 152\n",
      "value_stay[t+1] = 0.064 1 + 0.763 value_stay[t] + 0.448 reward + 0.064 harvest_duration + -0.236 value_stay*harvest_duration + 0.445 reward*harvest_duration + 0.065 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 153\n",
      "value_stay[t+1] = 0.885 value_stay[t] + 0.391 reward + -0.115 value_stay*harvest_duration + 0.391 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 154\n",
      "value_stay[t+1] = 0.209 1 + 0.724 value_stay[t] + 0.104 reward + 0.211 harvest_duration + -0.277 value_stay*harvest_duration + 0.105 reward*harvest_duration + 0.212 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 160\n",
      "value_stay[t+1] = 0.102 1 + 0.728 value_stay[t] + 0.407 reward + 0.1 harvest_duration + -0.273 value_stay*harvest_duration + 0.403 reward*harvest_duration + 0.102 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 161\n",
      "value_stay[t+1] = 0.845 value_stay[t] + 0.448 reward + -0.155 value_stay*harvest_duration + 0.448 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 162\n",
      "value_stay[t+1] = 0.061 1 + 0.688 value_stay[t] + 0.488 reward + 0.062 harvest_duration + -0.31 value_stay*harvest_duration + 0.488 reward*harvest_duration + 0.062 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 164\n",
      "value_stay[t+1] = 0.083 1 + 0.785 value_stay[t] + 0.352 reward + 0.082 harvest_duration + -0.214 value_stay*harvest_duration + 0.348 reward*harvest_duration + 0.081 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 165\n",
      "value_stay[t+1] = 0.067 1 + 0.692 value_stay[t] + 0.493 reward + 0.068 harvest_duration + -0.308 value_stay*harvest_duration + 0.494 reward*harvest_duration + 0.068 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 166\n",
      "value_stay[t+1] = 0.828 value_stay[t] + 0.492 reward + -0.172 value_stay*harvest_duration + 0.492 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 167\n",
      "value_stay[t+1] = 0.129 1 + 0.466 value_stay[t] + 0.078 reward + 0.129 harvest_duration + -0.534 value_stay*harvest_duration + 0.078 reward*harvest_duration + 0.13 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 168\n",
      "value_stay[t+1] = 0.841 value_stay[t] + 0.408 reward + -0.158 value_stay*harvest_duration + 0.403 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 171\n",
      "value_stay[t+1] = 0.056 1 + 0.747 value_stay[t] + 0.482 reward + 0.056 harvest_duration + -0.255 value_stay*harvest_duration + 0.485 reward*harvest_duration + 0.057 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 172\n",
      "value_stay[t+1] = 0.184 1 + 0.805 value_stay[t] + 0.453 reward + -0.194 value_stay*harvest_duration + 0.457 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 174\n",
      "value_stay[t+1] = 0.076 1 + 0.704 value_stay[t] + 0.474 reward + 0.074 harvest_duration + -0.296 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.075 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 176\n",
      "value_stay[t+1] = 0.06 1 + 0.747 value_stay[t] + 0.474 reward + 0.059 harvest_duration + -0.256 value_stay*harvest_duration + 0.476 reward*harvest_duration + 0.06 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 177\n",
      "value_stay[t+1] = 0.739 value_stay[t] + 0.512 reward + 0.123 harvest_duration + -0.262 value_stay*harvest_duration + 0.511 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 181\n",
      "value_stay[t+1] = 0.107 1 + 0.717 value_stay[t] + 0.408 reward + 0.106 harvest_duration + -0.279 value_stay*harvest_duration + 0.407 reward*harvest_duration + 0.106 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 182\n",
      "value_stay[t+1] = 0.097 1 + 0.569 value_stay[t] + 0.119 reward + 0.097 harvest_duration + -0.425 value_stay*harvest_duration + 0.324 reward^2 + 0.117 reward*harvest_duration + 0.097 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 184\n",
      "value_stay[t+1] = 0.098 1 + 0.715 value_stay[t] + 0.437 reward + 0.099 harvest_duration + -0.283 value_stay*harvest_duration + 0.433 reward*harvest_duration + 0.098 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 185\n",
      "value_stay[t+1] = 0.269 1 + 0.805 value_stay[t] + 0.27 harvest_duration + -0.167 value_stay^2 + -0.195 value_stay*harvest_duration + 0.269 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 186\n",
      "value_stay[t+1] = 0.133 1 + 0.731 value_stay[t] + 0.312 reward + 0.132 harvest_duration + -0.266 value_stay*harvest_duration + 0.316 reward*harvest_duration + 0.137 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 188\n",
      "value_stay[t+1] = 0.207 1 + 0.714 value_stay[t] + 0.145 reward + 0.205 harvest_duration + -0.285 value_stay*harvest_duration + 0.142 reward*harvest_duration + 0.208 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 189\n",
      "value_stay[t+1] = 0.133 1 + 0.458 value_stay[t] + 0.142 reward + 0.133 harvest_duration + -0.538 value_stay*harvest_duration + 0.131 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 191\n",
      "value_stay[t+1] = 0.231 1 + 0.709 value_stay[t] + 0.083 reward + 0.231 harvest_duration + -0.293 value_stay*harvest_duration + 0.083 reward*harvest_duration + 0.231 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 194\n",
      "value_stay[t+1] = 0.076 1 + 0.725 value_stay[t] + 0.495 reward + -0.277 value_stay*harvest_duration + 0.497 reward*harvest_duration + 0.078 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 195\n",
      "value_stay[t+1] = 0.06 1 + 0.678 value_stay[t] + 0.472 reward + 0.06 harvest_duration + -0.322 value_stay*harvest_duration + 0.467 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 198\n",
      "value_stay[t+1] = 0.84 value_stay[t] + 0.459 reward + -0.159 value_stay*harvest_duration + 0.461 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 199\n",
      "value_stay[t+1] = 0.145 1 + 0.418 value_stay[t] + 0.146 harvest_duration + -0.581 value_stay*harvest_duration + 0.144 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 202\n",
      "value_stay[t+1] = 0.252 1 + 0.754 value_stay[t] + 0.13 reward + 0.252 harvest_duration + -0.081 value_stay^2 + -0.246 value_stay*harvest_duration + 0.251 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 206\n",
      "value_stay[t+1] = 0.822 value_stay[t] + 0.468 reward + -0.179 value_stay*harvest_duration + 0.471 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 208\n",
      "value_stay[t+1] = 0.268 1 + 0.793 value_stay[t] + 0.266 harvest_duration + -0.148 value_stay^2 + -0.207 value_stay*harvest_duration + 0.268 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 209\n",
      "value_stay[t+1] = 0.065 1 + 0.697 value_stay[t] + 0.498 reward + 0.065 harvest_duration + -0.303 value_stay*harvest_duration + 0.495 reward*harvest_duration + 0.065 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 211\n",
      "value_stay[t+1] = 0.776 value_stay[t] + 0.476 reward + -0.223 value_stay*harvest_duration + 0.476 reward*harvest_duration + 0.062 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 214\n",
      "value_stay[t+1] = 0.269 1 + 0.805 value_stay[t] + 0.27 harvest_duration + -0.167 value_stay^2 + -0.195 value_stay*harvest_duration + 0.269 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 215\n",
      "value_stay[t+1] = 0.201 1 + 0.736 value_stay[t] + 0.106 reward + 0.2 harvest_duration + -0.266 value_stay*harvest_duration + 0.107 reward*harvest_duration + 0.201 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 216\n",
      "value_stay[t+1] = 0.726 value_stay[t] + 0.508 reward + -0.273 value_stay*harvest_duration + 0.508 reward*harvest_duration + 0.071 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 218\n",
      "value_stay[t+1] = 0.123 1 + 0.723 value_stay[t] + 0.36 reward + 0.123 harvest_duration + -0.276 value_stay*harvest_duration + 0.36 reward*harvest_duration + 0.123 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 219\n",
      "value_stay[t+1] = 0.265 1 + 0.79 value_stay[t] + 0.265 harvest_duration + -0.14 value_stay^2 + -0.21 value_stay*harvest_duration + 0.264 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 220\n",
      "value_stay[t+1] = 0.118 1 + 0.792 value_stay[t] + 0.219 reward + 0.117 harvest_duration + -0.208 value_stay*harvest_duration + 0.223 reward*harvest_duration + 0.117 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 221\n",
      "value_stay[t+1] = 0.221 1 + 0.71 value_stay[t] + 0.113 reward + 0.221 harvest_duration + -0.29 value_stay*harvest_duration + 0.112 reward*harvest_duration + 0.221 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 222\n",
      "value_stay[t+1] = 0.801 value_stay[t] + 0.49 reward + -0.199 value_stay*harvest_duration + 0.49 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 223\n",
      "value_stay[t+1] = 0.833 value_stay[t] + 0.391 reward + -0.166 value_stay*harvest_duration + 0.392 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 225\n",
      "value_stay[t+1] = 0.268 1 + 0.794 value_stay[t] + 0.267 harvest_duration + -0.151 value_stay^2 + -0.205 value_stay*harvest_duration + 0.268 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 226\n",
      "value_stay[t+1] = 0.793 value_stay[t] + 0.427 reward + 0.185 harvest_duration + -0.206 value_stay*harvest_duration + 0.423 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 230\n",
      "value_stay[t+1] = 0.144 1 + 0.455 value_stay[t] + 0.145 harvest_duration + -0.548 value_stay*harvest_duration + 0.144 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 231\n",
      "value_stay[t+1] = 0.051 1 + 0.721 value_stay[t] + 0.506 reward + -0.28 value_stay*harvest_duration + 0.506 reward*harvest_duration + 0.052 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 233\n",
      "value_stay[t+1] = 0.103 1 + 0.761 value_stay[t] + 0.484 reward + 0.102 harvest_duration + -0.239 value_stay*harvest_duration + 0.488 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 235\n",
      "value_stay[t+1] = 0.217 1 + 0.711 value_stay[t] + 0.121 reward + 0.217 harvest_duration + -0.29 value_stay*harvest_duration + 0.121 reward*harvest_duration + 0.217 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 236\n",
      "value_stay[t+1] = 0.817 value_stay[t] + 0.439 reward + -0.183 value_stay*harvest_duration + 0.443 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 238\n",
      "value_stay[t+1] = 0.182 1 + 0.722 value_stay[t] + 0.209 reward + 0.179 harvest_duration + -0.279 value_stay*harvest_duration + 0.214 reward*harvest_duration + 0.178 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 239\n",
      "value_stay[t+1] = 0.061 1 + 0.679 value_stay[t] + 0.468 reward + 0.06 harvest_duration + -0.319 value_stay*harvest_duration + 0.47 reward*harvest_duration + 0.06 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 240\n",
      "value_stay[t+1] = 0.08 1 + 0.803 value_stay[t] + 0.318 reward + 0.082 harvest_duration + -0.196 value_stay*harvest_duration + 0.314 reward*harvest_duration + 0.081 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 241\n",
      "value_stay[t+1] = 0.266 1 + 0.791 value_stay[t] + 0.267 harvest_duration + -0.144 value_stay^2 + -0.208 value_stay*harvest_duration + 0.266 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 242\n",
      "value_stay[t+1] = 0.193 1 + 0.722 value_stay[t] + 0.167 reward + 0.194 harvest_duration + -0.275 value_stay*harvest_duration + 0.167 reward*harvest_duration + 0.189 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 243\n",
      "value_stay[t+1] = 0.144 1 + 0.421 value_stay[t] + 0.145 harvest_duration + -0.583 value_stay*harvest_duration + 0.147 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 247\n",
      "value_stay[t+1] = 0.122 1 + 0.507 value_stay[t] + 0.081 reward + 0.122 harvest_duration + -0.487 value_stay*harvest_duration + 0.081 reward*harvest_duration + 0.11 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 249\n",
      "value_stay[t+1] = 0.145 1 + 0.437 value_stay[t] + 0.144 harvest_duration + -0.563 value_stay*harvest_duration + 0.144 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n"
     ]
    }
   ],
   "source": [
    "print('OVERHARVESTERS') \n",
    "for p in overharvesters:\n",
    "    print('Participant number', p)\n",
    "    estimator.print_spice_model(participant_id=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNDERHARVESTERS\n",
      "Participant number 0\n",
      "value_stay[t+1] = 0.668 value_stay[t] + 0.476 reward + 0.055 harvest_duration + -0.334 value_stay*harvest_duration + 0.477 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 2\n",
      "value_stay[t+1] = 0.82 value_stay[t] + 0.208 reward + -0.179 value_stay*harvest_duration + 0.11 reward^2 + 0.207 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 3\n",
      "value_stay[t+1] = 0.097 1 + 0.681 value_stay[t] + 0.488 reward + 0.097 harvest_duration + -0.317 value_stay*harvest_duration + 0.485 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 5\n",
      "value_stay[t+1] = 0.057 1 + 0.665 value_stay[t] + 0.481 reward + 0.057 harvest_duration + -0.331 value_stay*harvest_duration + 0.479 reward*harvest_duration + 0.058 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 6\n",
      "value_stay[t+1] = 0.055 1 + 0.667 value_stay[t] + 0.397 reward + 0.056 harvest_duration + -0.335 value_stay*harvest_duration + 0.16 reward^2 + 0.397 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 8\n",
      "value_stay[t+1] = 0.109 1 + 0.626 value_stay[t] + -0.176 reward + 0.111 harvest_duration + -0.374 value_stay*harvest_duration + -0.174 reward*harvest_duration + 0.11 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 9\n",
      "value_stay[t+1] = 0.106 1 + 0.532 value_stay[t] + 0.177 reward + 0.105 harvest_duration + -0.467 value_stay*harvest_duration + 0.052 reward^2 + 0.181 reward*harvest_duration + 0.104 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 10\n",
      "value_stay[t+1] = 0.064 1 + 0.619 value_stay[t] + 0.395 reward + 0.064 harvest_duration + -0.378 value_stay*harvest_duration + 0.398 reward*harvest_duration + 0.064 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 11\n",
      "value_stay[t+1] = 0.173 1 + 0.728 value_stay[t] + 0.362 reward + -0.271 value_stay*harvest_duration + 0.259 reward^2 + 0.366 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 15\n",
      "value_stay[t+1] = 0.861 value_stay[t] + 0.106 harvest_duration + -0.135 value_stay*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 16\n",
      "value_stay[t+1] = 0.148 1 + 0.422 value_stay[t] + 0.148 harvest_duration + -0.58 value_stay*harvest_duration + 0.147 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 17\n",
      "value_stay[t+1] = 0.733 value_stay[t] + 0.461 reward + 0.068 harvest_duration + -0.264 value_stay*harvest_duration + 0.057 reward^2 + 0.462 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 18\n",
      "value_stay[t+1] = 0.811 value_stay[t] + 0.292 reward + -0.191 value_stay*harvest_duration + 0.296 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 19\n",
      "value_stay[t+1] = 0.812 value_stay[t] + 0.391 reward + -0.188 value_stay*harvest_duration + 0.391 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 21\n",
      "value_stay[t+1] = 0.081 1 + 0.648 value_stay[t] + 0.081 harvest_duration + -0.351 value_stay*harvest_duration + 0.371 reward^2 + 0.08 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 22\n",
      "value_stay[t+1] = 0.251 1 + 0.846 value_stay[t] + -0.154 value_stay*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 28\n",
      "value_stay[t+1] = 0.06 1 + 0.641 value_stay[t] + 0.257 reward + 0.06 harvest_duration + -0.356 value_stay*harvest_duration + 0.33 reward^2 + 0.254 reward*harvest_duration + 0.061 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 29\n",
      "value_stay[t+1] = 0.127 1 + 0.471 value_stay[t] + 0.111 reward + 0.128 harvest_duration + -0.524 value_stay*harvest_duration + 0.109 reward*harvest_duration + 0.129 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 31\n",
      "value_stay[t+1] = 0.797 value_stay[t] + 0.301 reward + -0.203 value_stay*harvest_duration + 0.105 reward^2 + 0.298 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 34\n",
      "value_stay[t+1] = 0.816 value_stay[t] + 0.369 reward + -0.185 value_stay*harvest_duration + 0.049 reward^2 + 0.37 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 39\n",
      "value_stay[t+1] = 0.076 1 + 0.708 value_stay[t] + 0.486 reward + 0.076 harvest_duration + -0.291 value_stay*harvest_duration + 0.484 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 40\n",
      "value_stay[t+1] = 0.056 1 + 0.669 value_stay[t] + 0.48 reward + 0.056 harvest_duration + -0.327 value_stay*harvest_duration + 0.48 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 41\n",
      "value_stay[t+1] = 0.777 value_stay[t] + -0.222 value_stay*harvest_duration + 0.085 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 42\n",
      "value_stay[t+1] = 0.059 1 + 0.647 value_stay[t] + 0.412 reward + 0.059 harvest_duration + -0.353 value_stay*harvest_duration + 0.075 reward^2 + 0.412 reward*harvest_duration + 0.06 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 48\n",
      "value_stay[t+1] = 0.802 value_stay[t] + 0.321 reward + -0.199 value_stay*harvest_duration + 0.318 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 50\n",
      "value_stay[t+1] = 0.148 1 + 0.408 value_stay[t] + 0.148 harvest_duration + -0.592 value_stay*harvest_duration + 0.148 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 52\n",
      "value_stay[t+1] = 0.842 value_stay[t] + 0.109 reward + -0.158 value_stay*harvest_duration + 0.461 reward^2 + 0.108 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 53\n",
      "value_stay[t+1] = 0.101 1 + 0.674 value_stay[t] + 0.403 reward + 0.1 harvest_duration + -0.325 value_stay*harvest_duration + 0.119 reward^2 + 0.399 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 55\n",
      "value_stay[t+1] = 0.086 1 + 0.684 value_stay[t] + 0.426 reward + 0.085 harvest_duration + -0.322 value_stay*harvest_duration + 0.123 reward^2 + 0.425 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 56\n",
      "value_stay[t+1] = 0.236 1 + 0.708 value_stay[t] + 0.331 reward + -0.293 value_stay*harvest_duration + 0.294 reward^2 + 0.328 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 57\n",
      "value_stay[t+1] = 0.056 1 + 0.677 value_stay[t] + 0.501 reward + 0.054 harvest_duration + -0.325 value_stay*harvest_duration + 0.498 reward*harvest_duration + 0.055 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 58\n",
      "value_stay[t+1] = 0.094 1 + 0.817 value_stay[t] + 0.094 harvest_duration + -0.186 value_stay*harvest_duration + 0.081 reward^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 60\n",
      "value_stay[t+1] = 0.051 1 + 0.779 value_stay[t] + -0.22 value_stay*harvest_duration + 0.375 reward^2 + 0.051 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 61\n",
      "value_stay[t+1] = 0.148 1 + 0.405 value_stay[t] + 0.148 harvest_duration + -0.591 value_stay*harvest_duration + 0.147 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 62\n",
      "value_stay[t+1] = 0.758 value_stay[t] + 0.434 reward + -0.244 value_stay*harvest_duration + 0.125 reward^2 + 0.431 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 63\n",
      "value_stay[t+1] = 0.847 value_stay[t] + 0.112 reward + -0.156 value_stay*harvest_duration + 0.398 reward^2 + 0.112 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 64\n",
      "value_stay[t+1] = 0.237 1 + 0.801 value_stay[t] + -0.2 value_stay*harvest_duration + 0.29 reward^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 65\n",
      "value_stay[t+1] = 1.0 value_stay[t] \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 67\n",
      "value_stay[t+1] = 0.15 1 + 0.41 value_stay[t] + 0.15 harvest_duration + -0.594 value_stay*harvest_duration + 0.148 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 69\n",
      "value_stay[t+1] = 0.691 value_stay[t] + 0.486 reward + 0.13 harvest_duration + -0.307 value_stay*harvest_duration + 0.486 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 76\n",
      "value_stay[t+1] = 0.068 1 + 0.64 value_stay[t] + 0.349 reward + 0.069 harvest_duration + -0.364 value_stay*harvest_duration + 0.198 reward^2 + 0.348 reward*harvest_duration + 0.069 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 83\n",
      "value_stay[t+1] = 0.829 value_stay[t] + 0.132 harvest_duration + -0.19 value_stay*harvest_duration + 0.111 reward^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 85\n",
      "value_stay[t+1] = 0.054 1 + 0.654 value_stay[t] + 0.291 reward + 0.055 harvest_duration + -0.344 value_stay*harvest_duration + 0.284 reward^2 + 0.291 reward*harvest_duration + 0.054 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 87\n",
      "value_stay[t+1] = 0.149 1 + 0.4 value_stay[t] + 0.151 harvest_duration + -0.605 value_stay*harvest_duration + 0.151 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 88\n",
      "value_stay[t+1] = 0.085 1 + 0.683 value_stay[t] + -0.128 reward + 0.084 harvest_duration + -0.325 value_stay*harvest_duration + -0.132 reward*harvest_duration + 0.085 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 89\n",
      "value_stay[t+1] = 0.702 value_stay[t] + 0.469 reward + 0.109 harvest_duration + -0.297 value_stay*harvest_duration + 0.471 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 91\n",
      "value_stay[t+1] = 0.082 1 + 0.596 value_stay[t] + 0.245 reward + 0.082 harvest_duration + -0.403 value_stay*harvest_duration + 0.244 reward^2 + 0.25 reward*harvest_duration + 0.084 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 94\n",
      "value_stay[t+1] = 0.089 1 + 0.693 value_stay[t] + 0.298 reward + 0.09 harvest_duration + -0.304 value_stay*harvest_duration + 0.366 reward^2 + 0.298 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 96\n",
      "value_stay[t+1] = 0.083 1 + 0.693 value_stay[t] + 0.338 reward + 0.083 harvest_duration + -0.304 value_stay*harvest_duration + 0.259 reward^2 + 0.343 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 98\n",
      "value_stay[t+1] = 0.088 1 + 0.697 value_stay[t] + 0.348 reward + 0.088 harvest_duration + -0.305 value_stay*harvest_duration + 0.28 reward^2 + 0.349 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 102\n",
      "value_stay[t+1] = 0.673 value_stay[t] + 0.417 reward + 0.053 harvest_duration + -0.328 value_stay*harvest_duration + 0.102 reward^2 + 0.416 reward*harvest_duration + 0.053 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 106\n",
      "value_stay[t+1] = 0.058 1 + 0.666 value_stay[t] + 0.486 reward + 0.06 harvest_duration + -0.331 value_stay*harvest_duration + 0.483 reward*harvest_duration + 0.06 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 107\n",
      "value_stay[t+1] = 0.822 value_stay[t] + 0.229 reward + -0.177 value_stay*harvest_duration + 0.221 reward^2 + 0.231 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 108\n",
      "value_stay[t+1] = 0.104 1 + 0.789 value_stay[t] + 0.104 harvest_duration + -0.209 value_stay*harvest_duration + 0.144 reward^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 111\n",
      "value_stay[t+1] = 0.761 value_stay[t] + 0.486 reward + -0.24 value_stay*harvest_duration + 0.487 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 117\n",
      "value_stay[t+1] = 0.192 1 + 0.717 value_stay[t] + 0.488 reward + -0.281 value_stay*harvest_duration + 0.485 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 118\n",
      "value_stay[t+1] = 0.053 1 + 0.736 value_stay[t] + 0.516 reward + 0.052 harvest_duration + -0.052 value_stay^2 + -0.264 value_stay*harvest_duration + 0.516 reward*harvest_duration + 0.052 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 119\n",
      "value_stay[t+1] = 0.1 1 + 0.549 value_stay[t] + 0.163 reward + 0.099 harvest_duration + -0.45 value_stay*harvest_duration + 0.165 reward^2 + 0.163 reward*harvest_duration + 0.099 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 129\n",
      "value_stay[t+1] = 0.132 1 + 0.463 value_stay[t] + 0.096 reward + 0.131 harvest_duration + -0.532 value_stay*harvest_duration + 0.097 reward*harvest_duration + 0.131 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 136\n",
      "value_stay[t+1] = 0.801 value_stay[t] + 0.336 reward + -0.201 value_stay*harvest_duration + 0.336 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 137\n",
      "value_stay[t+1] = 0.153 1 + 0.389 value_stay[t] + 0.153 harvest_duration + -0.605 value_stay*harvest_duration + 0.153 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 138\n",
      "value_stay[t+1] = 0.224 1 + 0.708 value_stay[t] + 0.359 reward + -0.294 value_stay*harvest_duration + 0.229 reward^2 + 0.356 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 141\n",
      "value_stay[t+1] = 0.796 value_stay[t] + 0.101 reward + 0.078 harvest_duration + -0.204 value_stay*harvest_duration + 0.265 reward^2 + 0.098 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 145\n",
      "value_stay[t+1] = 0.725 value_stay[t] + 0.496 reward + 0.089 harvest_duration + -0.275 value_stay*harvest_duration + 0.495 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 147\n",
      "value_stay[t+1] = 0.095 1 + 0.596 value_stay[t] + 0.061 reward + 0.095 harvest_duration + -0.405 value_stay*harvest_duration + 0.061 reward*harvest_duration + 0.094 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 149\n",
      "value_stay[t+1] = 0.764 value_stay[t] + 0.496 reward + -0.237 value_stay*harvest_duration + 0.495 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 150\n",
      "value_stay[t+1] = 0.172 1 + 0.723 value_stay[t] + 0.488 reward + -0.275 value_stay*harvest_duration + 0.491 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 151\n",
      "value_stay[t+1] = 0.066 1 + 0.638 value_stay[t] + 0.372 reward + 0.066 harvest_duration + -0.363 value_stay*harvest_duration + 0.149 reward^2 + 0.369 reward*harvest_duration + 0.065 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 155\n",
      "value_stay[t+1] = 0.762 value_stay[t] + 0.463 reward + -0.24 value_stay*harvest_duration + 0.052 reward^2 + 0.465 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 156\n",
      "value_stay[t+1] = 0.104 1 + 0.761 value_stay[t] + 0.104 harvest_duration + -0.239 value_stay*harvest_duration + 0.427 reward^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 157\n",
      "value_stay[t+1] = 0.134 1 + 0.461 value_stay[t] + 0.083 reward + 0.133 harvest_duration + -0.535 value_stay*harvest_duration + 0.083 reward*harvest_duration + 0.134 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 158\n",
      "value_stay[t+1] = 0.105 1 + 0.764 value_stay[t] + 0.105 harvest_duration + -0.236 value_stay*harvest_duration + 0.297 reward^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 159\n",
      "value_stay[t+1] = 0.764 value_stay[t] + 0.403 reward + -0.236 value_stay*harvest_duration + 0.185 reward^2 + 0.406 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 163\n",
      "value_stay[t+1] = 0.869 value_stay[t] + 0.076 reward + -0.13 value_stay*harvest_duration + 0.295 reward^2 + 0.076 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 169\n",
      "value_stay[t+1] = 0.152 1 + 0.391 value_stay[t] + 0.152 harvest_duration + -0.604 value_stay*harvest_duration + 0.152 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 170\n",
      "value_stay[t+1] = 0.689 value_stay[t] + 0.496 reward + -0.308 value_stay*harvest_duration + 0.492 reward*harvest_duration + 0.072 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 173\n",
      "value_stay[t+1] = 0.073 1 + 0.72 value_stay[t] + -0.061 reward + 0.073 harvest_duration + -0.25 value_stay*harvest_duration + -0.058 reward*harvest_duration + 0.072 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 175\n",
      "value_stay[t+1] = 0.699 value_stay[t] + 0.469 reward + 0.107 harvest_duration + -0.299 value_stay*harvest_duration + 0.469 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 178\n",
      "value_stay[t+1] = 0.141 1 + 0.433 value_stay[t] + 0.14 harvest_duration + -0.563 value_stay*harvest_duration + 0.071 reward*harvest_duration + 0.141 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 179\n",
      "value_stay[t+1] = 0.125 1 + 0.506 value_stay[t] + -0.126 reward + 0.125 harvest_duration + -0.494 value_stay*harvest_duration + 0.125 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 180\n",
      "value_stay[t+1] = 0.796 value_stay[t] + 0.292 reward + -0.204 value_stay*harvest_duration + 0.131 reward^2 + 0.292 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 183\n",
      "value_stay[t+1] = 0.846 value_stay[t] + -0.091 reward + 0.071 harvest_duration + -0.154 value_stay*harvest_duration + -0.092 reward*harvest_duration + 0.054 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 187\n",
      "value_stay[t+1] = 0.137 1 + 0.444 value_stay[t] + 0.138 harvest_duration + -0.559 value_stay*harvest_duration + 0.137 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 190\n",
      "value_stay[t+1] = 0.808 value_stay[t] + 0.433 reward + -0.194 value_stay*harvest_duration + 0.43 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 192\n",
      "value_stay[t+1] = 0.269 1 + 0.779 value_stay[t] + 0.268 harvest_duration + -0.13 value_stay^2 + -0.221 value_stay*harvest_duration + 0.27 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 193\n",
      "value_stay[t+1] = 0.072 1 + 0.843 value_stay[t] + -0.092 reward + -0.156 value_stay*harvest_duration + -0.092 reward*harvest_duration + 0.071 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 196\n",
      "value_stay[t+1] = 0.671 value_stay[t] + 0.434 reward + 0.057 harvest_duration + -0.328 value_stay*harvest_duration + 0.075 reward^2 + 0.435 reward*harvest_duration + 0.056 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 197\n",
      "value_stay[t+1] = 0.748 value_stay[t] + 0.535 reward + -0.25 value_stay*harvest_duration + 0.535 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 200\n",
      "value_stay[t+1] = 0.809 value_stay[t] + 0.283 reward + -0.191 value_stay*harvest_duration + 0.183 reward^2 + 0.286 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 201\n",
      "value_stay[t+1] = 0.112 1 + 0.624 value_stay[t] + -0.175 reward + 0.111 harvest_duration + -0.376 value_stay*harvest_duration + -0.175 reward*harvest_duration + 0.111 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 203\n",
      "value_stay[t+1] = 0.073 1 + 0.627 value_stay[t] + 0.148 reward + 0.072 harvest_duration + -0.375 value_stay*harvest_duration + 0.382 reward^2 + 0.148 reward*harvest_duration + 0.072 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 204\n",
      "value_stay[t+1] = 0.052 1 + 0.668 value_stay[t] + 0.481 reward + 0.053 harvest_duration + -0.329 value_stay*harvest_duration + 0.478 reward*harvest_duration + 0.052 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 205\n",
      "value_stay[t+1] = 0.112 1 + 0.595 value_stay[t] + -0.143 reward + 0.112 harvest_duration + -0.412 value_stay*harvest_duration + -0.143 reward*harvest_duration + 0.112 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 207\n",
      "value_stay[t+1] = 0.146 1 + 0.417 value_stay[t] + 0.146 harvest_duration + -0.582 value_stay*harvest_duration + 0.147 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 210\n",
      "value_stay[t+1] = 0.057 1 + 0.675 value_stay[t] + 0.48 reward + 0.058 harvest_duration + -0.328 value_stay*harvest_duration + 0.482 reward*harvest_duration + 0.059 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 212\n",
      "value_stay[t+1] = 0.099 1 + 0.557 value_stay[t] + 0.16 reward + 0.098 harvest_duration + -0.444 value_stay*harvest_duration + 0.237 reward^2 + 0.163 reward*harvest_duration + 0.099 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 213\n",
      "value_stay[t+1] = 0.114 1 + 0.62 value_stay[t] + -0.174 reward + 0.112 harvest_duration + -0.385 value_stay*harvest_duration + -0.172 reward*harvest_duration + 0.114 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 217\n",
      "value_stay[t+1] = 0.142 1 + 0.457 value_stay[t] + 0.141 harvest_duration + -0.54 value_stay*harvest_duration + 0.142 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 224\n",
      "value_stay[t+1] = 0.103 1 + 0.648 value_stay[t] + -0.171 reward + 0.104 harvest_duration + -0.357 value_stay*harvest_duration + -0.171 reward*harvest_duration + 0.103 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 227\n",
      "value_stay[t+1] = 0.682 value_stay[t] + 0.497 reward + 0.052 harvest_duration + -0.321 value_stay*harvest_duration + 0.497 reward*harvest_duration + 0.052 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 228\n",
      "value_stay[t+1] = 0.149 1 + 0.413 value_stay[t] + 0.148 harvest_duration + -0.588 value_stay*harvest_duration + 0.149 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 229\n",
      "value_stay[t+1] = 0.817 value_stay[t] + 0.22 reward + -0.181 value_stay*harvest_duration + 0.175 reward^2 + 0.22 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 232\n",
      "value_stay[t+1] = 0.102 1 + 0.771 value_stay[t] + 0.102 harvest_duration + -0.23 value_stay*harvest_duration + 0.314 reward^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 234\n",
      "value_stay[t+1] = 0.756 value_stay[t] + 0.511 reward + -0.245 value_stay*harvest_duration + 0.51 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 237\n",
      "value_stay[t+1] = 0.062 1 + 0.651 value_stay[t] + 0.415 reward + 0.061 harvest_duration + -0.352 value_stay*harvest_duration + 0.081 reward^2 + 0.415 reward*harvest_duration + 0.062 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 244\n",
      "value_stay[t+1] = 0.832 value_stay[t] + 0.368 reward + -0.169 value_stay*harvest_duration + 0.365 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 245\n",
      "value_stay[t+1] = 0.151 1 + 0.432 value_stay[t] + 0.151 harvest_duration + -0.567 value_stay*harvest_duration + 0.151 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 246\n",
      "value_stay[t+1] = 0.819 value_stay[t] + 0.285 reward + -0.183 value_stay*harvest_duration + 0.134 reward^2 + 0.286 reward*harvest_duration \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n",
      "Participant number 248\n",
      "value_stay[t+1] = 0.101 1 + 0.569 value_stay[t] + 0.06 reward + 0.101 harvest_duration + -0.432 value_stay*harvest_duration + 0.06 reward*harvest_duration + 0.101 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n"
     ]
    }
   ],
   "source": [
    "print('UNDERHARVESTERS') \n",
    "for p in underharvesters:\n",
    "    print('Participant number', p)\n",
    "    estimator.print_spice_model(participant_id=p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MVT Model by Constantino et al. (2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "from weinhardt2025.benchmarking.benchmarking_bustamante2023 import MarginalValueTheoremModel\n",
    "from weinhardt2025.benchmarking.benchmarking_gru import training\n",
    "from spice.utils.agent import Agent\n",
    "\n",
    "# 1. stick to low effort \n",
    "# 2. two sets of params for low and high effort\n",
    "\n",
    "mvt = MarginalValueTheoremModel(\n",
    "    n_participants=n_participants,\n",
    "    depletion=None,  # if None: learn value; else: fix to given value;\n",
    "    baseline_gain=None,  # if None: learn value; else: fix to given value;\n",
    "    batch_first=True,\n",
    "    )\n",
    "\n",
    "epochs = 1000\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=mvt.parameters(), lr=0.01)\n",
    "\n",
    "path_mvt = '../../weinhardt2025/params/bustamante2023/baseline_bustamante2023.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000: L(Train): 0.7199206352233887; L(Test): 0.7148324251174927\n",
      "Epoch 2/1000: L(Train): 0.7145852446556091; L(Test): 0.7100205421447754\n",
      "Epoch 3/1000: L(Train): 0.709622323513031; L(Test): 0.7053030133247375\n",
      "Epoch 4/1000: L(Train): 0.7049347162246704; L(Test): 0.7006457448005676\n",
      "Epoch 5/1000: L(Train): 0.7001373767852783; L(Test): 0.6960488557815552\n",
      "Epoch 6/1000: L(Train): 0.69582599401474; L(Test): 0.6915087699890137\n",
      "Epoch 7/1000: L(Train): 0.6915344595909119; L(Test): 0.6870206594467163\n",
      "Epoch 8/1000: L(Train): 0.6870281100273132; L(Test): 0.6825779676437378\n",
      "Epoch 9/1000: L(Train): 0.6827908754348755; L(Test): 0.6781867146492004\n",
      "Epoch 10/1000: L(Train): 0.6779783368110657; L(Test): 0.6738501191139221\n",
      "Epoch 11/1000: L(Train): 0.6740661859512329; L(Test): 0.6695634722709656\n",
      "Epoch 12/1000: L(Train): 0.6697940826416016; L(Test): 0.6653233170509338\n",
      "Epoch 13/1000: L(Train): 0.6652541160583496; L(Test): 0.6611303091049194\n",
      "Epoch 14/1000: L(Train): 0.6611160039901733; L(Test): 0.6569823026657104\n",
      "Epoch 15/1000: L(Train): 0.6568900942802429; L(Test): 0.652880847454071\n",
      "Epoch 16/1000: L(Train): 0.6528928875923157; L(Test): 0.6488248109817505\n",
      "Epoch 17/1000: L(Train): 0.6490197777748108; L(Test): 0.6448135375976562\n",
      "Epoch 18/1000: L(Train): 0.6447246074676514; L(Test): 0.6408495306968689\n",
      "Epoch 19/1000: L(Train): 0.6409608125686646; L(Test): 0.6369319558143616\n",
      "Epoch 20/1000: L(Train): 0.6366987228393555; L(Test): 0.633060872554779\n",
      "Epoch 21/1000: L(Train): 0.6330204010009766; L(Test): 0.6292343735694885\n",
      "Epoch 22/1000: L(Train): 0.629463255405426; L(Test): 0.6254522204399109\n",
      "Epoch 23/1000: L(Train): 0.62552410364151; L(Test): 0.6217140555381775\n",
      "Epoch 24/1000: L(Train): 0.6219736337661743; L(Test): 0.6180192828178406\n",
      "Epoch 25/1000: L(Train): 0.6184539794921875; L(Test): 0.6143694519996643\n",
      "Epoch 26/1000: L(Train): 0.6143827438354492; L(Test): 0.6107633113861084\n",
      "Epoch 27/1000: L(Train): 0.6109620928764343; L(Test): 0.6072007417678833\n",
      "Epoch 28/1000: L(Train): 0.6069067716598511; L(Test): 0.6036789417266846\n",
      "Epoch 29/1000: L(Train): 0.6036773920059204; L(Test): 0.6001981496810913\n",
      "Epoch 30/1000: L(Train): 0.600479781627655; L(Test): 0.596759557723999\n",
      "Epoch 31/1000: L(Train): 0.5967574119567871; L(Test): 0.593361496925354\n",
      "Epoch 32/1000: L(Train): 0.593315839767456; L(Test): 0.5900037884712219\n",
      "Epoch 33/1000: L(Train): 0.5902352929115295; L(Test): 0.5866857767105103\n",
      "Epoch 34/1000: L(Train): 0.5861316919326782; L(Test): 0.5834041833877563\n",
      "Epoch 35/1000: L(Train): 0.583764374256134; L(Test): 0.5801633596420288\n",
      "Epoch 36/1000: L(Train): 0.5800980925559998; L(Test): 0.5769590139389038\n",
      "Epoch 37/1000: L(Train): 0.5770981907844543; L(Test): 0.573792576789856\n",
      "Epoch 38/1000: L(Train): 0.5735121369361877; L(Test): 0.5706624984741211\n",
      "Epoch 39/1000: L(Train): 0.5710322856903076; L(Test): 0.5675681233406067\n",
      "Epoch 40/1000: L(Train): 0.5678266286849976; L(Test): 0.5645108819007874\n",
      "Epoch 41/1000: L(Train): 0.5644029378890991; L(Test): 0.5614891052246094\n",
      "Epoch 42/1000: L(Train): 0.5618523359298706; L(Test): 0.5585018396377563\n",
      "Epoch 43/1000: L(Train): 0.5584064722061157; L(Test): 0.5555476546287537\n",
      "Epoch 44/1000: L(Train): 0.5558965802192688; L(Test): 0.5526271462440491\n",
      "Epoch 45/1000: L(Train): 0.5527957081794739; L(Test): 0.549739420413971\n",
      "Epoch 46/1000: L(Train): 0.5497692823410034; L(Test): 0.5468831658363342\n",
      "Epoch 47/1000: L(Train): 0.547430694103241; L(Test): 0.544059157371521\n",
      "Epoch 48/1000: L(Train): 0.5432100296020508; L(Test): 0.5412635803222656\n",
      "Epoch 49/1000: L(Train): 0.5414409637451172; L(Test): 0.5384984612464905\n",
      "Epoch 50/1000: L(Train): 0.5395830273628235; L(Test): 0.5357651710510254\n",
      "Epoch 51/1000: L(Train): 0.536592960357666; L(Test): 0.5330621004104614\n",
      "Epoch 52/1000: L(Train): 0.5318370461463928; L(Test): 0.530385434627533\n",
      "Epoch 53/1000: L(Train): 0.5304440855979919; L(Test): 0.5277374982833862\n",
      "Epoch 54/1000: L(Train): 0.5277808904647827; L(Test): 0.5251175165176392\n",
      "Epoch 55/1000: L(Train): 0.525389552116394; L(Test): 0.5225257277488708\n",
      "Epoch 56/1000: L(Train): 0.5226140022277832; L(Test): 0.5199601650238037\n",
      "Epoch 57/1000: L(Train): 0.5199989080429077; L(Test): 0.5174216628074646\n",
      "Epoch 58/1000: L(Train): 0.5178260803222656; L(Test): 0.5149185061454773\n",
      "Epoch 59/1000: L(Train): 0.5150222778320312; L(Test): 0.5124719738960266\n",
      "Epoch 60/1000: L(Train): 0.5119452476501465; L(Test): 0.5100937485694885\n",
      "Epoch 61/1000: L(Train): 0.5099132061004639; L(Test): 0.5077918171882629\n",
      "Epoch 62/1000: L(Train): 0.5076957941055298; L(Test): 0.5055922269821167\n",
      "Epoch 63/1000: L(Train): 0.5058284401893616; L(Test): 0.5034951567649841\n",
      "Epoch 64/1000: L(Train): 0.503658652305603; L(Test): 0.5014760494232178\n",
      "Epoch 65/1000: L(Train): 0.5014793872833252; L(Test): 0.49950578808784485\n",
      "Epoch 66/1000: L(Train): 0.49888402223587036; L(Test): 0.49757257103919983\n",
      "Epoch 67/1000: L(Train): 0.49730005860328674; L(Test): 0.4956713318824768\n",
      "Epoch 68/1000: L(Train): 0.49549752473831177; L(Test): 0.4937955141067505\n",
      "Epoch 69/1000: L(Train): 0.49403271079063416; L(Test): 0.49194398522377014\n",
      "Epoch 70/1000: L(Train): 0.4913465976715088; L(Test): 0.490111380815506\n",
      "Epoch 71/1000: L(Train): 0.49027112126350403; L(Test): 0.48829808831214905\n",
      "Epoch 72/1000: L(Train): 0.48798152804374695; L(Test): 0.48650336265563965\n",
      "Epoch 73/1000: L(Train): 0.4864262640476227; L(Test): 0.4847274124622345\n",
      "Epoch 74/1000: L(Train): 0.4854368269443512; L(Test): 0.48297154903411865\n",
      "Epoch 75/1000: L(Train): 0.48386651277542114; L(Test): 0.4812348484992981\n",
      "Epoch 76/1000: L(Train): 0.4807489216327667; L(Test): 0.47951561212539673\n",
      "Epoch 77/1000: L(Train): 0.4783444106578827; L(Test): 0.4778137803077698\n",
      "Epoch 78/1000: L(Train): 0.47755953669548035; L(Test): 0.4761297404766083\n",
      "Epoch 79/1000: L(Train): 0.476301908493042; L(Test): 0.4744630753993988\n",
      "Epoch 80/1000: L(Train): 0.4737924635410309; L(Test): 0.4728138744831085\n",
      "Epoch 81/1000: L(Train): 0.47331762313842773; L(Test): 0.47118255496025085\n",
      "Epoch 82/1000: L(Train): 0.47085896134376526; L(Test): 0.4695679247379303\n",
      "Epoch 83/1000: L(Train): 0.4695826768875122; L(Test): 0.4679698944091797\n",
      "Epoch 84/1000: L(Train): 0.46788081526756287; L(Test): 0.46638891100883484\n",
      "Epoch 85/1000: L(Train): 0.4672963321208954; L(Test): 0.46482476592063904\n",
      "Epoch 86/1000: L(Train): 0.46602484583854675; L(Test): 0.4632780849933624\n",
      "Epoch 87/1000: L(Train): 0.46337929368019104; L(Test): 0.46174734830856323\n",
      "Epoch 88/1000: L(Train): 0.4606248736381531; L(Test): 0.46023157238960266\n",
      "Epoch 89/1000: L(Train): 0.46179354190826416; L(Test): 0.4587332010269165\n",
      "Epoch 90/1000: L(Train): 0.45900291204452515; L(Test): 0.45725056529045105\n",
      "Epoch 91/1000: L(Train): 0.4576076865196228; L(Test): 0.4557839334011078\n",
      "Epoch 92/1000: L(Train): 0.45578891038894653; L(Test): 0.45433279871940613\n",
      "Epoch 93/1000: L(Train): 0.4546738266944885; L(Test): 0.4528968632221222\n",
      "Epoch 94/1000: L(Train): 0.45490550994873047; L(Test): 0.4514783024787903\n",
      "Epoch 95/1000: L(Train): 0.4503993093967438; L(Test): 0.4500730633735657\n",
      "Epoch 96/1000: L(Train): 0.450319766998291; L(Test): 0.4486832916736603\n",
      "Epoch 97/1000: L(Train): 0.4485532343387604; L(Test): 0.4473072588443756\n",
      "Epoch 98/1000: L(Train): 0.44739004969596863; L(Test): 0.44594621658325195\n",
      "Epoch 99/1000: L(Train): 0.44737163186073303; L(Test): 0.4446001648902893\n",
      "Epoch 100/1000: L(Train): 0.4449220597743988; L(Test): 0.4432680010795593\n",
      "Epoch 101/1000: L(Train): 0.4423545002937317; L(Test): 0.44194963574409485\n",
      "Epoch 102/1000: L(Train): 0.4428296387195587; L(Test): 0.44064587354660034\n",
      "Epoch 103/1000: L(Train): 0.4416307508945465; L(Test): 0.4393561780452728\n",
      "Epoch 104/1000: L(Train): 0.4384117126464844; L(Test): 0.43807923793792725\n",
      "Epoch 105/1000: L(Train): 0.43671101331710815; L(Test): 0.4368145763874054\n",
      "Epoch 106/1000: L(Train): 0.4361323416233063; L(Test): 0.43556320667266846\n",
      "Epoch 107/1000: L(Train): 0.43558675050735474; L(Test): 0.4343249797821045\n",
      "Epoch 108/1000: L(Train): 0.4343051016330719; L(Test): 0.4331001341342926\n",
      "Epoch 109/1000: L(Train): 0.43425479531288147; L(Test): 0.4318893849849701\n",
      "Epoch 110/1000: L(Train): 0.4324130117893219; L(Test): 0.4306917190551758\n",
      "Epoch 111/1000: L(Train): 0.4317089319229126; L(Test): 0.42950794100761414\n",
      "Epoch 112/1000: L(Train): 0.4297536313533783; L(Test): 0.42833763360977173\n",
      "Epoch 113/1000: L(Train): 0.4288071095943451; L(Test): 0.42718032002449036\n",
      "Epoch 114/1000: L(Train): 0.4286558926105499; L(Test): 0.42603638768196106\n",
      "Epoch 115/1000: L(Train): 0.4250946044921875; L(Test): 0.4249034821987152\n",
      "Epoch 116/1000: L(Train): 0.42450907826423645; L(Test): 0.42378145456314087\n",
      "Epoch 117/1000: L(Train): 0.4265052378177643; L(Test): 0.4226728081703186\n",
      "Epoch 118/1000: L(Train): 0.4239017367362976; L(Test): 0.4215765595436096\n",
      "Epoch 119/1000: L(Train): 0.42256930470466614; L(Test): 0.4204927086830139\n",
      "Epoch 120/1000: L(Train): 0.42041274905204773; L(Test): 0.419420450925827\n",
      "Epoch 121/1000: L(Train): 0.4200228750705719; L(Test): 0.41836005449295044\n",
      "Epoch 122/1000: L(Train): 0.4187779128551483; L(Test): 0.4173104465007782\n",
      "Epoch 123/1000: L(Train): 0.4168955683708191; L(Test): 0.41627079248428345\n",
      "Epoch 124/1000: L(Train): 0.41547372937202454; L(Test): 0.41524171829223633\n",
      "Epoch 125/1000: L(Train): 0.4126351475715637; L(Test): 0.4142218828201294\n",
      "Epoch 126/1000: L(Train): 0.41336479783058167; L(Test): 0.41321250796318054\n",
      "Epoch 127/1000: L(Train): 0.41033807396888733; L(Test): 0.4122123122215271\n",
      "Epoch 128/1000: L(Train): 0.41111233830451965; L(Test): 0.41122254729270935\n",
      "Epoch 129/1000: L(Train): 0.410549521446228; L(Test): 0.41024354100227356\n",
      "Epoch 130/1000: L(Train): 0.4097180962562561; L(Test): 0.4092753231525421\n",
      "Epoch 131/1000: L(Train): 0.40880900621414185; L(Test): 0.40831759572029114\n",
      "Epoch 132/1000: L(Train): 0.40734270215034485; L(Test): 0.4073708951473236\n",
      "Epoch 133/1000: L(Train): 0.4101347327232361; L(Test): 0.4064359962940216\n",
      "Epoch 134/1000: L(Train): 0.40700143575668335; L(Test): 0.4055115580558777\n",
      "Epoch 135/1000: L(Train): 0.4056491255760193; L(Test): 0.40459728240966797\n",
      "Epoch 136/1000: L(Train): 0.4080066978931427; L(Test): 0.4036949872970581\n",
      "Epoch 137/1000: L(Train): 0.40393367409706116; L(Test): 0.40280282497406006\n",
      "Epoch 138/1000: L(Train): 0.4018670916557312; L(Test): 0.4019196331501007\n",
      "Epoch 139/1000: L(Train): 0.4001571536064148; L(Test): 0.4010446071624756\n",
      "Epoch 140/1000: L(Train): 0.40451037883758545; L(Test): 0.4001806676387787\n",
      "Epoch 141/1000: L(Train): 0.4004639685153961; L(Test): 0.3993268609046936\n",
      "Epoch 142/1000: L(Train): 0.39823755621910095; L(Test): 0.39848172664642334\n",
      "Epoch 143/1000: L(Train): 0.3972952663898468; L(Test): 0.3976452052593231\n",
      "Epoch 144/1000: L(Train): 0.3974948823451996; L(Test): 0.3968178629875183\n",
      "Epoch 145/1000: L(Train): 0.3958020508289337; L(Test): 0.3959991931915283\n",
      "Epoch 146/1000: L(Train): 0.39664801955223083; L(Test): 0.3951895833015442\n",
      "Epoch 147/1000: L(Train): 0.3926500380039215; L(Test): 0.3943876326084137\n",
      "Epoch 148/1000: L(Train): 0.39470139145851135; L(Test): 0.3935950994491577\n",
      "Epoch 149/1000: L(Train): 0.3894953727722168; L(Test): 0.39280956983566284\n",
      "Epoch 150/1000: L(Train): 0.3909122049808502; L(Test): 0.3920321464538574\n",
      "Epoch 151/1000: L(Train): 0.3904803693294525; L(Test): 0.3912626802921295\n",
      "Epoch 152/1000: L(Train): 0.3912319242954254; L(Test): 0.39050284028053284\n",
      "Epoch 153/1000: L(Train): 0.388849139213562; L(Test): 0.389751136302948\n",
      "Epoch 154/1000: L(Train): 0.3903445303440094; L(Test): 0.389008492231369\n",
      "Epoch 155/1000: L(Train): 0.38743627071380615; L(Test): 0.38827332854270935\n",
      "Epoch 156/1000: L(Train): 0.38822871446609497; L(Test): 0.38754716515541077\n",
      "Epoch 157/1000: L(Train): 0.3861652612686157; L(Test): 0.3868286907672882\n",
      "Epoch 158/1000: L(Train): 0.3873416483402252; L(Test): 0.38611900806427\n",
      "Epoch 159/1000: L(Train): 0.38789427280426025; L(Test): 0.3854183554649353\n",
      "Epoch 160/1000: L(Train): 0.3861376941204071; L(Test): 0.3847261667251587\n",
      "Epoch 161/1000: L(Train): 0.38466134667396545; L(Test): 0.3840417265892029\n",
      "Epoch 162/1000: L(Train): 0.38427460193634033; L(Test): 0.38336506485939026\n",
      "Epoch 163/1000: L(Train): 0.38265207409858704; L(Test): 0.3826962411403656\n",
      "Epoch 164/1000: L(Train): 0.38295722007751465; L(Test): 0.38203519582748413\n",
      "Epoch 165/1000: L(Train): 0.3810214102268219; L(Test): 0.38138115406036377\n",
      "Epoch 166/1000: L(Train): 0.3822687268257141; L(Test): 0.38073551654815674\n",
      "Epoch 167/1000: L(Train): 0.3828103542327881; L(Test): 0.3800976276397705\n",
      "Epoch 168/1000: L(Train): 0.38002198934555054; L(Test): 0.3794667720794678\n",
      "Epoch 169/1000: L(Train): 0.38062235713005066; L(Test): 0.3788439631462097\n",
      "Epoch 170/1000: L(Train): 0.37741151452064514; L(Test): 0.37822747230529785\n",
      "Epoch 171/1000: L(Train): 0.3760077655315399; L(Test): 0.3776169419288635\n",
      "Epoch 172/1000: L(Train): 0.3772178590297699; L(Test): 0.37701308727264404\n",
      "Epoch 173/1000: L(Train): 0.3758834898471832; L(Test): 0.37641581892967224\n",
      "Epoch 174/1000: L(Train): 0.3780187964439392; L(Test): 0.37582603096961975\n",
      "Epoch 175/1000: L(Train): 0.37487590312957764; L(Test): 0.37524276971817017\n",
      "Epoch 176/1000: L(Train): 0.3748200833797455; L(Test): 0.3746660649776459\n",
      "Epoch 177/1000: L(Train): 0.3735692501068115; L(Test): 0.37409523129463196\n",
      "Epoch 178/1000: L(Train): 0.3742918074131012; L(Test): 0.37353068590164185\n",
      "Epoch 179/1000: L(Train): 0.37379467487335205; L(Test): 0.3729728162288666\n",
      "Epoch 180/1000: L(Train): 0.37345635890960693; L(Test): 0.3724212348461151\n",
      "Epoch 181/1000: L(Train): 0.37278053164482117; L(Test): 0.3718758225440979\n",
      "Epoch 182/1000: L(Train): 0.37136033177375793; L(Test): 0.37133681774139404\n",
      "Epoch 183/1000: L(Train): 0.37030819058418274; L(Test): 0.37080302834510803\n",
      "Epoch 184/1000: L(Train): 0.3720363676548004; L(Test): 0.3702758252620697\n",
      "Epoch 185/1000: L(Train): 0.3687981069087982; L(Test): 0.36975449323654175\n",
      "Epoch 186/1000: L(Train): 0.3683622181415558; L(Test): 0.36923858523368835\n",
      "Epoch 187/1000: L(Train): 0.36913755536079407; L(Test): 0.36872828006744385\n",
      "Epoch 188/1000: L(Train): 0.36920490860939026; L(Test): 0.36822405457496643\n",
      "Epoch 189/1000: L(Train): 0.3681223690509796; L(Test): 0.3677254319190979\n",
      "Epoch 190/1000: L(Train): 0.36809176206588745; L(Test): 0.3672327697277069\n",
      "Epoch 191/1000: L(Train): 0.36708706617355347; L(Test): 0.3667456805706024\n",
      "Epoch 192/1000: L(Train): 0.36642810702323914; L(Test): 0.3662642240524292\n",
      "Epoch 193/1000: L(Train): 0.36600732803344727; L(Test): 0.36578816175460815\n",
      "Epoch 194/1000: L(Train): 0.36404919624328613; L(Test): 0.3653172254562378\n",
      "Epoch 195/1000: L(Train): 0.366094172000885; L(Test): 0.3648515045642853\n",
      "Epoch 196/1000: L(Train): 0.36505019664764404; L(Test): 0.3643908202648163\n",
      "Epoch 197/1000: L(Train): 0.3649682402610779; L(Test): 0.36393532156944275\n",
      "Epoch 198/1000: L(Train): 0.3672950863838196; L(Test): 0.3634856641292572\n",
      "Epoch 199/1000: L(Train): 0.36161765456199646; L(Test): 0.36304041743278503\n",
      "Epoch 200/1000: L(Train): 0.36139973998069763; L(Test): 0.3625994920730591\n",
      "Epoch 201/1000: L(Train): 0.3614361584186554; L(Test): 0.3621631860733032\n",
      "Epoch 202/1000: L(Train): 0.36093661189079285; L(Test): 0.36173108220100403\n",
      "Epoch 203/1000: L(Train): 0.362560898065567; L(Test): 0.3613044321537018\n",
      "Epoch 204/1000: L(Train): 0.36411502957344055; L(Test): 0.36088308691978455\n",
      "Epoch 205/1000: L(Train): 0.3616369664669037; L(Test): 0.36046695709228516\n",
      "Epoch 206/1000: L(Train): 0.3608797788619995; L(Test): 0.3600556552410126\n",
      "Epoch 207/1000: L(Train): 0.3586304485797882; L(Test): 0.3596487045288086\n",
      "Epoch 208/1000: L(Train): 0.3577647805213928; L(Test): 0.3592454791069031\n",
      "Epoch 209/1000: L(Train): 0.3596413731575012; L(Test): 0.35884690284729004\n",
      "Epoch 210/1000: L(Train): 0.357500821352005; L(Test): 0.35845252871513367\n",
      "Epoch 211/1000: L(Train): 0.3553750216960907; L(Test): 0.35806185007095337\n",
      "Epoch 212/1000: L(Train): 0.35896405577659607; L(Test): 0.3576756715774536\n",
      "Epoch 213/1000: L(Train): 0.3570634126663208; L(Test): 0.35729411244392395\n",
      "Epoch 214/1000: L(Train): 0.35759711265563965; L(Test): 0.35691675543785095\n",
      "Epoch 215/1000: L(Train): 0.3548424541950226; L(Test): 0.35654306411743164\n",
      "Epoch 216/1000: L(Train): 0.35689038038253784; L(Test): 0.3561733663082123\n",
      "Epoch 217/1000: L(Train): 0.35444700717926025; L(Test): 0.35580694675445557\n",
      "Epoch 218/1000: L(Train): 0.3571511209011078; L(Test): 0.3554452657699585\n",
      "Epoch 219/1000: L(Train): 0.35532787442207336; L(Test): 0.35508742928504944\n",
      "Epoch 220/1000: L(Train): 0.3565944731235504; L(Test): 0.3547337055206299\n",
      "Epoch 221/1000: L(Train): 0.3556481599807739; L(Test): 0.3543839752674103\n",
      "Epoch 222/1000: L(Train): 0.3556497097015381; L(Test): 0.35403817892074585\n",
      "Epoch 223/1000: L(Train): 0.355923593044281; L(Test): 0.35369569063186646\n",
      "Epoch 224/1000: L(Train): 0.35599032044410706; L(Test): 0.35335689783096313\n",
      "Epoch 225/1000: L(Train): 0.3555983603000641; L(Test): 0.35302236676216125\n",
      "Epoch 226/1000: L(Train): 0.3509577810764313; L(Test): 0.35269084572792053\n",
      "Epoch 227/1000: L(Train): 0.35337749123573303; L(Test): 0.3523625135421753\n",
      "Epoch 228/1000: L(Train): 0.35231995582580566; L(Test): 0.3520375192165375\n",
      "Epoch 229/1000: L(Train): 0.3515492081642151; L(Test): 0.35171595215797424\n",
      "Epoch 230/1000: L(Train): 0.3538404107093811; L(Test): 0.3513978123664856\n",
      "Epoch 231/1000: L(Train): 0.3495214283466339; L(Test): 0.35108259320259094\n",
      "Epoch 232/1000: L(Train): 0.3561999797821045; L(Test): 0.35077157616615295\n",
      "Epoch 233/1000: L(Train): 0.3515247106552124; L(Test): 0.3504638969898224\n",
      "Epoch 234/1000: L(Train): 0.35108324885368347; L(Test): 0.350159615278244\n",
      "Epoch 235/1000: L(Train): 0.34967464208602905; L(Test): 0.3498586118221283\n",
      "Epoch 236/1000: L(Train): 0.34994497895240784; L(Test): 0.34956005215644836\n",
      "Epoch 237/1000: L(Train): 0.35105761885643005; L(Test): 0.349264532327652\n",
      "Epoch 238/1000: L(Train): 0.34693625569343567; L(Test): 0.34897103905677795\n",
      "Epoch 239/1000: L(Train): 0.3502373993396759; L(Test): 0.348680317401886\n",
      "Epoch 240/1000: L(Train): 0.3450835943222046; L(Test): 0.34839165210723877\n",
      "Epoch 241/1000: L(Train): 0.3463301956653595; L(Test): 0.3481055796146393\n",
      "Epoch 242/1000: L(Train): 0.3495059907436371; L(Test): 0.34782296419143677\n",
      "Epoch 243/1000: L(Train): 0.34596434235572815; L(Test): 0.3475428819656372\n",
      "Epoch 244/1000: L(Train): 0.3466634750366211; L(Test): 0.34726589918136597\n",
      "Epoch 245/1000: L(Train): 0.34722939133644104; L(Test): 0.3469918668270111\n",
      "Epoch 246/1000: L(Train): 0.3443942070007324; L(Test): 0.34672021865844727\n",
      "Epoch 247/1000: L(Train): 0.34316185116767883; L(Test): 0.3464505672454834\n",
      "Epoch 248/1000: L(Train): 0.3462326228618622; L(Test): 0.34618374705314636\n",
      "Epoch 249/1000: L(Train): 0.3475340008735657; L(Test): 0.3459196388721466\n",
      "Epoch 250/1000: L(Train): 0.34426575899124146; L(Test): 0.3456578254699707\n",
      "Epoch 251/1000: L(Train): 0.3432222604751587; L(Test): 0.34539857506752014\n",
      "Epoch 252/1000: L(Train): 0.34586042165756226; L(Test): 0.34514203667640686\n",
      "Epoch 253/1000: L(Train): 0.34697431325912476; L(Test): 0.34488818049430847\n",
      "Epoch 254/1000: L(Train): 0.3453241288661957; L(Test): 0.34463658928871155\n",
      "Epoch 255/1000: L(Train): 0.3448653817176819; L(Test): 0.344387412071228\n",
      "Epoch 256/1000: L(Train): 0.34352561831474304; L(Test): 0.3441409468650818\n",
      "Epoch 257/1000: L(Train): 0.34226274490356445; L(Test): 0.34389665722846985\n",
      "Epoch 258/1000: L(Train): 0.340168833732605; L(Test): 0.34365418553352356\n",
      "Epoch 259/1000: L(Train): 0.33957985043525696; L(Test): 0.34341296553611755\n",
      "Epoch 260/1000: L(Train): 0.34331056475639343; L(Test): 0.3431742787361145\n",
      "Epoch 261/1000: L(Train): 0.3451841175556183; L(Test): 0.34293854236602783\n",
      "Epoch 262/1000: L(Train): 0.3452194333076477; L(Test): 0.3427055776119232\n",
      "Epoch 263/1000: L(Train): 0.34367635846138; L(Test): 0.34247544407844543\n",
      "Epoch 264/1000: L(Train): 0.34278473258018494; L(Test): 0.3422476053237915\n",
      "Epoch 265/1000: L(Train): 0.34553995728492737; L(Test): 0.3420223891735077\n",
      "Epoch 266/1000: L(Train): 0.34229713678359985; L(Test): 0.3417992889881134\n",
      "Epoch 267/1000: L(Train): 0.33938145637512207; L(Test): 0.34157758951187134\n",
      "Epoch 268/1000: L(Train): 0.3400139808654785; L(Test): 0.3413577377796173\n",
      "Epoch 269/1000: L(Train): 0.3404391407966614; L(Test): 0.34114015102386475\n",
      "Epoch 270/1000: L(Train): 0.3406992256641388; L(Test): 0.34092432260513306\n",
      "Epoch 271/1000: L(Train): 0.3418784737586975; L(Test): 0.34071052074432373\n",
      "Epoch 272/1000: L(Train): 0.3431640565395355; L(Test): 0.34049907326698303\n",
      "Epoch 273/1000: L(Train): 0.3432299792766571; L(Test): 0.3402895927429199\n",
      "Epoch 274/1000: L(Train): 0.33776068687438965; L(Test): 0.3400816321372986\n",
      "Epoch 275/1000: L(Train): 0.33950749039649963; L(Test): 0.3398754596710205\n",
      "Epoch 276/1000: L(Train): 0.3426736295223236; L(Test): 0.3396710753440857\n",
      "Epoch 277/1000: L(Train): 0.3372044563293457; L(Test): 0.33946824073791504\n",
      "Epoch 278/1000: L(Train): 0.3394348919391632; L(Test): 0.3392672538757324\n",
      "Epoch 279/1000: L(Train): 0.33605432510375977; L(Test): 0.3390676975250244\n",
      "Epoch 280/1000: L(Train): 0.3373347818851471; L(Test): 0.3388698101043701\n",
      "Epoch 281/1000: L(Train): 0.34364578127861023; L(Test): 0.3386746942996979\n",
      "Epoch 282/1000: L(Train): 0.33771538734436035; L(Test): 0.3384811282157898\n",
      "Epoch 283/1000: L(Train): 0.3369626998901367; L(Test): 0.3382892310619354\n",
      "Epoch 284/1000: L(Train): 0.34015926718711853; L(Test): 0.3380992114543915\n",
      "Epoch 285/1000: L(Train): 0.33834102749824524; L(Test): 0.3379109799861908\n",
      "Epoch 286/1000: L(Train): 0.3381258547306061; L(Test): 0.3377242684364319\n",
      "Epoch 287/1000: L(Train): 0.3353138566017151; L(Test): 0.33753880858421326\n",
      "Epoch 288/1000: L(Train): 0.3385085165500641; L(Test): 0.3373549282550812\n",
      "Epoch 289/1000: L(Train): 0.33668896555900574; L(Test): 0.3371727764606476\n",
      "Epoch 290/1000: L(Train): 0.3365534543991089; L(Test): 0.33699125051498413\n",
      "Epoch 291/1000: L(Train): 0.3356263339519501; L(Test): 0.3368109166622162\n",
      "Epoch 292/1000: L(Train): 0.33649930357933044; L(Test): 0.3366314172744751\n",
      "Epoch 293/1000: L(Train): 0.3362348973751068; L(Test): 0.3364536464214325\n",
      "Epoch 294/1000: L(Train): 0.3346118927001953; L(Test): 0.3362772464752197\n",
      "Epoch 295/1000: L(Train): 0.33719879388809204; L(Test): 0.33610236644744873\n",
      "Epoch 296/1000: L(Train): 0.335311621427536; L(Test): 0.33592838048934937\n",
      "Epoch 297/1000: L(Train): 0.33635658025741577; L(Test): 0.33575594425201416\n",
      "Epoch 298/1000: L(Train): 0.33552125096321106; L(Test): 0.3355846703052521\n",
      "Epoch 299/1000: L(Train): 0.3370095491409302; L(Test): 0.3354146182537079\n",
      "Epoch 300/1000: L(Train): 0.3339012861251831; L(Test): 0.3352459669113159\n",
      "Epoch 301/1000: L(Train): 0.33435165882110596; L(Test): 0.33507829904556274\n",
      "Epoch 302/1000: L(Train): 0.33432042598724365; L(Test): 0.33491218090057373\n",
      "Epoch 303/1000: L(Train): 0.33649900555610657; L(Test): 0.33474743366241455\n",
      "Epoch 304/1000: L(Train): 0.3322787284851074; L(Test): 0.33458372950553894\n",
      "Epoch 305/1000: L(Train): 0.3311535120010376; L(Test): 0.3344210982322693\n",
      "Epoch 306/1000: L(Train): 0.333267480134964; L(Test): 0.3342598080635071\n",
      "Epoch 307/1000: L(Train): 0.3363357484340668; L(Test): 0.3341001868247986\n",
      "Epoch 308/1000: L(Train): 0.33448508381843567; L(Test): 0.33394163846969604\n",
      "Epoch 309/1000: L(Train): 0.3311399519443512; L(Test): 0.33378446102142334\n",
      "Epoch 310/1000: L(Train): 0.3344784677028656; L(Test): 0.3336282968521118\n",
      "Epoch 311/1000: L(Train): 0.333603173494339; L(Test): 0.3334732949733734\n",
      "Epoch 312/1000: L(Train): 0.33307337760925293; L(Test): 0.33331960439682007\n",
      "Epoch 313/1000: L(Train): 0.3329371213912964; L(Test): 0.3331671357154846\n",
      "Epoch 314/1000: L(Train): 0.33533787727355957; L(Test): 0.3330155611038208\n",
      "Epoch 315/1000: L(Train): 0.33239278197288513; L(Test): 0.33286532759666443\n",
      "Epoch 316/1000: L(Train): 0.33315449953079224; L(Test): 0.3327164351940155\n",
      "Epoch 317/1000: L(Train): 0.33536064624786377; L(Test): 0.3325686454772949\n",
      "Epoch 318/1000: L(Train): 0.3306545615196228; L(Test): 0.3324219584465027\n",
      "Epoch 319/1000: L(Train): 0.3351065218448639; L(Test): 0.3322770893573761\n",
      "Epoch 320/1000: L(Train): 0.3320004642009735; L(Test): 0.3321336507797241\n",
      "Epoch 321/1000: L(Train): 0.3307083249092102; L(Test): 0.3319910764694214\n",
      "Epoch 322/1000: L(Train): 0.32737720012664795; L(Test): 0.331849068403244\n",
      "Epoch 323/1000: L(Train): 0.3335934281349182; L(Test): 0.33170878887176514\n",
      "Epoch 324/1000: L(Train): 0.33244603872299194; L(Test): 0.3315691649913788\n",
      "Epoch 325/1000: L(Train): 0.3317187428474426; L(Test): 0.3314305245876312\n",
      "Epoch 326/1000: L(Train): 0.32938718795776367; L(Test): 0.33129239082336426\n",
      "Epoch 327/1000: L(Train): 0.33391156792640686; L(Test): 0.33115583658218384\n",
      "Epoch 328/1000: L(Train): 0.3283458650112152; L(Test): 0.33101996779441833\n",
      "Epoch 329/1000: L(Train): 0.3335522711277008; L(Test): 0.3308853507041931\n",
      "Epoch 330/1000: L(Train): 0.33223801851272583; L(Test): 0.3307517170906067\n",
      "Epoch 331/1000: L(Train): 0.3329163193702698; L(Test): 0.33061888813972473\n",
      "Epoch 332/1000: L(Train): 0.33015966415405273; L(Test): 0.33048680424690247\n",
      "Epoch 333/1000: L(Train): 0.32880446314811707; L(Test): 0.33035585284233093\n",
      "Epoch 334/1000: L(Train): 0.3313044607639313; L(Test): 0.33022600412368774\n",
      "Epoch 335/1000: L(Train): 0.32936426997184753; L(Test): 0.3300970494747162\n",
      "Epoch 336/1000: L(Train): 0.33231422305107117; L(Test): 0.32996901869773865\n",
      "Epoch 337/1000: L(Train): 0.331419438123703; L(Test): 0.32984206080436707\n",
      "Epoch 338/1000: L(Train): 0.3258887827396393; L(Test): 0.32971569895744324\n",
      "Epoch 339/1000: L(Train): 0.3281879723072052; L(Test): 0.3295900821685791\n",
      "Epoch 340/1000: L(Train): 0.3321631848812103; L(Test): 0.3294656276702881\n",
      "Epoch 341/1000: L(Train): 0.32651129364967346; L(Test): 0.3293418884277344\n",
      "Epoch 342/1000: L(Train): 0.33057454228401184; L(Test): 0.32921937108039856\n",
      "Epoch 343/1000: L(Train): 0.33167004585266113; L(Test): 0.3290979564189911\n",
      "Epoch 344/1000: L(Train): 0.3263157904148102; L(Test): 0.32897669076919556\n",
      "Epoch 345/1000: L(Train): 0.3273128867149353; L(Test): 0.32885634899139404\n",
      "Epoch 346/1000: L(Train): 0.3267240822315216; L(Test): 0.3287367820739746\n",
      "Epoch 347/1000: L(Train): 0.3269425630569458; L(Test): 0.32861778140068054\n",
      "Epoch 348/1000: L(Train): 0.33165794610977173; L(Test): 0.32850003242492676\n",
      "Epoch 349/1000: L(Train): 0.3259139657020569; L(Test): 0.3283831775188446\n",
      "Epoch 350/1000: L(Train): 0.32719001173973083; L(Test): 0.3282669186592102\n",
      "Epoch 351/1000: L(Train): 0.32970893383026123; L(Test): 0.3281513452529907\n",
      "Epoch 352/1000: L(Train): 0.32884636521339417; L(Test): 0.3280367851257324\n",
      "Epoch 353/1000: L(Train): 0.3294046223163605; L(Test): 0.32792308926582336\n",
      "Epoch 354/1000: L(Train): 0.3302910327911377; L(Test): 0.3278101682662964\n",
      "Epoch 355/1000: L(Train): 0.32757750153541565; L(Test): 0.32769790291786194\n",
      "Epoch 356/1000: L(Train): 0.32439547777175903; L(Test): 0.32758596539497375\n",
      "Epoch 357/1000: L(Train): 0.32635214924812317; L(Test): 0.32747477293014526\n",
      "Epoch 358/1000: L(Train): 0.3293849527835846; L(Test): 0.32736465334892273\n",
      "Epoch 359/1000: L(Train): 0.3261192739009857; L(Test): 0.3272553086280823\n",
      "Epoch 360/1000: L(Train): 0.32613709568977356; L(Test): 0.32714635133743286\n",
      "Epoch 361/1000: L(Train): 0.322775274515152; L(Test): 0.3270378112792969\n",
      "Epoch 362/1000: L(Train): 0.3243585526943207; L(Test): 0.3269299864768982\n",
      "Epoch 363/1000: L(Train): 0.3285757005214691; L(Test): 0.3268227279186249\n",
      "Epoch 364/1000: L(Train): 0.3269525468349457; L(Test): 0.3267163336277008\n",
      "Epoch 365/1000: L(Train): 0.32660043239593506; L(Test): 0.3266105353832245\n",
      "Epoch 366/1000: L(Train): 0.3248954713344574; L(Test): 0.32650554180145264\n",
      "Epoch 367/1000: L(Train): 0.3243081569671631; L(Test): 0.3264012336730957\n",
      "Epoch 368/1000: L(Train): 0.32321277260780334; L(Test): 0.32629847526550293\n",
      "Epoch 369/1000: L(Train): 0.3271670937538147; L(Test): 0.3261968791484833\n",
      "Epoch 370/1000: L(Train): 0.32210683822631836; L(Test): 0.3260956108570099\n",
      "Epoch 371/1000: L(Train): 0.3262719511985779; L(Test): 0.3259950876235962\n",
      "Epoch 372/1000: L(Train): 0.3252544403076172; L(Test): 0.32589539885520935\n",
      "Epoch 373/1000: L(Train): 0.32391199469566345; L(Test): 0.3257963955402374\n",
      "Epoch 374/1000: L(Train): 0.32829219102859497; L(Test): 0.32569795846939087\n",
      "Epoch 375/1000: L(Train): 0.32666078209877014; L(Test): 0.3256002962589264\n",
      "Epoch 376/1000: L(Train): 0.324517160654068; L(Test): 0.3255036771297455\n",
      "Epoch 377/1000: L(Train): 0.33009612560272217; L(Test): 0.3254079222679138\n",
      "Epoch 378/1000: L(Train): 0.3295691907405853; L(Test): 0.3253130614757538\n",
      "Epoch 379/1000: L(Train): 0.32588306069374084; L(Test): 0.32521888613700867\n",
      "Epoch 380/1000: L(Train): 0.32722073793411255; L(Test): 0.32512563467025757\n",
      "Epoch 381/1000: L(Train): 0.32725149393081665; L(Test): 0.32503318786621094\n",
      "Epoch 382/1000: L(Train): 0.32285353541374207; L(Test): 0.32494160532951355\n",
      "Epoch 383/1000: L(Train): 0.326823353767395; L(Test): 0.32485076785087585\n",
      "Epoch 384/1000: L(Train): 0.32538431882858276; L(Test): 0.3247600793838501\n",
      "Epoch 385/1000: L(Train): 0.3241996467113495; L(Test): 0.3246699571609497\n",
      "Epoch 386/1000: L(Train): 0.3255036175251007; L(Test): 0.3245804011821747\n",
      "Epoch 387/1000: L(Train): 0.3271792232990265; L(Test): 0.32449135184288025\n",
      "Epoch 388/1000: L(Train): 0.32601213455200195; L(Test): 0.3244028687477112\n",
      "Epoch 389/1000: L(Train): 0.324199378490448; L(Test): 0.32431504130363464\n",
      "Epoch 390/1000: L(Train): 0.3247925341129303; L(Test): 0.324227511882782\n",
      "Epoch 391/1000: L(Train): 0.32686352729797363; L(Test): 0.3241405189037323\n",
      "Epoch 392/1000: L(Train): 0.32356077432632446; L(Test): 0.32405415177345276\n",
      "Epoch 393/1000: L(Train): 0.324556440114975; L(Test): 0.3239685893058777\n",
      "Epoch 394/1000: L(Train): 0.3227541148662567; L(Test): 0.3238837420940399\n",
      "Epoch 395/1000: L(Train): 0.32313960790634155; L(Test): 0.3237994313240051\n",
      "Epoch 396/1000: L(Train): 0.3239680826663971; L(Test): 0.3237157166004181\n",
      "Epoch 397/1000: L(Train): 0.3202255368232727; L(Test): 0.32363179326057434\n",
      "Epoch 398/1000: L(Train): 0.3234511911869049; L(Test): 0.3235485851764679\n",
      "Epoch 399/1000: L(Train): 0.32651057839393616; L(Test): 0.3234664797782898\n",
      "Epoch 400/1000: L(Train): 0.32343026995658875; L(Test): 0.3233850598335266\n",
      "Epoch 401/1000: L(Train): 0.32663899660110474; L(Test): 0.3233044743537903\n",
      "Epoch 402/1000: L(Train): 0.32257649302482605; L(Test): 0.32322460412979126\n",
      "Epoch 403/1000: L(Train): 0.326446533203125; L(Test): 0.32314541935920715\n",
      "Epoch 404/1000: L(Train): 0.32339364290237427; L(Test): 0.3230665624141693\n",
      "Epoch 405/1000: L(Train): 0.3215975761413574; L(Test): 0.3229883313179016\n",
      "Epoch 406/1000: L(Train): 0.3237091898918152; L(Test): 0.32291072607040405\n",
      "Epoch 407/1000: L(Train): 0.3253113925457001; L(Test): 0.32283350825309753\n",
      "Epoch 408/1000: L(Train): 0.3254026770591736; L(Test): 0.32275664806365967\n",
      "Epoch 409/1000: L(Train): 0.3230365812778473; L(Test): 0.3226802945137024\n",
      "Epoch 410/1000: L(Train): 0.32429876923561096; L(Test): 0.32260432839393616\n",
      "Epoch 411/1000: L(Train): 0.3215641379356384; L(Test): 0.32252898812294006\n",
      "Epoch 412/1000: L(Train): 0.320363849401474; L(Test): 0.32245418429374695\n",
      "Epoch 413/1000: L(Train): 0.3239184617996216; L(Test): 0.3223799467086792\n",
      "Epoch 414/1000: L(Train): 0.3230500817298889; L(Test): 0.3223065733909607\n",
      "Epoch 415/1000: L(Train): 0.32314532995224; L(Test): 0.322233647108078\n",
      "Epoch 416/1000: L(Train): 0.32125377655029297; L(Test): 0.32216089963912964\n",
      "Epoch 417/1000: L(Train): 0.32108837366104126; L(Test): 0.3220883309841156\n",
      "Epoch 418/1000: L(Train): 0.3230617940425873; L(Test): 0.32201629877090454\n",
      "Epoch 419/1000: L(Train): 0.3211226761341095; L(Test): 0.3219444453716278\n",
      "Epoch 420/1000: L(Train): 0.32492610812187195; L(Test): 0.3218729794025421\n",
      "Epoch 421/1000: L(Train): 0.322516530752182; L(Test): 0.321802020072937\n",
      "Epoch 422/1000: L(Train): 0.32397782802581787; L(Test): 0.3217316269874573\n",
      "Epoch 423/1000: L(Train): 0.3190852999687195; L(Test): 0.32166165113449097\n",
      "Epoch 424/1000: L(Train): 0.32228219509124756; L(Test): 0.3215920925140381\n",
      "Epoch 425/1000: L(Train): 0.31985655426979065; L(Test): 0.32152286171913147\n",
      "Epoch 426/1000: L(Train): 0.3188819885253906; L(Test): 0.32145363092422485\n",
      "Epoch 427/1000: L(Train): 0.3227880895137787; L(Test): 0.32138487696647644\n",
      "Epoch 428/1000: L(Train): 0.3235052227973938; L(Test): 0.3213167190551758\n",
      "Epoch 429/1000: L(Train): 0.3181976079940796; L(Test): 0.3212489187717438\n",
      "Epoch 430/1000: L(Train): 0.3233032822608948; L(Test): 0.32118144631385803\n",
      "Epoch 431/1000: L(Train): 0.32104256749153137; L(Test): 0.3211143910884857\n",
      "Epoch 432/1000: L(Train): 0.32323211431503296; L(Test): 0.32104790210723877\n",
      "Epoch 433/1000: L(Train): 0.3191848695278168; L(Test): 0.320981502532959\n",
      "Epoch 434/1000: L(Train): 0.32157596945762634; L(Test): 0.3209156095981598\n",
      "Epoch 435/1000: L(Train): 0.3217225968837738; L(Test): 0.3208499848842621\n",
      "Epoch 436/1000: L(Train): 0.32054856419563293; L(Test): 0.32078462839126587\n",
      "Epoch 437/1000: L(Train): 0.31923675537109375; L(Test): 0.3207195997238159\n",
      "Epoch 438/1000: L(Train): 0.3156682550907135; L(Test): 0.32065457105636597\n",
      "Epoch 439/1000: L(Train): 0.32012999057769775; L(Test): 0.3205901086330414\n",
      "Epoch 440/1000: L(Train): 0.31971102952957153; L(Test): 0.3205258548259735\n",
      "Epoch 441/1000: L(Train): 0.3189367651939392; L(Test): 0.3204619586467743\n",
      "Epoch 442/1000: L(Train): 0.3161664605140686; L(Test): 0.3203984498977661\n",
      "Epoch 443/1000: L(Train): 0.32018667459487915; L(Test): 0.3203352391719818\n",
      "Epoch 444/1000: L(Train): 0.32341521978378296; L(Test): 0.3202725350856781\n",
      "Epoch 445/1000: L(Train): 0.3206557035446167; L(Test): 0.3202100992202759\n",
      "Epoch 446/1000: L(Train): 0.3227972388267517; L(Test): 0.3201479911804199\n",
      "Epoch 447/1000: L(Train): 0.32036101818084717; L(Test): 0.3200863301753998\n",
      "Epoch 448/1000: L(Train): 0.31997358798980713; L(Test): 0.32002514600753784\n",
      "Epoch 449/1000: L(Train): 0.32000499963760376; L(Test): 0.3199642598628998\n",
      "Epoch 450/1000: L(Train): 0.318817138671875; L(Test): 0.3199034333229065\n",
      "Epoch 451/1000: L(Train): 0.32038626074790955; L(Test): 0.3198430836200714\n",
      "Epoch 452/1000: L(Train): 0.3224569857120514; L(Test): 0.319783091545105\n",
      "Epoch 453/1000: L(Train): 0.31787246465682983; L(Test): 0.31972354650497437\n",
      "Epoch 454/1000: L(Train): 0.31546586751937866; L(Test): 0.3196641802787781\n",
      "Epoch 455/1000: L(Train): 0.31855037808418274; L(Test): 0.31960543990135193\n",
      "Epoch 456/1000: L(Train): 0.3175966739654541; L(Test): 0.31954705715179443\n",
      "Epoch 457/1000: L(Train): 0.3181159198284149; L(Test): 0.3194889724254608\n",
      "Epoch 458/1000: L(Train): 0.31942328810691833; L(Test): 0.3194313645362854\n",
      "Epoch 459/1000: L(Train): 0.319963663816452; L(Test): 0.319374144077301\n",
      "Epoch 460/1000: L(Train): 0.32262638211250305; L(Test): 0.31931713223457336\n",
      "Epoch 461/1000: L(Train): 0.32167723774909973; L(Test): 0.3192604184150696\n",
      "Epoch 462/1000: L(Train): 0.3142376244068146; L(Test): 0.319203644990921\n",
      "Epoch 463/1000: L(Train): 0.32068750262260437; L(Test): 0.3191471993923187\n",
      "Epoch 464/1000: L(Train): 0.32377365231513977; L(Test): 0.31909140944480896\n",
      "Epoch 465/1000: L(Train): 0.31899917125701904; L(Test): 0.31903567910194397\n",
      "Epoch 466/1000: L(Train): 0.3171599209308624; L(Test): 0.31898030638694763\n",
      "Epoch 467/1000: L(Train): 0.3215601444244385; L(Test): 0.3189252018928528\n",
      "Epoch 468/1000: L(Train): 0.3221905529499054; L(Test): 0.31887057423591614\n",
      "Epoch 469/1000: L(Train): 0.32112887501716614; L(Test): 0.31881624460220337\n",
      "Epoch 470/1000: L(Train): 0.320011168718338; L(Test): 0.31876206398010254\n",
      "Epoch 471/1000: L(Train): 0.318353533744812; L(Test): 0.31870830059051514\n",
      "Epoch 472/1000: L(Train): 0.3168703615665436; L(Test): 0.31865447759628296\n",
      "Epoch 473/1000: L(Train): 0.322919100522995; L(Test): 0.31860092282295227\n",
      "Epoch 474/1000: L(Train): 0.3174031376838684; L(Test): 0.3185475766658783\n",
      "Epoch 475/1000: L(Train): 0.31887444853782654; L(Test): 0.3184944987297058\n",
      "Epoch 476/1000: L(Train): 0.32085537910461426; L(Test): 0.31844162940979004\n",
      "Epoch 477/1000: L(Train): 0.3206416368484497; L(Test): 0.31838902831077576\n",
      "Epoch 478/1000: L(Train): 0.31806179881095886; L(Test): 0.3183368444442749\n",
      "Epoch 479/1000: L(Train): 0.31445205211639404; L(Test): 0.3182847499847412\n",
      "Epoch 480/1000: L(Train): 0.3200182020664215; L(Test): 0.3182329535484314\n",
      "Epoch 481/1000: L(Train): 0.31759998202323914; L(Test): 0.3181813359260559\n",
      "Epoch 482/1000: L(Train): 0.321444034576416; L(Test): 0.31813010573387146\n",
      "Epoch 483/1000: L(Train): 0.31736090779304504; L(Test): 0.31807941198349\n",
      "Epoch 484/1000: L(Train): 0.3199710547924042; L(Test): 0.31802889704704285\n",
      "Epoch 485/1000: L(Train): 0.3138357996940613; L(Test): 0.31797879934310913\n",
      "Epoch 486/1000: L(Train): 0.31684479117393494; L(Test): 0.31792888045310974\n",
      "Epoch 487/1000: L(Train): 0.3175966441631317; L(Test): 0.31787925958633423\n",
      "Epoch 488/1000: L(Train): 0.3177323043346405; L(Test): 0.31783005595207214\n",
      "Epoch 489/1000: L(Train): 0.3159680664539337; L(Test): 0.3177811801433563\n",
      "Epoch 490/1000: L(Train): 0.32239729166030884; L(Test): 0.31773248314857483\n",
      "Epoch 491/1000: L(Train): 0.32051190733909607; L(Test): 0.31768396496772766\n",
      "Epoch 492/1000: L(Train): 0.3178112208843231; L(Test): 0.31763577461242676\n",
      "Epoch 493/1000: L(Train): 0.31227943301200867; L(Test): 0.31758782267570496\n",
      "Epoch 494/1000: L(Train): 0.3187468349933624; L(Test): 0.3175399899482727\n",
      "Epoch 495/1000: L(Train): 0.31521210074424744; L(Test): 0.31749215722084045\n",
      "Epoch 496/1000: L(Train): 0.32110971212387085; L(Test): 0.3174446225166321\n",
      "Epoch 497/1000: L(Train): 0.31711000204086304; L(Test): 0.3173973262310028\n",
      "Epoch 498/1000: L(Train): 0.3133423328399658; L(Test): 0.3173500895500183\n",
      "Epoch 499/1000: L(Train): 0.3187218904495239; L(Test): 0.3173031210899353\n",
      "Epoch 500/1000: L(Train): 0.315162718296051; L(Test): 0.31725645065307617\n",
      "Epoch 501/1000: L(Train): 0.31293007731437683; L(Test): 0.31720978021621704\n",
      "Epoch 502/1000: L(Train): 0.3165219724178314; L(Test): 0.31716325879096985\n",
      "Epoch 503/1000: L(Train): 0.3197053074836731; L(Test): 0.3171170651912689\n",
      "Epoch 504/1000: L(Train): 0.31821951270103455; L(Test): 0.317070871591568\n",
      "Epoch 505/1000: L(Train): 0.31752416491508484; L(Test): 0.31702515482902527\n",
      "Epoch 506/1000: L(Train): 0.31453239917755127; L(Test): 0.31697922945022583\n",
      "Epoch 507/1000: L(Train): 0.31721749901771545; L(Test): 0.3169335424900055\n",
      "Epoch 508/1000: L(Train): 0.31648361682891846; L(Test): 0.3168879449367523\n",
      "Epoch 509/1000: L(Train): 0.31583327054977417; L(Test): 0.31684255599975586\n",
      "Epoch 510/1000: L(Train): 0.3162895441055298; L(Test): 0.3167974650859833\n",
      "Epoch 511/1000: L(Train): 0.3132426142692566; L(Test): 0.3167526423931122\n",
      "Epoch 512/1000: L(Train): 0.31509870290756226; L(Test): 0.316707968711853\n",
      "Epoch 513/1000: L(Train): 0.31751906871795654; L(Test): 0.31666362285614014\n",
      "Epoch 514/1000: L(Train): 0.3158162534236908; L(Test): 0.3166193664073944\n",
      "Epoch 515/1000: L(Train): 0.3137693703174591; L(Test): 0.31657516956329346\n",
      "Epoch 516/1000: L(Train): 0.31561484932899475; L(Test): 0.3165311813354492\n",
      "Epoch 517/1000: L(Train): 0.31687992811203003; L(Test): 0.3164873421192169\n",
      "Epoch 518/1000: L(Train): 0.31649088859558105; L(Test): 0.31644371151924133\n",
      "Epoch 519/1000: L(Train): 0.31469425559043884; L(Test): 0.31640031933784485\n",
      "Epoch 520/1000: L(Train): 0.3157229721546173; L(Test): 0.31635719537734985\n",
      "Epoch 521/1000: L(Train): 0.31519749760627747; L(Test): 0.316314160823822\n",
      "Epoch 522/1000: L(Train): 0.3149261474609375; L(Test): 0.3162713348865509\n",
      "Epoch 523/1000: L(Train): 0.3158775568008423; L(Test): 0.3162287771701813\n",
      "Epoch 524/1000: L(Train): 0.3126286268234253; L(Test): 0.31618642807006836\n",
      "Epoch 525/1000: L(Train): 0.31842219829559326; L(Test): 0.31614431738853455\n",
      "Epoch 526/1000: L(Train): 0.31766802072525024; L(Test): 0.3161025047302246\n",
      "Epoch 527/1000: L(Train): 0.31670868396759033; L(Test): 0.3160611391067505\n",
      "Epoch 528/1000: L(Train): 0.31694984436035156; L(Test): 0.31602001190185547\n",
      "Epoch 529/1000: L(Train): 0.3146306872367859; L(Test): 0.3159787952899933\n",
      "Epoch 530/1000: L(Train): 0.3189704716205597; L(Test): 0.3159377872943878\n",
      "Epoch 531/1000: L(Train): 0.3190087378025055; L(Test): 0.31589677929878235\n",
      "Epoch 532/1000: L(Train): 0.31654229760169983; L(Test): 0.31585603952407837\n",
      "Epoch 533/1000: L(Train): 0.31243085861206055; L(Test): 0.3158152997493744\n",
      "Epoch 534/1000: L(Train): 0.31181788444519043; L(Test): 0.31577491760253906\n",
      "Epoch 535/1000: L(Train): 0.31493309140205383; L(Test): 0.3157348334789276\n",
      "Epoch 536/1000: L(Train): 0.31550949811935425; L(Test): 0.3156951069831848\n",
      "Epoch 537/1000: L(Train): 0.3169828951358795; L(Test): 0.3156557083129883\n",
      "Epoch 538/1000: L(Train): 0.3162955045700073; L(Test): 0.3156163990497589\n",
      "Epoch 539/1000: L(Train): 0.31525346636772156; L(Test): 0.3155771493911743\n",
      "Epoch 540/1000: L(Train): 0.3200781047344208; L(Test): 0.3155381679534912\n",
      "Epoch 541/1000: L(Train): 0.3167172372341156; L(Test): 0.3154991567134857\n",
      "Epoch 542/1000: L(Train): 0.31847554445266724; L(Test): 0.31546008586883545\n",
      "Epoch 543/1000: L(Train): 0.31246325373649597; L(Test): 0.31542131304740906\n",
      "Epoch 544/1000: L(Train): 0.31648993492126465; L(Test): 0.31538262963294983\n",
      "Epoch 545/1000: L(Train): 0.31347227096557617; L(Test): 0.3153437674045563\n",
      "Epoch 546/1000: L(Train): 0.319217711687088; L(Test): 0.3153049051761627\n",
      "Epoch 547/1000: L(Train): 0.3140023946762085; L(Test): 0.31526613235473633\n",
      "Epoch 548/1000: L(Train): 0.314003586769104; L(Test): 0.3152276575565338\n",
      "Epoch 549/1000: L(Train): 0.31575170159339905; L(Test): 0.315189391374588\n",
      "Epoch 550/1000: L(Train): 0.3171725571155548; L(Test): 0.3151512145996094\n",
      "Epoch 551/1000: L(Train): 0.31259626150131226; L(Test): 0.3151131272315979\n",
      "Epoch 552/1000: L(Train): 0.31194067001342773; L(Test): 0.31507524847984314\n",
      "Epoch 553/1000: L(Train): 0.3102971017360687; L(Test): 0.3150375485420227\n",
      "Epoch 554/1000: L(Train): 0.3160738945007324; L(Test): 0.3149999976158142\n",
      "Epoch 555/1000: L(Train): 0.31302744150161743; L(Test): 0.3149625360965729\n",
      "Epoch 556/1000: L(Train): 0.3148740231990814; L(Test): 0.3149252235889435\n",
      "Epoch 557/1000: L(Train): 0.31674307584762573; L(Test): 0.3148881494998932\n",
      "Epoch 558/1000: L(Train): 0.31977003812789917; L(Test): 0.31485122442245483\n",
      "Epoch 559/1000: L(Train): 0.313524454832077; L(Test): 0.3148145079612732\n",
      "Epoch 560/1000: L(Train): 0.31770163774490356; L(Test): 0.31477785110473633\n",
      "Epoch 561/1000: L(Train): 0.31585392355918884; L(Test): 0.31474149227142334\n",
      "Epoch 562/1000: L(Train): 0.3121728003025055; L(Test): 0.3147050440311432\n",
      "Epoch 563/1000: L(Train): 0.3157799243927002; L(Test): 0.31466910243034363\n",
      "Epoch 564/1000: L(Train): 0.31634220480918884; L(Test): 0.31463316082954407\n",
      "Epoch 565/1000: L(Train): 0.3154768943786621; L(Test): 0.314597487449646\n",
      "Epoch 566/1000: L(Train): 0.3157205879688263; L(Test): 0.3145618438720703\n",
      "Epoch 567/1000: L(Train): 0.31659939885139465; L(Test): 0.31452620029449463\n",
      "Epoch 568/1000: L(Train): 0.3140251040458679; L(Test): 0.3144908547401428\n",
      "Epoch 569/1000: L(Train): 0.3188275098800659; L(Test): 0.3144558370113373\n",
      "Epoch 570/1000: L(Train): 0.31372973322868347; L(Test): 0.3144208788871765\n",
      "Epoch 571/1000: L(Train): 0.31688085198402405; L(Test): 0.3143858015537262\n",
      "Epoch 572/1000: L(Train): 0.3180367350578308; L(Test): 0.31435084342956543\n",
      "Epoch 573/1000: L(Train): 0.3146377503871918; L(Test): 0.314316064119339\n",
      "Epoch 574/1000: L(Train): 0.3172474205493927; L(Test): 0.31428098678588867\n",
      "Epoch 575/1000: L(Train): 0.3145045340061188; L(Test): 0.3142463266849518\n",
      "Epoch 576/1000: L(Train): 0.3123750388622284; L(Test): 0.31421181559562683\n",
      "Epoch 577/1000: L(Train): 0.31103768944740295; L(Test): 0.31417736411094666\n",
      "Epoch 578/1000: L(Train): 0.31055948138237; L(Test): 0.3141433000564575\n",
      "Epoch 579/1000: L(Train): 0.31426218152046204; L(Test): 0.3141094148159027\n",
      "Epoch 580/1000: L(Train): 0.3146803677082062; L(Test): 0.31407561898231506\n",
      "Epoch 581/1000: L(Train): 0.3162297010421753; L(Test): 0.31404176354408264\n",
      "Epoch 582/1000: L(Train): 0.3148990869522095; L(Test): 0.31400811672210693\n",
      "Epoch 583/1000: L(Train): 0.31545597314834595; L(Test): 0.3139744997024536\n",
      "Epoch 584/1000: L(Train): 0.3102762699127197; L(Test): 0.3139410614967346\n",
      "Epoch 585/1000: L(Train): 0.31671106815338135; L(Test): 0.31390753388404846\n",
      "Epoch 586/1000: L(Train): 0.31293433904647827; L(Test): 0.3138740062713623\n",
      "Epoch 587/1000: L(Train): 0.31463631987571716; L(Test): 0.3138403594493866\n",
      "Epoch 588/1000: L(Train): 0.31600072979927063; L(Test): 0.31380656361579895\n",
      "Epoch 589/1000: L(Train): 0.3166205585002899; L(Test): 0.31377294659614563\n",
      "Epoch 590/1000: L(Train): 0.31683430075645447; L(Test): 0.31373944878578186\n",
      "Epoch 591/1000: L(Train): 0.31485456228256226; L(Test): 0.3137059509754181\n",
      "Epoch 592/1000: L(Train): 0.3122422993183136; L(Test): 0.31367263197898865\n",
      "Epoch 593/1000: L(Train): 0.31451448798179626; L(Test): 0.3136395215988159\n",
      "Epoch 594/1000: L(Train): 0.3114732503890991; L(Test): 0.3136065602302551\n",
      "Epoch 595/1000: L(Train): 0.3107336163520813; L(Test): 0.31357356905937195\n",
      "Epoch 596/1000: L(Train): 0.3130165934562683; L(Test): 0.3135407269001007\n",
      "Epoch 597/1000: L(Train): 0.3149881958961487; L(Test): 0.31350794434547424\n",
      "Epoch 598/1000: L(Train): 0.3134011924266815; L(Test): 0.3134753704071045\n",
      "Epoch 599/1000: L(Train): 0.3127155601978302; L(Test): 0.31344303488731384\n",
      "Epoch 600/1000: L(Train): 0.3146158456802368; L(Test): 0.3134106993675232\n",
      "Epoch 601/1000: L(Train): 0.31166017055511475; L(Test): 0.31337857246398926\n",
      "Epoch 602/1000: L(Train): 0.3117850422859192; L(Test): 0.3133464455604553\n",
      "Epoch 603/1000: L(Train): 0.31109878420829773; L(Test): 0.3133147358894348\n",
      "Epoch 604/1000: L(Train): 0.31816205382347107; L(Test): 0.3132832646369934\n",
      "Epoch 605/1000: L(Train): 0.3117322623729706; L(Test): 0.3132518529891968\n",
      "Epoch 606/1000: L(Train): 0.31397032737731934; L(Test): 0.3132205307483673\n",
      "Epoch 607/1000: L(Train): 0.3129867911338806; L(Test): 0.31318914890289307\n",
      "Epoch 608/1000: L(Train): 0.3139570951461792; L(Test): 0.31315791606903076\n",
      "Epoch 609/1000: L(Train): 0.3125484883785248; L(Test): 0.313126802444458\n",
      "Epoch 610/1000: L(Train): 0.30921033024787903; L(Test): 0.3130958676338196\n",
      "Epoch 611/1000: L(Train): 0.3137184977531433; L(Test): 0.31306514143943787\n",
      "Epoch 612/1000: L(Train): 0.3142356276512146; L(Test): 0.31303438544273376\n",
      "Epoch 613/1000: L(Train): 0.31428977847099304; L(Test): 0.31300365924835205\n",
      "Epoch 614/1000: L(Train): 0.3130800127983093; L(Test): 0.3129732608795166\n",
      "Epoch 615/1000: L(Train): 0.31359902024269104; L(Test): 0.31294289231300354\n",
      "Epoch 616/1000: L(Train): 0.314071923494339; L(Test): 0.3129127025604248\n",
      "Epoch 617/1000: L(Train): 0.30973729491233826; L(Test): 0.3128826320171356\n",
      "Epoch 618/1000: L(Train): 0.31255364418029785; L(Test): 0.31285277009010315\n",
      "Epoch 619/1000: L(Train): 0.31165915727615356; L(Test): 0.312823086977005\n",
      "Epoch 620/1000: L(Train): 0.3134573996067047; L(Test): 0.312793493270874\n",
      "Epoch 621/1000: L(Train): 0.31477150321006775; L(Test): 0.3127637803554535\n",
      "Epoch 622/1000: L(Train): 0.3122824728488922; L(Test): 0.31273436546325684\n",
      "Epoch 623/1000: L(Train): 0.3169926702976227; L(Test): 0.31270503997802734\n",
      "Epoch 624/1000: L(Train): 0.3117692768573761; L(Test): 0.3126756548881531\n",
      "Epoch 625/1000: L(Train): 0.31426629424095154; L(Test): 0.31264635920524597\n",
      "Epoch 626/1000: L(Train): 0.3166654109954834; L(Test): 0.3126169443130493\n",
      "Epoch 627/1000: L(Train): 0.3131197690963745; L(Test): 0.3125876188278198\n",
      "Epoch 628/1000: L(Train): 0.31142938137054443; L(Test): 0.31255829334259033\n",
      "Epoch 629/1000: L(Train): 0.3096761703491211; L(Test): 0.3125288486480713\n",
      "Epoch 630/1000: L(Train): 0.3151929974555969; L(Test): 0.3124995529651642\n",
      "Epoch 631/1000: L(Train): 0.31583699584007263; L(Test): 0.3124701976776123\n",
      "Epoch 632/1000: L(Train): 0.31448888778686523; L(Test): 0.3124411106109619\n",
      "Epoch 633/1000: L(Train): 0.31050753593444824; L(Test): 0.31241199374198914\n",
      "Epoch 634/1000: L(Train): 0.31376853585243225; L(Test): 0.3123829960823059\n",
      "Epoch 635/1000: L(Train): 0.3102133870124817; L(Test): 0.31235402822494507\n",
      "Epoch 636/1000: L(Train): 0.3124493956565857; L(Test): 0.3123251795768738\n",
      "Epoch 637/1000: L(Train): 0.31481584906578064; L(Test): 0.31229645013809204\n",
      "Epoch 638/1000: L(Train): 0.3116634786128998; L(Test): 0.3122677206993103\n",
      "Epoch 639/1000: L(Train): 0.31364330649375916; L(Test): 0.3122391104698181\n",
      "Epoch 640/1000: L(Train): 0.3103712499141693; L(Test): 0.31221044063568115\n",
      "Epoch 641/1000: L(Train): 0.3115217983722687; L(Test): 0.31218159198760986\n",
      "Epoch 642/1000: L(Train): 0.31128519773483276; L(Test): 0.31215280294418335\n",
      "Epoch 643/1000: L(Train): 0.3137257993221283; L(Test): 0.31212398409843445\n",
      "Epoch 644/1000: L(Train): 0.3106880187988281; L(Test): 0.31209510564804077\n",
      "Epoch 645/1000: L(Train): 0.31058984994888306; L(Test): 0.31206652522087097\n",
      "Epoch 646/1000: L(Train): 0.31285297870635986; L(Test): 0.312037855386734\n",
      "Epoch 647/1000: L(Train): 0.3133237957954407; L(Test): 0.3120090663433075\n",
      "Epoch 648/1000: L(Train): 0.31120532751083374; L(Test): 0.31198054552078247\n",
      "Epoch 649/1000: L(Train): 0.3116110861301422; L(Test): 0.311952143907547\n",
      "Epoch 650/1000: L(Train): 0.3109436631202698; L(Test): 0.311924010515213\n",
      "Epoch 651/1000: L(Train): 0.31285563111305237; L(Test): 0.3118959367275238\n",
      "Epoch 652/1000: L(Train): 0.31152814626693726; L(Test): 0.311867892742157\n",
      "Epoch 653/1000: L(Train): 0.31155744194984436; L(Test): 0.3118399679660797\n",
      "Epoch 654/1000: L(Train): 0.3115861117839813; L(Test): 0.3118121922016144\n",
      "Epoch 655/1000: L(Train): 0.31265994906425476; L(Test): 0.31178441643714905\n",
      "Epoch 656/1000: L(Train): 0.3084855377674103; L(Test): 0.3117566704750061\n",
      "Epoch 657/1000: L(Train): 0.30954304337501526; L(Test): 0.3117290735244751\n",
      "Epoch 658/1000: L(Train): 0.3124023973941803; L(Test): 0.31170153617858887\n",
      "Epoch 659/1000: L(Train): 0.3138848841190338; L(Test): 0.3116741180419922\n",
      "Epoch 660/1000: L(Train): 0.309705525636673; L(Test): 0.3116469085216522\n",
      "Epoch 661/1000: L(Train): 0.3132515847682953; L(Test): 0.31161966919898987\n",
      "Epoch 662/1000: L(Train): 0.31041666865348816; L(Test): 0.31159257888793945\n",
      "Epoch 663/1000: L(Train): 0.31462204456329346; L(Test): 0.3115656077861786\n",
      "Epoch 664/1000: L(Train): 0.31248700618743896; L(Test): 0.31153884530067444\n",
      "Epoch 665/1000: L(Train): 0.3111627697944641; L(Test): 0.3115120530128479\n",
      "Epoch 666/1000: L(Train): 0.3142109513282776; L(Test): 0.3114851415157318\n",
      "Epoch 667/1000: L(Train): 0.3085024058818817; L(Test): 0.3114582300186157\n",
      "Epoch 668/1000: L(Train): 0.3088361918926239; L(Test): 0.311431348323822\n",
      "Epoch 669/1000: L(Train): 0.3124353587627411; L(Test): 0.31140434741973877\n",
      "Epoch 670/1000: L(Train): 0.30899062752723694; L(Test): 0.3113774359226227\n",
      "Epoch 671/1000: L(Train): 0.3127496540546417; L(Test): 0.31135037541389465\n",
      "Epoch 672/1000: L(Train): 0.31129807233810425; L(Test): 0.3113234043121338\n",
      "Epoch 673/1000: L(Train): 0.3085196316242218; L(Test): 0.3112964332103729\n",
      "Epoch 674/1000: L(Train): 0.3069819211959839; L(Test): 0.3112695813179016\n",
      "Epoch 675/1000: L(Train): 0.30848029255867004; L(Test): 0.3112424612045288\n",
      "Epoch 676/1000: L(Train): 0.30845046043395996; L(Test): 0.3112155795097351\n",
      "Epoch 677/1000: L(Train): 0.3117526173591614; L(Test): 0.31118887662887573\n",
      "Epoch 678/1000: L(Train): 0.31103309988975525; L(Test): 0.3111620843410492\n",
      "Epoch 679/1000: L(Train): 0.31090670824050903; L(Test): 0.31113553047180176\n",
      "Epoch 680/1000: L(Train): 0.3132888972759247; L(Test): 0.3111089766025543\n",
      "Epoch 681/1000: L(Train): 0.3094273507595062; L(Test): 0.31108254194259644\n",
      "Epoch 682/1000: L(Train): 0.3115479648113251; L(Test): 0.31105607748031616\n",
      "Epoch 683/1000: L(Train): 0.31261828541755676; L(Test): 0.3110298216342926\n",
      "Epoch 684/1000: L(Train): 0.31478437781333923; L(Test): 0.31100383400917053\n",
      "Epoch 685/1000: L(Train): 0.31126269698143005; L(Test): 0.3109777271747589\n",
      "Epoch 686/1000: L(Train): 0.31224045157432556; L(Test): 0.31095194816589355\n",
      "Epoch 687/1000: L(Train): 0.30983734130859375; L(Test): 0.31092649698257446\n",
      "Epoch 688/1000: L(Train): 0.3098682761192322; L(Test): 0.31090089678764343\n",
      "Epoch 689/1000: L(Train): 0.31183579564094543; L(Test): 0.31087538599967957\n",
      "Epoch 690/1000: L(Train): 0.3133421838283539; L(Test): 0.3108499348163605\n",
      "Epoch 691/1000: L(Train): 0.30755048990249634; L(Test): 0.31082454323768616\n",
      "Epoch 692/1000: L(Train): 0.3110848367214203; L(Test): 0.31079941987991333\n",
      "Epoch 693/1000: L(Train): 0.3077515959739685; L(Test): 0.3107742369174957\n",
      "Epoch 694/1000: L(Train): 0.30796071887016296; L(Test): 0.3107492923736572\n",
      "Epoch 695/1000: L(Train): 0.3107188940048218; L(Test): 0.310724675655365\n",
      "Epoch 696/1000: L(Train): 0.31003865599632263; L(Test): 0.3107001483440399\n",
      "Epoch 697/1000: L(Train): 0.3102738559246063; L(Test): 0.31067559123039246\n",
      "Epoch 698/1000: L(Train): 0.3086599111557007; L(Test): 0.310651034116745\n",
      "Epoch 699/1000: L(Train): 0.30856844782829285; L(Test): 0.31062638759613037\n",
      "Epoch 700/1000: L(Train): 0.3089865446090698; L(Test): 0.3106022775173187\n",
      "Epoch 701/1000: L(Train): 0.3106224238872528; L(Test): 0.31057846546173096\n",
      "Epoch 702/1000: L(Train): 0.310852974653244; L(Test): 0.3105540871620178\n",
      "Epoch 703/1000: L(Train): 0.3080710768699646; L(Test): 0.3105296492576599\n",
      "Epoch 704/1000: L(Train): 0.31124866008758545; L(Test): 0.3105050325393677\n",
      "Epoch 705/1000: L(Train): 0.31148484349250793; L(Test): 0.31048011779785156\n",
      "Epoch 706/1000: L(Train): 0.30989596247673035; L(Test): 0.3104550540447235\n",
      "Epoch 707/1000: L(Train): 0.31084924936294556; L(Test): 0.31043002009391785\n",
      "Epoch 708/1000: L(Train): 0.3077298104763031; L(Test): 0.3104049563407898\n",
      "Epoch 709/1000: L(Train): 0.31079918146133423; L(Test): 0.3103802800178528\n",
      "Epoch 710/1000: L(Train): 0.3101600706577301; L(Test): 0.3103558421134949\n",
      "Epoch 711/1000: L(Train): 0.3118869960308075; L(Test): 0.31033140420913696\n",
      "Epoch 712/1000: L(Train): 0.3121921718120575; L(Test): 0.31030726432800293\n",
      "Epoch 713/1000: L(Train): 0.3101396858692169; L(Test): 0.31028324365615845\n",
      "Epoch 714/1000: L(Train): 0.31116607785224915; L(Test): 0.3102594017982483\n",
      "Epoch 715/1000: L(Train): 0.3080972135066986; L(Test): 0.31023597717285156\n",
      "Epoch 716/1000: L(Train): 0.3101922273635864; L(Test): 0.31021276116371155\n",
      "Epoch 717/1000: L(Train): 0.31026914715766907; L(Test): 0.31018972396850586\n",
      "Epoch 718/1000: L(Train): 0.3124067187309265; L(Test): 0.31016677618026733\n",
      "Epoch 719/1000: L(Train): 0.3108943700790405; L(Test): 0.3101438879966736\n",
      "Epoch 720/1000: L(Train): 0.31108197569847107; L(Test): 0.31012120842933655\n",
      "Epoch 721/1000: L(Train): 0.31456565856933594; L(Test): 0.3100984990596771\n",
      "Epoch 722/1000: L(Train): 0.31245511770248413; L(Test): 0.31007587909698486\n",
      "Epoch 723/1000: L(Train): 0.30991485714912415; L(Test): 0.310053288936615\n",
      "Epoch 724/1000: L(Train): 0.308684378862381; L(Test): 0.31003063917160034\n",
      "Epoch 725/1000: L(Train): 0.31080207228660583; L(Test): 0.31000837683677673\n",
      "Epoch 726/1000: L(Train): 0.3092258870601654; L(Test): 0.3099863529205322\n",
      "Epoch 727/1000: L(Train): 0.30481934547424316; L(Test): 0.30996352434158325\n",
      "Epoch 728/1000: L(Train): 0.3059621751308441; L(Test): 0.30994096398353577\n",
      "Epoch 729/1000: L(Train): 0.3069536089897156; L(Test): 0.30991828441619873\n",
      "Epoch 730/1000: L(Train): 0.30720990896224976; L(Test): 0.30989497900009155\n",
      "Epoch 731/1000: L(Train): 0.3085092008113861; L(Test): 0.3098718523979187\n",
      "Epoch 732/1000: L(Train): 0.30858731269836426; L(Test): 0.3098476827144623\n",
      "Epoch 733/1000: L(Train): 0.30862635374069214; L(Test): 0.3098238408565521\n",
      "Epoch 734/1000: L(Train): 0.3087010383605957; L(Test): 0.3097999691963196\n",
      "Epoch 735/1000: L(Train): 0.3094622790813446; L(Test): 0.3097764253616333\n",
      "Epoch 736/1000: L(Train): 0.3094472289085388; L(Test): 0.30975306034088135\n",
      "Epoch 737/1000: L(Train): 0.3101634979248047; L(Test): 0.3097292482852936\n",
      "Epoch 738/1000: L(Train): 0.31011369824409485; L(Test): 0.30970558524131775\n",
      "Epoch 739/1000: L(Train): 0.3056648075580597; L(Test): 0.30968210101127625\n",
      "Epoch 740/1000: L(Train): 0.310098260641098; L(Test): 0.3096581995487213\n",
      "Epoch 741/1000: L(Train): 0.3154338002204895; L(Test): 0.30963456630706787\n",
      "Epoch 742/1000: L(Train): 0.3099200427532196; L(Test): 0.30961117148399353\n",
      "Epoch 743/1000: L(Train): 0.31095898151397705; L(Test): 0.3095881938934326\n",
      "Epoch 744/1000: L(Train): 0.3145817518234253; L(Test): 0.30956539511680603\n",
      "Epoch 745/1000: L(Train): 0.3105235993862152; L(Test): 0.3095426857471466\n",
      "Epoch 746/1000: L(Train): 0.31317976117134094; L(Test): 0.3095201253890991\n",
      "Epoch 747/1000: L(Train): 0.30782702565193176; L(Test): 0.30949726700782776\n",
      "Epoch 748/1000: L(Train): 0.3073001205921173; L(Test): 0.3094744086265564\n",
      "Epoch 749/1000: L(Train): 0.30774185061454773; L(Test): 0.3094511032104492\n",
      "Epoch 750/1000: L(Train): 0.30684223771095276; L(Test): 0.3094281256198883\n",
      "Epoch 751/1000: L(Train): 0.30646592378616333; L(Test): 0.3094055652618408\n",
      "Epoch 752/1000: L(Train): 0.3118428587913513; L(Test): 0.3093832731246948\n",
      "Epoch 753/1000: L(Train): 0.31089362502098083; L(Test): 0.30936139822006226\n",
      "Epoch 754/1000: L(Train): 0.31081223487854004; L(Test): 0.3093394935131073\n",
      "Epoch 755/1000: L(Train): 0.3100791573524475; L(Test): 0.30931729078292847\n",
      "Epoch 756/1000: L(Train): 0.3083728551864624; L(Test): 0.30929580330848694\n",
      "Epoch 757/1000: L(Train): 0.31072649359703064; L(Test): 0.30927449464797974\n",
      "Epoch 758/1000: L(Train): 0.30775824189186096; L(Test): 0.3092527389526367\n",
      "Epoch 759/1000: L(Train): 0.31132903695106506; L(Test): 0.3092312514781952\n",
      "Epoch 760/1000: L(Train): 0.30736586451530457; L(Test): 0.3092101812362671\n",
      "Epoch 761/1000: L(Train): 0.30695098638534546; L(Test): 0.3091889023780823\n",
      "Epoch 762/1000: L(Train): 0.30677956342697144; L(Test): 0.3091665506362915\n",
      "Epoch 763/1000: L(Train): 0.3108241558074951; L(Test): 0.30914345383644104\n",
      "Epoch 764/1000: L(Train): 0.30571219325065613; L(Test): 0.3091205954551697\n",
      "Epoch 765/1000: L(Train): 0.30625250935554504; L(Test): 0.3090977668762207\n",
      "Epoch 766/1000: L(Train): 0.3083514869213104; L(Test): 0.30907440185546875\n",
      "Epoch 767/1000: L(Train): 0.3069240152835846; L(Test): 0.3090517222881317\n",
      "Epoch 768/1000: L(Train): 0.30882102251052856; L(Test): 0.3090291917324066\n",
      "Epoch 769/1000: L(Train): 0.3085079789161682; L(Test): 0.3090069890022278\n",
      "Epoch 770/1000: L(Train): 0.30742889642715454; L(Test): 0.3089849352836609\n",
      "Epoch 771/1000: L(Train): 0.3106994926929474; L(Test): 0.3089631497859955\n",
      "Epoch 772/1000: L(Train): 0.3071035146713257; L(Test): 0.308940589427948\n",
      "Epoch 773/1000: L(Train): 0.30784872174263; L(Test): 0.3089183568954468\n",
      "Epoch 774/1000: L(Train): 0.3038802444934845; L(Test): 0.30889591574668884\n",
      "Epoch 775/1000: L(Train): 0.3074590265750885; L(Test): 0.3088732659816742\n",
      "Epoch 776/1000: L(Train): 0.30720603466033936; L(Test): 0.3088502883911133\n",
      "Epoch 777/1000: L(Train): 0.30959585309028625; L(Test): 0.3088277578353882\n",
      "Epoch 778/1000: L(Train): 0.3119339048862457; L(Test): 0.30880457162857056\n",
      "Epoch 779/1000: L(Train): 0.30792713165283203; L(Test): 0.30878135561943054\n",
      "Epoch 780/1000: L(Train): 0.3045620322227478; L(Test): 0.30875858664512634\n",
      "Epoch 781/1000: L(Train): 0.3083236515522003; L(Test): 0.30873608589172363\n",
      "Epoch 782/1000: L(Train): 0.3079074025154114; L(Test): 0.30871307849884033\n",
      "Epoch 783/1000: L(Train): 0.3090360462665558; L(Test): 0.3086903989315033\n",
      "Epoch 784/1000: L(Train): 0.30773428082466125; L(Test): 0.3086674213409424\n",
      "Epoch 785/1000: L(Train): 0.3107563555240631; L(Test): 0.308644562959671\n",
      "Epoch 786/1000: L(Train): 0.31040748953819275; L(Test): 0.3086220324039459\n",
      "Epoch 787/1000: L(Train): 0.3074004352092743; L(Test): 0.30859971046447754\n",
      "Epoch 788/1000: L(Train): 0.3098877966403961; L(Test): 0.3085775077342987\n",
      "Epoch 789/1000: L(Train): 0.3064647614955902; L(Test): 0.30855512619018555\n",
      "Epoch 790/1000: L(Train): 0.307224839925766; L(Test): 0.30853271484375\n",
      "Epoch 791/1000: L(Train): 0.3083333969116211; L(Test): 0.30851104855537415\n",
      "Epoch 792/1000: L(Train): 0.3076701760292053; L(Test): 0.3084891438484192\n",
      "Epoch 793/1000: L(Train): 0.3088552951812744; L(Test): 0.30846765637397766\n",
      "Epoch 794/1000: L(Train): 0.3065842092037201; L(Test): 0.3084465563297272\n",
      "Epoch 795/1000: L(Train): 0.3038034737110138; L(Test): 0.30842575430870056\n",
      "Epoch 796/1000: L(Train): 0.30876630544662476; L(Test): 0.3084050714969635\n",
      "Epoch 797/1000: L(Train): 0.31031107902526855; L(Test): 0.30838483572006226\n",
      "Epoch 798/1000: L(Train): 0.309321790933609; L(Test): 0.30836495757102966\n",
      "Epoch 799/1000: L(Train): 0.3088386058807373; L(Test): 0.308345228433609\n",
      "Epoch 800/1000: L(Train): 0.3065539300441742; L(Test): 0.3083251118659973\n",
      "Epoch 801/1000: L(Train): 0.3111605644226074; L(Test): 0.308305561542511\n",
      "Epoch 802/1000: L(Train): 0.3080374300479889; L(Test): 0.30828604102134705\n",
      "Epoch 803/1000: L(Train): 0.3075079321861267; L(Test): 0.30826640129089355\n",
      "Epoch 804/1000: L(Train): 0.3052317798137665; L(Test): 0.3082462549209595\n",
      "Epoch 805/1000: L(Train): 0.30592450499534607; L(Test): 0.30822625756263733\n",
      "Epoch 806/1000: L(Train): 0.3085261583328247; L(Test): 0.30820584297180176\n",
      "Epoch 807/1000: L(Train): 0.30730193853378296; L(Test): 0.30818548798561096\n",
      "Epoch 808/1000: L(Train): 0.3059394955635071; L(Test): 0.30816537141799927\n",
      "Epoch 809/1000: L(Train): 0.30729806423187256; L(Test): 0.30814501643180847\n",
      "Epoch 810/1000: L(Train): 0.30846989154815674; L(Test): 0.30812469124794006\n",
      "Epoch 811/1000: L(Train): 0.3047903776168823; L(Test): 0.3081044852733612\n",
      "Epoch 812/1000: L(Train): 0.3062150478363037; L(Test): 0.3080843389034271\n",
      "Epoch 813/1000: L(Train): 0.3099159300327301; L(Test): 0.3080648183822632\n",
      "Epoch 814/1000: L(Train): 0.30917951464653015; L(Test): 0.30804529786109924\n",
      "Epoch 815/1000: L(Train): 0.30631834268569946; L(Test): 0.308025598526001\n",
      "Epoch 816/1000: L(Train): 0.30573973059654236; L(Test): 0.30800575017929077\n",
      "Epoch 817/1000: L(Train): 0.3095019459724426; L(Test): 0.30798566341400146\n",
      "Epoch 818/1000: L(Train): 0.3107210099697113; L(Test): 0.30796536803245544\n",
      "Epoch 819/1000: L(Train): 0.307643860578537; L(Test): 0.30794522166252136\n",
      "Epoch 820/1000: L(Train): 0.30891942977905273; L(Test): 0.3079259991645813\n",
      "Epoch 821/1000: L(Train): 0.3100605010986328; L(Test): 0.30790650844573975\n",
      "Epoch 822/1000: L(Train): 0.3093637526035309; L(Test): 0.3078865110874176\n",
      "Epoch 823/1000: L(Train): 0.304557204246521; L(Test): 0.3078671991825104\n",
      "Epoch 824/1000: L(Train): 0.30846551060676575; L(Test): 0.3078485131263733\n",
      "Epoch 825/1000: L(Train): 0.3132888972759247; L(Test): 0.30782896280288696\n",
      "Epoch 826/1000: L(Train): 0.3086622953414917; L(Test): 0.3078102469444275\n",
      "Epoch 827/1000: L(Train): 0.3065257668495178; L(Test): 0.30779165029525757\n",
      "Epoch 828/1000: L(Train): 0.30509448051452637; L(Test): 0.3077729046344757\n",
      "Epoch 829/1000: L(Train): 0.3079143464565277; L(Test): 0.3077544569969177\n",
      "Epoch 830/1000: L(Train): 0.30890148878097534; L(Test): 0.3077355623245239\n",
      "Epoch 831/1000: L(Train): 0.3092910945415497; L(Test): 0.30771616101264954\n",
      "Epoch 832/1000: L(Train): 0.3057653605937958; L(Test): 0.3076969087123871\n",
      "Epoch 833/1000: L(Train): 0.3051735460758209; L(Test): 0.30767762660980225\n",
      "Epoch 834/1000: L(Train): 0.3049086928367615; L(Test): 0.30765843391418457\n",
      "Epoch 835/1000: L(Train): 0.30640530586242676; L(Test): 0.30763953924179077\n",
      "Epoch 836/1000: L(Train): 0.30659085512161255; L(Test): 0.30762040615081787\n",
      "Epoch 837/1000: L(Train): 0.3042573034763336; L(Test): 0.30760157108306885\n",
      "Epoch 838/1000: L(Train): 0.3105125427246094; L(Test): 0.3075830042362213\n",
      "Epoch 839/1000: L(Train): 0.30719032883644104; L(Test): 0.30756470561027527\n",
      "Epoch 840/1000: L(Train): 0.30605047941207886; L(Test): 0.3075462281703949\n",
      "Epoch 841/1000: L(Train): 0.30908581614494324; L(Test): 0.30752813816070557\n",
      "Epoch 842/1000: L(Train): 0.30799826979637146; L(Test): 0.30750924348831177\n",
      "Epoch 843/1000: L(Train): 0.30613476037979126; L(Test): 0.3074895739555359\n",
      "Epoch 844/1000: L(Train): 0.3049829304218292; L(Test): 0.30746990442276\n",
      "Epoch 845/1000: L(Train): 0.3078286647796631; L(Test): 0.30745038390159607\n",
      "Epoch 846/1000: L(Train): 0.3085496127605438; L(Test): 0.3074306845664978\n",
      "Epoch 847/1000: L(Train): 0.30533623695373535; L(Test): 0.3074111342430115\n",
      "Epoch 848/1000: L(Train): 0.307647168636322; L(Test): 0.30739179253578186\n",
      "Epoch 849/1000: L(Train): 0.3077166974544525; L(Test): 0.3073729872703552\n",
      "Epoch 850/1000: L(Train): 0.3066045939922333; L(Test): 0.3073546588420868\n",
      "Epoch 851/1000: L(Train): 0.3123478293418884; L(Test): 0.3073371350765228\n",
      "Epoch 852/1000: L(Train): 0.3059353232383728; L(Test): 0.3073197603225708\n",
      "Epoch 853/1000: L(Train): 0.30795344710350037; L(Test): 0.30730271339416504\n",
      "Epoch 854/1000: L(Train): 0.30838558077812195; L(Test): 0.3072856068611145\n",
      "Epoch 855/1000: L(Train): 0.3065081536769867; L(Test): 0.30726808309555054\n",
      "Epoch 856/1000: L(Train): 0.305115282535553; L(Test): 0.3072507083415985\n",
      "Epoch 857/1000: L(Train): 0.30751165747642517; L(Test): 0.30723294615745544\n",
      "Epoch 858/1000: L(Train): 0.30556392669677734; L(Test): 0.3072158098220825\n",
      "Epoch 859/1000: L(Train): 0.305433064699173; L(Test): 0.307199090719223\n",
      "Epoch 860/1000: L(Train): 0.3059869408607483; L(Test): 0.30718231201171875\n",
      "Epoch 861/1000: L(Train): 0.3077549934387207; L(Test): 0.3071662485599518\n",
      "Epoch 862/1000: L(Train): 0.3077529966831207; L(Test): 0.30715101957321167\n",
      "Epoch 863/1000: L(Train): 0.3067762553691864; L(Test): 0.30713582038879395\n",
      "Epoch 864/1000: L(Train): 0.3087626099586487; L(Test): 0.30711984634399414\n",
      "Epoch 865/1000: L(Train): 0.3071536421775818; L(Test): 0.3071037828922272\n",
      "Epoch 866/1000: L(Train): 0.3039763271808624; L(Test): 0.30708709359169006\n",
      "Epoch 867/1000: L(Train): 0.3044355511665344; L(Test): 0.3070698380470276\n",
      "Epoch 868/1000: L(Train): 0.3077360987663269; L(Test): 0.30705249309539795\n",
      "Epoch 869/1000: L(Train): 0.3066459000110626; L(Test): 0.3070344030857086\n",
      "Epoch 870/1000: L(Train): 0.3086729645729065; L(Test): 0.3070155084133148\n",
      "Epoch 871/1000: L(Train): 0.31075185537338257; L(Test): 0.30699723958969116\n",
      "Epoch 872/1000: L(Train): 0.3082467317581177; L(Test): 0.306979238986969\n",
      "Epoch 873/1000: L(Train): 0.3061540722846985; L(Test): 0.30696040391921997\n",
      "Epoch 874/1000: L(Train): 0.30333876609802246; L(Test): 0.30694085359573364\n",
      "Epoch 875/1000: L(Train): 0.3079278767108917; L(Test): 0.3069213926792145\n",
      "Epoch 876/1000: L(Train): 0.30716148018836975; L(Test): 0.3069015443325043\n",
      "Epoch 877/1000: L(Train): 0.31090521812438965; L(Test): 0.30688217282295227\n",
      "Epoch 878/1000: L(Train): 0.30916860699653625; L(Test): 0.3068622052669525\n",
      "Epoch 879/1000: L(Train): 0.3034987151622772; L(Test): 0.3068419098854065\n",
      "Epoch 880/1000: L(Train): 0.30945995450019836; L(Test): 0.3068215250968933\n",
      "Epoch 881/1000: L(Train): 0.30430102348327637; L(Test): 0.30680179595947266\n",
      "Epoch 882/1000: L(Train): 0.30375608801841736; L(Test): 0.30678239464759827\n",
      "Epoch 883/1000: L(Train): 0.307425320148468; L(Test): 0.3067634701728821\n",
      "Epoch 884/1000: L(Train): 0.3066285252571106; L(Test): 0.3067440986633301\n",
      "Epoch 885/1000: L(Train): 0.30706775188446045; L(Test): 0.30672574043273926\n",
      "Epoch 886/1000: L(Train): 0.30610930919647217; L(Test): 0.30670785903930664\n",
      "Epoch 887/1000: L(Train): 0.30585697293281555; L(Test): 0.30668947100639343\n",
      "Epoch 888/1000: L(Train): 0.30779558420181274; L(Test): 0.3066712021827698\n",
      "Epoch 889/1000: L(Train): 0.3042091131210327; L(Test): 0.30665332078933716\n",
      "Epoch 890/1000: L(Train): 0.305459201335907; L(Test): 0.30663561820983887\n",
      "Epoch 891/1000: L(Train): 0.3061787188053131; L(Test): 0.3066180944442749\n",
      "Epoch 892/1000: L(Train): 0.30404409766197205; L(Test): 0.30660057067871094\n",
      "Epoch 893/1000: L(Train): 0.30838295817375183; L(Test): 0.30658337473869324\n",
      "Epoch 894/1000: L(Train): 0.3054770827293396; L(Test): 0.30656617879867554\n",
      "Epoch 895/1000: L(Train): 0.30605727434158325; L(Test): 0.3065486550331116\n",
      "Epoch 896/1000: L(Train): 0.3066255450248718; L(Test): 0.3065311312675476\n",
      "Epoch 897/1000: L(Train): 0.3070968687534332; L(Test): 0.3065137267112732\n",
      "Epoch 898/1000: L(Train): 0.306764155626297; L(Test): 0.3064967393875122\n",
      "Epoch 899/1000: L(Train): 0.3064413368701935; L(Test): 0.3064797520637512\n",
      "Epoch 900/1000: L(Train): 0.3070218563079834; L(Test): 0.30646276473999023\n",
      "Epoch 901/1000: L(Train): 0.3093883991241455; L(Test): 0.3064456582069397\n",
      "Epoch 902/1000: L(Train): 0.30476024746894836; L(Test): 0.3064285218715668\n",
      "Epoch 903/1000: L(Train): 0.3072975277900696; L(Test): 0.3064116835594177\n",
      "Epoch 904/1000: L(Train): 0.30096185207366943; L(Test): 0.3063947558403015\n",
      "Epoch 905/1000: L(Train): 0.3096659481525421; L(Test): 0.3063780963420868\n",
      "Epoch 906/1000: L(Train): 0.3048688769340515; L(Test): 0.3063613474369049\n",
      "Epoch 907/1000: L(Train): 0.31224364042282104; L(Test): 0.30634424090385437\n",
      "Epoch 908/1000: L(Train): 0.305904358625412; L(Test): 0.3063269555568695\n",
      "Epoch 909/1000: L(Train): 0.3034267723560333; L(Test): 0.30630987882614136\n",
      "Epoch 910/1000: L(Train): 0.3045937716960907; L(Test): 0.3062928318977356\n",
      "Epoch 911/1000: L(Train): 0.308368980884552; L(Test): 0.30627599358558655\n",
      "Epoch 912/1000: L(Train): 0.306418776512146; L(Test): 0.3062592148780823\n",
      "Epoch 913/1000: L(Train): 0.3031427562236786; L(Test): 0.30624231696128845\n",
      "Epoch 914/1000: L(Train): 0.3074414134025574; L(Test): 0.3062257170677185\n",
      "Epoch 915/1000: L(Train): 0.3094845712184906; L(Test): 0.30620935559272766\n",
      "Epoch 916/1000: L(Train): 0.3062182664871216; L(Test): 0.3061930239200592\n",
      "Epoch 917/1000: L(Train): 0.3080419600009918; L(Test): 0.3061768412590027\n",
      "Epoch 918/1000: L(Train): 0.3054471015930176; L(Test): 0.30616065859794617\n",
      "Epoch 919/1000: L(Train): 0.3065211772918701; L(Test): 0.3061445653438568\n",
      "Epoch 920/1000: L(Train): 0.3088846206665039; L(Test): 0.3061285614967346\n",
      "Epoch 921/1000: L(Train): 0.30827391147613525; L(Test): 0.306112676858902\n",
      "Epoch 922/1000: L(Train): 0.30929216742515564; L(Test): 0.3060970902442932\n",
      "Epoch 923/1000: L(Train): 0.30547192692756653; L(Test): 0.3060818314552307\n",
      "Epoch 924/1000: L(Train): 0.3054051399230957; L(Test): 0.30606669187545776\n",
      "Epoch 925/1000: L(Train): 0.308125376701355; L(Test): 0.3060514032840729\n",
      "Epoch 926/1000: L(Train): 0.30727607011795044; L(Test): 0.3060362637042999\n",
      "Epoch 927/1000: L(Train): 0.30767300724983215; L(Test): 0.30602094531059265\n",
      "Epoch 928/1000: L(Train): 0.30872371792793274; L(Test): 0.30600589513778687\n",
      "Epoch 929/1000: L(Train): 0.3047553598880768; L(Test): 0.3059903681278229\n",
      "Epoch 930/1000: L(Train): 0.3040197193622589; L(Test): 0.305974543094635\n",
      "Epoch 931/1000: L(Train): 0.3054715394973755; L(Test): 0.30595844984054565\n",
      "Epoch 932/1000: L(Train): 0.3067094683647156; L(Test): 0.3059425950050354\n",
      "Epoch 933/1000: L(Train): 0.30491289496421814; L(Test): 0.3059269189834595\n",
      "Epoch 934/1000: L(Train): 0.30560827255249023; L(Test): 0.30591145157814026\n",
      "Epoch 935/1000: L(Train): 0.30820268392562866; L(Test): 0.3058960437774658\n",
      "Epoch 936/1000: L(Train): 0.3076121211051941; L(Test): 0.3058808445930481\n",
      "Epoch 937/1000: L(Train): 0.3110645115375519; L(Test): 0.305865079164505\n",
      "Epoch 938/1000: L(Train): 0.3081202805042267; L(Test): 0.3058494031429291\n",
      "Epoch 939/1000: L(Train): 0.30534595251083374; L(Test): 0.3058340847492218\n",
      "Epoch 940/1000: L(Train): 0.3054520785808563; L(Test): 0.3058188557624817\n",
      "Epoch 941/1000: L(Train): 0.3028910458087921; L(Test): 0.3058035969734192\n",
      "Epoch 942/1000: L(Train): 0.30518078804016113; L(Test): 0.30578818917274475\n",
      "Epoch 943/1000: L(Train): 0.30616772174835205; L(Test): 0.305772989988327\n",
      "Epoch 944/1000: L(Train): 0.30603697896003723; L(Test): 0.3057577610015869\n",
      "Epoch 945/1000: L(Train): 0.30818572640419006; L(Test): 0.3057425618171692\n",
      "Epoch 946/1000: L(Train): 0.3058963119983673; L(Test): 0.3057273030281067\n",
      "Epoch 947/1000: L(Train): 0.30565616488456726; L(Test): 0.30571213364601135\n",
      "Epoch 948/1000: L(Train): 0.3055914044380188; L(Test): 0.3056965172290802\n",
      "Epoch 949/1000: L(Train): 0.3025716543197632; L(Test): 0.3056808412075043\n",
      "Epoch 950/1000: L(Train): 0.30943214893341064; L(Test): 0.30566561222076416\n",
      "Epoch 951/1000: L(Train): 0.3063007593154907; L(Test): 0.30565017461776733\n",
      "Epoch 952/1000: L(Train): 0.3023298680782318; L(Test): 0.305635005235672\n",
      "Epoch 953/1000: L(Train): 0.3078436851501465; L(Test): 0.30562064051628113\n",
      "Epoch 954/1000: L(Train): 0.3054073750972748; L(Test): 0.3056063950061798\n",
      "Epoch 955/1000: L(Train): 0.3055521249771118; L(Test): 0.3055915832519531\n",
      "Epoch 956/1000: L(Train): 0.30621838569641113; L(Test): 0.30557721853256226\n",
      "Epoch 957/1000: L(Train): 0.30626237392425537; L(Test): 0.3055630922317505\n",
      "Epoch 958/1000: L(Train): 0.3064534068107605; L(Test): 0.3055485486984253\n",
      "Epoch 959/1000: L(Train): 0.30749228596687317; L(Test): 0.3055337071418762\n",
      "Epoch 960/1000: L(Train): 0.3041852116584778; L(Test): 0.3055187463760376\n",
      "Epoch 961/1000: L(Train): 0.3047948479652405; L(Test): 0.30550405383110046\n",
      "Epoch 962/1000: L(Train): 0.30711016058921814; L(Test): 0.305489182472229\n",
      "Epoch 963/1000: L(Train): 0.30282020568847656; L(Test): 0.30547353625297546\n",
      "Epoch 964/1000: L(Train): 0.3063344657421112; L(Test): 0.3054574728012085\n",
      "Epoch 965/1000: L(Train): 0.3078692853450775; L(Test): 0.3054417073726654\n",
      "Epoch 966/1000: L(Train): 0.30436086654663086; L(Test): 0.30542629957199097\n",
      "Epoch 967/1000: L(Train): 0.30660581588745117; L(Test): 0.30541089177131653\n",
      "Epoch 968/1000: L(Train): 0.30504608154296875; L(Test): 0.30539560317993164\n",
      "Epoch 969/1000: L(Train): 0.3077974319458008; L(Test): 0.3053807020187378\n",
      "Epoch 970/1000: L(Train): 0.30727946758270264; L(Test): 0.3053660988807678\n",
      "Epoch 971/1000: L(Train): 0.30583953857421875; L(Test): 0.3053516149520874\n",
      "Epoch 972/1000: L(Train): 0.305663526058197; L(Test): 0.30533716082572937\n",
      "Epoch 973/1000: L(Train): 0.3060527443885803; L(Test): 0.3053224980831146\n",
      "Epoch 974/1000: L(Train): 0.30695948004722595; L(Test): 0.30530738830566406\n",
      "Epoch 975/1000: L(Train): 0.3002908527851105; L(Test): 0.3052922189235687\n",
      "Epoch 976/1000: L(Train): 0.3017677664756775; L(Test): 0.30527710914611816\n",
      "Epoch 977/1000: L(Train): 0.3049662709236145; L(Test): 0.3052622079849243\n",
      "Epoch 978/1000: L(Train): 0.30453407764434814; L(Test): 0.30524739623069763\n",
      "Epoch 979/1000: L(Train): 0.3049169182777405; L(Test): 0.3052332103252411\n",
      "Epoch 980/1000: L(Train): 0.30886849761009216; L(Test): 0.3052194118499756\n",
      "Epoch 981/1000: L(Train): 0.3064473867416382; L(Test): 0.3052058219909668\n",
      "Epoch 982/1000: L(Train): 0.3053513765335083; L(Test): 0.3051920235157013\n",
      "Epoch 983/1000: L(Train): 0.30773600935935974; L(Test): 0.30517813563346863\n",
      "Epoch 984/1000: L(Train): 0.30409982800483704; L(Test): 0.3051648437976837\n",
      "Epoch 985/1000: L(Train): 0.30604666471481323; L(Test): 0.3051515221595764\n",
      "Epoch 986/1000: L(Train): 0.30286359786987305; L(Test): 0.3051376938819885\n",
      "Epoch 987/1000: L(Train): 0.30447709560394287; L(Test): 0.30512359738349915\n",
      "Epoch 988/1000: L(Train): 0.30727460980415344; L(Test): 0.30510929226875305\n",
      "Epoch 989/1000: L(Train): 0.30784130096435547; L(Test): 0.30509471893310547\n",
      "Epoch 990/1000: L(Train): 0.30321669578552246; L(Test): 0.3050800561904907\n",
      "Epoch 991/1000: L(Train): 0.30594077706336975; L(Test): 0.30506598949432373\n",
      "Epoch 992/1000: L(Train): 0.30605772137641907; L(Test): 0.3050518333911896\n",
      "Epoch 993/1000: L(Train): 0.30128762125968933; L(Test): 0.3050377368927002\n",
      "Epoch 994/1000: L(Train): 0.30515995621681213; L(Test): 0.30502307415008545\n",
      "Epoch 995/1000: L(Train): 0.30588027834892273; L(Test): 0.3050086796283722\n",
      "Epoch 996/1000: L(Train): 0.3065854012966156; L(Test): 0.3049940764904022\n",
      "Epoch 997/1000: L(Train): 0.30313682556152344; L(Test): 0.3049798607826233\n",
      "Epoch 998/1000: L(Train): 0.3059765100479126; L(Test): 0.3049652576446533\n",
      "Epoch 999/1000: L(Train): 0.30770641565322876; L(Test): 0.30495020747184753\n",
      "Epoch 1000/1000: L(Train): 0.30392730236053467; L(Test): 0.30493536591529846\n"
     ]
    }
   ],
   "source": [
    "mvt = training(\n",
    "    gru=mvt,\n",
    "    optimizer=optimizer,\n",
    "    epochs=epochs,\n",
    "    dataset_train=dataset,\n",
    "    dataset_test=dataset,\n",
    "    device=torch.device('cpu'),\n",
    ")\n",
    "\n",
    "torch.save(mvt.state_dict(), path_mvt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvt.load_state_dict(torch.load(path_mvt))\n",
    "mvt_agent = Agent(mvt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted parameters:\n",
      "\n",
      "Alpha\n",
      "tensor([0.3407, 0.1255, 0.3739, 0.2537, 0.0412, 0.2567, 0.2282, 0.0847, 0.0100,\n",
      "        0.5686, 0.6103, 0.2755, 0.0730, 0.1246, 0.1330, 0.9314, 0.3499, 0.2282,\n",
      "        0.3803, 0.1973, 0.0752, 0.5314, 0.9242, 0.1805, 0.2448, 0.1240, 0.0100,\n",
      "        0.2014, 0.6940, 0.8867, 0.0412, 0.3079, 0.1423, 0.0100, 0.2088, 0.1170,\n",
      "        0.0100, 0.0100, 0.1179, 0.2375, 0.2180, 0.9752, 0.3192, 0.0491, 0.1163,\n",
      "        0.1505, 0.1851, 0.0100, 0.2909, 0.0100, 0.2105, 0.1042, 0.4473, 0.3790,\n",
      "        0.0561, 0.3352, 0.3260, 0.2186, 0.6505, 0.0443, 0.6244, 0.2081, 0.3203,\n",
      "        0.4529, 0.5281, 0.8817, 0.1729, 0.3259, 0.0532, 0.2649, 0.1156, 0.0454,\n",
      "        0.1328, 0.0100, 0.2118, 0.0100, 0.3532, 0.1741, 0.1421, 0.0100, 0.1827,\n",
      "        0.1508, 0.0559, 0.5989, 0.2039, 0.4308, 0.1285, 0.2196, 0.5030, 0.2719,\n",
      "        0.1501, 0.3935, 0.1319, 0.1128, 0.3272, 0.0963, 0.4051, 0.0622, 0.3459,\n",
      "        0.1455, 0.0644, 0.1288, 0.3236, 0.0766, 0.1154, 0.1620, 0.2783, 0.3198,\n",
      "        0.6088, 0.1113, 0.0615, 0.2393, 0.0100, 0.1669, 0.0100, 0.0850, 0.0618,\n",
      "        0.2464, 0.2911, 0.6377, 0.0582, 0.1412, 0.0734, 0.1588, 0.0766, 0.0683,\n",
      "        0.1496, 0.1685, 0.0719, 0.9269, 0.0100, 0.6345, 0.1848, 0.1080, 0.0776,\n",
      "        0.1872, 0.3363, 0.0100, 0.3159, 0.0799, 0.1172, 0.4085, 0.1231, 0.2283,\n",
      "        0.0955, 0.2052, 0.1241, 0.9412, 0.0100, 0.2111, 0.2141, 0.3222, 0.0575,\n",
      "        0.0905, 0.0100, 0.2409, 0.5433, 0.9752, 0.7996, 0.2837, 0.0578, 0.0867,\n",
      "        0.1593, 0.5036, 0.0100, 0.1249, 0.0934, 0.0614, 0.1528, 0.2661, 0.2157,\n",
      "        0.0769, 0.0711, 0.9680, 0.1186, 0.2779, 0.0858, 0.1404, 0.8055, 0.5832,\n",
      "        0.4059, 0.0792, 0.2107, 0.7040, 0.1275, 0.1008, 0.0860, 0.2292, 0.0100,\n",
      "        0.0257, 0.1791, 0.0100, 0.2197, 0.9319, 0.1327, 0.1187, 0.3191, 0.2274,\n",
      "        0.0828, 0.0100, 0.3070, 0.0100, 0.0100, 0.4950, 0.2725, 0.0100, 0.1145,\n",
      "        0.3197, 0.1907, 0.1559, 0.2320, 0.0783, 0.4057, 0.0100, 0.0100, 0.0100,\n",
      "        0.1630, 0.3284, 0.0544, 0.0100, 0.1006, 0.0100, 0.1346, 0.1696, 0.0100,\n",
      "        0.0100, 0.0486, 0.2583, 0.2180, 0.3436, 0.1973, 0.1744, 0.5704, 0.0964,\n",
      "        0.2251, 0.0100, 0.1655, 0.2986, 0.0100, 0.1169, 0.0414, 0.0153, 0.0100,\n",
      "        0.1434, 0.1667, 0.3820, 0.2660, 0.1950, 0.2739, 0.0694],\n",
      "       grad_fn=<ClampBackward1>)\n",
      "\n",
      "Beta\n",
      "tensor([4.3790, 5.8484, 6.2185, 5.8385, 5.6735, 5.5463, 5.5921, 6.2666, 6.1226,\n",
      "        2.8977, 1.7248, 6.1311, 6.0124, 5.4872, 6.0486, 5.5255, 6.0596, 5.6669,\n",
      "        5.4233, 6.2045, 3.2402, 4.0205, 3.7330, 5.2557, 3.6374, 6.2410, 5.1139,\n",
      "        5.2512, 2.5734, 4.9677, 5.5141, 6.0121, 4.8940, 4.2320, 5.7027, 6.1079,\n",
      "        5.4401, 3.9515, 4.3038, 6.0043, 5.2637, 3.5007, 6.2796, 5.6188, 6.2023,\n",
      "        6.0725, 6.3794, 5.8921, 5.9921, 5.6693, 6.2699, 5.4035, 5.1362, 5.0883,\n",
      "        5.6367, 3.5724, 5.9248, 5.4294, 5.2293, 5.2554, 4.7509, 5.6565, 5.1950,\n",
      "        4.6876, 5.9952, 4.2208, 6.1315, 5.7826, 4.8603, 5.3645, 5.3822, 5.6416,\n",
      "        6.2405, 5.8249, 5.4879, 3.8088, 5.5337, 5.9563, 5.6375, 5.5028, 6.2238,\n",
      "        4.2402, 5.7217, 5.9541, 5.8449, 4.6738, 5.8746, 5.9968, 4.3344, 6.0779,\n",
      "        5.6890, 6.1084, 6.1093, 6.0761, 6.0055, 5.1194, 4.2377, 5.5350, 5.1362,\n",
      "        5.8141, 3.2407, 6.0428, 5.6711, 5.8842, 5.8640, 6.2273, 5.3570, 6.0535,\n",
      "        5.5156, 6.1795, 5.9047, 5.8873, 5.8041, 5.8397, 5.6954, 4.7154, 5.6411,\n",
      "        5.6901, 1.4516, 0.9557, 5.7637, 6.0754, 6.2012, 6.1974, 5.4608, 5.9774,\n",
      "        5.5330, 5.3841, 5.9375, 4.9145, 5.1621, 0.6399, 6.1949, 5.5878, 6.0147,\n",
      "        6.2203, 5.0991, 1.1632, 6.0210, 6.1077, 5.9233, 5.8144, 5.2280, 4.4658,\n",
      "        6.2242, 5.6419, 5.8569, 4.5447, 4.4662, 6.2241, 5.6635, 6.2354, 5.6244,\n",
      "        5.4371, 5.3991, 6.1287, 4.7968, 5.8891, 4.7698, 5.9344, 6.1963, 6.0679,\n",
      "        6.2828, 5.0593, 5.5954, 5.7208, 6.0722, 5.5260, 5.8929, 6.0740, 6.0493,\n",
      "        5.7807, 6.0823, 3.0389, 6.2108, 5.6500, 5.6444, 5.3399, 3.8063, 6.3956,\n",
      "        4.8230, 4.6137, 5.6586, 5.5297, 5.4116, 5.8205, 5.2342, 5.6449, 4.2682,\n",
      "        3.2782, 6.3900, 5.5921, 6.3473, 5.2004, 5.5576, 5.7192, 4.1460, 5.9423,\n",
      "        5.9721, 5.3576, 6.1549, 6.2203, 5.6798, 5.1008, 5.3445, 3.2485, 6.2315,\n",
      "        6.0453, 5.9156, 5.8970, 5.7514, 6.1847, 6.5071, 6.4584, 2.3321, 5.5274,\n",
      "        5.4616, 5.9861, 5.8734, 3.1769, 6.1531, 5.2861, 5.9073, 5.8926, 4.4068,\n",
      "        5.3516, 5.2253, 2.2030, 3.3982, 5.4256, 5.9484, 5.5991, 5.7139, 5.5326,\n",
      "        5.9710, 5.4750, 6.1093, 6.0314, 5.8717, 5.7988, 5.4445, 0.9692, 5.6424,\n",
      "        4.6694, 6.3973, 5.7691, 5.9941, 5.9722, 5.8540, 5.6590],\n",
      "       grad_fn=<ClampBackward1>)\n",
      "\n",
      "C\n",
      "tensor([ 1.6569,  2.1044,  1.2929,  1.5931,  2.5033,  1.6363,  1.6919,  2.2096,\n",
      "        -1.3683,  1.7558,  1.9053,  1.5743,  2.3381,  2.3941,  2.0303,  1.0802,\n",
      "         1.3829,  1.7187,  1.4230,  1.7335,  2.3130,  1.3934,  1.2276,  1.9316,\n",
      "         2.1633,  2.0816,  2.5453,  1.8879,  1.6046,  1.1220,  2.4645,  1.4246,\n",
      "         2.1573,  2.9932,  1.7210,  2.0548,  2.3353,  2.6027,  2.2004,  1.7079,\n",
      "         1.7124,  1.2712,  1.4361,  2.4462,  2.1730,  2.0395,  1.7658,  2.5289,\n",
      "         1.4371,  2.8433,  1.7564,  2.2383,  1.3688,  1.6049,  2.4347,  1.4921,\n",
      "         1.4265,  1.8091,  1.1259,  2.4545,  1.2602,  1.7700,  1.5773,  1.3576,\n",
      "         1.1586,  1.0705,  1.8800,  1.4333,  2.4701,  1.6944,  2.2529,  2.3888,\n",
      "         2.0034,  2.7140,  1.8107,  2.3662,  1.4281,  1.8989,  1.9894,  2.4410,\n",
      "         1.8105,  2.1598,  2.3650,  1.0281,  1.8176,  1.3532,  2.1065,  1.6993,\n",
      "         0.9453,  1.6080,  2.0916,  1.3084,  2.0702,  2.1290,  1.4022,  2.3573,\n",
      "         1.4850,  2.3910,  1.5440,  2.0203,  2.5879,  2.0669,  1.5095,  2.3421,\n",
      "         2.2053,  1.9039,  1.7761,  1.3997,  1.0795,  2.1724,  2.4349,  1.6133,\n",
      "         2.4902,  1.9031,  2.4237,  2.3349,  2.3936,  1.8357,  2.1447,  1.8656,\n",
      "         2.3725,  1.9420,  2.3570,  1.9300,  2.3845,  2.3902,  2.0182,  1.9887,\n",
      "         2.3526,  1.1317,  2.8987,  3.2357,  1.7928,  2.2107,  2.2487,  1.7874,\n",
      "         1.5125,  0.0431,  1.4373,  2.2965,  2.1661,  1.2715,  2.1924,  2.0249,\n",
      "         2.2568,  1.7557,  2.1517,  1.3188,  2.6759,  1.6955,  1.7948,  1.3691,\n",
      "         2.3980,  2.2843,  2.6057,  1.6265,  1.2483,  0.8501,  1.2600,  1.5234,\n",
      "         2.4105,  2.2423,  1.9476,  1.2145,  2.3239,  2.0479,  2.2541,  2.3493,\n",
      "         2.0009,  1.5302,  1.7271,  2.2875,  2.3531,  2.1134,  2.1473,  1.5874,\n",
      "         2.2980,  2.0844,  1.0913,  0.9772,  1.4894,  2.4140,  1.8787,  0.7912,\n",
      "         2.3838,  2.1982,  2.5464,  1.7185,  2.5180,  2.3076,  1.8231,  2.6449,\n",
      "         1.6101,  0.7901,  2.0987,  2.1519,  1.7160,  1.8316,  2.2545,  2.4910,\n",
      "         1.4868, -1.5972,  2.6757,  1.5940,  1.6547,  0.3069,  2.0967,  1.3962,\n",
      "         1.8480,  2.0351,  1.7623,  2.3122,  1.1736, -1.6798,  3.0696,  2.4573,\n",
      "         2.0701,  1.3838,  2.4206,  3.0103,  2.2334,  2.6352,  2.1043,  1.8872,\n",
      "        -0.9779,  2.8724,  2.3861,  1.7991,  1.4293,  1.3740,  1.8131,  1.9764,\n",
      "         1.1079,  2.2526,  1.6893,  2.5151,  1.9128,  1.4394,  2.3778,  2.1722,\n",
      "         2.4758,  3.1318,  2.5486,  2.0584,  1.6902,  1.3054,  1.5068,  1.8172,\n",
      "         1.5990,  2.3389], grad_fn=<ClampBackward1>)\n",
      "\n",
      "Baseline Gain\n",
      "tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1329, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1068, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1275, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1718, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1800, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1579, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000,\n",
      "        0.1000, 0.2061, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000],\n",
      "       grad_fn=<ClampBackward1>)\n",
      "\n",
      "Depletion\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 0.2511, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       grad_fn=<ClampBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitted parameters:\")\n",
    "print(\"\\nAlpha\")\n",
    "print(mvt.alpha_env)\n",
    "print(\"\\nBeta\")\n",
    "print(mvt.beta)\n",
    "print(\"\\nC\")\n",
    "print(mvt.c)\n",
    "print(\"\\nBaseline Gain\")\n",
    "print(mvt.baseline_gain)\n",
    "print(\"\\nDepletion\")\n",
    "print(mvt.depletion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../..')\n",
    "from weinhardt2025.benchmarking.benchmarking_gru import GRU, training, setup_agent_gru\n",
    "\n",
    "gru = GRU(n_actions).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "epochs = 1000\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(gru.parameters(), lr=0.01)\n",
    "\n",
    "path_gru = '../../weinhardt2025/params/bustamante2023/gru_bustamante2023.pkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000: L(Train): 0.7161166667938232; L(Test): 0.47229355573654175\n",
      "Epoch 2/1000: L(Train): 0.4765810966491699; L(Test): 0.37618812918663025\n",
      "Epoch 3/1000: L(Train): 0.3779475688934326; L(Test): 0.36393970251083374\n",
      "Epoch 4/1000: L(Train): 0.36273038387298584; L(Test): 0.38288426399230957\n",
      "Epoch 5/1000: L(Train): 0.38493612408638; L(Test): 0.3947180509567261\n",
      "Epoch 6/1000: L(Train): 0.39147648215293884; L(Test): 0.3930591940879822\n",
      "Epoch 7/1000: L(Train): 0.39858609437942505; L(Test): 0.38186413049697876\n",
      "Epoch 8/1000: L(Train): 0.38475459814071655; L(Test): 0.36771348118782043\n",
      "Epoch 9/1000: L(Train): 0.3699730634689331; L(Test): 0.35727158188819885\n",
      "Epoch 10/1000: L(Train): 0.3610268235206604; L(Test): 0.35526126623153687\n",
      "Epoch 11/1000: L(Train): 0.35285648703575134; L(Test): 0.360530823469162\n",
      "Epoch 12/1000: L(Train): 0.3646722137928009; L(Test): 0.3655615746974945\n",
      "Epoch 13/1000: L(Train): 0.36735743284225464; L(Test): 0.3644333481788635\n",
      "Epoch 14/1000: L(Train): 0.3677738308906555; L(Test): 0.3588416278362274\n",
      "Epoch 15/1000: L(Train): 0.36275148391723633; L(Test): 0.35331085324287415\n",
      "Epoch 16/1000: L(Train): 0.35603058338165283; L(Test): 0.3507177233695984\n",
      "Epoch 17/1000: L(Train): 0.35231924057006836; L(Test): 0.35117024183273315\n",
      "Epoch 18/1000: L(Train): 0.35570451617240906; L(Test): 0.35294023156166077\n",
      "Epoch 19/1000: L(Train): 0.3561630845069885; L(Test): 0.35413244366645813\n",
      "Epoch 20/1000: L(Train): 0.3553842008113861; L(Test): 0.3537321090698242\n",
      "Epoch 21/1000: L(Train): 0.3612397611141205; L(Test): 0.3515201508998871\n",
      "Epoch 22/1000: L(Train): 0.3544256091117859; L(Test): 0.34836187958717346\n",
      "Epoch 23/1000: L(Train): 0.35239142179489136; L(Test): 0.3453559875488281\n",
      "Epoch 24/1000: L(Train): 0.3466046154499054; L(Test): 0.34347113966941833\n",
      "Epoch 25/1000: L(Train): 0.34534940123558044; L(Test): 0.34287360310554504\n",
      "Epoch 26/1000: L(Train): 0.3437497019767761; L(Test): 0.34283456206321716\n",
      "Epoch 27/1000: L(Train): 0.3492409288883209; L(Test): 0.34233030676841736\n",
      "Epoch 28/1000: L(Train): 0.34654152393341064; L(Test): 0.3406074643135071\n",
      "Epoch 29/1000: L(Train): 0.34327900409698486; L(Test): 0.33801206946372986\n",
      "Epoch 30/1000: L(Train): 0.3379058837890625; L(Test): 0.3356594443321228\n",
      "Epoch 31/1000: L(Train): 0.3361555337905884; L(Test): 0.33428364992141724\n",
      "Epoch 32/1000: L(Train): 0.3400034010410309; L(Test): 0.3333033621311188\n",
      "Epoch 33/1000: L(Train): 0.3341403901576996; L(Test): 0.33178579807281494\n",
      "Epoch 34/1000: L(Train): 0.33888009190559387; L(Test): 0.3291873633861542\n",
      "Epoch 35/1000: L(Train): 0.33353614807128906; L(Test): 0.3264753818511963\n",
      "Epoch 36/1000: L(Train): 0.32700663805007935; L(Test): 0.3247435986995697\n",
      "Epoch 37/1000: L(Train): 0.32863128185272217; L(Test): 0.32346588373184204\n",
      "Epoch 38/1000: L(Train): 0.32368195056915283; L(Test): 0.32148200273513794\n",
      "Epoch 39/1000: L(Train): 0.322065532207489; L(Test): 0.31914210319519043\n",
      "Epoch 40/1000: L(Train): 0.3238773047924042; L(Test): 0.31736913323402405\n",
      "Epoch 41/1000: L(Train): 0.3212448060512543; L(Test): 0.3159669041633606\n",
      "Epoch 42/1000: L(Train): 0.31923094391822815; L(Test): 0.3137347996234894\n",
      "Epoch 43/1000: L(Train): 0.3165140450000763; L(Test): 0.31087037920951843\n",
      "Epoch 44/1000: L(Train): 0.3146904408931732; L(Test): 0.3080039620399475\n",
      "Epoch 45/1000: L(Train): 0.3128856122493744; L(Test): 0.30481061339378357\n",
      "Epoch 46/1000: L(Train): 0.3100869655609131; L(Test): 0.30034637451171875\n",
      "Epoch 47/1000: L(Train): 0.3104807436466217; L(Test): 0.2953309118747711\n",
      "Epoch 48/1000: L(Train): 0.3003022372722626; L(Test): 0.28991997241973877\n",
      "Epoch 49/1000: L(Train): 0.29409727454185486; L(Test): 0.28353822231292725\n",
      "Epoch 50/1000: L(Train): 0.2929166257381439; L(Test): 0.27672794461250305\n",
      "Epoch 51/1000: L(Train): 0.2828306257724762; L(Test): 0.2710990905761719\n",
      "Epoch 52/1000: L(Train): 0.2781752645969391; L(Test): 0.26682958006858826\n",
      "Epoch 53/1000: L(Train): 0.27168262004852295; L(Test): 0.2633441090583801\n",
      "Epoch 54/1000: L(Train): 0.27107664942741394; L(Test): 0.26012396812438965\n",
      "Epoch 55/1000: L(Train): 0.26604434847831726; L(Test): 0.2566811144351959\n",
      "Epoch 56/1000: L(Train): 0.25953635573387146; L(Test): 0.2533399760723114\n",
      "Epoch 57/1000: L(Train): 0.2576581835746765; L(Test): 0.25073808431625366\n",
      "Epoch 58/1000: L(Train): 0.2585475444793701; L(Test): 0.2487574815750122\n",
      "Epoch 59/1000: L(Train): 0.2536117136478424; L(Test): 0.24640683829784393\n",
      "Epoch 60/1000: L(Train): 0.2521112263202667; L(Test): 0.24418801069259644\n",
      "Epoch 61/1000: L(Train): 0.25034099817276; L(Test): 0.2414306402206421\n",
      "Epoch 62/1000: L(Train): 0.24466274678707123; L(Test): 0.23916245996952057\n",
      "Epoch 63/1000: L(Train): 0.2473091036081314; L(Test): 0.23752610385417938\n",
      "Epoch 64/1000: L(Train): 0.23953433334827423; L(Test): 0.23522508144378662\n",
      "Epoch 65/1000: L(Train): 0.23718196153640747; L(Test): 0.2336527705192566\n",
      "Epoch 66/1000: L(Train): 0.23688678443431854; L(Test): 0.23072931170463562\n",
      "Epoch 67/1000: L(Train): 0.2368277609348297; L(Test): 0.2291354238986969\n",
      "Epoch 68/1000: L(Train): 0.23553158342838287; L(Test): 0.22830450534820557\n",
      "Epoch 69/1000: L(Train): 0.2342236191034317; L(Test): 0.2258516252040863\n",
      "Epoch 70/1000: L(Train): 0.22976315021514893; L(Test): 0.22427496314048767\n",
      "Epoch 71/1000: L(Train): 0.23049597442150116; L(Test): 0.22315147519111633\n",
      "Epoch 72/1000: L(Train): 0.23346887528896332; L(Test): 0.22216364741325378\n",
      "Epoch 73/1000: L(Train): 0.22921229898929596; L(Test): 0.221328005194664\n",
      "Epoch 74/1000: L(Train): 0.2275746464729309; L(Test): 0.22327640652656555\n",
      "Epoch 75/1000: L(Train): 0.22804836928844452; L(Test): 0.21920424699783325\n",
      "Epoch 76/1000: L(Train): 0.2252415269613266; L(Test): 0.21852965652942657\n",
      "Epoch 77/1000: L(Train): 0.22701530158519745; L(Test): 0.22086358070373535\n",
      "Epoch 78/1000: L(Train): 0.22736255824565887; L(Test): 0.21694596111774445\n",
      "Epoch 79/1000: L(Train): 0.2276371866464615; L(Test): 0.2161928415298462\n",
      "Epoch 80/1000: L(Train): 0.22059807181358337; L(Test): 0.21743999421596527\n",
      "Epoch 81/1000: L(Train): 0.22350826859474182; L(Test): 0.2150404006242752\n",
      "Epoch 82/1000: L(Train): 0.2205199897289276; L(Test): 0.2144104689359665\n",
      "Epoch 83/1000: L(Train): 0.22123409807682037; L(Test): 0.21451336145401\n",
      "Epoch 84/1000: L(Train): 0.22024531662464142; L(Test): 0.2139362245798111\n",
      "Epoch 85/1000: L(Train): 0.2205401062965393; L(Test): 0.21315838396549225\n",
      "Epoch 86/1000: L(Train): 0.21952250599861145; L(Test): 0.21328623592853546\n",
      "Epoch 87/1000: L(Train): 0.21718193590641022; L(Test): 0.21309992671012878\n",
      "Epoch 88/1000: L(Train): 0.2172623723745346; L(Test): 0.2121763974428177\n",
      "Epoch 89/1000: L(Train): 0.2183980494737625; L(Test): 0.21190690994262695\n",
      "Epoch 90/1000: L(Train): 0.21560288965702057; L(Test): 0.21163935959339142\n",
      "Epoch 91/1000: L(Train): 0.21702145040035248; L(Test): 0.21116633713245392\n",
      "Epoch 92/1000: L(Train): 0.2202133685350418; L(Test): 0.21104460954666138\n",
      "Epoch 93/1000: L(Train): 0.21582545340061188; L(Test): 0.2105681300163269\n",
      "Epoch 94/1000: L(Train): 0.21858759224414825; L(Test): 0.21024920046329498\n",
      "Epoch 95/1000: L(Train): 0.21420760452747345; L(Test): 0.21012423932552338\n",
      "Epoch 96/1000: L(Train): 0.21879220008850098; L(Test): 0.20983248949050903\n",
      "Epoch 97/1000: L(Train): 0.21419578790664673; L(Test): 0.20982472598552704\n",
      "Epoch 98/1000: L(Train): 0.21098192036151886; L(Test): 0.20916132628917694\n",
      "Epoch 99/1000: L(Train): 0.21475866436958313; L(Test): 0.20887179672718048\n",
      "Epoch 100/1000: L(Train): 0.21597795188426971; L(Test): 0.21082773804664612\n",
      "Epoch 101/1000: L(Train): 0.21676278114318848; L(Test): 0.2085537165403366\n",
      "Epoch 102/1000: L(Train): 0.21542423963546753; L(Test): 0.20833630859851837\n",
      "Epoch 103/1000: L(Train): 0.2095167338848114; L(Test): 0.2094414234161377\n",
      "Epoch 104/1000: L(Train): 0.21430043876171112; L(Test): 0.2077845185995102\n",
      "Epoch 105/1000: L(Train): 0.2132960557937622; L(Test): 0.20754094421863556\n",
      "Epoch 106/1000: L(Train): 0.21234247088432312; L(Test): 0.20827022194862366\n",
      "Epoch 107/1000: L(Train): 0.2127871960401535; L(Test): 0.20711813867092133\n",
      "Epoch 108/1000: L(Train): 0.21333640813827515; L(Test): 0.2069200724363327\n",
      "Epoch 109/1000: L(Train): 0.21228082478046417; L(Test): 0.2070828676223755\n",
      "Epoch 110/1000: L(Train): 0.21009691059589386; L(Test): 0.20674307644367218\n",
      "Epoch 111/1000: L(Train): 0.21137529611587524; L(Test): 0.20640024542808533\n",
      "Epoch 112/1000: L(Train): 0.20965127646923065; L(Test): 0.2066011279821396\n",
      "Epoch 113/1000: L(Train): 0.21163617074489594; L(Test): 0.20629294216632843\n",
      "Epoch 114/1000: L(Train): 0.21037748456001282; L(Test): 0.20571061968803406\n",
      "Epoch 115/1000: L(Train): 0.2125299721956253; L(Test): 0.20556314289569855\n",
      "Epoch 116/1000: L(Train): 0.210485577583313; L(Test): 0.20596827566623688\n",
      "Epoch 117/1000: L(Train): 0.21161533892154694; L(Test): 0.20519475638866425\n",
      "Epoch 118/1000: L(Train): 0.20838765799999237; L(Test): 0.20493857562541962\n",
      "Epoch 119/1000: L(Train): 0.21245089173316956; L(Test): 0.2051309198141098\n",
      "Epoch 120/1000: L(Train): 0.21087563037872314; L(Test): 0.2047191858291626\n",
      "Epoch 121/1000: L(Train): 0.21137158572673798; L(Test): 0.20443010330200195\n",
      "Epoch 122/1000: L(Train): 0.2074413150548935; L(Test): 0.20457535982131958\n",
      "Epoch 123/1000: L(Train): 0.2087840884923935; L(Test): 0.2041706144809723\n",
      "Epoch 124/1000: L(Train): 0.20918144285678864; L(Test): 0.20402637124061584\n",
      "Epoch 125/1000: L(Train): 0.20909541845321655; L(Test): 0.20392313599586487\n",
      "Epoch 126/1000: L(Train): 0.2085750699043274; L(Test): 0.20366738736629486\n",
      "Epoch 127/1000: L(Train): 0.20894746482372284; L(Test): 0.20372222363948822\n",
      "Epoch 128/1000: L(Train): 0.20603102445602417; L(Test): 0.20356686413288116\n",
      "Epoch 129/1000: L(Train): 0.20733818411827087; L(Test): 0.20325833559036255\n",
      "Epoch 130/1000: L(Train): 0.20727966725826263; L(Test): 0.20319947600364685\n",
      "Epoch 131/1000: L(Train): 0.21173255145549774; L(Test): 0.2028668075799942\n",
      "Epoch 132/1000: L(Train): 0.20784412324428558; L(Test): 0.20325569808483124\n",
      "Epoch 133/1000: L(Train): 0.20811887085437775; L(Test): 0.20276972651481628\n",
      "Epoch 134/1000: L(Train): 0.21025988459587097; L(Test): 0.2024659663438797\n",
      "Epoch 135/1000: L(Train): 0.20866671204566956; L(Test): 0.20297670364379883\n",
      "Epoch 136/1000: L(Train): 0.20516376197338104; L(Test): 0.20216025412082672\n",
      "Epoch 137/1000: L(Train): 0.20644550025463104; L(Test): 0.20210354030132294\n",
      "Epoch 138/1000: L(Train): 0.20538146793842316; L(Test): 0.2022308111190796\n",
      "Epoch 139/1000: L(Train): 0.20385493338108063; L(Test): 0.20180930197238922\n",
      "Epoch 140/1000: L(Train): 0.20524607598781586; L(Test): 0.20203736424446106\n",
      "Epoch 141/1000: L(Train): 0.20420017838478088; L(Test): 0.20158186554908752\n",
      "Epoch 142/1000: L(Train): 0.20661917328834534; L(Test): 0.20137746632099152\n",
      "Epoch 143/1000: L(Train): 0.2052099108695984; L(Test): 0.2014581710100174\n",
      "Epoch 144/1000: L(Train): 0.20527370274066925; L(Test): 0.20111225545406342\n",
      "Epoch 145/1000: L(Train): 0.20811006426811218; L(Test): 0.20098519325256348\n",
      "Epoch 146/1000: L(Train): 0.20379920303821564; L(Test): 0.20121818780899048\n",
      "Epoch 147/1000: L(Train): 0.20576123893260956; L(Test): 0.20063833892345428\n",
      "Epoch 148/1000: L(Train): 0.20149284601211548; L(Test): 0.2009001076221466\n",
      "Epoch 149/1000: L(Train): 0.20465365052223206; L(Test): 0.2006053328514099\n",
      "Epoch 150/1000: L(Train): 0.20723508298397064; L(Test): 0.20045924186706543\n",
      "Epoch 151/1000: L(Train): 0.20338177680969238; L(Test): 0.20181967318058014\n",
      "Epoch 152/1000: L(Train): 0.20633774995803833; L(Test): 0.19991257786750793\n",
      "Epoch 153/1000: L(Train): 0.20490442216396332; L(Test): 0.19983729720115662\n",
      "Epoch 154/1000: L(Train): 0.20088040828704834; L(Test): 0.20125533640384674\n",
      "Epoch 155/1000: L(Train): 0.20662912726402283; L(Test): 0.19976799190044403\n",
      "Epoch 156/1000: L(Train): 0.2076425552368164; L(Test): 0.1994549185037613\n",
      "Epoch 157/1000: L(Train): 0.20237930119037628; L(Test): 0.20021115243434906\n",
      "Epoch 158/1000: L(Train): 0.205064594745636; L(Test): 0.199203222990036\n",
      "Epoch 159/1000: L(Train): 0.20255382359027863; L(Test): 0.1990804672241211\n",
      "Epoch 160/1000: L(Train): 0.20508351922035217; L(Test): 0.1992989033460617\n",
      "Epoch 161/1000: L(Train): 0.20339316129684448; L(Test): 0.1989147663116455\n",
      "Epoch 162/1000: L(Train): 0.20290446281433105; L(Test): 0.1990499347448349\n",
      "Epoch 163/1000: L(Train): 0.2030595988035202; L(Test): 0.1987878531217575\n",
      "Epoch 164/1000: L(Train): 0.20471397042274475; L(Test): 0.19867102801799774\n",
      "Epoch 165/1000: L(Train): 0.20103499293327332; L(Test): 0.19866825640201569\n",
      "Epoch 166/1000: L(Train): 0.20117288827896118; L(Test): 0.19903014600276947\n",
      "Epoch 167/1000: L(Train): 0.2069581300020218; L(Test): 0.19904294610023499\n",
      "Epoch 168/1000: L(Train): 0.20463740825653076; L(Test): 0.1987055242061615\n",
      "Epoch 169/1000: L(Train): 0.20291800796985626; L(Test): 0.19866809248924255\n",
      "Epoch 170/1000: L(Train): 0.2050495743751526; L(Test): 0.19816188514232635\n",
      "Epoch 171/1000: L(Train): 0.20400147140026093; L(Test): 0.19829729199409485\n",
      "Epoch 172/1000: L(Train): 0.20617005228996277; L(Test): 0.1982288807630539\n",
      "Epoch 173/1000: L(Train): 0.20610728859901428; L(Test): 0.1979994922876358\n",
      "Epoch 174/1000: L(Train): 0.2016955316066742; L(Test): 0.1984073519706726\n",
      "Epoch 175/1000: L(Train): 0.2014637291431427; L(Test): 0.19787253439426422\n",
      "Epoch 176/1000: L(Train): 0.2026003897190094; L(Test): 0.19781555235385895\n",
      "Epoch 177/1000: L(Train): 0.2011314183473587; L(Test): 0.19837647676467896\n",
      "Epoch 178/1000: L(Train): 0.20177392661571503; L(Test): 0.19765928387641907\n",
      "Epoch 179/1000: L(Train): 0.2019520401954651; L(Test): 0.19762296974658966\n",
      "Epoch 180/1000: L(Train): 0.20315031707286835; L(Test): 0.19913232326507568\n",
      "Epoch 181/1000: L(Train): 0.20201443135738373; L(Test): 0.19756178557872772\n",
      "Epoch 182/1000: L(Train): 0.20436793565750122; L(Test): 0.19751660525798798\n",
      "Epoch 183/1000: L(Train): 0.20197424292564392; L(Test): 0.19861073791980743\n",
      "Epoch 184/1000: L(Train): 0.20329977571964264; L(Test): 0.197261780500412\n",
      "Epoch 185/1000: L(Train): 0.20070740580558777; L(Test): 0.19733992218971252\n",
      "Epoch 186/1000: L(Train): 0.20117448270320892; L(Test): 0.19821543991565704\n",
      "Epoch 187/1000: L(Train): 0.20356440544128418; L(Test): 0.1970950812101364\n",
      "Epoch 188/1000: L(Train): 0.20322956144809723; L(Test): 0.19713222980499268\n",
      "Epoch 189/1000: L(Train): 0.2016768753528595; L(Test): 0.19783708453178406\n",
      "Epoch 190/1000: L(Train): 0.1997685432434082; L(Test): 0.19708552956581116\n",
      "Epoch 191/1000: L(Train): 0.20287084579467773; L(Test): 0.19697219133377075\n",
      "Epoch 192/1000: L(Train): 0.2009143978357315; L(Test): 0.19726522266864777\n",
      "Epoch 193/1000: L(Train): 0.20076608657836914; L(Test): 0.1967894434928894\n",
      "Epoch 194/1000: L(Train): 0.201852947473526; L(Test): 0.19712965190410614\n",
      "Epoch 195/1000: L(Train): 0.20219053328037262; L(Test): 0.19665589928627014\n",
      "Epoch 196/1000: L(Train): 0.19893115758895874; L(Test): 0.1967073678970337\n",
      "Epoch 197/1000: L(Train): 0.19890475273132324; L(Test): 0.1972155123949051\n",
      "Epoch 198/1000: L(Train): 0.2022605538368225; L(Test): 0.1966831535100937\n",
      "Epoch 199/1000: L(Train): 0.20200033485889435; L(Test): 0.1967620551586151\n",
      "Epoch 200/1000: L(Train): 0.19662807881832123; L(Test): 0.1971474140882492\n",
      "Epoch 201/1000: L(Train): 0.1996629387140274; L(Test): 0.1965504139661789\n",
      "Epoch 202/1000: L(Train): 0.20043601095676422; L(Test): 0.19711710512638092\n",
      "Epoch 203/1000: L(Train): 0.19724468886852264; L(Test): 0.19663210213184357\n",
      "Epoch 204/1000: L(Train): 0.20318184792995453; L(Test): 0.19668111205101013\n",
      "Epoch 205/1000: L(Train): 0.1980915665626526; L(Test): 0.19838860630989075\n",
      "Epoch 206/1000: L(Train): 0.20013952255249023; L(Test): 0.19629190862178802\n",
      "Epoch 207/1000: L(Train): 0.20022419095039368; L(Test): 0.1968776285648346\n",
      "Epoch 208/1000: L(Train): 0.20019866526126862; L(Test): 0.19813846051692963\n",
      "Epoch 209/1000: L(Train): 0.20340321958065033; L(Test): 0.19647109508514404\n",
      "Epoch 210/1000: L(Train): 0.20116814970970154; L(Test): 0.19721388816833496\n",
      "Epoch 211/1000: L(Train): 0.20323744416236877; L(Test): 0.19780051708221436\n",
      "Epoch 212/1000: L(Train): 0.2029886245727539; L(Test): 0.19703546166419983\n",
      "Epoch 213/1000: L(Train): 0.19918939471244812; L(Test): 0.19652260839939117\n",
      "Epoch 214/1000: L(Train): 0.20294983685016632; L(Test): 0.19627904891967773\n",
      "Epoch 215/1000: L(Train): 0.20039981603622437; L(Test): 0.19741395115852356\n",
      "Epoch 216/1000: L(Train): 0.2033841907978058; L(Test): 0.19616810977458954\n",
      "Epoch 217/1000: L(Train): 0.2015618085861206; L(Test): 0.19641318917274475\n",
      "Epoch 218/1000: L(Train): 0.19878838956356049; L(Test): 0.1963575780391693\n",
      "Epoch 219/1000: L(Train): 0.19970549643039703; L(Test): 0.1969957798719406\n",
      "Epoch 220/1000: L(Train): 0.20064446330070496; L(Test): 0.19629886746406555\n",
      "Epoch 221/1000: L(Train): 0.20199453830718994; L(Test): 0.1959834098815918\n",
      "Epoch 222/1000: L(Train): 0.1975095421075821; L(Test): 0.19686706364154816\n",
      "Epoch 223/1000: L(Train): 0.20081336796283722; L(Test): 0.1960797756910324\n",
      "Epoch 224/1000: L(Train): 0.2038528174161911; L(Test): 0.1959393471479416\n",
      "Epoch 225/1000: L(Train): 0.20058396458625793; L(Test): 0.19622179865837097\n",
      "Epoch 226/1000: L(Train): 0.19844362139701843; L(Test): 0.1960867941379547\n",
      "Epoch 227/1000: L(Train): 0.2015324831008911; L(Test): 0.19585958123207092\n",
      "Epoch 228/1000: L(Train): 0.20032942295074463; L(Test): 0.19597043097019196\n",
      "Epoch 229/1000: L(Train): 0.1995811015367508; L(Test): 0.19600743055343628\n",
      "Epoch 230/1000: L(Train): 0.1981632262468338; L(Test): 0.19586557149887085\n",
      "Epoch 231/1000: L(Train): 0.19834771752357483; L(Test): 0.1957695186138153\n",
      "Epoch 232/1000: L(Train): 0.20190580189228058; L(Test): 0.19576948881149292\n",
      "Epoch 233/1000: L(Train): 0.19851186871528625; L(Test): 0.19581109285354614\n",
      "Epoch 234/1000: L(Train): 0.20063884556293488; L(Test): 0.1958274245262146\n",
      "Epoch 235/1000: L(Train): 0.19943949580192566; L(Test): 0.1955891102552414\n",
      "Epoch 236/1000: L(Train): 0.20098605751991272; L(Test): 0.19559481739997864\n",
      "Epoch 237/1000: L(Train): 0.1993551254272461; L(Test): 0.1963396966457367\n",
      "Epoch 238/1000: L(Train): 0.20058564841747284; L(Test): 0.1957775056362152\n",
      "Epoch 239/1000: L(Train): 0.19931872189044952; L(Test): 0.1956852674484253\n",
      "Epoch 240/1000: L(Train): 0.19846512377262115; L(Test): 0.19582869112491608\n",
      "Epoch 241/1000: L(Train): 0.2010890543460846; L(Test): 0.19599202275276184\n",
      "Epoch 242/1000: L(Train): 0.19625671207904816; L(Test): 0.19546137750148773\n",
      "Epoch 243/1000: L(Train): 0.19996468722820282; L(Test): 0.19560682773590088\n",
      "Epoch 244/1000: L(Train): 0.20086845755577087; L(Test): 0.1959877759218216\n",
      "Epoch 245/1000: L(Train): 0.20189842581748962; L(Test): 0.1953524500131607\n",
      "Epoch 246/1000: L(Train): 0.1959681659936905; L(Test): 0.1952897012233734\n",
      "Epoch 247/1000: L(Train): 0.1984786093235016; L(Test): 0.1957540363073349\n",
      "Epoch 248/1000: L(Train): 0.20035578310489655; L(Test): 0.19525907933712006\n",
      "Epoch 249/1000: L(Train): 0.1989912986755371; L(Test): 0.19519789516925812\n",
      "Epoch 250/1000: L(Train): 0.19974958896636963; L(Test): 0.19544756412506104\n",
      "Epoch 251/1000: L(Train): 0.19920413196086884; L(Test): 0.19523926079273224\n",
      "Epoch 252/1000: L(Train): 0.19874976575374603; L(Test): 0.1952291876077652\n",
      "Epoch 253/1000: L(Train): 0.2010820209980011; L(Test): 0.1954822987318039\n",
      "Epoch 254/1000: L(Train): 0.2002590298652649; L(Test): 0.19526870548725128\n",
      "Epoch 255/1000: L(Train): 0.19444391131401062; L(Test): 0.1952051818370819\n",
      "Epoch 256/1000: L(Train): 0.20012806355953217; L(Test): 0.19526131451129913\n",
      "Epoch 257/1000: L(Train): 0.19843140244483948; L(Test): 0.19529937207698822\n",
      "Epoch 258/1000: L(Train): 0.19663743674755096; L(Test): 0.19519992172718048\n",
      "Epoch 259/1000: L(Train): 0.19917896389961243; L(Test): 0.19516094028949738\n",
      "Epoch 260/1000: L(Train): 0.1984577775001526; L(Test): 0.19511720538139343\n",
      "Epoch 261/1000: L(Train): 0.19907139241695404; L(Test): 0.19505789875984192\n",
      "Epoch 262/1000: L(Train): 0.20201830565929413; L(Test): 0.19499382376670837\n",
      "Epoch 263/1000: L(Train): 0.19715987145900726; L(Test): 0.1951104700565338\n",
      "Epoch 264/1000: L(Train): 0.2004055231809616; L(Test): 0.19503068923950195\n",
      "Epoch 265/1000: L(Train): 0.19827871024608612; L(Test): 0.19521918892860413\n",
      "Epoch 266/1000: L(Train): 0.2036965936422348; L(Test): 0.19497980177402496\n",
      "Epoch 267/1000: L(Train): 0.19971735775470734; L(Test): 0.1952238231897354\n",
      "Epoch 268/1000: L(Train): 0.19937297701835632; L(Test): 0.19514581561088562\n",
      "Epoch 269/1000: L(Train): 0.19933904707431793; L(Test): 0.19503523409366608\n",
      "Epoch 270/1000: L(Train): 0.1988137662410736; L(Test): 0.195248082280159\n",
      "Epoch 271/1000: L(Train): 0.19769002497196198; L(Test): 0.19506505131721497\n",
      "Epoch 272/1000: L(Train): 0.19805340468883514; L(Test): 0.19485989212989807\n",
      "Epoch 273/1000: L(Train): 0.19626985490322113; L(Test): 0.19526013731956482\n",
      "Epoch 274/1000: L(Train): 0.19677267968654633; L(Test): 0.19492892920970917\n",
      "Epoch 275/1000: L(Train): 0.19938510656356812; L(Test): 0.19478240609169006\n",
      "Epoch 276/1000: L(Train): 0.19601847231388092; L(Test): 0.19563263654708862\n",
      "Epoch 277/1000: L(Train): 0.1975165158510208; L(Test): 0.1947636604309082\n",
      "Epoch 278/1000: L(Train): 0.2023801952600479; L(Test): 0.19477565586566925\n",
      "Epoch 279/1000: L(Train): 0.19930076599121094; L(Test): 0.19520168006420135\n",
      "Epoch 280/1000: L(Train): 0.2004491537809372; L(Test): 0.19479352235794067\n",
      "Epoch 281/1000: L(Train): 0.1961963027715683; L(Test): 0.19487689435482025\n",
      "Epoch 282/1000: L(Train): 0.19913645088672638; L(Test): 0.19483312964439392\n",
      "Epoch 283/1000: L(Train): 0.201180100440979; L(Test): 0.1947711855173111\n",
      "Epoch 284/1000: L(Train): 0.20099642872810364; L(Test): 0.19499291479587555\n",
      "Epoch 285/1000: L(Train): 0.1990414559841156; L(Test): 0.19459106028079987\n",
      "Epoch 286/1000: L(Train): 0.20021553337574005; L(Test): 0.19454869627952576\n",
      "Epoch 287/1000: L(Train): 0.19599121809005737; L(Test): 0.19517800211906433\n",
      "Epoch 288/1000: L(Train): 0.19929005205631256; L(Test): 0.19455909729003906\n",
      "Epoch 289/1000: L(Train): 0.1947903335094452; L(Test): 0.1945103406906128\n",
      "Epoch 290/1000: L(Train): 0.1983177810907364; L(Test): 0.19474631547927856\n",
      "Epoch 291/1000: L(Train): 0.19967487454414368; L(Test): 0.1945994645357132\n",
      "Epoch 292/1000: L(Train): 0.19373705983161926; L(Test): 0.19464407861232758\n",
      "Epoch 293/1000: L(Train): 0.19773317873477936; L(Test): 0.19487181305885315\n",
      "Epoch 294/1000: L(Train): 0.19688034057617188; L(Test): 0.19448605179786682\n",
      "Epoch 295/1000: L(Train): 0.19879217445850372; L(Test): 0.19440816342830658\n",
      "Epoch 296/1000: L(Train): 0.19713479280471802; L(Test): 0.19474394619464874\n",
      "Epoch 297/1000: L(Train): 0.19720657169818878; L(Test): 0.19440574944019318\n",
      "Epoch 298/1000: L(Train): 0.19739845395088196; L(Test): 0.19432756304740906\n",
      "Epoch 299/1000: L(Train): 0.19714109599590302; L(Test): 0.19460415840148926\n",
      "Epoch 300/1000: L(Train): 0.19800551235675812; L(Test): 0.1943133920431137\n",
      "Epoch 301/1000: L(Train): 0.20008298754692078; L(Test): 0.1947373002767563\n",
      "Epoch 302/1000: L(Train): 0.1988147348165512; L(Test): 0.19429689645767212\n",
      "Epoch 303/1000: L(Train): 0.19784826040267944; L(Test): 0.1943126618862152\n",
      "Epoch 304/1000: L(Train): 0.19656437635421753; L(Test): 0.19446426630020142\n",
      "Epoch 305/1000: L(Train): 0.19862550497055054; L(Test): 0.19424040615558624\n",
      "Epoch 306/1000: L(Train): 0.1999668926000595; L(Test): 0.19433388113975525\n",
      "Epoch 307/1000: L(Train): 0.19654588401317596; L(Test): 0.19418558478355408\n",
      "Epoch 308/1000: L(Train): 0.19889169931411743; L(Test): 0.19426329433918\n",
      "Epoch 309/1000: L(Train): 0.19747526943683624; L(Test): 0.19410890340805054\n",
      "Epoch 310/1000: L(Train): 0.19528384506702423; L(Test): 0.19444282352924347\n",
      "Epoch 311/1000: L(Train): 0.1959381103515625; L(Test): 0.19425177574157715\n",
      "Epoch 312/1000: L(Train): 0.19608160853385925; L(Test): 0.19417762756347656\n",
      "Epoch 313/1000: L(Train): 0.1974755823612213; L(Test): 0.19415995478630066\n",
      "Epoch 314/1000: L(Train): 0.1992620825767517; L(Test): 0.19423775374889374\n",
      "Epoch 315/1000: L(Train): 0.19426856935024261; L(Test): 0.19429191946983337\n",
      "Epoch 316/1000: L(Train): 0.19785210490226746; L(Test): 0.1942882388830185\n",
      "Epoch 317/1000: L(Train): 0.19669072329998016; L(Test): 0.19549235701560974\n",
      "Epoch 318/1000: L(Train): 0.19875489175319672; L(Test): 0.1946294754743576\n",
      "Epoch 319/1000: L(Train): 0.19849993288516998; L(Test): 0.19440291821956635\n",
      "Epoch 320/1000: L(Train): 0.19595816731452942; L(Test): 0.19457505643367767\n",
      "Epoch 321/1000: L(Train): 0.19759050011634827; L(Test): 0.19416023790836334\n",
      "Epoch 322/1000: L(Train): 0.19556021690368652; L(Test): 0.1945061832666397\n",
      "Epoch 323/1000: L(Train): 0.19740918278694153; L(Test): 0.19417165219783783\n",
      "Epoch 324/1000: L(Train): 0.19369332492351532; L(Test): 0.19431932270526886\n",
      "Epoch 325/1000: L(Train): 0.1965414136648178; L(Test): 0.1942378580570221\n",
      "Epoch 326/1000: L(Train): 0.19803951680660248; L(Test): 0.19394463300704956\n",
      "Epoch 327/1000: L(Train): 0.1980963498353958; L(Test): 0.1946718692779541\n",
      "Epoch 328/1000: L(Train): 0.19721533358097076; L(Test): 0.19387324154376984\n",
      "Epoch 329/1000: L(Train): 0.19626137614250183; L(Test): 0.194219172000885\n",
      "Epoch 330/1000: L(Train): 0.19834861159324646; L(Test): 0.19469134509563446\n",
      "Epoch 331/1000: L(Train): 0.1990274041891098; L(Test): 0.1940608024597168\n",
      "Epoch 332/1000: L(Train): 0.19830822944641113; L(Test): 0.19395339488983154\n",
      "Epoch 333/1000: L(Train): 0.1953626573085785; L(Test): 0.19429616630077362\n",
      "Epoch 334/1000: L(Train): 0.1971554160118103; L(Test): 0.19399690628051758\n",
      "Epoch 335/1000: L(Train): 0.19688671827316284; L(Test): 0.19410322606563568\n",
      "Epoch 336/1000: L(Train): 0.19698794186115265; L(Test): 0.19384290277957916\n",
      "Epoch 337/1000: L(Train): 0.19644953310489655; L(Test): 0.19373644888401031\n",
      "Epoch 338/1000: L(Train): 0.19538792967796326; L(Test): 0.1943855881690979\n",
      "Epoch 339/1000: L(Train): 0.1942588835954666; L(Test): 0.19380512833595276\n",
      "Epoch 340/1000: L(Train): 0.19597569108009338; L(Test): 0.19385920464992523\n",
      "Epoch 341/1000: L(Train): 0.20028311014175415; L(Test): 0.1946442425251007\n",
      "Epoch 342/1000: L(Train): 0.19645634293556213; L(Test): 0.19373950362205505\n",
      "Epoch 343/1000: L(Train): 0.19580714404582977; L(Test): 0.1941554993391037\n",
      "Epoch 344/1000: L(Train): 0.1999984234571457; L(Test): 0.19450220465660095\n",
      "Epoch 345/1000: L(Train): 0.19414812326431274; L(Test): 0.19391779601573944\n",
      "Epoch 346/1000: L(Train): 0.19737404584884644; L(Test): 0.19453762471675873\n",
      "Epoch 347/1000: L(Train): 0.19792242348194122; L(Test): 0.19622847437858582\n",
      "Epoch 348/1000: L(Train): 0.198982372879982; L(Test): 0.19379326701164246\n",
      "Epoch 349/1000: L(Train): 0.19411402940750122; L(Test): 0.19446183741092682\n",
      "Epoch 350/1000: L(Train): 0.198702871799469; L(Test): 0.19465044140815735\n",
      "Epoch 351/1000: L(Train): 0.1980476975440979; L(Test): 0.19385159015655518\n",
      "Epoch 352/1000: L(Train): 0.20119774341583252; L(Test): 0.19497525691986084\n",
      "Epoch 353/1000: L(Train): 0.19836287200450897; L(Test): 0.1946275532245636\n",
      "Epoch 354/1000: L(Train): 0.1971825212240219; L(Test): 0.19443972408771515\n",
      "Epoch 355/1000: L(Train): 0.19729070365428925; L(Test): 0.19508929550647736\n",
      "Epoch 356/1000: L(Train): 0.2000761777162552; L(Test): 0.1937110871076584\n",
      "Epoch 357/1000: L(Train): 0.19729869067668915; L(Test): 0.19570888578891754\n",
      "Epoch 358/1000: L(Train): 0.20159265398979187; L(Test): 0.19369877874851227\n",
      "Epoch 359/1000: L(Train): 0.19713211059570312; L(Test): 0.19438126683235168\n",
      "Epoch 360/1000: L(Train): 0.19681450724601746; L(Test): 0.1951371133327484\n",
      "Epoch 361/1000: L(Train): 0.19991564750671387; L(Test): 0.19469161331653595\n",
      "Epoch 362/1000: L(Train): 0.19559386372566223; L(Test): 0.19426366686820984\n",
      "Epoch 363/1000: L(Train): 0.19552239775657654; L(Test): 0.19376778602600098\n",
      "Epoch 364/1000: L(Train): 0.19777002930641174; L(Test): 0.19500575959682465\n",
      "Epoch 365/1000: L(Train): 0.19646137952804565; L(Test): 0.19403254985809326\n",
      "Epoch 366/1000: L(Train): 0.1964326947927475; L(Test): 0.1939733475446701\n",
      "Epoch 367/1000: L(Train): 0.1956152319908142; L(Test): 0.1935414969921112\n",
      "Epoch 368/1000: L(Train): 0.19661150872707367; L(Test): 0.1944514960050583\n",
      "Epoch 369/1000: L(Train): 0.19625531136989594; L(Test): 0.19377881288528442\n",
      "Epoch 370/1000: L(Train): 0.1964351385831833; L(Test): 0.19394995272159576\n",
      "Epoch 371/1000: L(Train): 0.19880901277065277; L(Test): 0.19352923333644867\n",
      "Epoch 372/1000: L(Train): 0.19672457873821259; L(Test): 0.1939656138420105\n",
      "Epoch 373/1000: L(Train): 0.20098094642162323; L(Test): 0.19348867237567902\n",
      "Epoch 374/1000: L(Train): 0.1959535926580429; L(Test): 0.19385606050491333\n",
      "Epoch 375/1000: L(Train): 0.19599656760692596; L(Test): 0.19360430538654327\n",
      "Epoch 376/1000: L(Train): 0.19552664458751678; L(Test): 0.1945926547050476\n",
      "Epoch 377/1000: L(Train): 0.1996295005083084; L(Test): 0.19354033470153809\n",
      "Epoch 378/1000: L(Train): 0.19803602993488312; L(Test): 0.1938580870628357\n",
      "Epoch 379/1000: L(Train): 0.19596272706985474; L(Test): 0.1937829852104187\n",
      "Epoch 380/1000: L(Train): 0.19736908376216888; L(Test): 0.1941642463207245\n",
      "Epoch 381/1000: L(Train): 0.19605307281017303; L(Test): 0.193447083234787\n",
      "Epoch 382/1000: L(Train): 0.19862931966781616; L(Test): 0.19338174164295197\n",
      "Epoch 383/1000: L(Train): 0.19569680094718933; L(Test): 0.19353410601615906\n",
      "Epoch 384/1000: L(Train): 0.19757477939128876; L(Test): 0.19347260892391205\n",
      "Epoch 385/1000: L(Train): 0.1963953822851181; L(Test): 0.19319163262844086\n",
      "Epoch 386/1000: L(Train): 0.1967938244342804; L(Test): 0.19317878782749176\n",
      "Epoch 387/1000: L(Train): 0.19763611257076263; L(Test): 0.19349969923496246\n",
      "Epoch 388/1000: L(Train): 0.19497349858283997; L(Test): 0.1933511197566986\n",
      "Epoch 389/1000: L(Train): 0.1966189593076706; L(Test): 0.19320815801620483\n",
      "Epoch 390/1000: L(Train): 0.19487610459327698; L(Test): 0.19315481185913086\n",
      "Epoch 391/1000: L(Train): 0.19589082896709442; L(Test): 0.19334140419960022\n",
      "Epoch 392/1000: L(Train): 0.19591949880123138; L(Test): 0.1932491958141327\n",
      "Epoch 393/1000: L(Train): 0.19376662373542786; L(Test): 0.19313755631446838\n",
      "Epoch 394/1000: L(Train): 0.1951754242181778; L(Test): 0.19310042262077332\n",
      "Epoch 395/1000: L(Train): 0.19634416699409485; L(Test): 0.19304826855659485\n",
      "Epoch 396/1000: L(Train): 0.1976715326309204; L(Test): 0.1929948478937149\n",
      "Epoch 397/1000: L(Train): 0.19674639403820038; L(Test): 0.19308501482009888\n",
      "Epoch 398/1000: L(Train): 0.1936151683330536; L(Test): 0.19299224019050598\n",
      "Epoch 399/1000: L(Train): 0.19511018693447113; L(Test): 0.19303074479103088\n",
      "Epoch 400/1000: L(Train): 0.19748692214488983; L(Test): 0.19301411509513855\n",
      "Epoch 401/1000: L(Train): 0.1989140659570694; L(Test): 0.19302843511104584\n",
      "Epoch 402/1000: L(Train): 0.1966204047203064; L(Test): 0.19328367710113525\n",
      "Epoch 403/1000: L(Train): 0.1962641179561615; L(Test): 0.19291388988494873\n",
      "Epoch 404/1000: L(Train): 0.19678843021392822; L(Test): 0.19293394684791565\n",
      "Epoch 405/1000: L(Train): 0.19499315321445465; L(Test): 0.19306974112987518\n",
      "Epoch 406/1000: L(Train): 0.19790957868099213; L(Test): 0.19292908906936646\n",
      "Epoch 407/1000: L(Train): 0.19794410467147827; L(Test): 0.19296151399612427\n",
      "Epoch 408/1000: L(Train): 0.1959630846977234; L(Test): 0.19294650852680206\n",
      "Epoch 409/1000: L(Train): 0.19507277011871338; L(Test): 0.19328294694423676\n",
      "Epoch 410/1000: L(Train): 0.19468413293361664; L(Test): 0.19287702441215515\n",
      "Epoch 411/1000: L(Train): 0.1978864073753357; L(Test): 0.19309522211551666\n",
      "Epoch 412/1000: L(Train): 0.197018563747406; L(Test): 0.1934819519519806\n",
      "Epoch 413/1000: L(Train): 0.19647550582885742; L(Test): 0.19321832060813904\n",
      "Epoch 414/1000: L(Train): 0.19331350922584534; L(Test): 0.19316016137599945\n",
      "Epoch 415/1000: L(Train): 0.1969609409570694; L(Test): 0.19324854016304016\n",
      "Epoch 416/1000: L(Train): 0.1979692131280899; L(Test): 0.19303067028522491\n",
      "Epoch 417/1000: L(Train): 0.19639642536640167; L(Test): 0.1928059458732605\n",
      "Epoch 418/1000: L(Train): 0.1965583711862564; L(Test): 0.19305069744586945\n",
      "Epoch 419/1000: L(Train): 0.197548970580101; L(Test): 0.19297204911708832\n",
      "Epoch 420/1000: L(Train): 0.1933307647705078; L(Test): 0.19305528700351715\n",
      "Epoch 421/1000: L(Train): 0.19575855135917664; L(Test): 0.19295170903205872\n",
      "Epoch 422/1000: L(Train): 0.1939237117767334; L(Test): 0.1934838742017746\n",
      "Epoch 423/1000: L(Train): 0.19441357254981995; L(Test): 0.1929224729537964\n",
      "Epoch 424/1000: L(Train): 0.19476741552352905; L(Test): 0.19294235110282898\n",
      "Epoch 425/1000: L(Train): 0.196268692612648; L(Test): 0.19286803901195526\n",
      "Epoch 426/1000: L(Train): 0.1943950206041336; L(Test): 0.19337162375450134\n",
      "Epoch 427/1000: L(Train): 0.19392716884613037; L(Test): 0.19277074933052063\n",
      "Epoch 428/1000: L(Train): 0.1944018006324768; L(Test): 0.192615807056427\n",
      "Epoch 429/1000: L(Train): 0.1951926201581955; L(Test): 0.19334019720554352\n",
      "Epoch 430/1000: L(Train): 0.19645807147026062; L(Test): 0.19270800054073334\n",
      "Epoch 431/1000: L(Train): 0.19730232656002045; L(Test): 0.1928602010011673\n",
      "Epoch 432/1000: L(Train): 0.19781941175460815; L(Test): 0.19283485412597656\n",
      "Epoch 433/1000: L(Train): 0.1959228366613388; L(Test): 0.1929459273815155\n",
      "Epoch 434/1000: L(Train): 0.1953435093164444; L(Test): 0.19276635348796844\n",
      "Epoch 435/1000: L(Train): 0.19758746027946472; L(Test): 0.19260884821414948\n",
      "Epoch 436/1000: L(Train): 0.1964883655309677; L(Test): 0.1928127408027649\n",
      "Epoch 437/1000: L(Train): 0.19584335386753082; L(Test): 0.19261907041072845\n",
      "Epoch 438/1000: L(Train): 0.19705389440059662; L(Test): 0.19286341965198517\n",
      "Epoch 439/1000: L(Train): 0.19766832888126373; L(Test): 0.1927308589220047\n",
      "Epoch 440/1000: L(Train): 0.1983463317155838; L(Test): 0.19305089116096497\n",
      "Epoch 441/1000: L(Train): 0.19488196074962616; L(Test): 0.19255563616752625\n",
      "Epoch 442/1000: L(Train): 0.19717128574848175; L(Test): 0.19290877878665924\n",
      "Epoch 443/1000: L(Train): 0.1962110549211502; L(Test): 0.1929081529378891\n",
      "Epoch 444/1000: L(Train): 0.19591188430786133; L(Test): 0.19261550903320312\n",
      "Epoch 445/1000: L(Train): 0.19542743265628815; L(Test): 0.1926877796649933\n",
      "Epoch 446/1000: L(Train): 0.19632844626903534; L(Test): 0.19273075461387634\n",
      "Epoch 447/1000: L(Train): 0.19463662803173065; L(Test): 0.19289806485176086\n",
      "Epoch 448/1000: L(Train): 0.19710879027843475; L(Test): 0.19244202971458435\n",
      "Epoch 449/1000: L(Train): 0.19344615936279297; L(Test): 0.19281408190727234\n",
      "Epoch 450/1000: L(Train): 0.19572319090366364; L(Test): 0.19247131049633026\n",
      "Epoch 451/1000: L(Train): 0.19968067109584808; L(Test): 0.19257478415966034\n",
      "Epoch 452/1000: L(Train): 0.19791914522647858; L(Test): 0.19242730736732483\n",
      "Epoch 453/1000: L(Train): 0.19499169290065765; L(Test): 0.19273371994495392\n",
      "Epoch 454/1000: L(Train): 0.19469347596168518; L(Test): 0.1925320327281952\n",
      "Epoch 455/1000: L(Train): 0.1967305690050125; L(Test): 0.19289539754390717\n",
      "Epoch 456/1000: L(Train): 0.1963104009628296; L(Test): 0.1928434669971466\n",
      "Epoch 457/1000: L(Train): 0.19572164118289948; L(Test): 0.19239361584186554\n",
      "Epoch 458/1000: L(Train): 0.19375087320804596; L(Test): 0.19273395836353302\n",
      "Epoch 459/1000: L(Train): 0.197346031665802; L(Test): 0.19236791133880615\n",
      "Epoch 460/1000: L(Train): 0.1943739354610443; L(Test): 0.1924905776977539\n",
      "Epoch 461/1000: L(Train): 0.1931825876235962; L(Test): 0.19266943633556366\n",
      "Epoch 462/1000: L(Train): 0.19570545852184296; L(Test): 0.19227997958660126\n",
      "Epoch 463/1000: L(Train): 0.19642063975334167; L(Test): 0.19242101907730103\n",
      "Epoch 464/1000: L(Train): 0.19213546812534332; L(Test): 0.1928393393754959\n",
      "Epoch 465/1000: L(Train): 0.1953481137752533; L(Test): 0.1925245076417923\n",
      "Epoch 466/1000: L(Train): 0.1974630206823349; L(Test): 0.19240042567253113\n",
      "Epoch 467/1000: L(Train): 0.1958213746547699; L(Test): 0.19332006573677063\n",
      "Epoch 468/1000: L(Train): 0.19513194262981415; L(Test): 0.19243954122066498\n",
      "Epoch 469/1000: L(Train): 0.19439303874969482; L(Test): 0.1926545798778534\n",
      "Epoch 470/1000: L(Train): 0.1943734884262085; L(Test): 0.19290974736213684\n",
      "Epoch 471/1000: L(Train): 0.1940971165895462; L(Test): 0.19306524097919464\n",
      "Epoch 472/1000: L(Train): 0.1958298683166504; L(Test): 0.19253526628017426\n",
      "Epoch 473/1000: L(Train): 0.19814792275428772; L(Test): 0.19230708479881287\n",
      "Epoch 474/1000: L(Train): 0.19461002945899963; L(Test): 0.19315198063850403\n",
      "Epoch 475/1000: L(Train): 0.1981774866580963; L(Test): 0.19208334386348724\n",
      "Epoch 476/1000: L(Train): 0.19995826482772827; L(Test): 0.1927657425403595\n",
      "Epoch 477/1000: L(Train): 0.19520944356918335; L(Test): 0.1935049444437027\n",
      "Epoch 478/1000: L(Train): 0.19296589493751526; L(Test): 0.19256356358528137\n",
      "Epoch 479/1000: L(Train): 0.1953831911087036; L(Test): 0.1931265890598297\n",
      "Epoch 480/1000: L(Train): 0.19707293808460236; L(Test): 0.19257062673568726\n",
      "Epoch 481/1000: L(Train): 0.19501639902591705; L(Test): 0.19350166618824005\n",
      "Epoch 482/1000: L(Train): 0.19496433436870575; L(Test): 0.19224807620048523\n",
      "Epoch 483/1000: L(Train): 0.19454868137836456; L(Test): 0.1926453858613968\n",
      "Epoch 484/1000: L(Train): 0.1990005522966385; L(Test): 0.19255675375461578\n",
      "Epoch 485/1000: L(Train): 0.1941680908203125; L(Test): 0.1927570253610611\n",
      "Epoch 486/1000: L(Train): 0.19470813870429993; L(Test): 0.19261950254440308\n",
      "Epoch 487/1000: L(Train): 0.19474099576473236; L(Test): 0.19208762049674988\n",
      "Epoch 488/1000: L(Train): 0.19564513862133026; L(Test): 0.1925722062587738\n",
      "Epoch 489/1000: L(Train): 0.19528111815452576; L(Test): 0.1921846866607666\n",
      "Epoch 490/1000: L(Train): 0.19416511058807373; L(Test): 0.192125141620636\n",
      "Epoch 491/1000: L(Train): 0.1956096589565277; L(Test): 0.19223059713840485\n",
      "Epoch 492/1000: L(Train): 0.19549457728862762; L(Test): 0.19209304451942444\n",
      "Epoch 493/1000: L(Train): 0.19487962126731873; L(Test): 0.19210226833820343\n",
      "Epoch 494/1000: L(Train): 0.1976119726896286; L(Test): 0.19195561110973358\n",
      "Epoch 495/1000: L(Train): 0.19510556757450104; L(Test): 0.19203530251979828\n",
      "Epoch 496/1000: L(Train): 0.19327616691589355; L(Test): 0.19200550019741058\n",
      "Epoch 497/1000: L(Train): 0.19322456419467926; L(Test): 0.1919221580028534\n",
      "Epoch 498/1000: L(Train): 0.19531767070293427; L(Test): 0.19193731248378754\n",
      "Epoch 499/1000: L(Train): 0.19273129105567932; L(Test): 0.19197587668895721\n",
      "Epoch 500/1000: L(Train): 0.19522063434123993; L(Test): 0.1919485628604889\n",
      "Epoch 501/1000: L(Train): 0.19393585622310638; L(Test): 0.19189919531345367\n",
      "Epoch 502/1000: L(Train): 0.19672682881355286; L(Test): 0.19192494451999664\n",
      "Epoch 503/1000: L(Train): 0.1948908269405365; L(Test): 0.1919097602367401\n",
      "Epoch 504/1000: L(Train): 0.19766616821289062; L(Test): 0.19198796153068542\n",
      "Epoch 505/1000: L(Train): 0.19675689935684204; L(Test): 0.1918984353542328\n",
      "Epoch 506/1000: L(Train): 0.19628365337848663; L(Test): 0.19186082482337952\n",
      "Epoch 507/1000: L(Train): 0.19718435406684875; L(Test): 0.19197435677051544\n",
      "Epoch 508/1000: L(Train): 0.19602403044700623; L(Test): 0.19187995791435242\n",
      "Epoch 509/1000: L(Train): 0.1929282248020172; L(Test): 0.19182877242565155\n",
      "Epoch 510/1000: L(Train): 0.19709496200084686; L(Test): 0.1918448805809021\n",
      "Epoch 511/1000: L(Train): 0.19621041417121887; L(Test): 0.19190272688865662\n",
      "Epoch 512/1000: L(Train): 0.19698168337345123; L(Test): 0.19182763993740082\n",
      "Epoch 513/1000: L(Train): 0.19236676394939423; L(Test): 0.19181254506111145\n",
      "Epoch 514/1000: L(Train): 0.19322797656059265; L(Test): 0.19206959009170532\n",
      "Epoch 515/1000: L(Train): 0.19256868958473206; L(Test): 0.19190460443496704\n",
      "Epoch 516/1000: L(Train): 0.19534441828727722; L(Test): 0.19179533421993256\n",
      "Epoch 517/1000: L(Train): 0.19382885098457336; L(Test): 0.19190430641174316\n",
      "Epoch 518/1000: L(Train): 0.19269992411136627; L(Test): 0.19191674888134003\n",
      "Epoch 519/1000: L(Train): 0.19723102450370789; L(Test): 0.1919928938150406\n",
      "Epoch 520/1000: L(Train): 0.1965106576681137; L(Test): 0.19251133501529694\n",
      "Epoch 521/1000: L(Train): 0.19626681506633759; L(Test): 0.19170354306697845\n",
      "Epoch 522/1000: L(Train): 0.19734671711921692; L(Test): 0.19194994866847992\n",
      "Epoch 523/1000: L(Train): 0.19495147466659546; L(Test): 0.19287894666194916\n",
      "Epoch 524/1000: L(Train): 0.19594354927539825; L(Test): 0.19178399443626404\n",
      "Epoch 525/1000: L(Train): 0.19257454574108124; L(Test): 0.19193768501281738\n",
      "Epoch 526/1000: L(Train): 0.19863976538181305; L(Test): 0.19229714572429657\n",
      "Epoch 527/1000: L(Train): 0.19347622990608215; L(Test): 0.19205926358699799\n",
      "Epoch 528/1000: L(Train): 0.1980414241552353; L(Test): 0.1921926587820053\n",
      "Epoch 529/1000: L(Train): 0.1965317577123642; L(Test): 0.19185857474803925\n",
      "Epoch 530/1000: L(Train): 0.19410568475723267; L(Test): 0.19219201803207397\n",
      "Epoch 531/1000: L(Train): 0.19724413752555847; L(Test): 0.19187919795513153\n",
      "Epoch 532/1000: L(Train): 0.19871455430984497; L(Test): 0.19164733588695526\n",
      "Epoch 533/1000: L(Train): 0.1932070553302765; L(Test): 0.19268231093883514\n",
      "Epoch 534/1000: L(Train): 0.19592128694057465; L(Test): 0.19165657460689545\n",
      "Epoch 535/1000: L(Train): 0.19507722556591034; L(Test): 0.19187138974666595\n",
      "Epoch 536/1000: L(Train): 0.19823020696640015; L(Test): 0.1919480413198471\n",
      "Epoch 537/1000: L(Train): 0.19661669433116913; L(Test): 0.19179439544677734\n",
      "Epoch 538/1000: L(Train): 0.19582068920135498; L(Test): 0.1916818469762802\n",
      "Epoch 539/1000: L(Train): 0.19800859689712524; L(Test): 0.19170953333377838\n",
      "Epoch 540/1000: L(Train): 0.19442926347255707; L(Test): 0.1920541375875473\n",
      "Epoch 541/1000: L(Train): 0.197824165225029; L(Test): 0.19159196317195892\n",
      "Epoch 542/1000: L(Train): 0.19460885226726532; L(Test): 0.19157324731349945\n",
      "Epoch 543/1000: L(Train): 0.19699139893054962; L(Test): 0.19169503450393677\n",
      "Epoch 544/1000: L(Train): 0.1932917982339859; L(Test): 0.19163191318511963\n",
      "Epoch 545/1000: L(Train): 0.1967267543077469; L(Test): 0.1915591061115265\n",
      "Epoch 546/1000: L(Train): 0.19733130931854248; L(Test): 0.19153867661952972\n",
      "Epoch 547/1000: L(Train): 0.19480182230472565; L(Test): 0.1919150948524475\n",
      "Epoch 548/1000: L(Train): 0.1960451751947403; L(Test): 0.1915881186723709\n",
      "Epoch 549/1000: L(Train): 0.19464527070522308; L(Test): 0.19172298908233643\n",
      "Epoch 550/1000: L(Train): 0.19223923981189728; L(Test): 0.1919572502374649\n",
      "Epoch 551/1000: L(Train): 0.1935955286026001; L(Test): 0.19157449901103973\n",
      "Epoch 552/1000: L(Train): 0.1934574842453003; L(Test): 0.19152794778347015\n",
      "Epoch 553/1000: L(Train): 0.19555655121803284; L(Test): 0.19148856401443481\n",
      "Epoch 554/1000: L(Train): 0.1943240612745285; L(Test): 0.19158127903938293\n",
      "Epoch 555/1000: L(Train): 0.19488494098186493; L(Test): 0.19144587218761444\n",
      "Epoch 556/1000: L(Train): 0.19375289976596832; L(Test): 0.19149301946163177\n",
      "Epoch 557/1000: L(Train): 0.19468288123607635; L(Test): 0.19167006015777588\n",
      "Epoch 558/1000: L(Train): 0.195421501994133; L(Test): 0.19141587615013123\n",
      "Epoch 559/1000: L(Train): 0.1948097050189972; L(Test): 0.19139155745506287\n",
      "Epoch 560/1000: L(Train): 0.19279587268829346; L(Test): 0.19170928001403809\n",
      "Epoch 561/1000: L(Train): 0.1929311901330948; L(Test): 0.19140730798244476\n",
      "Epoch 562/1000: L(Train): 0.19170430302619934; L(Test): 0.1914229393005371\n",
      "Epoch 563/1000: L(Train): 0.1951574981212616; L(Test): 0.19159619510173798\n",
      "Epoch 564/1000: L(Train): 0.1954507678747177; L(Test): 0.19138340651988983\n",
      "Epoch 565/1000: L(Train): 0.19220609962940216; L(Test): 0.19135698676109314\n",
      "Epoch 566/1000: L(Train): 0.19446836411952972; L(Test): 0.19153176248073578\n",
      "Epoch 567/1000: L(Train): 0.19468064606189728; L(Test): 0.19142678380012512\n",
      "Epoch 568/1000: L(Train): 0.1942499577999115; L(Test): 0.19132991135120392\n",
      "Epoch 569/1000: L(Train): 0.19377337396144867; L(Test): 0.19138465821743011\n",
      "Epoch 570/1000: L(Train): 0.19840991497039795; L(Test): 0.1913260817527771\n",
      "Epoch 571/1000: L(Train): 0.19614189863204956; L(Test): 0.19129665195941925\n",
      "Epoch 572/1000: L(Train): 0.19556036591529846; L(Test): 0.19160307943820953\n",
      "Epoch 573/1000: L(Train): 0.19318978488445282; L(Test): 0.19129498302936554\n",
      "Epoch 574/1000: L(Train): 0.19791600108146667; L(Test): 0.19140484929084778\n",
      "Epoch 575/1000: L(Train): 0.1948224902153015; L(Test): 0.1925216019153595\n",
      "Epoch 576/1000: L(Train): 0.19289623200893402; L(Test): 0.1914704591035843\n",
      "Epoch 577/1000: L(Train): 0.19539320468902588; L(Test): 0.19149498641490936\n",
      "Epoch 578/1000: L(Train): 0.19374796748161316; L(Test): 0.19185517728328705\n",
      "Epoch 579/1000: L(Train): 0.19144275784492493; L(Test): 0.1914006918668747\n",
      "Epoch 580/1000: L(Train): 0.19605912268161774; L(Test): 0.19129136204719543\n",
      "Epoch 581/1000: L(Train): 0.19575005769729614; L(Test): 0.1914021074771881\n",
      "Epoch 582/1000: L(Train): 0.195312961935997; L(Test): 0.19116975367069244\n",
      "Epoch 583/1000: L(Train): 0.1937469094991684; L(Test): 0.19140441715717316\n",
      "Epoch 584/1000: L(Train): 0.193846195936203; L(Test): 0.19121894240379333\n",
      "Epoch 585/1000: L(Train): 0.19405300915241241; L(Test): 0.19136394560337067\n",
      "Epoch 586/1000: L(Train): 0.1931879222393036; L(Test): 0.19224300980567932\n",
      "Epoch 587/1000: L(Train): 0.19461578130722046; L(Test): 0.1913640797138214\n",
      "Epoch 588/1000: L(Train): 0.1933353692293167; L(Test): 0.19126054644584656\n",
      "Epoch 589/1000: L(Train): 0.1943829208612442; L(Test): 0.19166743755340576\n",
      "Epoch 590/1000: L(Train): 0.1928129941225052; L(Test): 0.1912253350019455\n",
      "Epoch 591/1000: L(Train): 0.19216713309288025; L(Test): 0.19122324883937836\n",
      "Epoch 592/1000: L(Train): 0.1935425102710724; L(Test): 0.19180986285209656\n",
      "Epoch 593/1000: L(Train): 0.19448566436767578; L(Test): 0.1913101226091385\n",
      "Epoch 594/1000: L(Train): 0.19431984424591064; L(Test): 0.1912369430065155\n",
      "Epoch 595/1000: L(Train): 0.19619245827198029; L(Test): 0.19150063395500183\n",
      "Epoch 596/1000: L(Train): 0.19464583694934845; L(Test): 0.19125621020793915\n",
      "Epoch 597/1000: L(Train): 0.1945895552635193; L(Test): 0.19131650030612946\n",
      "Epoch 598/1000: L(Train): 0.19562114775180817; L(Test): 0.1911691278219223\n",
      "Epoch 599/1000: L(Train): 0.1958818882703781; L(Test): 0.19127057492733002\n",
      "Epoch 600/1000: L(Train): 0.19309331476688385; L(Test): 0.1912107616662979\n",
      "Epoch 601/1000: L(Train): 0.19353614747524261; L(Test): 0.19122402369976044\n",
      "Epoch 602/1000: L(Train): 0.1945004016160965; L(Test): 0.19116510450839996\n",
      "Epoch 603/1000: L(Train): 0.192332923412323; L(Test): 0.19108451902866364\n",
      "Epoch 604/1000: L(Train): 0.19269725680351257; L(Test): 0.19128940999507904\n",
      "Epoch 605/1000: L(Train): 0.194877490401268; L(Test): 0.19111168384552002\n",
      "Epoch 606/1000: L(Train): 0.19518965482711792; L(Test): 0.19111330807209015\n",
      "Epoch 607/1000: L(Train): 0.19512881338596344; L(Test): 0.1911754459142685\n",
      "Epoch 608/1000: L(Train): 0.19284085929393768; L(Test): 0.19108377397060394\n",
      "Epoch 609/1000: L(Train): 0.19470973312854767; L(Test): 0.19113023579120636\n",
      "Epoch 610/1000: L(Train): 0.19429455697536469; L(Test): 0.19103023409843445\n",
      "Epoch 611/1000: L(Train): 0.19365185499191284; L(Test): 0.19116272032260895\n",
      "Epoch 612/1000: L(Train): 0.19325906038284302; L(Test): 0.19101865589618683\n",
      "Epoch 613/1000: L(Train): 0.19455675780773163; L(Test): 0.19127602875232697\n",
      "Epoch 614/1000: L(Train): 0.1946886032819748; L(Test): 0.1911194771528244\n",
      "Epoch 615/1000: L(Train): 0.19072102010250092; L(Test): 0.19112049043178558\n",
      "Epoch 616/1000: L(Train): 0.1934731900691986; L(Test): 0.1910136342048645\n",
      "Epoch 617/1000: L(Train): 0.19314995408058167; L(Test): 0.19120846688747406\n",
      "Epoch 618/1000: L(Train): 0.1971200704574585; L(Test): 0.1911047250032425\n",
      "Epoch 619/1000: L(Train): 0.19662557542324066; L(Test): 0.19098006188869476\n",
      "Epoch 620/1000: L(Train): 0.1918543428182602; L(Test): 0.19181135296821594\n",
      "Epoch 621/1000: L(Train): 0.1940920054912567; L(Test): 0.19159074127674103\n",
      "Epoch 622/1000: L(Train): 0.19435231387615204; L(Test): 0.19245687127113342\n",
      "Epoch 623/1000: L(Train): 0.19788211584091187; L(Test): 0.1912166327238083\n",
      "Epoch 624/1000: L(Train): 0.19511546194553375; L(Test): 0.19105766713619232\n",
      "Epoch 625/1000: L(Train): 0.19505555927753448; L(Test): 0.1916169971227646\n",
      "Epoch 626/1000: L(Train): 0.194930762052536; L(Test): 0.19094103574752808\n",
      "Epoch 627/1000: L(Train): 0.19286435842514038; L(Test): 0.19098441302776337\n",
      "Epoch 628/1000: L(Train): 0.19442008435726166; L(Test): 0.19146667420864105\n",
      "Epoch 629/1000: L(Train): 0.1921505481004715; L(Test): 0.19091451168060303\n",
      "Epoch 630/1000: L(Train): 0.1947954148054123; L(Test): 0.19129346311092377\n",
      "Epoch 631/1000: L(Train): 0.1937360018491745; L(Test): 0.1926131248474121\n",
      "Epoch 632/1000: L(Train): 0.19424642622470856; L(Test): 0.19114112854003906\n",
      "Epoch 633/1000: L(Train): 0.1940908432006836; L(Test): 0.19196544587612152\n",
      "Epoch 634/1000: L(Train): 0.19350719451904297; L(Test): 0.1926572173833847\n",
      "Epoch 635/1000: L(Train): 0.19422508776187897; L(Test): 0.19124585390090942\n",
      "Epoch 636/1000: L(Train): 0.19261227548122406; L(Test): 0.19252276420593262\n",
      "Epoch 637/1000: L(Train): 0.19597774744033813; L(Test): 0.19139675796031952\n",
      "Epoch 638/1000: L(Train): 0.19505111873149872; L(Test): 0.1922360062599182\n",
      "Epoch 639/1000: L(Train): 0.19467706978321075; L(Test): 0.19140265882015228\n",
      "Epoch 640/1000: L(Train): 0.19341261684894562; L(Test): 0.19118474423885345\n",
      "Epoch 641/1000: L(Train): 0.1948985457420349; L(Test): 0.19176477193832397\n",
      "Epoch 642/1000: L(Train): 0.19208383560180664; L(Test): 0.19097477197647095\n",
      "Epoch 643/1000: L(Train): 0.19388897716999054; L(Test): 0.1911906599998474\n",
      "Epoch 644/1000: L(Train): 0.1953936666250229; L(Test): 0.1915973424911499\n",
      "Epoch 645/1000: L(Train): 0.1930219531059265; L(Test): 0.19134695827960968\n",
      "Epoch 646/1000: L(Train): 0.19305431842803955; L(Test): 0.19123193621635437\n",
      "Epoch 647/1000: L(Train): 0.19775782525539398; L(Test): 0.1911318302154541\n",
      "Epoch 648/1000: L(Train): 0.1950090527534485; L(Test): 0.19156424701213837\n",
      "Epoch 649/1000: L(Train): 0.19636443257331848; L(Test): 0.19107678532600403\n",
      "Epoch 650/1000: L(Train): 0.19316771626472473; L(Test): 0.19100478291511536\n",
      "Epoch 651/1000: L(Train): 0.1927787959575653; L(Test): 0.19110697507858276\n",
      "Epoch 652/1000: L(Train): 0.19324062764644623; L(Test): 0.1908939927816391\n",
      "Epoch 653/1000: L(Train): 0.19561707973480225; L(Test): 0.19083969295024872\n",
      "Epoch 654/1000: L(Train): 0.1928456425666809; L(Test): 0.1911301463842392\n",
      "Epoch 655/1000: L(Train): 0.1931561529636383; L(Test): 0.19088102877140045\n",
      "Epoch 656/1000: L(Train): 0.19488804042339325; L(Test): 0.19091111421585083\n",
      "Epoch 657/1000: L(Train): 0.1938469409942627; L(Test): 0.1911557912826538\n",
      "Epoch 658/1000: L(Train): 0.19434621930122375; L(Test): 0.19083015620708466\n",
      "Epoch 659/1000: L(Train): 0.1915162354707718; L(Test): 0.19082427024841309\n",
      "Epoch 660/1000: L(Train): 0.19496293365955353; L(Test): 0.19091975688934326\n",
      "Epoch 661/1000: L(Train): 0.19271710515022278; L(Test): 0.19088920950889587\n",
      "Epoch 662/1000: L(Train): 0.19599519670009613; L(Test): 0.19092096388339996\n",
      "Epoch 663/1000: L(Train): 0.19195407629013062; L(Test): 0.19084949791431427\n",
      "Epoch 664/1000: L(Train): 0.19116759300231934; L(Test): 0.19086134433746338\n",
      "Epoch 665/1000: L(Train): 0.19427980482578278; L(Test): 0.19077634811401367\n",
      "Epoch 666/1000: L(Train): 0.19541418552398682; L(Test): 0.19087249040603638\n",
      "Epoch 667/1000: L(Train): 0.19144515693187714; L(Test): 0.1909118890762329\n",
      "Epoch 668/1000: L(Train): 0.1927163004875183; L(Test): 0.19077357649803162\n",
      "Epoch 669/1000: L(Train): 0.1960257887840271; L(Test): 0.1907251477241516\n",
      "Epoch 670/1000: L(Train): 0.19048255681991577; L(Test): 0.19102223217487335\n",
      "Epoch 671/1000: L(Train): 0.1914263218641281; L(Test): 0.1908084750175476\n",
      "Epoch 672/1000: L(Train): 0.19197750091552734; L(Test): 0.19066648185253143\n",
      "Epoch 673/1000: L(Train): 0.1917302906513214; L(Test): 0.19161058962345123\n",
      "Epoch 674/1000: L(Train): 0.19571799039840698; L(Test): 0.19068074226379395\n",
      "Epoch 675/1000: L(Train): 0.19300614297389984; L(Test): 0.19082383811473846\n",
      "Epoch 676/1000: L(Train): 0.19454815983772278; L(Test): 0.1912134736776352\n",
      "Epoch 677/1000: L(Train): 0.19666920602321625; L(Test): 0.19056656956672668\n",
      "Epoch 678/1000: L(Train): 0.1944812685251236; L(Test): 0.19124749302864075\n",
      "Epoch 679/1000: L(Train): 0.1950158327817917; L(Test): 0.19179658591747284\n",
      "Epoch 680/1000: L(Train): 0.19467465579509735; L(Test): 0.1908501386642456\n",
      "Epoch 681/1000: L(Train): 0.19579315185546875; L(Test): 0.19227677583694458\n",
      "Epoch 682/1000: L(Train): 0.19778817892074585; L(Test): 0.19143547117710114\n",
      "Epoch 683/1000: L(Train): 0.19653865694999695; L(Test): 0.19139325618743896\n",
      "Epoch 684/1000: L(Train): 0.1958407461643219; L(Test): 0.19141638278961182\n",
      "Epoch 685/1000: L(Train): 0.1954934298992157; L(Test): 0.19077035784721375\n",
      "Epoch 686/1000: L(Train): 0.19448111951351166; L(Test): 0.19151964783668518\n",
      "Epoch 687/1000: L(Train): 0.19246605038642883; L(Test): 0.19071319699287415\n",
      "Epoch 688/1000: L(Train): 0.19338928163051605; L(Test): 0.19140949845314026\n",
      "Epoch 689/1000: L(Train): 0.19573575258255005; L(Test): 0.1911250650882721\n",
      "Epoch 690/1000: L(Train): 0.1913909912109375; L(Test): 0.1914103925228119\n",
      "Epoch 691/1000: L(Train): 0.19370447099208832; L(Test): 0.19089427590370178\n",
      "Epoch 692/1000: L(Train): 0.1946018934249878; L(Test): 0.1908082813024521\n",
      "Epoch 693/1000: L(Train): 0.1909705251455307; L(Test): 0.19146546721458435\n",
      "Epoch 694/1000: L(Train): 0.19545672833919525; L(Test): 0.1908041536808014\n",
      "Epoch 695/1000: L(Train): 0.18957751989364624; L(Test): 0.19112426042556763\n",
      "Epoch 696/1000: L(Train): 0.19716496765613556; L(Test): 0.1906830370426178\n",
      "Epoch 697/1000: L(Train): 0.19291670620441437; L(Test): 0.1911744326353073\n",
      "Epoch 698/1000: L(Train): 0.19634626805782318; L(Test): 0.19065657258033752\n",
      "Epoch 699/1000: L(Train): 0.19510820508003235; L(Test): 0.19075173139572144\n",
      "Epoch 700/1000: L(Train): 0.1926109790802002; L(Test): 0.1916520595550537\n",
      "Epoch 701/1000: L(Train): 0.195083886384964; L(Test): 0.1908046007156372\n",
      "Epoch 702/1000: L(Train): 0.19395577907562256; L(Test): 0.19143302738666534\n",
      "Epoch 703/1000: L(Train): 0.19347698986530304; L(Test): 0.1906691938638687\n",
      "Epoch 704/1000: L(Train): 0.1947866976261139; L(Test): 0.1915723830461502\n",
      "Epoch 705/1000: L(Train): 0.19517940282821655; L(Test): 0.19053137302398682\n",
      "Epoch 706/1000: L(Train): 0.1885804682970047; L(Test): 0.19078201055526733\n",
      "Epoch 707/1000: L(Train): 0.1921164095401764; L(Test): 0.19082243740558624\n",
      "Epoch 708/1000: L(Train): 0.1953672170639038; L(Test): 0.19071921706199646\n",
      "Epoch 709/1000: L(Train): 0.19255226850509644; L(Test): 0.19044815003871918\n",
      "Epoch 710/1000: L(Train): 0.1925215870141983; L(Test): 0.19060315191745758\n",
      "Epoch 711/1000: L(Train): 0.19359196722507477; L(Test): 0.19086499512195587\n",
      "Epoch 712/1000: L(Train): 0.19493022561073303; L(Test): 0.19049809873104095\n",
      "Epoch 713/1000: L(Train): 0.19156980514526367; L(Test): 0.1905367225408554\n",
      "Epoch 714/1000: L(Train): 0.1951456218957901; L(Test): 0.1906243860721588\n",
      "Epoch 715/1000: L(Train): 0.19432774186134338; L(Test): 0.1905643492937088\n",
      "Epoch 716/1000: L(Train): 0.1923155039548874; L(Test): 0.19039595127105713\n",
      "Epoch 717/1000: L(Train): 0.193174809217453; L(Test): 0.19038085639476776\n",
      "Epoch 718/1000: L(Train): 0.19025877118110657; L(Test): 0.19057290256023407\n",
      "Epoch 719/1000: L(Train): 0.1915232539176941; L(Test): 0.19044220447540283\n",
      "Epoch 720/1000: L(Train): 0.19612814486026764; L(Test): 0.1905066967010498\n",
      "Epoch 721/1000: L(Train): 0.19221706688404083; L(Test): 0.19040729105472565\n",
      "Epoch 722/1000: L(Train): 0.19365820288658142; L(Test): 0.1908295750617981\n",
      "Epoch 723/1000: L(Train): 0.19587740302085876; L(Test): 0.1903771162033081\n",
      "Epoch 724/1000: L(Train): 0.19311420619487762; L(Test): 0.1903742253780365\n",
      "Epoch 725/1000: L(Train): 0.19118863344192505; L(Test): 0.19084306061267853\n",
      "Epoch 726/1000: L(Train): 0.19226859509944916; L(Test): 0.19032205641269684\n",
      "Epoch 727/1000: L(Train): 0.191532164812088; L(Test): 0.19035911560058594\n",
      "Epoch 728/1000: L(Train): 0.19242806732654572; L(Test): 0.1905439794063568\n",
      "Epoch 729/1000: L(Train): 0.19667716324329376; L(Test): 0.19035246968269348\n",
      "Epoch 730/1000: L(Train): 0.189693883061409; L(Test): 0.1903320848941803\n",
      "Epoch 731/1000: L(Train): 0.19424164295196533; L(Test): 0.19034576416015625\n",
      "Epoch 732/1000: L(Train): 0.19267188012599945; L(Test): 0.19034193456172943\n",
      "Epoch 733/1000: L(Train): 0.19397591054439545; L(Test): 0.1902865767478943\n",
      "Epoch 734/1000: L(Train): 0.19366350769996643; L(Test): 0.19030597805976868\n",
      "Epoch 735/1000: L(Train): 0.19508561491966248; L(Test): 0.1903684139251709\n",
      "Epoch 736/1000: L(Train): 0.19242113828659058; L(Test): 0.19019943475723267\n",
      "Epoch 737/1000: L(Train): 0.1918189525604248; L(Test): 0.19023962318897247\n",
      "Epoch 738/1000: L(Train): 0.19272460043430328; L(Test): 0.19030556082725525\n",
      "Epoch 739/1000: L(Train): 0.19588029384613037; L(Test): 0.19027060270309448\n",
      "Epoch 740/1000: L(Train): 0.19225433468818665; L(Test): 0.19072815775871277\n",
      "Epoch 741/1000: L(Train): 0.19211344420909882; L(Test): 0.1904585361480713\n",
      "Epoch 742/1000: L(Train): 0.19131538271903992; L(Test): 0.19040465354919434\n",
      "Epoch 743/1000: L(Train): 0.19369558990001678; L(Test): 0.19045300781726837\n",
      "Epoch 744/1000: L(Train): 0.19212143123149872; L(Test): 0.19020316004753113\n",
      "Epoch 745/1000: L(Train): 0.19074474275112152; L(Test): 0.1902712881565094\n",
      "Epoch 746/1000: L(Train): 0.19385121762752533; L(Test): 0.19023378193378448\n",
      "Epoch 747/1000: L(Train): 0.19207119941711426; L(Test): 0.19023188948631287\n",
      "Epoch 748/1000: L(Train): 0.19146372377872467; L(Test): 0.19030971825122833\n",
      "Epoch 749/1000: L(Train): 0.1946105808019638; L(Test): 0.19018979370594025\n",
      "Epoch 750/1000: L(Train): 0.1963394731283188; L(Test): 0.19017356634140015\n",
      "Epoch 751/1000: L(Train): 0.19369475543498993; L(Test): 0.190155491232872\n",
      "Epoch 752/1000: L(Train): 0.19600261747837067; L(Test): 0.19012098014354706\n",
      "Epoch 753/1000: L(Train): 0.19486895203590393; L(Test): 0.19011692702770233\n",
      "Epoch 754/1000: L(Train): 0.19395406544208527; L(Test): 0.1901288777589798\n",
      "Epoch 755/1000: L(Train): 0.19420334696769714; L(Test): 0.19028693437576294\n",
      "Epoch 756/1000: L(Train): 0.19322054088115692; L(Test): 0.19021764397621155\n",
      "Epoch 757/1000: L(Train): 0.19200894236564636; L(Test): 0.1903388500213623\n",
      "Epoch 758/1000: L(Train): 0.19353465735912323; L(Test): 0.19008606672286987\n",
      "Epoch 759/1000: L(Train): 0.19135400652885437; L(Test): 0.1901177167892456\n",
      "Epoch 760/1000: L(Train): 0.1919161081314087; L(Test): 0.19055978953838348\n",
      "Epoch 761/1000: L(Train): 0.1928078532218933; L(Test): 0.1900452822446823\n",
      "Epoch 762/1000: L(Train): 0.1896074116230011; L(Test): 0.1900675892829895\n",
      "Epoch 763/1000: L(Train): 0.19310380518436432; L(Test): 0.19034218788146973\n",
      "Epoch 764/1000: L(Train): 0.19503000378608704; L(Test): 0.19016876816749573\n",
      "Epoch 765/1000: L(Train): 0.19298091530799866; L(Test): 0.19008280336856842\n",
      "Epoch 766/1000: L(Train): 0.19325675070285797; L(Test): 0.19024771451950073\n",
      "Epoch 767/1000: L(Train): 0.19136804342269897; L(Test): 0.18995630741119385\n",
      "Epoch 768/1000: L(Train): 0.19556409120559692; L(Test): 0.19009007513523102\n",
      "Epoch 769/1000: L(Train): 0.1955140233039856; L(Test): 0.1900113970041275\n",
      "Epoch 770/1000: L(Train): 0.1917356699705124; L(Test): 0.1900227963924408\n",
      "Epoch 771/1000: L(Train): 0.19271312654018402; L(Test): 0.18992573022842407\n",
      "Epoch 772/1000: L(Train): 0.19003675878047943; L(Test): 0.19012533128261566\n",
      "Epoch 773/1000: L(Train): 0.19111809134483337; L(Test): 0.18998482823371887\n",
      "Epoch 774/1000: L(Train): 0.1936970353126526; L(Test): 0.18994106352329254\n",
      "Epoch 775/1000: L(Train): 0.19463875889778137; L(Test): 0.19028478860855103\n",
      "Epoch 776/1000: L(Train): 0.19440853595733643; L(Test): 0.19003811478614807\n",
      "Epoch 777/1000: L(Train): 0.19220009446144104; L(Test): 0.18994714319705963\n",
      "Epoch 778/1000: L(Train): 0.1914624273777008; L(Test): 0.18996001780033112\n",
      "Epoch 779/1000: L(Train): 0.19345346093177795; L(Test): 0.19010621309280396\n",
      "Epoch 780/1000: L(Train): 0.1901564747095108; L(Test): 0.19012869894504547\n",
      "Epoch 781/1000: L(Train): 0.19261078536510468; L(Test): 0.19014327228069305\n",
      "Epoch 782/1000: L(Train): 0.19424954056739807; L(Test): 0.19047650694847107\n",
      "Epoch 783/1000: L(Train): 0.19375662505626678; L(Test): 0.19007162749767303\n",
      "Epoch 784/1000: L(Train): 0.19312025606632233; L(Test): 0.19011832773685455\n",
      "Epoch 785/1000: L(Train): 0.19158890843391418; L(Test): 0.19016516208648682\n",
      "Epoch 786/1000: L(Train): 0.19564515352249146; L(Test): 0.19014696776866913\n",
      "Epoch 787/1000: L(Train): 0.19391438364982605; L(Test): 0.19012963771820068\n",
      "Epoch 788/1000: L(Train): 0.19134576618671417; L(Test): 0.1901199221611023\n",
      "Epoch 789/1000: L(Train): 0.1901305615901947; L(Test): 0.1899918168783188\n",
      "Epoch 790/1000: L(Train): 0.1928708255290985; L(Test): 0.19034360349178314\n",
      "Epoch 791/1000: L(Train): 0.19188053905963898; L(Test): 0.19056864082813263\n",
      "Epoch 792/1000: L(Train): 0.1933155208826065; L(Test): 0.1899898648262024\n",
      "Epoch 793/1000: L(Train): 0.19338122010231018; L(Test): 0.18997283279895782\n",
      "Epoch 794/1000: L(Train): 0.1930309683084488; L(Test): 0.19028343260288239\n",
      "Epoch 795/1000: L(Train): 0.193293958902359; L(Test): 0.1899218112230301\n",
      "Epoch 796/1000: L(Train): 0.19661945104599; L(Test): 0.190279021859169\n",
      "Epoch 797/1000: L(Train): 0.19241109490394592; L(Test): 0.19157953560352325\n",
      "Epoch 798/1000: L(Train): 0.19393298029899597; L(Test): 0.18979273736476898\n",
      "Epoch 799/1000: L(Train): 0.19288459420204163; L(Test): 0.19146795570850372\n",
      "Epoch 800/1000: L(Train): 0.19275283813476562; L(Test): 0.19277149438858032\n",
      "Epoch 801/1000: L(Train): 0.1976367086172104; L(Test): 0.19084790349006653\n",
      "Epoch 802/1000: L(Train): 0.19055286049842834; L(Test): 0.19225174188613892\n",
      "Epoch 803/1000: L(Train): 0.19439230859279633; L(Test): 0.19035601615905762\n",
      "Epoch 804/1000: L(Train): 0.19493317604064941; L(Test): 0.19113078713417053\n",
      "Epoch 805/1000: L(Train): 0.19304496049880981; L(Test): 0.19014230370521545\n",
      "Epoch 806/1000: L(Train): 0.19314205646514893; L(Test): 0.19099456071853638\n",
      "Epoch 807/1000: L(Train): 0.19277644157409668; L(Test): 0.19060561060905457\n",
      "Epoch 808/1000: L(Train): 0.19284778833389282; L(Test): 0.19066432118415833\n",
      "Epoch 809/1000: L(Train): 0.18918129801750183; L(Test): 0.19035381078720093\n",
      "Epoch 810/1000: L(Train): 0.1950235664844513; L(Test): 0.19005711376667023\n",
      "Epoch 811/1000: L(Train): 0.1921864002943039; L(Test): 0.1906910389661789\n",
      "Epoch 812/1000: L(Train): 0.19316010177135468; L(Test): 0.19027505815029144\n",
      "Epoch 813/1000: L(Train): 0.19107568264007568; L(Test): 0.19008725881576538\n",
      "Epoch 814/1000: L(Train): 0.19511860609054565; L(Test): 0.19017210602760315\n",
      "Epoch 815/1000: L(Train): 0.19518069922924042; L(Test): 0.1901993751525879\n",
      "Epoch 816/1000: L(Train): 0.1948109120130539; L(Test): 0.19024212658405304\n",
      "Epoch 817/1000: L(Train): 0.19491292536258698; L(Test): 0.19002805650234222\n",
      "Epoch 818/1000: L(Train): 0.19204920530319214; L(Test): 0.19019746780395508\n",
      "Epoch 819/1000: L(Train): 0.1931440830230713; L(Test): 0.1904158890247345\n",
      "Epoch 820/1000: L(Train): 0.1919478327035904; L(Test): 0.18989349901676178\n",
      "Epoch 821/1000: L(Train): 0.19487068057060242; L(Test): 0.19067463278770447\n",
      "Epoch 822/1000: L(Train): 0.19295264780521393; L(Test): 0.19094419479370117\n",
      "Epoch 823/1000: L(Train): 0.191796213388443; L(Test): 0.19009362161159515\n",
      "Epoch 824/1000: L(Train): 0.19121573865413666; L(Test): 0.19056262075901031\n",
      "Epoch 825/1000: L(Train): 0.19225537776947021; L(Test): 0.1905868947505951\n",
      "Epoch 826/1000: L(Train): 0.1943209320306778; L(Test): 0.19065211713314056\n",
      "Epoch 827/1000: L(Train): 0.1931813657283783; L(Test): 0.18998152017593384\n",
      "Epoch 828/1000: L(Train): 0.19454869627952576; L(Test): 0.19030103087425232\n",
      "Epoch 829/1000: L(Train): 0.19368618726730347; L(Test): 0.1901087909936905\n",
      "Epoch 830/1000: L(Train): 0.19584998488426208; L(Test): 0.19014492630958557\n",
      "Epoch 831/1000: L(Train): 0.1945962756872177; L(Test): 0.19026929140090942\n",
      "Epoch 832/1000: L(Train): 0.1914474368095398; L(Test): 0.1898341178894043\n",
      "Epoch 833/1000: L(Train): 0.19159288704395294; L(Test): 0.19028757512569427\n",
      "Epoch 834/1000: L(Train): 0.19385316967964172; L(Test): 0.18978959321975708\n",
      "Epoch 835/1000: L(Train): 0.19026629626750946; L(Test): 0.18990616500377655\n",
      "Epoch 836/1000: L(Train): 0.19102148711681366; L(Test): 0.1898551732301712\n",
      "Epoch 837/1000: L(Train): 0.19385382533073425; L(Test): 0.18991468846797943\n",
      "Epoch 838/1000: L(Train): 0.19196569919586182; L(Test): 0.19016562402248383\n",
      "Epoch 839/1000: L(Train): 0.19078144431114197; L(Test): 0.1897125542163849\n",
      "Epoch 840/1000: L(Train): 0.192642942070961; L(Test): 0.19056302309036255\n",
      "Epoch 841/1000: L(Train): 0.19343601167201996; L(Test): 0.18981420993804932\n",
      "Epoch 842/1000: L(Train): 0.19184330105781555; L(Test): 0.18988047540187836\n",
      "Epoch 843/1000: L(Train): 0.19471658766269684; L(Test): 0.189878448843956\n",
      "Epoch 844/1000: L(Train): 0.19136977195739746; L(Test): 0.19016854465007782\n",
      "Epoch 845/1000: L(Train): 0.19073310494422913; L(Test): 0.18960736691951752\n",
      "Epoch 846/1000: L(Train): 0.19270730018615723; L(Test): 0.19010867178440094\n",
      "Epoch 847/1000: L(Train): 0.19142282009124756; L(Test): 0.18981753289699554\n",
      "Epoch 848/1000: L(Train): 0.191959947347641; L(Test): 0.18986758589744568\n",
      "Epoch 849/1000: L(Train): 0.19060440361499786; L(Test): 0.18981803953647614\n",
      "Epoch 850/1000: L(Train): 0.19208069145679474; L(Test): 0.18947061896324158\n",
      "Epoch 851/1000: L(Train): 0.191635861992836; L(Test): 0.19008970260620117\n",
      "Epoch 852/1000: L(Train): 0.19464175403118134; L(Test): 0.18947136402130127\n",
      "Epoch 853/1000: L(Train): 0.1939719319343567; L(Test): 0.1895464062690735\n",
      "Epoch 854/1000: L(Train): 0.1927025467157364; L(Test): 0.18965411186218262\n",
      "Epoch 855/1000: L(Train): 0.1937423050403595; L(Test): 0.18952061235904694\n",
      "Epoch 856/1000: L(Train): 0.19046948850154877; L(Test): 0.18950121104717255\n",
      "Epoch 857/1000: L(Train): 0.19356632232666016; L(Test): 0.189527690410614\n",
      "Epoch 858/1000: L(Train): 0.19084295630455017; L(Test): 0.18944193422794342\n",
      "Epoch 859/1000: L(Train): 0.19107860326766968; L(Test): 0.18939071893692017\n",
      "Epoch 860/1000: L(Train): 0.19228523969650269; L(Test): 0.1894204020500183\n",
      "Epoch 861/1000: L(Train): 0.18988299369812012; L(Test): 0.18962600827217102\n",
      "Epoch 862/1000: L(Train): 0.19078296422958374; L(Test): 0.18944312632083893\n",
      "Epoch 863/1000: L(Train): 0.19117259979248047; L(Test): 0.18941132724285126\n",
      "Epoch 864/1000: L(Train): 0.19341100752353668; L(Test): 0.1895396113395691\n",
      "Epoch 865/1000: L(Train): 0.1925296038389206; L(Test): 0.18964222073554993\n",
      "Epoch 866/1000: L(Train): 0.19259332120418549; L(Test): 0.18928872048854828\n",
      "Epoch 867/1000: L(Train): 0.1909184455871582; L(Test): 0.18932756781578064\n",
      "Epoch 868/1000: L(Train): 0.19334036111831665; L(Test): 0.18935039639472961\n",
      "Epoch 869/1000: L(Train): 0.193842813372612; L(Test): 0.18938232958316803\n",
      "Epoch 870/1000: L(Train): 0.19292838871479034; L(Test): 0.189707413315773\n",
      "Epoch 871/1000: L(Train): 0.18995584547519684; L(Test): 0.18948213756084442\n",
      "Epoch 872/1000: L(Train): 0.19389060139656067; L(Test): 0.18954068422317505\n",
      "Epoch 873/1000: L(Train): 0.19056813418865204; L(Test): 0.18949316442012787\n",
      "Epoch 874/1000: L(Train): 0.1930188685655594; L(Test): 0.18971946835517883\n",
      "Epoch 875/1000: L(Train): 0.19144409894943237; L(Test): 0.18948984146118164\n",
      "Epoch 876/1000: L(Train): 0.19605904817581177; L(Test): 0.18939359486103058\n",
      "Epoch 877/1000: L(Train): 0.19227486848831177; L(Test): 0.18987661600112915\n",
      "Epoch 878/1000: L(Train): 0.19227322936058044; L(Test): 0.18930886685848236\n",
      "Epoch 879/1000: L(Train): 0.18985113501548767; L(Test): 0.18951736390590668\n",
      "Epoch 880/1000: L(Train): 0.1934303194284439; L(Test): 0.18970420956611633\n",
      "Epoch 881/1000: L(Train): 0.1953633725643158; L(Test): 0.18961240351200104\n",
      "Epoch 882/1000: L(Train): 0.19493255019187927; L(Test): 0.18992498517036438\n",
      "Epoch 883/1000: L(Train): 0.1904968023300171; L(Test): 0.18955405056476593\n",
      "Epoch 884/1000: L(Train): 0.19059433043003082; L(Test): 0.190058633685112\n",
      "Epoch 885/1000: L(Train): 0.19373196363449097; L(Test): 0.1896064728498459\n",
      "Epoch 886/1000: L(Train): 0.19405996799468994; L(Test): 0.18952617049217224\n",
      "Epoch 887/1000: L(Train): 0.19537396728992462; L(Test): 0.18994338810443878\n",
      "Epoch 888/1000: L(Train): 0.19134151935577393; L(Test): 0.18936672806739807\n",
      "Epoch 889/1000: L(Train): 0.1899557262659073; L(Test): 0.1894623041152954\n",
      "Epoch 890/1000: L(Train): 0.18967145681381226; L(Test): 0.18917028605937958\n",
      "Epoch 891/1000: L(Train): 0.19181300699710846; L(Test): 0.190087229013443\n",
      "Epoch 892/1000: L(Train): 0.19522032141685486; L(Test): 0.18916365504264832\n",
      "Epoch 893/1000: L(Train): 0.1904592514038086; L(Test): 0.189673513174057\n",
      "Epoch 894/1000: L(Train): 0.19311276078224182; L(Test): 0.1896386444568634\n",
      "Epoch 895/1000: L(Train): 0.190941721200943; L(Test): 0.18950146436691284\n",
      "Epoch 896/1000: L(Train): 0.1936885118484497; L(Test): 0.1901462823152542\n",
      "Epoch 897/1000: L(Train): 0.19047555327415466; L(Test): 0.18943607807159424\n",
      "Epoch 898/1000: L(Train): 0.19426977634429932; L(Test): 0.19027628004550934\n",
      "Epoch 899/1000: L(Train): 0.1925354301929474; L(Test): 0.1893012523651123\n",
      "Epoch 900/1000: L(Train): 0.19285838305950165; L(Test): 0.18973878026008606\n",
      "Epoch 901/1000: L(Train): 0.19143953919410706; L(Test): 0.18941651284694672\n",
      "Epoch 902/1000: L(Train): 0.1915024071931839; L(Test): 0.18963907659053802\n",
      "Epoch 903/1000: L(Train): 0.19427652657032013; L(Test): 0.18961133062839508\n",
      "Epoch 904/1000: L(Train): 0.1900377869606018; L(Test): 0.1892591118812561\n",
      "Epoch 905/1000: L(Train): 0.1926979422569275; L(Test): 0.189634770154953\n",
      "Epoch 906/1000: L(Train): 0.19341972470283508; L(Test): 0.18912911415100098\n",
      "Epoch 907/1000: L(Train): 0.1925317943096161; L(Test): 0.1893487274646759\n",
      "Epoch 908/1000: L(Train): 0.1949186772108078; L(Test): 0.18921932578086853\n",
      "Epoch 909/1000: L(Train): 0.19204549491405487; L(Test): 0.18947109580039978\n",
      "Epoch 910/1000: L(Train): 0.19226200878620148; L(Test): 0.18909095227718353\n",
      "Epoch 911/1000: L(Train): 0.19235438108444214; L(Test): 0.1891891062259674\n",
      "Epoch 912/1000: L(Train): 0.18870174884796143; L(Test): 0.18919485807418823\n",
      "Epoch 913/1000: L(Train): 0.19487592577934265; L(Test): 0.18917222321033478\n",
      "Epoch 914/1000: L(Train): 0.19208768010139465; L(Test): 0.18910270929336548\n",
      "Epoch 915/1000: L(Train): 0.19253720343112946; L(Test): 0.18928693234920502\n",
      "Epoch 916/1000: L(Train): 0.18946246802806854; L(Test): 0.1891607642173767\n",
      "Epoch 917/1000: L(Train): 0.1937480866909027; L(Test): 0.18892893195152283\n",
      "Epoch 918/1000: L(Train): 0.19059446454048157; L(Test): 0.18900059163570404\n",
      "Epoch 919/1000: L(Train): 0.19397468864917755; L(Test): 0.18909910321235657\n",
      "Epoch 920/1000: L(Train): 0.1889767348766327; L(Test): 0.18896545469760895\n",
      "Epoch 921/1000: L(Train): 0.19308717548847198; L(Test): 0.18900656700134277\n",
      "Epoch 922/1000: L(Train): 0.19093859195709229; L(Test): 0.18898765742778778\n",
      "Epoch 923/1000: L(Train): 0.18981224298477173; L(Test): 0.1889888197183609\n",
      "Epoch 924/1000: L(Train): 0.19253657758235931; L(Test): 0.18882650136947632\n",
      "Epoch 925/1000: L(Train): 0.19281278550624847; L(Test): 0.18890562653541565\n",
      "Epoch 926/1000: L(Train): 0.19192032516002655; L(Test): 0.18902869522571564\n",
      "Epoch 927/1000: L(Train): 0.19304904341697693; L(Test): 0.1890602558851242\n",
      "Epoch 928/1000: L(Train): 0.1916155368089676; L(Test): 0.1889907419681549\n",
      "Epoch 929/1000: L(Train): 0.19205766916275024; L(Test): 0.18904957175254822\n",
      "Epoch 930/1000: L(Train): 0.19482073187828064; L(Test): 0.18891267478466034\n",
      "Epoch 931/1000: L(Train): 0.1913970559835434; L(Test): 0.18886584043502808\n",
      "Epoch 932/1000: L(Train): 0.19356843829154968; L(Test): 0.18903453648090363\n",
      "Epoch 933/1000: L(Train): 0.19545963406562805; L(Test): 0.18879587948322296\n",
      "Epoch 934/1000: L(Train): 0.19000457227230072; L(Test): 0.18879103660583496\n",
      "Epoch 935/1000: L(Train): 0.19506298005580902; L(Test): 0.1888454258441925\n",
      "Epoch 936/1000: L(Train): 0.1909017264842987; L(Test): 0.18903480470180511\n",
      "Epoch 937/1000: L(Train): 0.1910809874534607; L(Test): 0.18895117938518524\n",
      "Epoch 938/1000: L(Train): 0.19071809947490692; L(Test): 0.18886572122573853\n",
      "Epoch 939/1000: L(Train): 0.1938638836145401; L(Test): 0.18885579705238342\n",
      "Epoch 940/1000: L(Train): 0.1925361305475235; L(Test): 0.18886658549308777\n",
      "Epoch 941/1000: L(Train): 0.1914025843143463; L(Test): 0.1890338957309723\n",
      "Epoch 942/1000: L(Train): 0.19251056015491486; L(Test): 0.18890272080898285\n",
      "Epoch 943/1000: L(Train): 0.1911119669675827; L(Test): 0.18881765007972717\n",
      "Epoch 944/1000: L(Train): 0.19198033213615417; L(Test): 0.18884047865867615\n",
      "Epoch 945/1000: L(Train): 0.1936643421649933; L(Test): 0.18870232999324799\n",
      "Epoch 946/1000: L(Train): 0.18578767776489258; L(Test): 0.18893644213676453\n",
      "Epoch 947/1000: L(Train): 0.1927747130393982; L(Test): 0.18903270363807678\n",
      "Epoch 948/1000: L(Train): 0.19589348137378693; L(Test): 0.18889600038528442\n",
      "Epoch 949/1000: L(Train): 0.19529536366462708; L(Test): 0.18887324631214142\n",
      "Epoch 950/1000: L(Train): 0.19263802468776703; L(Test): 0.1888519823551178\n",
      "Epoch 951/1000: L(Train): 0.19216445088386536; L(Test): 0.18868976831436157\n",
      "Epoch 952/1000: L(Train): 0.19094690680503845; L(Test): 0.1886504590511322\n",
      "Epoch 953/1000: L(Train): 0.19263990223407745; L(Test): 0.1888343095779419\n",
      "Epoch 954/1000: L(Train): 0.19199822843074799; L(Test): 0.188777893781662\n",
      "Epoch 955/1000: L(Train): 0.19013337790966034; L(Test): 0.18866096436977386\n",
      "Epoch 956/1000: L(Train): 0.19310353696346283; L(Test): 0.18863902986049652\n",
      "Epoch 957/1000: L(Train): 0.19043266773223877; L(Test): 0.18864265084266663\n",
      "Epoch 958/1000: L(Train): 0.19180205464363098; L(Test): 0.18859277665615082\n",
      "Epoch 959/1000: L(Train): 0.19208824634552002; L(Test): 0.18863317370414734\n",
      "Epoch 960/1000: L(Train): 0.19210746884346008; L(Test): 0.18868228793144226\n",
      "Epoch 961/1000: L(Train): 0.19396498799324036; L(Test): 0.1886410415172577\n",
      "Epoch 962/1000: L(Train): 0.1926591396331787; L(Test): 0.1887599527835846\n",
      "Epoch 963/1000: L(Train): 0.19357432425022125; L(Test): 0.1886993646621704\n",
      "Epoch 964/1000: L(Train): 0.1889958381652832; L(Test): 0.18875983357429504\n",
      "Epoch 965/1000: L(Train): 0.1895633488893509; L(Test): 0.18872006237506866\n",
      "Epoch 966/1000: L(Train): 0.1929486095905304; L(Test): 0.18864712119102478\n",
      "Epoch 967/1000: L(Train): 0.19144149124622345; L(Test): 0.18872784078121185\n",
      "Epoch 968/1000: L(Train): 0.19016197323799133; L(Test): 0.18891747295856476\n",
      "Epoch 969/1000: L(Train): 0.19236153364181519; L(Test): 0.18867167830467224\n",
      "Epoch 970/1000: L(Train): 0.19024643301963806; L(Test): 0.1885535717010498\n",
      "Epoch 971/1000: L(Train): 0.19243527948856354; L(Test): 0.1887405961751938\n",
      "Epoch 972/1000: L(Train): 0.19067203998565674; L(Test): 0.18890434503555298\n",
      "Epoch 973/1000: L(Train): 0.19348707795143127; L(Test): 0.18971474468708038\n",
      "Epoch 974/1000: L(Train): 0.1910521239042282; L(Test): 0.1888258010149002\n",
      "Epoch 975/1000: L(Train): 0.19163791835308075; L(Test): 0.1895092874765396\n",
      "Epoch 976/1000: L(Train): 0.1927746832370758; L(Test): 0.18942828476428986\n",
      "Epoch 977/1000: L(Train): 0.19456221163272858; L(Test): 0.188986137509346\n",
      "Epoch 978/1000: L(Train): 0.19147458672523499; L(Test): 0.19003936648368835\n",
      "Epoch 979/1000: L(Train): 0.19445784389972687; L(Test): 0.19019527733325958\n",
      "Epoch 980/1000: L(Train): 0.19322679936885834; L(Test): 0.1897924244403839\n",
      "Epoch 981/1000: L(Train): 0.19350223243236542; L(Test): 0.18929031491279602\n",
      "Epoch 982/1000: L(Train): 0.19588088989257812; L(Test): 0.189880833029747\n",
      "Epoch 983/1000: L(Train): 0.19307363033294678; L(Test): 0.18937727808952332\n",
      "Epoch 984/1000: L(Train): 0.19271446764469147; L(Test): 0.18934814631938934\n",
      "Epoch 985/1000: L(Train): 0.1907450258731842; L(Test): 0.18938139081001282\n",
      "Epoch 986/1000: L(Train): 0.19398243725299835; L(Test): 0.18889567255973816\n",
      "Epoch 987/1000: L(Train): 0.1927897036075592; L(Test): 0.18971890211105347\n",
      "Epoch 988/1000: L(Train): 0.19176918268203735; L(Test): 0.18882185220718384\n",
      "Epoch 989/1000: L(Train): 0.19136135280132294; L(Test): 0.1895335465669632\n",
      "Epoch 990/1000: L(Train): 0.19360335171222687; L(Test): 0.18882809579372406\n",
      "Epoch 991/1000: L(Train): 0.19036376476287842; L(Test): 0.1892799586057663\n",
      "Epoch 992/1000: L(Train): 0.19391196966171265; L(Test): 0.18934698402881622\n",
      "Epoch 993/1000: L(Train): 0.19084428250789642; L(Test): 0.18852511048316956\n",
      "Epoch 994/1000: L(Train): 0.19191890954971313; L(Test): 0.18878167867660522\n",
      "Epoch 995/1000: L(Train): 0.19389890134334564; L(Test): 0.18864186108112335\n",
      "Epoch 996/1000: L(Train): 0.19234497845172882; L(Test): 0.18873417377471924\n",
      "Epoch 997/1000: L(Train): 0.1865701526403427; L(Test): 0.188790962100029\n",
      "Epoch 998/1000: L(Train): 0.19271238148212433; L(Test): 0.1885818988084793\n",
      "Epoch 999/1000: L(Train): 0.19031696021556854; L(Test): 0.1887858510017395\n",
      "Epoch 1000/1000: L(Train): 0.19133006036281586; L(Test): 0.18875978887081146\n"
     ]
    }
   ],
   "source": [
    "gru = training(\n",
    "    gru=gru,\n",
    "    optimizer=optimizer,\n",
    "    dataset_train=dataset,\n",
    "    dataset_test=dataset,\n",
    "    epochs=epochs,\n",
    "    )\n",
    "\n",
    "torch.save(gru.state_dict(), path_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_agent = setup_agent_gru(path_gru)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot SPICE against benchmark models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_stay[t+1] = 0.085 1 + 0.712 value_stay[t] + 0.455 reward + 0.085 harvest_duration + -0.287 value_stay*harvest_duration + 0.455 reward*harvest_duration + 0.085 harvest_duration^2 \n",
      "value_exit[t+1] = 1.0 value_exit[t] \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting\n",
    "participant_id = 7\n",
    "\n",
    "estimator.print_spice_model(participant_id)\n",
    "\n",
    "agents = {\n",
    "    'rnn': estimator.rnn_agent,\n",
    "    'spice': estimator.spice_agent,\n",
    "    'mvt': mvt_agent,\n",
    "    'gru': gru_agent,\n",
    "}\n",
    "\n",
    "fig, axs = plot_session(agents, dataset.xs[participant_id], signals_to_plot=[])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "spice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}