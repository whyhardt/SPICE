{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tf7jlYw4NA0v",
    "outputId": "0969ca34-675d-422e-cbfb-7387d9bcd8ad"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/whyhardt/SPICE.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oXIbg826NS5i",
    "outputId": "3825864a-cb2d-4ad5-f2e5-79a4e81dfc3e"
   },
   "outputs": [],
   "source": [
    "# !pip install -e SPICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "f0uVlABYznR5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from spice import SpiceEstimator, SpiceConfig, SpiceDataset, csv_to_dataset, BaseRNN\n",
    "\n",
    "# For custom RNN\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data first with the `convert_dataset` method. This method returns a `SpiceDataset` object which we can use right away "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: torch.Size([311, 144, 19])\n",
      "Number of participants: 42\n",
      "Number of actions in dataset: 6\n",
      "Number of additional inputs: 4\n"
     ]
    }
   ],
   "source": [
    "# Load your data\n",
    "dataset = csv_to_dataset(\n",
    "    file = '../data/hwang2025/hwang2025.csv',\n",
    "    df_participant_id='interaction_id',\n",
    "    df_choice='SigAct_ID1',\n",
    "    df_feedback='Grooming_ID2',\n",
    "    additional_inputs=['ID1', 'ID2', 'SigAct_ID2', 'Grooming_ID1'],\n",
    "    timeshift_additional_inputs=False,\n",
    "    )\n",
    "\n",
    "# in order to set up the participant embedding we have to compute the number of unique participants in our data \n",
    "# to get the number of participants n_participants we do:\n",
    "n_actions = dataset.ys.shape[-1]\n",
    "n_participants = dataset.xs[:, 0, n_actions*2:n_actions*2+2].nan_to_num(0).max().int().item()+1\n",
    "\n",
    "# replace participant id and experiment id columns in dataset with ID1 and ID2 columns from additional inputs\n",
    "# participant id -> ID1\n",
    "# experiment id -> ID2\n",
    "dataset.xs[..., -1] = dataset.xs[:, 0, n_actions*2].unsqueeze(-1).nan_to_num(0).repeat(1, dataset.xs.shape[1])\n",
    "dataset.xs[..., -2] = dataset.xs[:, 0, n_actions*2+1].unsqueeze(-1).nan_to_num(0).repeat(1, dataset.xs.shape[1])\n",
    "\n",
    "# TODO: Implement dataset split into training and testing data\n",
    "dataset_train, dataset_test = dataset, dataset\n",
    "# blueprint for splitting:\n",
    "# def datasplit(dataset, ...) -> SpiceDataset, SpiceDataset\n",
    "    # return dataset_train, dataset_test\n",
    "    \n",
    "# structure of dataset:\n",
    "# dataset has two main attributes: xs -> inputs; ys -> targets (next action)\n",
    "# shape: (n_participants*n_blocks*n_experiments, n_timesteps, features)\n",
    "# features are (n_actions * action, n_actions * reward, n_additional_inputs * additional_input, block_number, experiment_id, participant_id)\n",
    "\n",
    "print(f\"Shape of dataset: {dataset.xs.shape}\")\n",
    "print(f\"Number of participants: {n_participants}\")\n",
    "print(f\"Number of actions in dataset: {n_actions}\")\n",
    "print(f\"Number of additional inputs: {dataset.xs.shape[-1]-2*n_actions-3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([311, 144, 19])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.xs.shape # shape -> (n_participants: 41, timesteps: 496, features: 16)\n",
    "\n",
    "# normal RL exp:    [A] [B] [C] [D] [E]\n",
    "# choice:           [x] [ ] [ ] [ ] [ ]\n",
    "# reward:           [1] [ ] [ ] [ ] [ ]    (partial feedback)\n",
    "# reward:           [1] [0] [1] [1] [0]    (full feedback)\n",
    "\n",
    "# features: (action0, action1, action2, action3, action4, reward0, reward1, reward2, reward3, reward4, 'ID2', 'SigAct_ID2', 'Grooming_ID1', block number, experiment id, ID1)\n",
    "# in your case: (x, x, x, x, x, -, -, -, -, -, x, x, x, -, -, -, -, x)    -> x: keep; -: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to define the configuration for SPICE with a `SpiceConfig` object.\n",
    "\n",
    "The `SpiceConfig` takes as arguments \n",
    "1. `library_setup (dict)`: Defining the variable names of each module.\n",
    "2. `memory_state (dict)`: Defining the memory state variables and their initial values.\n",
    "3. `states_in_logit (list)`: Defining which of the memory state variables are used later for the logit computation. This is necessary for some background processes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spice_config = SpiceConfig(\n",
    "    library_setup={\n",
    "        'value_action': ['chosen', 'sig_action', 'sig_grooming', 'sig_non_contact', 'sig_contact', 'sig_scratch', 'sig_waiting', 'prev_action', 'prev_grooming', 'prev_non_contact', 'prev_contact', 'prev_scratch', 'prev_waiting'],\n",
    "        'value_grooming': ['chosen', 'sig_action', 'sig_grooming', 'sig_non_contact', 'sig_contact', 'sig_scratch', 'sig_waiting', 'prev_action', 'prev_grooming', 'prev_non_contact', 'prev_contact', 'prev_scratch', 'prev_waiting'],\n",
    "        'value_non_contact': ['chosen', 'sig_action', 'sig_grooming', 'sig_non_contact', 'sig_contact', 'sig_scratch', 'sig_waiting', 'prev_action', 'prev_grooming', 'prev_non_contact', 'prev_contact', 'prev_scratch', 'prev_waiting'],\n",
    "        'value_contact': ['chosen', 'sig_action', 'sig_grooming', 'sig_non_contact', 'sig_contact', 'sig_scratch', 'sig_waiting', 'prev_action', 'prev_grooming', 'prev_non_contact', 'prev_contact', 'prev_scratch', 'prev_waiting'],\n",
    "        'value_scratch': ['chosen', 'sig_action', 'sig_grooming', 'sig_non_contact', 'sig_contact', 'sig_scratch', 'sig_waiting', 'prev_action', 'prev_grooming', 'prev_non_contact', 'prev_contact', 'prev_scratch', 'prev_waiting'],\n",
    "        'value_waiting': ['chosen', 'sig_action', 'sig_grooming', 'sig_non_contact', 'sig_contact', 'sig_scratch', 'sig_waiting', 'prev_action', 'prev_grooming', 'prev_non_contact', 'prev_contact', 'prev_scratch', 'prev_waiting'],\n",
    "    },\n",
    "    \n",
    "    memory_state={\n",
    "        # 'value_action': 0,\n",
    "        # 'value_grooming': 0,\n",
    "        # 'value_non_conctant': 0,\n",
    "        # 'value_contact': 0,\n",
    "        # 'value_scratch': 0,\n",
    "        # 'waiting': 0,\n",
    "        'values': 0,\n",
    "        },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we are going to define the SPICE model which is a child of the `BaseRNN` and `torch.nn.Module` class and takes as required arguments:\n",
    "1. `spice_config (SpiceConfig)`: previously defined SpiceConfig object\n",
    "2. `n_actions (int)`: number of possible actions in your dataset (including non-displayed ones if applicable).\n",
    "3. `n_participants (int)`: number of participants in your dataset.\n",
    "\n",
    "As usual for a `torch.nn.Module` we have to define at least the `__init__` method and the `forward` method.\n",
    "The `forward` method gets called when computing a forward pass through the model and takes as inputs `(inputs (SpiceDataset.xs), prev_state (dict, default: None), batch_first (bool, default: False))` and returns `(logits (torch.Tensor, shape: (n_participants*n_blocks*n_experiments, timesteps, n_actions)), updated_state (dict))`. Two necessary method calls inside the forward pass are:\n",
    "1. `self.init_forward_pass(inputs, prev_state, batch_first) -> SpiceSignals`: returns a `SpiceSignals` object which carries all relevant information already processed.\n",
    "2. `self.post_forward_pass(SpiceSignals, batch_first) -> SpiceSignals`: does some re-arranging of the logits to adhere to `batch_first`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "z0kOR2Qgz0FZ"
   },
   "outputs": [],
   "source": [
    "class SPICERNN(BaseRNN):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(embedding_size=8, **kwargs)\n",
    "        \n",
    "        dropout = 0.1\n",
    "            \n",
    "        # participant embedding\n",
    "        self.participant_embedding = self.setup_embedding(num_embeddings=self.n_participants, embedding_size=self.embedding_size, dropout=dropout)\n",
    "        \n",
    "        # rnn modules\n",
    "        # reward-based modules\n",
    "        self.setup_module(key_module='value_action', input_size=13+self.embedding_size*2, dropout=dropout)\n",
    "        self.setup_module(key_module='value_grooming', input_size=13+self.embedding_size*2, dropout=dropout)\n",
    "        self.setup_module(key_module='value_non_contact', input_size=13+self.embedding_size*2, dropout=dropout)\n",
    "        self.setup_module(key_module='value_contact', input_size=13+self.embedding_size*2, dropout=dropout)\n",
    "        self.setup_module(key_module='value_scratch', input_size=13+self.embedding_size*2, dropout=dropout)\n",
    "        self.setup_module(key_module='value_waiting', input_size=13+self.embedding_size*2, dropout=dropout)\n",
    "    \n",
    "    def forward(self, inputs, prev_state, batch_first=False):\n",
    "        \n",
    "        spice_signals = self.init_forward_pass(inputs, prev_state, batch_first)\n",
    "        \n",
    "        # time-invariant participant features\n",
    "        participant_embeddings_1 = self.participant_embedding(spice_signals.participant_ids)\n",
    "        participant_embeddings_2 = self.participant_embedding(spice_signals.experiment_ids)\n",
    "        batch_size = spice_signals.actions.shape[1]\n",
    "        \n",
    "        # setup all variables\n",
    "        \n",
    "        # current actions\n",
    "        sig_action = spice_signals.actions[..., 0].unsqueeze(-1).repeat(1, 1, self.n_actions)  # make that a proper onehot-tensor; shape = (timesteps, batch, binary)\n",
    "        sig_grooming = spice_signals.actions[..., 1].unsqueeze(-1).repeat(1, 1, self.n_actions)\n",
    "        sig_non_contact = spice_signals.actions[..., 2].unsqueeze(-1).repeat(1, 1, self.n_actions)\n",
    "        sig_contact = spice_signals.actions[..., 3].unsqueeze(-1).repeat(1, 1, self.n_actions)\n",
    "        sig_scratch = spice_signals.actions[..., 4].unsqueeze(-1).repeat(1, 1, self.n_actions)\n",
    "        sig_waiting = spice_signals.actions[..., 5].unsqueeze(-1).repeat(1, 1, self.n_actions)\n",
    "        \n",
    "        # previous actions (t-1)\n",
    "        prev_action = torch.concat((\n",
    "            torch.zeros((1, batch_size, 1), device=self.device), \n",
    "            spice_signals.actions[:-1, :, 0].unsqueeze(-1),\n",
    "            )).repeat(1, 1, self.n_actions)\n",
    "        \n",
    "        prev_grooming = torch.concat((\n",
    "            torch.zeros((1, batch_size, 1), device=self.device), \n",
    "            spice_signals.actions[:-1, :, 1].unsqueeze(-1),\n",
    "            )).repeat(1, 1, self.n_actions)\n",
    "        \n",
    "        prev_non_contact = torch.concat((\n",
    "            torch.zeros((1, batch_size, 1), device=self.device), \n",
    "            spice_signals.actions[:-1, :, 2].unsqueeze(-1),\n",
    "            )).repeat(1, 1, self.n_actions)\n",
    "        \n",
    "        prev_contact = torch.concat((\n",
    "            torch.zeros((1, batch_size, 1), device=self.device), \n",
    "            spice_signals.actions[:-1, :, 3].unsqueeze(-1),\n",
    "            )).repeat(1, 1, self.n_actions)\n",
    "        \n",
    "        prev_scratch = torch.concat((\n",
    "            torch.zeros((1, batch_size, 1), device=self.device), \n",
    "            spice_signals.actions[:-1, :, 4].unsqueeze(-1),\n",
    "            )).repeat(1, 1, self.n_actions)\n",
    "        \n",
    "        prev_waiting = torch.concat((\n",
    "            torch.zeros((1, batch_size, 1), device=self.device), \n",
    "            spice_signals.actions[:-1, :, 5].unsqueeze(-1),\n",
    "            )).repeat(1, 1, self.n_actions)\n",
    "        \n",
    "        for timestep in spice_signals.timesteps:\n",
    "            \n",
    "            # update chosen value\n",
    "            self.call_module(\n",
    "                key_module='value_action',\n",
    "                key_state='values',\n",
    "                action_mask=torch.tensor((1, 0, 0, 0, 0, 0), device=self.device).reshape(1, -1).repeat(spice_signals.actions.shape[1], 1), \n",
    "                inputs=(\n",
    "                    spice_signals.actions[timestep],\n",
    "                    sig_action[timestep], \n",
    "                    sig_grooming[timestep], \n",
    "                    sig_non_contact[timestep], \n",
    "                    sig_contact[timestep], \n",
    "                    sig_scratch[timestep], \n",
    "                    sig_waiting[timestep], \n",
    "                    prev_action[timestep], \n",
    "                    prev_grooming[timestep], \n",
    "                    prev_non_contact[timestep], \n",
    "                    prev_contact[timestep], \n",
    "                    prev_scratch[timestep], \n",
    "                    prev_waiting[timestep],\n",
    "                    ),\n",
    "                participant_index=spice_signals.participant_ids,\n",
    "                participant_embedding=participant_embeddings_1,\n",
    "                experiment_index=spice_signals.experiment_ids,\n",
    "                experiment_embedding=participant_embeddings_2,\n",
    "            )\n",
    "            \n",
    "            self.call_module(\n",
    "                key_module='value_grooming',\n",
    "                key_state='values',\n",
    "                action_mask=torch.tensor((0, 1, 0, 0, 0, 0), device=self.device).reshape(1, -1).repeat(spice_signals.actions.shape[1], 1), # dummy-solution; make torch-tensor; reshape in \n",
    "                inputs=(\n",
    "                    spice_signals.actions[timestep],\n",
    "                    sig_action[timestep], \n",
    "                    sig_grooming[timestep], \n",
    "                    sig_non_contact[timestep], \n",
    "                    sig_contact[timestep], \n",
    "                    sig_scratch[timestep], \n",
    "                    sig_waiting[timestep], \n",
    "                    prev_action[timestep], \n",
    "                    prev_grooming[timestep], \n",
    "                    prev_non_contact[timestep], \n",
    "                    prev_contact[timestep], \n",
    "                    prev_scratch[timestep], \n",
    "                    prev_waiting[timestep],\n",
    "                    ),\n",
    "                participant_index=spice_signals.participant_ids,\n",
    "                participant_embedding=participant_embeddings_1,\n",
    "                experiment_index=spice_signals.experiment_ids,\n",
    "                experiment_embedding=participant_embeddings_2,\n",
    "            )\n",
    "            \n",
    "            self.call_module(\n",
    "                key_module='value_non_contact',\n",
    "                key_state='values',\n",
    "                action_mask=torch.tensor((0, 0, 1, 0, 0, 0), device=self.device).reshape(1, -1).repeat(spice_signals.actions.shape[1], 1), # dummy-solution; make torch-tensor; reshape in \n",
    "                inputs=(\n",
    "                    spice_signals.actions[timestep],\n",
    "                    sig_action[timestep], \n",
    "                    sig_grooming[timestep], \n",
    "                    sig_non_contact[timestep], \n",
    "                    sig_contact[timestep], \n",
    "                    sig_scratch[timestep], \n",
    "                    sig_waiting[timestep], \n",
    "                    prev_action[timestep], \n",
    "                    prev_grooming[timestep], \n",
    "                    prev_non_contact[timestep], \n",
    "                    prev_contact[timestep], \n",
    "                    prev_scratch[timestep], \n",
    "                    prev_waiting[timestep],\n",
    "                    ),\n",
    "                participant_index=spice_signals.participant_ids,\n",
    "                participant_embedding=participant_embeddings_1,\n",
    "                experiment_index=spice_signals.experiment_ids,\n",
    "                experiment_embedding=participant_embeddings_2,\n",
    "            )\n",
    "            \n",
    "            self.call_module(\n",
    "                key_module='value_contact',\n",
    "                key_state='values',\n",
    "                action_mask=torch.tensor((0, 0, 0, 1, 0, 0), device=self.device).reshape(1, -1).repeat(spice_signals.actions.shape[1], 1), # dummy-solution; make torch-tensor; reshape in \n",
    "                inputs=(\n",
    "                    spice_signals.actions[timestep],\n",
    "                    sig_action[timestep], \n",
    "                    sig_grooming[timestep], \n",
    "                    sig_non_contact[timestep], \n",
    "                    sig_contact[timestep], \n",
    "                    sig_scratch[timestep], \n",
    "                    sig_waiting[timestep], \n",
    "                    prev_action[timestep], \n",
    "                    prev_grooming[timestep], \n",
    "                    prev_non_contact[timestep], \n",
    "                    prev_contact[timestep], \n",
    "                    prev_scratch[timestep], \n",
    "                    prev_waiting[timestep],\n",
    "                    ),\n",
    "                participant_index=spice_signals.participant_ids,\n",
    "                participant_embedding=participant_embeddings_1,\n",
    "                experiment_index=spice_signals.experiment_ids,\n",
    "                experiment_embedding=participant_embeddings_2,\n",
    "            )\n",
    "            \n",
    "            self.call_module(\n",
    "                key_module='value_scratch',\n",
    "                key_state='values',\n",
    "                action_mask=torch.tensor((0, 0, 0, 0, 1, 0), device=self.device).reshape(1, -1).repeat(spice_signals.actions.shape[1], 1), # dummy-solution; make torch-tensor; reshape in \n",
    "                inputs=(\n",
    "                    spice_signals.actions[timestep],\n",
    "                    sig_action[timestep], \n",
    "                    sig_grooming[timestep], \n",
    "                    sig_non_contact[timestep], \n",
    "                    sig_contact[timestep], \n",
    "                    sig_scratch[timestep], \n",
    "                    sig_waiting[timestep], \n",
    "                    prev_action[timestep], \n",
    "                    prev_grooming[timestep], \n",
    "                    prev_non_contact[timestep], \n",
    "                    prev_contact[timestep], \n",
    "                    prev_scratch[timestep], \n",
    "                    prev_waiting[timestep],\n",
    "                    ),\n",
    "                participant_index=spice_signals.participant_ids,\n",
    "                participant_embedding=participant_embeddings_1,\n",
    "                experiment_index=spice_signals.experiment_ids,\n",
    "                experiment_embedding=participant_embeddings_2,\n",
    "            )\n",
    "            \n",
    "            self.call_module(\n",
    "                key_module='value_waiting',\n",
    "                key_state='values',\n",
    "                action_mask=torch.tensor((0, 0, 0, 0, 0, 1), device=self.device).reshape(1, -1).repeat(spice_signals.actions.shape[1], 1), # dummy-solution; make torch-tensor; reshape in \n",
    "                inputs=(\n",
    "                    spice_signals.actions[timestep],\n",
    "                    sig_action[timestep], \n",
    "                    sig_grooming[timestep], \n",
    "                    sig_non_contact[timestep], \n",
    "                    sig_contact[timestep], \n",
    "                    sig_scratch[timestep], \n",
    "                    sig_waiting[timestep], \n",
    "                    prev_action[timestep], \n",
    "                    prev_grooming[timestep], \n",
    "                    prev_non_contact[timestep], \n",
    "                    prev_contact[timestep], \n",
    "                    prev_scratch[timestep], \n",
    "                    prev_waiting[timestep],\n",
    "                    ),\n",
    "                participant_index=spice_signals.participant_ids,\n",
    "                participant_embedding=participant_embeddings_1,\n",
    "                experiment_index=spice_signals.experiment_ids,\n",
    "                experiment_embedding=participant_embeddings_2,\n",
    "            )\n",
    "            \n",
    "            spice_signals.logits[timestep] = self.state['values']\n",
    "            \n",
    "        spice_signals = self.post_forward_pass(spice_signals, batch_first)\n",
    "        \n",
    "        return spice_signals.logits, self.get_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's setup now the `SpiceEstimator` object and fit it to the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "id": "3EnmDiUMWq6e",
    "outputId": "e53b1bbd-4173-4d2c-bcdc-15832bc31bd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training (ep10_warm100_th0.05_alpha0.01) on cuda...\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "SPICE Training Configuration:\n",
      "\tSPICE joint training: active\n",
      "\tSINDy-only training: active\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Stage 1: SPICE joint training\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 1/10 --- L(Train): 1.8347378 --- L(Val, RNN): 1.7989613 --- L(Val, SINDy): 1.8014894 --- Time: 3.83s; --- Convergence: 8.99e-01\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 90):\n",
      "value_action[t+1]      = 0.008 1 + 0.992 value_action[t] + 0.008 chosen + -0.008 sig_action + 0.008 sig_grooming + -0.009 sig_non_contact + -0.009 sig_contact + 0.009 sig_scratch + -0.009 sig_waiting + -0.008 prev_action + -0.008 prev_grooming + 0.008 prev_non_contact + -0.008 prev_contact + 0.009 prev_scratch + 0.007 prev_waiting \n",
      "value_grooming[t+1]    = 0.008 1 + 0.991 value_grooming[t] + 0.008 chosen + 0.007 sig_action + 0.008 sig_grooming + 0.008 sig_non_contact + -0.007 sig_contact + -0.008 sig_scratch + -0.007 sig_waiting + -0.009 prev_action + 0.009 prev_grooming + 0.009 prev_non_contact + 0.009 prev_contact + -0.008 prev_scratch + -0.007 prev_waiting \n",
      "value_non_contact[t+1] = -0.008 1 + 0.991 value_non_contact[t] + -0.008 chosen + -0.008 sig_action + -0.008 sig_grooming + 0.009 sig_non_contact + -0.008 sig_contact + 0.009 sig_scratch + -0.009 sig_waiting + -0.009 prev_action + 0.008 prev_grooming + -0.008 prev_non_contact + 0.009 prev_contact + 0.008 prev_scratch + 0.008 prev_waiting \n",
      "value_contact[t+1]     = -0.008 1 + 0.991 value_contact[t] + 0.008 chosen + -0.007 sig_action + 0.009 sig_grooming + -0.008 sig_non_contact + -0.009 sig_contact + -0.009 sig_scratch + -0.009 sig_waiting + -0.009 prev_action + 0.009 prev_grooming + -0.009 prev_non_contact + -0.008 prev_contact + 0.008 prev_scratch + 0.009 prev_waiting \n",
      "value_scratch[t+1]     = -0.008 1 + 1.009 value_scratch[t] + -0.009 chosen + 0.009 sig_action + 0.008 sig_grooming + -0.009 sig_non_contact + 0.009 sig_contact + -0.009 sig_scratch + 0.007 sig_waiting + 0.009 prev_action + 0.007 prev_grooming + -0.009 prev_non_contact + -0.009 prev_contact + -0.009 prev_scratch + 0.008 prev_waiting \n",
      "value_waiting[t+1]     = -0.008 1 + 1.009 value_waiting[t] + -0.008 chosen + -0.009 sig_action + -0.008 sig_grooming + -0.009 sig_non_contact + -0.008 sig_contact + -0.008 sig_scratch + 0.008 sig_waiting + -0.008 prev_action + 0.009 prev_grooming + 0.009 prev_non_contact + -0.007 prev_contact + 0.009 prev_scratch + 0.008 prev_waiting \n",
      "--------------------------------------------------------------------------------\n",
      "Pruning patience:\n",
      "value_action:      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_grooming:    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_contact:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_scratch:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_waiting:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "--------------------------------------------------------------------------------\n",
      "Term presence across SPICE models (number of models=1764):\n",
      "value_action:      1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_grooming:    1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_non_contact: 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_contact:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_scratch:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_waiting:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 2/10 --- L(Train): 1.8026329 --- L(Val, RNN): 1.7815778 --- L(Val, SINDy): 1.8003930 --- Time: 2.75s; --- Convergence: 4.58e-01\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 90):\n",
      "value_action[t+1]      = 0.007 1 + 0.992 value_action[t] + 0.008 chosen + -0.007 sig_action + 0.008 sig_grooming + -0.008 sig_non_contact + -0.009 sig_contact + 0.008 sig_scratch + -0.008 sig_waiting + -0.007 prev_action + -0.008 prev_grooming + 0.007 prev_non_contact + -0.008 prev_contact + 0.008 prev_scratch + 0.007 prev_waiting \n",
      "value_grooming[t+1]    = 0.008 1 + 0.991 value_grooming[t] + 0.008 chosen + 0.007 sig_action + 0.008 sig_grooming + 0.007 sig_non_contact + -0.007 sig_contact + -0.007 sig_scratch + -0.007 sig_waiting + -0.008 prev_action + 0.008 prev_grooming + 0.008 prev_non_contact + 0.008 prev_contact + -0.008 prev_scratch + -0.007 prev_waiting \n",
      "value_non_contact[t+1] = -0.008 1 + 0.992 value_non_contact[t] + -0.008 chosen + -0.008 sig_action + -0.008 sig_grooming + 0.008 sig_non_contact + -0.007 sig_contact + 0.009 sig_scratch + -0.008 sig_waiting + -0.008 prev_action + 0.007 prev_grooming + -0.007 prev_non_contact + 0.008 prev_contact + 0.008 prev_scratch + 0.008 prev_waiting \n",
      "value_contact[t+1]     = -0.007 1 + 0.991 value_contact[t] + 0.008 chosen + -0.007 sig_action + 0.008 sig_grooming + -0.008 sig_non_contact + -0.009 sig_contact + -0.008 sig_scratch + -0.008 sig_waiting + -0.009 prev_action + 0.008 prev_grooming + -0.008 prev_non_contact + -0.008 prev_contact + 0.008 prev_scratch + 0.009 prev_waiting \n",
      "value_scratch[t+1]     = -0.008 1 + 1.008 value_scratch[t] + -0.009 chosen + 0.008 sig_action + 0.007 sig_grooming + -0.008 sig_non_contact + 0.008 sig_contact + -0.008 sig_scratch + 0.007 sig_waiting + 0.008 prev_action + 0.006 prev_grooming + -0.008 prev_non_contact + -0.009 prev_contact + -0.009 prev_scratch + 0.008 prev_waiting \n",
      "value_waiting[t+1]     = -0.008 1 + 1.008 value_waiting[t] + -0.008 chosen + -0.008 sig_action + -0.008 sig_grooming + -0.009 sig_non_contact + -0.007 sig_contact + -0.008 sig_scratch + 0.008 sig_waiting + -0.008 prev_action + 0.008 prev_grooming + 0.009 prev_non_contact + -0.007 prev_contact + 0.008 prev_scratch + 0.008 prev_waiting \n",
      "--------------------------------------------------------------------------------\n",
      "Pruning patience:\n",
      "value_action:      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_grooming:    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_contact:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_scratch:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_waiting:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "--------------------------------------------------------------------------------\n",
      "Term presence across SPICE models (number of models=1764):\n",
      "value_action:      1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_grooming:    1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_non_contact: 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_contact:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_scratch:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_waiting:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 3/10 --- L(Train): 1.7829417 --- L(Val, RNN): 1.7719496 --- L(Val, SINDy): 1.7949338 --- Time: 2.84s; --- Convergence: 2.34e-01\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 90):\n",
      "value_action[t+1]      = 0.003 1 + 0.996 value_action[t] + 0.004 chosen + -0.003 sig_action + 0.004 sig_grooming + -0.005 sig_non_contact + -0.005 sig_contact + 0.004 sig_scratch + -0.004 sig_waiting + -0.004 prev_action + -0.004 prev_grooming + 0.004 prev_non_contact + -0.004 prev_contact + 0.005 prev_scratch + 0.003 prev_waiting \n",
      "value_grooming[t+1]    = 0.005 1 + 0.995 value_grooming[t] + 0.004 chosen + 0.003 sig_action + 0.004 sig_grooming + 0.003 sig_non_contact + -0.003 sig_contact + -0.004 sig_scratch + -0.003 sig_waiting + -0.005 prev_action + 0.004 prev_grooming + 0.005 prev_non_contact + 0.004 prev_contact + -0.004 prev_scratch + -0.003 prev_waiting \n",
      "value_non_contact[t+1] = -0.005 1 + 0.995 value_non_contact[t] + -0.004 chosen + -0.004 sig_action + -0.004 sig_grooming + 0.005 sig_non_contact + -0.004 sig_contact + 0.005 sig_scratch + -0.004 sig_waiting + -0.005 prev_action + 0.004 prev_grooming + -0.004 prev_non_contact + 0.005 prev_contact + 0.004 prev_scratch + 0.004 prev_waiting \n",
      "value_contact[t+1]     = -0.004 1 + 0.995 value_contact[t] + 0.004 chosen + -0.003 sig_action + 0.005 sig_grooming + -0.004 sig_non_contact + -0.005 sig_contact + -0.004 sig_scratch + -0.005 sig_waiting + -0.005 prev_action + 0.005 prev_grooming + -0.004 prev_non_contact + -0.004 prev_contact + 0.004 prev_scratch + 0.005 prev_waiting \n",
      "value_scratch[t+1]     = -0.004 1 + 1.004 value_scratch[t] + -0.005 chosen + 0.005 sig_action + 0.004 sig_grooming + -0.005 sig_non_contact + 0.005 sig_contact + -0.004 sig_scratch + 0.003 sig_waiting + 0.004 prev_action + 0.003 prev_grooming + -0.005 prev_non_contact + -0.005 prev_contact + -0.005 prev_scratch + 0.004 prev_waiting \n",
      "value_waiting[t+1]     = -0.004 1 + 1.004 value_waiting[t] + -0.004 chosen + -0.005 sig_action + -0.004 sig_grooming + -0.005 sig_non_contact + -0.003 sig_contact + -0.004 sig_scratch + 0.004 sig_waiting + -0.004 prev_action + 0.005 prev_grooming + 0.005 prev_non_contact + -0.003 prev_contact + 0.004 prev_scratch + 0.004 prev_waiting \n",
      "--------------------------------------------------------------------------------\n",
      "Pruning patience:\n",
      "value_action:      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_grooming:    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_contact:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_scratch:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_waiting:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "--------------------------------------------------------------------------------\n",
      "Term presence across SPICE models (number of models=1764):\n",
      "value_action:      1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_grooming:    1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_non_contact: 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_contact:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_scratch:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_waiting:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 4/10 --- L(Train): 1.7745845 --- L(Val, RNN): 1.7655075 --- L(Val, SINDy): 1.7913854 --- Time: 2.75s; --- Convergence: 1.20e-01\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 90):\n",
      "value_action[t+1]      = -0.002 1 + 1.001 value_action[t] + -0.001 chosen + 0.002 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
      "value_grooming[t+1]    = -0.0 1 + 1.0 value_grooming[t] + -0.001 chosen + -0.002 sig_action + -0.001 sig_grooming + -0.002 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
      "value_non_contact[t+1] = -0.0 1 + 1.001 value_non_contact[t] + 0.001 chosen + 0.001 sig_action + 0.001 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
      "value_contact[t+1]     = 0.001 1 + 1.0 value_contact[t] + -0.001 chosen + 0.002 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
      "value_scratch[t+1]     = 0.001 1 + 0.999 value_scratch[t] + 0.0 chosen + -0.001 sig_action + -0.002 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + -0.003 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
      "value_waiting[t+1]     = 0.001 1 + 0.998 value_waiting[t] + 0.001 chosen + 0.001 sig_action + 0.001 sig_grooming + 0.0 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
      "--------------------------------------------------------------------------------\n",
      "Pruning patience:\n",
      "value_action:      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_grooming:    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_contact:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_scratch:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_waiting:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "--------------------------------------------------------------------------------\n",
      "Term presence across SPICE models (number of models=1764):\n",
      "value_action:      1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_grooming:    1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_non_contact: 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_contact:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_scratch:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_waiting:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 5/10 --- L(Train): 1.7668452 --- L(Val, RNN): 1.7604097 --- L(Val, SINDy): 1.7907273 --- Time: 2.70s; --- Convergence: 6.27e-02\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 90):\n",
      "value_action[t+1]      = -0.004 1 + 1.003 value_action[t] + -0.003 chosen + 0.004 sig_action + -0.003 sig_grooming + 0.002 sig_non_contact + 0.002 sig_contact + -0.003 sig_scratch + 0.003 sig_waiting + 0.003 prev_action + 0.003 prev_grooming + -0.004 prev_non_contact + 0.003 prev_contact + -0.002 prev_scratch + -0.004 prev_waiting \n",
      "value_grooming[t+1]    = -0.001 1 + 1.002 value_grooming[t] + -0.003 chosen + -0.004 sig_action + -0.003 sig_grooming + -0.004 sig_non_contact + 0.004 sig_contact + 0.003 sig_scratch + 0.004 sig_waiting + 0.003 prev_action + -0.003 prev_grooming + -0.002 prev_non_contact + -0.003 prev_contact + 0.003 prev_scratch + 0.004 prev_waiting \n",
      "value_non_contact[t+1] = 0.006 1 + 1.002 value_non_contact[t] + 0.003 chosen + 0.003 sig_action + 0.003 sig_grooming + -0.002 sig_non_contact + 0.004 sig_contact + -0.002 sig_scratch + 0.003 sig_waiting + 0.002 prev_action + -0.003 prev_grooming + 0.003 prev_non_contact + -0.003 prev_contact + -0.003 prev_scratch + -0.003 prev_waiting \n",
      "value_contact[t+1]     = 0.002 1 + 1.006 value_contact[t] + -0.003 chosen + 0.004 sig_action + -0.003 sig_grooming + 0.003 sig_non_contact + 0.002 sig_contact + 0.003 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + 0.003 prev_non_contact + 0.003 prev_contact + -0.003 prev_scratch + -0.002 prev_waiting \n",
      "value_scratch[t+1]     = 0.002 1 + 0.997 value_scratch[t] + 0.002 chosen + -0.002 sig_action + -0.003 sig_grooming + 0.002 sig_non_contact + -0.002 sig_contact + 0.003 sig_scratch + -0.004 sig_waiting + -0.003 prev_action + -0.004 prev_grooming + 0.002 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.003 prev_waiting \n",
      "value_waiting[t+1]     = 0.003 1 + 0.995 value_waiting[t] + 0.003 chosen + 0.003 sig_action + 0.003 sig_grooming + 0.002 sig_non_contact + 0.004 sig_contact + 0.003 sig_scratch + -0.003 sig_waiting + 0.003 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + 0.004 prev_contact + -0.003 prev_scratch + -0.003 prev_waiting \n",
      "--------------------------------------------------------------------------------\n",
      "Pruning patience:\n",
      "value_action:      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_grooming:    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_contact:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_scratch:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_waiting:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "--------------------------------------------------------------------------------\n",
      "Term presence across SPICE models (number of models=1764):\n",
      "value_action:      1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_grooming:    1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_non_contact: 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_contact:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_scratch:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_waiting:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 6/10 --- L(Train): 1.7611531 --- L(Val, RNN): 1.7584198 --- L(Val, SINDy): 1.7900356 --- Time: 2.73s; --- Convergence: 3.23e-02\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 90):\n",
      "value_action[t+1]      = -0.004 1 + 1.002 value_action[t] + -0.002 chosen + 0.003 sig_action + -0.002 sig_grooming + 0.002 sig_non_contact + 0.002 sig_contact + -0.002 sig_scratch + 0.002 sig_waiting + 0.003 prev_action + 0.002 prev_grooming + -0.003 prev_non_contact + 0.003 prev_contact + -0.002 prev_scratch + -0.003 prev_waiting \n",
      "value_grooming[t+1]    = -0.001 1 + 1.001 value_grooming[t] + -0.002 chosen + -0.003 sig_action + -0.003 sig_grooming + -0.003 sig_non_contact + 0.004 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + -0.002 prev_contact + 0.003 prev_scratch + 0.004 prev_waiting \n",
      "value_non_contact[t+1] = 0.008 1 + 1.002 value_non_contact[t] + 0.002 chosen + 0.003 sig_action + 0.002 sig_grooming + -0.002 sig_non_contact + 0.003 sig_contact + -0.002 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + -0.003 prev_grooming + 0.003 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + -0.002 prev_waiting \n",
      "value_contact[t+1]     = 0.002 1 + 1.008 value_contact[t] + -0.002 chosen + 0.003 sig_action + -0.002 sig_grooming + 0.002 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + 0.003 prev_contact + -0.003 prev_scratch + -0.002 prev_waiting \n",
      "value_scratch[t+1]     = 0.001 1 + 0.997 value_scratch[t] + 0.002 chosen + -0.002 sig_action + -0.003 sig_grooming + 0.002 sig_non_contact + -0.002 sig_contact + 0.002 sig_scratch + -0.003 sig_waiting + -0.002 prev_action + -0.004 prev_grooming + 0.002 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
      "value_waiting[t+1]     = 0.003 1 + 0.995 value_waiting[t] + 0.002 chosen + 0.002 sig_action + 0.002 sig_grooming + 0.002 sig_non_contact + 0.003 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.004 prev_contact + -0.002 prev_scratch + -0.002 prev_waiting \n",
      "--------------------------------------------------------------------------------\n",
      "Pruning patience:\n",
      "value_action:      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_grooming:    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_contact:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_scratch:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_waiting:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "--------------------------------------------------------------------------------\n",
      "Term presence across SPICE models (number of models=1764):\n",
      "value_action:      1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_grooming:    1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_non_contact: 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_contact:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_scratch:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_waiting:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 7/10 --- L(Train): 1.7596172 --- L(Val, RNN): 1.7572628 --- L(Val, SINDy): 1.7898475 --- Time: 2.88s; --- Convergence: 1.67e-02\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 90):\n",
      "value_action[t+1]      = -0.002 1 + 1.0 value_action[t] + -0.0 chosen + 0.001 sig_action + 0.0 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
      "value_grooming[t+1]    = 0.002 1 + 0.999 value_grooming[t] + -0.0 chosen + -0.001 sig_action + -0.0 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
      "value_non_contact[t+1] = 0.007 1 + 1.0 value_non_contact[t] + 0.0 chosen + 0.0 sig_action + 0.0 sig_grooming + 0.0 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
      "value_contact[t+1]     = -0.001 1 + 1.009 value_contact[t] + -0.0 chosen + 0.001 sig_action + 0.0 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
      "value_scratch[t+1]     = -0.001 1 + 1.0 value_scratch[t] + -0.001 chosen + 0.0 sig_action + -0.001 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
      "value_waiting[t+1]     = 0.002 1 + 0.997 value_waiting[t] + 0.0 chosen + -0.0 sig_action + 0.0 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
      "--------------------------------------------------------------------------------\n",
      "Pruning patience:\n",
      "value_action:      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_grooming:    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_contact:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_scratch:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_waiting:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "--------------------------------------------------------------------------------\n",
      "Term presence across SPICE models (number of models=1764):\n",
      "value_action:      1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_grooming:    1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_non_contact: 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_contact:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_scratch:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_waiting:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 8/10 --- L(Train): 1.7579584 --- L(Val, RNN): 1.7561297 --- L(Val, SINDy): 1.7918477 --- Time: 2.15s; --- Convergence: 8.94e-03\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 90):\n",
      "value_action[t+1]      = 0.001 1 + 0.997 value_action[t] + 0.003 chosen + -0.003 sig_action + 0.0 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + -0.003 prev_action + -0.0 prev_grooming + 0.003 prev_non_contact + -0.003 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
      "value_grooming[t+1]    = 0.002 1 + 0.999 value_grooming[t] + 0.003 chosen + 0.002 sig_action + 0.003 sig_grooming + 0.003 sig_non_contact + -0.002 sig_contact + -0.003 sig_scratch + -0.002 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.003 prev_scratch + -0.002 prev_waiting \n",
      "value_non_contact[t+1] = 0.005 1 + 1.0 value_non_contact[t] + -0.003 chosen + -0.003 sig_action + -0.003 sig_grooming + 0.001 sig_non_contact + -0.003 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + 0.003 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + 0.003 prev_scratch + 0.003 prev_waiting \n",
      "value_contact[t+1]     = -0.001 1 + 1.007 value_contact[t] + 0.003 chosen + -0.002 sig_action + 0.0 sig_grooming + -0.003 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + -0.003 prev_contact + 0.003 prev_scratch + 0.001 prev_waiting \n",
      "value_scratch[t+1]     = -0.002 1 + 1.003 value_scratch[t] + -0.001 chosen + 0.001 sig_action + 0.003 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.003 prev_waiting \n",
      "value_waiting[t+1]     = -0.001 1 + 1.0 value_waiting[t] + -0.003 chosen + -0.001 sig_action + -0.003 sig_grooming + -0.001 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + 0.0 prev_scratch + 0.003 prev_waiting \n",
      "--------------------------------------------------------------------------------\n",
      "Pruning patience:\n",
      "value_action:      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_grooming:    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_contact:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_scratch:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_waiting:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "--------------------------------------------------------------------------------\n",
      "Term presence across SPICE models (number of models=1764):\n",
      "value_action:      1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_grooming:    1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_non_contact: 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_contact:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_scratch:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_waiting:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 9/10 --- L(Train): 1.7573440 --- L(Val, RNN): 1.7550390 --- L(Val, SINDy): 1.7933007 --- Time: 2.26s; --- Convergence: 5.01e-03\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 90):\n",
      "value_action[t+1]      = 0.003 1 + 0.995 value_action[t] + 0.005 chosen + -0.004 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.004 prev_action + 0.001 prev_grooming + 0.004 prev_non_contact + -0.004 prev_contact + -0.001 prev_scratch + 0.004 prev_waiting \n",
      "value_grooming[t+1]    = 0.001 1 + 1.0 value_grooming[t] + 0.005 chosen + 0.004 sig_action + 0.004 sig_grooming + 0.004 sig_non_contact + -0.004 sig_contact + -0.004 sig_scratch + -0.004 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.004 prev_scratch + -0.003 prev_waiting \n",
      "value_non_contact[t+1] = 0.002 1 + 1.001 value_non_contact[t] + -0.005 chosen + -0.005 sig_action + -0.005 sig_grooming + -0.001 sig_non_contact + -0.004 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.004 prev_grooming + -0.004 prev_non_contact + -0.001 prev_contact + 0.005 prev_scratch + 0.005 prev_waiting \n",
      "value_contact[t+1]     = 0.0 1 + 1.004 value_contact[t] + 0.005 chosen + -0.004 sig_action + -0.001 sig_grooming + -0.005 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.004 prev_contact + 0.005 prev_scratch + -0.0 prev_waiting \n",
      "value_scratch[t+1]     = -0.002 1 + 1.004 value_scratch[t] + 0.0 chosen + -0.001 sig_action + 0.004 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.004 sig_waiting + -0.001 prev_action + 0.003 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.005 prev_waiting \n",
      "value_waiting[t+1]     = -0.001 1 + 1.004 value_waiting[t] + -0.005 chosen + 0.001 sig_action + -0.005 sig_grooming + 0.0 sig_non_contact + -0.004 sig_contact + -0.005 sig_scratch + 0.005 sig_waiting + -0.005 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.004 prev_contact + -0.001 prev_scratch + 0.005 prev_waiting \n",
      "--------------------------------------------------------------------------------\n",
      "Pruning patience:\n",
      "value_action:      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_grooming:    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_contact:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_scratch:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_waiting:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "--------------------------------------------------------------------------------\n",
      "Term presence across SPICE models (number of models=1764):\n",
      "value_action:      1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_grooming:    1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_non_contact: 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_contact:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_scratch:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_waiting:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 10/10 --- L(Train): 1.7562835 --- L(Val, RNN): 1.7540078 --- L(Val, SINDy): 1.7929916 --- Time: 2.21s; --- Convergence: 3.02e-03\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 90):\n",
      "value_action[t+1]      = 0.002 1 + 0.995 value_action[t] + 0.005 chosen + -0.004 sig_action + -0.001 sig_grooming + 0.0 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.004 prev_action + 0.001 prev_grooming + 0.004 prev_non_contact + -0.004 prev_contact + -0.0 prev_scratch + 0.003 prev_waiting \n",
      "value_grooming[t+1]    = -0.001 1 + 1.002 value_grooming[t] + 0.005 chosen + 0.004 sig_action + 0.004 sig_grooming + 0.004 sig_non_contact + -0.003 sig_contact + -0.004 sig_scratch + -0.004 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.004 prev_scratch + -0.003 prev_waiting \n",
      "value_non_contact[t+1] = -0.003 1 + 1.001 value_non_contact[t] + -0.005 chosen + -0.004 sig_action + -0.004 sig_grooming + -0.0 sig_non_contact + -0.004 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.004 prev_grooming + -0.004 prev_non_contact + -0.001 prev_contact + 0.004 prev_scratch + 0.004 prev_waiting \n",
      "value_contact[t+1]     = -0.0 1 + 1.0 value_contact[t] + 0.004 chosen + -0.003 sig_action + -0.001 sig_grooming + -0.004 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.004 prev_contact + 0.004 prev_scratch + -0.0 prev_waiting \n",
      "value_scratch[t+1]     = -0.0 1 + 1.004 value_scratch[t] + 0.0 chosen + -0.0 sig_action + 0.004 sig_grooming + 0.0 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + 0.004 sig_waiting + -0.001 prev_action + 0.003 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.004 prev_waiting \n",
      "value_waiting[t+1]     = 0.001 1 + 1.006 value_waiting[t] + -0.005 chosen + 0.0 sig_action + -0.004 sig_grooming + 0.0 sig_non_contact + -0.004 sig_contact + -0.004 sig_scratch + 0.004 sig_waiting + -0.004 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + -0.003 prev_contact + -0.001 prev_scratch + 0.005 prev_waiting \n",
      "--------------------------------------------------------------------------------\n",
      "Pruning patience:\n",
      "value_action:      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_grooming:    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_contact:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_scratch:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_waiting:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "--------------------------------------------------------------------------------\n",
      "Term presence across SPICE models (number of models=1764):\n",
      "value_action:      1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_grooming:    1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_non_contact: 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_contact:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_scratch:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_waiting:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "================================================================================\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "SINDy reset with confidence-filtered mask.\n",
      "\n",
      "================================================================================\n",
      "Starting SINDy finetuning...\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 1/10 --- L(Train): 0.0872989 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 90):\n",
      "value_action[t+1]      = 0.009 1 + 1.008 value_action[t] + 0.009 chosen + 0.009 sig_action + -0.008 sig_grooming + 0.01 sig_non_contact + -0.009 sig_contact + 0.009 sig_scratch + 0.009 sig_waiting + 0.009 prev_action + -0.009 prev_grooming + 0.008 prev_non_contact + 0.009 prev_contact + 0.009 prev_scratch + -0.009 prev_waiting \n",
      "value_grooming[t+1]    = 0.008 1 + 0.991 value_grooming[t] + 0.009 chosen + -0.009 sig_action + -0.01 sig_grooming + -0.009 sig_non_contact + -0.008 sig_contact + -0.009 sig_scratch + -0.01 sig_waiting + -0.009 prev_action + -0.009 prev_grooming + 0.009 prev_non_contact + -0.009 prev_contact + -0.01 prev_scratch + 0.009 prev_waiting \n",
      "value_non_contact[t+1] = 0.01 1 + 0.991 value_non_contact[t] + -0.009 chosen + -0.008 sig_action + -0.009 sig_grooming + 0.009 sig_non_contact + -0.009 sig_contact + -0.009 sig_scratch + -0.008 sig_waiting + 0.009 prev_action + 0.009 prev_grooming + -0.01 prev_non_contact + -0.01 prev_contact + -0.008 prev_scratch + -0.009 prev_waiting \n",
      "value_contact[t+1]     = -0.01 1 + 0.99 value_contact[t] + -0.009 chosen + -0.01 sig_action + 0.008 sig_grooming + 0.01 sig_non_contact + 0.009 sig_contact + 0.01 sig_scratch + -0.01 sig_waiting + 0.009 prev_action + 0.01 prev_grooming + 0.01 prev_non_contact + -0.009 prev_contact + -0.009 prev_scratch + 0.009 prev_waiting \n",
      "value_scratch[t+1]     = 0.01 1 + 1.008 value_scratch[t] + -0.009 chosen + 0.009 sig_action + -0.009 sig_grooming + 0.009 sig_non_contact + 0.009 sig_contact + -0.01 sig_scratch + -0.009 sig_waiting + -0.009 prev_action + 0.01 prev_grooming + 0.009 prev_non_contact + 0.01 prev_contact + 0.009 prev_scratch + 0.009 prev_waiting \n",
      "value_waiting[t+1]     = 0.01 1 + 1.009 value_waiting[t] + -0.009 chosen + -0.01 sig_action + 0.008 sig_grooming + 0.01 sig_non_contact + -0.01 sig_contact + -0.009 sig_scratch + -0.01 sig_waiting + -0.009 prev_action + 0.01 prev_grooming + -0.009 prev_non_contact + 0.01 prev_contact + -0.01 prev_scratch + -0.008 prev_waiting \n",
      "--------------------------------------------------------------------------------\n",
      "Pruning patience:\n",
      "value_action:      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_grooming:    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_contact:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_scratch:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_waiting:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "--------------------------------------------------------------------------------\n",
      "Term presence across SPICE models (number of models=1764):\n",
      "value_action:      1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_grooming:    1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_non_contact: 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_contact:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_scratch:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_waiting:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 2/10 --- L(Train): 0.0985785 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 90):\n",
      "value_action[t+1]      = 0.009 1 + 1.008 value_action[t] + 0.009 chosen + 0.008 sig_action + -0.008 sig_grooming + 0.009 sig_non_contact + -0.009 sig_contact + 0.009 sig_scratch + 0.009 sig_waiting + 0.009 prev_action + -0.008 prev_grooming + 0.008 prev_non_contact + 0.008 prev_contact + 0.009 prev_scratch + -0.009 prev_waiting \n",
      "value_grooming[t+1]    = 0.007 1 + 0.992 value_grooming[t] + 0.008 chosen + -0.008 sig_action + -0.009 sig_grooming + -0.009 sig_non_contact + -0.007 sig_contact + -0.008 sig_scratch + -0.009 sig_waiting + -0.009 prev_action + -0.008 prev_grooming + 0.008 prev_non_contact + -0.008 prev_contact + -0.009 prev_scratch + 0.009 prev_waiting \n",
      "value_non_contact[t+1] = 0.009 1 + 0.991 value_non_contact[t] + -0.008 chosen + -0.008 sig_action + -0.009 sig_grooming + 0.009 sig_non_contact + -0.008 sig_contact + -0.009 sig_scratch + -0.007 sig_waiting + 0.008 prev_action + 0.008 prev_grooming + -0.009 prev_non_contact + -0.009 prev_contact + -0.008 prev_scratch + -0.009 prev_waiting \n",
      "value_contact[t+1]     = -0.009 1 + 0.991 value_contact[t] + -0.009 chosen + -0.009 sig_action + 0.008 sig_grooming + 0.009 sig_non_contact + 0.008 sig_contact + 0.009 sig_scratch + -0.009 sig_waiting + 0.008 prev_action + 0.009 prev_grooming + 0.009 prev_non_contact + -0.009 prev_contact + -0.009 prev_scratch + 0.008 prev_waiting \n",
      "value_scratch[t+1]     = 0.009 1 + 1.008 value_scratch[t] + -0.009 chosen + 0.009 sig_action + -0.009 sig_grooming + 0.008 sig_non_contact + 0.008 sig_contact + -0.009 sig_scratch + -0.009 sig_waiting + -0.008 prev_action + 0.009 prev_grooming + 0.008 prev_non_contact + 0.009 prev_contact + 0.009 prev_scratch + 0.008 prev_waiting \n",
      "value_waiting[t+1]     = 0.009 1 + 1.008 value_waiting[t] + -0.008 chosen + -0.009 sig_action + 0.007 sig_grooming + 0.009 sig_non_contact + -0.009 sig_contact + -0.009 sig_scratch + -0.009 sig_waiting + -0.008 prev_action + 0.009 prev_grooming + -0.008 prev_non_contact + 0.009 prev_contact + -0.009 prev_scratch + -0.008 prev_waiting \n",
      "--------------------------------------------------------------------------------\n",
      "Pruning patience:\n",
      "value_action:      0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_grooming:    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_contact:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_scratch:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "value_waiting:     0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
      "--------------------------------------------------------------------------------\n",
      "Term presence across SPICE models (number of models=1764):\n",
      "value_action:      1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_grooming:    1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_non_contact: 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_contact:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_scratch:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_waiting:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 3/10 --- L(Train): 0.0949440 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 90):\n",
      "value_action[t+1]      = 0.005 1 + 1.004 value_action[t] + 0.005 chosen + 0.004 sig_action + -0.004 sig_grooming + 0.005 sig_non_contact + -0.005 sig_contact + 0.005 sig_scratch + 0.005 sig_waiting + 0.005 prev_action + -0.004 prev_grooming + 0.004 prev_non_contact + 0.004 prev_contact + 0.005 prev_scratch + -0.005 prev_waiting \n",
      "value_grooming[t+1]    = 0.003 1 + 0.996 value_grooming[t] + 0.004 chosen + -0.004 sig_action + -0.005 sig_grooming + -0.005 sig_non_contact + -0.003 sig_contact + -0.004 sig_scratch + -0.005 sig_waiting + -0.005 prev_action + -0.004 prev_grooming + 0.004 prev_non_contact + -0.004 prev_contact + -0.005 prev_scratch + 0.005 prev_waiting \n",
      "value_non_contact[t+1] = 0.005 1 + 0.995 value_non_contact[t] + -0.004 chosen + -0.004 sig_action + -0.005 sig_grooming + 0.005 sig_non_contact + -0.004 sig_contact + -0.005 sig_scratch + -0.003 sig_waiting + 0.004 prev_action + 0.004 prev_grooming + -0.005 prev_non_contact + -0.005 prev_contact + -0.004 prev_scratch + -0.005 prev_waiting \n",
      "value_contact[t+1]     = -0.005 1 + 0.995 value_contact[t] + -0.005 chosen + -0.005 sig_action + 0.004 sig_grooming + 0.005 sig_non_contact + 0.004 sig_contact + 0.005 sig_scratch + -0.005 sig_waiting + 0.004 prev_action + 0.005 prev_grooming + 0.005 prev_non_contact + -0.005 prev_contact + -0.005 prev_scratch + 0.004 prev_waiting \n",
      "value_scratch[t+1]     = 0.005 1 + 1.004 value_scratch[t] + -0.005 chosen + 0.005 sig_action + -0.005 sig_grooming + 0.004 sig_non_contact + 0.004 sig_contact + -0.005 sig_scratch + -0.005 sig_waiting + -0.004 prev_action + 0.005 prev_grooming + 0.004 prev_non_contact + 0.005 prev_contact + 0.005 prev_scratch + 0.004 prev_waiting \n",
      "value_waiting[t+1]     = 0.005 1 + 1.004 value_waiting[t] + -0.004 chosen + -0.005 sig_action + 0.003 sig_grooming + 0.005 sig_non_contact + -0.005 sig_contact + -0.005 sig_scratch + -0.005 sig_waiting + -0.004 prev_action + 0.005 prev_grooming + -0.004 prev_non_contact + 0.005 prev_contact + -0.005 prev_scratch + -0.004 prev_waiting \n",
      "--------------------------------------------------------------------------------\n",
      "Pruning patience:\n",
      "value_action:      1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
      "value_grooming:    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
      "value_non_contact: 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
      "value_contact:     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
      "value_scratch:     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
      "value_waiting:     1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
      "--------------------------------------------------------------------------------\n",
      "Term presence across SPICE models (number of models=1764):\n",
      "value_action:      1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_grooming:    1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_non_contact: 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_contact:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_scratch:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_waiting:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 4/10 --- L(Train): 0.0856536 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 90):\n",
      "value_action[t+1]      = -0.001 1 + 0.998 value_action[t] + -0.001 chosen + -0.002 sig_action + 0.002 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + -0.002 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
      "value_grooming[t+1]    = -0.003 1 + 1.001 value_grooming[t] + -0.002 chosen + 0.002 sig_action + 0.0 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
      "value_non_contact[t+1] = -0.001 1 + 1.001 value_non_contact[t] + 0.002 chosen + 0.002 sig_action + 0.001 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.003 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
      "value_contact[t+1]     = 0.001 1 + 1.001 value_contact[t] + 0.001 chosen + 0.0 sig_action + -0.002 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
      "value_scratch[t+1]     = -0.001 1 + 0.998 value_scratch[t] + 0.001 chosen + -0.001 sig_action + 0.001 sig_grooming + -0.001 sig_non_contact + -0.002 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
      "value_waiting[t+1]     = -0.001 1 + 0.998 value_waiting[t] + 0.001 chosen + 0.0 sig_action + -0.002 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
      "--------------------------------------------------------------------------------\n",
      "Pruning patience:\n",
      "value_action:      2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2\n",
      "value_grooming:    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2\n",
      "value_non_contact: 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2\n",
      "value_contact:     2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2\n",
      "value_scratch:     2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2\n",
      "value_waiting:     2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2\n",
      "--------------------------------------------------------------------------------\n",
      "Term presence across SPICE models (number of models=1764):\n",
      "value_action:      1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_grooming:    1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_non_contact: 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_contact:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_scratch:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_waiting:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 5/10 --- L(Train): 0.0774286 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 90):\n",
      "value_action[t+1]      = -0.003 1 + 0.996 value_action[t] + -0.003 chosen + -0.004 sig_action + 0.004 sig_grooming + -0.003 sig_non_contact + 0.003 sig_contact + -0.003 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + 0.003 prev_grooming + -0.004 prev_non_contact + -0.004 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
      "value_grooming[t+1]    = -0.005 1 + 1.003 value_grooming[t] + -0.004 chosen + 0.004 sig_action + 0.002 sig_grooming + 0.003 sig_non_contact + 0.004 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + 0.003 prev_action + 0.004 prev_grooming + -0.004 prev_non_contact + 0.004 prev_contact + 0.003 prev_scratch + -0.003 prev_waiting \n",
      "value_non_contact[t+1] = -0.002 1 + 1.003 value_non_contact[t] + 0.004 chosen + 0.004 sig_action + 0.003 sig_grooming + -0.003 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.005 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.002 prev_non_contact + 0.002 prev_contact + 0.004 prev_scratch + 0.003 prev_waiting \n",
      "value_contact[t+1]     = 0.003 1 + 1.003 value_contact[t] + 0.003 chosen + 0.002 sig_action + -0.004 sig_grooming + -0.002 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + 0.002 sig_waiting + -0.004 prev_action + -0.003 prev_grooming + -0.002 prev_non_contact + 0.003 prev_contact + 0.003 prev_scratch + -0.003 prev_waiting \n",
      "value_scratch[t+1]     = -0.002 1 + 0.996 value_scratch[t] + 0.003 chosen + -0.003 sig_action + 0.003 sig_grooming + -0.003 sig_non_contact + -0.004 sig_contact + 0.002 sig_scratch + 0.003 sig_waiting + 0.004 prev_action + -0.002 prev_grooming + -0.003 prev_non_contact + -0.003 prev_contact + -0.003 prev_scratch + -0.003 prev_waiting \n",
      "value_waiting[t+1]     = -0.002 1 + 0.997 value_waiting[t] + 0.003 chosen + 0.002 sig_action + -0.004 sig_grooming + -0.002 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + 0.003 prev_action + -0.003 prev_grooming + 0.004 prev_non_contact + -0.002 prev_contact + 0.003 prev_scratch + 0.004 prev_waiting \n",
      "--------------------------------------------------------------------------------\n",
      "Pruning patience:\n",
      "value_action:      3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3\n",
      "value_grooming:    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3\n",
      "value_non_contact: 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3\n",
      "value_contact:     3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3\n",
      "value_scratch:     3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3\n",
      "value_waiting:     3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3\n",
      "--------------------------------------------------------------------------------\n",
      "Term presence across SPICE models (number of models=1764):\n",
      "value_action:      1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_grooming:    1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_non_contact: 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_contact:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_scratch:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_waiting:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 6/10 --- L(Train): 0.0784080 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 90):\n",
      "value_action[t+1]      = -0.002 1 + 0.997 value_action[t] + -0.002 chosen + -0.003 sig_action + 0.003 sig_grooming + -0.002 sig_non_contact + 0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + 0.003 prev_grooming + -0.003 prev_non_contact + -0.003 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
      "value_grooming[t+1]    = -0.004 1 + 1.003 value_grooming[t] + -0.003 chosen + 0.003 sig_action + 0.002 sig_grooming + 0.002 sig_non_contact + 0.004 sig_contact + 0.003 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.003 prev_grooming + -0.003 prev_non_contact + 0.003 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
      "value_non_contact[t+1] = -0.002 1 + 1.002 value_non_contact[t] + 0.003 chosen + 0.003 sig_action + 0.002 sig_grooming + -0.002 sig_non_contact + 0.003 sig_contact + 0.002 sig_scratch + 0.004 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.002 prev_non_contact + 0.002 prev_contact + 0.003 prev_scratch + 0.002 prev_waiting \n",
      "value_contact[t+1]     = 0.002 1 + 1.002 value_contact[t] + 0.002 chosen + 0.002 sig_action + -0.003 sig_grooming + -0.002 sig_non_contact + -0.003 sig_contact + -0.002 sig_scratch + 0.002 sig_waiting + -0.003 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.003 prev_waiting \n",
      "value_scratch[t+1]     = -0.002 1 + 0.997 value_scratch[t] + 0.002 chosen + -0.002 sig_action + 0.002 sig_grooming + -0.003 sig_non_contact + -0.003 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + 0.003 prev_action + -0.002 prev_grooming + -0.003 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + -0.003 prev_waiting \n",
      "value_waiting[t+1]     = -0.002 1 + 0.997 value_waiting[t] + 0.003 chosen + 0.002 sig_action + -0.004 sig_grooming + -0.002 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + 0.003 prev_action + -0.002 prev_grooming + 0.003 prev_non_contact + -0.002 prev_contact + 0.002 prev_scratch + 0.003 prev_waiting \n",
      "--------------------------------------------------------------------------------\n",
      "Pruning patience:\n",
      "value_action:      4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4\n",
      "value_grooming:    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4\n",
      "value_non_contact: 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4\n",
      "value_contact:     4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4\n",
      "value_scratch:     4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4\n",
      "value_waiting:     4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4\n",
      "--------------------------------------------------------------------------------\n",
      "Term presence across SPICE models (number of models=1764):\n",
      "value_action:      1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_grooming:    1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_non_contact: 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_contact:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_scratch:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_waiting:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 7/10 --- L(Train): 0.0752297 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 90):\n",
      "value_action[t+1]      = -0.0 1 + 0.999 value_action[t] + 0.0 chosen + -0.001 sig_action + 0.001 sig_grooming + 0.0 sig_non_contact + -0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
      "value_grooming[t+1]    = -0.002 1 + 1.0 value_grooming[t] + -0.0 chosen + 0.001 sig_action + -0.001 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
      "value_non_contact[t+1] = 0.001 1 + 1.0 value_non_contact[t] + 0.001 chosen + 0.001 sig_action + -0.0 sig_grooming + 0.0 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
      "value_contact[t+1]     = -0.0 1 + 1.0 value_contact[t] + -0.0 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
      "value_scratch[t+1]     = 0.001 1 + 0.999 value_scratch[t] + -0.0 chosen + -0.0 sig_action + 0.0 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
      "value_waiting[t+1]     = 0.001 1 + 1.0 value_waiting[t] + 0.0 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
      "--------------------------------------------------------------------------------\n",
      "Pruning patience:\n",
      "value_action:      5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5\n",
      "value_grooming:    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5\n",
      "value_non_contact: 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5\n",
      "value_contact:     5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5\n",
      "value_scratch:     5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5\n",
      "value_waiting:     5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5\n",
      "--------------------------------------------------------------------------------\n",
      "Term presence across SPICE models (number of models=1764):\n",
      "value_action:      1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_grooming:    1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_non_contact: 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_contact:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_scratch:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_waiting:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 8/10 --- L(Train): 0.0700088 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 90):\n",
      "value_action[t+1]      = 0.004 1 + 1.003 value_action[t] + 0.0 chosen + 0.003 sig_action + -0.003 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + -0.003 prev_grooming + 0.003 prev_non_contact + 0.003 prev_contact + 0.004 prev_scratch + -0.0 prev_waiting \n",
      "value_grooming[t+1]    = 0.002 1 + 0.996 value_grooming[t] + 0.003 chosen + -0.003 sig_action + -0.001 sig_grooming + -0.0 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + -0.003 prev_grooming + 0.003 prev_non_contact + -0.003 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
      "value_non_contact[t+1] = 0.001 1 + 1.0 value_non_contact[t] + -0.003 chosen + -0.003 sig_action + -0.0 sig_grooming + 0.001 sig_non_contact + -0.004 sig_contact + -0.004 sig_scratch + -0.002 sig_waiting + 0.003 prev_action + 0.004 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + -0.004 prev_waiting \n",
      "value_contact[t+1]     = -0.001 1 + 0.999 value_contact[t] + -0.0 chosen + -0.001 sig_action + 0.003 sig_grooming + 0.001 sig_non_contact + 0.004 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.003 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.004 prev_waiting \n",
      "value_scratch[t+1]     = 0.001 1 + 1.003 value_scratch[t] + -0.0 chosen + 0.004 sig_action + -0.004 sig_grooming + 0.004 sig_non_contact + 0.003 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.003 prev_action + 0.001 prev_grooming + 0.004 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + 0.004 prev_waiting \n",
      "value_waiting[t+1]     = 0.001 1 + 1.003 value_waiting[t] + -0.003 chosen + -0.001 sig_action + 0.002 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.003 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.003 prev_waiting \n",
      "--------------------------------------------------------------------------------\n",
      "Pruning patience:\n",
      "value_action:      6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6\n",
      "value_grooming:    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6\n",
      "value_non_contact: 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6\n",
      "value_contact:     6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6\n",
      "value_scratch:     6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6\n",
      "value_waiting:     6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6\n",
      "--------------------------------------------------------------------------------\n",
      "Term presence across SPICE models (number of models=1764):\n",
      "value_action:      1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_grooming:    1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_non_contact: 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_contact:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_scratch:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_waiting:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 9/10 --- L(Train): 0.0700215 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 90):\n",
      "value_action[t+1]      = 0.005 1 + 1.004 value_action[t] + -0.001 chosen + 0.005 sig_action + -0.005 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.005 prev_grooming + 0.004 prev_non_contact + 0.005 prev_contact + 0.005 prev_scratch + 0.001 prev_waiting \n",
      "value_grooming[t+1]    = 0.004 1 + 0.995 value_grooming[t] + 0.005 chosen + -0.005 sig_action + 0.0 sig_grooming + 0.001 sig_non_contact + -0.004 sig_contact + -0.005 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.005 prev_grooming + 0.005 prev_non_contact + -0.005 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
      "value_non_contact[t+1] = -0.001 1 + 1.001 value_non_contact[t] + -0.005 chosen + -0.005 sig_action + 0.001 sig_grooming + -0.001 sig_non_contact + -0.005 sig_contact + -0.005 sig_scratch + -0.004 sig_waiting + 0.005 prev_action + 0.005 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + -0.004 prev_scratch + -0.005 prev_waiting \n",
      "value_contact[t+1]     = 0.001 1 + 1.001 value_contact[t] + 0.001 chosen + 0.001 sig_action + 0.004 sig_grooming + -0.001 sig_non_contact + 0.005 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.005 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.005 prev_waiting \n",
      "value_scratch[t+1]     = -0.001 1 + 1.005 value_scratch[t] + 0.001 chosen + 0.005 sig_action + -0.005 sig_grooming + 0.005 sig_non_contact + 0.005 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.005 prev_action + -0.001 prev_grooming + 0.005 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.005 prev_waiting \n",
      "value_waiting[t+1]     = -0.001 1 + 1.005 value_waiting[t] + -0.005 chosen + 0.0 sig_action + 0.004 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.005 prev_action + -0.001 prev_grooming + -0.005 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.004 prev_waiting \n",
      "--------------------------------------------------------------------------------\n",
      "Pruning patience:\n",
      "value_action:      7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7\n",
      "value_grooming:    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7\n",
      "value_non_contact: 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7\n",
      "value_contact:     7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7\n",
      "value_scratch:     7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7\n",
      "value_waiting:     7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7\n",
      "--------------------------------------------------------------------------------\n",
      "Term presence across SPICE models (number of models=1764):\n",
      "value_action:      1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_grooming:    1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_non_contact: 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_contact:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_scratch:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_waiting:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 10/10 --- L(Train): 0.0691802 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 90):\n",
      "value_action[t+1]      = 0.005 1 + 1.004 value_action[t] + -0.001 chosen + 0.004 sig_action + -0.004 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.005 prev_grooming + 0.004 prev_non_contact + 0.004 prev_contact + 0.005 prev_scratch + 0.001 prev_waiting \n",
      "value_grooming[t+1]    = 0.003 1 + 0.995 value_grooming[t] + 0.005 chosen + -0.004 sig_action + 0.0 sig_grooming + 0.001 sig_non_contact + -0.004 sig_contact + -0.005 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + -0.005 prev_grooming + 0.004 prev_non_contact + -0.004 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
      "value_non_contact[t+1] = -0.0 1 + 1.001 value_non_contact[t] + -0.004 chosen + -0.004 sig_action + 0.001 sig_grooming + -0.001 sig_non_contact + -0.005 sig_contact + -0.005 sig_scratch + -0.003 sig_waiting + 0.005 prev_action + 0.005 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + -0.004 prev_scratch + -0.005 prev_waiting \n",
      "value_contact[t+1]     = 0.0 1 + 1.0 value_contact[t] + 0.001 chosen + 0.0 sig_action + 0.004 sig_grooming + -0.0 sig_non_contact + 0.005 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.004 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.005 prev_waiting \n",
      "value_scratch[t+1]     = -0.0 1 + 1.004 value_scratch[t] + 0.001 chosen + 0.005 sig_action + -0.005 sig_grooming + 0.005 sig_non_contact + 0.004 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + -0.004 prev_action + -0.0 prev_grooming + 0.005 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.005 prev_waiting \n",
      "value_waiting[t+1]     = -0.0 1 + 1.005 value_waiting[t] + -0.005 chosen + 0.0 sig_action + 0.004 sig_grooming + -0.0 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.005 prev_action + -0.0 prev_grooming + -0.004 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + -0.004 prev_waiting \n",
      "--------------------------------------------------------------------------------\n",
      "Pruning patience:\n",
      "value_action:      8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8\n",
      "value_grooming:    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8\n",
      "value_non_contact: 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8\n",
      "value_contact:     8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8\n",
      "value_scratch:     8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8\n",
      "value_waiting:     8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8\n",
      "--------------------------------------------------------------------------------\n",
      "Term presence across SPICE models (number of models=1764):\n",
      "value_action:      1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_grooming:    1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_non_contact: 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_contact:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_scratch:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_waiting:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 11/10 --- L(Train): 0.0668520 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 90):\n",
      "value_action[t+1]      = 0.003 1 + 1.002 value_action[t] + 0.001 chosen + 0.003 sig_action + -0.003 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.003 prev_grooming + 0.002 prev_non_contact + 0.003 prev_contact + 0.003 prev_scratch + -0.001 prev_waiting \n",
      "value_grooming[t+1]    = 0.002 1 + 0.997 value_grooming[t] + 0.003 chosen + -0.003 sig_action + -0.002 sig_grooming + -0.001 sig_non_contact + -0.002 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.003 prev_grooming + 0.003 prev_non_contact + -0.003 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
      "value_non_contact[t+1] = 0.001 1 + 0.999 value_non_contact[t] + -0.003 chosen + -0.003 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + -0.002 sig_waiting + 0.003 prev_action + 0.003 prev_grooming + -0.002 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + -0.003 prev_waiting \n",
      "value_contact[t+1]     = -0.001 1 + 0.999 value_contact[t] + -0.001 chosen + -0.002 sig_action + 0.002 sig_grooming + 0.002 sig_non_contact + 0.003 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + 0.003 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.003 prev_waiting \n",
      "value_scratch[t+1]     = 0.001 1 + 1.003 value_scratch[t] + -0.001 chosen + 0.003 sig_action + -0.003 sig_grooming + 0.003 sig_non_contact + 0.003 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + -0.003 prev_action + 0.002 prev_grooming + 0.003 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.003 prev_waiting \n",
      "value_waiting[t+1]     = 0.001 1 + 1.003 value_waiting[t] + -0.003 chosen + -0.002 sig_action + 0.002 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.003 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
      "--------------------------------------------------------------------------------\n",
      "Pruning patience:\n",
      "value_action:      9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9\n",
      "value_grooming:    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9\n",
      "value_non_contact: 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9\n",
      "value_contact:     9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9\n",
      "value_scratch:     9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9\n",
      "value_waiting:     9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9\n",
      "--------------------------------------------------------------------------------\n",
      "Term presence across SPICE models (number of models=1764):\n",
      "value_action:      1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_grooming:    1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_non_contact: 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_contact:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_scratch:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "value_waiting:     1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764, 1764\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Training results:\n",
      "\tL(Train, RNN): 1.7562835\n",
      "\tL(Val, RNN):   1.7540078\n",
      "\tL(Val, SINDy): 1.7627280\n",
      "================================================================================\n",
      "\n",
      "RNN training finished.\n",
      "Training took 28.74 seconds.\n",
      "Saving SPICE model to ../params/hwang2025/spice_ep10_warm100_th0.05_alpha0.01.pkl...\n",
      "================================================================================\n",
      "\n",
      "Training complete!\n",
      "\n",
      "Example SPICE model (participant 0):\n",
      "--------------------------------------------------------------------------------\n",
      "value_action[t+1]      = 0.003 1 + 1.002 value_action[t] + 0.001 chosen + 0.003 sig_action + -0.003 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.003 prev_grooming + 0.002 prev_non_contact + 0.003 prev_contact + 0.003 prev_scratch + -0.001 prev_waiting \n",
      "value_grooming[t+1]    = 0.002 1 + 0.997 value_grooming[t] + 0.003 chosen + -0.003 sig_action + -0.002 sig_grooming + -0.001 sig_non_contact + -0.002 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.003 prev_grooming + 0.003 prev_non_contact + -0.003 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
      "value_non_contact[t+1] = 0.001 1 + 0.999 value_non_contact[t] + -0.003 chosen + -0.003 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + -0.002 sig_waiting + 0.003 prev_action + 0.003 prev_grooming + -0.002 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + -0.003 prev_waiting \n",
      "value_contact[t+1]     = -0.001 1 + 0.999 value_contact[t] + -0.001 chosen + -0.002 sig_action + 0.002 sig_grooming + 0.002 sig_non_contact + 0.003 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + 0.003 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.003 prev_waiting \n",
      "value_scratch[t+1]     = 0.001 1 + 1.003 value_scratch[t] + -0.001 chosen + 0.003 sig_action + -0.003 sig_grooming + 0.003 sig_non_contact + 0.003 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + -0.003 prev_action + 0.002 prev_grooming + 0.003 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.003 prev_waiting \n",
      "value_waiting[t+1]     = 0.001 1 + 1.003 value_waiting[t] + -0.003 chosen + -0.002 sig_action + 0.002 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.003 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# if epochs==4000: warmup_steps=1000; sindy_weight=1;\n",
    "\n",
    "runs = [\n",
    "    (10, 100, 0.05, 1e-2),\n",
    "    #(1000, 100, 0.05, 1e-5),\n",
    "    #(1000, 100, 0.05, 1e-3),\n",
    "    #(1000, 100, 0.1, 1e-4),\n",
    "    #(1000, 100, 0.1, 1e-5),\n",
    "    #(1000, 100, 0.1, 1e-3),\n",
    "    #(4000, 1000, 0.05, 1e-4),\n",
    "    #(4000, 1000, 0.05, 1e-5),\n",
    "    #(4000, 1000, 0.05, 1e-3),\n",
    "    #(4000, 1000, 0.1, 1e-4),\n",
    "    #(4000, 1000, 0.1, 1e-5),\n",
    "    #(4000, 1000, 0.1, 1e-3),\n",
    "]\n",
    "\n",
    "for epochs, warmup_steps, sindy_threshold, sindy_alpha in runs:\n",
    "    exp_tag = f\"ep{epochs}_warm{warmup_steps}_th{sindy_threshold:g}_alpha{sindy_alpha:g}\"\n",
    "    save_path = f\"../params/hwang2025/spice_{exp_tag}.pkl\"\n",
    "\n",
    "    estimator = SpiceEstimator(\n",
    "            # model paramaeters\n",
    "            rnn_class=SPICERNN,\n",
    "            spice_config=spice_config,\n",
    "            n_actions=n_actions,\n",
    "            n_participants=n_participants,\n",
    "            n_experiments=n_participants,\n",
    "            \n",
    "            # rnn training parameters\n",
    "            epochs=epochs,  # --> try: 1000 --> 4000\n",
    "            warmup_steps=warmup_steps,  # if epochs==4000: warmup_steps=1000\n",
    "            l2_rnn=0,#.00001,\n",
    "            learning_rate=0.01,\n",
    "            \n",
    "            # sindy fitting parameters\n",
    "            sindy_weight=0.001,\n",
    "            sindy_pruning_threshold=sindy_threshold,  # try: 0.1\n",
    "            sindy_pruning_frequency=1,\n",
    "            sindy_pruning_terms=1,\n",
    "            sindy_pruning_patience=100,\n",
    "            sindy_epochs=10,\n",
    "            sindy_l2_lambda=sindy_alpha,  # try: 0.00001, 0.001\n",
    "            sindy_library_polynomial_degree=1,\n",
    "            \n",
    "            verbose=True,\n",
    "            device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "            save_path_spice=save_path,\n",
    "        )\n",
    "\n",
    "    #print(f\"\\nStarting training on {estimator.device}...\")\n",
    "    print(f\"\\nStarting training ({exp_tag}) on {estimator.device}...\")\n",
    "    print(\"=\" * 80)\n",
    "    estimator.fit(dataset_train.xs, dataset_train.ys, dataset_test.xs, dataset_test.ys)\n",
    "    # estimator.load_spice(args.model)\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\nTraining complete!\")\n",
    "\n",
    "    # Print example SPICE model for first participant\n",
    "    print(\"\\nExample SPICE model (participant 0):\")\n",
    "    print(\"-\" * 80)\n",
    "    estimator.print_spice_model(participant_id=0)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42, 42, 1, 15)\n"
     ]
    }
   ],
   "source": [
    "print(estimator.get_sindy_coefficients()['value_action'].shape)  # shape of coefficients: (ID1, ID2, Ensemble, Coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "\n",
    "estimator = SpiceEstimator(\n",
    "        # model paramaeters\n",
    "        rnn_class=SPICERNN,\n",
    "        spice_config=spice_config,\n",
    "        n_actions=6,\n",
    "        # n_items=6,\n",
    "        n_participants=n_participants,\n",
    "        n_experiments=1,\n",
    "            \n",
    "        # rnn training parameters\n",
    "        epochs=10,  # --> try: 1000 --> 4000\n",
    "        warmup_steps=10,  # if epochs==4000: warmup_steps=1000\n",
    "        l2_rnn=0.00001,\n",
    "        learning_rate=0.01,\n",
    "            \n",
    "        # sindy fitting parameters\n",
    "        sindy_weight=0.001,\n",
    "        sindy_threshold=0.05,  # try: 0.1\n",
    "        sindy_threshold_frequency=1,\n",
    "        sindy_threshold_terms=1,\n",
    "        sindy_cutoff_patience=100,\n",
    "        sindy_epochs=1000,\n",
    "        sindy_alpha=0.0001,  # try: 0.00001, 0.001\n",
    "        sindy_library_polynomial_degree=1,\n",
    "            \n",
    "        verbose=True,\n",
    "        device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "        save_path_spice=f\"../params/hwang2025/test.pkl\",\n",
    "    )\n",
    "\n",
    "    #print(f\"\\nStarting training on {estimator.device}...\")\n",
    "print(f\"\\nStarting training\")\n",
    "print(\"=\" * 80)\n",
    "estimator.fit(dataset_train.xs, dataset_train.ys, dataset_test.xs, dataset_test.ys)\n",
    "    # estimator.load_spice(args.model)\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nTraining complete!\")\n",
    "\n",
    "    # Print example SPICE model for first participant\n",
    "print(\"\\nExample SPICE model (participant 0):\")\n",
    "print(\"-\" * 80)\n",
    "estimator.print_spice_model(participant_id=0)\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = []\n",
    "for module in estimator.rnn_model.sindy_coefficients.keys():\n",
    "    coefs.append(estimator.rnn_model.sindy_coefficients[module].detach().numpy())\n",
    "coefs = np.concatenate(coefs, axis=-1)\n",
    "print(coefs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SPICE for Ape 0 -> Ape 2:\")\n",
    "estimator.print_spice_model(1)\n",
    "\n",
    "print(\"\\nSPICE for Ape 0 -> Ape 5:\")\n",
    "estimator.print_spice_model(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained model\n",
    "path_model = \"../params/hwang2025/spice_ep10_warm100_th0.05_alpha0.01.pkl\"\n",
    "\n",
    "estimator = SpiceEstimator(\n",
    "            # model paramaeters\n",
    "            rnn_class=SPICERNN,\n",
    "            spice_config=spice_config,\n",
    "            n_actions=6,\n",
    "            # n_items=6,\n",
    "            n_participants=n_participants,\n",
    "            n_experiments=1,\n",
    "            ensemble_size=1,\n",
    ")\n",
    "estimator.load_spice(path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.print_spice_model(participant_id=0)\n",
    "print(estimator.rnn_model.sindy_coefficients['value_action'][0, 0] * estimator.rnn_model.sindy_coefficients_presence['value_action'][0, 0])\n",
    "print(estimator.rnn_model.sindy_candidate_terms['value_action'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU for benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classic GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../..')\n",
    "from weinhardt2025.benchmarking.benchmarking_gru import GRU, training, setup_agent_gru\n",
    "\n",
    "path_gru = '../../weinhardt2025/params/hwang2025/gru_hwang2025.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "\n",
    "gru = GRU(n_actions=n_actions, additional_inputs=4).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(gru.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = training(\n",
    "    gru=gru,\n",
    "    optimizer=optimizer,\n",
    "    dataset_train=dataset_train,\n",
    "    dataset_test=dataset_test,\n",
    "    epochs=epochs,\n",
    "    )\n",
    "\n",
    "torch.save(gru.state_dict(), path_gru)\n",
    "print(\"Trained GRU parameters saved to \" + path_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_agent = setup_agent_gru(path_gru, gru)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU with participant embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUEmbed(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_actions, n_participants, additional_inputs: int = 0, hidden_size: int = 32, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gru_features = hidden_size\n",
    "        self.n_actions = n_actions\n",
    "        self.additional_inputs = additional_inputs\n",
    "        self.embed_size = 8\n",
    "        \n",
    "        self.embedding = torch.nn.Embedding(n_participants, self.embed_size)\n",
    "        \n",
    "        self.linear_in = torch.nn.Linear(in_features=n_actions+1+additional_inputs+2*self.embed_size, out_features=hidden_size)\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "        self.gru = torch.nn.GRU(input_size=hidden_size, hidden_size=hidden_size, batch_first=True)\n",
    "        self.linear_out = torch.nn.Linear(in_features=hidden_size, out_features=n_actions)\n",
    "        \n",
    "    def forward(self, inputs, state=None):\n",
    "        \n",
    "        id1 = inputs[..., 2*self.n_actions+1].nan_to_num(0).long()\n",
    "        id2 = inputs[..., 2*self.n_actions+2].nan_to_num(0).long()\n",
    "        \n",
    "        embed1 = self.embedding(id1)\n",
    "        embed2 = self.embedding(id2)\n",
    "        \n",
    "        actions = inputs[..., :self.n_actions]\n",
    "        rewards = inputs[..., self.n_actions:2*self.n_actions].nan_to_num(0).sum(dim=-1, keepdims=True)\n",
    "        additional_inputs = inputs[..., self.n_actions*2+2:self.n_actions*2+2+self.additional_inputs]\n",
    "        inputs = torch.concat((actions, rewards, additional_inputs, embed1, embed2), dim=-1)\n",
    "        \n",
    "        if state is not None and len(inputs.shape) == 3:\n",
    "            state = state.reshape(1, 1, self.gru_features)\n",
    "        \n",
    "        y = self.linear_in(inputs.nan_to_num(0))\n",
    "        y = self.dropout(y)\n",
    "        y, state = self.gru(y, state)\n",
    "        y = self.dropout(y)\n",
    "        y = self.linear_out(y)\n",
    "        return y, state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "\n",
    "path_gru_embed = '../../weinhardt2025/params/hwang2025/gruembed_hwang2025.pkl'\n",
    "gru_embed = GRUEmbed(n_actions=n_actions, additional_inputs=4, n_participants=n_participants).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(gru_embed.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = training(\n",
    "    gru=gru_embed,\n",
    "    optimizer=optimizer,\n",
    "    dataset_train=dataset_train,\n",
    "    dataset_test=dataset_test,\n",
    "    epochs=epochs,\n",
    "    )\n",
    "\n",
    "torch.save(gru_embed.state_dict(), path_gru)\n",
    "print(\"Trained GRU+Embedding parameters saved to \" + path_gru_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_embed_agent = setup_agent_gru(path_gru, gru)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot choice dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spice import plot_session\n",
    "\n",
    "# plotting\n",
    "session_id = 1\n",
    "\n",
    "# estimator.print_spice_model(participant_id)\n",
    "\n",
    "agents = {\n",
    "    # add baseline agent here\n",
    "    'rnn': estimator.rnn_agent,\n",
    "    'spice': estimator.spice_agent,\n",
    "    # 'baseline': baseline_agent,\n",
    "    'gru': gru_agent,\n",
    "    'gru_embed': gru_embed_agent,\n",
    "}\n",
    "\n",
    "fig, axs = plot_session(agents, dataset.xs[session_id], signals_to_plot=[], display_choice=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chance level predictions\n",
    "\n",
    "num_actions = 6\n",
    "num_samples = 311*144\n",
    "chance_accuracy = 1 / num_actions\n",
    "print(f\"Chance level accuracy: {chance_accuracy:.4f} ({1/num_actions:.2%})\")\n",
    "\n",
    "# create random predictions for comparison in next cell\n",
    "random_predictions = torch.randint(0, num_actions, (num_samples,))\n",
    "random_predictions = torch.nn.functional.one_hot(random_predictions, num_classes=num_actions).float()\n",
    "\n",
    "labels_flat = dataset.ys[..., 1].reshape(-1).nan_to_num(0).long()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "loss_random = criterion(random_predictions, labels_flat)\n",
    "print(f\"Random predictions loss: {loss_random.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the models by getting their predictions on the real data and comparing the CE loss\n",
    "\n",
    "estimator.rnn_model.eval(use_sindy=True)\n",
    "estimator.rnn_model.init_state(batch_size=dataset.xs.shape[0])\n",
    "logits_spice = estimator.rnn_model(dataset.xs, prev_state=None, batch_first=True)[0]\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits_gru = model(dataset.xs)\n",
    "nan_mask = dataset.xs[:, :, 0].reshape(-1) != torch.nan\n",
    "logits_spice_flat = logits_spice.reshape(-1, 6)\n",
    "logits_gru_flat = logits_gru.reshape(-1, 6)\n",
    "labels_flat = dataset.ys[..., 1].reshape(-1).nan_to_num(0).long()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss_spice = criterion(logits_spice_flat[nan_mask], labels_flat[nan_mask])\n",
    "loss_gru = criterion(logits_gru_flat[nan_mask], labels_flat[nan_mask])\n",
    "print(f\"SPICE Loss: {loss_spice.item()}\")\n",
    "print(f\"GRU Loss: {loss_gru.item()}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO-DO:\n",
    "\n",
    "1. **implement some logic to ignore SigAct_ID1 == 5 (waiting)** \n",
    "\n",
    "-> nothing to predict here\n",
    "\n",
    "-> whenever SigAct_ID1[t+1] == 5: Don't let the RNN predict because there's actually nothing to predict\n",
    "\n",
    "2. **add reversed blocks in csv file (ID1<->ID2) to double the amount of predictable data:**\n",
    "\n",
    "ID1,Dominan0 rank_ID1,ID2,Dominan0 rank_ID2,SigAct_ID1,SigAct_ID2,interaction_id,community_id,Grooming_ID1,Grooming_ID2\n",
    "\n",
    "Original block:\n",
    "\n",
    "13,13,6,6,1.0,5.0,1,0,1,0\n",
    "\n",
    "13,13,6,6,2.0,5.0,1,0,0,0\n",
    "\n",
    "13,13,6,6,0.0,5.0,1,0,0,0\n",
    "\n",
    "Add reversed block:\n",
    "\n",
    "6,6,13,13,5.0,1.0,1,0,0,1\n",
    "\n",
    "6,6,13,13,5.0,2.0,1,0,0,0\n",
    "\n",
    "6,6,13,13,5.0,0.0,1,0,0,0\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "spice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}