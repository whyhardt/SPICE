{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tf7jlYw4NA0v",
        "outputId": "0969ca34-675d-422e-cbfb-7387d9bcd8ad"
      },
      "outputs": [],
      "source": [
        "#!git clone https://github.com/whyhardt/SPICE.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oXIbg826NS5i",
        "outputId": "3825864a-cb2d-4ad5-f2e5-79a4e81dfc3e"
      },
      "outputs": [],
      "source": [
        "# !pip install -e SPICE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "f0uVlABYznR5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Dict, List, Tuple\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from spice.estimator import SpiceEstimator\n",
        "from spice.resources.spice_utils import SpiceConfig, SpiceDataset\n",
        "from spice.utils.convert_dataset import convert_dataset\n",
        "from spice.resources.rnn import BaseRNN\n",
        "\n",
        "# For custom RNN\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's load the data first with the `convert_dataset` method. This method returns a `SpiceDataset` object which we can use right away "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of dataset: torch.Size([311, 144, 19])\n",
            "Number of participants: 311\n",
            "Number of actions in dataset: 6\n",
            "Number of additional inputs: 4\n"
          ]
        }
      ],
      "source": [
        "# Load your data\n",
        "dataset = convert_dataset(\n",
        "    file = '../../weinhardt2025/data/hwang2025/hwang2025.csv',\n",
        "    df_participant_id='interaction_id',\n",
        "    df_choice='SigAct_ID1',\n",
        "    df_reward='Grooming_ID2',\n",
        "    additional_inputs=['ID1', 'ID2', 'SigAct_ID2', 'Grooming_ID1'],\n",
        "    timeshift_additional_inputs=False,\n",
        "    )\n",
        "\n",
        "# TODO: Implement dataset split into training and testing data\n",
        "dataset_train, dataset_test = dataset, dataset\n",
        "# blueprint for splitting:\n",
        "# def datasplit(dataset, ...) -> SpiceDataset, SpiceDataset\n",
        "    # return dataset_train, dataset_test\n",
        "    \n",
        "# structure of dataset:\n",
        "# dataset has two main attributes: xs -> inputs; ys -> targets (next action)\n",
        "# shape: (n_participants*n_blocks*n_experiments, n_timesteps, features)\n",
        "# features are (n_actions * action, n_actions * reward, n_additional_inputs * additional_input, block_number, experiment_id, participant_id)\n",
        "\n",
        "# in order to set up the participant embedding we have to compute the number of unique participants in our data \n",
        "# to get the number of participants n_participants we do:\n",
        "n_participants = 311\n",
        "n_actions = dataset.ys.shape[-1]\n",
        "\n",
        "print(f\"Shape of dataset: {dataset.xs.shape}\")\n",
        "print(f\"Number of participants: {n_participants}\")\n",
        "print(f\"Number of actions in dataset: {n_actions}\")\n",
        "print(f\"Number of additional inputs: {dataset.xs.shape[-1]-2*n_actions-3}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([311, 144, 19])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.xs.shape # shape -> (n_participants: 41, timesteps: 496, features: 16)\n",
        "\n",
        "# normal RL exp:    [A] [B] [C] [D] [E]\n",
        "# choice:           [x] [ ] [ ] [ ] [ ]\n",
        "# reward:           [1] [ ] [ ] [ ] [ ]    (partial feedback)\n",
        "# reward:           [1] [0] [1] [1] [0]    (full feedback)\n",
        "\n",
        "# features: (action0, action1, action2, action3, action4, reward0, reward1, reward2, reward3, reward4, 'ID2', 'SigAct_ID2', 'Grooming_ID1', block number, experiment id, ID1)\n",
        "# in your case: (x, x, x, x, x, -, -, -, -, -, x, x, x, -, -, -, -, x)    -> x: keep; -: ignore"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we are going to define the configuration for SPICE with a `SpiceConfig` object.\n",
        "\n",
        "The `SpiceConfig` takes as arguments \n",
        "1. `library_setup (dict)`: Defining the variable names of each module.\n",
        "2. `memory_state (dict)`: Defining the memory state variables and their initial values.\n",
        "3. `states_in_logit (list)`: Defining which of the memory state variables are used later for the logit computation. This is necessary for some background processes.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "spice_config = SpiceConfig(\n",
        "    library_setup={\n",
        "        'value_action': ['chosen', 'sig_action', 'sig_grooming', 'sig_non_contact', 'sig_contact', 'sig_scratch', 'sig_waiting', 'prev_action', 'prev_grooming', 'prev_non_contact', 'prev_contact', 'prev_scratch', 'prev_waiting'],\n",
        "        'value_grooming': ['chosen', 'sig_action', 'sig_grooming', 'sig_non_contact', 'sig_contact', 'sig_scratch', 'sig_waiting', 'prev_action', 'prev_grooming', 'prev_non_contact', 'prev_contact', 'prev_scratch', 'prev_waiting'],\n",
        "        'value_non_contact': ['chosen', 'sig_action', 'sig_grooming', 'sig_non_contact', 'sig_contact', 'sig_scratch', 'sig_waiting', 'prev_action', 'prev_grooming', 'prev_non_contact', 'prev_contact', 'prev_scratch', 'prev_waiting'],\n",
        "        'value_contact': ['chosen', 'sig_action', 'sig_grooming', 'sig_non_contact', 'sig_contact', 'sig_scratch', 'sig_waiting', 'prev_action', 'prev_grooming', 'prev_non_contact', 'prev_contact', 'prev_scratch', 'prev_waiting'],\n",
        "        'value_scratch': ['chosen', 'sig_action', 'sig_grooming', 'sig_non_contact', 'sig_contact', 'sig_scratch', 'sig_waiting', 'prev_action', 'prev_grooming', 'prev_non_contact', 'prev_contact', 'prev_scratch', 'prev_waiting'],\n",
        "        'value_waiting': ['chosen', 'sig_action', 'sig_grooming', 'sig_non_contact', 'sig_contact', 'sig_scratch', 'sig_waiting', 'prev_action', 'prev_grooming', 'prev_non_contact', 'prev_contact', 'prev_scratch', 'prev_waiting'],\n",
        "    },\n",
        "    \n",
        "    memory_state={\n",
        "        # 'value_action': 0,\n",
        "        # 'value_grooming': 0,\n",
        "        # 'value_non_conctant': 0,\n",
        "        # 'value_contact': 0,\n",
        "        # 'value_scratch': 0,\n",
        "        # 'waiting': 0,\n",
        "        'values': 0,\n",
        "        },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And now we are going to define the SPICE model which is a child of the `BaseRNN` and `torch.nn.Module` class and takes as required arguments:\n",
        "1. `spice_config (SpiceConfig)`: previously defined SpiceConfig object\n",
        "2. `n_actions (int)`: number of possible actions in your dataset (including non-displayed ones if applicable).\n",
        "3. `n_participants (int)`: number of participants in your dataset.\n",
        "\n",
        "As usual for a `torch.nn.Module` we have to define at least the `__init__` method and the `forward` method.\n",
        "The `forward` method gets called when computing a forward pass through the model and takes as inputs `(inputs (SpiceDataset.xs), prev_state (dict, default: None), batch_first (bool, default: False))` and returns `(logits (torch.Tensor, shape: (n_participants*n_blocks*n_experiments, timesteps, n_actions)), updated_state (dict))`. Two necessary method calls inside the forward pass are:\n",
        "1. `self.init_forward_pass(inputs, prev_state, batch_first) -> SpiceSignals`: returns a `SpiceSignals` object which carries all relevant information already processed.\n",
        "2. `self.post_forward_pass(SpiceSignals, batch_first) -> SpiceSignals`: does some re-arranging of the logits to adhere to `batch_first`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "z0kOR2Qgz0FZ"
      },
      "outputs": [],
      "source": [
        "class SPICERNN(BaseRNN):\n",
        "    \n",
        "    def __init__(self, n_actions, spice_config, n_participants, **kwargs):\n",
        "        super().__init__(n_actions=n_actions, spice_config=spice_config, n_participants=n_participants, embedding_size=8, **kwargs)\n",
        "        \n",
        "        # participant embedding\n",
        "        self.participant_embedding = self.setup_embedding(num_embeddings=42, embedding_size=self.embedding_size, dropout=0.1)\n",
        "        \n",
        "        # rnn modules\n",
        "        # reward-based modules\n",
        "        self.setup_module(key_module='value_action', input_size=13+self.embedding_size*2, dropout=0.1)\n",
        "        self.setup_module(key_module='value_grooming', input_size=13+self.embedding_size*2, dropout=0.1)\n",
        "        self.setup_module(key_module='value_non_contact', input_size=13+self.embedding_size*2, dropout=0.1)\n",
        "        self.setup_module(key_module='value_contact', input_size=13+self.embedding_size*2, dropout=0.1)\n",
        "        self.setup_module(key_module='value_scratch', input_size=13+self.embedding_size*2, dropout=0.1)\n",
        "        self.setup_module(key_module='value_waiting', input_size=13+self.embedding_size*2, dropout=0.1)\n",
        "    \n",
        "    def forward(self, inputs, prev_state, batch_first=False):\n",
        "        \n",
        "        spice_signals = self.init_forward_pass(inputs, prev_state, batch_first)\n",
        "        \n",
        "        # get participant id of Ape 2 (not implemented in spice_signals.participant_ids)\n",
        "        participant_id_1 = spice_signals.additional_inputs[0, :, 0].long()\n",
        "        participant_id_2 = spice_signals.additional_inputs[0, :, 1].long()\n",
        "        \n",
        "        # time-invariant participant features\n",
        "        participant_embeddings_1 = self.participant_embedding(participant_id_1)\n",
        "        participant_embeddings_2 = self.participant_embedding(participant_id_2)\n",
        "        participant_embeddings = torch.concat((participant_embeddings_1, participant_embeddings_2), dim=-1)\n",
        "        \n",
        "        # setup all variables\n",
        "        sig_action = spice_signals.actions[..., 0].unsqueeze(-1).repeat(1, 1, spice_signals.actions.shape[-1])  # make that a proper onehot-tensor; shape = (timesteps, batch, binary)\n",
        "        sig_grooming = spice_signals.actions[..., 1].unsqueeze(-1).repeat(1, 1, spice_signals.actions.shape[-1])\n",
        "        sig_non_contact = spice_signals.actions[..., 2].unsqueeze(-1).repeat(1, 1, spice_signals.actions.shape[-1])\n",
        "        sig_contact = spice_signals.actions[..., 3].unsqueeze(-1).repeat(1, 1, spice_signals.actions.shape[-1])\n",
        "        sig_scratch = spice_signals.actions[..., 4].unsqueeze(-1).repeat(1, 1, spice_signals.actions.shape[-1])\n",
        "        sig_waiting = spice_signals.actions[..., 5].unsqueeze(-1).repeat(1, 1, spice_signals.actions.shape[-1])\n",
        "        prev_action = torch.concat((torch.zeros((1, participant_id_1.shape[0], 1), device=self.device), spice_signals.actions[:-1, :, 0].unsqueeze(-1))).repeat(1, 1, spice_signals.actions.shape[-1])\n",
        "        prev_grooming = torch.concat((torch.zeros((1, participant_id_1.shape[0], 1), device=self.device), spice_signals.actions[:-1, :, 1].unsqueeze(-1))).repeat(1, 1, spice_signals.actions.shape[-1])\n",
        "        prev_non_contact = torch.concat((torch.zeros((1, participant_id_1.shape[0], 1), device=self.device), spice_signals.actions[:-1, :, 2].unsqueeze(-1))).repeat(1, 1, spice_signals.actions.shape[-1])\n",
        "        prev_contact = torch.concat((torch.zeros((1, participant_id_1.shape[0], 1), device=self.device), spice_signals.actions[:-1, :, 3].unsqueeze(-1))).repeat(1, 1, spice_signals.actions.shape[-1])\n",
        "        prev_scratch = torch.concat((torch.zeros((1, participant_id_1.shape[0], 1), device=self.device), spice_signals.actions[:-1, :, 4].unsqueeze(-1))).repeat(1, 1, spice_signals.actions.shape[-1])\n",
        "        prev_waiting = torch.concat((torch.zeros((1, participant_id_1.shape[0], 1), device=self.device), spice_signals.actions[:-1, :, 5].unsqueeze(-1))).repeat(1, 1, spice_signals.actions.shape[-1])\n",
        "        \n",
        "        for timestep in spice_signals.timesteps:\n",
        "            \n",
        "            # update chosen value\n",
        "            self.call_module(\n",
        "                key_module='value_action',\n",
        "                key_state='values',\n",
        "                action_mask=torch.tensor((1, 0, 0, 0, 0, 0), device=self.device).reshape(1, -1).repeat(spice_signals.actions.shape[1], 1), \n",
        "                inputs=(\n",
        "                    spice_signals.actions[timestep],\n",
        "                    sig_action[timestep], \n",
        "                    sig_grooming[timestep], \n",
        "                    sig_non_contact[timestep], \n",
        "                    sig_contact[timestep], \n",
        "                    sig_scratch[timestep], \n",
        "                    sig_waiting[timestep], \n",
        "                    prev_action[timestep], \n",
        "                    prev_grooming[timestep], \n",
        "                    prev_non_contact[timestep], \n",
        "                    prev_contact[timestep], \n",
        "                    prev_scratch[timestep], \n",
        "                    prev_waiting[timestep],\n",
        "                    ),\n",
        "                participant_index=spice_signals.participant_ids,\n",
        "                participant_embedding=participant_embeddings,\n",
        "            )\n",
        "            \n",
        "            self.call_module(\n",
        "                key_module='value_grooming',\n",
        "                key_state='values',\n",
        "                action_mask=torch.tensor((0, 1, 0, 0, 0, 0), device=self.device).reshape(1, -1).repeat(spice_signals.actions.shape[1], 1), # dummy-solution; make torch-tensor; reshape in \n",
        "                inputs=(\n",
        "                    spice_signals.actions[timestep],\n",
        "                    sig_action[timestep], \n",
        "                    sig_grooming[timestep], \n",
        "                    sig_non_contact[timestep], \n",
        "                    sig_contact[timestep], \n",
        "                    sig_scratch[timestep], \n",
        "                    sig_waiting[timestep], \n",
        "                    prev_action[timestep], \n",
        "                    prev_grooming[timestep], \n",
        "                    prev_non_contact[timestep], \n",
        "                    prev_contact[timestep], \n",
        "                    prev_scratch[timestep], \n",
        "                    prev_waiting[timestep],\n",
        "                    ),\n",
        "                participant_index=spice_signals.participant_ids,\n",
        "                participant_embedding=participant_embeddings,\n",
        "            )\n",
        "            \n",
        "            self.call_module(\n",
        "                key_module='value_non_contact',\n",
        "                key_state='values',\n",
        "                action_mask=torch.tensor((0, 0, 1, 0, 0, 0), device=self.device).reshape(1, -1).repeat(spice_signals.actions.shape[1], 1), # dummy-solution; make torch-tensor; reshape in \n",
        "                inputs=(\n",
        "                    spice_signals.actions[timestep],\n",
        "                    sig_action[timestep], \n",
        "                    sig_grooming[timestep], \n",
        "                    sig_non_contact[timestep], \n",
        "                    sig_contact[timestep], \n",
        "                    sig_scratch[timestep], \n",
        "                    sig_waiting[timestep], \n",
        "                    prev_action[timestep], \n",
        "                    prev_grooming[timestep], \n",
        "                    prev_non_contact[timestep], \n",
        "                    prev_contact[timestep], \n",
        "                    prev_scratch[timestep], \n",
        "                    prev_waiting[timestep],\n",
        "                    ),\n",
        "                participant_index=spice_signals.participant_ids,\n",
        "                participant_embedding=participant_embeddings,\n",
        "            )\n",
        "            \n",
        "            self.call_module(\n",
        "                key_module='value_contact',\n",
        "                key_state='values',\n",
        "                action_mask=torch.tensor((0, 0, 0, 1, 0, 0), device=self.device).reshape(1, -1).repeat(spice_signals.actions.shape[1], 1), # dummy-solution; make torch-tensor; reshape in \n",
        "                inputs=(\n",
        "                    spice_signals.actions[timestep],\n",
        "                    sig_action[timestep], \n",
        "                    sig_grooming[timestep], \n",
        "                    sig_non_contact[timestep], \n",
        "                    sig_contact[timestep], \n",
        "                    sig_scratch[timestep], \n",
        "                    sig_waiting[timestep], \n",
        "                    prev_action[timestep], \n",
        "                    prev_grooming[timestep], \n",
        "                    prev_non_contact[timestep], \n",
        "                    prev_contact[timestep], \n",
        "                    prev_scratch[timestep], \n",
        "                    prev_waiting[timestep],\n",
        "                    ),\n",
        "                participant_index=spice_signals.participant_ids,\n",
        "                participant_embedding=participant_embeddings,\n",
        "            )\n",
        "            \n",
        "            self.call_module(\n",
        "                key_module='value_scratch',\n",
        "                key_state='values',\n",
        "                action_mask=torch.tensor((0, 0, 0, 0, 1, 0), device=self.device).reshape(1, -1).repeat(spice_signals.actions.shape[1], 1), # dummy-solution; make torch-tensor; reshape in \n",
        "                inputs=(\n",
        "                    spice_signals.actions[timestep],\n",
        "                    sig_action[timestep], \n",
        "                    sig_grooming[timestep], \n",
        "                    sig_non_contact[timestep], \n",
        "                    sig_contact[timestep], \n",
        "                    sig_scratch[timestep], \n",
        "                    sig_waiting[timestep], \n",
        "                    prev_action[timestep], \n",
        "                    prev_grooming[timestep], \n",
        "                    prev_non_contact[timestep], \n",
        "                    prev_contact[timestep], \n",
        "                    prev_scratch[timestep], \n",
        "                    prev_waiting[timestep],\n",
        "                    ),\n",
        "                participant_index=spice_signals.participant_ids,\n",
        "                participant_embedding=participant_embeddings,\n",
        "            )\n",
        "            \n",
        "            self.call_module(\n",
        "                key_module='value_waiting',\n",
        "                key_state='values',\n",
        "                action_mask=torch.tensor((0, 0, 0, 0, 0, 1), device=self.device).reshape(1, -1).repeat(spice_signals.actions.shape[1], 1), # dummy-solution; make torch-tensor; reshape in \n",
        "                inputs=(\n",
        "                    spice_signals.actions[timestep],\n",
        "                    sig_action[timestep], \n",
        "                    sig_grooming[timestep], \n",
        "                    sig_non_contact[timestep], \n",
        "                    sig_contact[timestep], \n",
        "                    sig_scratch[timestep], \n",
        "                    sig_waiting[timestep], \n",
        "                    prev_action[timestep], \n",
        "                    prev_grooming[timestep], \n",
        "                    prev_non_contact[timestep], \n",
        "                    prev_contact[timestep], \n",
        "                    prev_scratch[timestep], \n",
        "                    prev_waiting[timestep],\n",
        "                    ),\n",
        "                participant_index=spice_signals.participant_ids,\n",
        "                participant_embedding=participant_embeddings,\n",
        "            )\n",
        "            \n",
        "            spice_signals.logits[timestep] = self.state['values']\n",
        "            \n",
        "        spice_signals = self.post_forward_pass(spice_signals, batch_first)\n",
        "        \n",
        "        return spice_signals.logits, self.get_state()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's setup now the `SpiceEstimator` object and fit it to the data!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "3EnmDiUMWq6e",
        "outputId": "e53b1bbd-4173-4d2c-bcdc-15832bc31bd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training (ep10_warm100_th0.05_alpha0.01) on cuda...\n",
            "================================================================================\n",
            "\n",
            "Training the RNN...\n",
            "================================================================================\n",
            "Epoch 1/10 --- L(Train): 2.4046624 --- L(Val, RNN): 2.0070868 --- L(Val, SINDy): 1.8163218 --- Time: 2.88s; --- Convergence: 1.00e+00\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.006 1 + 1.008 value_action[t] + 0.007 chosen + -0.008 sig_action + 0.006 sig_grooming + -0.008 sig_non_contact + 0.007 sig_contact + 0.007 sig_scratch + 0.007 sig_waiting + -0.006 prev_action + -0.007 prev_grooming + 0.008 prev_non_contact + -0.006 prev_contact + 0.006 prev_scratch + -0.006 prev_waiting \n",
            "value_grooming[t+1] = -0.006 1 + 1.007 value_grooming[t] + 0.006 chosen + 0.007 sig_action + -0.005 sig_grooming + -0.007 sig_non_contact + 0.007 sig_contact + -0.007 sig_scratch + -0.008 sig_waiting + -0.006 prev_action + -0.007 prev_grooming + 0.007 prev_non_contact + -0.007 prev_contact + -0.008 prev_scratch + 0.007 prev_waiting \n",
            "value_non_contact[t+1] = -0.005 1 + 0.993 value_non_contact[t] + -0.007 chosen + -0.007 sig_action + -0.007 sig_grooming + 0.007 sig_non_contact + -0.006 sig_contact + 0.007 sig_scratch + -0.007 sig_waiting + 0.008 prev_action + -0.007 prev_grooming + 0.008 prev_non_contact + -0.008 prev_contact + -0.007 prev_scratch + 0.007 prev_waiting \n",
            "value_contact[t+1] = 0.006 1 + 0.993 value_contact[t] + 0.007 chosen + 0.007 sig_action + -0.008 sig_grooming + -0.006 sig_non_contact + -0.007 sig_contact + -0.007 sig_scratch + 0.007 sig_waiting + -0.007 prev_action + 0.007 prev_grooming + -0.005 prev_non_contact + -0.007 prev_contact + 0.008 prev_scratch + -0.008 prev_waiting \n",
            "value_scratch[t+1] = -0.006 1 + 1.007 value_scratch[t] + 0.006 chosen + 0.007 sig_action + 0.006 sig_grooming + -0.007 sig_non_contact + -0.006 sig_contact + -0.007 sig_scratch + -0.007 sig_waiting + 0.007 prev_action + -0.007 prev_grooming + 0.007 prev_non_contact + 0.007 prev_contact + 0.006 prev_scratch + 0.007 prev_waiting \n",
            "value_waiting[t+1] = 0.005 1 + 0.993 value_waiting[t] + -0.008 chosen + 0.007 sig_action + -0.007 sig_grooming + 0.007 sig_non_contact + 0.007 sig_contact + -0.007 sig_scratch + 0.007 sig_waiting + 0.007 prev_action + -0.008 prev_grooming + 0.006 prev_non_contact + -0.007 prev_contact + 0.007 prev_scratch + -0.007 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 2/10 --- L(Train): 2.0060511 --- L(Val, RNN): 1.8429458 --- L(Val, SINDy): 1.8030578 --- Time: 2.22s; --- Convergence: 5.84e-01\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.003 1 + 1.005 value_action[t] + 0.004 chosen + -0.005 sig_action + 0.003 sig_grooming + -0.005 sig_non_contact + 0.004 sig_contact + 0.004 sig_scratch + 0.004 sig_waiting + -0.003 prev_action + -0.004 prev_grooming + 0.005 prev_non_contact + -0.003 prev_contact + 0.003 prev_scratch + -0.003 prev_waiting \n",
            "value_grooming[t+1] = -0.004 1 + 1.004 value_grooming[t] + 0.003 chosen + 0.004 sig_action + -0.002 sig_grooming + -0.004 sig_non_contact + 0.004 sig_contact + -0.004 sig_scratch + -0.005 sig_waiting + -0.003 prev_action + -0.004 prev_grooming + 0.004 prev_non_contact + -0.004 prev_contact + -0.005 prev_scratch + 0.004 prev_waiting \n",
            "value_non_contact[t+1] = -0.003 1 + 0.996 value_non_contact[t] + -0.004 chosen + -0.004 sig_action + -0.004 sig_grooming + 0.004 sig_non_contact + -0.003 sig_contact + 0.004 sig_scratch + -0.004 sig_waiting + 0.004 prev_action + -0.004 prev_grooming + 0.005 prev_non_contact + -0.005 prev_contact + -0.004 prev_scratch + 0.004 prev_waiting \n",
            "value_contact[t+1] = 0.003 1 + 0.996 value_contact[t] + 0.004 chosen + 0.004 sig_action + -0.005 sig_grooming + -0.003 sig_non_contact + -0.004 sig_contact + -0.004 sig_scratch + 0.004 sig_waiting + -0.004 prev_action + 0.004 prev_grooming + -0.002 prev_non_contact + -0.004 prev_contact + 0.005 prev_scratch + -0.005 prev_waiting \n",
            "value_scratch[t+1] = -0.003 1 + 1.004 value_scratch[t] + 0.003 chosen + 0.004 sig_action + 0.003 sig_grooming + -0.004 sig_non_contact + -0.003 sig_contact + -0.004 sig_scratch + -0.004 sig_waiting + 0.004 prev_action + -0.004 prev_grooming + 0.004 prev_non_contact + 0.004 prev_contact + 0.003 prev_scratch + 0.004 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 0.996 value_waiting[t] + -0.005 chosen + 0.004 sig_action + -0.004 sig_grooming + 0.004 sig_non_contact + 0.004 sig_contact + -0.004 sig_scratch + 0.004 sig_waiting + 0.004 prev_action + -0.005 prev_grooming + 0.003 prev_non_contact + -0.004 prev_contact + 0.004 prev_scratch + -0.004 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 3/10 --- L(Train): 1.8557922 --- L(Val, RNN): 1.7687600 --- L(Val, SINDy): 1.8046385 --- Time: 2.25s; --- Convergence: 3.29e-01\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.999 value_action[t] + -0.001 chosen + 0.001 sig_action + -0.002 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 0.999 value_grooming[t] + -0.003 chosen + -0.002 sig_action + 0.003 sig_grooming + 0.002 sig_non_contact + -0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = 0.002 1 + 1.001 value_non_contact[t] + 0.001 chosen + 0.001 sig_action + 0.001 sig_grooming + -0.001 sig_non_contact + 0.003 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.002 1 + 1.002 value_contact[t] + -0.001 chosen + -0.001 sig_action + 0.001 sig_grooming + 0.002 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + 0.003 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = 0.002 1 + 0.998 value_scratch[t] + -0.002 chosen + -0.002 sig_action + -0.002 sig_grooming + 0.002 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = -0.002 1 + 1.001 value_waiting[t] + 0.001 chosen + -0.001 sig_action + 0.001 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 4/10 --- L(Train): 1.7876337 --- L(Val, RNN): 1.6919793 --- L(Val, SINDy): 1.8113569 --- Time: 2.29s; --- Convergence: 2.03e-01\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.002 1 + 0.998 value_action[t] + -0.002 chosen + 0.002 sig_action + -0.003 sig_grooming + 0.002 sig_non_contact + -0.003 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.003 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.003 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 0.998 value_grooming[t] + -0.004 chosen + -0.003 sig_action + 0.004 sig_grooming + 0.002 sig_non_contact + -0.002 sig_contact + 0.003 sig_scratch + 0.002 sig_waiting + 0.003 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = 0.003 1 + 1.002 value_non_contact[t] + 0.002 chosen + 0.002 sig_action + 0.002 sig_grooming + -0.002 sig_non_contact + 0.004 sig_contact + -0.002 sig_scratch + 0.003 sig_waiting + -0.002 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.003 1 + 1.003 value_contact[t] + -0.002 chosen + -0.002 sig_action + 0.002 sig_grooming + 0.003 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + -0.003 prev_grooming + 0.004 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = 0.003 1 + 0.997 value_scratch[t] + -0.003 chosen + -0.003 sig_action + -0.003 sig_grooming + 0.003 sig_non_contact + 0.003 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + 0.003 prev_grooming + -0.002 prev_non_contact + -0.002 prev_contact + -0.003 prev_scratch + -0.002 prev_waiting \n",
            "value_waiting[t+1] = -0.003 1 + 1.002 value_waiting[t] + 0.002 chosen + -0.002 sig_action + 0.002 sig_grooming + -0.002 sig_non_contact + -0.002 sig_contact + 0.003 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + 0.002 prev_grooming + -0.003 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 5/10 --- L(Train): 1.7061306 --- L(Val, RNN): 1.6429306 --- L(Val, SINDy): 1.8100835 --- Time: 2.38s; --- Convergence: 1.26e-01\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + -0.001 chosen + 0.0 sig_action + -0.001 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.0 value_grooming[t] + -0.002 chosen + -0.001 sig_action + 0.003 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = 0.001 1 + 1.0 value_non_contact[t] + 0.001 chosen + 0.001 sig_action + 0.001 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.001 1 + 1.001 value_contact[t] + -0.0 chosen + -0.0 sig_action + 0.0 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = 0.001 1 + 0.999 value_scratch[t] + -0.001 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = -0.001 1 + 1.001 value_waiting[t] + 0.0 chosen + -0.0 sig_action + 0.0 sig_grooming + -0.0 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 6/10 --- L(Train): 1.6549716 --- L(Val, RNN): 1.6218799 --- L(Val, SINDy): 1.8104852 --- Time: 2.29s; --- Convergence: 7.35e-02\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 1.003 value_action[t] + 0.003 chosen + -0.003 sig_action + 0.002 sig_grooming + -0.003 sig_non_contact + 0.002 sig_contact + 0.003 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.003 prev_grooming + 0.003 prev_non_contact + -0.002 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = -0.004 1 + 1.005 value_grooming[t] + 0.001 chosen + 0.002 sig_action + -0.0 sig_grooming + -0.002 sig_non_contact + 0.002 sig_contact + -0.002 sig_scratch + -0.003 sig_waiting + -0.002 prev_action + -0.003 prev_grooming + 0.003 prev_non_contact + -0.002 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_non_contact[t+1] = -0.002 1 + 0.996 value_non_contact[t] + -0.002 chosen + -0.002 sig_action + -0.002 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + 0.003 sig_scratch + -0.002 sig_waiting + 0.003 prev_action + -0.002 prev_grooming + 0.003 prev_non_contact + -0.003 prev_contact + -0.003 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = 0.002 1 + 0.998 value_contact[t] + 0.003 chosen + 0.003 sig_action + -0.003 sig_grooming + -0.001 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + 0.003 prev_scratch + -0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.002 1 + 1.002 value_scratch[t] + 0.002 chosen + 0.002 sig_action + 0.002 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + -0.002 sig_scratch + -0.003 sig_waiting + 0.003 prev_action + -0.002 prev_grooming + 0.003 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + 0.003 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 0.997 value_waiting[t] + -0.003 chosen + 0.003 sig_action + -0.003 sig_grooming + 0.003 sig_non_contact + 0.003 sig_contact + -0.002 sig_scratch + 0.002 sig_waiting + 0.003 prev_action + -0.003 prev_grooming + 0.002 prev_non_contact + -0.002 prev_contact + 0.002 prev_scratch + -0.003 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 7/10 --- L(Train): 1.6339340 --- L(Val, RNN): 1.6022432 --- L(Val, SINDy): 1.8141742 --- Time: 2.30s; --- Convergence: 4.66e-02\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.003 1 + 1.004 value_action[t] + 0.003 chosen + -0.004 sig_action + 0.003 sig_grooming + -0.004 sig_non_contact + 0.003 sig_contact + 0.004 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.004 prev_grooming + 0.004 prev_non_contact + -0.003 prev_contact + 0.003 prev_scratch + -0.003 prev_waiting \n",
            "value_grooming[t+1] = -0.007 1 + 1.009 value_grooming[t] + 0.002 chosen + 0.003 sig_action + -0.001 sig_grooming + -0.003 sig_non_contact + 0.003 sig_contact + -0.003 sig_scratch + -0.004 sig_waiting + -0.003 prev_action + -0.004 prev_grooming + 0.003 prev_non_contact + -0.003 prev_contact + -0.004 prev_scratch + 0.004 prev_waiting \n",
            "value_non_contact[t+1] = -0.002 1 + 0.993 value_non_contact[t] + -0.003 chosen + -0.003 sig_action + -0.003 sig_grooming + 0.003 sig_non_contact + -0.002 sig_contact + 0.004 sig_scratch + -0.003 sig_waiting + 0.004 prev_action + -0.003 prev_grooming + 0.004 prev_non_contact + -0.004 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = 0.002 1 + 0.997 value_contact[t] + 0.004 chosen + 0.004 sig_action + -0.004 sig_grooming + -0.002 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + 0.004 sig_waiting + -0.004 prev_action + 0.003 prev_grooming + -0.002 prev_non_contact + -0.003 prev_contact + 0.004 prev_scratch + -0.004 prev_waiting \n",
            "value_scratch[t+1] = -0.002 1 + 1.003 value_scratch[t] + 0.003 chosen + 0.003 sig_action + 0.003 sig_grooming + -0.003 sig_non_contact + -0.002 sig_contact + -0.003 sig_scratch + -0.004 sig_waiting + 0.003 prev_action + -0.003 prev_grooming + 0.004 prev_non_contact + 0.003 prev_contact + 0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 0.997 value_waiting[t] + -0.004 chosen + 0.004 sig_action + -0.004 sig_grooming + 0.004 sig_non_contact + 0.004 sig_contact + -0.003 sig_scratch + 0.003 sig_waiting + 0.004 prev_action + -0.004 prev_grooming + 0.003 prev_non_contact + -0.003 prev_contact + 0.003 prev_scratch + -0.003 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 8/10 --- L(Train): 1.6098888 --- L(Val, RNN): 1.5820065 --- L(Val, SINDy): 1.8147894 --- Time: 2.44s; --- Convergence: 3.34e-02\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 1.003 value_action[t] + 0.002 chosen + -0.003 sig_action + 0.002 sig_grooming + -0.003 sig_non_contact + 0.002 sig_contact + 0.003 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.003 prev_grooming + 0.003 prev_non_contact + -0.002 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = -0.013 1 + 1.015 value_grooming[t] + 0.001 chosen + 0.002 sig_action + -0.0 sig_grooming + -0.002 sig_non_contact + 0.002 sig_contact + -0.002 sig_scratch + -0.003 sig_waiting + -0.002 prev_action + -0.003 prev_grooming + 0.003 prev_non_contact + -0.002 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_non_contact[t+1] = -0.002 1 + 0.989 value_non_contact[t] + -0.002 chosen + -0.002 sig_action + -0.002 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + 0.003 sig_scratch + -0.002 sig_waiting + 0.003 prev_action + -0.002 prev_grooming + 0.003 prev_non_contact + -0.003 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = 0.001 1 + 0.998 value_contact[t] + 0.003 chosen + 0.003 sig_action + -0.003 sig_grooming + -0.001 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + 0.003 prev_scratch + -0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.002 1 + 1.002 value_scratch[t] + 0.002 chosen + 0.002 sig_action + 0.002 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + -0.002 sig_scratch + -0.003 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + 0.003 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 0.998 value_waiting[t] + -0.003 chosen + 0.003 sig_action + -0.003 sig_grooming + 0.003 sig_non_contact + 0.003 sig_contact + -0.002 sig_scratch + 0.002 sig_waiting + 0.003 prev_action + -0.003 prev_grooming + 0.002 prev_non_contact + -0.002 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 9/10 --- L(Train): 1.5906103 --- L(Val, RNN): 1.5606830 --- L(Val, SINDy): 1.8164221 --- Time: 2.41s; --- Convergence: 2.74e-02\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.001 value_action[t] + 0.0 chosen + -0.001 sig_action + -0.0 sig_grooming + -0.001 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = -0.017 1 + 1.021 value_grooming[t] + -0.001 chosen + -0.0 sig_action + 0.002 sig_grooming + 0.0 sig_non_contact + -0.0 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = 0.0 1 + 0.986 value_non_contact[t] + -0.0 chosen + 0.0 sig_action + -0.0 sig_grooming + 0.0 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.001 1 + 1.0 value_contact[t] + 0.0 chosen + 0.0 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = 0.0 1 + 1.0 value_scratch[t] + -0.001 chosen + -0.0 sig_action + -0.0 sig_grooming + 0.0 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = -0.0 1 + 1.0 value_waiting[t] + -0.001 chosen + 0.0 sig_action + -0.0 sig_grooming + 0.0 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 10/10 --- L(Train): 1.5677795 --- L(Val, RNN): 1.5391196 --- L(Val, SINDy): 1.8207822 --- Time: 2.35s; --- Convergence: 2.45e-02\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.997 value_action[t] + -0.003 chosen + 0.003 sig_action + -0.001 sig_grooming + 0.003 sig_non_contact + -0.001 sig_contact + -0.003 sig_scratch + -0.003 sig_waiting + 0.001 prev_action + 0.003 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = -0.02 1 + 1.025 value_grooming[t] + -0.002 chosen + -0.001 sig_action + 0.002 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.003 sig_waiting + 0.001 prev_action + 0.003 prev_grooming + -0.003 prev_non_contact + 0.003 prev_contact + 0.003 prev_scratch + -0.003 prev_waiting \n",
            "value_non_contact[t+1] = 0.001 1 + 0.985 value_non_contact[t] + 0.003 chosen + 0.001 sig_action + 0.003 sig_grooming + -0.003 sig_non_contact + 0.002 sig_contact + -0.003 sig_scratch + 0.001 sig_waiting + -0.003 prev_action + 0.003 prev_grooming + -0.003 prev_non_contact + 0.003 prev_contact + 0.003 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.001 1 + 1.001 value_contact[t] + -0.003 chosen + -0.003 sig_action + 0.003 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.003 sig_waiting + 0.003 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.003 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_scratch[t+1] = 0.001 1 + 0.999 value_scratch[t] + -0.001 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_waiting[t+1] = -0.001 1 + 1.003 value_waiting[t] + 0.003 chosen + -0.003 sig_action + 0.003 sig_grooming + -0.003 sig_non_contact + -0.003 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.003 prev_action + 0.003 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.003 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "Maximum number of training epochs reached.\n",
            "Model did not converge yet.\n",
            "\n",
            "================================================================================\n",
            "Starting second stage SINDy fitting (threshold=0.05, single model)\n",
            "================================================================================\n",
            "================================================================================\n",
            "Epoch 1/10 --- L(Train): 0.0501219 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.011 1 + 0.992 value_action[t] + 0.009 chosen + 0.01 sig_action + 0.009 sig_grooming + 0.01 sig_non_contact + -0.01 sig_contact + -0.009 sig_scratch + 0.009 sig_waiting + 0.009 prev_action + -0.01 prev_grooming + -0.01 prev_non_contact + -0.009 prev_contact + 0.009 prev_scratch + 0.01 prev_waiting \n",
            "value_grooming[t+1] = -0.01 1 + 0.99 value_grooming[t] + -0.009 chosen + 0.01 sig_action + 0.009 sig_grooming + -0.01 sig_non_contact + 0.009 sig_contact + -0.01 sig_scratch + -0.01 sig_waiting + -0.009 prev_action + 0.008 prev_grooming + 0.01 prev_non_contact + 0.01 prev_contact + 0.009 prev_scratch + -0.01 prev_waiting \n",
            "value_non_contact[t+1] = 0.009 1 + 1.01 value_non_contact[t] + 0.011 chosen + -0.01 sig_action + -0.009 sig_grooming + 0.011 sig_non_contact + -0.01 sig_contact + -0.008 sig_scratch + -0.008 sig_waiting + 0.008 prev_action + -0.01 prev_grooming + 0.009 prev_non_contact + -0.008 prev_contact + 0.01 prev_scratch + 0.009 prev_waiting \n",
            "value_contact[t+1] = -0.009 1 + 0.992 value_contact[t] + -0.009 chosen + 0.009 sig_action + -0.009 sig_grooming + 0.008 sig_non_contact + 0.009 sig_contact + -0.008 sig_scratch + -0.01 sig_waiting + -0.009 prev_action + -0.009 prev_grooming + -0.01 prev_non_contact + -0.009 prev_contact + -0.009 prev_scratch + 0.009 prev_waiting \n",
            "value_scratch[t+1] = -0.01 1 + 0.99 value_scratch[t] + 0.009 chosen + 0.009 sig_action + -0.01 sig_grooming + -0.01 sig_non_contact + 0.009 sig_contact + -0.01 sig_scratch + -0.01 sig_waiting + 0.009 prev_action + -0.01 prev_grooming + -0.01 prev_non_contact + 0.009 prev_contact + 0.009 prev_scratch + 0.01 prev_waiting \n",
            "value_waiting[t+1] = 0.01 1 + 0.99 value_waiting[t] + 0.009 chosen + -0.01 sig_action + -0.009 sig_grooming + 0.009 sig_non_contact + -0.008 sig_contact + 0.01 sig_scratch + -0.01 sig_waiting + 0.008 prev_action + -0.009 prev_grooming + -0.01 prev_non_contact + 0.008 prev_contact + -0.01 prev_scratch + -0.01 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 2/10 --- L(Train): 0.0493096 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.02 1 + 0.992 value_action[t] + 0.009 chosen + 0.009 sig_action + 0.017 sig_grooming + 0.008 sig_non_contact + -0.009 sig_contact + -0.008 sig_scratch + 0.009 sig_waiting + 0.009 prev_action + -0.009 prev_grooming + -0.009 prev_non_contact + -0.009 prev_contact + 0.008 prev_scratch + 0.009 prev_waiting \n",
            "value_grooming[t+1] = -0.019 1 + 0.991 value_grooming[t] + -0.007 chosen + 0.009 sig_action + 0.009 sig_grooming + -0.02 sig_non_contact + 0.009 sig_contact + -0.009 sig_scratch + -0.009 sig_waiting + -0.009 prev_action + 0.008 prev_grooming + 0.009 prev_non_contact + 0.009 prev_contact + 0.009 prev_scratch + -0.009 prev_waiting \n",
            "value_non_contact[t+1] = 0.005 1 + 1.004 value_non_contact[t] + 0.02 chosen + -0.009 sig_action + -0.019 sig_grooming + 0.021 sig_non_contact + -0.009 sig_contact + -0.007 sig_scratch + -0.007 sig_waiting + 0.007 prev_action + -0.009 prev_grooming + 0.008 prev_non_contact + -0.007 prev_contact + 0.009 prev_scratch + 0.008 prev_waiting \n",
            "value_contact[t+1] = -0.019 1 + 0.992 value_contact[t] + -0.009 chosen + 0.009 sig_action + -0.018 sig_grooming + 0.007 sig_non_contact + 0.008 sig_contact + -0.007 sig_scratch + -0.009 sig_waiting + -0.008 prev_action + -0.009 prev_grooming + -0.009 prev_non_contact + -0.009 prev_contact + -0.009 prev_scratch + 0.008 prev_waiting \n",
            "value_scratch[t+1] = -0.017 1 + 0.991 value_scratch[t] + 0.008 chosen + 0.009 sig_action + -0.014 sig_grooming + -0.012 sig_non_contact + 0.009 sig_contact + -0.009 sig_scratch + -0.009 sig_waiting + 0.008 prev_action + -0.009 prev_grooming + -0.009 prev_non_contact + 0.009 prev_contact + 0.009 prev_scratch + 0.009 prev_waiting \n",
            "value_waiting[t+1] = 0.018 1 + 0.991 value_waiting[t] + 0.008 chosen + -0.009 sig_action + -0.003 sig_grooming + 0.01 sig_non_contact + -0.008 sig_contact + 0.009 sig_scratch + -0.009 sig_waiting + 0.008 prev_action + -0.009 prev_grooming + -0.009 prev_non_contact + 0.007 prev_contact + -0.009 prev_scratch + -0.009 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 3/10 --- L(Train): 0.0473832 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.03 1 + 0.996 value_action[t] + 0.005 chosen + 0.005 sig_action + 0.024 sig_grooming + 0.002 sig_non_contact + -0.005 sig_contact + -0.004 sig_scratch + 0.005 sig_waiting + 0.005 prev_action + -0.005 prev_grooming + -0.005 prev_non_contact + -0.005 prev_contact + 0.004 prev_scratch + 0.005 prev_waiting \n",
            "value_grooming[t+1] = -0.028 1 + 0.995 value_grooming[t] + -0.002 chosen + 0.005 sig_action + 0.007 sig_grooming + -0.03 sig_non_contact + 0.005 sig_contact + -0.005 sig_scratch + -0.005 sig_waiting + -0.005 prev_action + 0.004 prev_grooming + 0.005 prev_non_contact + 0.005 prev_contact + 0.005 prev_scratch + -0.005 prev_waiting \n",
            "value_non_contact[t+1] = -0.003 1 + 0.996 value_non_contact[t] + 0.03 chosen + -0.005 sig_action + -0.027 sig_grooming + 0.03 sig_non_contact + -0.005 sig_contact + -0.003 sig_scratch + -0.003 sig_waiting + 0.003 prev_action + -0.005 prev_grooming + 0.004 prev_non_contact + -0.003 prev_contact + 0.005 prev_scratch + 0.004 prev_waiting \n",
            "value_contact[t+1] = -0.029 1 + 0.996 value_contact[t] + -0.005 chosen + 0.004 sig_action + -0.028 sig_grooming + 0.003 sig_non_contact + 0.004 sig_contact + -0.003 sig_scratch + -0.005 sig_waiting + -0.004 prev_action + -0.004 prev_grooming + -0.005 prev_non_contact + -0.005 prev_contact + -0.005 prev_scratch + 0.004 prev_waiting \n",
            "value_scratch[t+1] = -0.023 1 + 0.995 value_scratch[t] + 0.004 chosen + 0.005 sig_action + -0.016 sig_grooming + -0.01 sig_non_contact + 0.005 sig_contact + -0.005 sig_scratch + -0.005 sig_waiting + 0.004 prev_action + -0.005 prev_grooming + -0.005 prev_non_contact + 0.005 prev_contact + 0.005 prev_scratch + 0.005 prev_waiting \n",
            "value_waiting[t+1] = 0.024 1 + 0.995 value_waiting[t] + 0.004 chosen + -0.005 sig_action + 0.005 sig_grooming + 0.007 sig_non_contact + -0.004 sig_contact + 0.005 sig_scratch + -0.005 sig_waiting + 0.004 prev_action + -0.005 prev_grooming + -0.005 prev_non_contact + 0.003 prev_contact + -0.005 prev_scratch + -0.005 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
            "value_grooming: 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
            "value_non_contact: 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
            "value_contact: 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
            "value_scratch: 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
            "value_waiting: 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 4/10 --- L(Train): 0.0452929 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.038 1 + 1.001 value_action[t] + -0.001 chosen + -0.0 sig_action + 0.03 sig_grooming + -0.004 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = -0.037 1 + 1.0 value_grooming[t] + 0.004 chosen + -0.001 sig_action + 0.002 sig_grooming + -0.04 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.008 1 + 0.991 value_non_contact[t] + 0.04 chosen + 0.0 sig_action + -0.036 sig_grooming + 0.04 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + 0.0 prev_grooming + -0.002 prev_non_contact + 0.003 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.002 value_contact[t] + 0.001 chosen + -0.001 sig_action + -0.037 sig_grooming + -0.002 sig_non_contact + -0.002 sig_contact + 0.003 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.028 1 + 1.001 value_scratch[t] + -0.001 chosen + -0.001 sig_action + -0.015 sig_grooming + -0.006 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.029 1 + 1.001 value_waiting[t] + -0.002 chosen + 0.001 sig_action + 0.01 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.003 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2\n",
            "value_grooming: 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2\n",
            "value_non_contact: 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2\n",
            "value_contact: 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2\n",
            "value_scratch: 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2\n",
            "value_waiting: 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 5/10 --- L(Train): 0.0435108 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.046 1 + 1.002 value_action[t] + -0.003 chosen + -0.002 sig_action + 0.035 sig_grooming + -0.009 sig_non_contact + 0.002 sig_contact + 0.003 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + 0.003 prev_contact + -0.003 prev_scratch + -0.003 prev_waiting \n",
            "value_grooming[t+1] = -0.046 1 + 1.002 value_grooming[t] + 0.008 chosen + -0.002 sig_action + -0.004 sig_grooming + -0.049 sig_non_contact + -0.003 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + 0.003 prev_action + -0.004 prev_grooming + -0.003 prev_non_contact + -0.003 prev_contact + -0.003 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.012 1 + 0.988 value_non_contact[t] + 0.049 chosen + 0.002 sig_action + -0.045 sig_grooming + 0.049 sig_non_contact + 0.002 sig_contact + 0.004 sig_scratch + 0.005 sig_waiting + -0.005 prev_action + 0.002 prev_grooming + -0.004 prev_non_contact + 0.004 prev_contact + -0.002 prev_scratch + -0.004 prev_waiting \n",
            "value_contact[t+1] = -0.048 1 + 1.003 value_contact[t] + 0.003 chosen + -0.003 sig_action + -0.046 sig_grooming + -0.003 sig_non_contact + -0.003 sig_contact + 0.005 sig_scratch + 0.002 sig_waiting + 0.003 prev_action + 0.003 prev_grooming + 0.002 prev_non_contact + 0.003 prev_contact + 0.003 prev_scratch + -0.004 prev_waiting \n",
            "value_scratch[t+1] = -0.032 1 + 1.003 value_scratch[t] + -0.003 chosen + -0.003 sig_action + -0.012 sig_grooming + -0.0 sig_non_contact + -0.003 sig_contact + 0.003 sig_scratch + 0.002 sig_waiting + -0.003 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + -0.003 prev_contact + -0.003 prev_scratch + -0.003 prev_waiting \n",
            "value_waiting[t+1] = 0.032 1 + 1.003 value_waiting[t] + -0.004 chosen + 0.003 sig_action + 0.013 sig_grooming + -0.005 sig_non_contact + 0.004 sig_contact + -0.002 sig_scratch + 0.003 sig_waiting + -0.004 prev_action + 0.003 prev_grooming + 0.002 prev_non_contact + -0.004 prev_contact + 0.002 prev_scratch + 0.003 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3\n",
            "value_grooming: 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3\n",
            "value_non_contact: 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3\n",
            "value_contact: 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3\n",
            "value_scratch: 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3\n",
            "value_waiting: 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 6/10 --- L(Train): 0.0424373 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.053 1 + 1.001 value_action[t] + -0.002 chosen + -0.002 sig_action + 0.039 sig_grooming + -0.011 sig_non_contact + 0.002 sig_contact + 0.003 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + 0.002 prev_contact + -0.003 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = -0.054 1 + 1.001 value_grooming[t] + 0.01 chosen + -0.002 sig_action + -0.004 sig_grooming + -0.058 sig_non_contact + -0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + -0.003 prev_grooming + -0.002 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.016 1 + 0.986 value_non_contact[t] + 0.059 chosen + 0.002 sig_action + -0.053 sig_grooming + 0.059 sig_non_contact + 0.002 sig_contact + 0.004 sig_scratch + 0.004 sig_waiting + -0.004 prev_action + 0.002 prev_grooming + -0.003 prev_non_contact + 0.004 prev_contact + -0.002 prev_scratch + -0.003 prev_waiting \n",
            "value_contact[t+1] = -0.058 1 + 1.002 value_contact[t] + 0.003 chosen + -0.003 sig_action + -0.056 sig_grooming + -0.001 sig_non_contact + -0.003 sig_contact + 0.004 sig_scratch + 0.002 sig_waiting + 0.003 prev_action + 0.003 prev_grooming + 0.002 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.034 1 + 1.003 value_scratch[t] + -0.003 chosen + -0.002 sig_action + -0.009 sig_grooming + 0.006 sig_non_contact + -0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.003 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + -0.002 prev_contact + -0.003 prev_scratch + -0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.034 1 + 1.002 value_waiting[t] + -0.003 chosen + 0.002 sig_action + 0.013 sig_grooming + -0.008 sig_non_contact + 0.003 sig_contact + -0.002 sig_scratch + 0.002 sig_waiting + -0.003 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + -0.004 prev_contact + 0.002 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4\n",
            "value_grooming: 0, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4\n",
            "value_non_contact: 4, 4, 0, 4, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4\n",
            "value_contact: 0, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4\n",
            "value_scratch: 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4\n",
            "value_waiting: 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 7/10 --- L(Train): 0.0411899 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.059 1 + 0.998 value_action[t] + 0.0 chosen + 0.001 sig_action + 0.042 sig_grooming + -0.012 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = -0.062 1 + 0.999 value_grooming[t] + 0.01 chosen + 0.001 sig_action + -0.002 sig_grooming + -0.067 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.019 1 + 0.986 value_non_contact[t] + 0.067 chosen + -0.001 sig_action + -0.061 sig_grooming + 0.067 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.067 1 + 0.998 value_contact[t] + 0.0 chosen + -0.0 sig_action + -0.065 sig_grooming + 0.003 sig_non_contact + -0.0 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.036 1 + 1.0 value_scratch[t] + -0.0 chosen + 0.0 sig_action + -0.004 sig_grooming + 0.009 sig_non_contact + 0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.035 1 + 1.0 value_waiting[t] + -0.001 chosen + -0.0 sig_action + 0.013 sig_grooming + -0.009 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5\n",
            "value_grooming: 0, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5\n",
            "value_non_contact: 5, 5, 0, 5, 0, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5\n",
            "value_contact: 0, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5\n",
            "value_scratch: 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5\n",
            "value_waiting: 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 8/10 --- L(Train): 0.0398949 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.063 1 + 0.997 value_action[t] + 0.0 chosen + 0.001 sig_action + 0.045 sig_grooming + -0.012 sig_non_contact + -0.001 sig_contact + -0.003 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.003 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = -0.07 1 + 0.998 value_grooming[t] + 0.01 chosen + 0.001 sig_action + 0.002 sig_grooming + -0.075 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.003 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.022 1 + 0.987 value_non_contact[t] + 0.076 chosen + -0.001 sig_action + -0.069 sig_grooming + 0.076 sig_non_contact + -0.001 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + 0.003 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.076 1 + 0.997 value_contact[t] + -0.004 chosen + 0.004 sig_action + -0.074 sig_grooming + 0.006 sig_non_contact + 0.003 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + -0.003 prev_action + -0.004 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.004 prev_scratch + 0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.038 1 + 0.997 value_scratch[t] + 0.003 chosen + 0.0 sig_action + 0.001 sig_grooming + 0.01 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.003 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.004 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.035 1 + 0.999 value_waiting[t] + 0.003 chosen + -0.001 sig_action + 0.011 sig_grooming + -0.008 sig_non_contact + -0.003 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.003 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6\n",
            "value_grooming: 0, 6, 6, 6, 6, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6\n",
            "value_non_contact: 6, 6, 0, 6, 0, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6\n",
            "value_contact: 0, 6, 6, 6, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6\n",
            "value_scratch: 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6\n",
            "value_waiting: 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 9/10 --- L(Train): 0.0389897 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.065 1 + 0.998 value_action[t] + -0.001 chosen + -0.001 sig_action + 0.046 sig_grooming + -0.011 sig_non_contact + 0.0 sig_contact + -0.005 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.005 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = -0.076 1 + 1.0 value_grooming[t] + 0.009 chosen + -0.001 sig_action + 0.005 sig_grooming + -0.083 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + 0.004 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.025 1 + 0.989 value_non_contact[t] + 0.084 chosen + 0.001 sig_action + -0.077 sig_grooming + 0.084 sig_non_contact + 0.0 sig_contact + -0.004 sig_scratch + -0.004 sig_waiting + 0.004 prev_action + 0.0 prev_grooming + 0.005 prev_non_contact + -0.004 prev_contact + -0.001 prev_scratch + 0.005 prev_waiting \n",
            "value_contact[t+1] = -0.085 1 + 0.997 value_contact[t] + -0.005 chosen + 0.005 sig_action + -0.083 sig_grooming + 0.008 sig_non_contact + 0.005 sig_contact + -0.004 sig_scratch + 0.001 sig_waiting + -0.005 prev_action + -0.005 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.005 prev_scratch + 0.005 prev_waiting \n",
            "value_scratch[t+1] = -0.04 1 + 0.995 value_scratch[t] + 0.005 chosen + -0.001 sig_action + 0.002 sig_grooming + 0.008 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.005 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.005 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.035 1 + 1.001 value_waiting[t] + 0.005 chosen + 0.001 sig_action + 0.009 sig_grooming + -0.005 sig_non_contact + -0.005 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.004 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.004 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7\n",
            "value_grooming: 0, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7\n",
            "value_non_contact: 7, 7, 0, 7, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7\n",
            "value_contact: 0, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7\n",
            "value_scratch: 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7\n",
            "value_waiting: 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 10/10 --- L(Train): 0.0381031 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.066 1 + 1.0 value_action[t] + -0.001 chosen + -0.0 sig_action + 0.047 sig_grooming + -0.009 sig_non_contact + 0.0 sig_contact + -0.005 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.005 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = -0.082 1 + 1.002 value_grooming[t] + 0.007 chosen + -0.0 sig_action + 0.007 sig_grooming + -0.09 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + 0.004 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.027 1 + 0.992 value_non_contact[t] + 0.091 chosen + 0.0 sig_action + -0.084 sig_grooming + 0.091 sig_non_contact + 0.0 sig_contact + -0.004 sig_scratch + -0.003 sig_waiting + 0.003 prev_action + 0.0 prev_grooming + 0.005 prev_non_contact + -0.004 prev_contact + -0.0 prev_scratch + 0.005 prev_waiting \n",
            "value_contact[t+1] = -0.094 1 + 0.997 value_contact[t] + -0.005 chosen + 0.005 sig_action + -0.092 sig_grooming + 0.009 sig_non_contact + 0.005 sig_contact + -0.003 sig_scratch + 0.0 sig_waiting + -0.005 prev_action + -0.005 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.005 prev_scratch + 0.004 prev_waiting \n",
            "value_scratch[t+1] = -0.041 1 + 0.996 value_scratch[t] + 0.005 chosen + -0.001 sig_action + 0.001 sig_grooming + 0.006 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.005 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.005 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.033 1 + 1.001 value_waiting[t] + 0.004 chosen + 0.0 sig_action + 0.005 sig_grooming + -0.002 sig_non_contact + -0.004 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.004 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.004 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8\n",
            "value_grooming: 0, 8, 8, 8, 8, 0, 8, 8, 8, 8, 8, 8, 8, 8, 8\n",
            "value_non_contact: 8, 8, 0, 8, 0, 0, 8, 8, 8, 8, 8, 8, 8, 8, 8\n",
            "value_contact: 0, 8, 8, 8, 0, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8\n",
            "value_scratch: 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8\n",
            "value_waiting: 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 11/10 --- L(Train): 0.0371923 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.065 1 + 1.003 value_action[t] + 0.001 chosen + 0.002 sig_action + 0.047 sig_grooming + -0.007 sig_non_contact + -0.002 sig_contact + -0.003 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + 0.003 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = -0.087 1 + 1.003 value_grooming[t] + 0.005 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.096 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.03 1 + 0.996 value_non_contact[t] + 0.097 chosen + -0.002 sig_action + -0.091 sig_grooming + 0.097 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + 0.003 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.103 1 + 0.999 value_contact[t] + -0.003 chosen + 0.003 sig_action + -0.1 sig_grooming + 0.009 sig_non_contact + 0.003 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.042 1 + 0.997 value_scratch[t] + 0.003 chosen + 0.001 sig_action + -0.002 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.003 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + 0.003 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.032 1 + 0.999 value_waiting[t] + 0.003 chosen + -0.001 sig_action + 0.001 sig_grooming + 0.002 sig_non_contact + -0.003 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9\n",
            "value_grooming: 0, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9\n",
            "value_non_contact: 9, 9, 0, 9, 0, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9\n",
            "value_contact: 0, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9\n",
            "value_scratch: 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9\n",
            "value_waiting: 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9\n",
            "================================================================================\n",
            "\n",
            "Training result:\n",
            "L(Train): 1.5677795 --- L(Val, RNN): 1.5391196 --- L(Val, SINDy): 1.6079898\n",
            "\n",
            "RNN training finished.\n",
            "Training took 25.23 seconds.\n",
            "Saving SPICE model to ../params/hwang2025/spice_ep10_warm100_th0.05_alpha0.01.pkl...\n",
            "================================================================================\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Example SPICE model (participant 0):\n",
            "--------------------------------------------------------------------------------\n",
            "value_action[t+1] = 0.065 1 + 1.003 value_action[t] + 0.001 chosen + 0.002 sig_action + 0.047 sig_grooming + -0.007 sig_non_contact + -0.002 sig_contact + -0.003 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + 0.003 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = -0.087 1 + 1.003 value_grooming[t] + 0.005 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.096 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.03 1 + 0.996 value_non_contact[t] + 0.097 chosen + -0.002 sig_action + -0.091 sig_grooming + 0.097 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + 0.003 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.103 1 + 0.999 value_contact[t] + -0.003 chosen + 0.003 sig_action + -0.1 sig_grooming + 0.009 sig_non_contact + 0.003 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.042 1 + 0.997 value_scratch[t] + 0.003 chosen + 0.001 sig_action + -0.002 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.003 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + 0.003 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.032 1 + 0.999 value_waiting[t] + 0.003 chosen + -0.001 sig_action + 0.001 sig_grooming + 0.002 sig_non_contact + -0.003 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# if epochs==4000: warmup_steps=1000; sindy_weight=1;\n",
        "\n",
        "runs = [\n",
        "    (10, 100, 0.05, 1e-2),\n",
        "    #(1000, 100, 0.05, 1e-5),\n",
        "    #(1000, 100, 0.05, 1e-3),\n",
        "    #(1000, 100, 0.1, 1e-4),\n",
        "    #(1000, 100, 0.1, 1e-5),\n",
        "    #(1000, 100, 0.1, 1e-3),\n",
        "    #(4000, 1000, 0.05, 1e-4),\n",
        "    #(4000, 1000, 0.05, 1e-5),\n",
        "    #(4000, 1000, 0.05, 1e-3),\n",
        "    #(4000, 1000, 0.1, 1e-4),\n",
        "    #(4000, 1000, 0.1, 1e-5),\n",
        "    #(4000, 1000, 0.1, 1e-3),\n",
        "]\n",
        "\n",
        "for epochs, warmup_steps, sindy_threshold, sindy_alpha in runs:\n",
        "    exp_tag = f\"ep{epochs}_warm{warmup_steps}_th{sindy_threshold:g}_alpha{sindy_alpha:g}\"\n",
        "    save_path = f\"../params/hwang2025/spice_{exp_tag}.pkl\"\n",
        "\n",
        "    estimator = SpiceEstimator(\n",
        "            # model paramaeters\n",
        "            rnn_class=SPICERNN,\n",
        "            spice_config=spice_config,\n",
        "            n_actions=6,\n",
        "            # n_items=6,\n",
        "            n_participants=n_participants,\n",
        "            n_experiments=1,\n",
        "            \n",
        "            # rnn training parameters\n",
        "            epochs=epochs,  # --> try: 1000 --> 4000\n",
        "            warmup_steps=warmup_steps,  # if epochs==4000: warmup_steps=1000\n",
        "            l2_rnn=0,#.00001,\n",
        "            learning_rate=0.01,\n",
        "            \n",
        "            # sindy fitting parameters\n",
        "            sindy_weight=0.001,\n",
        "            sindy_threshold=sindy_threshold,  # try: 0.1\n",
        "            sindy_threshold_frequency=1,\n",
        "            sindy_threshold_terms=1,\n",
        "            sindy_cutoff_patience=100,\n",
        "            sindy_epochs=10,\n",
        "            sindy_alpha=sindy_alpha,  # try: 0.00001, 0.001\n",
        "            sindy_library_polynomial_degree=1,\n",
        "            \n",
        "            verbose=True,\n",
        "            device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
        "            save_path_spice=save_path,\n",
        "        )\n",
        "\n",
        "    #print(f\"\\nStarting training on {estimator.device}...\")\n",
        "    print(f\"\\nStarting training ({exp_tag}) on {estimator.device}...\")\n",
        "    print(\"=\" * 80)\n",
        "    estimator.fit(dataset_train.xs, dataset_train.ys, dataset_test.xs, dataset_test.ys)\n",
        "    # estimator.load_spice(args.model)\n",
        "    print(\"=\" * 80)\n",
        "    print(\"\\nTraining complete!\")\n",
        "\n",
        "    # Print example SPICE model for first participant\n",
        "    print(\"\\nExample SPICE model (participant 0):\")\n",
        "    print(\"-\" * 80)\n",
        "    estimator.print_spice_model(participant_id=0)\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "print(estimator.rnn_model.sindy_ensemble_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training\n",
            "================================================================================\n",
            "\n",
            "Training the RNN...\n",
            "================================================================================\n",
            "Epoch 1/10 --- L(Train): 2.0816371 --- L(Val, RNN): 1.7770035 --- L(Val, SINDy): 1.7924765 --- Time: 2.56s; --- Convergence: 8.89e-01\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.002 1 + 1.0 value_action[t] + 0.001 chosen + -0.0 sig_action + 0.0 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = -0.001 1 + 0.997 value_grooming[t] + -0.001 chosen + 0.001 sig_action + 0.001 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + -0.003 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = 0.001 1 + 1.002 value_non_contact[t] + 0.001 chosen + -0.001 sig_action + -0.002 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.002 1 + 1.0 value_contact[t] + 0.0 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.0 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.001 1 + 1.001 value_scratch[t] + 0.0 chosen + 0.0 sig_action + -0.0 sig_grooming + 0.0 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = -0.001 1 + 1.0 value_waiting[t] + 0.001 chosen + -0.0 sig_action + 0.001 sig_grooming + 0.0 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 2/10 --- L(Train): 1.7887899 --- L(Val, RNN): 1.6820525 --- L(Val, SINDy): 1.7913048 --- Time: 2.49s; --- Convergence: 4.92e-01\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.002 1 + 1.0 value_action[t] + 0.001 chosen + -0.0 sig_action + 0.0 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = -0.001 1 + 0.997 value_grooming[t] + -0.001 chosen + 0.001 sig_action + 0.001 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + -0.003 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = 0.001 1 + 1.002 value_non_contact[t] + 0.001 chosen + -0.001 sig_action + -0.002 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.002 1 + 1.0 value_contact[t] + 0.0 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.0 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.001 1 + 1.001 value_scratch[t] + 0.0 chosen + 0.0 sig_action + -0.0 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = -0.001 1 + 0.999 value_waiting[t] + 0.001 chosen + -0.0 sig_action + 0.001 sig_grooming + 0.0 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 3/10 --- L(Train): 1.6949177 --- L(Val, RNN): 1.6180549 --- L(Val, SINDy): 1.7880137 --- Time: 2.43s; --- Convergence: 2.78e-01\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.002 1 + 0.999 value_action[t] + 0.001 chosen + -0.0 sig_action + 0.0 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = -0.001 1 + 0.997 value_grooming[t] + -0.001 chosen + 0.001 sig_action + 0.001 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = 0.002 1 + 1.001 value_non_contact[t] + 0.001 chosen + -0.001 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.001 1 + 1.0 value_contact[t] + 0.0 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.0 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.0 1 + 1.0 value_scratch[t] + 0.0 chosen + 0.0 sig_action + -0.0 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = -0.001 1 + 0.996 value_waiting[t] + 0.001 chosen + -0.0 sig_action + 0.001 sig_grooming + 0.0 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 4/10 --- L(Train): 1.6371514 --- L(Val, RNN): 1.5750500 --- L(Val, SINDy): 1.7808274 --- Time: 2.44s; --- Convergence: 1.60e-01\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.002 1 + 0.998 value_action[t] + 0.001 chosen + -0.0 sig_action + 0.001 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = -0.001 1 + 0.996 value_grooming[t] + -0.001 chosen + 0.001 sig_action + 0.001 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = 0.002 1 + 0.999 value_non_contact[t] + 0.001 chosen + -0.001 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.001 1 + 1.0 value_contact[t] + 0.0 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.0 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.0 1 + 0.999 value_scratch[t] + 0.0 chosen + 0.0 sig_action + -0.0 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = -0.001 1 + 0.991 value_waiting[t] + 0.001 chosen + -0.0 sig_action + 0.0 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 5/10 --- L(Train): 1.5864463 --- L(Val, RNN): 1.5465282 --- L(Val, SINDy): 1.7674102 --- Time: 2.52s; --- Convergence: 9.45e-02\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.002 1 + 0.996 value_action[t] + 0.001 chosen + -0.0 sig_action + 0.001 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = -0.0 1 + 0.996 value_grooming[t] + -0.001 chosen + 0.001 sig_action + 0.001 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = 0.003 1 + 0.995 value_non_contact[t] + 0.0 chosen + -0.001 sig_action + -0.001 sig_grooming + -0.002 sig_non_contact + 0.002 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.001 1 + 0.999 value_contact[t] + 0.0 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.0 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.0 1 + 0.998 value_scratch[t] + 0.0 chosen + 0.0 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = -0.001 1 + 0.984 value_waiting[t] + 0.001 chosen + -0.0 sig_action + 0.0 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 6/10 --- L(Train): 1.5648003 --- L(Val, RNN): 1.5274819 --- L(Val, SINDy): 1.7472409 --- Time: 2.56s; --- Convergence: 5.68e-02\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.002 1 + 0.994 value_action[t] + 0.001 chosen + -0.0 sig_action + 0.002 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.0 1 + 0.995 value_grooming[t] + -0.001 chosen + 0.001 sig_action + 0.001 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = 0.001 1 + 0.989 value_non_contact[t] + -0.001 chosen + -0.001 sig_action + -0.002 sig_grooming + -0.003 sig_non_contact + 0.002 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.0 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.0 1 + 0.999 value_contact[t] + 0.0 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.0 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.001 1 + 0.995 value_scratch[t] + 0.0 chosen + 0.0 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = -0.001 1 + 0.977 value_waiting[t] + 0.001 chosen + -0.0 sig_action + 0.0 sig_grooming + 0.002 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 7/10 --- L(Train): 1.5488423 --- L(Val, RNN): 1.5111639 --- L(Val, SINDy): 1.7222934 --- Time: 2.56s; --- Convergence: 3.65e-02\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.992 value_action[t] + 0.0 chosen + -0.0 sig_action + 0.003 sig_grooming + -0.003 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.003 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 0.994 value_grooming[t] + -0.001 chosen + 0.001 sig_action + 0.001 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.003 1 + 0.983 value_non_contact[t] + -0.003 chosen + -0.001 sig_action + -0.004 sig_grooming + -0.005 sig_non_contact + 0.002 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + 0.004 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = 0.0 1 + 0.999 value_contact[t] + 0.0 chosen + -0.001 sig_action + -0.001 sig_grooming + -0.0 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.002 1 + 0.992 value_scratch[t] + 0.0 chosen + 0.0 sig_action + -0.002 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.003 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.0 1 + 0.971 value_waiting[t] + 0.001 chosen + -0.0 sig_action + -0.0 sig_grooming + 0.003 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 8/10 --- L(Train): 1.5298692 --- L(Val, RNN): 1.4969591 --- L(Val, SINDy): 1.6946139 --- Time: 2.67s; --- Convergence: 2.54e-02\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.988 value_action[t] + 0.0 chosen + -0.0 sig_action + 0.005 sig_grooming + -0.003 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.003 prev_grooming + 0.003 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 0.993 value_grooming[t] + -0.001 chosen + 0.001 sig_action + 0.001 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.008 1 + 0.978 value_non_contact[t] + -0.005 chosen + -0.001 sig_action + -0.009 sig_grooming + -0.008 sig_non_contact + 0.002 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.005 prev_grooming + 0.005 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.0 1 + 0.999 value_contact[t] + 0.0 chosen + -0.001 sig_action + -0.002 sig_grooming + -0.0 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.005 1 + 0.987 value_scratch[t] + 0.0 chosen + 0.0 sig_action + -0.005 sig_grooming + -0.003 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.004 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 0.966 value_waiting[t] + 0.001 chosen + -0.0 sig_action + -0.0 sig_grooming + 0.004 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + 0.003 prev_grooming + 0.002 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 9/10 --- L(Train): 1.5184298 --- L(Val, RNN): 1.4848546 --- L(Val, SINDy): 1.6692467 --- Time: 2.46s; --- Convergence: 1.87e-02\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.984 value_action[t] + 0.0 chosen + -0.0 sig_action + 0.007 sig_grooming + -0.005 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.005 prev_grooming + 0.005 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 0.989 value_grooming[t] + 0.0 chosen + 0.001 sig_action + 0.002 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.014 1 + 0.978 value_non_contact[t] + -0.009 chosen + -0.001 sig_action + -0.014 sig_grooming + -0.011 sig_non_contact + 0.002 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + -0.009 prev_grooming + 0.005 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.001 1 + 0.999 value_contact[t] + 0.0 chosen + -0.001 sig_action + -0.003 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.009 1 + 0.982 value_scratch[t] + 0.0 chosen + 0.0 sig_action + -0.008 sig_grooming + -0.006 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.006 prev_grooming + 0.003 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 0.96 value_waiting[t] + 0.001 chosen + -0.0 sig_action + -0.0 sig_grooming + 0.005 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + 0.004 prev_grooming + 0.002 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\n",
            ">>> Warmup complete (epoch 10). Reset optimizer state for 6 SINDy parameters (fresh start at full regularization strength).\n",
            "\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 10/10 --- L(Train): 1.5131233 --- L(Val, RNN): 1.4749963 --- L(Val, SINDy): 1.6477003 --- Time: 2.46s; --- Convergence: 1.43e-02\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.002 1 + 0.98 value_action[t] + 0.0 chosen + -0.0 sig_action + 0.01 sig_grooming + -0.008 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.008 prev_grooming + 0.007 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 0.985 value_grooming[t] + 0.002 chosen + 0.001 sig_action + 0.004 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.021 1 + 0.981 value_non_contact[t] + -0.014 chosen + -0.001 sig_action + -0.02 sig_grooming + -0.016 sig_non_contact + 0.002 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + -0.013 prev_grooming + 0.005 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.002 1 + 0.999 value_contact[t] + 0.0 chosen + -0.001 sig_action + -0.004 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.013 1 + 0.976 value_scratch[t] + 0.0 chosen + 0.0 sig_action + -0.013 sig_grooming + -0.009 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.01 prev_grooming + 0.003 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = -0.001 1 + 0.954 value_waiting[t] + 0.001 chosen + -0.0 sig_action + 0.0 sig_grooming + 0.006 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + 0.005 prev_grooming + 0.003 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
            "value_grooming: 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
            "value_non_contact: 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
            "value_contact: 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
            "value_scratch: 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
            "value_waiting: 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
            "================================================================================\n",
            "Maximum number of training epochs reached.\n",
            "Model did not converge yet.\n",
            "\n",
            "================================================================================\n",
            "Starting second stage SINDy fitting (threshold=0.05, single model)\n",
            "================================================================================\n",
            "================================================================================\n",
            "Epoch 1/1000 --- L(Train): 0.1976582 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.009 1 + 0.991 value_action[t] + -0.01 chosen + 0.009 sig_action + 0.011 sig_grooming + -0.01 sig_non_contact + 0.01 sig_contact + 0.01 sig_scratch + 0.01 sig_waiting + -0.01 prev_action + -0.01 prev_grooming + -0.01 prev_non_contact + 0.008 prev_contact + -0.01 prev_scratch + 0.009 prev_waiting \n",
            "value_grooming[t+1] = 0.01 1 + 1.009 value_grooming[t] + 0.01 chosen + -0.01 sig_action + 0.01 sig_grooming + 0.008 sig_non_contact + 0.009 sig_contact + -0.009 sig_scratch + -0.01 sig_waiting + -0.01 prev_action + -0.01 prev_grooming + 0.01 prev_non_contact + -0.01 prev_contact + 0.009 prev_scratch + -0.008 prev_waiting \n",
            "value_non_contact[t+1] = -0.01 1 + 1.012 value_non_contact[t] + -0.009 chosen + 0.009 sig_action + -0.009 sig_grooming + -0.01 sig_non_contact + -0.009 sig_contact + 0.009 sig_scratch + -0.01 sig_waiting + -0.01 prev_action + -0.009 prev_grooming + 0.009 prev_non_contact + -0.009 prev_contact + -0.01 prev_scratch + 0.01 prev_waiting \n",
            "value_contact[t+1] = -0.011 1 + 1.009 value_contact[t] + 0.01 chosen + -0.009 sig_action + -0.01 sig_grooming + 0.009 sig_non_contact + -0.01 sig_contact + -0.01 sig_scratch + 0.009 sig_waiting + 0.009 prev_action + -0.009 prev_grooming + -0.01 prev_non_contact + 0.009 prev_contact + 0.009 prev_scratch + -0.009 prev_waiting \n",
            "value_scratch[t+1] = -0.011 1 + 0.991 value_scratch[t] + -0.009 chosen + -0.008 sig_action + -0.009 sig_grooming + -0.009 sig_non_contact + 0.009 sig_contact + -0.01 sig_scratch + -0.009 sig_waiting + -0.01 prev_action + -0.009 prev_grooming + -0.008 prev_non_contact + 0.009 prev_contact + -0.009 prev_scratch + -0.009 prev_waiting \n",
            "value_waiting[t+1] = 0.01 1 + 1.008 value_waiting[t] + -0.009 chosen + 0.009 sig_action + 0.008 sig_grooming + 0.011 sig_non_contact + -0.01 sig_contact + -0.009 sig_scratch + -0.009 sig_waiting + 0.009 prev_action + 0.009 prev_grooming + -0.008 prev_non_contact + -0.009 prev_contact + -0.01 prev_scratch + -0.008 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 2/1000 --- L(Train): 0.1919589 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.006 1 + 0.99 value_action[t] + -0.009 chosen + 0.008 sig_action + 0.009 sig_grooming + -0.017 sig_non_contact + 0.009 sig_contact + 0.009 sig_scratch + 0.009 sig_waiting + -0.009 prev_action + -0.009 prev_grooming + -0.009 prev_non_contact + 0.008 prev_contact + -0.009 prev_scratch + 0.008 prev_waiting \n",
            "value_grooming[t+1] = 0.004 1 + 1.008 value_grooming[t] + 0.004 chosen + -0.009 sig_action + 0.016 sig_grooming + 0.003 sig_non_contact + 0.008 sig_contact + -0.008 sig_scratch + -0.009 sig_waiting + -0.009 prev_action + -0.009 prev_grooming + 0.009 prev_non_contact + -0.009 prev_contact + 0.009 prev_scratch + -0.008 prev_waiting \n",
            "value_non_contact[t+1] = -0.02 1 + 1.021 value_non_contact[t] + -0.018 chosen + 0.009 sig_action + -0.019 sig_grooming + -0.02 sig_non_contact + -0.008 sig_contact + 0.009 sig_scratch + -0.009 sig_waiting + -0.009 prev_action + -0.008 prev_grooming + 0.008 prev_non_contact + -0.008 prev_contact + -0.009 prev_scratch + 0.009 prev_waiting \n",
            "value_contact[t+1] = -0.021 1 + 1.009 value_contact[t] + 0.009 chosen + -0.009 sig_action + -0.015 sig_grooming + 0.005 sig_non_contact + -0.009 sig_contact + -0.009 sig_scratch + 0.009 sig_waiting + 0.008 prev_action + -0.009 prev_grooming + -0.009 prev_non_contact + 0.009 prev_contact + 0.009 prev_scratch + -0.008 prev_waiting \n",
            "value_scratch[t+1] = -0.021 1 + 0.997 value_scratch[t] + -0.009 chosen + -0.008 sig_action + -0.019 sig_grooming + -0.017 sig_non_contact + 0.009 sig_contact + -0.009 sig_scratch + -0.008 sig_waiting + -0.009 prev_action + -0.008 prev_grooming + -0.007 prev_non_contact + 0.008 prev_contact + -0.009 prev_scratch + -0.009 prev_waiting \n",
            "value_waiting[t+1] = 0.02 1 + 1.006 value_waiting[t] + -0.009 chosen + 0.008 sig_action + 0.003 sig_grooming + 0.021 sig_non_contact + -0.009 sig_contact + -0.009 sig_scratch + -0.009 sig_waiting + 0.008 prev_action + 0.008 prev_grooming + -0.007 prev_non_contact + -0.008 prev_contact + -0.009 prev_scratch + -0.008 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 3/1000 --- L(Train): 0.1855419 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.0 1 + 0.993 value_action[t] + -0.005 chosen + 0.004 sig_action + 0.004 sig_grooming + -0.023 sig_non_contact + 0.005 sig_contact + 0.005 sig_scratch + 0.005 sig_waiting + -0.005 prev_action + -0.005 prev_grooming + -0.005 prev_non_contact + 0.004 prev_contact + -0.005 prev_scratch + 0.004 prev_waiting \n",
            "value_grooming[t+1] = -0.004 1 + 1.003 value_grooming[t] + -0.003 chosen + -0.005 sig_action + 0.02 sig_grooming + -0.004 sig_non_contact + 0.004 sig_contact + -0.004 sig_scratch + -0.005 sig_waiting + -0.005 prev_action + -0.005 prev_grooming + 0.005 prev_non_contact + -0.005 prev_contact + 0.005 prev_scratch + -0.004 prev_waiting \n",
            "value_non_contact[t+1] = -0.03 1 + 1.031 value_non_contact[t] + -0.026 chosen + 0.005 sig_action + -0.029 sig_grooming + -0.03 sig_non_contact + -0.004 sig_contact + 0.005 sig_scratch + -0.005 sig_waiting + -0.005 prev_action + -0.004 prev_grooming + 0.004 prev_non_contact + -0.004 prev_contact + -0.005 prev_scratch + 0.005 prev_waiting \n",
            "value_contact[t+1] = -0.03 1 + 1.005 value_contact[t] + 0.005 chosen + -0.005 sig_action + -0.017 sig_grooming + -0.001 sig_non_contact + -0.005 sig_contact + -0.005 sig_scratch + 0.005 sig_waiting + 0.004 prev_action + -0.005 prev_grooming + -0.005 prev_non_contact + 0.005 prev_contact + 0.005 prev_scratch + -0.004 prev_waiting \n",
            "value_scratch[t+1] = -0.031 1 + 1.005 value_scratch[t] + -0.005 chosen + -0.004 sig_action + -0.028 sig_grooming + -0.024 sig_non_contact + 0.004 sig_contact + -0.005 sig_scratch + -0.004 sig_waiting + -0.005 prev_action + -0.004 prev_grooming + -0.003 prev_non_contact + 0.004 prev_contact + -0.005 prev_scratch + -0.005 prev_waiting \n",
            "value_waiting[t+1] = 0.03 1 + 1.001 value_waiting[t] + -0.005 chosen + 0.004 sig_action + -0.004 sig_grooming + 0.031 sig_non_contact + -0.005 sig_contact + -0.005 sig_scratch + -0.005 sig_waiting + 0.004 prev_action + 0.004 prev_grooming + -0.003 prev_non_contact + -0.004 prev_contact + -0.005 prev_scratch + -0.004 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 4/1000 --- L(Train): 0.1791125 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 0.998 value_action[t] + 0.001 chosen + -0.001 sig_action + 0.002 sig_grooming + -0.027 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = -0.001 1 + 0.997 value_grooming[t] + 0.002 chosen + 0.001 sig_action + 0.023 sig_grooming + -0.008 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.04 1 + 1.04 value_non_contact[t] + -0.033 chosen + -0.001 sig_action + -0.039 sig_grooming + -0.039 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + -0.001 chosen + 0.001 sig_action + -0.016 sig_grooming + -0.003 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.04 1 + 1.01 value_scratch[t] + 0.001 chosen + 0.002 sig_action + -0.037 sig_grooming + -0.029 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + 0.003 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.039 1 + 0.994 value_waiting[t] + 0.001 chosen + -0.002 sig_action + -0.009 sig_grooming + 0.041 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + 0.003 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 5/1000 --- L(Train): 0.1730756 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.0 1 + 1.004 value_action[t] + 0.003 chosen + -0.003 sig_action + 0.003 sig_grooming + -0.031 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.003 sig_waiting + 0.003 prev_action + 0.002 prev_grooming + 0.003 prev_non_contact + -0.004 prev_contact + 0.003 prev_scratch + -0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.004 1 + 0.995 value_grooming[t] + 0.006 chosen + 0.003 sig_action + 0.025 sig_grooming + -0.011 sig_non_contact + -0.003 sig_contact + 0.004 sig_scratch + 0.003 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.003 prev_non_contact + 0.003 prev_contact + -0.003 prev_scratch + 0.004 prev_waiting \n",
            "value_non_contact[t+1] = -0.05 1 + 1.049 value_non_contact[t] + -0.04 chosen + -0.003 sig_action + -0.048 sig_grooming + -0.047 sig_non_contact + 0.003 sig_contact + -0.003 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.003 prev_grooming + -0.004 prev_non_contact + 0.003 prev_contact + 0.003 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.042 1 + 0.998 value_contact[t] + -0.003 chosen + 0.003 sig_action + -0.014 sig_grooming + -0.003 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + 0.003 prev_grooming + 0.003 prev_non_contact + -0.003 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.05 1 + 1.013 value_scratch[t] + 0.003 chosen + 0.004 sig_action + -0.046 sig_grooming + -0.034 sig_non_contact + -0.003 sig_contact + 0.003 sig_scratch + 0.004 sig_waiting + 0.002 prev_action + 0.003 prev_grooming + 0.005 prev_non_contact + -0.003 prev_contact + 0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_waiting[t+1] = 0.049 1 + 0.991 value_waiting[t] + 0.003 chosen + -0.004 sig_action + -0.013 sig_grooming + 0.05 sig_non_contact + 0.002 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.004 prev_grooming + 0.005 prev_non_contact + 0.003 prev_contact + 0.002 prev_scratch + 0.004 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 6/1000 --- L(Train): 0.1678430 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.003 1 + 1.006 value_action[t] + 0.002 chosen + -0.003 sig_action + 0.005 sig_grooming + -0.034 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + -0.003 prev_contact + 0.002 prev_scratch + -0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.008 1 + 0.995 value_grooming[t] + 0.008 chosen + 0.002 sig_action + 0.027 sig_grooming + -0.011 sig_non_contact + -0.003 sig_contact + 0.003 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + 0.003 prev_waiting \n",
            "value_non_contact[t+1] = -0.06 1 + 1.056 value_non_contact[t] + -0.046 chosen + -0.002 sig_action + -0.058 sig_grooming + -0.055 sig_non_contact + 0.003 sig_contact + -0.002 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.003 prev_grooming + -0.003 prev_non_contact + 0.003 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.045 1 + 0.999 value_contact[t] + -0.002 chosen + 0.002 sig_action + -0.011 sig_grooming + -0.0 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + -0.003 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.06 1 + 1.014 value_scratch[t] + 0.002 chosen + 0.003 sig_action + -0.056 sig_grooming + -0.037 sig_non_contact + -0.003 sig_contact + 0.002 sig_scratch + 0.003 sig_waiting + 0.002 prev_action + 0.003 prev_grooming + 0.004 prev_non_contact + -0.003 prev_contact + 0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.058 1 + 0.99 value_waiting[t] + 0.002 chosen + -0.003 sig_action + -0.016 sig_grooming + 0.06 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.004 prev_non_contact + 0.003 prev_contact + 0.002 prev_scratch + 0.003 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 7/1000 --- L(Train): 0.1625573 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.005 1 + 1.005 value_action[t] + -0.0 chosen + -0.0 sig_action + 0.007 sig_grooming + -0.036 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.011 1 + 0.997 value_grooming[t] + 0.009 chosen + -0.0 sig_action + 0.027 sig_grooming + -0.011 sig_non_contact + -0.0 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.07 1 + 1.062 value_non_contact[t] + -0.051 chosen + 0.0 sig_action + -0.068 sig_grooming + -0.061 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.046 1 + 1.001 value_contact[t] + 0.0 chosen + -0.0 sig_action + -0.007 sig_grooming + 0.004 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.07 1 + 1.014 value_scratch[t] + -0.0 chosen + 0.001 sig_action + -0.065 sig_grooming + -0.039 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.066 1 + 0.991 value_waiting[t] + -0.0 chosen + -0.001 sig_action + -0.019 sig_grooming + 0.069 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 8/1000 --- L(Train): 0.1573438 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.005 1 + 1.003 value_action[t] + -0.001 chosen + 0.004 sig_action + 0.007 sig_grooming + -0.038 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.003 prev_contact + -0.001 prev_scratch + 0.004 prev_waiting \n",
            "value_grooming[t+1] = 0.011 1 + 1.0 value_grooming[t] + 0.01 chosen + -0.001 sig_action + 0.026 sig_grooming + -0.01 sig_non_contact + 0.003 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_non_contact[t+1] = -0.079 1 + 1.066 value_non_contact[t] + -0.055 chosen + 0.0 sig_action + -0.078 sig_grooming + -0.065 sig_non_contact + -0.003 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.003 prev_grooming + 0.003 prev_non_contact + -0.003 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.046 1 + 1.001 value_contact[t] + 0.001 chosen + -0.0 sig_action + -0.002 sig_grooming + 0.005 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.004 sig_waiting + 0.003 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + -0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.079 1 + 1.012 value_scratch[t] + -0.0 chosen + -0.003 sig_action + -0.073 sig_grooming + -0.04 sig_non_contact + 0.004 sig_contact + -0.001 sig_scratch + -0.003 sig_waiting + -0.001 prev_action + -0.003 prev_grooming + -0.002 prev_non_contact + 0.003 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.074 1 + 0.993 value_waiting[t] + -0.0 chosen + 0.003 sig_action + -0.021 sig_grooming + 0.078 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.003 prev_action + 0.003 prev_grooming + -0.002 prev_non_contact + -0.003 prev_contact + -0.001 prev_scratch + -0.003 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 9/1000 --- L(Train): 0.1526375 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.004 1 + 0.999 value_action[t] + 0.001 chosen + 0.005 sig_action + 0.007 sig_grooming + -0.039 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.005 prev_contact + 0.001 prev_scratch + 0.005 prev_waiting \n",
            "value_grooming[t+1] = 0.011 1 + 1.004 value_grooming[t] + 0.009 chosen + 0.001 sig_action + 0.025 sig_grooming + -0.008 sig_non_contact + 0.005 sig_contact + -0.005 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.004 prev_waiting \n",
            "value_non_contact[t+1] = -0.089 1 + 1.068 value_non_contact[t] + -0.058 chosen + -0.001 sig_action + -0.087 sig_grooming + -0.068 sig_non_contact + -0.005 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + -0.005 prev_grooming + 0.005 prev_non_contact + -0.005 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.046 1 + 1.0 value_contact[t] + -0.001 chosen + 0.001 sig_action + 0.003 sig_grooming + 0.005 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.005 sig_waiting + 0.005 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.005 prev_waiting \n",
            "value_scratch[t+1] = -0.088 1 + 1.009 value_scratch[t] + 0.001 chosen + -0.004 sig_action + -0.082 sig_grooming + -0.04 sig_non_contact + 0.005 sig_contact + 0.001 sig_scratch + -0.005 sig_waiting + 0.0 prev_action + -0.005 prev_grooming + -0.004 prev_non_contact + 0.005 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.081 1 + 0.997 value_waiting[t] + 0.001 chosen + 0.005 sig_action + -0.022 sig_grooming + 0.086 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.005 prev_action + 0.005 prev_grooming + -0.004 prev_non_contact + -0.005 prev_contact + 0.001 prev_scratch + -0.004 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 10/1000 --- L(Train): 0.1480594 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.002 1 + 0.997 value_action[t] + 0.0 chosen + 0.005 sig_action + 0.006 sig_grooming + -0.04 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.004 prev_contact + 0.0 prev_scratch + 0.005 prev_waiting \n",
            "value_grooming[t+1] = 0.009 1 + 1.006 value_grooming[t] + 0.008 chosen + 0.0 sig_action + 0.023 sig_grooming + -0.005 sig_non_contact + 0.005 sig_contact + -0.005 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + -0.004 prev_waiting \n",
            "value_non_contact[t+1] = -0.098 1 + 1.069 value_non_contact[t] + -0.059 chosen + -0.001 sig_action + -0.097 sig_grooming + -0.069 sig_non_contact + -0.005 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + -0.005 prev_grooming + 0.005 prev_non_contact + -0.005 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.045 1 + 0.997 value_contact[t] + -0.0 chosen + 0.001 sig_action + 0.005 sig_grooming + 0.003 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.005 sig_waiting + 0.005 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.005 prev_waiting \n",
            "value_scratch[t+1] = -0.097 1 + 1.006 value_scratch[t] + 0.001 chosen + -0.004 sig_action + -0.091 sig_grooming + -0.039 sig_non_contact + 0.005 sig_contact + 0.0 sig_scratch + -0.005 sig_waiting + 0.0 prev_action + -0.005 prev_grooming + -0.003 prev_non_contact + 0.005 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.087 1 + 1.002 value_waiting[t] + 0.001 chosen + 0.004 sig_action + -0.024 sig_grooming + 0.094 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.005 prev_action + 0.004 prev_grooming + -0.003 prev_non_contact + -0.005 prev_contact + 0.0 prev_scratch + -0.004 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 11/1000 --- L(Train): 0.1435638 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.997 value_action[t] + -0.001 chosen + 0.003 sig_action + 0.005 sig_grooming + -0.041 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.003 prev_contact + -0.001 prev_scratch + 0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.007 1 + 1.006 value_grooming[t] + 0.006 chosen + -0.001 sig_action + 0.021 sig_grooming + -0.002 sig_non_contact + 0.003 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.108 1 + 1.068 value_non_contact[t] + -0.06 chosen + 0.001 sig_action + -0.106 sig_grooming + -0.068 sig_non_contact + -0.003 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + -0.003 prev_grooming + 0.003 prev_non_contact + -0.003 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.044 1 + 0.997 value_contact[t] + 0.001 chosen + -0.001 sig_action + 0.004 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.003 sig_waiting + 0.003 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.106 1 + 1.001 value_scratch[t] + -0.001 chosen + -0.003 sig_action + -0.099 sig_grooming + -0.037 sig_non_contact + 0.003 sig_contact + -0.001 sig_scratch + -0.003 sig_waiting + -0.002 prev_action + -0.003 prev_grooming + -0.002 prev_non_contact + 0.003 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.093 1 + 1.004 value_waiting[t] + -0.001 chosen + 0.003 sig_action + -0.025 sig_grooming + 0.102 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.003 prev_action + 0.003 prev_grooming + -0.002 prev_non_contact + -0.003 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 12/1000 --- L(Train): 0.1392560 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.998 value_action[t] + -0.001 chosen + 0.0 sig_action + 0.005 sig_grooming + -0.041 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.004 1 + 1.005 value_grooming[t] + 0.004 chosen + -0.001 sig_action + 0.018 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + -0.0 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.117 1 + 1.065 value_non_contact[t] + -0.059 chosen + 0.001 sig_action + -0.116 sig_grooming + -0.066 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.043 1 + 0.997 value_contact[t] + 0.001 chosen + -0.001 sig_action + 0.002 sig_grooming + -0.003 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.115 1 + 0.996 value_scratch[t] + -0.001 chosen + 0.0 sig_action + -0.107 sig_grooming + -0.034 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.097 1 + 1.004 value_waiting[t] + -0.001 chosen + -0.0 sig_action + -0.027 sig_grooming + 0.109 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.002 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 13/1000 --- L(Train): 0.1350322 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.0 1 + 1.0 value_action[t] + -0.0 chosen + -0.004 sig_action + 0.007 sig_grooming + -0.04 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + -0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.002 value_grooming[t] + 0.001 chosen + -0.0 sig_action + 0.016 sig_grooming + 0.002 sig_non_contact + -0.004 sig_contact + 0.004 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.126 1 + 1.062 value_non_contact[t] + -0.057 chosen + -0.0 sig_action + -0.125 sig_grooming + -0.063 sig_non_contact + 0.004 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.004 prev_grooming + -0.004 prev_non_contact + 0.004 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.042 1 + 0.999 value_contact[t] + 0.0 chosen + 0.0 sig_action + -0.002 sig_grooming + -0.005 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.003 sig_waiting + -0.004 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.004 prev_waiting \n",
            "value_scratch[t+1] = -0.123 1 + 0.993 value_scratch[t] + 0.0 chosen + 0.001 sig_action + -0.115 sig_grooming + -0.031 sig_non_contact + -0.003 sig_contact + -0.0 sig_scratch + 0.004 sig_waiting + -0.0 prev_action + 0.004 prev_grooming + 0.002 prev_non_contact + -0.004 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.099 1 + 1.003 value_waiting[t] + 0.0 chosen + -0.001 sig_action + -0.028 sig_grooming + 0.115 sig_non_contact + -0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.004 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.004 prev_contact + -0.0 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 14/1000 --- L(Train): 0.1310773 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.003 1 + 1.003 value_action[t] + 0.002 chosen + -0.006 sig_action + 0.008 sig_grooming + -0.039 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.005 prev_waiting \n",
            "value_grooming[t+1] = -0.002 1 + 0.998 value_grooming[t] + -0.001 chosen + 0.002 sig_action + 0.013 sig_grooming + -0.0 sig_non_contact + -0.006 sig_contact + 0.006 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.135 1 + 1.057 value_non_contact[t] + -0.055 chosen + 0.0 sig_action + -0.134 sig_grooming + -0.059 sig_non_contact + 0.006 sig_contact + -0.002 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.006 prev_grooming + -0.006 prev_non_contact + 0.006 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 1.002 value_contact[t] + -0.002 chosen + 0.0 sig_action + -0.005 sig_grooming + -0.006 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.005 sig_waiting + -0.006 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.006 prev_waiting \n",
            "value_scratch[t+1] = -0.132 1 + 0.992 value_scratch[t] + -0.0 chosen + 0.001 sig_action + -0.123 sig_grooming + -0.026 sig_non_contact + -0.005 sig_contact + 0.002 sig_scratch + 0.006 sig_waiting + 0.002 prev_action + 0.006 prev_grooming + 0.002 prev_non_contact + -0.006 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.101 1 + 1.001 value_waiting[t] + -0.0 chosen + -0.001 sig_action + -0.03 sig_grooming + 0.121 sig_non_contact + 0.002 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + -0.006 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.006 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 15/1000 --- L(Train): 0.1273666 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.004 1 + 1.004 value_action[t] + 0.003 chosen + -0.006 sig_action + 0.009 sig_grooming + -0.038 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + -0.003 sig_waiting + 0.003 prev_action + 0.003 prev_grooming + 0.003 prev_non_contact + 0.001 prev_contact + 0.003 prev_scratch + -0.006 prev_waiting \n",
            "value_grooming[t+1] = -0.003 1 + 0.996 value_grooming[t] + 0.001 chosen + 0.003 sig_action + 0.01 sig_grooming + -0.001 sig_non_contact + -0.006 sig_contact + 0.006 sig_scratch + 0.003 sig_waiting + 0.003 prev_action + 0.003 prev_grooming + -0.003 prev_non_contact + 0.003 prev_contact + -0.003 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.144 1 + 1.052 value_non_contact[t] + -0.052 chosen + -0.001 sig_action + -0.144 sig_grooming + -0.054 sig_non_contact + 0.006 sig_contact + -0.003 sig_scratch + 0.003 sig_waiting + 0.003 prev_action + 0.006 prev_grooming + -0.006 prev_non_contact + 0.006 prev_contact + 0.003 prev_scratch + -0.003 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.003 value_contact[t] + -0.003 chosen + -0.001 sig_action + -0.007 sig_grooming + -0.005 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + -0.006 sig_waiting + -0.006 prev_action + -0.001 prev_grooming + 0.003 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.006 prev_waiting \n",
            "value_scratch[t+1] = -0.14 1 + 0.993 value_scratch[t] + 0.001 chosen + -0.0 sig_action + -0.13 sig_grooming + -0.021 sig_non_contact + -0.006 sig_contact + 0.003 sig_scratch + 0.006 sig_waiting + 0.003 prev_action + 0.006 prev_grooming + 0.0 prev_non_contact + -0.006 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.102 1 + 0.998 value_waiting[t] + 0.001 chosen + 0.001 sig_action + -0.032 sig_grooming + 0.126 sig_non_contact + 0.003 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.006 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.006 prev_contact + 0.003 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 16/1000 --- L(Train): 0.1237377 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.005 1 + 1.004 value_action[t] + 0.002 chosen + -0.005 sig_action + 0.008 sig_grooming + -0.037 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.003 prev_non_contact + 0.001 prev_contact + 0.003 prev_scratch + -0.005 prev_waiting \n",
            "value_grooming[t+1] = -0.0 1 + 0.996 value_grooming[t] + 0.002 chosen + 0.003 sig_action + 0.008 sig_grooming + -0.001 sig_non_contact + -0.005 sig_contact + 0.005 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.003 prev_non_contact + 0.002 prev_contact + -0.003 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.153 1 + 1.046 value_non_contact[t] + -0.048 chosen + -0.001 sig_action + -0.153 sig_grooming + -0.048 sig_non_contact + 0.005 sig_contact + -0.003 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.005 prev_grooming + -0.005 prev_non_contact + 0.005 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.035 1 + 1.003 value_contact[t] + -0.003 chosen + -0.001 sig_action + -0.008 sig_grooming + -0.003 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.005 sig_waiting + -0.005 prev_action + -0.001 prev_grooming + 0.003 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.005 prev_waiting \n",
            "value_scratch[t+1] = -0.148 1 + 0.995 value_scratch[t] + 0.001 chosen + -0.001 sig_action + -0.138 sig_grooming + -0.015 sig_non_contact + -0.005 sig_contact + 0.003 sig_scratch + 0.005 sig_waiting + 0.002 prev_action + 0.005 prev_grooming + -0.002 prev_non_contact + -0.005 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.101 1 + 0.996 value_waiting[t] + 0.001 chosen + 0.001 sig_action + -0.034 sig_grooming + 0.131 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.005 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + 0.005 prev_contact + 0.002 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 17/1000 --- L(Train): 0.1201740 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.004 1 + 1.002 value_action[t] + 0.001 chosen + -0.003 sig_action + 0.007 sig_grooming + -0.035 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 0.996 value_grooming[t] + 0.004 chosen + 0.001 sig_action + 0.006 sig_grooming + -0.0 sig_non_contact + -0.003 sig_contact + 0.004 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.162 1 + 1.039 value_non_contact[t] + -0.044 chosen + 0.001 sig_action + -0.162 sig_grooming + -0.042 sig_non_contact + 0.003 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.004 prev_grooming + -0.004 prev_non_contact + 0.003 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.032 1 + 1.002 value_contact[t] + -0.001 chosen + -0.0 sig_action + -0.008 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.155 1 + 0.998 value_scratch[t] + -0.001 chosen + 0.001 sig_action + -0.144 sig_grooming + -0.009 sig_non_contact + -0.003 sig_contact + 0.001 sig_scratch + 0.004 sig_waiting + 0.001 prev_action + 0.004 prev_grooming + -0.003 prev_non_contact + -0.003 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.099 1 + 0.995 value_waiting[t] + -0.001 chosen + -0.0 sig_action + -0.035 sig_grooming + 0.135 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.003 prev_action + -0.0 prev_grooming + -0.003 prev_non_contact + 0.003 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 18/1000 --- L(Train): 0.1166723 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.003 1 + 1.0 value_action[t] + -0.002 chosen + -0.0 sig_action + 0.005 sig_grooming + -0.034 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + -0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.007 1 + 0.998 value_grooming[t] + 0.005 chosen + -0.002 sig_action + 0.004 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + -0.002 prev_contact + 0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.17 1 + 1.032 value_non_contact[t] + -0.039 chosen + 0.001 sig_action + -0.171 sig_grooming + -0.035 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.03 1 + 1.0 value_contact[t] + 0.002 chosen + 0.002 sig_action + -0.007 sig_grooming + 0.004 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.162 1 + 1.002 value_scratch[t] + -0.001 chosen + 0.0 sig_action + -0.151 sig_grooming + -0.003 sig_non_contact + -0.0 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.097 1 + 0.996 value_waiting[t] + -0.001 chosen + -0.0 sig_action + -0.037 sig_grooming + 0.139 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 19/1000 --- L(Train): 0.1134037 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.998 value_action[t] + -0.003 chosen + 0.003 sig_action + 0.003 sig_grooming + -0.032 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.009 1 + 1.0 value_grooming[t] + 0.006 chosen + -0.003 sig_action + 0.002 sig_grooming + -0.0 sig_non_contact + 0.003 sig_contact + -0.003 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.003 prev_non_contact + -0.003 prev_contact + 0.003 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.179 1 + 1.025 value_non_contact[t] + -0.034 chosen + -0.0 sig_action + -0.18 sig_grooming + -0.029 sig_non_contact + -0.003 sig_contact + 0.003 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.003 prev_non_contact + -0.003 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.029 1 + 0.999 value_contact[t] + 0.003 chosen + 0.003 sig_action + -0.006 sig_grooming + 0.005 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + 0.003 sig_waiting + 0.003 prev_action + 0.003 prev_grooming + -0.003 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.169 1 + 1.004 value_scratch[t] + 0.0 chosen + -0.001 sig_action + -0.157 sig_grooming + 0.004 sig_non_contact + 0.003 sig_contact + -0.003 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.002 prev_non_contact + 0.003 prev_contact + 0.003 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.094 1 + 0.998 value_waiting[t] + 0.0 chosen + 0.001 sig_action + -0.039 sig_grooming + 0.141 sig_non_contact + -0.003 sig_contact + 0.0 sig_scratch + 0.003 sig_waiting + 0.003 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + -0.003 prev_contact + -0.003 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 20/1000 --- L(Train): 0.1103881 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 0.998 value_action[t] + -0.003 chosen + 0.005 sig_action + 0.002 sig_grooming + -0.031 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + -0.003 prev_scratch + 0.005 prev_waiting \n",
            "value_grooming[t+1] = 0.011 1 + 1.001 value_grooming[t] + 0.006 chosen + -0.003 sig_action + -0.0 sig_grooming + -0.0 sig_non_contact + 0.005 sig_contact + -0.005 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.003 prev_non_contact + -0.003 prev_contact + 0.003 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.187 1 + 1.018 value_non_contact[t] + -0.029 chosen + -0.0 sig_action + -0.189 sig_grooming + -0.022 sig_non_contact + -0.005 sig_contact + 0.003 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.005 prev_grooming + 0.005 prev_non_contact + -0.005 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.028 1 + 0.999 value_contact[t] + 0.003 chosen + 0.002 sig_action + -0.004 sig_grooming + 0.006 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + 0.005 sig_waiting + 0.005 prev_action + 0.002 prev_grooming + -0.003 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.005 prev_waiting \n",
            "value_scratch[t+1] = -0.176 1 + 1.005 value_scratch[t] + -0.0 chosen + -0.001 sig_action + -0.163 sig_grooming + 0.009 sig_non_contact + 0.005 sig_contact + -0.003 sig_scratch + -0.005 sig_waiting + -0.003 prev_action + -0.005 prev_grooming + 0.001 prev_non_contact + 0.005 prev_contact + 0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.09 1 + 1.0 value_waiting[t] + 0.0 chosen + 0.001 sig_action + -0.04 sig_grooming + 0.144 sig_non_contact + -0.003 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + 0.005 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.005 prev_contact + -0.003 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 21/1000 --- L(Train): 0.1074243 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.003 1 + 0.999 value_action[t] + -0.002 chosen + 0.006 sig_action + 0.003 sig_grooming + -0.029 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.002 prev_scratch + 0.006 prev_waiting \n",
            "value_grooming[t+1] = 0.013 1 + 1.001 value_grooming[t] + 0.006 chosen + -0.002 sig_action + 0.001 sig_grooming + -0.0 sig_non_contact + 0.006 sig_contact + -0.006 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.196 1 + 1.011 value_non_contact[t] + -0.024 chosen + 0.001 sig_action + -0.197 sig_grooming + -0.015 sig_non_contact + -0.006 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.006 prev_grooming + 0.006 prev_non_contact + -0.006 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.029 1 + 1.001 value_contact[t] + 0.001 chosen + 0.001 sig_action + -0.002 sig_grooming + 0.005 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.006 sig_waiting + 0.006 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.006 prev_waiting \n",
            "value_scratch[t+1] = -0.182 1 + 1.005 value_scratch[t] + 0.001 chosen + -0.0 sig_action + -0.168 sig_grooming + 0.012 sig_non_contact + 0.006 sig_contact + -0.001 sig_scratch + -0.006 sig_waiting + -0.002 prev_action + -0.006 prev_grooming + 0.002 prev_non_contact + 0.006 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.086 1 + 1.002 value_waiting[t] + -0.001 chosen + 0.0 sig_action + -0.041 sig_grooming + 0.146 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.006 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + -0.006 prev_contact + -0.002 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 22/1000 --- L(Train): 0.1045130 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 1.001 value_action[t] + 0.001 chosen + 0.006 sig_action + 0.006 sig_grooming + -0.027 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + 0.006 prev_waiting \n",
            "value_grooming[t+1] = 0.014 1 + 0.999 value_grooming[t] + 0.007 chosen + 0.001 sig_action + 0.003 sig_grooming + 0.001 sig_non_contact + 0.006 sig_contact + -0.005 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.204 1 + 1.004 value_non_contact[t] + -0.019 chosen + 0.001 sig_action + -0.206 sig_grooming + -0.008 sig_non_contact + -0.006 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + -0.005 prev_grooming + 0.005 prev_non_contact + -0.006 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.031 1 + 1.001 value_contact[t] + -0.001 chosen + -0.002 sig_action + 0.001 sig_grooming + 0.003 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.006 sig_waiting + 0.005 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.005 prev_waiting \n",
            "value_scratch[t+1] = -0.188 1 + 1.004 value_scratch[t] + 0.001 chosen + 0.002 sig_action + -0.173 sig_grooming + 0.013 sig_non_contact + 0.006 sig_contact + 0.001 sig_scratch + -0.005 sig_waiting + 0.0 prev_action + -0.005 prev_grooming + 0.001 prev_non_contact + 0.006 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.082 1 + 1.001 value_waiting[t] + -0.001 chosen + -0.002 sig_action + -0.042 sig_grooming + 0.147 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + 0.006 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.006 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 23/1000 --- L(Train): 0.1017131 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.0 1 + 1.001 value_action[t] + 0.001 chosen + 0.004 sig_action + 0.009 sig_grooming + -0.025 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + -0.003 prev_contact + 0.002 prev_scratch + 0.004 prev_waiting \n",
            "value_grooming[t+1] = 0.014 1 + 0.999 value_grooming[t] + 0.006 chosen + 0.001 sig_action + 0.004 sig_grooming + -0.001 sig_non_contact + 0.004 sig_contact + -0.004 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.213 1 + 0.997 value_non_contact[t] + -0.014 chosen + 0.0 sig_action + -0.214 sig_grooming + -0.001 sig_non_contact + -0.004 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.004 prev_grooming + 0.004 prev_non_contact + -0.004 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.033 1 + 1.0 value_contact[t] + -0.002 chosen + -0.003 sig_action + 0.001 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.004 sig_waiting + 0.004 prev_action + -0.003 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + -0.004 prev_waiting \n",
            "value_scratch[t+1] = -0.194 1 + 1.002 value_scratch[t] + -0.001 chosen + 0.003 sig_action + -0.177 sig_grooming + 0.013 sig_non_contact + 0.004 sig_contact + 0.002 sig_scratch + -0.004 sig_waiting + 0.001 prev_action + -0.004 prev_grooming + 0.0 prev_non_contact + 0.004 prev_contact + -0.003 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.077 1 + 1.0 value_waiting[t] + -0.0 chosen + -0.003 sig_action + -0.043 sig_grooming + 0.149 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + -0.003 sig_waiting + 0.004 prev_action + -0.003 prev_grooming + -0.0 prev_non_contact + -0.004 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 24/1000 --- L(Train): 0.0990776 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.002 1 + 1.0 value_action[t] + 0.001 chosen + 0.002 sig_action + 0.011 sig_grooming + -0.023 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.013 1 + 1.0 value_grooming[t] + 0.006 chosen + 0.001 sig_action + 0.005 sig_grooming + -0.002 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.221 1 + 0.993 value_non_contact[t] + -0.009 chosen + -0.002 sig_action + -0.223 sig_grooming + 0.005 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 0.999 value_contact[t] + -0.001 chosen + -0.003 sig_action + -0.0 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + -0.003 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.199 1 + 0.998 value_scratch[t] + -0.001 chosen + 0.002 sig_action + -0.181 sig_grooming + 0.011 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + 0.002 prev_contact + -0.003 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.073 1 + 0.998 value_waiting[t] + 0.002 chosen + -0.002 sig_action + -0.043 sig_grooming + 0.15 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + -0.003 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 25/1000 --- L(Train): 0.0964866 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.004 1 + 1.0 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.013 sig_grooming + -0.022 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.012 1 + 1.002 value_grooming[t] + 0.005 chosen + -0.0 sig_action + 0.005 sig_grooming + -0.002 sig_non_contact + -0.002 sig_contact + 0.002 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.229 1 + 0.992 value_non_contact[t] + -0.005 chosen + -0.003 sig_action + -0.231 sig_grooming + 0.008 sig_non_contact + 0.002 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.002 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 0.998 value_contact[t] + 0.0 chosen + -0.001 sig_action + -0.001 sig_grooming + -0.002 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.003 prev_contact + -0.003 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.204 1 + 0.997 value_scratch[t] + 0.0 chosen + 0.001 sig_action + -0.185 sig_grooming + 0.009 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.003 prev_non_contact + -0.002 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.068 1 + 0.997 value_waiting[t] + 0.003 chosen + -0.001 sig_action + -0.042 sig_grooming + 0.151 sig_non_contact + -0.0 sig_contact + 0.003 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 26/1000 --- L(Train): 0.0940045 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.004 1 + 1.001 value_action[t] + -0.0 chosen + -0.003 sig_action + 0.012 sig_grooming + -0.02 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + 0.002 prev_contact + -0.0 prev_scratch + -0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.011 1 + 1.002 value_grooming[t] + 0.004 chosen + -0.0 sig_action + 0.005 sig_grooming + -0.001 sig_non_contact + -0.003 sig_contact + 0.004 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.237 1 + 0.993 value_non_contact[t] + -0.001 chosen + -0.002 sig_action + -0.239 sig_grooming + 0.009 sig_non_contact + 0.003 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.003 prev_grooming + -0.004 prev_non_contact + 0.003 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 0.999 value_contact[t] + 0.0 chosen + 0.001 sig_action + -0.001 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.209 1 + 0.996 value_scratch[t] + 0.0 chosen + -0.001 sig_action + -0.188 sig_grooming + 0.005 sig_non_contact + -0.003 sig_contact + -0.0 sig_scratch + 0.004 sig_waiting + -0.001 prev_action + 0.003 prev_grooming + -0.003 prev_non_contact + -0.003 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.063 1 + 0.997 value_waiting[t] + 0.002 chosen + 0.002 sig_action + -0.041 sig_grooming + 0.151 sig_non_contact + -0.0 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.003 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.003 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 27/1000 --- L(Train): 0.0917262 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.003 1 + 1.001 value_action[t] + 0.001 chosen + -0.004 sig_action + 0.01 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.003 prev_contact + 0.001 prev_scratch + -0.004 prev_waiting \n",
            "value_grooming[t+1] = 0.009 1 + 1.001 value_grooming[t] + 0.003 chosen + 0.001 sig_action + 0.005 sig_grooming + -0.001 sig_non_contact + -0.004 sig_contact + 0.004 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.245 1 + 0.996 value_non_contact[t] + 0.004 chosen + -0.001 sig_action + -0.247 sig_grooming + 0.007 sig_non_contact + 0.004 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.004 prev_grooming + -0.004 prev_non_contact + 0.004 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.042 1 + 1.0 value_contact[t] + -0.001 chosen + 0.002 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + -0.004 sig_waiting + -0.004 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.004 prev_waiting \n",
            "value_scratch[t+1] = -0.213 1 + 0.997 value_scratch[t] + -0.001 chosen + -0.003 sig_action + -0.19 sig_grooming + 0.001 sig_non_contact + -0.004 sig_contact + 0.001 sig_scratch + 0.004 sig_waiting + 0.0 prev_action + 0.004 prev_grooming + -0.002 prev_non_contact + -0.004 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.059 1 + 0.998 value_waiting[t] + 0.001 chosen + 0.003 sig_action + -0.04 sig_grooming + 0.152 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.004 prev_action + 0.003 prev_grooming + -0.001 prev_non_contact + 0.004 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 28/1000 --- L(Train): 0.0895091 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.999 value_action[t] + 0.0 chosen + -0.003 sig_action + 0.007 sig_grooming + -0.017 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.003 prev_contact + 0.0 prev_scratch + -0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.007 1 + 0.999 value_grooming[t] + 0.002 chosen + 0.0 sig_action + 0.004 sig_grooming + 0.001 sig_non_contact + -0.003 sig_contact + 0.004 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.253 1 + 1.0 value_non_contact[t] + 0.006 chosen + 0.002 sig_action + -0.255 sig_grooming + 0.004 sig_non_contact + 0.003 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.003 prev_grooming + -0.004 prev_non_contact + 0.003 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.043 1 + 1.0 value_contact[t] + -0.0 chosen + 0.001 sig_action + 0.001 sig_grooming + 0.002 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + 0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.217 1 + 0.998 value_scratch[t] + -0.001 chosen + -0.002 sig_action + -0.192 sig_grooming + -0.003 sig_non_contact + -0.003 sig_contact + 0.0 sig_scratch + 0.004 sig_waiting + 0.0 prev_action + 0.003 prev_grooming + 0.0 prev_non_contact + -0.003 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.054 1 + 1.0 value_waiting[t] + -0.002 chosen + 0.003 sig_action + -0.038 sig_grooming + 0.153 sig_non_contact + 0.0 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + -0.003 prev_action + 0.003 prev_grooming + -0.001 prev_non_contact + 0.003 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 29/1000 --- L(Train): 0.0873468 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 0.999 value_action[t] + -0.001 chosen + -0.002 sig_action + 0.005 sig_grooming + -0.016 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 0.998 value_grooming[t] + 0.001 chosen + -0.001 sig_action + 0.004 sig_grooming + -0.0 sig_non_contact + -0.002 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.261 1 + 1.003 value_non_contact[t] + 0.006 chosen + 0.003 sig_action + -0.262 sig_grooming + 0.0 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.043 1 + 1.0 value_contact[t] + 0.001 chosen + -0.0 sig_action + 0.0 sig_grooming + 0.003 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.003 prev_contact + 0.003 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.22 1 + 1.0 value_scratch[t] + -0.0 chosen + -0.001 sig_action + -0.194 sig_grooming + -0.005 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.05 1 + 1.001 value_waiting[t] + -0.003 chosen + 0.001 sig_action + -0.035 sig_grooming + 0.154 sig_non_contact + -0.001 sig_contact + -0.003 sig_scratch + -0.0 sig_waiting + -0.002 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 30/1000 --- L(Train): 0.0852775 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.004 1 + 1.0 value_action[t] + -0.001 chosen + 0.001 sig_action + 0.004 sig_grooming + -0.016 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 0.999 value_grooming[t] + -0.0 chosen + -0.001 sig_action + 0.003 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.269 1 + 1.006 value_non_contact[t] + 0.004 chosen + 0.003 sig_action + -0.27 sig_grooming + -0.005 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.044 1 + 1.0 value_contact[t] + 0.001 chosen + -0.0 sig_action + -0.002 sig_grooming + 0.003 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.003 prev_contact + 0.003 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.223 1 + 1.001 value_scratch[t] + 0.002 chosen + 0.001 sig_action + -0.195 sig_grooming + -0.006 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.047 1 + 1.0 value_waiting[t] + -0.003 chosen + -0.001 sig_action + -0.032 sig_grooming + 0.155 sig_non_contact + -0.001 sig_contact + -0.002 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 31/1000 --- L(Train): 0.0832828 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.004 1 + 1.001 value_action[t] + -0.0 chosen + 0.002 sig_action + 0.004 sig_grooming + -0.015 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + -0.002 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.0 value_grooming[t] + 0.002 chosen + -0.0 sig_action + 0.003 sig_grooming + 0.0 sig_non_contact + 0.002 sig_contact + -0.002 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.277 1 + 1.007 value_non_contact[t] + 0.002 chosen + 0.001 sig_action + -0.277 sig_grooming + -0.009 sig_non_contact + -0.002 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + -0.002 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.043 1 + 0.999 value_contact[t] + -0.0 chosen + 0.001 sig_action + -0.003 sig_grooming + 0.002 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.225 1 + 1.0 value_scratch[t] + 0.002 chosen + 0.002 sig_action + -0.196 sig_grooming + -0.005 sig_non_contact + 0.002 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + -0.0 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.043 1 + 0.999 value_waiting[t] + -0.001 chosen + -0.001 sig_action + -0.028 sig_grooming + 0.156 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 32/1000 --- L(Train): 0.0813835 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.003 1 + 1.001 value_action[t] + 0.002 chosen + 0.002 sig_action + 0.006 sig_grooming + -0.014 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = -0.001 1 + 1.0 value_grooming[t] + 0.004 chosen + 0.002 sig_action + 0.003 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + -0.002 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.002 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.284 1 + 1.008 value_non_contact[t] + -0.001 chosen + -0.001 sig_action + -0.284 sig_grooming + -0.012 sig_non_contact + -0.002 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + -0.002 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.043 1 + 1.0 value_contact[t] + 0.0 chosen + 0.0 sig_action + -0.003 sig_grooming + -0.0 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.227 1 + 0.998 value_scratch[t] + 0.002 chosen + 0.001 sig_action + -0.196 sig_grooming + -0.002 sig_non_contact + 0.002 sig_contact + -0.0 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + 0.002 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.04 1 + 0.998 value_waiting[t] + 0.001 chosen + -0.001 sig_action + -0.024 sig_grooming + 0.157 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + 0.002 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 33/1000 --- L(Train): 0.0796063 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + 0.002 chosen + 0.001 sig_action + 0.009 sig_grooming + -0.013 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = -0.0 1 + 0.999 value_grooming[t] + 0.006 chosen + 0.003 sig_action + 0.002 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.003 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + 0.003 prev_waiting \n",
            "value_non_contact[t+1] = -0.291 1 + 1.007 value_non_contact[t] + -0.003 chosen + -0.001 sig_action + -0.291 sig_grooming + -0.013 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.041 1 + 1.001 value_contact[t] + -0.001 chosen + -0.001 sig_action + -0.003 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.229 1 + 0.998 value_scratch[t] + 0.001 chosen + -0.0 sig_action + -0.196 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.038 1 + 0.999 value_waiting[t] + 0.001 chosen + 0.0 sig_action + -0.02 sig_grooming + 0.158 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + 0.003 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 34/1000 --- L(Train): 0.0778564 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.998 value_action[t] + 0.002 chosen + -0.001 sig_action + 0.011 sig_grooming + -0.013 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 0.999 value_grooming[t] + 0.008 chosen + 0.002 sig_action + 0.002 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.298 1 + 1.005 value_non_contact[t] + -0.004 chosen + -0.001 sig_action + -0.298 sig_grooming + -0.014 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 1.001 value_contact[t] + -0.001 chosen + -0.001 sig_action + -0.002 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.23 1 + 0.998 value_scratch[t] + -0.002 chosen + -0.0 sig_action + -0.196 sig_grooming + 0.005 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.035 1 + 1.0 value_waiting[t] + 0.001 chosen + 0.0 sig_action + -0.015 sig_grooming + 0.159 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 35/1000 --- L(Train): 0.0761865 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.002 1 + 0.997 value_action[t] + 0.001 chosen + -0.002 sig_action + 0.013 sig_grooming + -0.013 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 1.0 value_grooming[t] + 0.01 chosen + 0.001 sig_action + 0.001 sig_grooming + -0.001 sig_non_contact + -0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.305 1 + 1.003 value_non_contact[t] + -0.004 chosen + 0.0 sig_action + -0.305 sig_grooming + -0.013 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.001 value_contact[t] + 0.001 chosen + 0.0 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.231 1 + 0.999 value_scratch[t] + -0.003 chosen + 0.001 sig_action + -0.195 sig_grooming + 0.007 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.033 1 + 1.0 value_waiting[t] + -0.0 chosen + -0.001 sig_action + -0.01 sig_grooming + 0.161 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 36/1000 --- L(Train): 0.0745542 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.002 1 + 0.997 value_action[t] + -0.002 chosen + -0.002 sig_action + 0.013 sig_grooming + -0.013 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.007 1 + 1.0 value_grooming[t] + 0.011 chosen + -0.002 sig_action + 0.001 sig_grooming + -0.0 sig_non_contact + -0.002 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.312 1 + 0.999 value_non_contact[t] + -0.003 chosen + 0.0 sig_action + -0.311 sig_grooming + -0.011 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + -0.002 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 0.999 value_contact[t] + 0.001 chosen + -0.0 sig_action + 0.001 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.232 1 + 1.0 value_scratch[t] + -0.003 chosen + 0.001 sig_action + -0.194 sig_grooming + 0.008 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + -0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.031 1 + 0.999 value_waiting[t] + -0.0 chosen + -0.0 sig_action + -0.005 sig_grooming + 0.163 sig_non_contact + -0.002 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 37/1000 --- L(Train): 0.0730358 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.998 value_action[t] + -0.003 chosen + -0.0 sig_action + 0.012 sig_grooming + -0.013 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.008 1 + 1.001 value_grooming[t] + 0.012 chosen + -0.003 sig_action + -0.0 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.003 prev_non_contact + -0.003 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.318 1 + 0.997 value_non_contact[t] + -0.0 chosen + -0.001 sig_action + -0.317 sig_grooming + -0.008 sig_non_contact + 0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.003 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.035 1 + 0.998 value_contact[t] + -0.0 chosen + 0.001 sig_action + 0.001 sig_grooming + -0.0 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.232 1 + 1.001 value_scratch[t] + -0.001 chosen + -0.001 sig_action + -0.193 sig_grooming + 0.008 sig_non_contact + -0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.003 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.029 1 + 1.0 value_waiting[t] + 0.001 chosen + 0.001 sig_action + 0.001 sig_grooming + 0.165 sig_non_contact + -0.003 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + -0.003 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 38/1000 --- L(Train): 0.0715545 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 0.999 value_action[t] + -0.003 chosen + 0.002 sig_action + 0.01 sig_grooming + -0.013 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.009 1 + 1.0 value_grooming[t] + 0.012 chosen + -0.002 sig_action + 0.003 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + -0.002 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.002 prev_non_contact + -0.003 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.324 1 + 0.996 value_non_contact[t] + 0.003 chosen + -0.0 sig_action + -0.323 sig_grooming + -0.005 sig_non_contact + -0.002 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.003 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + -0.002 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.034 1 + 0.999 value_contact[t] + 0.0 chosen + 0.001 sig_action + -0.0 sig_grooming + -0.0 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.232 1 + 1.0 value_scratch[t] + 0.001 chosen + -0.001 sig_action + -0.191 sig_grooming + 0.008 sig_non_contact + 0.002 sig_contact + -0.0 sig_scratch + -0.002 sig_waiting + -0.003 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.027 1 + 1.001 value_waiting[t] + 0.0 chosen + 0.001 sig_action + 0.001 sig_grooming + 0.167 sig_non_contact + -0.003 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + -0.002 prev_contact + -0.003 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 39/1000 --- L(Train): 0.0701659 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.003 1 + 1.002 value_action[t] + -0.001 chosen + 0.003 sig_action + 0.008 sig_grooming + -0.013 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.009 1 + 0.999 value_grooming[t] + 0.013 chosen + -0.001 sig_action + 0.005 sig_grooming + -0.001 sig_non_contact + 0.003 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.33 1 + 0.996 value_non_contact[t] + 0.005 chosen + 0.001 sig_action + -0.329 sig_grooming + -0.0 sig_non_contact + -0.003 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.002 prev_action + -0.003 prev_grooming + 0.003 prev_non_contact + -0.003 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.034 1 + 1.0 value_contact[t] + -0.001 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.003 sig_waiting + 0.003 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.232 1 + 1.0 value_scratch[t] + 0.001 chosen + 0.0 sig_action + -0.19 sig_grooming + 0.006 sig_non_contact + 0.003 sig_contact + 0.001 sig_scratch + -0.003 sig_waiting + -0.002 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + 0.003 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.025 1 + 1.0 value_waiting[t] + -0.001 chosen + -0.0 sig_action + -0.001 sig_grooming + 0.169 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.003 prev_action + 0.0 prev_grooming + 0.003 prev_non_contact + -0.003 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 40/1000 --- L(Train): 0.0687920 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.003 1 + 1.003 value_action[t] + 0.001 chosen + 0.003 sig_action + 0.008 sig_grooming + -0.014 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + 0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.008 1 + 0.998 value_grooming[t] + 0.013 chosen + 0.001 sig_action + 0.007 sig_grooming + -0.003 sig_non_contact + 0.003 sig_contact + -0.003 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.336 1 + 0.997 value_non_contact[t] + 0.006 chosen + 0.001 sig_action + -0.335 sig_grooming + 0.004 sig_non_contact + -0.003 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + -0.003 prev_grooming + 0.003 prev_non_contact + -0.003 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.034 1 + 1.001 value_contact[t] + -0.001 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.0 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.003 sig_waiting + 0.003 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.232 1 + 1.0 value_scratch[t] + 0.001 chosen + 0.0 sig_action + -0.188 sig_grooming + 0.005 sig_non_contact + 0.003 sig_contact + 0.001 sig_scratch + -0.003 sig_waiting + 0.0 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + 0.003 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.023 1 + 0.999 value_waiting[t] + -0.001 chosen + 0.0 sig_action + -0.003 sig_grooming + 0.171 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.003 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + -0.003 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 41/1000 --- L(Train): 0.0674578 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 1.003 value_action[t] + 0.001 chosen + 0.002 sig_action + 0.007 sig_grooming + -0.014 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.008 1 + 0.999 value_grooming[t] + 0.012 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.004 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.342 1 + 0.998 value_non_contact[t] + 0.006 chosen + -0.0 sig_action + -0.341 sig_grooming + 0.008 sig_non_contact + -0.002 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.035 1 + 1.0 value_contact[t] + 0.001 chosen + 0.0 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.231 1 + 1.0 value_scratch[t] + -0.0 chosen + -0.001 sig_action + -0.185 sig_grooming + 0.003 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.002 prev_contact + 0.0 prev_scratch + -0.003 prev_waiting \n",
            "value_waiting[t+1] = 0.022 1 + 0.999 value_waiting[t] + 0.0 chosen + -0.001 sig_action + -0.004 sig_grooming + 0.174 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 42/1000 --- L(Train): 0.0661848 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.001 value_action[t] + 0.001 chosen + -0.0 sig_action + 0.008 sig_grooming + -0.015 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 1.001 value_grooming[t] + 0.012 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.004 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.347 1 + 1.001 value_non_contact[t] + 0.005 chosen + 0.0 sig_action + -0.346 sig_grooming + 0.01 sig_non_contact + 0.0 sig_contact + -0.002 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 1.0 value_contact[t] + 0.001 chosen + 0.0 sig_action + 0.0 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.23 1 + 1.0 value_scratch[t] + -0.0 chosen + -0.001 sig_action + -0.183 sig_grooming + 0.0 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + -0.003 prev_waiting \n",
            "value_waiting[t+1] = 0.02 1 + 1.0 value_waiting[t] + -0.0 chosen + -0.0 sig_action + -0.004 sig_grooming + 0.176 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 43/1000 --- L(Train): 0.0649279 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.002 1 + 0.999 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.015 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 1.001 value_grooming[t] + 0.011 chosen + -0.0 sig_action + 0.009 sig_grooming + -0.004 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + -0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.353 1 + 1.002 value_non_contact[t] + 0.003 chosen + -0.001 sig_action + -0.351 sig_grooming + 0.012 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + -0.0 chosen + -0.001 sig_action + -0.001 sig_grooming + -0.0 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.23 1 + 0.999 value_scratch[t] + 0.001 chosen + -0.0 sig_action + -0.181 sig_grooming + -0.003 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.019 1 + 1.002 value_waiting[t] + 0.001 chosen + 0.001 sig_action + -0.004 sig_grooming + 0.179 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 44/1000 --- L(Train): 0.0637551 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.003 1 + 0.998 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.016 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 1.0 value_grooming[t] + 0.009 chosen + -0.0 sig_action + 0.009 sig_grooming + -0.003 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + -0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.358 1 + 1.001 value_non_contact[t] + 0.001 chosen + -0.001 sig_action + -0.356 sig_grooming + 0.012 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] + -0.0 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.229 1 + 0.999 value_scratch[t] + 0.0 chosen + 0.002 sig_action + -0.178 sig_grooming + -0.004 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.018 1 + 1.002 value_waiting[t] + 0.001 chosen + 0.001 sig_action + -0.003 sig_grooming + 0.181 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 45/1000 --- L(Train): 0.0626322 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.002 1 + 0.997 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.017 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 0.998 value_grooming[t] + 0.008 chosen + 0.001 sig_action + 0.009 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_non_contact[t+1] = -0.362 1 + 1.0 value_non_contact[t] + -0.001 chosen + 0.001 sig_action + -0.361 sig_grooming + 0.012 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.003 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + 0.001 chosen + -0.0 sig_action + -0.0 sig_grooming + 0.002 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.228 1 + 1.0 value_scratch[t] + -0.001 chosen + 0.002 sig_action + -0.176 sig_grooming + -0.003 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.017 1 + 1.001 value_waiting[t] + -0.001 chosen + -0.0 sig_action + -0.002 sig_grooming + 0.184 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.003 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 46/1000 --- L(Train): 0.0615410 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.998 value_action[t] + 0.0 chosen + 0.001 sig_action + 0.007 sig_grooming + -0.017 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = -0.001 1 + 0.998 value_grooming[t] + 0.007 chosen + 0.0 sig_action + 0.008 sig_grooming + 0.0 sig_non_contact + 0.0 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + -0.003 prev_waiting \n",
            "value_non_contact[t+1] = -0.367 1 + 0.999 value_non_contact[t] + -0.002 chosen + 0.001 sig_action + -0.366 sig_grooming + 0.011 sig_non_contact + -0.0 sig_contact + 0.002 sig_scratch + -0.003 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 1.0 value_contact[t] + 0.001 chosen + 0.002 sig_action + 0.001 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.227 1 + 1.0 value_scratch[t] + -0.001 chosen + 0.002 sig_action + -0.173 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.016 1 + 1.0 value_waiting[t] + -0.001 chosen + 0.0 sig_action + 0.0 sig_grooming + 0.187 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 47/1000 --- L(Train): 0.0605019 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + -0.001 chosen + -0.0 sig_action + 0.006 sig_grooming + -0.018 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = -0.001 1 + 0.998 value_grooming[t] + 0.005 chosen + -0.001 sig_action + 0.008 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.003 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.371 1 + 0.998 value_non_contact[t] + -0.002 chosen + -0.0 sig_action + -0.37 sig_grooming + 0.01 sig_non_contact + 0.001 sig_contact + 0.003 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 1.001 value_contact[t] + 0.0 chosen + 0.002 sig_action + -0.0 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.226 1 + 1.0 value_scratch[t] + 0.0 chosen + 0.001 sig_action + -0.17 sig_grooming + 0.002 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.015 1 + 0.999 value_waiting[t] + 0.0 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.189 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 48/1000 --- L(Train): 0.0595043 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.002 value_action[t] + -0.001 chosen + -0.0 sig_action + 0.006 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 0.999 value_grooming[t] + 0.004 chosen + -0.001 sig_action + 0.007 sig_grooming + -0.001 sig_non_contact + -0.0 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.003 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 0.999 value_non_contact[t] + -0.0 chosen + -0.0 sig_action + -0.374 sig_grooming + 0.008 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.041 1 + 1.002 value_contact[t] + -0.002 chosen + 0.002 sig_action + -0.0 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.224 1 + 0.999 value_scratch[t] + -0.0 chosen + -0.002 sig_action + -0.168 sig_grooming + 0.005 sig_non_contact + -0.0 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.014 1 + 0.999 value_waiting[t] + -0.0 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.192 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 49/1000 --- L(Train): 0.0585274 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.003 value_action[t] + -0.0 chosen + 0.001 sig_action + 0.006 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.004 1 + 1.001 value_grooming[t] + 0.003 chosen + -0.0 sig_action + 0.006 sig_grooming + -0.003 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.38 1 + 1.0 value_non_contact[t] + 0.003 chosen + 0.001 sig_action + -0.378 sig_grooming + 0.006 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.041 1 + 1.001 value_contact[t] + -0.002 chosen + 0.001 sig_action + 0.0 sig_grooming + -0.0 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.223 1 + 0.999 value_scratch[t] + 0.001 chosen + -0.003 sig_action + -0.165 sig_grooming + 0.006 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.014 1 + 1.001 value_waiting[t] + 0.001 chosen + 0.001 sig_action + -0.001 sig_grooming + 0.194 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 50/1000 --- L(Train): 0.0575924 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.0 1 + 1.002 value_action[t] + 0.002 chosen + 0.001 sig_action + 0.007 sig_grooming + -0.02 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + -0.002 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 1.002 value_grooming[t] + 0.001 chosen + 0.002 sig_action + 0.006 sig_grooming + -0.003 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.383 1 + 1.001 value_non_contact[t] + 0.005 chosen + 0.001 sig_action + -0.382 sig_grooming + 0.003 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.041 1 + 0.999 value_contact[t] + -0.002 chosen + -0.002 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.222 1 + 1.0 value_scratch[t] + 0.001 chosen + -0.002 sig_action + -0.163 sig_grooming + 0.007 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.013 1 + 1.001 value_waiting[t] + 0.001 chosen + 0.001 sig_action + 0.0 sig_grooming + 0.196 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 51/1000 --- L(Train): 0.0567272 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.002 1 + 1.001 value_action[t] + 0.002 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.02 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.007 1 + 1.002 value_grooming[t] + -0.0 chosen + 0.002 sig_action + 0.005 sig_grooming + -0.003 sig_non_contact + -0.0 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.387 1 + 1.001 value_non_contact[t] + 0.007 chosen + 0.0 sig_action + -0.386 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.002 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 0.999 value_contact[t] + -0.001 chosen + -0.003 sig_action + -0.001 sig_grooming + 0.002 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.003 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.221 1 + 1.0 value_scratch[t] + -0.001 chosen + -0.001 sig_action + -0.16 sig_grooming + 0.007 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.002 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + -0.003 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.012 1 + 1.0 value_waiting[t] + -0.001 chosen + -0.0 sig_action + -0.002 sig_grooming + 0.199 sig_non_contact + 0.002 sig_contact + -0.0 sig_scratch + -0.003 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.003 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 52/1000 --- L(Train): 0.0558465 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.003 1 + 0.998 value_action[t] + 0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.021 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + -0.002 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.008 1 + 1.0 value_grooming[t] + 0.002 chosen + 0.002 sig_action + 0.004 sig_grooming + -0.002 sig_non_contact + 0.0 sig_contact + -0.0 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.0 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.39 1 + 0.999 value_non_contact[t] + 0.008 chosen + -0.002 sig_action + -0.389 sig_grooming + -0.002 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 0.999 value_contact[t] + 0.002 chosen + -0.002 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.221 1 + 1.0 value_scratch[t] + -0.001 chosen + 0.001 sig_action + -0.158 sig_grooming + 0.006 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.0 sig_waiting + 0.002 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.011 1 + 1.0 value_waiting[t] + -0.001 chosen + 0.0 sig_action + -0.003 sig_grooming + 0.201 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + 0.0 prev_grooming + -0.003 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 53/1000 --- L(Train): 0.0550273 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.003 1 + 0.997 value_action[t] + 0.001 chosen + -0.002 sig_action + 0.008 sig_grooming + -0.021 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.003 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.008 1 + 0.998 value_grooming[t] + 0.004 chosen + 0.001 sig_action + 0.003 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.393 1 + 0.997 value_non_contact[t] + 0.008 chosen + -0.002 sig_action + -0.393 sig_grooming + -0.003 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.003 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.001 value_contact[t] + 0.003 chosen + -0.001 sig_action + 0.0 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.003 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.22 1 + 1.0 value_scratch[t] + 0.0 chosen + 0.001 sig_action + -0.155 sig_grooming + 0.004 sig_non_contact + -0.002 sig_contact + -0.003 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.01 1 + 1.001 value_waiting[t] + 0.0 chosen + -0.001 sig_action + -0.003 sig_grooming + 0.203 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + -0.003 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 54/1000 --- L(Train): 0.0541854 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.997 value_action[t] + -0.002 chosen + -0.002 sig_action + 0.008 sig_grooming + -0.022 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.003 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.008 1 + 0.997 value_grooming[t] + 0.006 chosen + -0.002 sig_action + 0.002 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.396 1 + 0.997 value_non_contact[t] + 0.009 chosen + -0.002 sig_action + -0.396 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.002 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.001 value_contact[t] + 0.003 chosen + 0.001 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.219 1 + 1.0 value_scratch[t] + -0.0 chosen + 0.001 sig_action + -0.153 sig_grooming + 0.002 sig_non_contact + -0.002 sig_contact + -0.003 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.009 1 + 1.001 value_waiting[t] + 0.0 chosen + -0.001 sig_action + -0.002 sig_grooming + 0.205 sig_non_contact + -0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 55/1000 --- L(Train): 0.0534229 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.997 value_action[t] + -0.003 chosen + -0.001 sig_action + 0.007 sig_grooming + -0.022 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + 0.003 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.008 1 + 0.997 value_grooming[t] + 0.007 chosen + -0.003 sig_action + 0.001 sig_grooming + 0.0 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.0 prev_non_contact + -0.003 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.399 1 + 0.996 value_non_contact[t] + 0.009 chosen + -0.001 sig_action + -0.399 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.003 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + 0.001 chosen + 0.001 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.219 1 + 1.001 value_scratch[t] + 0.001 chosen + -0.0 sig_action + -0.151 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.003 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.003 prev_waiting \n",
            "value_waiting[t+1] = 0.008 1 + 1.0 value_waiting[t] + -0.001 chosen + 0.001 sig_action + -0.001 sig_grooming + 0.206 sig_non_contact + -0.003 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + -0.003 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 56/1000 --- L(Train): 0.0526709 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.999 value_action[t] + -0.003 chosen + 0.002 sig_action + 0.006 sig_grooming + -0.022 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.008 1 + 0.998 value_grooming[t] + 0.009 chosen + -0.002 sig_action + 0.0 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.0 prev_non_contact + -0.003 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.402 1 + 0.996 value_non_contact[t] + 0.008 chosen + 0.002 sig_action + -0.402 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.003 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 0.999 value_contact[t] + -0.001 chosen + 0.001 sig_action + -0.0 sig_grooming + 0.0 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.218 1 + 1.001 value_scratch[t] + 0.001 chosen + -0.0 sig_action + -0.149 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.003 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.007 1 + 0.999 value_waiting[t] + -0.001 chosen + 0.001 sig_action + 0.0 sig_grooming + 0.208 sig_non_contact + -0.003 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + -0.003 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 57/1000 --- L(Train): 0.0519527 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.001 value_action[t] + -0.001 chosen + 0.003 sig_action + 0.006 sig_grooming + -0.022 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.007 1 + 0.999 value_grooming[t] + 0.009 chosen + -0.001 sig_action + -0.001 sig_grooming + -0.003 sig_non_contact + -0.0 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.404 1 + 0.997 value_non_contact[t] + 0.007 chosen + 0.003 sig_action + -0.404 sig_grooming + 0.004 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + -0.002 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 0.998 value_contact[t] + -0.001 chosen + -0.0 sig_action + 0.001 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.003 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.003 prev_contact + 0.003 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.218 1 + 0.999 value_scratch[t] + -0.001 chosen + 0.001 sig_action + -0.147 sig_grooming + -0.001 sig_non_contact + 0.003 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + -0.002 prev_action + 0.0 prev_grooming + 0.003 prev_non_contact + 0.003 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.006 1 + 1.0 value_waiting[t] + -0.0 chosen + -0.0 sig_action + -0.001 sig_grooming + 0.21 sig_non_contact + -0.001 sig_contact + -0.003 sig_scratch + -0.0 sig_waiting + 0.002 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.003 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 58/1000 --- L(Train): 0.0512161 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.002 value_action[t] + 0.001 chosen + 0.002 sig_action + 0.007 sig_grooming + -0.022 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.002 prev_scratch + 0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 1.002 value_grooming[t] + 0.01 chosen + 0.001 sig_action + 0.002 sig_grooming + -0.004 sig_non_contact + -0.0 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.406 1 + 0.997 value_non_contact[t] + 0.006 chosen + 0.002 sig_action + -0.407 sig_grooming + 0.005 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 0.999 value_contact[t] + -0.001 chosen + -0.0 sig_action + 0.0 sig_grooming + -0.0 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.003 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.218 1 + 0.999 value_scratch[t] + -0.001 chosen + 0.0 sig_action + -0.146 sig_grooming + 0.001 sig_non_contact + 0.003 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + 0.002 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.005 1 + 1.0 value_waiting[t] + 0.002 chosen + -0.0 sig_action + -0.001 sig_grooming + 0.211 sig_non_contact + 0.0 sig_contact + -0.002 sig_scratch + -0.0 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + -0.002 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 59/1000 --- L(Train): 0.0505050 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.001 value_action[t] + 0.001 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.022 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 1.003 value_grooming[t] + 0.01 chosen + 0.001 sig_action + 0.004 sig_grooming + -0.004 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.408 1 + 0.998 value_non_contact[t] + 0.005 chosen + 0.001 sig_action + -0.409 sig_grooming + 0.005 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 1.0 value_contact[t] + 0.0 chosen + 0.001 sig_action + -0.002 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.217 1 + 1.0 value_scratch[t] + 0.0 chosen + -0.001 sig_action + -0.144 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_waiting[t+1] = 0.004 1 + 1.001 value_waiting[t] + 0.002 chosen + 0.001 sig_action + -0.0 sig_grooming + 0.212 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + -0.003 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 60/1000 --- L(Train): 0.0498355 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + 0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.022 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 1.003 value_grooming[t] + 0.01 chosen + 0.001 sig_action + 0.005 sig_grooming + -0.004 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.41 1 + 0.999 value_non_contact[t] + 0.004 chosen + -0.001 sig_action + -0.411 sig_grooming + 0.006 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.001 value_contact[t] + 0.0 chosen + 0.0 sig_action + -0.004 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.217 1 + 1.001 value_scratch[t] + 0.0 chosen + -0.001 sig_action + -0.143 sig_grooming + 0.002 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 1.0 value_waiting[t] + 0.002 chosen + 0.001 sig_action + 0.001 sig_grooming + 0.213 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 61/1000 --- L(Train): 0.0491550 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.998 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.022 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 1.002 value_grooming[t] + 0.01 chosen + -0.0 sig_action + 0.007 sig_grooming + -0.003 sig_non_contact + 0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.412 1 + 1.001 value_non_contact[t] + 0.003 chosen + -0.001 sig_action + -0.414 sig_grooming + 0.006 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + -0.001 chosen + -0.001 sig_action + -0.004 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.218 1 + 1.001 value_scratch[t] + -0.001 chosen + 0.0 sig_action + -0.141 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 0.999 value_waiting[t] + 0.001 chosen + 0.0 sig_action + -0.0 sig_grooming + 0.214 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 62/1000 --- L(Train): 0.0485126 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 0.996 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.021 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.0 1 + 1.0 value_grooming[t] + 0.01 chosen + -0.0 sig_action + 0.008 sig_grooming + -0.001 sig_non_contact + -0.002 sig_contact + 0.002 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.413 1 + 1.0 value_non_contact[t] + 0.001 chosen + -0.001 sig_action + -0.416 sig_grooming + 0.005 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + -0.0 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 0.999 value_contact[t] + -0.0 chosen + -0.001 sig_action + -0.004 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.218 1 + 1.0 value_scratch[t] + -0.001 chosen + 0.0 sig_action + -0.14 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 0.998 value_waiting[t] + -0.002 chosen + -0.002 sig_action + -0.001 sig_grooming + 0.215 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 63/1000 --- L(Train): 0.0479095 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.996 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.01 sig_grooming + -0.021 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = -0.002 1 + 0.999 value_grooming[t] + 0.009 chosen + 0.001 sig_action + 0.009 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.414 1 + 1.0 value_non_contact[t] + -0.001 chosen + 0.0 sig_action + -0.417 sig_grooming + 0.005 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.003 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 0.998 value_contact[t] + 0.001 chosen + 0.0 sig_action + -0.004 sig_grooming + -0.0 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.002 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.218 1 + 1.0 value_scratch[t] + -0.0 chosen + -0.001 sig_action + -0.139 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.0 1 + 0.999 value_waiting[t] + -0.003 chosen + -0.002 sig_action + -0.001 sig_grooming + 0.216 sig_non_contact + 0.0 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.003 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 64/1000 --- L(Train): 0.0473003 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.997 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.01 sig_grooming + -0.02 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = -0.001 1 + 0.999 value_grooming[t] + 0.009 chosen + 0.0 sig_action + 0.009 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.415 1 + 0.999 value_non_contact[t] + 0.0 chosen + 0.0 sig_action + -0.419 sig_grooming + 0.005 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.003 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 0.999 value_contact[t] + 0.001 chosen + -0.0 sig_action + -0.003 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.218 1 + 1.0 value_scratch[t] + 0.002 chosen + -0.001 sig_action + -0.138 sig_grooming + -0.002 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = -0.0 1 + 1.0 value_waiting[t] + -0.002 chosen + -0.002 sig_action + 0.001 sig_grooming + 0.217 sig_non_contact + 0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 65/1000 --- L(Train): 0.0467167 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.998 value_action[t] + -0.001 chosen + -0.001 sig_action + 0.01 sig_grooming + -0.02 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 1.0 value_grooming[t] + 0.008 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.416 1 + 0.999 value_non_contact[t] + 0.0 chosen + -0.001 sig_action + -0.421 sig_grooming + 0.004 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + -0.0 chosen + 0.001 sig_action + -0.001 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.219 1 + 1.0 value_scratch[t] + 0.002 chosen + -0.0 sig_action + -0.138 sig_grooming + -0.0 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 1.0 value_waiting[t] + -0.001 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.217 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 66/1000 --- L(Train): 0.0461614 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + -0.001 chosen + -0.0 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.004 1 + 1.002 value_grooming[t] + 0.007 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.002 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.417 1 + 0.999 value_non_contact[t] + 0.001 chosen + -0.0 sig_action + -0.422 sig_grooming + 0.003 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.001 value_contact[t] + 0.0 chosen + 0.001 sig_action + 0.001 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.219 1 + 1.0 value_scratch[t] + 0.002 chosen + 0.002 sig_action + -0.137 sig_grooming + 0.002 sig_non_contact + -0.0 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.0 value_waiting[t] + 0.001 chosen + 0.002 sig_action + -0.001 sig_grooming + 0.218 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 67/1000 --- L(Train): 0.0456025 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.001 value_action[t] + -0.0 chosen + 0.001 sig_action + 0.007 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 1.002 value_grooming[t] + 0.006 chosen + -0.0 sig_action + 0.009 sig_grooming + -0.002 sig_non_contact + 0.003 sig_contact + -0.002 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.418 1 + 1.0 value_non_contact[t] + 0.001 chosen + 0.001 sig_action + -0.423 sig_grooming + 0.003 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + -0.003 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + -0.001 chosen + -0.001 sig_action + 0.001 sig_grooming + -0.001 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.003 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.22 1 + 0.999 value_scratch[t] + 0.001 chosen + 0.002 sig_action + -0.136 sig_grooming + 0.004 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + -0.0 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 1.0 value_waiting[t] + 0.001 chosen + 0.003 sig_action + -0.001 sig_grooming + 0.218 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 68/1000 --- L(Train): 0.0450587 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.001 value_action[t] + 0.002 chosen + 0.001 sig_action + 0.007 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.007 1 + 1.002 value_grooming[t] + 0.005 chosen + 0.002 sig_action + 0.009 sig_grooming + -0.002 sig_non_contact + 0.002 sig_contact + -0.002 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.419 1 + 1.0 value_non_contact[t] + 0.001 chosen + 0.001 sig_action + -0.425 sig_grooming + 0.002 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 0.999 value_contact[t] + -0.0 chosen + -0.001 sig_action + 0.0 sig_grooming + -0.0 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.221 1 + 0.999 value_scratch[t] + -0.002 chosen + 0.002 sig_action + -0.136 sig_grooming + 0.004 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 1.001 value_waiting[t] + 0.001 chosen + 0.003 sig_action + 0.0 sig_grooming + 0.219 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 69/1000 --- L(Train): 0.0445839 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.0 1 + 0.999 value_action[t] + 0.002 chosen + 0.0 sig_action + 0.007 sig_grooming + -0.018 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.007 1 + 1.0 value_grooming[t] + 0.003 chosen + 0.002 sig_action + 0.008 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.419 1 + 0.998 value_non_contact[t] + 0.0 chosen + -0.0 sig_action + -0.426 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 0.998 value_contact[t] + 0.001 chosen + 0.0 sig_action + -0.003 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.221 1 + 1.0 value_scratch[t] + -0.003 chosen + 0.001 sig_action + -0.135 sig_grooming + 0.004 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + -0.003 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.004 1 + 1.001 value_waiting[t] + -0.0 chosen + 0.001 sig_action + -0.001 sig_grooming + 0.219 sig_non_contact + 0.002 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 70/1000 --- L(Train): 0.0440730 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.999 value_action[t] + 0.002 chosen + -0.002 sig_action + 0.007 sig_grooming + -0.018 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.007 1 + 0.998 value_grooming[t] + 0.002 chosen + 0.002 sig_action + 0.007 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.419 1 + 0.997 value_non_contact[t] + 0.0 chosen + 0.0 sig_action + -0.427 sig_grooming + 0.0 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 0.999 value_contact[t] + 0.001 chosen + 0.0 sig_action + -0.005 sig_grooming + 0.002 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.222 1 + 1.0 value_scratch[t] + -0.002 chosen + -0.002 sig_action + -0.135 sig_grooming + 0.003 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.004 1 + 1.0 value_waiting[t] + -0.0 chosen + -0.001 sig_action + -0.002 sig_grooming + 0.219 sig_non_contact + 0.002 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 71/1000 --- L(Train): 0.0435814 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.002 1 + 0.999 value_action[t] + 0.001 chosen + -0.002 sig_action + 0.007 sig_grooming + -0.018 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.007 1 + 0.997 value_grooming[t] + 0.0 chosen + 0.001 sig_action + 0.006 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.419 1 + 0.996 value_non_contact[t] + -0.0 chosen + -0.001 sig_action + -0.428 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.001 value_contact[t] + -0.0 chosen + -0.001 sig_action + -0.006 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.223 1 + 0.999 value_scratch[t] + -0.001 chosen + -0.003 sig_action + -0.135 sig_grooming + 0.002 sig_non_contact + -0.002 sig_contact + -0.003 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.004 1 + 1.0 value_waiting[t] + 0.001 chosen + -0.001 sig_action + -0.002 sig_grooming + 0.219 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 72/1000 --- L(Train): 0.0430640 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + -0.002 chosen + -0.002 sig_action + 0.007 sig_grooming + -0.018 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.007 1 + 0.997 value_grooming[t] + -0.001 chosen + -0.002 sig_action + 0.005 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.419 1 + 0.995 value_non_contact[t] + 0.002 chosen + -0.001 sig_action + -0.429 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + -0.002 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.001 value_contact[t] + 0.0 chosen + -0.001 sig_action + -0.006 sig_grooming + -0.0 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.224 1 + 0.998 value_scratch[t] + 0.001 chosen + -0.002 sig_action + -0.134 sig_grooming + 0.0 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.004 1 + 1.001 value_waiting[t] + 0.0 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.219 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + -0.002 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 73/1000 --- L(Train): 0.0426121 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.0 1 + 1.0 value_action[t] + -0.003 chosen + -0.001 sig_action + 0.007 sig_grooming + -0.018 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 0.997 value_grooming[t] + 0.001 chosen + -0.003 sig_action + 0.004 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + -0.0 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.0 prev_non_contact + -0.003 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.419 1 + 0.994 value_non_contact[t] + 0.003 chosen + 0.001 sig_action + -0.429 sig_grooming + 0.002 sig_non_contact + -0.003 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.003 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + -0.001 chosen + -0.0 sig_action + -0.006 sig_grooming + -0.001 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.225 1 + 0.999 value_scratch[t] + 0.001 chosen + -0.001 sig_action + -0.134 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.003 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 1.0 value_waiting[t] + -0.001 chosen + 0.0 sig_action + 0.001 sig_grooming + 0.218 sig_non_contact + -0.003 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 74/1000 --- L(Train): 0.0421713 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.999 value_action[t] + -0.003 chosen + 0.002 sig_action + 0.008 sig_grooming + -0.018 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 0.999 value_grooming[t] + 0.003 chosen + -0.002 sig_action + 0.003 sig_grooming + -0.003 sig_non_contact + 0.0 sig_contact + -0.0 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.0 prev_non_contact + -0.003 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.419 1 + 0.994 value_non_contact[t] + 0.004 chosen + 0.001 sig_action + -0.43 sig_grooming + 0.003 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.003 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.002 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 0.999 value_contact[t] + -0.001 chosen + 0.002 sig_action + -0.005 sig_grooming + -0.0 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.226 1 + 1.0 value_scratch[t] + 0.001 chosen + 0.001 sig_action + -0.134 sig_grooming + -0.003 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.003 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 0.999 value_waiting[t] + -0.001 chosen + 0.0 sig_action + -0.0 sig_grooming + 0.218 sig_non_contact + -0.003 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 75/1000 --- L(Train): 0.0417305 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.0 1 + 0.999 value_action[t] + -0.001 chosen + 0.003 sig_action + 0.008 sig_grooming + -0.018 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.004 1 + 1.001 value_grooming[t] + 0.005 chosen + -0.001 sig_action + 0.002 sig_grooming + -0.003 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.419 1 + 0.994 value_non_contact[t] + 0.005 chosen + -0.0 sig_action + -0.431 sig_grooming + 0.003 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.035 1 + 0.999 value_contact[t] + 0.001 chosen + 0.002 sig_action + -0.004 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.003 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.226 1 + 1.002 value_scratch[t] + -0.0 chosen + 0.001 sig_action + -0.134 sig_grooming + -0.002 sig_non_contact + 0.003 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 0.999 value_waiting[t] + 0.0 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.217 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + -0.002 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 76/1000 --- L(Train): 0.0412576 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + 0.001 chosen + 0.002 sig_action + 0.009 sig_grooming + -0.018 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + 0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 1.002 value_grooming[t] + 0.007 chosen + 0.001 sig_action + 0.001 sig_grooming + -0.003 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.419 1 + 0.994 value_non_contact[t] + 0.006 chosen + -0.0 sig_action + -0.431 sig_grooming + 0.004 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.035 1 + 0.999 value_contact[t] + 0.001 chosen + 0.002 sig_action + -0.002 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.003 sig_waiting + -0.0 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.227 1 + 1.002 value_scratch[t] + -0.0 chosen + 0.001 sig_action + -0.134 sig_grooming + -0.0 sig_non_contact + 0.003 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.002 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.0 value_waiting[t] + -0.0 chosen + -0.0 sig_action + -0.0 sig_grooming + 0.217 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + -0.0 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 77/1000 --- L(Train): 0.0408046 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + 0.001 chosen + 0.001 sig_action + 0.009 sig_grooming + -0.018 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + -0.003 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 1.002 value_grooming[t] + 0.008 chosen + 0.001 sig_action + 0.0 sig_grooming + -0.003 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.419 1 + 0.994 value_non_contact[t] + 0.006 chosen + 0.001 sig_action + -0.432 sig_grooming + 0.004 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.035 1 + 1.001 value_contact[t] + -0.0 chosen + 0.001 sig_action + 0.001 sig_grooming + 0.0 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.228 1 + 1.001 value_scratch[t] + 0.001 chosen + -0.0 sig_action + -0.133 sig_grooming + 0.003 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + -0.003 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 1.001 value_waiting[t] + 0.001 chosen + 0.001 sig_action + 0.001 sig_grooming + 0.216 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 78/1000 --- L(Train): 0.0404007 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + 0.001 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.018 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.001 value_grooming[t] + 0.009 chosen + 0.001 sig_action + -0.001 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.418 1 + 0.995 value_non_contact[t] + 0.006 chosen + 0.001 sig_action + -0.432 sig_grooming + 0.003 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.035 1 + 1.001 value_contact[t] + -0.0 chosen + -0.002 sig_action + 0.001 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.229 1 + 0.999 value_scratch[t] + 0.0 chosen + -0.0 sig_action + -0.133 sig_grooming + 0.006 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + -0.003 prev_non_contact + -0.001 prev_contact + -0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.0 1 + 1.002 value_waiting[t] + 0.001 chosen + 0.001 sig_action + -0.0 sig_grooming + 0.216 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 79/1000 --- L(Train): 0.0399722 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.999 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = -0.0 1 + 0.999 value_grooming[t] + 0.01 chosen + -0.0 sig_action + 0.002 sig_grooming + -0.0 sig_non_contact + -0.0 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.418 1 + 0.996 value_non_contact[t] + 0.006 chosen + 0.0 sig_action + -0.433 sig_grooming + 0.003 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 1.001 value_contact[t] + 0.001 chosen + -0.003 sig_action + -0.0 sig_grooming + -0.002 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.23 1 + 0.998 value_scratch[t] + -0.001 chosen + 0.001 sig_action + -0.133 sig_grooming + 0.008 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + -0.003 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = -0.001 1 + 1.001 value_waiting[t] + -0.001 chosen + -0.0 sig_action + -0.0 sig_grooming + 0.216 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.003 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 80/1000 --- L(Train): 0.0395475 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.007 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 0.998 value_grooming[t] + 0.011 chosen + -0.0 sig_action + 0.005 sig_grooming + 0.002 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.417 1 + 0.997 value_non_contact[t] + 0.006 chosen + -0.002 sig_action + -0.433 sig_grooming + 0.003 sig_non_contact + -0.0 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + 0.002 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 0.999 value_contact[t] + 0.001 chosen + -0.002 sig_action + -0.001 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.23 1 + 0.999 value_scratch[t] + -0.001 chosen + 0.0 sig_action + -0.133 sig_grooming + 0.008 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 0.999 value_waiting[t] + -0.001 chosen + 0.0 sig_action + 0.0 sig_grooming + 0.215 sig_non_contact + -0.0 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 81/1000 --- L(Train): 0.0391689 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.001 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 0.998 value_grooming[t] + 0.012 chosen + 0.001 sig_action + 0.007 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.003 prev_scratch + -0.003 prev_waiting \n",
            "value_non_contact[t+1] = -0.417 1 + 0.998 value_non_contact[t] + 0.005 chosen + -0.002 sig_action + -0.434 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.003 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 0.999 value_contact[t] + 0.0 chosen + -0.001 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.231 1 + 0.999 value_scratch[t] + 0.0 chosen + -0.001 sig_action + -0.133 sig_grooming + 0.009 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 0.999 value_waiting[t] + 0.0 chosen + -0.001 sig_action + -0.002 sig_grooming + 0.215 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + 0.003 prev_grooming + 0.003 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 82/1000 --- L(Train): 0.0387744 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.001 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 0.999 value_grooming[t] + 0.012 chosen + 0.0 sig_action + 0.009 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + -0.003 prev_waiting \n",
            "value_non_contact[t+1] = -0.416 1 + 0.999 value_non_contact[t] + 0.005 chosen + -0.002 sig_action + -0.434 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 0.999 value_contact[t] + -0.002 chosen + 0.001 sig_action + -0.0 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.232 1 + 1.001 value_scratch[t] + -0.0 chosen + -0.001 sig_action + -0.133 sig_grooming + 0.008 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.004 1 + 0.999 value_waiting[t] + -0.0 chosen + -0.0 sig_action + -0.003 sig_grooming + 0.215 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 83/1000 --- L(Train): 0.0383915 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.999 value_action[t] + -0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.003 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 1.001 value_grooming[t] + 0.012 chosen + -0.001 sig_action + 0.01 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.003 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.416 1 + 1.0 value_non_contact[t] + 0.004 chosen + -0.001 sig_action + -0.434 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.001 value_contact[t] + -0.002 chosen + 0.001 sig_action + 0.001 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.233 1 + 1.001 value_scratch[t] + 0.001 chosen + 0.0 sig_action + -0.133 sig_grooming + 0.007 sig_non_contact + -0.0 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.005 1 + 1.001 value_waiting[t] + 0.001 chosen + 0.001 sig_action + -0.003 sig_grooming + 0.214 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 84/1000 --- L(Train): 0.0380281 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.999 value_action[t] + -0.001 chosen + -0.0 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.002 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 1.002 value_grooming[t] + 0.011 chosen + -0.001 sig_action + 0.011 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.003 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.415 1 + 0.999 value_non_contact[t] + 0.003 chosen + 0.002 sig_action + -0.435 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + -0.002 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 1.001 value_contact[t] + -0.002 chosen + 0.001 sig_action + 0.0 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.233 1 + 1.0 value_scratch[t] + 0.001 chosen + 0.0 sig_action + -0.132 sig_grooming + 0.005 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.005 1 + 1.001 value_waiting[t] + 0.001 chosen + 0.001 sig_action + -0.002 sig_grooming + 0.214 sig_non_contact + -0.001 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 85/1000 --- L(Train): 0.0376677 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + -0.0 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 1.001 value_grooming[t] + 0.01 chosen + -0.0 sig_action + 0.011 sig_grooming + -0.001 sig_non_contact + -0.0 sig_contact + 0.002 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.415 1 + 0.998 value_non_contact[t] + 0.002 chosen + 0.003 sig_action + -0.435 sig_grooming + 0.0 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + -0.002 prev_non_contact + -0.003 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.041 1 + 1.001 value_contact[t] + -0.001 chosen + -0.0 sig_action + -0.002 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.003 prev_contact + 0.003 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.234 1 + 0.998 value_scratch[t] + -0.001 chosen + -0.001 sig_action + -0.132 sig_grooming + 0.003 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.0 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.006 1 + 1.0 value_waiting[t] + -0.001 chosen + -0.0 sig_action + -0.001 sig_grooming + 0.214 sig_non_contact + -0.0 sig_contact + -0.003 sig_scratch + -0.0 sig_waiting + 0.003 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 86/1000 --- L(Train): 0.0372964 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 1.001 value_action[t] + 0.002 chosen + 0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.0 value_grooming[t] + 0.009 chosen + 0.002 sig_action + 0.011 sig_grooming + -0.001 sig_non_contact + -0.0 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.414 1 + 0.998 value_non_contact[t] + 0.001 chosen + 0.002 sig_action + -0.435 sig_grooming + 0.002 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.0 prev_grooming + -0.002 prev_non_contact + -0.002 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.041 1 + 0.999 value_contact[t] + 0.002 chosen + -0.0 sig_action + -0.003 sig_grooming + -0.002 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.002 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.235 1 + 0.997 value_scratch[t] + -0.001 chosen + -0.001 sig_action + -0.132 sig_grooming + 0.0 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.006 1 + 1.0 value_waiting[t] + -0.001 chosen + 0.0 sig_action + 0.001 sig_grooming + 0.213 sig_non_contact + 0.002 sig_contact + -0.002 sig_scratch + -0.0 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 87/1000 --- L(Train): 0.0369839 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.002 value_action[t] + 0.002 chosen + 0.0 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.003 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = -0.001 1 + 0.999 value_grooming[t] + 0.008 chosen + 0.002 sig_action + 0.011 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.413 1 + 0.998 value_non_contact[t] + 0.0 chosen + 0.001 sig_action + -0.435 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 0.999 value_contact[t] + 0.003 chosen + 0.001 sig_action + -0.003 sig_grooming + -0.002 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.235 1 + 0.997 value_scratch[t] + 0.0 chosen + -0.0 sig_action + -0.131 sig_grooming + -0.003 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.006 1 + 1.001 value_waiting[t] + 0.0 chosen + -0.001 sig_action + -0.0 sig_grooming + 0.213 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 88/1000 --- L(Train): 0.0366342 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.001 value_action[t] + 0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.003 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.0 1 + 1.0 value_grooming[t] + 0.007 chosen + 0.002 sig_action + 0.011 sig_grooming + 0.0 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.413 1 + 0.998 value_non_contact[t] + -0.001 chosen + -0.001 sig_action + -0.435 sig_grooming + 0.003 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + 0.003 chosen + 0.0 sig_action + -0.003 sig_grooming + -0.002 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.003 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.236 1 + 0.998 value_scratch[t] + -0.0 chosen + 0.002 sig_action + -0.131 sig_grooming + -0.004 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.006 1 + 1.001 value_waiting[t] + 0.0 chosen + -0.001 sig_action + -0.0 sig_grooming + 0.212 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 89/1000 --- L(Train): 0.0362985 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.999 value_action[t] + 0.001 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.001 value_grooming[t] + 0.006 chosen + 0.001 sig_action + 0.01 sig_grooming + -0.002 sig_non_contact + 0.0 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.412 1 + 0.998 value_non_contact[t] + 0.0 chosen + -0.001 sig_action + -0.436 sig_grooming + 0.003 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.003 sig_waiting + 0.001 prev_action + -0.0 prev_grooming + 0.003 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.001 value_contact[t] + 0.001 chosen + -0.001 sig_action + -0.002 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.236 1 + 0.999 value_scratch[t] + 0.001 chosen + 0.002 sig_action + -0.131 sig_grooming + -0.003 sig_non_contact + -0.002 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + 0.0 prev_action + -0.003 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.006 1 + 1.0 value_waiting[t] + -0.001 chosen + 0.001 sig_action + 0.0 sig_grooming + 0.212 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 90/1000 --- L(Train): 0.0359369 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.998 value_action[t] + -0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.002 value_grooming[t] + 0.004 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.004 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + -0.002 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.411 1 + 0.998 value_non_contact[t] + 0.001 chosen + -0.001 sig_action + -0.436 sig_grooming + 0.003 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.003 sig_waiting + -0.002 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.035 1 + 1.002 value_contact[t] + -0.001 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.236 1 + 1.001 value_scratch[t] + 0.001 chosen + 0.002 sig_action + -0.13 sig_grooming + -0.001 sig_non_contact + -0.002 sig_contact + -0.0 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.006 1 + 0.999 value_waiting[t] + -0.001 chosen + 0.001 sig_action + -0.001 sig_grooming + 0.211 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + 0.002 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 91/1000 --- L(Train): 0.0356382 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.998 value_action[t] + -0.003 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.001 value_grooming[t] + 0.003 chosen + -0.003 sig_action + 0.008 sig_grooming + -0.004 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + -0.003 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.41 1 + 0.999 value_non_contact[t] + 0.002 chosen + 0.0 sig_action + -0.436 sig_grooming + 0.003 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + -0.003 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.034 1 + 1.001 value_contact[t] + -0.001 chosen + 0.0 sig_action + 0.001 sig_grooming + 0.001 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.236 1 + 1.001 value_scratch[t] + -0.001 chosen + 0.001 sig_action + -0.13 sig_grooming + 0.003 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.003 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.003 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.005 1 + 1.0 value_waiting[t] + -0.0 chosen + -0.0 sig_action + -0.002 sig_grooming + 0.211 sig_non_contact + -0.003 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + -0.003 prev_contact + -0.003 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 92/1000 --- L(Train): 0.0353280 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 0.999 value_action[t] + -0.003 chosen + 0.002 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 0.999 value_grooming[t] + 0.001 chosen + -0.002 sig_action + 0.008 sig_grooming + -0.004 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.0 prev_non_contact + -0.003 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.41 1 + 1.0 value_non_contact[t] + 0.002 chosen + 0.0 sig_action + -0.436 sig_grooming + 0.003 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + -0.003 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.002 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.034 1 + 1.0 value_contact[t] + -0.001 chosen + -0.0 sig_action + 0.001 sig_grooming + 0.001 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.237 1 + 1.001 value_scratch[t] + -0.001 chosen + -0.002 sig_action + -0.13 sig_grooming + 0.005 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.003 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.003 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.004 1 + 1.0 value_waiting[t] + 0.002 chosen + 0.0 sig_action + -0.002 sig_grooming + 0.21 sig_non_contact + -0.003 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + -0.003 prev_contact + -0.003 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 93/1000 --- L(Train): 0.0350170 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + -0.001 chosen + 0.003 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 0.998 value_grooming[t] + 0.0 chosen + -0.001 sig_action + 0.007 sig_grooming + -0.004 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.409 1 + 1.001 value_non_contact[t] + 0.002 chosen + -0.001 sig_action + -0.436 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.035 1 + 0.999 value_contact[t] + 0.0 chosen + 0.001 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.003 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.237 1 + 0.999 value_scratch[t] + 0.0 chosen + -0.003 sig_action + -0.129 sig_grooming + 0.007 sig_non_contact + 0.003 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_waiting[t+1] = 0.004 1 + 1.001 value_waiting[t] + 0.002 chosen + -0.001 sig_action + -0.002 sig_grooming + 0.21 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + -0.003 prev_non_contact + -0.001 prev_contact + -0.002 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 94/1000 --- L(Train): 0.0346817 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.001 value_action[t] + 0.001 chosen + 0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 0.998 value_grooming[t] + -0.001 chosen + 0.001 sig_action + 0.006 sig_grooming + -0.003 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.408 1 + 1.0 value_non_contact[t] + 0.002 chosen + -0.0 sig_action + -0.436 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 1.0 value_contact[t] + 0.0 chosen + 0.001 sig_action + -0.002 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.003 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.237 1 + 0.998 value_scratch[t] + 0.0 chosen + -0.002 sig_action + -0.129 sig_grooming + 0.008 sig_non_contact + 0.003 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 1.0 value_waiting[t] + 0.002 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.21 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + -0.002 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 95/1000 --- L(Train): 0.0343523 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + 0.001 chosen + 0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.0 value_grooming[t] + 0.002 chosen + 0.001 sig_action + 0.005 sig_grooming + -0.001 sig_non_contact + 0.003 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.407 1 + 0.999 value_non_contact[t] + 0.002 chosen + 0.001 sig_action + -0.437 sig_grooming + 0.0 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.003 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.001 value_contact[t] + -0.001 chosen + -0.001 sig_action + -0.002 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.003 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.237 1 + 0.998 value_scratch[t] + -0.001 chosen + -0.001 sig_action + -0.128 sig_grooming + 0.009 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 0.999 value_waiting[t] + 0.001 chosen + 0.001 sig_action + 0.001 sig_grooming + 0.21 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 96/1000 --- L(Train): 0.0340699 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.998 value_action[t] + 0.001 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.002 value_grooming[t] + 0.004 chosen + 0.001 sig_action + 0.004 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.406 1 + 0.998 value_non_contact[t] + 0.001 chosen + 0.001 sig_action + -0.437 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.002 value_contact[t] + -0.0 chosen + -0.001 sig_action + -0.002 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.237 1 + 0.998 value_scratch[t] + -0.001 chosen + 0.001 sig_action + -0.128 sig_grooming + 0.008 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 0.998 value_waiting[t] + -0.002 chosen + 0.001 sig_action + 0.0 sig_grooming + 0.21 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 97/1000 --- L(Train): 0.0337631 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.998 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.003 value_grooming[t] + 0.006 chosen + -0.0 sig_action + 0.004 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.406 1 + 0.998 value_non_contact[t] + 0.0 chosen + -0.0 sig_action + -0.437 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.001 value_contact[t] + 0.001 chosen + 0.0 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + -0.0 chosen + 0.001 sig_action + -0.127 sig_grooming + 0.007 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 0.999 value_waiting[t] + -0.003 chosen + -0.0 sig_action + -0.002 sig_grooming + 0.21 sig_non_contact + -0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 98/1000 --- L(Train): 0.0334496 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.998 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.018 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.002 value_grooming[t] + 0.008 chosen + -0.0 sig_action + 0.003 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.405 1 + 0.998 value_non_contact[t] + -0.001 chosen + 0.0 sig_action + -0.437 sig_grooming + 0.002 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + 0.001 chosen + 0.0 sig_action + 0.0 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.002 value_scratch[t] + 0.002 chosen + 0.001 sig_action + -0.127 sig_grooming + 0.006 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.0 value_waiting[t] + -0.002 chosen + -0.0 sig_action + -0.004 sig_grooming + 0.21 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 99/1000 --- L(Train): 0.0331801 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.999 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.018 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.0 1 + 1.001 value_grooming[t] + 0.01 chosen + 0.001 sig_action + 0.002 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.404 1 + 0.998 value_non_contact[t] + 0.001 chosen + -0.001 sig_action + -0.437 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 0.999 value_contact[t] + -0.0 chosen + -0.001 sig_action + -0.0 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.003 value_scratch[t] + 0.002 chosen + -0.0 sig_action + -0.126 sig_grooming + 0.004 sig_non_contact + 0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + 0.003 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 1.001 value_waiting[t] + -0.001 chosen + 0.001 sig_action + -0.005 sig_grooming + 0.21 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.003 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 100/1000 --- L(Train): 0.0329041 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.001 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.009 sig_grooming + -0.018 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = -0.0 1 + 0.998 value_grooming[t] + 0.011 chosen + 0.0 sig_action + 0.001 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.404 1 + 0.999 value_non_contact[t] + 0.002 chosen + -0.001 sig_action + -0.437 sig_grooming + 0.002 sig_non_contact + -0.002 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 1.0 value_contact[t] + 0.0 chosen + -0.001 sig_action + 0.0 sig_grooming + -0.002 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.002 value_scratch[t] + 0.002 chosen + -0.0 sig_action + -0.126 sig_grooming + 0.002 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 1.0 value_waiting[t] + 0.001 chosen + 0.001 sig_action + -0.005 sig_grooming + 0.21 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 101/1000 --- L(Train): 0.0326239 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.001 value_action[t] + -0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.018 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 0.997 value_grooming[t] + 0.012 chosen + -0.001 sig_action + 0.0 sig_grooming + -0.002 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.003 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.403 1 + 1.0 value_non_contact[t] + 0.002 chosen + 0.001 sig_action + -0.438 sig_grooming + 0.002 sig_non_contact + -0.003 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 1.0 value_contact[t] + -0.001 chosen + -0.0 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + 0.001 chosen + 0.001 sig_action + -0.126 sig_grooming + -0.001 sig_non_contact + -0.0 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.0 value_waiting[t] + 0.001 chosen + 0.0 sig_action + -0.004 sig_grooming + 0.211 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 102/1000 --- L(Train): 0.0323561 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.001 value_action[t] + -0.001 chosen + -0.0 sig_action + 0.008 sig_grooming + -0.018 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 0.997 value_grooming[t] + 0.013 chosen + -0.001 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.402 1 + 1.001 value_non_contact[t] + 0.002 chosen + 0.001 sig_action + -0.438 sig_grooming + 0.002 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + -0.0 chosen + 0.002 sig_action + -0.002 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 0.998 value_scratch[t] + -0.002 chosen + 0.0 sig_action + -0.125 sig_grooming + -0.001 sig_non_contact + -0.0 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.001 value_waiting[t] + 0.001 chosen + -0.002 sig_action + -0.003 sig_grooming + 0.211 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + -0.003 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 103/1000 --- L(Train): 0.0320975 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.999 value_action[t] + -0.0 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.018 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 0.998 value_grooming[t] + 0.014 chosen + -0.0 sig_action + 0.002 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.401 1 + 1.0 value_non_contact[t] + 0.002 chosen + -0.0 sig_action + -0.438 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] + 0.001 chosen + 0.002 sig_action + -0.002 sig_grooming + 0.0 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 0.996 value_scratch[t] + -0.003 chosen + -0.001 sig_action + -0.125 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.001 value_waiting[t] + -0.0 chosen + -0.002 sig_action + -0.001 sig_grooming + 0.212 sig_non_contact + -0.0 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 104/1000 --- L(Train): 0.0318297 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 0.998 value_action[t] + 0.002 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 1.0 value_grooming[t] + 0.014 chosen + 0.002 sig_action + 0.005 sig_grooming + 0.0 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.401 1 + 0.999 value_non_contact[t] + 0.002 chosen + -0.0 sig_action + -0.438 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.001 value_contact[t] + 0.001 chosen + 0.002 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 0.995 value_scratch[t] + -0.002 chosen + -0.001 sig_action + -0.124 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.0 value_waiting[t] + -0.0 chosen + -0.002 sig_action + 0.001 sig_grooming + 0.212 sig_non_contact + 0.002 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 105/1000 --- L(Train): 0.0316084 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.999 value_action[t] + 0.002 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 1.002 value_grooming[t] + 0.014 chosen + 0.002 sig_action + 0.007 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + -0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.4 1 + 0.999 value_non_contact[t] + 0.001 chosen + 0.001 sig_action + -0.439 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + 0.0 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + -0.0 chosen + 0.001 sig_action + 0.0 sig_grooming + -0.0 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 0.995 value_scratch[t] + -0.001 chosen + 0.0 sig_action + -0.124 sig_grooming + 0.004 sig_non_contact + 0.0 sig_contact + -0.003 sig_scratch + -0.0 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 1.0 value_waiting[t] + 0.001 chosen + -0.001 sig_action + 0.001 sig_grooming + 0.212 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 106/1000 --- L(Train): 0.0313504 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + 0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.0 prev_non_contact + -0.002 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 1.003 value_grooming[t] + 0.013 chosen + 0.002 sig_action + 0.008 sig_grooming + -0.004 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + -0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.4 1 + 0.999 value_non_contact[t] + 0.0 chosen + 0.001 sig_action + -0.439 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 0.999 value_contact[t] + 0.0 chosen + -0.002 sig_action + -0.0 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 0.996 value_scratch[t] + 0.001 chosen + 0.0 sig_action + -0.124 sig_grooming + 0.005 sig_non_contact + -0.002 sig_contact + -0.003 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 1.001 value_waiting[t] + 0.0 chosen + 0.002 sig_action + -0.001 sig_grooming + 0.213 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 107/1000 --- L(Train): 0.0311136 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.002 value_action[t] + 0.001 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + 0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.004 1 + 1.003 value_grooming[t] + 0.013 chosen + 0.001 sig_action + 0.009 sig_grooming + -0.005 sig_non_contact + -0.0 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.399 1 + 0.999 value_non_contact[t] + -0.001 chosen + 0.0 sig_action + -0.439 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.003 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 0.998 value_contact[t] + -0.001 chosen + -0.003 sig_action + -0.0 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + -0.0 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 0.997 value_scratch[t] + 0.001 chosen + -0.001 sig_action + -0.123 sig_grooming + 0.005 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + -0.003 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 1.0 value_waiting[t] + -0.001 chosen + 0.003 sig_action + -0.002 sig_grooming + 0.213 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + -0.003 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 108/1000 --- L(Train): 0.0308425 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.002 value_action[t] + -0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + 0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 1.002 value_grooming[t] + 0.012 chosen + -0.002 sig_action + 0.01 sig_grooming + -0.005 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.398 1 + 1.0 value_non_contact[t] + 0.001 chosen + -0.002 sig_action + -0.439 sig_grooming + 0.002 sig_non_contact + -0.0 sig_contact + 0.002 sig_scratch + -0.003 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + -0.002 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 0.999 value_contact[t] + -0.001 chosen + -0.002 sig_action + 0.001 sig_grooming + -0.0 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 0.999 value_scratch[t] + 0.001 chosen + -0.001 sig_action + -0.123 sig_grooming + 0.004 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 0.999 value_waiting[t] + -0.001 chosen + 0.003 sig_action + -0.003 sig_grooming + 0.214 sig_non_contact + -0.002 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 109/1000 --- L(Train): 0.0306319 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.002 value_action[t] + -0.003 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.0 value_grooming[t] + 0.01 chosen + -0.003 sig_action + 0.01 sig_grooming + -0.004 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + -0.003 prev_contact + 0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.398 1 + 0.999 value_non_contact[t] + 0.001 chosen + -0.002 sig_action + -0.44 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.003 sig_scratch + -0.002 sig_waiting + -0.003 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.001 value_contact[t] + 0.001 chosen + -0.001 sig_action + -0.0 sig_grooming + -0.0 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.002 value_scratch[t] + -0.0 chosen + -0.0 sig_action + -0.123 sig_grooming + 0.004 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.003 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 0.999 value_waiting[t] + 0.0 chosen + 0.001 sig_action + -0.002 sig_grooming + 0.214 sig_non_contact + -0.003 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.003 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 110/1000 --- L(Train): 0.0304000 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 1.0 value_action[t] + -0.002 chosen + 0.002 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = -0.001 1 + 0.997 value_grooming[t] + 0.009 chosen + -0.002 sig_action + 0.01 sig_grooming + -0.003 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.0 prev_non_contact + -0.003 prev_contact + -0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.397 1 + 0.998 value_non_contact[t] + 0.002 chosen + -0.002 sig_action + -0.44 sig_grooming + 0.002 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + -0.003 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.002 value_contact[t] + 0.001 chosen + 0.001 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.003 value_scratch[t] + -0.0 chosen + 0.002 sig_action + -0.122 sig_grooming + 0.002 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + -0.003 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.0 value_waiting[t] + -0.0 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.214 sig_non_contact + -0.003 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.003 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 111/1000 --- L(Train): 0.0301734 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.999 value_action[t] + -0.001 chosen + 0.003 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + 0.003 prev_contact + -0.0 prev_scratch + 0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.0 1 + 0.996 value_grooming[t] + 0.007 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.397 1 + 0.997 value_non_contact[t] + 0.002 chosen + -0.001 sig_action + -0.44 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.003 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.001 value_contact[t] + -0.0 chosen + 0.001 sig_action + -0.001 sig_grooming + 0.0 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.003 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.003 value_scratch[t] + 0.001 chosen + 0.002 sig_action + -0.122 sig_grooming + 0.0 sig_non_contact + 0.003 sig_contact + -0.0 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + -0.003 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.001 value_waiting[t] + 0.001 chosen + -0.001 sig_action + -0.0 sig_grooming + 0.215 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 112/1000 --- L(Train): 0.0299228 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + 0.001 chosen + 0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 0.995 value_grooming[t] + 0.006 chosen + 0.001 sig_action + 0.009 sig_grooming + 0.0 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.396 1 + 0.997 value_non_contact[t] + 0.001 chosen + 0.002 sig_action + -0.441 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + -0.0 chosen + 0.001 sig_action + 0.0 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.003 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.002 value_scratch[t] + 0.0 chosen + 0.002 sig_action + -0.122 sig_grooming + -0.002 sig_non_contact + 0.003 sig_contact + -0.0 sig_scratch + -0.002 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + -0.003 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.002 value_waiting[t] + 0.001 chosen + -0.001 sig_action + 0.002 sig_grooming + 0.215 sig_non_contact + 0.0 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 113/1000 --- L(Train): 0.0296773 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.001 value_action[t] + 0.001 chosen + 0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 0.996 value_grooming[t] + 0.004 chosen + 0.001 sig_action + 0.008 sig_grooming + 0.0 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.396 1 + 0.997 value_non_contact[t] + 0.0 chosen + 0.003 sig_action + -0.441 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.003 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 0.999 value_contact[t] + 0.001 chosen + -0.0 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.003 prev_contact + 0.003 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + -0.001 chosen + 0.001 sig_action + -0.122 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.001 value_waiting[t] + -0.001 chosen + 0.0 sig_action + 0.001 sig_grooming + 0.215 sig_non_contact + 0.001 sig_contact + -0.003 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 114/1000 --- L(Train): 0.0294676 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.001 value_action[t] + 0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 0.997 value_grooming[t] + 0.003 chosen + 0.001 sig_action + 0.007 sig_grooming + -0.001 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.395 1 + 0.998 value_non_contact[t] + -0.001 chosen + 0.002 sig_action + -0.441 sig_grooming + 0.002 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + 0.001 chosen + -0.0 sig_action + -0.001 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.998 value_scratch[t] + -0.001 chosen + -0.002 sig_action + -0.121 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 0.999 value_waiting[t] + -0.001 chosen + 0.0 sig_action + -0.001 sig_grooming + 0.215 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + -0.0 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 115/1000 --- L(Train): 0.0292321 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.999 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 0.999 value_grooming[t] + 0.001 chosen + -0.0 sig_action + 0.006 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + 0.003 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.395 1 + 0.999 value_non_contact[t] + 0.0 chosen + 0.001 sig_action + -0.442 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.002 value_contact[t] + 0.0 chosen + 0.001 sig_action + -0.0 sig_grooming + 0.002 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.997 value_scratch[t] + 0.0 chosen + -0.003 sig_action + -0.121 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 0.999 value_waiting[t] + 0.0 chosen + -0.001 sig_action + -0.002 sig_grooming + 0.215 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 116/1000 --- L(Train): 0.0289910 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 0.999 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.002 value_grooming[t] + -0.0 chosen + -0.0 sig_action + 0.006 sig_grooming + -0.003 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.394 1 + 1.001 value_non_contact[t] + 0.001 chosen + -0.001 sig_action + -0.442 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.002 value_contact[t] + -0.002 chosen + 0.0 sig_action + 0.001 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.997 value_scratch[t] + -0.0 chosen + -0.002 sig_action + -0.121 sig_grooming + 0.004 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 0.999 value_waiting[t] + -0.0 chosen + -0.0 sig_action + -0.003 sig_grooming + 0.215 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + -0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 117/1000 --- L(Train): 0.0287870 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + -0.003 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.004 value_grooming[t] + 0.003 chosen + 0.001 sig_action + 0.005 sig_grooming + -0.002 sig_non_contact + 0.0 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_non_contact[t+1] = -0.394 1 + 1.0 value_non_contact[t] + 0.001 chosen + -0.001 sig_action + -0.442 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.002 value_contact[t] + -0.002 chosen + -0.001 sig_action + 0.0 sig_grooming + 0.002 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.998 value_scratch[t] + 0.001 chosen + -0.001 sig_action + -0.121 sig_grooming + 0.006 sig_non_contact + 0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.0 1 + 1.0 value_waiting[t] + 0.001 chosen + 0.001 sig_action + -0.003 sig_grooming + 0.215 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.003 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 118/1000 --- L(Train): 0.0285846 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.001 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + -0.003 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.004 value_grooming[t] + 0.005 chosen + 0.0 sig_action + 0.004 sig_grooming + -0.001 sig_non_contact + -0.002 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_non_contact[t+1] = -0.394 1 + 0.999 value_non_contact[t] + 0.001 chosen + -0.001 sig_action + -0.443 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + -0.002 chosen + -0.001 sig_action + -0.002 sig_grooming + 0.0 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + 0.001 chosen + 0.001 sig_action + -0.121 sig_grooming + 0.006 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.0 1 + 1.001 value_waiting[t] + 0.001 chosen + 0.001 sig_action + -0.002 sig_grooming + 0.216 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 119/1000 --- L(Train): 0.0283735 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.002 value_action[t] + -0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.003 value_grooming[t] + 0.007 chosen + -0.001 sig_action + 0.004 sig_grooming + 0.0 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.003 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.393 1 + 0.999 value_non_contact[t] + 0.001 chosen + 0.0 sig_action + -0.443 sig_grooming + -0.0 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 0.998 value_contact[t] + -0.001 chosen + 0.0 sig_action + -0.003 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.002 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + -0.001 chosen + 0.001 sig_action + -0.121 sig_grooming + 0.006 sig_non_contact + -0.0 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = -0.0 1 + 1.0 value_waiting[t] + -0.001 chosen + -0.0 sig_action + -0.001 sig_grooming + 0.216 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.003 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 120/1000 --- L(Train): 0.0281756 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.001 value_action[t] + -0.001 chosen + -0.0 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.0 1 + 1.001 value_grooming[t] + 0.009 chosen + -0.001 sig_action + 0.003 sig_grooming + -0.0 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.393 1 + 1.0 value_non_contact[t] + -0.0 chosen + 0.0 sig_action + -0.444 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 0.997 value_contact[t] + 0.002 chosen + -0.0 sig_action + -0.004 sig_grooming + -0.003 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + -0.002 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + -0.001 chosen + 0.001 sig_action + -0.121 sig_grooming + 0.005 sig_non_contact + -0.0 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.0 value_waiting[t] + -0.001 chosen + 0.0 sig_action + 0.001 sig_grooming + 0.216 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 121/1000 --- L(Train): 0.0279795 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.999 value_action[t] + -0.0 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = -0.0 1 + 0.999 value_grooming[t] + 0.011 chosen + -0.0 sig_action + 0.002 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.392 1 + 1.001 value_non_contact[t] + 0.001 chosen + -0.001 sig_action + -0.444 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 0.997 value_contact[t] + 0.003 chosen + 0.001 sig_action + -0.004 sig_grooming + -0.003 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + 0.0 chosen + -0.0 sig_action + -0.121 sig_grooming + 0.004 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.004 1 + 1.001 value_waiting[t] + 0.0 chosen + -0.001 sig_action + 0.001 sig_grooming + 0.216 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 122/1000 --- L(Train): 0.0277732 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 0.998 value_action[t] + 0.002 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 0.997 value_grooming[t] + 0.012 chosen + 0.002 sig_action + 0.001 sig_grooming + 0.0 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.392 1 + 0.999 value_non_contact[t] + 0.002 chosen + -0.0 sig_action + -0.444 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.035 1 + 0.998 value_contact[t] + 0.003 chosen + 0.001 sig_action + -0.003 sig_grooming + -0.003 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + -0.0 chosen + -0.0 sig_action + -0.12 sig_grooming + 0.003 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.006 1 + 1.001 value_waiting[t] + 0.0 chosen + -0.0 sig_action + -0.002 sig_grooming + 0.216 sig_non_contact + 0.002 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 123/1000 --- L(Train): 0.0276205 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.998 value_action[t] + 0.002 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.004 1 + 0.997 value_grooming[t] + 0.013 chosen + 0.002 sig_action + 0.0 sig_grooming + -0.001 sig_non_contact + 0.003 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.392 1 + 0.998 value_non_contact[t] + 0.002 chosen + 0.001 sig_action + -0.445 sig_grooming + 0.002 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + -0.003 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.034 1 + 1.0 value_contact[t] + 0.001 chosen + -0.001 sig_action + -0.002 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + 0.003 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.001 value_scratch[t] + 0.001 chosen + 0.001 sig_action + -0.12 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + -0.003 sig_scratch + 0.0 sig_waiting + 0.002 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.007 1 + 0.999 value_waiting[t] + -0.001 chosen + 0.001 sig_action + -0.003 sig_grooming + 0.216 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + 0.003 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 124/1000 --- L(Train): 0.0274334 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.999 value_action[t] + 0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 0.997 value_grooming[t] + 0.014 chosen + 0.002 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.391 1 + 0.998 value_non_contact[t] + 0.002 chosen + 0.001 sig_action + -0.445 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.033 1 + 1.002 value_contact[t] + -0.001 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.002 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 1.001 value_scratch[t] + 0.001 chosen + 0.0 sig_action + -0.12 sig_grooming + -0.002 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.0 sig_waiting + 0.002 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.008 1 + 0.999 value_waiting[t] + -0.001 chosen + 0.001 sig_action + -0.004 sig_grooming + 0.215 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 125/1000 --- L(Train): 0.0272550 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.001 value_action[t] + 0.001 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 0.999 value_grooming[t] + 0.014 chosen + 0.001 sig_action + 0.002 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.391 1 + 0.998 value_non_contact[t] + 0.002 chosen + -0.0 sig_action + -0.446 sig_grooming + 0.0 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.034 1 + 1.004 value_contact[t] + -0.001 chosen + 0.0 sig_action + 0.001 sig_grooming + 0.003 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 1.0 value_scratch[t] + -0.001 chosen + -0.001 sig_action + -0.12 sig_grooming + -0.002 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.009 1 + 1.0 value_waiting[t] + -0.0 chosen + -0.0 sig_action + -0.004 sig_grooming + 0.215 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 126/1000 --- L(Train): 0.0270422 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.001 value_action[t] + -0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 1.001 value_grooming[t] + 0.014 chosen + -0.002 sig_action + 0.005 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.391 1 + 0.999 value_non_contact[t] + 0.001 chosen + 0.0 sig_action + -0.446 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.035 1 + 1.004 value_contact[t] + -0.001 chosen + 0.0 sig_action + 0.002 sig_grooming + 0.003 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.998 value_scratch[t] + -0.001 chosen + -0.001 sig_action + -0.12 sig_grooming + -0.001 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + -0.002 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.009 1 + 1.0 value_waiting[t] + 0.002 chosen + 0.0 sig_action + -0.003 sig_grooming + 0.214 sig_non_contact + -0.002 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 127/1000 --- L(Train): 0.0268882 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + -0.003 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 1.002 value_grooming[t] + 0.014 chosen + -0.003 sig_action + 0.007 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + -0.003 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.391 1 + 1.0 value_non_contact[t] + -0.0 chosen + -0.001 sig_action + -0.446 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + -0.003 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.003 value_contact[t] + 0.0 chosen + -0.001 sig_action + 0.0 sig_grooming + 0.002 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.996 value_scratch[t] + 0.0 chosen + 0.0 sig_action + -0.12 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.003 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.008 1 + 1.0 value_waiting[t] + 0.002 chosen + -0.001 sig_action + -0.002 sig_grooming + 0.213 sig_non_contact + -0.003 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + 0.002 prev_contact + -0.003 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 128/1000 --- L(Train): 0.0267202 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 0.999 value_action[t] + -0.002 chosen + 0.002 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.004 1 + 1.002 value_grooming[t] + 0.013 chosen + -0.002 sig_action + 0.008 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.0 prev_non_contact + -0.003 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.39 1 + 0.999 value_non_contact[t] + 0.001 chosen + -0.001 sig_action + -0.447 sig_grooming + 0.003 sig_non_contact + -0.002 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + -0.003 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 1.002 value_contact[t] + 0.0 chosen + -0.001 sig_action + -0.003 sig_grooming + -0.0 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.996 value_scratch[t] + 0.0 chosen + 0.0 sig_action + -0.12 sig_grooming + 0.004 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.003 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.008 1 + 1.0 value_waiting[t] + 0.002 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.213 sig_non_contact + -0.003 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + 0.002 prev_contact + -0.003 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 129/1000 --- L(Train): 0.0265618 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.998 value_action[t] + -0.001 chosen + 0.003 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 1.001 value_grooming[t] + 0.012 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.0 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.39 1 + 0.998 value_non_contact[t] + 0.001 chosen + 0.001 sig_action + -0.447 sig_grooming + 0.005 sig_non_contact + -0.003 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.041 1 + 0.999 value_contact[t] + -0.001 chosen + -0.0 sig_action + -0.005 sig_grooming + -0.001 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.003 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.996 value_scratch[t] + -0.001 chosen + -0.001 sig_action + -0.12 sig_grooming + 0.005 sig_non_contact + 0.003 sig_contact + -0.0 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.007 1 + 1.0 value_waiting[t] + 0.001 chosen + 0.001 sig_action + 0.001 sig_grooming + 0.212 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 130/1000 --- L(Train): 0.0263707 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.998 value_action[t] + 0.001 chosen + 0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 0.999 value_grooming[t] + 0.011 chosen + 0.001 sig_action + 0.009 sig_grooming + 0.0 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.39 1 + 0.998 value_non_contact[t] + 0.001 chosen + 0.001 sig_action + -0.448 sig_grooming + 0.006 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.042 1 + 0.998 value_contact[t] + -0.0 chosen + 0.002 sig_action + -0.006 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.003 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.997 value_scratch[t] + -0.001 chosen + -0.001 sig_action + -0.12 sig_grooming + 0.005 sig_non_contact + 0.003 sig_contact + -0.0 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.006 1 + 1.0 value_waiting[t] + -0.002 chosen + 0.001 sig_action + 0.001 sig_grooming + 0.211 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 131/1000 --- L(Train): 0.0261820 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.999 value_action[t] + 0.001 chosen + 0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = -0.001 1 + 0.998 value_grooming[t] + 0.01 chosen + 0.001 sig_action + 0.009 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.39 1 + 0.999 value_non_contact[t] + 0.001 chosen + -0.0 sig_action + -0.448 sig_grooming + 0.007 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.041 1 + 0.998 value_contact[t] + 0.001 chosen + 0.002 sig_action + -0.006 sig_grooming + 0.0 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.999 value_scratch[t] + -0.0 chosen + -0.0 sig_action + -0.12 sig_grooming + 0.005 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.003 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.005 1 + 1.0 value_waiting[t] + -0.003 chosen + -0.0 sig_action + -0.002 sig_grooming + 0.21 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + -0.0 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + -0.003 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 132/1000 --- L(Train): 0.0260165 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.001 value_action[t] + 0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = -0.0 1 + 0.998 value_grooming[t] + 0.009 chosen + 0.001 sig_action + 0.009 sig_grooming + -0.002 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.389 1 + 1.0 value_non_contact[t] + -0.0 chosen + -0.0 sig_action + -0.449 sig_grooming + 0.008 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 0.999 value_contact[t] + 0.001 chosen + 0.002 sig_action + -0.006 sig_grooming + 0.0 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 1.001 value_scratch[t] + 0.002 chosen + 0.002 sig_action + -0.12 sig_grooming + 0.005 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.003 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.004 1 + 1.0 value_waiting[t] + -0.002 chosen + 0.0 sig_action + -0.003 sig_grooming + 0.209 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + -0.003 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 133/1000 --- L(Train): 0.0258378 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.002 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 0.999 value_grooming[t] + 0.007 chosen + -0.0 sig_action + 0.009 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.389 1 + 1.001 value_non_contact[t] + 0.001 chosen + 0.001 sig_action + -0.449 sig_grooming + 0.007 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + -0.003 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.003 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 1.001 value_contact[t] + -0.0 chosen + 0.001 sig_action + -0.005 sig_grooming + -0.001 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 1.002 value_scratch[t] + 0.002 chosen + 0.002 sig_action + -0.12 sig_grooming + 0.003 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 1.0 value_waiting[t] + -0.001 chosen + -0.001 sig_action + -0.004 sig_grooming + 0.209 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 134/1000 --- L(Train): 0.0256694 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 1.001 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 1.0 value_grooming[t] + 0.006 chosen + -0.0 sig_action + 0.008 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.389 1 + 1.0 value_non_contact[t] + 0.002 chosen + 0.001 sig_action + -0.45 sig_grooming + 0.007 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + -0.003 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.034 1 + 1.001 value_contact[t] + 0.0 chosen + -0.002 sig_action + -0.004 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 1.002 value_scratch[t] + 0.002 chosen + 0.002 sig_action + -0.12 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 1.001 value_waiting[t] + 0.001 chosen + -0.001 sig_action + -0.004 sig_grooming + 0.208 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 135/1000 --- L(Train): 0.0255162 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.999 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + -0.003 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.007 1 + 1.001 value_grooming[t] + 0.004 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.0 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.389 1 + 0.997 value_non_contact[t] + 0.002 chosen + 0.0 sig_action + -0.45 sig_grooming + 0.006 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.032 1 + 1.001 value_contact[t] + -0.001 chosen + -0.003 sig_action + -0.002 sig_grooming + 0.0 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 1.0 value_scratch[t] + 0.001 chosen + 0.001 sig_action + -0.12 sig_grooming + -0.0 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.001 value_waiting[t] + 0.001 chosen + 0.001 sig_action + -0.003 sig_grooming + 0.208 sig_non_contact + 0.0 sig_contact + -0.0 sig_scratch + -0.003 sig_waiting + 0.001 prev_action + 0.003 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 136/1000 --- L(Train): 0.0253414 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.999 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.008 1 + 1.0 value_grooming[t] + 0.002 chosen + 0.0 sig_action + 0.007 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.389 1 + 0.996 value_non_contact[t] + 0.001 chosen + -0.002 sig_action + -0.45 sig_grooming + 0.004 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.032 1 + 1.0 value_contact[t] + -0.0 chosen + -0.002 sig_action + 0.001 sig_grooming + 0.0 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.997 value_scratch[t] + -0.002 chosen + -0.002 sig_action + -0.12 sig_grooming + -0.0 sig_non_contact + 0.0 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.0 value_waiting[t] + 0.001 chosen + 0.001 sig_action + -0.002 sig_grooming + 0.208 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + 0.002 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 137/1000 --- L(Train): 0.0251917 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.999 value_action[t] + -0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.009 1 + 0.999 value_grooming[t] + 0.0 chosen + -0.001 sig_action + 0.006 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.389 1 + 0.994 value_non_contact[t] + 0.0 chosen + -0.002 sig_action + -0.451 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.032 1 + 0.999 value_contact[t] + 0.001 chosen + -0.001 sig_action + 0.001 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.996 value_scratch[t] + -0.003 chosen + -0.003 sig_action + -0.12 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 0.998 value_waiting[t] + -0.0 chosen + -0.0 sig_action + -0.0 sig_grooming + 0.208 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 138/1000 --- L(Train): 0.0250643 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + -0.001 chosen + -0.0 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.009 1 + 0.998 value_grooming[t] + -0.001 chosen + -0.001 sig_action + 0.005 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.389 1 + 0.994 value_non_contact[t] + -0.001 chosen + -0.002 sig_action + -0.451 sig_grooming + 0.0 sig_non_contact + 0.0 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.034 1 + 1.0 value_contact[t] + 0.001 chosen + 0.001 sig_action + -0.0 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.995 value_scratch[t] + -0.002 chosen + -0.002 sig_action + -0.12 sig_grooming + 0.002 sig_non_contact + -0.0 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 0.997 value_waiting[t] + -0.0 chosen + -0.0 sig_action + 0.002 sig_grooming + 0.209 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 139/1000 --- L(Train): 0.0249091 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.002 value_action[t] + -0.0 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + 0.003 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.008 1 + 0.999 value_grooming[t] + 0.001 chosen + -0.0 sig_action + 0.004 sig_grooming + -0.003 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.388 1 + 0.994 value_non_contact[t] + -0.0 chosen + -0.001 sig_action + -0.452 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + -0.002 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 1.0 value_contact[t] + -0.0 chosen + 0.001 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.995 value_scratch[t] + -0.001 chosen + -0.001 sig_action + -0.12 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.003 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 0.998 value_waiting[t] + 0.001 chosen + 0.001 sig_action + 0.002 sig_grooming + 0.209 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 140/1000 --- L(Train): 0.0247365 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 1.002 value_action[t] + 0.002 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.0 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.008 1 + 1.0 value_grooming[t] + 0.003 chosen + 0.002 sig_action + 0.002 sig_grooming + -0.004 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + -0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.388 1 + 0.994 value_non_contact[t] + 0.003 chosen + 0.002 sig_action + -0.452 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.002 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 0.999 value_contact[t] + 0.0 chosen + 0.001 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.996 value_scratch[t] + 0.001 chosen + 0.001 sig_action + -0.12 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 0.999 value_waiting[t] + 0.0 chosen + 0.001 sig_action + -0.0 sig_grooming + 0.21 sig_non_contact + 0.002 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 141/1000 --- L(Train): 0.0246339 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.002 value_action[t] + 0.002 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.007 1 + 1.0 value_grooming[t] + 0.005 chosen + 0.002 sig_action + 0.001 sig_grooming + -0.004 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.388 1 + 0.995 value_non_contact[t] + 0.005 chosen + 0.003 sig_action + -0.453 sig_grooming + -0.0 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + 0.002 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.003 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 0.999 value_contact[t] + -0.001 chosen + -0.0 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.003 prev_contact + 0.003 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.997 value_scratch[t] + 0.001 chosen + 0.001 sig_action + -0.12 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + 0.003 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 1.001 value_waiting[t] + -0.001 chosen + 0.0 sig_action + -0.001 sig_grooming + 0.21 sig_non_contact + 0.002 sig_contact + -0.003 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 142/1000 --- L(Train): 0.0245007 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + 0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 0.999 value_grooming[t] + 0.006 chosen + 0.002 sig_action + -0.0 sig_grooming + -0.004 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.388 1 + 0.997 value_non_contact[t] + 0.006 chosen + 0.002 sig_action + -0.453 sig_grooming + 0.003 sig_non_contact + -0.0 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + 0.002 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + -0.002 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.042 1 + 1.0 value_contact[t] + -0.001 chosen + -0.0 sig_action + 0.001 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.241 1 + 1.0 value_scratch[t] + 0.001 chosen + 0.001 sig_action + -0.12 sig_grooming + -0.0 sig_non_contact + -0.002 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.001 value_waiting[t] + -0.001 chosen + -0.002 sig_action + -0.002 sig_grooming + 0.211 sig_non_contact + 0.002 sig_contact + -0.002 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 143/1000 --- L(Train): 0.0243648 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.998 value_action[t] + 0.001 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 0.999 value_grooming[t] + 0.008 chosen + 0.001 sig_action + 0.003 sig_grooming + -0.003 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.388 1 + 0.998 value_non_contact[t] + 0.007 chosen + 0.001 sig_action + -0.453 sig_grooming + 0.006 sig_non_contact + 0.001 sig_contact + 0.003 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.042 1 + 1.001 value_contact[t] + 0.001 chosen + 0.001 sig_action + 0.0 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 1.002 value_scratch[t] + -0.0 chosen + -0.0 sig_action + -0.12 sig_grooming + 0.0 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.001 value_waiting[t] + 0.0 chosen + -0.002 sig_action + -0.002 sig_grooming + 0.212 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.003 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 144/1000 --- L(Train): 0.0241940 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.996 value_action[t] + -0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.004 1 + 1.001 value_grooming[t] + 0.009 chosen + -0.002 sig_action + 0.006 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.388 1 + 1.0 value_non_contact[t] + 0.007 chosen + -0.001 sig_action + -0.454 sig_grooming + 0.008 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.042 1 + 1.002 value_contact[t] + 0.001 chosen + 0.0 sig_action + -0.002 sig_grooming + -0.001 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 1.004 value_scratch[t] + -0.0 chosen + -0.0 sig_action + -0.12 sig_grooming + 0.0 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 0.999 value_waiting[t] + -0.0 chosen + -0.002 sig_action + -0.001 sig_grooming + 0.212 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.003 prev_non_contact + -0.0 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 145/1000 --- L(Train): 0.0240839 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.996 value_action[t] + -0.003 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 1.0 value_grooming[t] + 0.009 chosen + -0.003 sig_action + 0.008 sig_grooming + 0.0 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + -0.003 prev_contact + -0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.388 1 + 1.001 value_non_contact[t] + 0.006 chosen + -0.001 sig_action + -0.454 sig_grooming + 0.009 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.003 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.041 1 + 1.002 value_contact[t] + -0.0 chosen + -0.001 sig_action + -0.003 sig_grooming + -0.001 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 1.003 value_scratch[t] + 0.001 chosen + 0.001 sig_action + -0.12 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + -0.003 prev_action + -0.0 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 0.999 value_waiting[t] + 0.001 chosen + -0.001 sig_action + 0.001 sig_grooming + 0.213 sig_non_contact + -0.003 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + -0.003 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 146/1000 --- L(Train): 0.0239643 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 0.996 value_action[t] + -0.002 chosen + 0.002 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 0.999 value_grooming[t] + 0.009 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.0 sig_non_contact + -0.002 sig_contact + 0.0 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + -0.003 prev_contact + -0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.388 1 + 0.999 value_non_contact[t] + 0.005 chosen + -0.001 sig_action + -0.455 sig_grooming + 0.01 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + -0.003 prev_action + 0.002 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + -0.0 chosen + -0.001 sig_action + -0.004 sig_grooming + 0.001 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 1.002 value_scratch[t] + 0.0 chosen + 0.0 sig_action + -0.12 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + -0.003 prev_action + -0.0 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.0 value_waiting[t] + 0.001 chosen + 0.002 sig_action + -0.0 sig_grooming + 0.214 sig_non_contact + -0.003 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.003 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 147/1000 --- L(Train): 0.0238475 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.997 value_action[t] + -0.001 chosen + 0.003 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + 0.003 prev_waiting \n",
            "value_grooming[t+1] = -0.001 1 + 0.999 value_grooming[t] + 0.009 chosen + -0.001 sig_action + 0.011 sig_grooming + 0.0 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.388 1 + 0.998 value_non_contact[t] + 0.004 chosen + 0.0 sig_action + -0.455 sig_grooming + 0.01 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 0.998 value_contact[t] + 0.001 chosen + 0.0 sig_action + -0.003 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.003 sig_waiting + -0.002 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.999 value_scratch[t] + -0.001 chosen + -0.001 sig_action + -0.12 sig_grooming + 0.001 sig_non_contact + 0.003 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.001 value_waiting[t] + -0.001 chosen + 0.003 sig_action + -0.0 sig_grooming + 0.214 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.002 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 148/1000 --- L(Train): 0.0236992 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.999 value_action[t] + 0.001 chosen + 0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = -0.0 1 + 1.0 value_grooming[t] + 0.009 chosen + 0.001 sig_action + 0.011 sig_grooming + -0.001 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.388 1 + 0.997 value_non_contact[t] + 0.002 chosen + 0.0 sig_action + -0.455 sig_grooming + 0.009 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.035 1 + 0.997 value_contact[t] + 0.001 chosen + -0.0 sig_action + -0.003 sig_grooming + 0.0 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.003 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.998 value_scratch[t] + -0.001 chosen + -0.001 sig_action + -0.12 sig_grooming + 0.001 sig_non_contact + 0.003 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.001 value_waiting[t] + -0.001 chosen + 0.003 sig_action + 0.0 sig_grooming + 0.215 sig_non_contact + 0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 149/1000 --- L(Train): 0.0235449 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.002 value_action[t] + 0.001 chosen + 0.001 sig_action + 0.009 sig_grooming + -0.018 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 1.002 value_grooming[t] + 0.009 chosen + 0.001 sig_action + 0.012 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.003 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.388 1 + 0.998 value_non_contact[t] + -0.001 chosen + -0.001 sig_action + -0.456 sig_grooming + 0.008 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.034 1 + 0.997 value_contact[t] + 0.0 chosen + 0.001 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.997 value_scratch[t] + 0.0 chosen + 0.0 sig_action + -0.12 sig_grooming + 0.0 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.001 value_waiting[t] + 0.0 chosen + 0.001 sig_action + -0.001 sig_grooming + 0.215 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 150/1000 --- L(Train): 0.0234182 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.003 value_action[t] + 0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.018 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 1.002 value_grooming[t] + 0.008 chosen + 0.001 sig_action + 0.012 sig_grooming + -0.002 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.388 1 + 0.998 value_non_contact[t] + -0.001 chosen + -0.0 sig_action + -0.456 sig_grooming + 0.006 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.033 1 + 0.998 value_contact[t] + -0.002 chosen + 0.001 sig_action + 0.001 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.997 value_scratch[t] + -0.0 chosen + 0.0 sig_action + -0.12 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 0.999 value_waiting[t] + -0.0 chosen + -0.001 sig_action + -0.002 sig_grooming + 0.216 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 151/1000 --- L(Train): 0.0232897 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.004 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.002 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.007 1 + 1.001 value_grooming[t] + 0.007 chosen + -0.0 sig_action + 0.012 sig_grooming + -0.001 sig_non_contact + 0.003 sig_contact + 0.002 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.388 1 + 0.999 value_non_contact[t] + 0.001 chosen + 0.001 sig_action + -0.456 sig_grooming + 0.004 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.003 sig_waiting + -0.0 prev_action + -0.003 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.033 1 + 1.0 value_contact[t] + -0.002 chosen + -0.001 sig_action + 0.0 sig_grooming + -0.001 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.003 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.998 value_scratch[t] + 0.001 chosen + -0.001 sig_action + -0.12 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 0.998 value_waiting[t] + 0.001 chosen + -0.001 sig_action + -0.002 sig_grooming + 0.216 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 152/1000 --- L(Train): 0.0231725 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 1.002 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.007 1 + 1.0 value_grooming[t] + 0.006 chosen + -0.0 sig_action + 0.011 sig_grooming + -0.0 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.388 1 + 1.001 value_non_contact[t] + 0.002 chosen + 0.001 sig_action + -0.457 sig_grooming + 0.002 sig_non_contact + 0.002 sig_contact + -0.0 sig_scratch + -0.003 sig_waiting + -0.0 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.035 1 + 1.001 value_contact[t] + -0.002 chosen + -0.001 sig_action + -0.001 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 1.0 value_scratch[t] + 0.001 chosen + -0.001 sig_action + -0.12 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 0.998 value_waiting[t] + 0.001 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.216 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 153/1000 --- L(Train): 0.0230602 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.007 1 + 0.999 value_grooming[t] + 0.004 chosen + 0.001 sig_action + 0.01 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_non_contact[t+1] = -0.387 1 + 1.001 value_non_contact[t] + 0.003 chosen + -0.0 sig_action + -0.457 sig_grooming + -0.0 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 1.001 value_contact[t] + -0.001 chosen + 0.0 sig_action + -0.002 sig_grooming + 0.002 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.002 value_scratch[t] + -0.001 chosen + -0.0 sig_action + -0.12 sig_grooming + -0.0 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 1.0 value_waiting[t] + -0.001 chosen + 0.0 sig_action + -0.0 sig_grooming + 0.216 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.003 prev_action + 0.003 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 154/1000 --- L(Train): 0.0229144 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.997 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.007 1 + 1.0 value_grooming[t] + 0.002 chosen + 0.0 sig_action + 0.009 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_non_contact[t+1] = -0.387 1 + 0.998 value_non_contact[t] + 0.003 chosen + 0.0 sig_action + -0.457 sig_grooming + -0.0 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 0.999 value_contact[t] + 0.002 chosen + 0.0 sig_action + -0.003 sig_grooming + 0.003 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + -0.002 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.003 value_scratch[t] + -0.001 chosen + 0.002 sig_action + -0.12 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 1.002 value_waiting[t] + -0.001 chosen + 0.0 sig_action + 0.002 sig_grooming + 0.216 sig_non_contact + 0.0 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 155/1000 --- L(Train): 0.0227991 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.995 value_action[t] + -0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 1.001 value_grooming[t] + 0.001 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.387 1 + 0.996 value_non_contact[t] + 0.003 chosen + -0.001 sig_action + -0.458 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.003 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 0.999 value_contact[t] + 0.003 chosen + -0.001 sig_action + -0.002 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.003 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.002 value_scratch[t] + 0.0 chosen + 0.002 sig_action + -0.12 sig_grooming + 0.002 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.0 1 + 1.002 value_waiting[t] + 0.0 chosen + -0.001 sig_action + 0.001 sig_grooming + 0.217 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 156/1000 --- L(Train): 0.0227195 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.995 value_action[t] + -0.001 chosen + -0.0 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 1.001 value_grooming[t] + -0.001 chosen + -0.001 sig_action + 0.007 sig_grooming + -0.003 sig_non_contact + -0.001 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.387 1 + 0.995 value_non_contact[t] + 0.002 chosen + -0.001 sig_action + -0.458 sig_grooming + 0.003 sig_non_contact + -0.002 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.041 1 + 1.0 value_contact[t] + 0.003 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.003 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + -0.0 chosen + 0.002 sig_action + -0.12 sig_grooming + 0.002 sig_non_contact + -0.0 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = -0.0 1 + 1.002 value_waiting[t] + 0.0 chosen + -0.0 sig_action + -0.001 sig_grooming + 0.217 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 157/1000 --- L(Train): 0.0226004 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.995 value_action[t] + -0.0 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.004 1 + 1.0 value_grooming[t] + 0.001 chosen + -0.0 sig_action + 0.006 sig_grooming + -0.004 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.387 1 + 0.995 value_non_contact[t] + 0.001 chosen + 0.001 sig_action + -0.458 sig_grooming + 0.003 sig_non_contact + -0.003 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.041 1 + 1.0 value_contact[t] + 0.001 chosen + -0.0 sig_action + 0.0 sig_grooming + -0.001 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.997 value_scratch[t] + 0.001 chosen + 0.001 sig_action + -0.12 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.001 value_waiting[t] + -0.001 chosen + 0.001 sig_action + -0.003 sig_grooming + 0.217 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 158/1000 --- L(Train): 0.0224622 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 0.996 value_action[t] + 0.002 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 0.998 value_grooming[t] + 0.004 chosen + 0.002 sig_action + 0.004 sig_grooming + -0.004 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.387 1 + 0.995 value_non_contact[t] + -0.001 chosen + 0.001 sig_action + -0.458 sig_grooming + 0.003 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.041 1 + 0.999 value_contact[t] + -0.001 chosen + 0.002 sig_action + -0.0 sig_grooming + -0.002 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.996 value_scratch[t] + 0.001 chosen + -0.002 sig_action + -0.12 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + -0.003 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.004 1 + 0.998 value_waiting[t] + -0.001 chosen + 0.001 sig_action + -0.003 sig_grooming + 0.217 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 159/1000 --- L(Train): 0.0224018 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.998 value_action[t] + 0.002 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 0.997 value_grooming[t] + 0.005 chosen + 0.002 sig_action + 0.003 sig_grooming + -0.004 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.387 1 + 0.995 value_non_contact[t] + -0.0 chosen + -0.0 sig_action + -0.459 sig_grooming + 0.003 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 0.999 value_contact[t] + -0.001 chosen + 0.002 sig_action + 0.0 sig_grooming + -0.002 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.995 value_scratch[t] + -0.001 chosen + -0.003 sig_action + -0.12 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.006 1 + 0.997 value_waiting[t] + -0.0 chosen + -0.0 sig_action + -0.003 sig_grooming + 0.217 sig_non_contact + 0.002 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 160/1000 --- L(Train): 0.0223061 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + 0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.018 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.0 1 + 0.998 value_grooming[t] + 0.007 chosen + 0.002 sig_action + 0.002 sig_grooming + -0.003 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.387 1 + 0.997 value_non_contact[t] + 0.002 chosen + -0.0 sig_action + -0.459 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + 0.002 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + -0.001 chosen + 0.002 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + -0.0 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.995 value_scratch[t] + -0.001 chosen + -0.002 sig_action + -0.12 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.007 1 + 0.997 value_waiting[t] + 0.002 chosen + 0.0 sig_action + -0.003 sig_grooming + 0.216 sig_non_contact + 0.002 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 161/1000 --- L(Train): 0.0222050 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.001 value_action[t] + 0.001 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.018 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = -0.001 1 + 0.999 value_grooming[t] + 0.009 chosen + 0.001 sig_action + 0.001 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.386 1 + 0.998 value_non_contact[t] + 0.004 chosen + 0.001 sig_action + -0.459 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.002 value_contact[t] + 0.0 chosen + 0.001 sig_action + -0.002 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.995 value_scratch[t] + 0.0 chosen + -0.001 sig_action + -0.12 sig_grooming + 0.0 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + -0.003 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.008 1 + 0.998 value_waiting[t] + 0.002 chosen + -0.001 sig_action + -0.002 sig_grooming + 0.216 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 162/1000 --- L(Train): 0.0220662 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.001 value_action[t] + -0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.018 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.001 value_grooming[t] + 0.01 chosen + -0.002 sig_action + -0.0 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + -0.002 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.386 1 + 1.0 value_non_contact[t] + 0.005 chosen + 0.001 sig_action + -0.46 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 1.002 value_contact[t] + 0.0 chosen + -0.002 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.997 value_scratch[t] + 0.0 chosen + 0.001 sig_action + -0.121 sig_grooming + -0.001 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.002 prev_action + 0.002 prev_grooming + -0.003 prev_non_contact + -0.0 prev_contact + -0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.009 1 + 1.0 value_waiting[t] + 0.002 chosen + -0.0 sig_action + 0.0 sig_grooming + 0.215 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 163/1000 --- L(Train): 0.0219901 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + -0.003 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 1.002 value_grooming[t] + 0.011 chosen + -0.003 sig_action + 0.003 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + -0.003 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.386 1 + 1.002 value_non_contact[t] + 0.005 chosen + 0.0 sig_action + -0.46 sig_grooming + -0.001 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.003 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.035 1 + 1.002 value_contact[t] + -0.001 chosen + -0.003 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + -0.001 chosen + 0.001 sig_action + -0.121 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + -0.003 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + -0.003 prev_scratch + -0.003 prev_waiting \n",
            "value_waiting[t+1] = 0.008 1 + 1.002 value_waiting[t] + 0.001 chosen + 0.001 sig_action + -0.001 sig_grooming + 0.214 sig_non_contact + -0.003 sig_contact + -0.0 sig_scratch + -0.003 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 164/1000 --- L(Train): 0.0219098 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 0.998 value_action[t] + -0.002 chosen + 0.002 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.0 prev_non_contact + -0.002 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.004 1 + 1.001 value_grooming[t] + 0.011 chosen + -0.002 sig_action + 0.006 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.002 prev_non_contact + -0.003 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.386 1 + 1.002 value_non_contact[t] + 0.005 chosen + -0.002 sig_action + -0.46 sig_grooming + 0.002 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.003 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.035 1 + 1.001 value_contact[t] + -0.0 chosen + -0.002 sig_action + 0.0 sig_grooming + -0.0 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.002 value_scratch[t] + -0.001 chosen + 0.001 sig_action + -0.121 sig_grooming + 0.002 sig_non_contact + 0.002 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + -0.003 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.008 1 + 1.004 value_waiting[t] + -0.002 chosen + 0.001 sig_action + -0.001 sig_grooming + 0.213 sig_non_contact + -0.003 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 165/1000 --- L(Train): 0.0218284 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.997 value_action[t] + -0.001 chosen + 0.003 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + 0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.004 1 + 1.0 value_grooming[t] + 0.012 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.003 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.386 1 + 1.0 value_non_contact[t] + 0.005 chosen + -0.002 sig_action + -0.46 sig_grooming + 0.004 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 0.998 value_contact[t] + 0.001 chosen + -0.001 sig_action + -0.0 sig_grooming + -0.001 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.003 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.003 value_scratch[t] + -0.0 chosen + -0.0 sig_action + -0.121 sig_grooming + 0.004 sig_non_contact + 0.003 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.007 1 + 1.004 value_waiting[t] + -0.003 chosen + -0.0 sig_action + -0.0 sig_grooming + 0.212 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + 0.003 prev_non_contact + -0.0 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 166/1000 --- L(Train): 0.0217020 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.997 value_action[t] + 0.001 chosen + 0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.004 1 + 0.999 value_grooming[t] + 0.012 chosen + 0.001 sig_action + 0.01 sig_grooming + -0.003 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.003 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.386 1 + 0.996 value_non_contact[t] + 0.004 chosen + -0.002 sig_action + -0.46 sig_grooming + 0.005 sig_non_contact + 0.0 sig_contact + -0.002 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 0.997 value_contact[t] + 0.001 chosen + 0.001 sig_action + -0.0 sig_grooming + -0.0 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.003 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.003 value_scratch[t] + 0.002 chosen + -0.0 sig_action + -0.121 sig_grooming + 0.005 sig_non_contact + 0.003 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.006 1 + 1.003 value_waiting[t] + -0.002 chosen + 0.0 sig_action + 0.001 sig_grooming + 0.211 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + 0.002 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 167/1000 --- L(Train): 0.0215881 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.997 value_action[t] + 0.001 chosen + 0.001 sig_action + 0.009 sig_grooming + -0.018 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.003 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.004 1 + 1.0 value_grooming[t] + 0.012 chosen + 0.001 sig_action + 0.011 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.385 1 + 0.994 value_non_contact[t] + 0.002 chosen + -0.001 sig_action + -0.461 sig_grooming + 0.005 sig_non_contact + -0.001 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 0.998 value_contact[t] + -0.0 chosen + 0.001 sig_action + 0.001 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.001 value_scratch[t] + 0.002 chosen + 0.001 sig_action + -0.121 sig_grooming + 0.005 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.005 1 + 1.001 value_waiting[t] + -0.001 chosen + -0.001 sig_action + -0.0 sig_grooming + 0.21 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 168/1000 --- L(Train): 0.0215027 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.999 value_action[t] + 0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 1.001 value_grooming[t] + 0.011 chosen + 0.001 sig_action + 0.011 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.385 1 + 0.992 value_non_contact[t] + 0.001 chosen + 0.002 sig_action + -0.461 sig_grooming + 0.005 sig_non_contact + -0.001 sig_contact + -0.002 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 0.999 value_contact[t] + 0.0 chosen + 0.001 sig_action + -0.001 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + 0.002 chosen + 0.0 sig_action + -0.121 sig_grooming + 0.004 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.004 1 + 0.998 value_waiting[t] + 0.001 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.21 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 169/1000 --- L(Train): 0.0213991 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.001 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.002 value_grooming[t] + 0.01 chosen + -0.0 sig_action + 0.012 sig_grooming + -0.0 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.385 1 + 0.991 value_non_contact[t] + -0.002 chosen + 0.003 sig_action + -0.461 sig_grooming + 0.004 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.003 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 1.001 value_contact[t] + -0.001 chosen + -0.0 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.003 prev_contact + 0.003 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.997 value_scratch[t] + 0.001 chosen + -0.001 sig_action + -0.121 sig_grooming + 0.003 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 0.996 value_waiting[t] + 0.001 chosen + 0.001 sig_action + -0.0 sig_grooming + 0.209 sig_non_contact + -0.0 sig_contact + -0.003 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 170/1000 --- L(Train): 0.0212986 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 1.002 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = -0.001 1 + 1.001 value_grooming[t] + 0.009 chosen + -0.0 sig_action + 0.011 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.385 1 + 0.99 value_non_contact[t] + -0.002 chosen + 0.002 sig_action + -0.461 sig_grooming + 0.003 sig_non_contact + -0.0 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.041 1 + 1.001 value_contact[t] + -0.0 chosen + -0.0 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.997 value_scratch[t] + -0.002 chosen + -0.001 sig_action + -0.121 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 0.996 value_waiting[t] + 0.001 chosen + 0.001 sig_action + 0.0 sig_grooming + 0.208 sig_non_contact + -0.0 sig_contact + -0.002 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + -0.002 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 171/1000 --- L(Train): 0.0212189 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.002 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.0 1 + 0.999 value_grooming[t] + 0.007 chosen + 0.001 sig_action + 0.011 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.385 1 + 0.99 value_non_contact[t] + 0.0 chosen + 0.001 sig_action + -0.462 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.003 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.041 1 + 1.001 value_contact[t] + 0.001 chosen + 0.001 sig_action + 0.0 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.997 value_scratch[t] + -0.003 chosen + 0.0 sig_action + -0.121 sig_grooming + 0.0 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.003 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 0.996 value_waiting[t] + -0.0 chosen + -0.0 sig_action + -0.001 sig_grooming + 0.208 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.003 prev_grooming + -0.001 prev_non_contact + -0.003 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 172/1000 --- L(Train): 0.0211156 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 0.998 value_grooming[t] + 0.006 chosen + 0.0 sig_action + 0.01 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.385 1 + 0.991 value_non_contact[t] + 0.001 chosen + -0.001 sig_action + -0.462 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 1.0 value_contact[t] + 0.001 chosen + 0.0 sig_action + -0.0 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.998 value_scratch[t] + -0.002 chosen + 0.0 sig_action + -0.121 sig_grooming + -0.002 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.003 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.0 1 + 0.998 value_waiting[t] + -0.0 chosen + 0.0 sig_action + -0.001 sig_grooming + 0.208 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.003 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 173/1000 --- L(Train): 0.0210266 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.998 value_action[t] + -0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 0.999 value_grooming[t] + 0.004 chosen + -0.001 sig_action + 0.01 sig_grooming + -0.002 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.385 1 + 0.992 value_non_contact[t] + 0.002 chosen + -0.001 sig_action + -0.462 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + -0.0 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + -0.001 chosen + -0.001 sig_action + -0.121 sig_grooming + -0.002 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.0 1 + 1.0 value_waiting[t] + 0.001 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.208 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 174/1000 --- L(Train): 0.0209652 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.997 value_action[t] + -0.001 chosen + -0.0 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + -0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.0 value_grooming[t] + 0.003 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.002 sig_non_contact + -0.002 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.384 1 + 0.994 value_non_contact[t] + 0.001 chosen + -0.001 sig_action + -0.462 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.001 value_contact[t] + 0.0 chosen + -0.001 sig_action + -0.0 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.002 value_scratch[t] + 0.001 chosen + -0.001 sig_action + -0.121 sig_grooming + -0.001 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = -0.0 1 + 1.003 value_waiting[t] + 0.0 chosen + -0.001 sig_action + -0.0 sig_grooming + 0.209 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 175/1000 --- L(Train): 0.0208769 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.997 value_action[t] + -0.0 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.002 value_grooming[t] + 0.001 chosen + -0.0 sig_action + 0.008 sig_grooming + -0.002 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.384 1 + 0.996 value_non_contact[t] + 0.001 chosen + 0.0 sig_action + -0.462 sig_grooming + 0.002 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.001 value_contact[t] + -0.001 chosen + 0.0 sig_action + 0.001 sig_grooming + -0.0 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.003 value_scratch[t] + 0.001 chosen + -0.0 sig_action + -0.121 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + -0.003 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 1.004 value_waiting[t] + -0.001 chosen + 0.001 sig_action + 0.001 sig_grooming + 0.209 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 176/1000 --- L(Train): 0.0207688 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 0.997 value_action[t] + 0.002 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.003 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.0 1 + 1.003 value_grooming[t] + -0.0 chosen + 0.002 sig_action + 0.007 sig_grooming + -0.002 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.384 1 + 0.998 value_non_contact[t] + -0.0 chosen + 0.0 sig_action + -0.463 sig_grooming + 0.003 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 0.999 value_contact[t] + -0.001 chosen + -0.0 sig_action + 0.0 sig_grooming + 0.0 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.002 value_scratch[t] + 0.001 chosen + 0.002 sig_action + -0.121 sig_grooming + 0.004 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.006 1 + 1.004 value_waiting[t] + -0.001 chosen + 0.001 sig_action + 0.0 sig_grooming + 0.21 sig_non_contact + 0.002 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 177/1000 --- L(Train): 0.0207359 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.999 value_action[t] + 0.002 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.0 1 + 1.002 value_grooming[t] + 0.003 chosen + 0.002 sig_action + 0.006 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + -0.002 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + 0.002 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.384 1 + 1.001 value_non_contact[t] + 0.001 chosen + -0.001 sig_action + -0.463 sig_grooming + 0.003 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.003 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + 0.003 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 0.999 value_contact[t] + 0.001 chosen + 0.001 sig_action + -0.002 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + -0.0 chosen + 0.002 sig_action + -0.121 sig_grooming + 0.005 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.008 1 + 1.004 value_waiting[t] + 0.0 chosen + -0.0 sig_action + -0.002 sig_grooming + 0.211 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + -0.003 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 178/1000 --- L(Train): 0.0206660 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.001 value_action[t] + 0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = -0.0 1 + 1.001 value_grooming[t] + 0.005 chosen + 0.002 sig_action + 0.006 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + -0.002 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.384 1 + 1.002 value_non_contact[t] + 0.001 chosen + -0.0 sig_action + -0.463 sig_grooming + 0.003 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.003 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + 0.001 chosen + 0.001 sig_action + -0.003 sig_grooming + -0.0 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.997 value_scratch[t] + -0.0 chosen + 0.002 sig_action + -0.121 sig_grooming + 0.006 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.01 1 + 1.002 value_waiting[t] + -0.0 chosen + -0.0 sig_action + -0.004 sig_grooming + 0.211 sig_non_contact + 0.002 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + -0.003 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 179/1000 --- L(Train): 0.0205917 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.002 value_action[t] + 0.001 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 0.999 value_grooming[t] + 0.008 chosen + 0.001 sig_action + 0.005 sig_grooming + 0.001 sig_non_contact + 0.003 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.384 1 + 1.0 value_non_contact[t] + 0.001 chosen + 0.001 sig_action + -0.463 sig_grooming + 0.002 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + -0.003 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + -0.0 chosen + -0.001 sig_action + -0.004 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + 0.003 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.996 value_scratch[t] + 0.001 chosen + 0.001 sig_action + -0.121 sig_grooming + 0.006 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.011 1 + 0.999 value_waiting[t] + 0.001 chosen + 0.001 sig_action + -0.005 sig_grooming + 0.211 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 180/1000 --- L(Train): 0.0204815 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.001 value_action[t] + -0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.004 1 + 0.998 value_grooming[t] + 0.009 chosen + -0.002 sig_action + 0.004 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.383 1 + 0.999 value_non_contact[t] + 0.001 chosen + 0.001 sig_action + -0.463 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 0.999 value_contact[t] + -0.0 chosen + -0.001 sig_action + -0.004 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.995 value_scratch[t] + 0.0 chosen + -0.002 sig_action + -0.121 sig_grooming + 0.005 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.012 1 + 0.998 value_waiting[t] + 0.001 chosen + 0.001 sig_action + -0.006 sig_grooming + 0.211 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 181/1000 --- L(Train): 0.0204285 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + -0.003 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 0.998 value_grooming[t] + 0.011 chosen + -0.003 sig_action + 0.003 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + -0.003 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.383 1 + 0.999 value_non_contact[t] + -0.0 chosen + -0.0 sig_action + -0.463 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.003 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 0.999 value_contact[t] + 0.001 chosen + 0.0 sig_action + -0.003 sig_grooming + -0.0 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.995 value_scratch[t] + -0.001 chosen + -0.003 sig_action + -0.121 sig_grooming + 0.004 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.002 sig_waiting + -0.003 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.012 1 + 0.997 value_waiting[t] + -0.001 chosen + 0.0 sig_action + -0.005 sig_grooming + 0.211 sig_non_contact + -0.003 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 182/1000 --- L(Train): 0.0203710 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 0.999 value_action[t] + -0.002 chosen + 0.002 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 0.998 value_grooming[t] + 0.012 chosen + -0.002 sig_action + 0.002 sig_grooming + -0.003 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.002 prev_non_contact + -0.003 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.383 1 + 0.999 value_non_contact[t] + 0.001 chosen + 0.0 sig_action + -0.464 sig_grooming + -0.0 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.003 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.002 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + 0.001 chosen + 0.0 sig_action + -0.002 sig_grooming + -0.001 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.996 value_scratch[t] + -0.001 chosen + -0.002 sig_action + -0.121 sig_grooming + 0.002 sig_non_contact + 0.002 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + -0.003 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.012 1 + 0.998 value_waiting[t] + -0.001 chosen + -0.002 sig_action + -0.005 sig_grooming + 0.211 sig_non_contact + -0.003 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + -0.002 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 183/1000 --- L(Train): 0.0203071 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + -0.001 chosen + 0.003 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 1.0 value_grooming[t] + 0.013 chosen + -0.001 sig_action + 0.0 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.003 prev_non_contact + -0.001 prev_contact + 0.003 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.383 1 + 0.999 value_non_contact[t] + 0.001 chosen + -0.001 sig_action + -0.464 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + 0.0 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.0 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.003 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.997 value_scratch[t] + 0.0 chosen + -0.001 sig_action + -0.121 sig_grooming + 0.0 sig_non_contact + 0.003 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + 0.003 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.012 1 + 1.0 value_waiting[t] + 0.0 chosen + -0.002 sig_action + -0.004 sig_grooming + 0.21 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 184/1000 --- L(Train): 0.0202128 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.001 value_action[t] + 0.001 chosen + 0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 1.001 value_grooming[t] + 0.013 chosen + 0.001 sig_action + -0.001 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.383 1 + 1.001 value_non_contact[t] + 0.001 chosen + -0.001 sig_action + -0.464 sig_grooming + 0.004 sig_non_contact + -0.002 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 0.999 value_contact[t] + -0.002 chosen + -0.001 sig_action + 0.001 sig_grooming + 0.0 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.003 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.999 value_scratch[t] + -0.0 chosen + 0.001 sig_action + -0.121 sig_grooming + -0.002 sig_non_contact + 0.003 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.011 1 + 1.002 value_waiting[t] + -0.0 chosen + -0.002 sig_action + -0.002 sig_grooming + 0.21 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 185/1000 --- L(Train): 0.0201240 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.001 value_action[t] + 0.001 chosen + 0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 1.0 value_grooming[t] + 0.013 chosen + 0.001 sig_action + 0.002 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.382 1 + 1.0 value_non_contact[t] + 0.001 chosen + 0.001 sig_action + -0.464 sig_grooming + 0.005 sig_non_contact + -0.003 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 0.999 value_contact[t] + -0.002 chosen + -0.0 sig_action + 0.002 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 1.002 value_scratch[t] + 0.001 chosen + 0.001 sig_action + -0.121 sig_grooming + -0.003 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.01 1 + 1.003 value_waiting[t] + 0.001 chosen + -0.001 sig_action + -0.0 sig_grooming + 0.209 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 186/1000 --- L(Train): 0.0200652 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + 0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 1.0 value_grooming[t] + 0.013 chosen + 0.001 sig_action + 0.004 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.382 1 + 0.999 value_non_contact[t] + -0.0 chosen + 0.001 sig_action + -0.464 sig_grooming + 0.005 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + -0.002 chosen + 0.002 sig_action + 0.0 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 1.003 value_scratch[t] + 0.001 chosen + 0.001 sig_action + -0.121 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.009 1 + 1.003 value_waiting[t] + 0.001 chosen + 0.002 sig_action + 0.002 sig_grooming + 0.208 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + -0.003 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 187/1000 --- L(Train): 0.0199839 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.998 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 1.0 value_grooming[t] + 0.013 chosen + -0.0 sig_action + 0.006 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.382 1 + 1.0 value_non_contact[t] + 0.001 chosen + -0.0 sig_action + -0.464 sig_grooming + 0.005 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + -0.001 chosen + 0.002 sig_action + -0.003 sig_grooming + -0.0 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 1.003 value_scratch[t] + -0.001 chosen + -0.0 sig_action + -0.121 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.007 1 + 1.002 value_waiting[t] + -0.001 chosen + 0.003 sig_action + 0.002 sig_grooming + 0.207 sig_non_contact + -0.0 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + 0.003 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 188/1000 --- L(Train): 0.0199018 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 0.997 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 1.0 value_grooming[t] + 0.012 chosen + -0.0 sig_action + 0.007 sig_grooming + -0.002 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.382 1 + 1.0 value_non_contact[t] + 0.001 chosen + -0.0 sig_action + -0.465 sig_grooming + 0.005 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.001 value_contact[t] + 0.002 chosen + 0.002 sig_action + -0.005 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 1.002 value_scratch[t] + -0.001 chosen + -0.0 sig_action + -0.121 sig_grooming + 0.004 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.005 1 + 1.0 value_waiting[t] + -0.001 chosen + 0.003 sig_action + 0.0 sig_grooming + 0.207 sig_non_contact + -0.0 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 189/1000 --- L(Train): 0.0198522 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.997 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.003 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = -0.0 1 + 1.001 value_grooming[t] + 0.011 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.003 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + -0.003 prev_waiting \n",
            "value_non_contact[t+1] = -0.381 1 + 0.999 value_non_contact[t] + 0.001 chosen + 0.001 sig_action + -0.465 sig_grooming + 0.004 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.001 value_contact[t] + 0.003 chosen + 0.001 sig_action + -0.006 sig_grooming + 0.002 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.999 value_scratch[t] + 0.0 chosen + 0.001 sig_action + -0.121 sig_grooming + 0.005 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.004 1 + 0.999 value_waiting[t] + 0.0 chosen + 0.001 sig_action + -0.003 sig_grooming + 0.206 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.003 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 190/1000 --- L(Train): 0.0197833 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.998 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.003 prev_non_contact + -0.002 prev_contact + 0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.001 value_grooming[t] + 0.01 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.004 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + -0.003 prev_waiting \n",
            "value_non_contact[t+1] = -0.381 1 + 0.999 value_non_contact[t] + 0.0 chosen + 0.001 sig_action + -0.465 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] + 0.003 chosen + -0.002 sig_action + -0.006 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.998 value_scratch[t] + -0.0 chosen + 0.0 sig_action + -0.121 sig_grooming + 0.005 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 0.999 value_waiting[t] + 0.0 chosen + -0.001 sig_action + -0.006 sig_grooming + 0.206 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 191/1000 --- L(Train): 0.0197202 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + -0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.0 value_grooming[t] + 0.009 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.004 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.381 1 + 0.999 value_non_contact[t] + -0.001 chosen + 0.0 sig_action + -0.465 sig_grooming + 0.0 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 1.0 value_contact[t] + 0.001 chosen + -0.003 sig_action + -0.006 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.997 value_scratch[t] + 0.001 chosen + -0.001 sig_action + -0.121 sig_grooming + 0.005 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.0 value_waiting[t] + -0.001 chosen + -0.001 sig_action + -0.008 sig_grooming + 0.206 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.003 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 192/1000 --- L(Train): 0.0196670 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.002 value_action[t] + -0.001 chosen + -0.0 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.0 value_grooming[t] + 0.008 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.003 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.381 1 + 0.999 value_non_contact[t] + 0.0 chosen + -0.002 sig_action + -0.465 sig_grooming + -0.002 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.035 1 + 1.001 value_contact[t] + -0.001 chosen + -0.002 sig_action + -0.005 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.997 value_scratch[t] + 0.001 chosen + -0.001 sig_action + -0.121 sig_grooming + 0.005 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 1.001 value_waiting[t] + -0.001 chosen + -0.001 sig_action + -0.009 sig_grooming + 0.207 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 193/1000 --- L(Train): 0.0196082 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.003 value_action[t] + -0.0 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.001 value_grooming[t] + 0.006 chosen + -0.0 sig_action + 0.008 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.381 1 + 1.0 value_non_contact[t] + 0.001 chosen + -0.002 sig_action + -0.466 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.002 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.034 1 + 1.001 value_contact[t] + -0.001 chosen + -0.001 sig_action + -0.004 sig_grooming + -0.0 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.998 value_scratch[t] + -0.001 chosen + 0.0 sig_action + -0.121 sig_grooming + 0.004 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 1.002 value_waiting[t] + -0.0 chosen + 0.0 sig_action + -0.009 sig_grooming + 0.207 sig_non_contact + -0.0 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 194/1000 --- L(Train): 0.0195365 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 1.003 value_action[t] + 0.002 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.001 value_grooming[t] + 0.005 chosen + 0.002 sig_action + 0.008 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.38 1 + 0.999 value_non_contact[t] + 0.001 chosen + -0.002 sig_action + -0.466 sig_grooming + -0.0 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.033 1 + 0.999 value_contact[t] + -0.001 chosen + 0.001 sig_action + -0.002 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 1.0 value_scratch[t] + -0.001 chosen + 0.0 sig_action + -0.121 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.001 value_waiting[t] + 0.002 chosen + 0.0 sig_action + -0.009 sig_grooming + 0.208 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 195/1000 --- L(Train): 0.0195205 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.001 value_action[t] + 0.002 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.0 prev_non_contact + 0.003 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 0.999 value_grooming[t] + 0.003 chosen + 0.002 sig_action + 0.007 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + 0.002 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.38 1 + 0.999 value_non_contact[t] + -0.0 chosen + -0.001 sig_action + -0.466 sig_grooming + 0.004 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.003 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.034 1 + 0.999 value_contact[t] + 0.0 chosen + 0.001 sig_action + 0.001 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 1.002 value_scratch[t] + 0.0 chosen + -0.001 sig_action + -0.121 sig_grooming + -0.0 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + -0.0 prev_grooming + -0.003 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.0 value_waiting[t] + 0.002 chosen + -0.001 sig_action + -0.007 sig_grooming + 0.209 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 196/1000 --- L(Train): 0.0194543 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.999 value_action[t] + 0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.0 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.0 1 + 0.999 value_grooming[t] + 0.002 chosen + 0.002 sig_action + 0.007 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.002 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.38 1 + 0.999 value_non_contact[t] + 0.001 chosen + 0.002 sig_action + -0.466 sig_grooming + 0.007 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.003 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + -0.002 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.035 1 + 1.001 value_contact[t] + 0.0 chosen + 0.001 sig_action + 0.001 sig_grooming + 0.0 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 1.003 value_scratch[t] + 0.0 chosen + -0.001 sig_action + -0.121 sig_grooming + -0.0 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + -0.0 prev_grooming + -0.003 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 0.999 value_waiting[t] + 0.002 chosen + -0.0 sig_action + -0.006 sig_grooming + 0.21 sig_non_contact + 0.002 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 197/1000 --- L(Train): 0.0194062 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.998 value_action[t] + 0.001 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = -0.001 1 + 1.0 value_grooming[t] + 0.001 chosen + 0.001 sig_action + 0.006 sig_grooming + -0.0 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.38 1 + 1.0 value_non_contact[t] + 0.002 chosen + 0.003 sig_action + -0.466 sig_grooming + 0.009 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.003 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + -0.001 chosen + -0.0 sig_action + -0.0 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.003 prev_contact + 0.003 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 1.003 value_scratch[t] + -0.001 chosen + -0.0 sig_action + -0.121 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + -0.003 prev_waiting \n",
            "value_waiting[t+1] = 0.004 1 + 1.0 value_waiting[t] + 0.001 chosen + 0.001 sig_action + -0.004 sig_grooming + 0.211 sig_non_contact + 0.001 sig_contact + -0.003 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 198/1000 --- L(Train): 0.0193249 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.998 value_action[t] + -0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 1.002 value_grooming[t] + -0.001 chosen + -0.002 sig_action + 0.006 sig_grooming + -0.001 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + -0.002 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.38 1 + 1.001 value_non_contact[t] + 0.002 chosen + 0.002 sig_action + -0.466 sig_grooming + 0.01 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + -0.002 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 0.999 value_contact[t] + -0.0 chosen + -0.0 sig_action + -0.001 sig_grooming + -0.002 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 1.001 value_scratch[t] + -0.001 chosen + 0.002 sig_action + -0.121 sig_grooming + 0.002 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + -0.003 prev_waiting \n",
            "value_waiting[t+1] = 0.005 1 + 1.001 value_waiting[t] + -0.002 chosen + 0.001 sig_action + -0.001 sig_grooming + 0.212 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 199/1000 --- L(Train): 0.0192898 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.998 value_action[t] + -0.003 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.004 1 + 1.002 value_grooming[t] + 0.003 chosen + -0.003 sig_action + 0.005 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + -0.003 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.379 1 + 1.0 value_non_contact[t] + 0.001 chosen + 0.001 sig_action + -0.467 sig_grooming + 0.01 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + -0.003 prev_action + -0.001 prev_grooming + 0.003 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 0.999 value_contact[t] + 0.001 chosen + 0.001 sig_action + -0.001 sig_grooming + -0.002 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.998 value_scratch[t] + -0.0 chosen + 0.002 sig_action + -0.121 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + -0.003 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.005 1 + 1.002 value_waiting[t] + -0.003 chosen + -0.0 sig_action + 0.002 sig_grooming + 0.213 sig_non_contact + -0.003 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 200/1000 --- L(Train): 0.0192432 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 1.0 value_action[t] + -0.002 chosen + 0.002 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 1.001 value_grooming[t] + 0.005 chosen + -0.002 sig_action + 0.005 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.002 prev_non_contact + -0.003 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.379 1 + 0.998 value_non_contact[t] + 0.0 chosen + -0.001 sig_action + -0.467 sig_grooming + 0.01 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + -0.003 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.041 1 + 1.001 value_contact[t] + 0.001 chosen + 0.0 sig_action + -0.0 sig_grooming + -0.001 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.996 value_scratch[t] + 0.002 chosen + 0.002 sig_action + -0.12 sig_grooming + 0.002 sig_non_contact + 0.002 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + -0.003 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.006 1 + 1.001 value_waiting[t] + -0.002 chosen + 0.0 sig_action + 0.003 sig_grooming + 0.213 sig_non_contact + -0.003 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 201/1000 --- L(Train): 0.0191964 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.002 value_action[t] + -0.001 chosen + 0.003 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + 0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 1.0 value_grooming[t] + 0.007 chosen + -0.001 sig_action + 0.004 sig_grooming + -0.0 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.003 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.379 1 + 0.996 value_non_contact[t] + -0.001 chosen + -0.001 sig_action + -0.467 sig_grooming + 0.009 sig_non_contact + -0.001 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 1.0 value_contact[t] + -0.0 chosen + -0.001 sig_action + 0.001 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.003 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.995 value_scratch[t] + 0.002 chosen + 0.001 sig_action + -0.12 sig_grooming + 0.001 sig_non_contact + 0.003 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.006 1 + 0.999 value_waiting[t] + -0.001 chosen + -0.001 sig_action + 0.001 sig_grooming + 0.214 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 202/1000 --- L(Train): 0.0191243 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.003 value_action[t] + 0.001 chosen + 0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.007 1 + 0.999 value_grooming[t] + 0.009 chosen + 0.001 sig_action + 0.003 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.379 1 + 0.996 value_non_contact[t] + -0.001 chosen + -0.001 sig_action + -0.467 sig_grooming + 0.008 sig_non_contact + -0.001 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 0.999 value_contact[t] + 0.0 chosen + -0.001 sig_action + 0.0 sig_grooming + 0.002 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.003 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.995 value_scratch[t] + 0.002 chosen + -0.002 sig_action + -0.12 sig_grooming + -0.0 sig_non_contact + 0.003 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.005 1 + 0.998 value_waiting[t] + 0.001 chosen + -0.0 sig_action + -0.002 sig_grooming + 0.214 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 203/1000 --- L(Train): 0.0190461 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.003 value_action[t] + 0.001 chosen + 0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.007 1 + 0.999 value_grooming[t] + 0.011 chosen + 0.001 sig_action + 0.002 sig_grooming + 0.0 sig_non_contact + -0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.379 1 + 0.996 value_non_contact[t] + 0.001 chosen + 0.0 sig_action + -0.467 sig_grooming + 0.006 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 0.999 value_contact[t] + -0.001 chosen + 0.0 sig_action + -0.002 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.996 value_scratch[t] + 0.001 chosen + -0.003 sig_action + -0.12 sig_grooming + 0.0 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.005 1 + 0.999 value_waiting[t] + 0.001 chosen + 0.001 sig_action + -0.004 sig_grooming + 0.214 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 204/1000 --- L(Train): 0.0189988 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.001 value_action[t] + 0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 1.001 value_grooming[t] + 0.012 chosen + 0.001 sig_action + 0.001 sig_grooming + -0.002 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.379 1 + 0.996 value_non_contact[t] + 0.002 chosen + 0.0 sig_action + -0.468 sig_grooming + 0.004 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.001 value_contact[t] + -0.0 chosen + -0.0 sig_action + -0.003 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 0.998 value_scratch[t] + -0.002 chosen + -0.002 sig_action + -0.12 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.004 1 + 1.0 value_waiting[t] + 0.001 chosen + 0.001 sig_action + -0.006 sig_grooming + 0.214 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 205/1000 --- L(Train): 0.0189329 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.999 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 1.001 value_grooming[t] + 0.012 chosen + -0.0 sig_action + -0.0 sig_grooming + -0.004 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.379 1 + 0.997 value_non_contact[t] + 0.003 chosen + -0.001 sig_action + -0.468 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.003 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] + 0.001 chosen + 0.001 sig_action + -0.003 sig_grooming + -0.001 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 1.0 value_scratch[t] + -0.003 chosen + -0.001 sig_action + -0.12 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 1.002 value_waiting[t] + -0.0 chosen + -0.0 sig_action + -0.006 sig_grooming + 0.215 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 206/1000 --- L(Train): 0.0188733 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 0.997 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.004 1 + 1.0 value_grooming[t] + 0.013 chosen + -0.0 sig_action + 0.003 sig_grooming + -0.004 sig_non_contact + 0.002 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.379 1 + 0.999 value_non_contact[t] + 0.003 chosen + -0.0 sig_action + -0.468 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 0.999 value_contact[t] + 0.001 chosen + 0.001 sig_action + -0.003 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 1.003 value_scratch[t] + -0.002 chosen + 0.001 sig_action + -0.12 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 1.003 value_waiting[t] + -0.0 chosen + 0.0 sig_action + -0.006 sig_grooming + 0.214 sig_non_contact + -0.0 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + 0.002 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 207/1000 --- L(Train): 0.0188330 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.997 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 1.0 value_grooming[t] + 0.013 chosen + 0.001 sig_action + 0.005 sig_grooming + -0.005 sig_non_contact + 0.003 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.379 1 + 1.001 value_non_contact[t] + 0.003 chosen + 0.001 sig_action + -0.468 sig_grooming + -0.002 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.035 1 + 1.0 value_contact[t] + -0.0 chosen + -0.001 sig_action + -0.002 sig_grooming + -0.002 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.003 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.24 1 + 1.004 value_scratch[t] + -0.001 chosen + 0.001 sig_action + -0.12 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.002 value_waiting[t] + 0.001 chosen + -0.001 sig_action + -0.006 sig_grooming + 0.214 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.003 prev_grooming + 0.003 prev_non_contact + 0.002 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 208/1000 --- L(Train): 0.0187821 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.998 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.001 value_grooming[t] + 0.013 chosen + 0.0 sig_action + 0.007 sig_grooming + -0.004 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.379 1 + 1.001 value_non_contact[t] + 0.002 chosen + 0.001 sig_action + -0.468 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.034 1 + 1.001 value_contact[t] + 0.0 chosen + -0.001 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.003 value_scratch[t] + 0.001 chosen + 0.001 sig_action + -0.12 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.001 value_waiting[t] + 0.0 chosen + -0.001 sig_action + -0.004 sig_grooming + 0.214 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + 0.002 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 209/1000 --- L(Train): 0.0187314 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.999 value_action[t] + -0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = -0.001 1 + 1.001 value_grooming[t] + 0.012 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.003 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.379 1 + 0.999 value_non_contact[t] + 0.0 chosen + -0.0 sig_action + -0.468 sig_grooming + 0.002 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.034 1 + 1.001 value_contact[t] + -0.001 chosen + 0.0 sig_action + 0.001 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.002 value_scratch[t] + 0.001 chosen + -0.0 sig_action + -0.12 sig_grooming + 0.0 sig_non_contact + -0.0 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 0.998 value_waiting[t] + -0.001 chosen + 0.001 sig_action + -0.003 sig_grooming + 0.214 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 210/1000 --- L(Train): 0.0186973 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.001 value_action[t] + -0.001 chosen + -0.0 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.0 1 + 0.999 value_grooming[t] + 0.012 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.379 1 + 0.998 value_non_contact[t] + -0.002 chosen + 0.0 sig_action + -0.469 sig_grooming + 0.004 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.035 1 + 1.0 value_contact[t] + -0.001 chosen + 0.0 sig_action + 0.0 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + 0.001 chosen + -0.0 sig_action + -0.12 sig_grooming + -0.001 sig_non_contact + -0.0 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + 0.002 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 0.997 value_waiting[t] + -0.001 chosen + 0.001 sig_action + -0.001 sig_grooming + 0.214 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 211/1000 --- L(Train): 0.0186544 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.002 value_action[t] + -0.0 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 0.999 value_grooming[t] + 0.011 chosen + -0.0 sig_action + 0.01 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.379 1 + 0.997 value_non_contact[t] + -0.001 chosen + -0.001 sig_action + -0.469 sig_grooming + 0.006 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 1.0 value_contact[t] + 0.001 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.998 value_scratch[t] + -0.0 chosen + 0.001 sig_action + -0.12 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.003 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 0.997 value_waiting[t] + 0.0 chosen + -0.0 sig_action + 0.002 sig_grooming + 0.214 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + -0.003 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 212/1000 --- L(Train): 0.0185981 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 1.002 value_action[t] + 0.002 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.0 value_grooming[t] + 0.01 chosen + 0.002 sig_action + 0.01 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.379 1 + 0.997 value_non_contact[t] + 0.001 chosen + -0.001 sig_action + -0.469 sig_grooming + 0.007 sig_non_contact + -0.002 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.001 value_contact[t] + 0.001 chosen + -0.001 sig_action + -0.002 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.997 value_scratch[t] + -0.0 chosen + 0.0 sig_action + -0.121 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.003 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 0.998 value_waiting[t] + -0.0 chosen + 0.0 sig_action + 0.002 sig_grooming + 0.214 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + -0.003 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 213/1000 --- L(Train): 0.0185955 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + 0.002 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.0 value_grooming[t] + 0.008 chosen + 0.002 sig_action + 0.01 sig_grooming + 0.003 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.0 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.379 1 + 0.998 value_non_contact[t] + 0.002 chosen + 0.001 sig_action + -0.469 sig_grooming + 0.007 sig_non_contact + -0.003 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.001 value_contact[t] + -0.0 chosen + -0.0 sig_action + -0.003 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.997 value_scratch[t] + 0.001 chosen + -0.001 sig_action + -0.121 sig_grooming + 0.004 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.0 1 + 1.0 value_waiting[t] + 0.001 chosen + -0.001 sig_action + 0.001 sig_grooming + 0.214 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 214/1000 --- L(Train): 0.0185536 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.998 value_action[t] + 0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.0 1 + 1.0 value_grooming[t] + 0.007 chosen + 0.002 sig_action + 0.01 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.379 1 + 0.999 value_non_contact[t] + 0.003 chosen + 0.001 sig_action + -0.469 sig_grooming + 0.006 sig_non_contact + -0.002 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 1.0 value_contact[t] + -0.0 chosen + 0.002 sig_action + -0.002 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.998 value_scratch[t] + 0.0 chosen + -0.001 sig_action + -0.121 sig_grooming + 0.004 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_waiting[t+1] = -0.0 1 + 1.002 value_waiting[t] + 0.001 chosen + -0.001 sig_action + -0.002 sig_grooming + 0.214 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 215/1000 --- L(Train): 0.0185250 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.997 value_action[t] + 0.001 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = -0.001 1 + 1.0 value_grooming[t] + 0.006 chosen + 0.001 sig_action + 0.009 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.379 1 + 1.001 value_non_contact[t] + 0.003 chosen + -0.0 sig_action + -0.469 sig_grooming + 0.005 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 1.0 value_contact[t] + 0.001 chosen + 0.002 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + -0.001 chosen + 0.0 sig_action + -0.121 sig_grooming + 0.004 sig_non_contact + -0.002 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.003 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 1.004 value_waiting[t] + -0.001 chosen + 0.001 sig_action + -0.005 sig_grooming + 0.214 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 216/1000 --- L(Train): 0.0184542 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.996 value_action[t] + -0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.0 value_grooming[t] + 0.004 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.004 sig_non_contact + -0.0 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + -0.002 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.379 1 + 1.0 value_non_contact[t] + 0.002 chosen + -0.0 sig_action + -0.47 sig_grooming + 0.004 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + 0.0 prev_grooming + -0.002 prev_non_contact + 0.0 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.001 value_contact[t] + 0.001 chosen + 0.002 sig_action + 0.0 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + -0.0 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.002 value_scratch[t] + -0.001 chosen + 0.0 sig_action + -0.121 sig_grooming + 0.004 sig_non_contact + -0.002 sig_contact + -0.0 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.005 1 + 1.004 value_waiting[t] + -0.001 chosen + 0.001 sig_action + -0.006 sig_grooming + 0.215 sig_non_contact + -0.002 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 217/1000 --- L(Train): 0.0184461 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.997 value_action[t] + -0.003 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 1.0 value_grooming[t] + 0.003 chosen + -0.003 sig_action + 0.008 sig_grooming + -0.006 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.001 prev_non_contact + -0.003 prev_contact + 0.003 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.379 1 + 0.998 value_non_contact[t] + 0.001 chosen + 0.001 sig_action + -0.47 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + 0.002 sig_waiting + -0.003 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.001 value_contact[t] + 0.0 chosen + 0.001 sig_action + -0.0 sig_grooming + 0.001 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.003 value_scratch[t] + 0.0 chosen + -0.001 sig_action + -0.121 sig_grooming + 0.003 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.003 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.008 1 + 1.002 value_waiting[t] + 0.0 chosen + -0.0 sig_action + -0.007 sig_grooming + 0.215 sig_non_contact + -0.003 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + -0.003 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 218/1000 --- L(Train): 0.0184168 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 0.998 value_action[t] + -0.002 chosen + 0.002 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.002 prev_non_contact + -0.002 prev_contact + -0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.004 1 + 1.0 value_grooming[t] + 0.001 chosen + -0.002 sig_action + 0.007 sig_grooming + -0.006 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.001 prev_non_contact + -0.003 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.379 1 + 0.997 value_non_contact[t] + -0.001 chosen + 0.001 sig_action + -0.47 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + -0.003 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + -0.002 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] + -0.002 chosen + -0.002 sig_action + 0.0 sig_grooming + -0.001 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.002 value_scratch[t] + -0.0 chosen + -0.001 sig_action + -0.121 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + -0.003 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.01 1 + 1.0 value_waiting[t] + -0.0 chosen + -0.0 sig_action + -0.007 sig_grooming + 0.214 sig_non_contact + -0.003 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + -0.003 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 219/1000 --- L(Train): 0.0183927 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + -0.001 chosen + 0.003 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + 0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 0.999 value_grooming[t] + -0.0 chosen + -0.001 sig_action + 0.007 sig_grooming + -0.006 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.378 1 + 0.996 value_non_contact[t] + -0.0 chosen + 0.0 sig_action + -0.47 sig_grooming + -0.001 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] + -0.002 chosen + -0.003 sig_action + -0.001 sig_grooming + -0.002 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.003 sig_waiting + -0.0 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.001 value_scratch[t] + 0.001 chosen + -0.0 sig_action + -0.121 sig_grooming + -0.0 sig_non_contact + 0.003 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.011 1 + 0.998 value_waiting[t] + 0.001 chosen + 0.001 sig_action + -0.006 sig_grooming + 0.214 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.003 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 220/1000 --- L(Train): 0.0183289 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.001 value_action[t] + 0.001 chosen + 0.002 sig_action + 0.009 sig_grooming + -0.018 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 1.0 value_grooming[t] + 0.002 chosen + 0.001 sig_action + 0.006 sig_grooming + -0.005 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.378 1 + 0.996 value_non_contact[t] + 0.002 chosen + -0.002 sig_action + -0.47 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + 0.002 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.001 value_contact[t] + -0.002 chosen + -0.002 sig_action + -0.002 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.003 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.998 value_scratch[t] + 0.001 chosen + 0.002 sig_action + -0.121 sig_grooming + -0.0 sig_non_contact + 0.003 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.012 1 + 0.996 value_waiting[t] + 0.001 chosen + 0.001 sig_action + -0.005 sig_grooming + 0.213 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + -0.003 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 221/1000 --- L(Train): 0.0182757 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.001 value_action[t] + 0.001 chosen + 0.001 sig_action + 0.009 sig_grooming + -0.018 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 1.001 value_grooming[t] + 0.005 chosen + 0.001 sig_action + 0.005 sig_grooming + -0.004 sig_non_contact + -0.001 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.378 1 + 0.997 value_non_contact[t] + 0.004 chosen + -0.002 sig_action + -0.47 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.003 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.003 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 1.001 value_contact[t] + -0.001 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.0 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.996 value_scratch[t] + -0.001 chosen + 0.002 sig_action + -0.121 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.012 1 + 0.995 value_waiting[t] + -0.001 chosen + 0.0 sig_action + -0.004 sig_grooming + 0.212 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + 0.003 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 222/1000 --- L(Train): 0.0182464 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.999 value_action[t] + 0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.018 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 1.001 value_grooming[t] + 0.007 chosen + 0.001 sig_action + 0.004 sig_grooming + -0.003 sig_non_contact + -0.001 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.378 1 + 0.998 value_non_contact[t] + 0.005 chosen + -0.002 sig_action + -0.47 sig_grooming + 0.003 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.003 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 1.0 value_contact[t] + 0.002 chosen + 0.001 sig_action + -0.001 sig_grooming + 0.0 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.995 value_scratch[t] + -0.001 chosen + 0.002 sig_action + -0.121 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.012 1 + 0.996 value_waiting[t] + -0.001 chosen + -0.002 sig_action + -0.002 sig_grooming + 0.211 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 223/1000 --- L(Train): 0.0181922 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.999 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.003 prev_non_contact + 0.003 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 1.0 value_grooming[t] + 0.009 chosen + -0.0 sig_action + 0.003 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.378 1 + 1.0 value_non_contact[t] + 0.005 chosen + -0.001 sig_action + -0.471 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.002 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 1.0 value_contact[t] + 0.003 chosen + 0.001 sig_action + 0.0 sig_grooming + -0.0 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.995 value_scratch[t] + 0.0 chosen + 0.001 sig_action + -0.121 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.011 1 + 0.997 value_waiting[t] + 0.0 chosen + -0.002 sig_action + 0.0 sig_grooming + 0.21 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 224/1000 --- L(Train): 0.0181362 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 0.999 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.003 prev_non_contact + 0.002 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 1.0 value_grooming[t] + 0.01 chosen + -0.0 sig_action + 0.001 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.378 1 + 1.002 value_non_contact[t] + 0.004 chosen + 0.002 sig_action + -0.471 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 0.999 value_contact[t] + 0.003 chosen + 0.001 sig_action + -0.0 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.996 value_scratch[t] + -0.0 chosen + -0.002 sig_action + -0.121 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.01 1 + 0.999 value_waiting[t] + 0.0 chosen + -0.002 sig_action + 0.0 sig_grooming + 0.208 sig_non_contact + -0.0 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 225/1000 --- L(Train): 0.0181061 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.001 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 1.001 value_grooming[t] + 0.011 chosen + 0.001 sig_action + 0.0 sig_grooming + 0.002 sig_non_contact + -0.0 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_non_contact[t+1] = -0.378 1 + 1.002 value_non_contact[t] + 0.003 chosen + 0.003 sig_action + -0.471 sig_grooming + 0.0 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.003 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 0.999 value_contact[t] + 0.001 chosen + -0.0 sig_action + -0.0 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.003 prev_contact + 0.003 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.998 value_scratch[t] + 0.001 chosen + -0.003 sig_action + -0.121 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + 0.003 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.008 1 + 1.002 value_waiting[t] + -0.001 chosen + -0.001 sig_action + -0.002 sig_grooming + 0.207 sig_non_contact + 0.0 sig_contact + -0.003 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + 0.003 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 226/1000 --- L(Train): 0.0180671 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.001 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 1.001 value_grooming[t] + 0.011 chosen + 0.0 sig_action + -0.001 sig_grooming + 0.0 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.003 prev_waiting \n",
            "value_non_contact[t+1] = -0.378 1 + 1.0 value_non_contact[t] + 0.002 chosen + 0.002 sig_action + -0.471 sig_grooming + -0.002 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + -0.001 chosen + -0.0 sig_action + 0.0 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + 0.001 chosen + -0.002 sig_action + -0.121 sig_grooming + -0.0 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.007 1 + 1.004 value_waiting[t] + -0.001 chosen + 0.002 sig_action + -0.003 sig_grooming + 0.206 sig_non_contact + 0.0 sig_contact + -0.002 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 227/1000 --- L(Train): 0.0180292 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + -0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 0.999 value_grooming[t] + 0.012 chosen + -0.001 sig_action + 0.002 sig_grooming + -0.003 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.378 1 + 0.999 value_non_contact[t] + 0.0 chosen + 0.001 sig_action + -0.471 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + -0.001 chosen + 0.001 sig_action + -0.001 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.002 value_scratch[t] + -0.001 chosen + -0.001 sig_action + -0.121 sig_grooming + 0.0 sig_non_contact + -0.0 sig_contact + -0.003 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.006 1 + 1.004 value_waiting[t] + -0.0 chosen + 0.003 sig_action + -0.004 sig_grooming + 0.205 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 228/1000 --- L(Train): 0.0180103 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.999 value_action[t] + -0.001 chosen + -0.0 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.0 1 + 0.999 value_grooming[t] + 0.012 chosen + -0.001 sig_action + 0.004 sig_grooming + -0.005 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.378 1 + 0.998 value_non_contact[t] + -0.002 chosen + -0.001 sig_action + -0.471 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 1.0 value_contact[t] + -0.001 chosen + 0.0 sig_action + -0.001 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.004 value_scratch[t] + -0.001 chosen + 0.001 sig_action + -0.121 sig_grooming + 0.0 sig_non_contact + -0.0 sig_contact + -0.002 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.004 1 + 1.004 value_waiting[t] + 0.002 chosen + 0.003 sig_action + -0.004 sig_grooming + 0.205 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + -0.003 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 229/1000 --- L(Train): 0.0179721 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + -0.0 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = -0.001 1 + 1.0 value_grooming[t] + 0.012 chosen + -0.0 sig_action + 0.006 sig_grooming + -0.007 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.378 1 + 0.998 value_non_contact[t] + -0.002 chosen + -0.001 sig_action + -0.471 sig_grooming + 0.003 sig_non_contact + -0.001 sig_contact + -0.002 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 1.0 value_contact[t] + 0.0 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.003 value_scratch[t] + 0.0 chosen + 0.001 sig_action + -0.121 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 1.002 value_waiting[t] + 0.002 chosen + 0.001 sig_action + -0.003 sig_grooming + 0.204 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 230/1000 --- L(Train): 0.0179206 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 1.0 value_action[t] + 0.002 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.0 1 + 1.002 value_grooming[t] + 0.012 chosen + 0.002 sig_action + 0.008 sig_grooming + -0.007 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.377 1 + 0.999 value_non_contact[t] + -0.0 chosen + -0.001 sig_action + -0.471 sig_grooming + 0.004 sig_non_contact + -0.001 sig_contact + -0.002 sig_scratch + 0.0 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.001 value_contact[t] + 0.0 chosen + -0.001 sig_action + 0.0 sig_grooming + 0.0 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.002 value_scratch[t] + 0.0 chosen + 0.001 sig_action + -0.121 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + 0.0 prev_grooming + -0.002 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 0.999 value_waiting[t] + 0.002 chosen + -0.001 sig_action + -0.002 sig_grooming + 0.204 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 231/1000 --- L(Train): 0.0179277 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + 0.002 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.002 value_grooming[t] + 0.011 chosen + 0.002 sig_action + 0.009 sig_grooming + -0.007 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.0 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.377 1 + 1.0 value_non_contact[t] + 0.004 chosen + 0.0 sig_action + -0.471 sig_grooming + 0.004 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.001 value_contact[t] + -0.001 chosen + 0.0 sig_action + -0.0 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + -0.002 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + -0.001 chosen + -0.0 sig_action + -0.121 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 0.998 value_waiting[t] + 0.001 chosen + -0.001 sig_action + -0.0 sig_grooming + 0.205 sig_non_contact + 0.002 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 232/1000 --- L(Train): 0.0179004 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + 0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + -0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 1.001 value_grooming[t] + 0.011 chosen + 0.002 sig_action + 0.01 sig_grooming + -0.006 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.377 1 + 1.001 value_non_contact[t] + 0.006 chosen + 0.0 sig_action + -0.472 sig_grooming + 0.003 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] + -0.0 chosen + -0.0 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.998 value_scratch[t] + -0.001 chosen + -0.0 sig_action + -0.121 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 0.997 value_waiting[t] + -0.002 chosen + -0.001 sig_action + 0.002 sig_grooming + 0.205 sig_non_contact + 0.002 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 233/1000 --- L(Train): 0.0178792 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + 0.001 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.003 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 1.0 value_grooming[t] + 0.01 chosen + 0.001 sig_action + 0.01 sig_grooming + -0.005 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.377 1 + 1.001 value_non_contact[t] + 0.008 chosen + -0.001 sig_action + -0.472 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + 0.003 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + 0.001 chosen + 0.001 sig_action + -0.0 sig_grooming + 0.0 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.997 value_scratch[t] + -0.0 chosen + 0.001 sig_action + -0.121 sig_grooming + 0.0 sig_non_contact + -0.002 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 0.998 value_waiting[t] + -0.003 chosen + 0.0 sig_action + 0.002 sig_grooming + 0.206 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 234/1000 --- L(Train): 0.0178154 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.001 value_action[t] + -0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.003 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 0.999 value_grooming[t] + 0.009 chosen + -0.002 sig_action + 0.01 sig_grooming + -0.003 sig_non_contact + 0.002 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.377 1 + 0.999 value_non_contact[t] + 0.009 chosen + -0.0 sig_action + -0.472 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 0.999 value_contact[t] + 0.001 chosen + 0.001 sig_action + 0.001 sig_grooming + -0.0 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.997 value_scratch[t] + 0.002 chosen + 0.0 sig_action + -0.121 sig_grooming + -0.001 sig_non_contact + -0.002 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + -0.002 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 0.999 value_waiting[t] + -0.002 chosen + 0.0 sig_action + 0.0 sig_grooming + 0.207 sig_non_contact + -0.002 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 235/1000 --- L(Train): 0.0178190 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.001 value_action[t] + -0.003 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 1.0 value_grooming[t] + 0.007 chosen + -0.003 sig_action + 0.01 sig_grooming + -0.001 sig_non_contact + 0.003 sig_contact + -0.001 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.001 prev_non_contact + -0.003 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.377 1 + 0.998 value_non_contact[t] + 0.009 chosen + 0.001 sig_action + -0.472 sig_grooming + -0.001 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 0.999 value_contact[t] + -0.0 chosen + -0.001 sig_action + 0.0 sig_grooming + 0.001 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + 0.003 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.998 value_scratch[t] + 0.002 chosen + -0.001 sig_action + -0.121 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.003 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.002 value_waiting[t] + -0.001 chosen + -0.001 sig_action + -0.004 sig_grooming + 0.208 sig_non_contact + -0.003 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.003 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 236/1000 --- L(Train): 0.0178108 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 1.0 value_action[t] + -0.002 chosen + 0.002 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.001 value_grooming[t] + 0.006 chosen + -0.002 sig_action + 0.01 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.001 prev_non_contact + -0.003 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.377 1 + 0.997 value_non_contact[t] + 0.009 chosen + 0.001 sig_action + -0.472 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + -0.003 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.002 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.001 value_contact[t] + 0.0 chosen + -0.001 sig_action + -0.002 sig_grooming + 0.0 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + 0.002 chosen + -0.001 sig_action + -0.121 sig_grooming + 0.002 sig_non_contact + 0.002 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.003 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.003 value_waiting[t] + 0.001 chosen + -0.0 sig_action + -0.006 sig_grooming + 0.21 sig_non_contact + -0.003 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.003 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 237/1000 --- L(Train): 0.0177866 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.999 value_action[t] + -0.001 chosen + 0.003 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.0 1 + 1.001 value_grooming[t] + 0.004 chosen + -0.001 sig_action + 0.009 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.377 1 + 0.997 value_non_contact[t] + 0.008 chosen + -0.0 sig_action + -0.472 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.001 value_contact[t] + -0.001 chosen + 0.0 sig_action + -0.003 sig_grooming + -0.001 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.003 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.002 value_scratch[t] + 0.001 chosen + 0.0 sig_action + -0.121 sig_grooming + 0.004 sig_non_contact + 0.003 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.002 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 1.003 value_waiting[t] + 0.001 chosen + 0.001 sig_action + -0.008 sig_grooming + 0.211 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 238/1000 --- L(Train): 0.0177229 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + 0.001 chosen + 0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = -0.001 1 + 1.0 value_grooming[t] + 0.003 chosen + 0.001 sig_action + 0.008 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.377 1 + 0.998 value_non_contact[t] + 0.006 chosen + 0.0 sig_action + -0.472 sig_grooming + 0.002 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] + -0.0 chosen + 0.0 sig_action + -0.004 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.003 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.003 value_scratch[t] + -0.002 chosen + 0.0 sig_action + -0.121 sig_grooming + 0.004 sig_non_contact + 0.003 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + -0.003 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 1.001 value_waiting[t] + 0.001 chosen + 0.001 sig_action + -0.009 sig_grooming + 0.212 sig_non_contact + 0.0 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 239/1000 --- L(Train): 0.0176795 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + 0.001 chosen + 0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 0.998 value_grooming[t] + 0.001 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.377 1 + 1.0 value_non_contact[t] + 0.004 chosen + -0.001 sig_action + -0.472 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.003 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + 0.001 chosen + -0.001 sig_action + -0.004 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.002 value_scratch[t] + -0.003 chosen + -0.001 sig_action + -0.121 sig_grooming + 0.004 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.004 1 + 0.999 value_waiting[t] + -0.0 chosen + -0.0 sig_action + -0.009 sig_grooming + 0.213 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 240/1000 --- L(Train): 0.0176752 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + 0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 0.997 value_grooming[t] + -0.0 chosen + 0.001 sig_action + 0.007 sig_grooming + -0.004 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.377 1 + 1.001 value_non_contact[t] + 0.002 chosen + -0.001 sig_action + -0.472 sig_grooming + 0.002 sig_non_contact + -0.002 sig_contact + 0.0 sig_scratch + -0.003 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 1.001 value_contact[t] + 0.001 chosen + -0.001 sig_action + -0.004 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.001 value_scratch[t] + -0.002 chosen + -0.001 sig_action + -0.121 sig_grooming + 0.004 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.005 1 + 0.998 value_waiting[t] + -0.0 chosen + 0.0 sig_action + -0.008 sig_grooming + 0.214 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 241/1000 --- L(Train): 0.0176298 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.001 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.004 1 + 0.998 value_grooming[t] + 0.003 chosen + -0.0 sig_action + 0.006 sig_grooming + -0.006 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.377 1 + 1.001 value_non_contact[t] + -0.001 chosen + 0.001 sig_action + -0.472 sig_grooming + 0.001 sig_non_contact + -0.003 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 1.001 value_contact[t] + -0.0 chosen + -0.0 sig_action + -0.002 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.998 value_scratch[t] + -0.001 chosen + -0.0 sig_action + -0.121 sig_grooming + 0.003 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.005 1 + 0.998 value_waiting[t] + 0.001 chosen + -0.001 sig_action + -0.007 sig_grooming + 0.215 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 242/1000 --- L(Train): 0.0175758 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 1.001 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 0.999 value_grooming[t] + 0.005 chosen + -0.0 sig_action + 0.005 sig_grooming + -0.006 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.377 1 + 0.999 value_non_contact[t] + -0.001 chosen + 0.001 sig_action + -0.473 sig_grooming + -0.0 sig_non_contact + -0.002 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 1.0 value_contact[t] + 0.0 chosen + 0.002 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.996 value_scratch[t] + 0.001 chosen + 0.002 sig_action + -0.121 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.006 1 + 0.999 value_waiting[t] + 0.0 chosen + -0.0 sig_action + -0.006 sig_grooming + 0.216 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 243/1000 --- L(Train): 0.0175562 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 1.001 value_grooming[t] + 0.007 chosen + 0.001 sig_action + 0.004 sig_grooming + -0.006 sig_non_contact + -0.001 sig_contact + -0.002 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.002 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.377 1 + 0.998 value_non_contact[t] + 0.0 chosen + -0.0 sig_action + -0.473 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + 0.003 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 0.998 value_contact[t] + -0.001 chosen + 0.002 sig_action + 0.001 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.995 value_scratch[t] + 0.001 chosen + 0.002 sig_action + -0.121 sig_grooming + -0.0 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.006 1 + 1.001 value_waiting[t] + -0.001 chosen + 0.001 sig_action + -0.004 sig_grooming + 0.216 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + 0.003 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 244/1000 --- L(Train): 0.0175356 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.998 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 1.001 value_grooming[t] + 0.009 chosen + 0.0 sig_action + 0.003 sig_grooming + -0.005 sig_non_contact + -0.0 sig_contact + -0.002 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.002 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.377 1 + 0.997 value_non_contact[t] + 0.001 chosen + -0.0 sig_action + -0.473 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 0.998 value_contact[t] + -0.001 chosen + 0.002 sig_action + 0.002 sig_grooming + -0.002 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.995 value_scratch[t] + 0.001 chosen + 0.002 sig_action + -0.121 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.006 1 + 1.002 value_waiting[t] + -0.001 chosen + 0.001 sig_action + -0.001 sig_grooming + 0.216 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 245/1000 --- L(Train): 0.0175024 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.997 value_action[t] + -0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 1.001 value_grooming[t] + 0.011 chosen + -0.001 sig_action + 0.002 sig_grooming + -0.004 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.377 1 + 0.997 value_non_contact[t] + 0.001 chosen + 0.001 sig_action + -0.473 sig_grooming + 0.0 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 0.998 value_contact[t] + 0.001 chosen + 0.001 sig_action + 0.0 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.996 value_scratch[t] + -0.0 chosen + 0.001 sig_action + -0.121 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + -0.003 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.005 1 + 1.001 value_waiting[t] + 0.0 chosen + -0.0 sig_action + 0.001 sig_grooming + 0.216 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 246/1000 --- L(Train): 0.0174891 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.997 value_action[t] + -0.001 chosen + -0.0 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + 0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 1.0 value_grooming[t] + 0.011 chosen + -0.001 sig_action + 0.001 sig_grooming + -0.003 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 0.998 value_non_contact[t] + 0.001 chosen + 0.001 sig_action + -0.473 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 0.999 value_contact[t] + 0.001 chosen + -0.002 sig_action + -0.003 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.998 value_scratch[t] + -0.0 chosen + -0.002 sig_action + -0.121 sig_grooming + 0.002 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + -0.003 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.005 1 + 1.0 value_waiting[t] + -0.0 chosen + 0.0 sig_action + 0.002 sig_grooming + 0.216 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 247/1000 --- L(Train): 0.0174703 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.998 value_action[t] + -0.0 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + -0.002 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 0.999 value_grooming[t] + 0.012 chosen + -0.0 sig_action + -0.001 sig_grooming + -0.0 sig_non_contact + -0.0 sig_contact + 0.002 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.003 prev_non_contact + -0.0 prev_contact + -0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 0.999 value_non_contact[t] + 0.0 chosen + 0.0 sig_action + -0.473 sig_grooming + 0.0 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.002 value_contact[t] + -0.0 chosen + -0.003 sig_action + -0.005 sig_grooming + 0.0 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + 0.001 chosen + -0.003 sig_action + -0.121 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + -0.002 prev_contact + -0.003 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.004 1 + 0.999 value_waiting[t] + 0.001 chosen + -0.001 sig_action + 0.001 sig_grooming + 0.215 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.003 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + 0.002 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 248/1000 --- L(Train): 0.0174266 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 0.999 value_action[t] + 0.002 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + -0.002 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.004 1 + 1.0 value_grooming[t] + 0.012 chosen + 0.002 sig_action + 0.002 sig_grooming + 0.002 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.003 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 1.0 value_non_contact[t] + -0.001 chosen + -0.002 sig_action + -0.473 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.002 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.003 value_contact[t] + -0.0 chosen + -0.002 sig_action + -0.006 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.002 value_scratch[t] + 0.0 chosen + -0.002 sig_action + -0.121 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.0 value_waiting[t] + 0.001 chosen + -0.001 sig_action + -0.003 sig_grooming + 0.215 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 249/1000 --- L(Train): 0.0174552 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.002 value_action[t] + 0.002 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 1.001 value_grooming[t] + 0.013 chosen + 0.002 sig_action + 0.005 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 1.0 value_non_contact[t] + -0.001 chosen + -0.002 sig_action + -0.473 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.003 value_contact[t] + 0.001 chosen + -0.001 sig_action + -0.006 sig_grooming + -0.0 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.004 value_scratch[t] + -0.001 chosen + -0.001 sig_action + -0.121 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 1.001 value_waiting[t] + -0.001 chosen + 0.001 sig_action + -0.005 sig_grooming + 0.214 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.003 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 250/1000 --- L(Train): 0.0174419 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.003 value_action[t] + 0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.018 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.002 value_grooming[t] + 0.012 chosen + 0.002 sig_action + 0.007 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 1.0 value_non_contact[t] + 0.002 chosen + -0.002 sig_action + -0.473 sig_grooming + 0.0 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 1.001 value_contact[t] + 0.001 chosen + 0.001 sig_action + -0.006 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.003 value_scratch[t] + -0.001 chosen + 0.001 sig_action + -0.121 sig_grooming + -0.0 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_waiting[t+1] = 0.0 1 + 1.001 value_waiting[t] + -0.001 chosen + 0.001 sig_action + -0.006 sig_grooming + 0.214 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + -0.002 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_grooming: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_non_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_contact: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_scratch: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "value_waiting: 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 251/1000 --- L(Train): 0.0174235 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.002 value_action[t] + 0.001 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.018 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + 0.003 prev_contact + -0.003 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = -0.001 1 + 1.001 value_grooming[t] + 0.012 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.003 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 0.998 value_non_contact[t] + 0.004 chosen + -0.001 sig_action + -0.473 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.034 1 + 0.999 value_contact[t] + 0.0 chosen + 0.001 sig_action + -0.005 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.002 value_scratch[t] + 0.0 chosen + 0.001 sig_action + -0.121 sig_grooming + 0.0 sig_non_contact + -0.002 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + 0.003 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = -0.0 1 + 1.001 value_waiting[t] + 0.0 chosen + -0.0 sig_action + -0.007 sig_grooming + 0.214 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.003 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
            "value_grooming: 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
            "value_non_contact: 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
            "value_contact: 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
            "value_scratch: 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
            "value_waiting: 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 252/1000 --- L(Train): 0.0173583 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.001 value_action[t] + -0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = -0.0 1 + 0.999 value_grooming[t] + 0.011 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.005 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 0.997 value_non_contact[t] + 0.005 chosen + 0.002 sig_action + -0.473 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.033 1 + 0.999 value_contact[t] + -0.002 chosen + 0.001 sig_action + -0.004 sig_grooming + -0.0 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + -0.0 chosen + 0.001 sig_action + -0.121 sig_grooming + 0.0 sig_non_contact + -0.002 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + 0.003 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 0.999 value_waiting[t] + -0.0 chosen + 0.0 sig_action + -0.007 sig_grooming + 0.213 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + -0.003 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2\n",
            "value_grooming: 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2\n",
            "value_non_contact: 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2\n",
            "value_contact: 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2\n",
            "value_scratch: 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2\n",
            "value_waiting: 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 253/1000 --- L(Train): 0.0173694 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.999 value_action[t] + -0.003 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 0.998 value_grooming[t] + 0.01 chosen + -0.003 sig_action + 0.01 sig_grooming + -0.006 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.0 prev_non_contact + -0.003 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 0.997 value_non_contact[t] + 0.005 chosen + 0.003 sig_action + -0.473 sig_grooming + 0.002 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + -0.003 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.003 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.033 1 + 0.999 value_contact[t] + -0.002 chosen + -0.0 sig_action + -0.002 sig_grooming + -0.0 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.002 prev_non_contact + 0.003 prev_contact + 0.003 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.998 value_scratch[t] + 0.001 chosen + -0.0 sig_action + -0.121 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.003 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.006 1 + 0.998 value_waiting[t] + 0.001 chosen + -0.001 sig_action + -0.006 sig_grooming + 0.213 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3\n",
            "value_grooming: 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3\n",
            "value_non_contact: 0, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3\n",
            "value_contact: 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3\n",
            "value_scratch: 0, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3\n",
            "value_waiting: 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 254/1000 --- L(Train): 0.0173716 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 0.997 value_action[t] + -0.002 chosen + 0.002 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 0.999 value_grooming[t] + 0.009 chosen + -0.002 sig_action + 0.01 sig_grooming + -0.006 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.0 prev_non_contact + -0.003 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.375 1 + 0.997 value_non_contact[t] + 0.004 chosen + 0.002 sig_action + -0.474 sig_grooming + 0.004 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.003 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.034 1 + 1.0 value_contact[t] + -0.002 chosen + -0.0 sig_action + 0.0 sig_grooming + 0.0 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + 0.002 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.002 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.997 value_scratch[t] + 0.001 chosen + -0.0 sig_action + -0.121 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.003 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.008 1 + 0.998 value_waiting[t] + 0.001 chosen + -0.001 sig_action + -0.005 sig_grooming + 0.213 sig_non_contact + -0.003 sig_contact + -0.002 sig_scratch + -0.0 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + -0.003 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4\n",
            "value_grooming: 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4\n",
            "value_non_contact: 0, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4\n",
            "value_contact: 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4\n",
            "value_scratch: 0, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4\n",
            "value_waiting: 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 255/1000 --- L(Train): 0.0173532 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.997 value_action[t] + -0.001 chosen + 0.003 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.008 1 + 1.0 value_grooming[t] + 0.008 chosen + -0.001 sig_action + 0.01 sig_grooming + -0.006 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.375 1 + 0.998 value_non_contact[t] + 0.003 chosen + 0.001 sig_action + -0.474 sig_grooming + 0.005 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 1.001 value_contact[t] + -0.001 chosen + 0.001 sig_action + 0.001 sig_grooming + 0.0 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.003 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.997 value_scratch[t] + -0.001 chosen + 0.001 sig_action + -0.121 sig_grooming + 0.001 sig_non_contact + 0.003 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.01 1 + 1.0 value_waiting[t] + -0.001 chosen + 0.001 sig_action + -0.003 sig_grooming + 0.213 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.003 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5\n",
            "value_grooming: 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5\n",
            "value_non_contact: 0, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5\n",
            "value_contact: 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5\n",
            "value_scratch: 0, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5\n",
            "value_waiting: 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 256/1000 --- L(Train): 0.0172981 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.998 value_action[t] + 0.001 chosen + 0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.009 1 + 1.002 value_grooming[t] + 0.006 chosen + 0.001 sig_action + 0.009 sig_grooming + -0.006 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.375 1 + 1.0 value_non_contact[t] + 0.002 chosen + -0.001 sig_action + -0.474 sig_grooming + 0.005 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] + 0.002 chosen + 0.0 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.003 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.998 value_scratch[t] + -0.001 chosen + 0.0 sig_action + -0.121 sig_grooming + 0.001 sig_non_contact + 0.003 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.011 1 + 1.002 value_waiting[t] + -0.001 chosen + 0.001 sig_action + -0.001 sig_grooming + 0.212 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6\n",
            "value_grooming: 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6\n",
            "value_non_contact: 0, 6, 6, 6, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6\n",
            "value_contact: 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6\n",
            "value_scratch: 0, 6, 6, 6, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6\n",
            "value_waiting: 6, 6, 6, 6, 6, 0, 6, 6, 6, 6, 6, 6, 6, 6, 6\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 257/1000 --- L(Train): 0.0172551 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.999 value_action[t] + 0.001 chosen + 0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.01 1 + 1.003 value_grooming[t] + 0.005 chosen + 0.001 sig_action + 0.009 sig_grooming + -0.005 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.375 1 + 1.002 value_non_contact[t] + 0.0 chosen + -0.001 sig_action + -0.474 sig_grooming + 0.005 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 1.0 value_contact[t] + 0.003 chosen + -0.001 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + -0.003 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + 0.0 chosen + -0.001 sig_action + -0.121 sig_grooming + 0.0 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.012 1 + 1.002 value_waiting[t] + 0.0 chosen + -0.0 sig_action + 0.001 sig_grooming + 0.211 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7\n",
            "value_grooming: 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7\n",
            "value_non_contact: 0, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7\n",
            "value_contact: 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7\n",
            "value_scratch: 0, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7\n",
            "value_waiting: 7, 7, 7, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 258/1000 --- L(Train): 0.0172556 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.001 value_action[t] + 0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.009 1 + 1.002 value_grooming[t] + 0.003 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.003 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.375 1 + 1.002 value_non_contact[t] + -0.002 chosen + -0.001 sig_action + -0.474 sig_grooming + 0.004 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.041 1 + 1.001 value_contact[t] + 0.003 chosen + -0.001 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + -0.003 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.002 value_scratch[t] + -0.0 chosen + -0.001 sig_action + -0.121 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.012 1 + 1.002 value_waiting[t] + 0.0 chosen + -0.0 sig_action + 0.002 sig_grooming + 0.21 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8\n",
            "value_grooming: 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8\n",
            "value_non_contact: 0, 8, 8, 8, 0, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8\n",
            "value_contact: 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8\n",
            "value_scratch: 0, 8, 8, 8, 0, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8\n",
            "value_waiting: 8, 8, 8, 8, 8, 0, 8, 8, 8, 8, 8, 8, 8, 8, 8\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 259/1000 --- L(Train): 0.0172204 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.002 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.009 1 + 1.001 value_grooming[t] + 0.001 chosen + -0.0 sig_action + 0.006 sig_grooming + -0.001 sig_non_contact + -0.002 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.375 1 + 1.0 value_non_contact[t] + -0.003 chosen + 0.0 sig_action + -0.474 sig_grooming + 0.002 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.041 1 + 1.001 value_contact[t] + 0.001 chosen + 0.0 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.003 value_scratch[t] + 0.001 chosen + 0.0 sig_action + -0.121 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.011 1 + 1.001 value_waiting[t] + -0.001 chosen + 0.001 sig_action + -0.0 sig_grooming + 0.209 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9\n",
            "value_grooming: 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9\n",
            "value_non_contact: 0, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9\n",
            "value_contact: 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9\n",
            "value_scratch: 0, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9\n",
            "value_waiting: 9, 9, 9, 9, 9, 0, 9, 9, 9, 9, 9, 9, 9, 9, 9\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 260/1000 --- L(Train): 0.0171737 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 1.002 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.008 1 + 0.999 value_grooming[t] + -0.001 chosen + -0.0 sig_action + 0.005 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + 0.002 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.375 1 + 0.997 value_non_contact[t] + -0.001 chosen + 0.0 sig_action + -0.474 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.0 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.041 1 + 1.0 value_contact[t] + -0.001 chosen + -0.0 sig_action + 0.001 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.002 value_scratch[t] + 0.001 chosen + 0.0 sig_action + -0.121 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + -0.002 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.01 1 + 0.998 value_waiting[t] + -0.001 chosen + 0.001 sig_action + -0.001 sig_grooming + 0.208 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10\n",
            "value_grooming: 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10\n",
            "value_non_contact: 0, 10, 10, 10, 0, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10\n",
            "value_contact: 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10\n",
            "value_scratch: 0, 10, 10, 10, 0, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10\n",
            "value_waiting: 10, 10, 10, 10, 10, 0, 10, 10, 10, 10, 10, 10, 10, 10, 10\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 261/1000 --- L(Train): 0.0171670 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.001 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.007 1 + 0.998 value_grooming[t] + 0.001 chosen + 0.001 sig_action + 0.004 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.002 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_non_contact[t+1] = -0.375 1 + 0.994 value_non_contact[t] + 0.003 chosen + -0.001 sig_action + -0.474 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 0.999 value_contact[t] + -0.001 chosen + 0.001 sig_action + 0.0 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.001 value_scratch[t] + -0.001 chosen + -0.001 sig_action + -0.121 sig_grooming + 0.003 sig_non_contact + 0.0 sig_contact + -0.003 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.009 1 + 0.997 value_waiting[t] + -0.0 chosen + 0.0 sig_action + -0.002 sig_grooming + 0.207 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.003 prev_grooming + -0.003 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11\n",
            "value_grooming: 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11\n",
            "value_non_contact: 0, 11, 11, 11, 0, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11\n",
            "value_contact: 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11\n",
            "value_scratch: 0, 11, 11, 11, 0, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11\n",
            "value_waiting: 11, 11, 11, 11, 11, 0, 11, 11, 11, 11, 11, 11, 11, 11, 11\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 262/1000 --- L(Train): 0.0171527 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.998 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 0.997 value_grooming[t] + 0.003 chosen + 0.0 sig_action + 0.002 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.002 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_non_contact[t+1] = -0.375 1 + 0.992 value_non_contact[t] + 0.005 chosen + -0.0 sig_action + -0.474 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + -0.002 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 0.998 value_contact[t] + -0.001 chosen + 0.001 sig_action + -0.002 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 0.998 value_scratch[t] + -0.001 chosen + -0.001 sig_action + -0.121 sig_grooming + 0.004 sig_non_contact + 0.0 sig_contact + -0.003 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.007 1 + 0.997 value_waiting[t] + 0.002 chosen + -0.002 sig_action + -0.002 sig_grooming + 0.206 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + -0.003 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12\n",
            "value_grooming: 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12\n",
            "value_non_contact: 0, 12, 12, 12, 0, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12\n",
            "value_contact: 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12\n",
            "value_scratch: 0, 12, 12, 12, 0, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12\n",
            "value_waiting: 12, 12, 12, 12, 12, 0, 12, 12, 12, 12, 12, 12, 12, 12, 12\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 263/1000 --- L(Train): 0.0171281 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.997 value_action[t] + -0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.004 1 + 0.998 value_grooming[t] + 0.005 chosen + -0.001 sig_action + 0.001 sig_grooming + -0.002 sig_non_contact + 0.003 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.375 1 + 0.991 value_non_contact[t] + 0.007 chosen + 0.001 sig_action + -0.474 sig_grooming + -0.0 sig_non_contact + -0.0 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 0.998 value_contact[t] + 0.0 chosen + -0.001 sig_action + -0.003 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.003 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 0.996 value_scratch[t] + 0.0 chosen + -0.0 sig_action + -0.121 sig_grooming + 0.004 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.006 1 + 0.998 value_waiting[t] + 0.002 chosen + -0.002 sig_action + -0.002 sig_grooming + 0.205 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13\n",
            "value_grooming: 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13\n",
            "value_non_contact: 0, 13, 13, 13, 0, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13\n",
            "value_contact: 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13\n",
            "value_scratch: 0, 13, 13, 13, 0, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13\n",
            "value_waiting: 13, 13, 13, 13, 13, 0, 13, 13, 13, 13, 13, 13, 13, 13, 13\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 264/1000 --- L(Train): 0.0171151 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.996 value_action[t] + -0.001 chosen + -0.0 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 1.0 value_grooming[t] + 0.006 chosen + -0.001 sig_action + 0.0 sig_grooming + -0.002 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.375 1 + 0.991 value_non_contact[t] + 0.007 chosen + 0.001 sig_action + -0.474 sig_grooming + 0.003 sig_non_contact + 0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 1.0 value_contact[t] + 0.0 chosen + -0.001 sig_action + -0.004 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 0.995 value_scratch[t] + 0.0 chosen + 0.002 sig_action + -0.121 sig_grooming + 0.004 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.005 1 + 1.0 value_waiting[t] + 0.002 chosen + -0.002 sig_action + -0.0 sig_grooming + 0.205 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14\n",
            "value_grooming: 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14\n",
            "value_non_contact: 0, 14, 14, 14, 0, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14\n",
            "value_contact: 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14\n",
            "value_scratch: 0, 14, 14, 14, 0, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14\n",
            "value_waiting: 14, 14, 14, 14, 14, 0, 14, 14, 14, 14, 14, 14, 14, 14, 14\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 265/1000 --- L(Train): 0.0170999 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.997 value_action[t] + -0.0 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.002 value_grooming[t] + 0.008 chosen + -0.0 sig_action + -0.001 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.003 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.375 1 + 0.992 value_non_contact[t] + 0.007 chosen + -0.0 sig_action + -0.474 sig_grooming + 0.005 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + -0.003 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.003 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.035 1 + 1.002 value_contact[t] + -0.001 chosen + 0.0 sig_action + -0.003 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.995 value_scratch[t] + -0.001 chosen + 0.002 sig_action + -0.121 sig_grooming + 0.003 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.004 1 + 1.002 value_waiting[t] + 0.001 chosen + -0.001 sig_action + 0.001 sig_grooming + 0.204 sig_non_contact + -0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15\n",
            "value_grooming: 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15\n",
            "value_non_contact: 0, 15, 15, 15, 0, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15\n",
            "value_contact: 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15\n",
            "value_scratch: 0, 15, 15, 15, 0, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15\n",
            "value_waiting: 15, 15, 15, 15, 15, 0, 15, 15, 15, 15, 15, 15, 15, 15, 15\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 266/1000 --- L(Train): 0.0170707 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 0.999 value_action[t] + 0.002 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = -0.0 1 + 1.004 value_grooming[t] + 0.009 chosen + 0.002 sig_action + 0.002 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + -0.002 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.375 1 + 0.993 value_non_contact[t] + 0.006 chosen + 0.0 sig_action + -0.474 sig_grooming + 0.006 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.003 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.034 1 + 1.003 value_contact[t] + -0.0 chosen + 0.0 sig_action + -0.003 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.996 value_scratch[t] + -0.001 chosen + 0.002 sig_action + -0.121 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 1.003 value_waiting[t] + -0.002 chosen + 0.002 sig_action + 0.0 sig_grooming + 0.204 sig_non_contact + 0.002 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16\n",
            "value_grooming: 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16\n",
            "value_non_contact: 0, 16, 16, 16, 0, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16\n",
            "value_contact: 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16\n",
            "value_scratch: 0, 16, 16, 16, 0, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16\n",
            "value_waiting: 16, 16, 16, 16, 16, 0, 16, 16, 16, 16, 16, 16, 16, 16, 16\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 267/1000 --- L(Train): 0.0170973 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.001 value_action[t] + 0.002 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.004 value_grooming[t] + 0.01 chosen + 0.002 sig_action + 0.005 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.375 1 + 0.995 value_non_contact[t] + 0.005 chosen + -0.001 sig_action + -0.475 sig_grooming + 0.007 sig_non_contact + 0.001 sig_contact + 0.003 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.034 1 + 1.003 value_contact[t] + 0.001 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.0 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.998 value_scratch[t] + -0.0 chosen + 0.001 sig_action + -0.121 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + 0.003 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.003 value_waiting[t] + -0.003 chosen + 0.003 sig_action + -0.002 sig_grooming + 0.205 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17\n",
            "value_grooming: 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17\n",
            "value_non_contact: 0, 17, 17, 17, 0, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17\n",
            "value_contact: 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17\n",
            "value_scratch: 0, 17, 17, 17, 0, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17\n",
            "value_waiting: 17, 17, 17, 17, 17, 0, 17, 17, 17, 17, 17, 17, 17, 17, 17\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 268/1000 --- L(Train): 0.0170869 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.002 value_action[t] + 0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.018 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 1.002 value_grooming[t] + 0.01 chosen + 0.002 sig_action + 0.008 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.375 1 + 0.998 value_non_contact[t] + 0.003 chosen + -0.001 sig_action + -0.475 sig_grooming + 0.006 sig_non_contact + -0.002 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.035 1 + 1.002 value_contact[t] + 0.001 chosen + -0.001 sig_action + 0.0 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + 0.002 chosen + -0.002 sig_action + -0.121 sig_grooming + -0.001 sig_non_contact + -0.002 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.002 value_waiting[t] + -0.002 chosen + 0.003 sig_action + -0.003 sig_grooming + 0.206 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18\n",
            "value_grooming: 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18\n",
            "value_non_contact: 0, 18, 18, 18, 0, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18\n",
            "value_contact: 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18\n",
            "value_scratch: 0, 18, 18, 18, 0, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18\n",
            "value_waiting: 18, 18, 18, 18, 18, 0, 18, 18, 18, 18, 18, 18, 18, 18, 18\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 269/1000 --- L(Train): 0.0170765 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.001 value_action[t] + 0.001 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.018 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 1.0 value_grooming[t] + 0.011 chosen + 0.001 sig_action + 0.009 sig_grooming + -0.0 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 1.0 value_non_contact[t] + 0.001 chosen + 0.001 sig_action + -0.475 sig_grooming + 0.005 sig_non_contact + -0.003 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + -0.0 chosen + -0.0 sig_action + 0.0 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.002 value_scratch[t] + 0.002 chosen + -0.003 sig_action + -0.121 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.0 value_waiting[t] + -0.001 chosen + 0.001 sig_action + -0.004 sig_grooming + 0.207 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.003 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19\n",
            "value_grooming: 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19\n",
            "value_non_contact: 0, 19, 19, 19, 0, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19\n",
            "value_contact: 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19\n",
            "value_scratch: 0, 19, 19, 19, 0, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19\n",
            "value_waiting: 19, 19, 19, 19, 19, 0, 19, 19, 19, 19, 19, 19, 19, 19, 19\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 270/1000 --- L(Train): 0.0170212 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + -0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.018 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 0.998 value_grooming[t] + 0.011 chosen + -0.002 sig_action + 0.011 sig_grooming + 0.0 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 1.001 value_non_contact[t] + -0.002 chosen + 0.001 sig_action + -0.475 sig_grooming + 0.004 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 0.997 value_contact[t] + 0.0 chosen + 0.002 sig_action + -0.002 sig_grooming + -0.002 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.004 value_scratch[t] + 0.002 chosen + -0.002 sig_action + -0.122 sig_grooming + 0.002 sig_non_contact + -0.002 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 0.997 value_waiting[t] + 0.001 chosen + -0.001 sig_action + -0.004 sig_grooming + 0.208 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + -0.003 prev_non_contact + -0.0 prev_contact + -0.002 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20\n",
            "value_grooming: 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20\n",
            "value_non_contact: 0, 20, 20, 20, 0, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20\n",
            "value_contact: 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20\n",
            "value_scratch: 0, 20, 20, 20, 0, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20\n",
            "value_waiting: 20, 20, 20, 20, 20, 0, 20, 20, 20, 20, 20, 20, 20, 20, 20\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 271/1000 --- L(Train): 0.0170345 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.999 value_action[t] + -0.003 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 0.996 value_grooming[t] + 0.01 chosen + -0.003 sig_action + 0.012 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.0 prev_non_contact + -0.003 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 1.0 value_non_contact[t] + -0.003 chosen + -0.0 sig_action + -0.475 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.003 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 0.996 value_contact[t] + -0.001 chosen + 0.002 sig_action + -0.002 sig_grooming + -0.0 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.003 value_scratch[t] + 0.001 chosen + -0.001 sig_action + -0.122 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.003 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 0.996 value_waiting[t] + 0.001 chosen + -0.001 sig_action + -0.004 sig_grooming + 0.209 sig_non_contact + -0.003 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + -0.003 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21\n",
            "value_grooming: 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21\n",
            "value_non_contact: 0, 21, 21, 21, 0, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21\n",
            "value_contact: 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21\n",
            "value_scratch: 0, 21, 21, 21, 0, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21\n",
            "value_waiting: 21, 21, 21, 21, 21, 0, 21, 21, 21, 21, 21, 21, 21, 21, 21\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 272/1000 --- L(Train): 0.0170345 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 1.0 value_action[t] + -0.002 chosen + 0.002 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 0.995 value_grooming[t] + 0.01 chosen + -0.002 sig_action + 0.012 sig_grooming + -0.001 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.0 prev_non_contact + -0.003 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 0.997 value_non_contact[t] + -0.002 chosen + -0.0 sig_action + -0.475 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.003 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + -0.002 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 0.996 value_contact[t] + -0.0 chosen + 0.002 sig_action + -0.003 sig_grooming + 0.002 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + 0.002 sig_waiting + -0.0 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.002 value_scratch[t] + -0.002 chosen + 0.001 sig_action + -0.122 sig_grooming + 0.002 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.003 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 0.995 value_waiting[t] + 0.001 chosen + -0.001 sig_action + -0.003 sig_grooming + 0.211 sig_non_contact + -0.003 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.003 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22\n",
            "value_grooming: 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22\n",
            "value_non_contact: 0, 22, 22, 22, 0, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22\n",
            "value_contact: 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22\n",
            "value_scratch: 0, 22, 22, 22, 0, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22\n",
            "value_waiting: 22, 22, 22, 22, 22, 0, 22, 22, 22, 22, 22, 22, 22, 22, 22\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 273/1000 --- L(Train): 0.0170289 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.001 value_action[t] + -0.001 chosen + 0.003 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.0 1 + 0.996 value_grooming[t] + 0.009 chosen + -0.001 sig_action + 0.012 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 0.995 value_non_contact[t] + 0.001 chosen + 0.001 sig_action + -0.475 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 0.996 value_contact[t] + 0.001 chosen + 0.001 sig_action + -0.002 sig_grooming + 0.003 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.003 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + -0.003 chosen + 0.001 sig_action + -0.122 sig_grooming + 0.001 sig_non_contact + 0.003 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 0.996 value_waiting[t] + -0.0 chosen + 0.0 sig_action + -0.001 sig_grooming + 0.212 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.002 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23\n",
            "value_grooming: 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23\n",
            "value_non_contact: 0, 23, 23, 23, 0, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23\n",
            "value_contact: 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23\n",
            "value_scratch: 0, 23, 23, 23, 0, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23\n",
            "value_waiting: 23, 23, 23, 23, 23, 0, 23, 23, 23, 23, 23, 23, 23, 23, 23\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 274/1000 --- L(Train): 0.0169909 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.001 value_action[t] + 0.001 chosen + 0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = -0.001 1 + 0.997 value_grooming[t] + 0.008 chosen + 0.001 sig_action + 0.012 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 0.994 value_non_contact[t] + 0.004 chosen + 0.001 sig_action + -0.475 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 0.998 value_contact[t] + 0.001 chosen + -0.002 sig_action + -0.001 sig_grooming + 0.002 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.003 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.998 value_scratch[t] + -0.002 chosen + 0.001 sig_action + -0.122 sig_grooming + -0.0 sig_non_contact + 0.003 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.004 1 + 0.997 value_waiting[t] + -0.0 chosen + 0.0 sig_action + 0.001 sig_grooming + 0.213 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24\n",
            "value_grooming: 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24\n",
            "value_non_contact: 0, 24, 24, 24, 0, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24\n",
            "value_contact: 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24\n",
            "value_scratch: 0, 24, 24, 24, 0, 24, 24, 24, 24, 24, 24, 24, 24, 24, 24\n",
            "value_waiting: 24, 24, 24, 24, 24, 0, 24, 24, 24, 24, 24, 24, 24, 24, 24\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 275/1000 --- L(Train): 0.0169567 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + 0.001 chosen + 0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + -0.002 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = -0.0 1 + 0.999 value_grooming[t] + 0.006 chosen + 0.001 sig_action + 0.012 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 0.993 value_non_contact[t] + 0.005 chosen + 0.0 sig_action + -0.475 sig_grooming + 0.003 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + -0.0 chosen + -0.003 sig_action + 0.0 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.0 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.997 value_scratch[t] + -0.001 chosen + -0.0 sig_action + -0.121 sig_grooming + 0.0 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + -0.0 prev_contact + -0.003 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.004 1 + 0.999 value_waiting[t] + 0.001 chosen + -0.001 sig_action + 0.001 sig_grooming + 0.214 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + -0.003 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25\n",
            "value_grooming: 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25\n",
            "value_non_contact: 0, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25\n",
            "value_contact: 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25\n",
            "value_scratch: 0, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25\n",
            "value_waiting: 25, 25, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25, 25, 25\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 276/1000 --- L(Train): 0.0169473 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + 0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + -0.002 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 1.002 value_grooming[t] + 0.005 chosen + 0.001 sig_action + 0.011 sig_grooming + 0.0 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 0.994 value_non_contact[t] + 0.006 chosen + -0.002 sig_action + -0.475 sig_grooming + 0.003 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.002 value_contact[t] + 0.0 chosen + -0.002 sig_action + -0.0 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.997 value_scratch[t] + 0.001 chosen + -0.0 sig_action + -0.121 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + -0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.004 1 + 1.002 value_waiting[t] + 0.0 chosen + -0.0 sig_action + -0.001 sig_grooming + 0.215 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26\n",
            "value_grooming: 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26\n",
            "value_non_contact: 0, 26, 26, 26, 0, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26\n",
            "value_contact: 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26\n",
            "value_scratch: 0, 26, 26, 26, 0, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26\n",
            "value_waiting: 26, 26, 26, 26, 26, 0, 26, 26, 26, 26, 26, 26, 26, 26, 26\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 277/1000 --- L(Train): 0.0169201 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.001 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 1.004 value_grooming[t] + 0.003 chosen + -0.0 sig_action + 0.01 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 0.994 value_non_contact[t] + 0.005 chosen + -0.002 sig_action + -0.475 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.002 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.002 value_contact[t] + -0.001 chosen + -0.001 sig_action + 0.0 sig_grooming + -0.002 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.998 value_scratch[t] + 0.001 chosen + 0.001 sig_action + -0.121 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 1.004 value_waiting[t] + -0.001 chosen + 0.001 sig_action + -0.002 sig_grooming + 0.216 sig_non_contact + -0.0 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27\n",
            "value_grooming: 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27\n",
            "value_non_contact: 0, 27, 27, 27, 0, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27\n",
            "value_contact: 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27\n",
            "value_scratch: 0, 27, 27, 27, 0, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27\n",
            "value_waiting: 27, 27, 27, 27, 27, 0, 27, 27, 27, 27, 27, 27, 27, 27, 27\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 278/1000 --- L(Train): 0.0168947 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 1.0 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.008 1 + 1.004 value_grooming[t] + 0.002 chosen + -0.0 sig_action + 0.009 sig_grooming + -0.004 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 0.996 value_non_contact[t] + 0.005 chosen + -0.002 sig_action + -0.475 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.002 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.001 value_contact[t] + -0.001 chosen + 0.001 sig_action + -0.001 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + 0.001 chosen + 0.0 sig_action + -0.121 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 1.004 value_waiting[t] + -0.001 chosen + 0.001 sig_action + -0.003 sig_grooming + 0.216 sig_non_contact + -0.0 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28\n",
            "value_grooming: 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28\n",
            "value_non_contact: 0, 28, 28, 28, 0, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28\n",
            "value_contact: 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28\n",
            "value_scratch: 0, 28, 28, 28, 0, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28\n",
            "value_waiting: 28, 28, 28, 28, 28, 0, 28, 28, 28, 28, 28, 28, 28, 28, 28\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 279/1000 --- L(Train): 0.0168881 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.999 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.003 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.01 1 + 1.003 value_grooming[t] + 0.0 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.005 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.002 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 0.998 value_non_contact[t] + 0.003 chosen + -0.001 sig_action + -0.475 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 0.999 value_contact[t] + 0.001 chosen + 0.001 sig_action + -0.002 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + -0.0 chosen + -0.001 sig_action + -0.121 sig_grooming + 0.003 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.003 value_waiting[t] + 0.0 chosen + -0.0 sig_action + -0.003 sig_grooming + 0.217 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.003 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29\n",
            "value_grooming: 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29\n",
            "value_non_contact: 0, 29, 29, 29, 0, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29\n",
            "value_contact: 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29\n",
            "value_scratch: 0, 29, 29, 29, 0, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29\n",
            "value_waiting: 29, 29, 29, 29, 29, 0, 29, 29, 29, 29, 29, 29, 29, 29, 29\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 280/1000 --- L(Train): 0.0168612 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.998 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.011 1 + 1.001 value_grooming[t] + -0.002 chosen + 0.0 sig_action + 0.007 sig_grooming + -0.005 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.002 prev_non_contact + 0.0 prev_contact + -0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 1.0 value_non_contact[t] + 0.001 chosen + 0.002 sig_action + -0.475 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 0.999 value_contact[t] + 0.001 chosen + 0.001 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + -0.0 chosen + -0.001 sig_action + -0.121 sig_grooming + 0.002 sig_non_contact + 0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.001 value_waiting[t] + -0.0 chosen + 0.0 sig_action + -0.002 sig_grooming + 0.217 sig_non_contact + 0.0 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30\n",
            "value_grooming: 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30\n",
            "value_non_contact: 0, 30, 30, 30, 0, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30\n",
            "value_contact: 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30\n",
            "value_scratch: 0, 30, 30, 30, 0, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30\n",
            "value_waiting: 30, 30, 30, 30, 30, 0, 30, 30, 30, 30, 30, 30, 30, 30, 30\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 281/1000 --- L(Train): 0.0168488 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.999 value_action[t] + -0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.011 1 + 0.999 value_grooming[t] + 0.001 chosen + -0.001 sig_action + 0.005 sig_grooming + -0.005 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 1.001 value_non_contact[t] + -0.001 chosen + 0.003 sig_action + -0.475 sig_grooming + 0.002 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.003 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 0.999 value_contact[t] + -0.0 chosen + -0.0 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + 0.003 prev_contact + 0.003 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + 0.001 chosen + 0.0 sig_action + -0.121 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 0.999 value_waiting[t] + 0.001 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.217 sig_non_contact + -0.001 sig_contact + -0.003 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31\n",
            "value_grooming: 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31\n",
            "value_non_contact: 0, 31, 31, 31, 0, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31\n",
            "value_contact: 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31\n",
            "value_scratch: 0, 31, 31, 31, 0, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31\n",
            "value_waiting: 31, 31, 31, 31, 31, 0, 31, 31, 31, 31, 31, 31, 31, 31, 31\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 282/1000 --- L(Train): 0.0168503 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + -0.001 chosen + -0.0 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.011 1 + 0.997 value_grooming[t] + 0.003 chosen + -0.001 sig_action + 0.004 sig_grooming + -0.004 sig_non_contact + -0.0 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 0.999 value_non_contact[t] + -0.001 chosen + 0.002 sig_action + -0.475 sig_grooming + 0.004 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + -0.002 prev_non_contact + -0.002 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + -0.0 chosen + -0.0 sig_action + 0.0 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + 0.0 chosen + 0.0 sig_action + -0.121 sig_grooming + 0.0 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.0 1 + 0.997 value_waiting[t] + 0.001 chosen + -0.0 sig_action + 0.001 sig_grooming + 0.217 sig_non_contact + -0.001 sig_contact + -0.002 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32\n",
            "value_grooming: 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32\n",
            "value_non_contact: 0, 32, 32, 32, 0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32\n",
            "value_contact: 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32\n",
            "value_scratch: 0, 32, 32, 32, 0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32\n",
            "value_waiting: 32, 32, 32, 32, 32, 0, 32, 32, 32, 32, 32, 32, 32, 32, 32\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 283/1000 --- L(Train): 0.0168340 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.002 value_action[t] + -0.0 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.01 1 + 0.997 value_grooming[t] + 0.005 chosen + -0.0 sig_action + 0.002 sig_grooming + -0.003 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.003 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 0.998 value_non_contact[t] + 0.001 chosen + 0.001 sig_action + -0.475 sig_grooming + 0.004 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.003 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.001 value_contact[t] + 0.001 chosen + 0.001 sig_action + -0.0 sig_grooming + -0.001 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.001 value_scratch[t] + -0.001 chosen + -0.001 sig_action + -0.121 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = -0.0 1 + 0.997 value_waiting[t] + -0.001 chosen + 0.001 sig_action + 0.001 sig_grooming + 0.217 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33\n",
            "value_grooming: 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33\n",
            "value_non_contact: 0, 33, 33, 33, 0, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33\n",
            "value_contact: 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33\n",
            "value_scratch: 0, 33, 33, 33, 0, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33\n",
            "value_waiting: 33, 33, 33, 33, 33, 0, 33, 33, 33, 33, 33, 33, 33, 33, 33\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 284/1000 --- L(Train): 0.0168117 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 1.003 value_action[t] + 0.002 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.009 1 + 0.997 value_grooming[t] + 0.006 chosen + 0.002 sig_action + 0.001 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 0.998 value_non_contact[t] + 0.002 chosen + -0.001 sig_action + -0.475 sig_grooming + 0.005 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.003 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + 0.001 chosen + 0.0 sig_action + -0.0 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.001 value_scratch[t] + -0.001 chosen + -0.001 sig_action + -0.121 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 0.998 value_waiting[t] + -0.001 chosen + 0.001 sig_action + -0.001 sig_grooming + 0.217 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34\n",
            "value_grooming: 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34\n",
            "value_non_contact: 0, 34, 34, 34, 0, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34\n",
            "value_contact: 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34\n",
            "value_scratch: 0, 34, 34, 34, 0, 34, 34, 34, 34, 34, 34, 34, 34, 34, 34\n",
            "value_waiting: 34, 34, 34, 34, 34, 0, 34, 34, 34, 34, 34, 34, 34, 34, 34\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 285/1000 --- L(Train): 0.0168355 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.002 value_action[t] + 0.002 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.008 1 + 0.999 value_grooming[t] + 0.007 chosen + 0.002 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + 0.003 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 0.998 value_non_contact[t] + 0.002 chosen + -0.001 sig_action + -0.475 sig_grooming + 0.004 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + 0.0 chosen + -0.001 sig_action + 0.0 sig_grooming + -0.0 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + 0.0 chosen + -0.0 sig_action + -0.121 sig_grooming + 0.0 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.005 1 + 0.999 value_waiting[t] + 0.0 chosen + -0.0 sig_action + -0.003 sig_grooming + 0.217 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35\n",
            "value_grooming: 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35\n",
            "value_non_contact: 0, 35, 35, 35, 0, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35\n",
            "value_contact: 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35\n",
            "value_scratch: 0, 35, 35, 35, 0, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35\n",
            "value_waiting: 35, 35, 35, 35, 35, 0, 35, 35, 35, 35, 35, 35, 35, 35, 35\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 286/1000 --- L(Train): 0.0168157 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.001 value_action[t] + 0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 1.001 value_grooming[t] + 0.008 chosen + 0.002 sig_action + 0.002 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 0.999 value_non_contact[t] + 0.002 chosen + -0.001 sig_action + -0.475 sig_grooming + 0.003 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 1.0 value_contact[t] + -0.002 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + -0.0 chosen + 0.002 sig_action + -0.121 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + -0.0 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + -0.002 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.007 1 + 1.001 value_waiting[t] + 0.0 chosen + 0.0 sig_action + -0.003 sig_grooming + 0.216 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36\n",
            "value_grooming: 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36\n",
            "value_non_contact: 0, 36, 36, 36, 0, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36\n",
            "value_contact: 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36\n",
            "value_scratch: 0, 36, 36, 36, 0, 36, 36, 36, 36, 36, 36, 36, 36, 36, 36\n",
            "value_waiting: 36, 36, 36, 36, 36, 0, 36, 36, 36, 36, 36, 36, 36, 36, 36\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 287/1000 --- L(Train): 0.0168178 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.998 value_action[t] + 0.001 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 1.002 value_grooming[t] + 0.008 chosen + 0.001 sig_action + 0.004 sig_grooming + -0.001 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 1.001 value_non_contact[t] + 0.001 chosen + 0.0 sig_action + -0.475 sig_grooming + 0.002 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.002 prev_grooming + 0.003 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 1.0 value_contact[t] + -0.002 chosen + 0.0 sig_action + -0.001 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + 0.001 chosen + 0.002 sig_action + -0.121 sig_grooming + 0.002 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + -0.002 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.008 1 + 1.002 value_waiting[t] + -0.001 chosen + -0.001 sig_action + -0.003 sig_grooming + 0.216 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37\n",
            "value_grooming: 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37\n",
            "value_non_contact: 0, 37, 37, 37, 0, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37\n",
            "value_contact: 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37\n",
            "value_scratch: 0, 37, 37, 37, 0, 37, 37, 37, 37, 37, 37, 37, 37, 37, 37\n",
            "value_waiting: 37, 37, 37, 37, 37, 0, 37, 37, 37, 37, 37, 37, 37, 37, 37\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 288/1000 --- L(Train): 0.0167806 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.997 value_action[t] + -0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 1.002 value_grooming[t] + 0.008 chosen + -0.002 sig_action + 0.006 sig_grooming + -0.002 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 1.0 value_non_contact[t] + 0.0 chosen + 0.0 sig_action + -0.475 sig_grooming + -0.0 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + -0.0 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 1.001 value_contact[t] + -0.002 chosen + -0.0 sig_action + -0.0 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.001 value_scratch[t] + 0.001 chosen + 0.002 sig_action + -0.121 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.003 prev_non_contact + -0.002 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.009 1 + 1.002 value_waiting[t] + -0.001 chosen + -0.001 sig_action + -0.003 sig_grooming + 0.215 sig_non_contact + -0.002 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.002 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38\n",
            "value_grooming: 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38\n",
            "value_non_contact: 0, 38, 38, 38, 0, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38\n",
            "value_contact: 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38\n",
            "value_scratch: 0, 38, 38, 38, 0, 38, 38, 38, 38, 38, 38, 38, 38, 38, 38\n",
            "value_waiting: 38, 38, 38, 38, 38, 0, 38, 38, 38, 38, 38, 38, 38, 38, 38\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 289/1000 --- L(Train): 0.0167917 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.996 value_action[t] + -0.003 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.0 1 + 1.0 value_grooming[t] + 0.008 chosen + -0.003 sig_action + 0.008 sig_grooming + -0.003 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.0 prev_non_contact + -0.003 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 0.998 value_non_contact[t] + -0.002 chosen + -0.001 sig_action + -0.475 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.003 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.001 value_contact[t] + -0.001 chosen + 0.001 sig_action + 0.0 sig_grooming + -0.001 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + -0.001 chosen + 0.001 sig_action + -0.121 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.009 1 + 1.001 value_waiting[t] + -0.0 chosen + 0.001 sig_action + -0.002 sig_grooming + 0.214 sig_non_contact + -0.003 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.003 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + -0.003 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39\n",
            "value_grooming: 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39\n",
            "value_non_contact: 0, 39, 39, 39, 0, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39\n",
            "value_contact: 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39\n",
            "value_scratch: 0, 39, 39, 39, 0, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39\n",
            "value_waiting: 39, 39, 39, 39, 39, 0, 39, 39, 39, 39, 39, 39, 39, 39, 39\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 290/1000 --- L(Train): 0.0167875 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 0.997 value_action[t] + -0.002 chosen + 0.002 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = -0.002 1 + 0.998 value_grooming[t] + 0.008 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.003 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.0 prev_non_contact + -0.003 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 0.997 value_non_contact[t] + -0.001 chosen + -0.0 sig_action + -0.475 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + -0.003 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.002 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.001 value_contact[t] + 0.002 chosen + 0.001 sig_action + -0.0 sig_grooming + -0.001 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 0.999 value_scratch[t] + -0.001 chosen + -0.002 sig_action + -0.121 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.003 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.009 1 + 0.999 value_waiting[t] + 0.002 chosen + 0.001 sig_action + -0.0 sig_grooming + 0.213 sig_non_contact + -0.003 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + -0.002 prev_contact + -0.003 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40\n",
            "value_grooming: 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40\n",
            "value_non_contact: 0, 40, 40, 40, 0, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40\n",
            "value_contact: 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40\n",
            "value_scratch: 0, 40, 40, 40, 0, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40\n",
            "value_waiting: 40, 40, 40, 40, 40, 0, 40, 40, 40, 40, 40, 40, 40, 40, 40\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 291/1000 --- L(Train): 0.0167913 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.998 value_action[t] + -0.001 chosen + 0.003 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + -0.003 prev_non_contact + -0.0 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_grooming[t+1] = -0.001 1 + 0.997 value_grooming[t] + 0.008 chosen + -0.001 sig_action + 0.01 sig_grooming + -0.002 sig_non_contact + 0.003 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 0.996 value_non_contact[t] + 0.001 chosen + 0.001 sig_action + -0.475 sig_grooming + 0.003 sig_non_contact + -0.0 sig_contact + -0.002 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 0.999 value_contact[t] + 0.003 chosen + -0.001 sig_action + -0.0 sig_grooming + -0.001 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.003 sig_waiting + 0.003 prev_action + -0.001 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 0.998 value_scratch[t] + 0.0 chosen + -0.003 sig_action + -0.121 sig_grooming + 0.0 sig_non_contact + 0.003 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.003 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.008 1 + 0.998 value_waiting[t] + 0.002 chosen + -0.0 sig_action + 0.002 sig_grooming + 0.211 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.003 prev_non_contact + -0.003 prev_contact + -0.002 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41\n",
            "value_grooming: 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41\n",
            "value_non_contact: 0, 41, 41, 41, 0, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41\n",
            "value_contact: 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41\n",
            "value_scratch: 0, 41, 41, 41, 0, 41, 41, 41, 41, 41, 41, 41, 41, 41, 41\n",
            "value_waiting: 41, 41, 41, 41, 41, 0, 41, 41, 41, 41, 41, 41, 41, 41, 41\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 292/1000 --- L(Train): 0.0167635 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + 0.001 chosen + 0.002 sig_action + 0.009 sig_grooming + -0.018 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.003 prev_non_contact + 0.0 prev_contact + -0.003 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 0.997 value_grooming[t] + 0.007 chosen + 0.001 sig_action + 0.01 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.376 1 + 0.996 value_non_contact[t] + 0.002 chosen + 0.001 sig_action + -0.475 sig_grooming + 0.004 sig_non_contact + 0.002 sig_contact + -0.002 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 0.998 value_contact[t] + 0.003 chosen + -0.001 sig_action + 0.0 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.003 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 0.999 value_scratch[t] + -0.0 chosen + -0.002 sig_action + -0.121 sig_grooming + 0.0 sig_non_contact + 0.003 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.003 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.007 1 + 0.998 value_waiting[t] + 0.002 chosen + 0.0 sig_action + 0.001 sig_grooming + 0.21 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + -0.003 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42\n",
            "value_grooming: 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42\n",
            "value_non_contact: 0, 42, 42, 42, 0, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42\n",
            "value_contact: 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42\n",
            "value_scratch: 0, 42, 42, 42, 0, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42\n",
            "value_waiting: 42, 42, 42, 42, 42, 0, 42, 42, 42, 42, 42, 42, 42, 42, 42\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 293/1000 --- L(Train): 0.0167250 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.001 value_action[t] + 0.001 chosen + 0.001 sig_action + 0.009 sig_grooming + -0.018 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 0.998 value_grooming[t] + 0.006 chosen + 0.001 sig_action + 0.01 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.375 1 + 0.996 value_non_contact[t] + 0.003 chosen + -0.0 sig_action + -0.475 sig_grooming + 0.004 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 0.999 value_contact[t] + 0.001 chosen + 0.0 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + 0.001 chosen + -0.001 sig_action + -0.122 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.006 1 + 0.999 value_waiting[t] + 0.001 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.209 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43\n",
            "value_grooming: 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43\n",
            "value_non_contact: 0, 43, 43, 43, 0, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43\n",
            "value_contact: 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43\n",
            "value_scratch: 0, 43, 43, 43, 0, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43\n",
            "value_waiting: 43, 43, 43, 43, 43, 0, 43, 43, 43, 43, 43, 43, 43, 43, 43\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 294/1000 --- L(Train): 0.0167151 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.001 value_action[t] + 0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.018 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.007 1 + 1.0 value_grooming[t] + 0.005 chosen + 0.001 sig_action + 0.01 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.375 1 + 0.997 value_non_contact[t] + 0.003 chosen + 0.0 sig_action + -0.475 sig_grooming + 0.003 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + -0.001 chosen + 0.0 sig_action + -0.002 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.001 value_scratch[t] + 0.001 chosen + 0.001 sig_action + -0.122 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.004 1 + 1.001 value_waiting[t] + -0.002 chosen + -0.001 sig_action + -0.002 sig_grooming + 0.208 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44\n",
            "value_grooming: 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44\n",
            "value_non_contact: 0, 44, 44, 44, 0, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44\n",
            "value_contact: 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44\n",
            "value_scratch: 0, 44, 44, 44, 0, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44\n",
            "value_waiting: 44, 44, 44, 44, 44, 0, 44, 44, 44, 44, 44, 44, 44, 44, 44\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 295/1000 --- L(Train): 0.0166847 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.999 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.008 1 + 1.003 value_grooming[t] + 0.004 chosen + -0.0 sig_action + 0.01 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.375 1 + 0.999 value_non_contact[t] + 0.002 chosen + -0.001 sig_action + -0.475 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.003 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.001 value_contact[t] + -0.001 chosen + -0.001 sig_action + -0.002 sig_grooming + 0.0 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.002 value_scratch[t] + -0.001 chosen + 0.001 sig_action + -0.122 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 1.002 value_waiting[t] + -0.003 chosen + 0.001 sig_action + -0.003 sig_grooming + 0.207 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45\n",
            "value_grooming: 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45\n",
            "value_non_contact: 0, 45, 45, 45, 0, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45\n",
            "value_contact: 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45\n",
            "value_scratch: 0, 45, 45, 45, 0, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45\n",
            "value_waiting: 45, 45, 45, 45, 45, 0, 45, 45, 45, 45, 45, 45, 45, 45, 45\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 296/1000 --- L(Train): 0.0166740 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 0.999 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.008 1 + 1.004 value_grooming[t] + 0.003 chosen + -0.0 sig_action + 0.009 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.375 1 + 1.001 value_non_contact[t] + 0.001 chosen + -0.001 sig_action + -0.475 sig_grooming + -0.0 sig_non_contact + -0.002 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + -0.001 chosen + -0.001 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.001 value_scratch[t] + -0.001 chosen + 0.001 sig_action + -0.122 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.001 value_waiting[t] + -0.002 chosen + 0.001 sig_action + -0.003 sig_grooming + 0.207 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46\n",
            "value_grooming: 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46\n",
            "value_non_contact: 0, 46, 46, 46, 0, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46\n",
            "value_contact: 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46\n",
            "value_scratch: 0, 46, 46, 46, 0, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46\n",
            "value_waiting: 46, 46, 46, 46, 46, 0, 46, 46, 46, 46, 46, 46, 46, 46, 46\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 297/1000 --- L(Train): 0.0166747 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.999 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.008 1 + 1.004 value_grooming[t] + 0.001 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.003 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.003 prev_waiting \n",
            "value_non_contact[t+1] = -0.375 1 + 1.001 value_non_contact[t] + -0.001 chosen + 0.001 sig_action + -0.475 sig_grooming + 0.0 sig_non_contact + -0.003 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] + 0.0 chosen + -0.0 sig_action + 0.0 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 0.998 value_scratch[t] + 0.0 chosen + -0.0 sig_action + -0.122 sig_grooming + 0.0 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 0.999 value_waiting[t] + -0.001 chosen + -0.0 sig_action + -0.003 sig_grooming + 0.207 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + 0.003 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47\n",
            "value_grooming: 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47\n",
            "value_non_contact: 0, 47, 47, 47, 0, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47\n",
            "value_contact: 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47\n",
            "value_scratch: 0, 47, 47, 47, 0, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47\n",
            "value_waiting: 47, 47, 47, 47, 47, 0, 47, 47, 47, 47, 47, 47, 47, 47, 47\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 298/1000 --- L(Train): 0.0166421 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.009 sig_grooming + -0.018 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.008 1 + 1.003 value_grooming[t] + -0.0 chosen + 0.0 sig_action + 0.007 sig_grooming + -0.003 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + -0.003 prev_waiting \n",
            "value_non_contact[t+1] = -0.375 1 + 0.999 value_non_contact[t] + -0.0 chosen + 0.001 sig_action + -0.475 sig_grooming + -0.0 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] + 0.0 chosen + 0.002 sig_action + -0.0 sig_grooming + 0.0 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 0.997 value_scratch[t] + 0.0 chosen + -0.0 sig_action + -0.122 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 0.999 value_waiting[t] + 0.001 chosen + -0.0 sig_action + -0.001 sig_grooming + 0.207 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + -0.0 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48\n",
            "value_grooming: 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48\n",
            "value_non_contact: 0, 48, 48, 48, 0, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48\n",
            "value_contact: 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48\n",
            "value_scratch: 0, 48, 48, 48, 0, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48\n",
            "value_waiting: 48, 48, 48, 48, 48, 0, 48, 48, 48, 48, 48, 48, 48, 48, 48\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 299/1000 --- L(Train): 0.0166343 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + -0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.018 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.007 1 + 1.001 value_grooming[t] + 0.002 chosen + -0.001 sig_action + 0.006 sig_grooming + -0.003 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.375 1 + 0.998 value_non_contact[t] + 0.002 chosen + -0.0 sig_action + -0.475 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + -0.001 chosen + 0.002 sig_action + 0.0 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 0.997 value_scratch[t] + -0.001 chosen + 0.001 sig_action + -0.122 sig_grooming + -0.0 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.0 value_waiting[t] + 0.001 chosen + 0.001 sig_action + 0.0 sig_grooming + 0.207 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49\n",
            "value_grooming: 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49\n",
            "value_non_contact: 0, 49, 49, 49, 0, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49\n",
            "value_contact: 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49\n",
            "value_scratch: 0, 49, 49, 49, 0, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49\n",
            "value_waiting: 49, 49, 49, 49, 49, 0, 49, 49, 49, 49, 49, 49, 49, 49, 49\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 300/1000 --- L(Train): 0.0166455 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.999 value_action[t] + -0.001 chosen + -0.0 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 0.998 value_grooming[t] + 0.005 chosen + -0.001 sig_action + 0.005 sig_grooming + -0.002 sig_non_contact + -0.0 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.375 1 + 0.998 value_non_contact[t] + 0.004 chosen + -0.0 sig_action + -0.475 sig_grooming + 0.003 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 0.999 value_contact[t] + -0.0 chosen + 0.002 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 0.997 value_scratch[t] + -0.001 chosen + 0.0 sig_action + -0.122 sig_grooming + 0.002 sig_non_contact + -0.0 sig_contact + -0.002 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.001 value_waiting[t] + 0.001 chosen + 0.001 sig_action + -0.0 sig_grooming + 0.208 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50\n",
            "value_grooming: 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50\n",
            "value_non_contact: 0, 50, 50, 50, 0, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50\n",
            "value_contact: 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50\n",
            "value_scratch: 0, 50, 50, 50, 0, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50\n",
            "value_waiting: 50, 50, 50, 50, 50, 0, 50, 50, 50, 50, 50, 50, 50, 50, 50\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 301/1000 --- L(Train): 0.0166295 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.999 value_action[t] + -0.0 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.004 1 + 0.996 value_grooming[t] + 0.006 chosen + -0.0 sig_action + 0.004 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.375 1 + 0.998 value_non_contact[t] + 0.004 chosen + 0.001 sig_action + -0.475 sig_grooming + 0.003 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + 0.001 chosen + 0.001 sig_action + -0.002 sig_grooming + -0.001 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 0.999 value_scratch[t] + -0.0 chosen + -0.001 sig_action + -0.122 sig_grooming + 0.003 sig_non_contact + 0.001 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.001 value_waiting[t] + -0.0 chosen + 0.0 sig_action + -0.0 sig_grooming + 0.209 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51\n",
            "value_grooming: 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51\n",
            "value_non_contact: 0, 51, 51, 51, 0, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51\n",
            "value_contact: 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51\n",
            "value_scratch: 0, 51, 51, 51, 0, 51, 51, 51, 51, 51, 51, 51, 51, 51, 51\n",
            "value_waiting: 51, 51, 51, 51, 51, 0, 51, 51, 51, 51, 51, 51, 51, 51, 51\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 302/1000 --- L(Train): 0.0166100 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 1.0 value_action[t] + 0.002 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 0.996 value_grooming[t] + 0.008 chosen + 0.002 sig_action + 0.002 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.375 1 + 0.999 value_non_contact[t] + 0.004 chosen + 0.001 sig_action + -0.475 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.001 value_contact[t] + 0.001 chosen + -0.002 sig_action + -0.002 sig_grooming + 0.0 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.001 value_scratch[t] + 0.002 chosen + -0.001 sig_action + -0.122 sig_grooming + 0.004 sig_non_contact + 0.001 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + -0.003 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.0 value_waiting[t] + -0.0 chosen + -0.002 sig_action + 0.001 sig_grooming + 0.21 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52\n",
            "value_grooming: 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52\n",
            "value_non_contact: 0, 52, 52, 52, 0, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52\n",
            "value_contact: 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52\n",
            "value_scratch: 0, 52, 52, 52, 0, 52, 52, 52, 52, 52, 52, 52, 52, 52, 52\n",
            "value_waiting: 52, 52, 52, 52, 52, 0, 52, 52, 52, 52, 52, 52, 52, 52, 52\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 303/1000 --- L(Train): 0.0166495 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.001 value_action[t] + 0.002 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + -0.002 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 0.996 value_grooming[t] + 0.009 chosen + 0.002 sig_action + 0.001 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.375 1 + 1.0 value_non_contact[t] + 0.004 chosen + 0.0 sig_action + -0.475 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.002 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.002 value_contact[t] + -0.0 chosen + -0.003 sig_action + -0.002 sig_grooming + 0.0 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.001 value_scratch[t] + 0.002 chosen + 0.0 sig_action + -0.122 sig_grooming + 0.004 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + -0.003 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 0.999 value_waiting[t] + 0.001 chosen + -0.002 sig_action + -0.001 sig_grooming + 0.211 sig_non_contact + 0.002 sig_contact + -0.0 sig_scratch + -0.003 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + -0.003 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53\n",
            "value_grooming: 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53\n",
            "value_non_contact: 0, 53, 53, 53, 0, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53\n",
            "value_contact: 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53\n",
            "value_scratch: 0, 53, 53, 53, 0, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53\n",
            "value_waiting: 53, 53, 53, 53, 53, 0, 53, 53, 53, 53, 53, 53, 53, 53, 53\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 304/1000 --- L(Train): 0.0166316 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.002 value_action[t] + 0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.0 prev_non_contact + -0.002 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = -0.0 1 + 0.997 value_grooming[t] + 0.01 chosen + 0.002 sig_action + -0.0 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.375 1 + 1.0 value_non_contact[t] + 0.003 chosen + -0.002 sig_action + -0.475 sig_grooming + -0.0 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + -0.0 prev_grooming + -0.002 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.001 value_contact[t] + 0.0 chosen + -0.002 sig_action + -0.0 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + 0.002 chosen + 0.0 sig_action + -0.122 sig_grooming + 0.004 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 0.998 value_waiting[t] + 0.0 chosen + -0.002 sig_action + -0.001 sig_grooming + 0.212 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + -0.003 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54\n",
            "value_grooming: 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54\n",
            "value_non_contact: 0, 54, 54, 54, 0, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54\n",
            "value_contact: 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54\n",
            "value_scratch: 0, 54, 54, 54, 0, 54, 54, 54, 54, 54, 54, 54, 54, 54, 54\n",
            "value_waiting: 54, 54, 54, 54, 54, 0, 54, 54, 54, 54, 54, 54, 54, 54, 54\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 305/1000 --- L(Train): 0.0166455 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.001 value_action[t] + 0.001 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.0 value_grooming[t] + 0.011 chosen + 0.001 sig_action + 0.003 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.374 1 + 1.0 value_non_contact[t] + 0.001 chosen + -0.002 sig_action + -0.475 sig_grooming + 0.0 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 0.999 value_contact[t] + -0.001 chosen + -0.001 sig_action + 0.001 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.998 value_scratch[t] + 0.001 chosen + -0.001 sig_action + -0.122 sig_grooming + 0.003 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 0.998 value_waiting[t] + -0.001 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.213 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55\n",
            "value_grooming: 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55\n",
            "value_non_contact: 0, 55, 55, 55, 0, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55\n",
            "value_contact: 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55\n",
            "value_scratch: 0, 55, 55, 55, 0, 55, 55, 55, 55, 55, 55, 55, 55, 55, 55\n",
            "value_waiting: 55, 55, 55, 55, 55, 0, 55, 55, 55, 55, 55, 55, 55, 55, 55\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 306/1000 --- L(Train): 0.0166114 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.999 value_action[t] + -0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 1.002 value_grooming[t] + 0.012 chosen + -0.002 sig_action + 0.006 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.374 1 + 1.001 value_non_contact[t] + -0.001 chosen + -0.002 sig_action + -0.475 sig_grooming + 0.0 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 0.999 value_contact[t] + -0.0 chosen + 0.001 sig_action + 0.001 sig_grooming + -0.0 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.997 value_scratch[t] + -0.002 chosen + -0.001 sig_action + -0.122 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 0.999 value_waiting[t] + -0.001 chosen + 0.002 sig_action + -0.0 sig_grooming + 0.214 sig_non_contact + -0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56\n",
            "value_grooming: 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56\n",
            "value_non_contact: 0, 56, 56, 56, 0, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56\n",
            "value_contact: 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56\n",
            "value_scratch: 0, 56, 56, 56, 0, 56, 56, 56, 56, 56, 56, 56, 56, 56, 56\n",
            "value_waiting: 56, 56, 56, 56, 56, 0, 56, 56, 56, 56, 56, 56, 56, 56, 56\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 307/1000 --- L(Train): 0.0166229 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.998 value_action[t] + -0.003 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + 0.003 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 1.004 value_grooming[t] + 0.012 chosen + -0.003 sig_action + 0.008 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.0 prev_non_contact + -0.003 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.374 1 + 0.999 value_non_contact[t] + -0.001 chosen + -0.001 sig_action + -0.475 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + -0.003 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 0.999 value_contact[t] + 0.001 chosen + 0.001 sig_action + -0.001 sig_grooming + 0.002 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.997 value_scratch[t] + -0.003 chosen + -0.0 sig_action + -0.122 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + -0.003 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 1.001 value_waiting[t] + 0.0 chosen + 0.003 sig_action + 0.001 sig_grooming + 0.215 sig_non_contact + -0.003 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57\n",
            "value_grooming: 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57\n",
            "value_non_contact: 0, 57, 57, 57, 0, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57\n",
            "value_contact: 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57\n",
            "value_scratch: 0, 57, 57, 57, 0, 57, 57, 57, 57, 57, 57, 57, 57, 57, 57\n",
            "value_waiting: 57, 57, 57, 57, 57, 0, 57, 57, 57, 57, 57, 57, 57, 57, 57\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 308/1000 --- L(Train): 0.0166123 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 0.998 value_action[t] + -0.002 chosen + 0.002 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 1.004 value_grooming[t] + 0.012 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.0 prev_non_contact + -0.003 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.374 1 + 0.999 value_non_contact[t] + 0.001 chosen + 0.002 sig_action + -0.475 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + -0.003 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.001 value_contact[t] + 0.001 chosen + 0.001 sig_action + -0.002 sig_grooming + 0.002 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.998 value_scratch[t] + -0.002 chosen + 0.002 sig_action + -0.122 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + -0.0 sig_scratch + -0.002 sig_waiting + -0.003 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.002 value_waiting[t] + -0.0 chosen + 0.003 sig_action + 0.0 sig_grooming + 0.216 sig_non_contact + -0.003 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58\n",
            "value_grooming: 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58\n",
            "value_non_contact: 0, 58, 58, 58, 0, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58\n",
            "value_contact: 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58\n",
            "value_scratch: 0, 58, 58, 58, 0, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58\n",
            "value_waiting: 58, 58, 58, 58, 58, 0, 58, 58, 58, 58, 58, 58, 58, 58, 58\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 309/1000 --- L(Train): 0.0166264 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.999 value_action[t] + -0.001 chosen + 0.003 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 1.003 value_grooming[t] + 0.011 chosen + -0.001 sig_action + 0.011 sig_grooming + -0.0 sig_non_contact + -0.0 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.374 1 + 0.999 value_non_contact[t] + 0.002 chosen + 0.003 sig_action + -0.475 sig_grooming + 0.002 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.003 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + 0.003 prev_non_contact + -0.003 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.001 value_contact[t] + -0.0 chosen + -0.0 sig_action + -0.002 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.003 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + 0.003 prev_contact + 0.003 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + -0.001 chosen + 0.002 sig_action + -0.122 sig_grooming + 0.001 sig_non_contact + 0.003 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + 0.003 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.002 value_waiting[t] + 0.001 chosen + 0.001 sig_action + -0.002 sig_grooming + 0.216 sig_non_contact + -0.001 sig_contact + -0.003 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59\n",
            "value_grooming: 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59\n",
            "value_non_contact: 0, 59, 59, 59, 0, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59\n",
            "value_contact: 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59\n",
            "value_scratch: 0, 59, 59, 59, 0, 59, 59, 59, 59, 59, 59, 59, 59, 59, 59\n",
            "value_waiting: 59, 59, 59, 59, 59, 0, 59, 59, 59, 59, 59, 59, 59, 59, 59\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 310/1000 --- L(Train): 0.0166046 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.001 value_action[t] + 0.001 chosen + 0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.002 value_grooming[t] + 0.011 chosen + 0.001 sig_action + 0.011 sig_grooming + 0.002 sig_non_contact + -0.0 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.374 1 + 1.0 value_non_contact[t] + 0.003 chosen + 0.002 sig_action + -0.475 sig_grooming + 0.002 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.003 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 1.0 value_contact[t] + 0.0 chosen + -0.0 sig_action + -0.002 sig_grooming + -0.0 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.003 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.001 value_scratch[t] + 0.001 chosen + 0.002 sig_action + -0.122 sig_grooming + 0.002 sig_non_contact + 0.003 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 1.0 value_waiting[t] + 0.001 chosen + -0.001 sig_action + -0.004 sig_grooming + 0.217 sig_non_contact + 0.0 sig_contact + -0.002 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60\n",
            "value_grooming: 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60\n",
            "value_non_contact: 0, 60, 60, 60, 0, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60\n",
            "value_contact: 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60\n",
            "value_scratch: 0, 60, 60, 60, 0, 60, 60, 60, 60, 60, 60, 60, 60, 60, 60\n",
            "value_waiting: 60, 60, 60, 60, 60, 0, 60, 60, 60, 60, 60, 60, 60, 60, 60\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 311/1000 --- L(Train): 0.0165658 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.001 value_action[t] + 0.001 chosen + 0.001 sig_action + 0.01 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = -0.0 1 + 0.999 value_grooming[t] + 0.01 chosen + 0.001 sig_action + 0.012 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.374 1 + 1.001 value_non_contact[t] + 0.003 chosen + 0.001 sig_action + -0.475 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 0.999 value_contact[t] + -0.001 chosen + 0.001 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.002 value_scratch[t] + 0.001 chosen + 0.001 sig_action + -0.122 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 0.998 value_waiting[t] + -0.001 chosen + -0.001 sig_action + -0.005 sig_grooming + 0.217 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61\n",
            "value_grooming: 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61\n",
            "value_non_contact: 0, 61, 61, 61, 0, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61\n",
            "value_contact: 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61\n",
            "value_scratch: 0, 61, 61, 61, 0, 61, 61, 61, 61, 61, 61, 61, 61, 61, 61\n",
            "value_waiting: 61, 61, 61, 61, 61, 0, 61, 61, 61, 61, 61, 61, 61, 61, 61\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 312/1000 --- L(Train): 0.0165592 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.001 value_action[t] + 0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 0.998 value_grooming[t] + 0.009 chosen + 0.001 sig_action + 0.012 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.374 1 + 1.0 value_non_contact[t] + 0.002 chosen + -0.001 sig_action + -0.475 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 0.998 value_contact[t] + -0.001 chosen + 0.0 sig_action + 0.0 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.001 value_scratch[t] + 0.001 chosen + -0.002 sig_action + -0.122 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 0.997 value_waiting[t] + -0.001 chosen + -0.001 sig_action + -0.005 sig_grooming + 0.217 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62\n",
            "value_grooming: 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62\n",
            "value_non_contact: 0, 62, 62, 62, 0, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62\n",
            "value_contact: 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62\n",
            "value_scratch: 0, 62, 62, 62, 0, 62, 62, 62, 62, 62, 62, 62, 62, 62, 62\n",
            "value_waiting: 62, 62, 62, 62, 62, 0, 62, 62, 62, 62, 62, 62, 62, 62, 62\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 313/1000 --- L(Train): 0.0165220 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.999 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 0.997 value_grooming[t] + 0.007 chosen + -0.0 sig_action + 0.011 sig_grooming + -0.002 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.374 1 + 0.998 value_non_contact[t] + 0.001 chosen + -0.001 sig_action + -0.476 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 0.999 value_contact[t] + 0.001 chosen + -0.001 sig_action + 0.0 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + -0.0 chosen + -0.003 sig_action + -0.122 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.0 1 + 0.997 value_waiting[t] + 0.0 chosen + 0.0 sig_action + -0.005 sig_grooming + 0.217 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63\n",
            "value_grooming: 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63\n",
            "value_non_contact: 0, 63, 63, 63, 0, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63\n",
            "value_contact: 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63\n",
            "value_scratch: 0, 63, 63, 63, 0, 63, 63, 63, 63, 63, 63, 63, 63, 63, 63\n",
            "value_waiting: 63, 63, 63, 63, 63, 0, 63, 63, 63, 63, 63, 63, 63, 63, 63\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 314/1000 --- L(Train): 0.0165095 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 0.998 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 0.998 value_grooming[t] + 0.006 chosen + -0.0 sig_action + 0.011 sig_grooming + -0.002 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.374 1 + 0.996 value_non_contact[t] + -0.001 chosen + -0.001 sig_action + -0.476 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] + 0.001 chosen + -0.001 sig_action + -0.002 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.998 value_scratch[t] + -0.0 chosen + -0.002 sig_action + -0.122 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.0 1 + 0.998 value_waiting[t] + -0.0 chosen + 0.0 sig_action + -0.004 sig_grooming + 0.217 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64\n",
            "value_grooming: 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64\n",
            "value_non_contact: 0, 64, 64, 64, 0, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64\n",
            "value_contact: 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64\n",
            "value_scratch: 0, 64, 64, 64, 0, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64\n",
            "value_waiting: 64, 64, 64, 64, 64, 0, 64, 64, 64, 64, 64, 64, 64, 64, 64\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 315/1000 --- L(Train): 0.0165054 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.998 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 0.999 value_grooming[t] + 0.004 chosen + 0.001 sig_action + 0.01 sig_grooming + -0.002 sig_non_contact + -0.002 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.374 1 + 0.995 value_non_contact[t] + -0.0 chosen + 0.0 sig_action + -0.476 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.001 value_contact[t] + -0.0 chosen + 0.0 sig_action + -0.003 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.002 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.998 value_scratch[t] + 0.001 chosen + -0.001 sig_action + -0.122 sig_grooming + -0.0 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = -0.0 1 + 0.999 value_waiting[t] + 0.001 chosen + -0.001 sig_action + -0.002 sig_grooming + 0.217 sig_non_contact + 0.0 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + 0.003 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65\n",
            "value_grooming: 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65\n",
            "value_non_contact: 0, 65, 65, 65, 0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65\n",
            "value_contact: 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65\n",
            "value_scratch: 0, 65, 65, 65, 0, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65\n",
            "value_waiting: 65, 65, 65, 65, 65, 0, 65, 65, 65, 65, 65, 65, 65, 65, 65\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 316/1000 --- L(Train): 0.0164779 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.999 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.009 sig_grooming + -0.018 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 1.002 value_grooming[t] + 0.003 chosen + 0.0 sig_action + 0.009 sig_grooming + -0.002 sig_non_contact + -0.002 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.374 1 + 0.995 value_non_contact[t] + 0.002 chosen + 0.0 sig_action + -0.476 sig_grooming + -0.0 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + -0.0 chosen + -0.0 sig_action + -0.003 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.998 value_scratch[t] + 0.0 chosen + 0.001 sig_action + -0.122 sig_grooming + 0.002 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 1.002 value_waiting[t] + 0.001 chosen + -0.0 sig_action + -0.0 sig_grooming + 0.217 sig_non_contact + 0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66\n",
            "value_grooming: 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66\n",
            "value_non_contact: 0, 66, 66, 66, 0, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66\n",
            "value_contact: 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66\n",
            "value_scratch: 0, 66, 66, 66, 0, 66, 66, 66, 66, 66, 66, 66, 66, 66, 66\n",
            "value_waiting: 66, 66, 66, 66, 66, 0, 66, 66, 66, 66, 66, 66, 66, 66, 66\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 317/1000 --- L(Train): 0.0164667 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.001 value_action[t] + -0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.018 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.003 value_grooming[t] + 0.001 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 0.995 value_non_contact[t] + 0.003 chosen + -0.001 sig_action + -0.476 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 0.999 value_contact[t] + 0.001 chosen + 0.001 sig_action + -0.003 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + -0.001 chosen + 0.001 sig_action + -0.122 sig_grooming + 0.003 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.006 1 + 1.003 value_waiting[t] + -0.001 chosen + 0.001 sig_action + 0.002 sig_grooming + 0.217 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67\n",
            "value_grooming: 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67\n",
            "value_non_contact: 0, 67, 67, 67, 0, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67\n",
            "value_contact: 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67\n",
            "value_scratch: 0, 67, 67, 67, 0, 67, 67, 67, 67, 67, 67, 67, 67, 67, 67\n",
            "value_waiting: 67, 67, 67, 67, 67, 0, 67, 67, 67, 67, 67, 67, 67, 67, 67\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 318/1000 --- L(Train): 0.0164869 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.002 value_action[t] + -0.001 chosen + -0.0 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.002 value_grooming[t] + -0.0 chosen + -0.001 sig_action + 0.007 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 0.997 value_non_contact[t] + 0.003 chosen + -0.0 sig_action + -0.476 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.002 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 0.998 value_contact[t] + 0.001 chosen + 0.001 sig_action + -0.002 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.002 value_scratch[t] + -0.001 chosen + 0.001 sig_action + -0.122 sig_grooming + 0.004 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.008 1 + 1.003 value_waiting[t] + -0.001 chosen + 0.001 sig_action + 0.003 sig_grooming + 0.216 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68\n",
            "value_grooming: 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68\n",
            "value_non_contact: 0, 68, 68, 68, 0, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68\n",
            "value_contact: 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68\n",
            "value_scratch: 0, 68, 68, 68, 0, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68\n",
            "value_waiting: 68, 68, 68, 68, 68, 0, 68, 68, 68, 68, 68, 68, 68, 68, 68\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 319/1000 --- L(Train): 0.0164800 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.001 value_action[t] + -0.0 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.0 1 + 1.001 value_grooming[t] + 0.002 chosen + -0.0 sig_action + 0.006 sig_grooming + 0.001 sig_non_contact + 0.003 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + 0.003 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 0.998 value_non_contact[t] + 0.003 chosen + 0.001 sig_action + -0.476 sig_grooming + 0.0 sig_non_contact + -0.0 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + -0.003 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 0.999 value_contact[t] + 0.0 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.0 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.003 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.002 value_scratch[t] + 0.0 chosen + -0.0 sig_action + -0.122 sig_grooming + 0.004 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_waiting[t+1] = 0.009 1 + 1.002 value_waiting[t] + 0.0 chosen + -0.0 sig_action + 0.001 sig_grooming + 0.216 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69\n",
            "value_grooming: 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69\n",
            "value_non_contact: 0, 69, 69, 69, 0, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69\n",
            "value_contact: 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69\n",
            "value_scratch: 0, 69, 69, 69, 0, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69\n",
            "value_waiting: 69, 69, 69, 69, 69, 0, 69, 69, 69, 69, 69, 69, 69, 69, 69\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 320/1000 --- L(Train): 0.0164565 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 1.0 value_action[t] + 0.002 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = -0.0 1 + 0.999 value_grooming[t] + 0.005 chosen + 0.002 sig_action + 0.005 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.0 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 1.0 value_non_contact[t] + 0.003 chosen + 0.001 sig_action + -0.476 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 1.0 value_contact[t] + -0.002 chosen + -0.001 sig_action + 0.001 sig_grooming + 0.0 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.002 value_scratch[t] + -0.0 chosen + -0.0 sig_action + -0.122 sig_grooming + 0.003 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.01 1 + 1.0 value_waiting[t] + 0.0 chosen + 0.0 sig_action + -0.003 sig_grooming + 0.215 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70\n",
            "value_grooming: 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70\n",
            "value_non_contact: 0, 70, 70, 70, 0, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70\n",
            "value_contact: 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70\n",
            "value_scratch: 0, 70, 70, 70, 0, 70, 70, 70, 70, 70, 70, 70, 70, 70, 70\n",
            "value_waiting: 70, 70, 70, 70, 70, 0, 70, 70, 70, 70, 70, 70, 70, 70, 70\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 321/1000 --- L(Train): 0.0164984 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.999 value_action[t] + 0.002 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 0.998 value_grooming[t] + 0.007 chosen + 0.002 sig_action + 0.005 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 1.0 value_non_contact[t] + 0.001 chosen + -0.0 sig_action + -0.476 sig_grooming + 0.0 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.001 value_contact[t] + -0.002 chosen + 0.0 sig_action + 0.001 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + 0.001 chosen + 0.001 sig_action + -0.121 sig_grooming + 0.002 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.01 1 + 0.997 value_waiting[t] + -0.001 chosen + -0.001 sig_action + -0.005 sig_grooming + 0.213 sig_non_contact + 0.002 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71\n",
            "value_grooming: 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71\n",
            "value_non_contact: 0, 71, 71, 71, 0, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71\n",
            "value_contact: 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71\n",
            "value_scratch: 0, 71, 71, 71, 0, 71, 71, 71, 71, 71, 71, 71, 71, 71, 71\n",
            "value_waiting: 71, 71, 71, 71, 71, 0, 71, 71, 71, 71, 71, 71, 71, 71, 71\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 322/1000 --- L(Train): 0.0164910 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.999 value_action[t] + 0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 0.998 value_grooming[t] + 0.009 chosen + 0.002 sig_action + 0.004 sig_grooming + -0.003 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 0.998 value_non_contact[t] + -0.0 chosen + 0.0 sig_action + -0.476 sig_grooming + 0.0 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] + -0.002 chosen + 0.0 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + 0.001 chosen + 0.0 sig_action + -0.121 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.009 1 + 0.996 value_waiting[t] + -0.001 chosen + -0.0 sig_action + -0.007 sig_grooming + 0.212 sig_non_contact + 0.002 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.002 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72\n",
            "value_grooming: 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72\n",
            "value_non_contact: 0, 72, 72, 72, 0, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72\n",
            "value_contact: 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72\n",
            "value_scratch: 0, 72, 72, 72, 0, 72, 72, 72, 72, 72, 72, 72, 72, 72, 72\n",
            "value_waiting: 72, 72, 72, 72, 72, 0, 72, 72, 72, 72, 72, 72, 72, 72, 72\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 323/1000 --- L(Train): 0.0164918 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + 0.001 chosen + -0.002 sig_action + 0.01 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 0.999 value_grooming[t] + 0.011 chosen + 0.001 sig_action + 0.003 sig_grooming + -0.003 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 0.997 value_non_contact[t] + 0.0 chosen + -0.001 sig_action + -0.476 sig_grooming + 0.0 sig_non_contact + 0.001 sig_contact + 0.003 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 0.999 value_contact[t] + -0.001 chosen + -0.001 sig_action + -0.002 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + -0.001 chosen + -0.001 sig_action + -0.121 sig_grooming + -0.001 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.009 1 + 0.995 value_waiting[t] + -0.0 chosen + 0.001 sig_action + -0.008 sig_grooming + 0.21 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.003 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73\n",
            "value_grooming: 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73\n",
            "value_non_contact: 0, 73, 73, 73, 0, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73\n",
            "value_contact: 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73\n",
            "value_scratch: 0, 73, 73, 73, 0, 73, 73, 73, 73, 73, 73, 73, 73, 73, 73\n",
            "value_waiting: 73, 73, 73, 73, 73, 0, 73, 73, 73, 73, 73, 73, 73, 73, 73\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 324/1000 --- L(Train): 0.0164629 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + -0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 1.001 value_grooming[t] + 0.012 chosen + -0.002 sig_action + 0.001 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + -0.002 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 0.997 value_non_contact[t] + -0.0 chosen + -0.001 sig_action + -0.476 sig_grooming + -0.001 sig_non_contact + -0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 0.998 value_contact[t] + 0.002 chosen + -0.001 sig_action + -0.002 sig_grooming + 0.0 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + -0.001 chosen + -0.001 sig_action + -0.121 sig_grooming + -0.001 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.008 1 + 0.996 value_waiting[t] + 0.002 chosen + 0.001 sig_action + -0.008 sig_grooming + 0.209 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74\n",
            "value_grooming: 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74\n",
            "value_non_contact: 0, 74, 74, 74, 0, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74\n",
            "value_contact: 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74\n",
            "value_scratch: 0, 74, 74, 74, 0, 74, 74, 74, 74, 74, 74, 74, 74, 74, 74\n",
            "value_waiting: 74, 74, 74, 74, 74, 0, 74, 74, 74, 74, 74, 74, 74, 74, 74\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 325/1000 --- L(Train): 0.0164851 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.999 value_action[t] + -0.003 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.003 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 1.001 value_grooming[t] + 0.013 chosen + -0.003 sig_action + 0.0 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + -0.0 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.002 prev_non_contact + -0.003 prev_contact + 0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 0.997 value_non_contact[t] + 0.002 chosen + 0.001 sig_action + -0.476 sig_grooming + 0.0 sig_non_contact + -0.003 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + -0.003 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 0.999 value_contact[t] + 0.003 chosen + -0.0 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.001 value_scratch[t] + 0.0 chosen + 0.0 sig_action + -0.121 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + -0.003 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.007 1 + 0.997 value_waiting[t] + 0.002 chosen + -0.0 sig_action + -0.008 sig_grooming + 0.207 sig_non_contact + -0.003 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.003 prev_contact + -0.003 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75\n",
            "value_grooming: 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75\n",
            "value_non_contact: 0, 75, 75, 75, 0, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75\n",
            "value_contact: 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75\n",
            "value_scratch: 0, 75, 75, 75, 0, 75, 75, 75, 75, 75, 75, 75, 75, 75, 75\n",
            "value_waiting: 75, 75, 75, 75, 75, 0, 75, 75, 75, 75, 75, 75, 75, 75, 75\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 326/1000 --- L(Train): 0.0164803 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 0.999 value_action[t] + -0.002 chosen + 0.002 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.003 prev_non_contact + -0.0 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 1.001 value_grooming[t] + 0.013 chosen + -0.002 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.002 prev_non_contact + -0.003 prev_contact + 0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 0.998 value_non_contact[t] + 0.002 chosen + 0.001 sig_action + -0.476 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + -0.003 prev_action + -0.0 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + -0.002 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + 0.003 chosen + 0.002 sig_action + -0.0 sig_grooming + -0.001 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.001 value_scratch[t] + -0.0 chosen + 0.0 sig_action + -0.121 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + -0.0 sig_scratch + 0.002 sig_waiting + -0.003 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + 0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.006 1 + 0.999 value_waiting[t] + 0.002 chosen + 0.0 sig_action + -0.007 sig_grooming + 0.206 sig_non_contact + -0.003 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.003 prev_contact + -0.003 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76\n",
            "value_grooming: 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76\n",
            "value_non_contact: 0, 76, 76, 76, 0, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76\n",
            "value_contact: 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76\n",
            "value_scratch: 0, 76, 76, 76, 0, 76, 76, 76, 76, 76, 76, 76, 76, 76, 76\n",
            "value_waiting: 76, 76, 76, 76, 76, 0, 76, 76, 76, 76, 76, 76, 76, 76, 76\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 327/1000 --- L(Train): 0.0164978 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.999 value_action[t] + -0.001 chosen + 0.003 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + 0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 0.999 value_grooming[t] + 0.013 chosen + -0.001 sig_action + 0.002 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 1.0 value_non_contact[t] + 0.003 chosen + -0.0 sig_action + -0.477 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.003 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.001 value_contact[t] + 0.001 chosen + 0.002 sig_action + 0.001 sig_grooming + 0.0 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.003 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + 0.001 chosen + -0.001 sig_action + -0.121 sig_grooming + 0.002 sig_non_contact + 0.003 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.002 prev_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.006 1 + 1.002 value_waiting[t] + 0.001 chosen + -0.001 sig_action + -0.006 sig_grooming + 0.205 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77\n",
            "value_grooming: 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77\n",
            "value_non_contact: 0, 77, 77, 77, 0, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77\n",
            "value_contact: 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77\n",
            "value_scratch: 0, 77, 77, 77, 0, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77\n",
            "value_waiting: 77, 77, 77, 77, 77, 0, 77, 77, 77, 77, 77, 77, 77, 77, 77\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 328/1000 --- L(Train): 0.0164743 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.001 value_action[t] + 0.001 chosen + 0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.004 1 + 0.999 value_grooming[t] + 0.013 chosen + 0.001 sig_action + 0.004 sig_grooming + -0.002 sig_non_contact + -0.0 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 1.001 value_non_contact[t] + 0.002 chosen + -0.0 sig_action + -0.477 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.003 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.002 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + -0.001 chosen + 0.002 sig_action + 0.001 sig_grooming + 0.0 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.003 sig_waiting + -0.0 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + 0.001 chosen + -0.001 sig_action + -0.121 sig_grooming + 0.001 sig_non_contact + 0.003 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + -0.002 prev_contact + 0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.006 1 + 1.003 value_waiting[t] + -0.002 chosen + -0.001 sig_action + -0.004 sig_grooming + 0.204 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78\n",
            "value_grooming: 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78\n",
            "value_non_contact: 0, 78, 78, 78, 0, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78\n",
            "value_contact: 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78\n",
            "value_scratch: 0, 78, 78, 78, 0, 78, 78, 78, 78, 78, 78, 78, 78, 78, 78\n",
            "value_waiting: 78, 78, 78, 78, 78, 0, 78, 78, 78, 78, 78, 78, 78, 78, 78\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 329/1000 --- L(Train): 0.0164411 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.001 value_action[t] + 0.001 chosen + 0.001 sig_action + 0.01 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 0.999 value_grooming[t] + 0.013 chosen + 0.001 sig_action + 0.006 sig_grooming + -0.003 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.003 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 1.001 value_non_contact[t] + 0.001 chosen + 0.001 sig_action + -0.477 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 0.999 value_contact[t] + -0.001 chosen + 0.001 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + -0.001 chosen + -0.0 sig_action + -0.121 sig_grooming + 0.0 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.003 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.006 1 + 1.004 value_waiting[t] + -0.003 chosen + 0.001 sig_action + -0.002 sig_grooming + 0.204 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79\n",
            "value_grooming: 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79\n",
            "value_non_contact: 0, 79, 79, 79, 0, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79\n",
            "value_contact: 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79\n",
            "value_scratch: 0, 79, 79, 79, 0, 79, 79, 79, 79, 79, 79, 79, 79, 79, 79\n",
            "value_waiting: 79, 79, 79, 79, 79, 0, 79, 79, 79, 79, 79, 79, 79, 79, 79\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 330/1000 --- L(Train): 0.0164402 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + 0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.001 value_grooming[t] + 0.012 chosen + 0.001 sig_action + 0.007 sig_grooming + -0.004 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.003 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 0.999 value_non_contact[t] + -0.0 chosen + 0.001 sig_action + -0.477 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 0.998 value_contact[t] + -0.001 chosen + -0.002 sig_action + -0.002 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.001 value_scratch[t] + -0.001 chosen + 0.002 sig_action + -0.121 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.003 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.005 1 + 1.003 value_waiting[t] + -0.002 chosen + 0.001 sig_action + 0.001 sig_grooming + 0.204 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80\n",
            "value_grooming: 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80\n",
            "value_non_contact: 0, 80, 80, 80, 0, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80\n",
            "value_contact: 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80\n",
            "value_scratch: 0, 80, 80, 80, 0, 80, 80, 80, 80, 80, 80, 80, 80, 80, 80\n",
            "value_waiting: 80, 80, 80, 80, 80, 0, 80, 80, 80, 80, 80, 80, 80, 80, 80\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 331/1000 --- L(Train): 0.0164224 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.998 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + -0.002 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = -0.0 1 + 1.001 value_grooming[t] + 0.011 chosen + -0.0 sig_action + 0.008 sig_grooming + -0.004 sig_non_contact + -0.0 sig_contact + -0.002 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 0.998 value_non_contact[t] + 0.0 chosen + 0.0 sig_action + -0.477 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + 0.003 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 0.999 value_contact[t] + 0.0 chosen + -0.003 sig_action + -0.002 sig_grooming + -0.0 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.001 value_scratch[t] + 0.0 chosen + 0.002 sig_action + -0.121 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + 0.003 prev_contact + -0.003 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.005 1 + 1.001 value_waiting[t] + -0.001 chosen + -0.0 sig_action + 0.001 sig_grooming + 0.205 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.003 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81\n",
            "value_grooming: 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81\n",
            "value_non_contact: 0, 81, 81, 81, 0, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81\n",
            "value_contact: 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81\n",
            "value_scratch: 0, 81, 81, 81, 0, 81, 81, 81, 81, 81, 81, 81, 81, 81, 81\n",
            "value_waiting: 81, 81, 81, 81, 81, 0, 81, 81, 81, 81, 81, 81, 81, 81, 81\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 332/1000 --- L(Train): 0.0163998 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 0.997 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.002 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.0 value_grooming[t] + 0.01 chosen + -0.0 sig_action + 0.009 sig_grooming + -0.003 sig_non_contact + 0.0 sig_contact + -0.002 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 0.998 value_non_contact[t] + 0.0 chosen + -0.002 sig_action + -0.477 sig_grooming + 0.0 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.002 prev_non_contact + 0.002 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 1.001 value_contact[t] + 0.0 chosen + -0.002 sig_action + -0.002 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + 0.0 chosen + 0.002 sig_action + -0.121 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.003 prev_contact + -0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.005 1 + 0.999 value_waiting[t] + 0.001 chosen + 0.0 sig_action + -0.001 sig_grooming + 0.205 sig_non_contact + -0.0 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + -0.0 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82\n",
            "value_grooming: 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82\n",
            "value_non_contact: 0, 82, 82, 82, 0, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82\n",
            "value_contact: 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82\n",
            "value_scratch: 0, 82, 82, 82, 0, 82, 82, 82, 82, 82, 82, 82, 82, 82, 82\n",
            "value_waiting: 82, 82, 82, 82, 82, 0, 82, 82, 82, 82, 82, 82, 82, 82, 82\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 333/1000 --- L(Train): 0.0164034 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.997 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 0.998 value_grooming[t] + 0.009 chosen + 0.001 sig_action + 0.009 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 0.998 value_non_contact[t] + -0.0 chosen + -0.002 sig_action + -0.477 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.001 value_contact[t] + -0.001 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.002 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + -0.001 chosen + 0.001 sig_action + -0.121 sig_grooming + 0.003 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.005 1 + 0.997 value_waiting[t] + 0.001 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.206 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.003 prev_grooming + 0.003 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83\n",
            "value_grooming: 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83\n",
            "value_non_contact: 0, 83, 83, 83, 0, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83\n",
            "value_contact: 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83\n",
            "value_scratch: 0, 83, 83, 83, 0, 83, 83, 83, 83, 83, 83, 83, 83, 83, 83\n",
            "value_waiting: 83, 83, 83, 83, 83, 0, 83, 83, 83, 83, 83, 83, 83, 83, 83\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 334/1000 --- L(Train): 0.0163893 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.998 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.009 sig_grooming + -0.018 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.002 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 0.997 value_grooming[t] + 0.008 chosen + 0.0 sig_action + 0.009 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 0.999 value_non_contact[t] + 0.001 chosen + -0.002 sig_action + -0.477 sig_grooming + -0.0 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + -0.0 chosen + 0.001 sig_action + -0.0 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + -0.001 chosen + -0.002 sig_action + -0.121 sig_grooming + 0.004 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.005 1 + 0.997 value_waiting[t] + 0.001 chosen + -0.001 sig_action + -0.002 sig_grooming + 0.207 sig_non_contact + 0.0 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84\n",
            "value_grooming: 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84\n",
            "value_non_contact: 0, 84, 84, 84, 0, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84\n",
            "value_contact: 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84\n",
            "value_scratch: 0, 84, 84, 84, 0, 84, 84, 84, 84, 84, 84, 84, 84, 84, 84\n",
            "value_waiting: 84, 84, 84, 84, 84, 0, 84, 84, 84, 84, 84, 84, 84, 84, 84\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 335/1000 --- L(Train): 0.0163777 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + -0.001 chosen + -0.001 sig_action + 0.01 sig_grooming + -0.018 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.003 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 0.998 value_grooming[t] + 0.006 chosen + -0.001 sig_action + 0.009 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 1.0 value_non_contact[t] + 0.002 chosen + -0.001 sig_action + -0.477 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 0.999 value_contact[t] + 0.001 chosen + 0.001 sig_action + 0.002 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + -0.0 chosen + -0.003 sig_action + -0.121 sig_grooming + 0.004 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.005 1 + 0.997 value_waiting[t] + -0.0 chosen + 0.001 sig_action + -0.001 sig_grooming + 0.208 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85\n",
            "value_grooming: 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85\n",
            "value_non_contact: 0, 85, 85, 85, 0, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85\n",
            "value_contact: 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85\n",
            "value_scratch: 0, 85, 85, 85, 0, 85, 85, 85, 85, 85, 85, 85, 85, 85, 85\n",
            "value_waiting: 85, 85, 85, 85, 85, 0, 85, 85, 85, 85, 85, 85, 85, 85, 85\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 336/1000 --- L(Train): 0.0163847 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.001 value_action[t] + -0.001 chosen + -0.0 sig_action + 0.009 sig_grooming + -0.018 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 0.999 value_grooming[t] + 0.005 chosen + -0.001 sig_action + 0.008 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 1.002 value_non_contact[t] + 0.002 chosen + 0.002 sig_action + -0.477 sig_grooming + 0.004 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 0.999 value_contact[t] + 0.001 chosen + 0.001 sig_action + 0.002 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.002 value_scratch[t] + 0.002 chosen + -0.002 sig_action + -0.121 sig_grooming + 0.003 sig_non_contact + -0.0 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.005 1 + 0.999 value_waiting[t] + -0.0 chosen + 0.001 sig_action + -0.0 sig_grooming + 0.209 sig_non_contact + -0.001 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86\n",
            "value_grooming: 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86\n",
            "value_non_contact: 0, 86, 86, 86, 0, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86\n",
            "value_contact: 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86\n",
            "value_scratch: 0, 86, 86, 86, 0, 86, 86, 86, 86, 86, 86, 86, 86, 86, 86\n",
            "value_waiting: 86, 86, 86, 86, 86, 0, 86, 86, 86, 86, 86, 86, 86, 86, 86\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 337/1000 --- L(Train): 0.0163817 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + -0.0 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.001 value_grooming[t] + 0.003 chosen + -0.0 sig_action + 0.008 sig_grooming + -0.0 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 1.001 value_non_contact[t] + 0.001 chosen + 0.003 sig_action + -0.477 sig_grooming + 0.005 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.003 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 0.999 value_contact[t] + -0.0 chosen + -0.0 sig_action + 0.0 sig_grooming + -0.0 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + 0.003 prev_contact + 0.003 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.002 value_scratch[t] + 0.002 chosen + -0.001 sig_action + -0.121 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.005 1 + 1.001 value_waiting[t] + 0.001 chosen + -0.0 sig_action + 0.001 sig_grooming + 0.21 sig_non_contact + -0.0 sig_contact + -0.003 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87\n",
            "value_grooming: 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87\n",
            "value_non_contact: 0, 87, 87, 87, 0, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87\n",
            "value_contact: 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87\n",
            "value_scratch: 0, 87, 87, 87, 0, 87, 87, 87, 87, 87, 87, 87, 87, 87, 87\n",
            "value_waiting: 87, 87, 87, 87, 87, 0, 87, 87, 87, 87, 87, 87, 87, 87, 87\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 338/1000 --- L(Train): 0.0163578 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 1.0 value_action[t] + 0.002 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = -0.0 1 + 1.002 value_grooming[t] + 0.002 chosen + 0.002 sig_action + 0.007 sig_grooming + -0.001 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.0 prev_non_contact + 0.002 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 0.999 value_non_contact[t] + -0.0 chosen + 0.002 sig_action + -0.477 sig_grooming + 0.005 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.002 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 1.001 value_contact[t] + 0.0 chosen + -0.0 sig_action + -0.003 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.001 value_scratch[t] + 0.002 chosen + 0.001 sig_action + -0.121 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + -0.0 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.004 1 + 1.002 value_waiting[t] + 0.0 chosen + -0.0 sig_action + 0.0 sig_grooming + 0.211 sig_non_contact + 0.002 sig_contact + -0.002 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88\n",
            "value_grooming: 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88\n",
            "value_non_contact: 0, 88, 88, 88, 0, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88\n",
            "value_contact: 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88\n",
            "value_scratch: 0, 88, 88, 88, 0, 88, 88, 88, 88, 88, 88, 88, 88, 88, 88\n",
            "value_waiting: 88, 88, 88, 88, 88, 0, 88, 88, 88, 88, 88, 88, 88, 88, 88\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 339/1000 --- L(Train): 0.0163895 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 0.999 value_action[t] + 0.002 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 1.001 value_grooming[t] + 0.0 chosen + 0.002 sig_action + 0.007 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 0.998 value_non_contact[t] + 0.0 chosen + 0.001 sig_action + -0.477 sig_grooming + 0.005 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 1.001 value_contact[t] + -0.001 chosen + 0.001 sig_action + -0.005 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + 0.001 chosen + 0.001 sig_action + -0.122 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.004 1 + 1.002 value_waiting[t] + -0.001 chosen + 0.001 sig_action + -0.002 sig_grooming + 0.212 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + -0.0 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89\n",
            "value_grooming: 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89\n",
            "value_non_contact: 0, 89, 89, 89, 0, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89\n",
            "value_contact: 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89\n",
            "value_scratch: 0, 89, 89, 89, 0, 89, 89, 89, 89, 89, 89, 89, 89, 89, 89\n",
            "value_waiting: 89, 89, 89, 89, 89, 0, 89, 89, 89, 89, 89, 89, 89, 89, 89\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 340/1000 --- L(Train): 0.0163902 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.999 value_action[t] + 0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.018 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.004 1 + 1.0 value_grooming[t] + -0.001 chosen + 0.002 sig_action + 0.006 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 0.998 value_non_contact[t] + 0.0 chosen + -0.001 sig_action + -0.477 sig_grooming + 0.004 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.001 value_contact[t] + -0.0 chosen + 0.0 sig_action + -0.006 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.998 value_scratch[t] + -0.002 chosen + 0.001 sig_action + -0.122 sig_grooming + -0.001 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 1.001 value_waiting[t] + -0.001 chosen + 0.001 sig_action + -0.004 sig_grooming + 0.213 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90\n",
            "value_grooming: 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90\n",
            "value_non_contact: 0, 90, 90, 90, 0, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90\n",
            "value_contact: 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90\n",
            "value_scratch: 0, 90, 90, 90, 0, 90, 90, 90, 90, 90, 90, 90, 90, 90, 90\n",
            "value_waiting: 90, 90, 90, 90, 90, 0, 90, 90, 90, 90, 90, 90, 90, 90, 90\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 341/1000 --- L(Train): 0.0163886 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + 0.001 chosen + -0.002 sig_action + 0.01 sig_grooming + -0.018 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 1.0 value_grooming[t] + 0.002 chosen + 0.001 sig_action + 0.005 sig_grooming + -0.0 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 0.998 value_non_contact[t] + -0.0 chosen + -0.001 sig_action + -0.477 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 0.999 value_contact[t] + 0.001 chosen + -0.001 sig_action + -0.007 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.997 value_scratch[t] + -0.003 chosen + -0.0 sig_action + -0.122 sig_grooming + 0.0 sig_non_contact + -0.002 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 0.999 value_waiting[t] + 0.0 chosen + 0.0 sig_action + -0.005 sig_grooming + 0.213 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91\n",
            "value_grooming: 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91\n",
            "value_non_contact: 0, 91, 91, 91, 0, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91\n",
            "value_contact: 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91\n",
            "value_scratch: 0, 91, 91, 91, 0, 91, 91, 91, 91, 91, 91, 91, 91, 91, 91\n",
            "value_waiting: 91, 91, 91, 91, 91, 0, 91, 91, 91, 91, 91, 91, 91, 91, 91\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 342/1000 --- L(Train): 0.0163529 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + -0.002 chosen + -0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 1.0 value_grooming[t] + 0.005 chosen + -0.002 sig_action + 0.005 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 0.999 value_non_contact[t] + 0.001 chosen + -0.001 sig_action + -0.477 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + -0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.034 1 + 0.999 value_contact[t] + 0.001 chosen + -0.001 sig_action + -0.007 sig_grooming + -0.002 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.998 value_scratch[t] + -0.002 chosen + -0.0 sig_action + -0.122 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 0.998 value_waiting[t] + -0.0 chosen + -0.002 sig_action + -0.005 sig_grooming + 0.214 sig_non_contact + -0.002 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92\n",
            "value_grooming: 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92\n",
            "value_non_contact: 0, 92, 92, 92, 0, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92\n",
            "value_contact: 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92\n",
            "value_scratch: 0, 92, 92, 92, 0, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92\n",
            "value_waiting: 92, 92, 92, 92, 92, 0, 92, 92, 92, 92, 92, 92, 92, 92, 92\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 343/1000 --- L(Train): 0.0163778 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + -0.003 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.007 1 + 1.0 value_grooming[t] + 0.007 chosen + -0.003 sig_action + 0.004 sig_grooming + 0.0 sig_non_contact + -0.002 sig_contact + 0.0 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.002 prev_non_contact + -0.003 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 1.0 value_non_contact[t] + 0.002 chosen + 0.0 sig_action + -0.478 sig_grooming + -0.002 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.003 prev_action + 0.002 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.032 1 + 0.999 value_contact[t] + -0.0 chosen + 0.0 sig_action + -0.006 sig_grooming + -0.001 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + -0.001 chosen + 0.001 sig_action + -0.122 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + -0.003 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 0.998 value_waiting[t] + 0.001 chosen + -0.002 sig_action + -0.004 sig_grooming + 0.215 sig_non_contact + -0.003 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + -0.003 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93\n",
            "value_grooming: 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93\n",
            "value_non_contact: 0, 93, 93, 93, 0, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93\n",
            "value_contact: 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93\n",
            "value_scratch: 0, 93, 93, 93, 0, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93\n",
            "value_waiting: 93, 93, 93, 93, 93, 0, 93, 93, 93, 93, 93, 93, 93, 93, 93\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 344/1000 --- L(Train): 0.0163795 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.002 1 + 1.0 value_action[t] + -0.002 chosen + 0.002 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.007 1 + 1.0 value_grooming[t] + 0.009 chosen + -0.002 sig_action + 0.003 sig_grooming + -0.002 sig_non_contact + -0.002 sig_contact + 0.0 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.002 prev_non_contact + -0.003 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 1.0 value_non_contact[t] + 0.002 chosen + 0.0 sig_action + -0.478 sig_grooming + -0.002 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + -0.003 prev_action + 0.002 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + -0.002 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.031 1 + 1.001 value_contact[t] + 0.0 chosen + -0.0 sig_action + -0.005 sig_grooming + -0.0 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.001 value_scratch[t] + 0.001 chosen + 0.0 sig_action + -0.122 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + -0.003 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 0.999 value_waiting[t] + 0.001 chosen + -0.002 sig_action + -0.003 sig_grooming + 0.215 sig_non_contact + -0.003 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + -0.003 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94\n",
            "value_grooming: 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94\n",
            "value_non_contact: 0, 94, 94, 94, 0, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94\n",
            "value_contact: 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94\n",
            "value_scratch: 0, 94, 94, 94, 0, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94\n",
            "value_waiting: 94, 94, 94, 94, 94, 0, 94, 94, 94, 94, 94, 94, 94, 94, 94\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 345/1000 --- L(Train): 0.0163814 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + -0.001 chosen + 0.003 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + 0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 1.0 value_grooming[t] + 0.01 chosen + -0.001 sig_action + 0.002 sig_grooming + -0.004 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 1.0 value_non_contact[t] + 0.001 chosen + -0.001 sig_action + -0.478 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.031 1 + 1.001 value_contact[t] + -0.001 chosen + 0.001 sig_action + -0.003 sig_grooming + 0.002 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.003 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.002 value_scratch[t] + 0.001 chosen + -0.001 sig_action + -0.122 sig_grooming + 0.0 sig_non_contact + 0.003 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 1.001 value_waiting[t] + -0.001 chosen + -0.001 sig_action + -0.002 sig_grooming + 0.216 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95\n",
            "value_grooming: 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95\n",
            "value_non_contact: 0, 95, 95, 95, 0, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95\n",
            "value_contact: 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95\n",
            "value_scratch: 0, 95, 95, 95, 0, 95, 95, 95, 95, 95, 95, 95, 95, 95, 95\n",
            "value_waiting: 95, 95, 95, 95, 95, 0, 95, 95, 95, 95, 95, 95, 95, 95, 95\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 346/1000 --- L(Train): 0.0163608 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 0.999 value_action[t] + 0.001 chosen + 0.002 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 1.0 value_grooming[t] + 0.011 chosen + 0.001 sig_action + 0.001 sig_grooming + -0.004 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.372 1 + 1.0 value_non_contact[t] + 0.0 chosen + -0.0 sig_action + -0.478 sig_grooming + 0.003 sig_non_contact + -0.001 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.033 1 + 1.001 value_contact[t] + -0.001 chosen + 0.001 sig_action + -0.001 sig_grooming + 0.003 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.003 sig_waiting + 0.002 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.001 value_scratch[t] + 0.001 chosen + -0.001 sig_action + -0.122 sig_grooming + -0.001 sig_non_contact + 0.003 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 1.001 value_waiting[t] + -0.001 chosen + 0.002 sig_action + 0.0 sig_grooming + 0.216 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + -0.003 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96\n",
            "value_grooming: 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96\n",
            "value_non_contact: 0, 96, 96, 96, 0, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96\n",
            "value_contact: 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96\n",
            "value_scratch: 0, 96, 96, 96, 0, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96\n",
            "value_waiting: 96, 96, 96, 96, 96, 0, 96, 96, 96, 96, 96, 96, 96, 96, 96\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 347/1000 --- L(Train): 0.0163362 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.001 1 + 0.999 value_action[t] + 0.001 chosen + 0.001 sig_action + 0.01 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 1.001 value_grooming[t] + 0.012 chosen + 0.001 sig_action + -0.001 sig_grooming + -0.005 sig_non_contact + 0.003 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.003 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.372 1 + 0.999 value_non_contact[t] + -0.001 chosen + 0.001 sig_action + -0.478 sig_grooming + 0.005 sig_non_contact + -0.0 sig_contact + -0.002 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + -0.003 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 0.999 value_contact[t] + 0.001 chosen + -0.001 sig_action + 0.002 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.003 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + -0.0 chosen + 0.0 sig_action + -0.122 sig_grooming + -0.0 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 1.001 value_waiting[t] + 0.0 chosen + 0.003 sig_action + -0.0 sig_grooming + 0.216 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97\n",
            "value_grooming: 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97\n",
            "value_non_contact: 0, 97, 97, 97, 0, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97\n",
            "value_contact: 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97\n",
            "value_scratch: 0, 97, 97, 97, 0, 97, 97, 97, 97, 97, 97, 97, 97, 97, 97\n",
            "value_waiting: 97, 97, 97, 97, 97, 0, 97, 97, 97, 97, 97, 97, 97, 97, 97\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 348/1000 --- L(Train): 0.0163372 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + 0.001 chosen + -0.001 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 1.001 value_grooming[t] + 0.012 chosen + 0.001 sig_action + 0.002 sig_grooming + -0.004 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.372 1 + 0.999 value_non_contact[t] + -0.001 chosen + 0.001 sig_action + -0.478 sig_grooming + 0.007 sig_non_contact + 0.002 sig_contact + -0.002 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.041 1 + 0.999 value_contact[t] + 0.001 chosen + -0.001 sig_action + 0.002 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.998 value_scratch[t] + -0.0 chosen + 0.0 sig_action + -0.122 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.002 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.0 1 + 0.999 value_waiting[t] + 0.0 chosen + 0.003 sig_action + 0.0 sig_grooming + 0.217 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98\n",
            "value_grooming: 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98\n",
            "value_non_contact: 0, 98, 98, 98, 0, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98\n",
            "value_contact: 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98\n",
            "value_scratch: 0, 98, 98, 98, 0, 98, 98, 98, 98, 98, 98, 98, 98, 98, 98\n",
            "value_waiting: 98, 98, 98, 98, 98, 0, 98, 98, 98, 98, 98, 98, 98, 98, 98\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 349/1000 --- L(Train): 0.0163273 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 90):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 1.0 value_grooming[t] + 0.013 chosen + -0.0 sig_action + 0.005 sig_grooming + -0.004 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.0 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.372 1 + 0.999 value_non_contact[t] + 0.001 chosen + -0.0 sig_action + -0.478 sig_grooming + 0.007 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.044 1 + 1.0 value_contact[t] + -0.0 chosen + 0.0 sig_action + 0.001 sig_grooming + -0.002 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.997 value_scratch[t] + 0.001 chosen + -0.001 sig_action + -0.122 sig_grooming + 0.003 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = -0.0 1 + 0.999 value_waiting[t] + -0.001 chosen + 0.001 sig_action + -0.001 sig_grooming + 0.217 sig_non_contact + -0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + 0.002 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99\n",
            "value_grooming: 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99\n",
            "value_non_contact: 0, 99, 99, 99, 0, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99\n",
            "value_contact: 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99\n",
            "value_scratch: 0, 99, 99, 99, 0, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99\n",
            "value_waiting: 99, 99, 99, 99, 99, 0, 99, 99, 99, 99, 99, 99, 99, 99, 99\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 350/1000 --- L(Train): 0.0163102 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 89):\n",
            "value_action[t+1] = -0.002 1 + 0.999 value_action[t] + -0.0 chosen + -0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 0.998 value_grooming[t] + 0.012 chosen + -0.0 sig_action + 0.007 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.372 1 + 1.0 value_non_contact[t] + 0.002 chosen + 0.0 sig_action + -0.478 sig_grooming + 0.007 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.046 1 + 1.001 value_contact[t] + -0.0 chosen + 0.0 sig_action + -0.001 sig_grooming + -0.003 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.998 value_scratch[t] + 0.0 chosen + -0.001 sig_action + -0.122 sig_grooming + 0.004 sig_non_contact + -0.001 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 0.999 value_waiting[t] + -0.001 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.217 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100\n",
            "value_grooming: 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100\n",
            "value_non_contact: 0, 100, 100, 100, 0, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100\n",
            "value_contact: 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100\n",
            "value_scratch: 0, 100, 100, 100, 0, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100\n",
            "value_waiting: 100, 100, 100, 100, 100, 0, 100, 100, 100, 100, 100, 100, -, 100, 100\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 351/1000 --- L(Train): 0.0163031 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 88):\n",
            "value_action[t+1] = -0.001 1 + 0.999 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = -0.001 1 + 0.997 value_grooming[t] + 0.012 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + -0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.372 1 + 1.001 value_non_contact[t] + 0.003 chosen + -0.001 sig_action + -0.478 sig_grooming + 0.007 sig_non_contact + 0.001 sig_contact + 0.003 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.045 1 + 1.002 value_contact[t] + 0.001 chosen + -0.001 sig_action + -0.003 sig_grooming + -0.003 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + -0.001 chosen + -0.0 sig_action + -0.122 sig_grooming + 0.004 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.003 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.006 1 + 1.001 value_waiting[t] + -0.0 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.217 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + 0.003 prev_grooming + 0.0 prev_non_contact + 0.0 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101\n",
            "value_grooming: 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101\n",
            "value_non_contact: 0, 101, 101, 101, 0, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101\n",
            "value_contact: 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101\n",
            "value_scratch: 0, 101, 101, 101, 0, 101, 101, 101, 101, 101, 101, 101, 101, 101, 101\n",
            "value_waiting: 101, 101, 101, 101, 101, 0, 101, 101, 101, 101, 101, 101, -, 101, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 352/1000 --- L(Train): 0.0162906 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 87):\n",
            "value_action[t+1] = 0.0 1 + 0.999 value_action[t] + 0.0 chosen + 0.0 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = -0.0 1 + 0.998 value_grooming[t] + 0.011 chosen + 0.0 sig_action + 0.009 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.372 1 + 1.001 value_non_contact[t] + 0.003 chosen + -0.001 sig_action + -0.478 sig_grooming + 0.006 sig_non_contact + -0.002 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + 0.0 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.041 1 + 1.001 value_contact[t] + 0.001 chosen + -0.001 sig_action + -0.004 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.001 value_scratch[t] + -0.001 chosen + 0.002 sig_action + -0.122 sig_grooming + 0.003 sig_non_contact + 0.0 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + 0.0 prev_action + 0.002 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_waiting[t+1] = 0.008 1 + 1.001 value_waiting[t] + 0.002 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.216 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.0 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102\n",
            "value_grooming: 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102\n",
            "value_non_contact: 0, 102, 102, 102, 0, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102\n",
            "value_contact: 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102, 102\n",
            "value_scratch: 0, 102, 102, 102, 0, 102, 102, 102, 102, 102, -, 102, 102, 102, 102\n",
            "value_waiting: 102, 102, 102, 102, 102, 0, 102, 102, 102, 102, 102, 102, -, 102, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 353/1000 --- L(Train): 0.0162878 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 86):\n",
            "value_action[t+1] = 0.001 1 + 1.001 value_action[t] + -0.001 chosen + -0.001 sig_action + 0.01 sig_grooming + -0.018 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 0.999 value_grooming[t] + 0.011 chosen + -0.001 sig_action + 0.01 sig_grooming + 0.002 sig_non_contact + 0.0 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.003 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.372 1 + 0.998 value_non_contact[t] + 0.002 chosen + 0.001 sig_action + -0.478 sig_grooming + 0.004 sig_non_contact + -0.003 sig_contact + 0.001 sig_scratch + -0.003 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + 0.003 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + 0.0 chosen + -0.0 sig_action + -0.004 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.002 value_scratch[t] + 0.0 chosen + 0.002 sig_action + -0.122 sig_grooming + 0.002 sig_non_contact + -0.0 sig_contact + -0.002 sig_waiting + -0.001 prev_action + 0.001 prev_non_contact + 0.001 prev_contact + -0.0 prev_scratch + -0.003 prev_waiting \n",
            "value_waiting[t+1] = 0.009 1 + 1.0 value_waiting[t] + 0.002 chosen + 0.0 sig_action + 0.0 sig_grooming + 0.216 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.002 prev_action + 0.001 prev_grooming + -0.003 prev_non_contact + -0.001 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103\n",
            "value_grooming: 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103\n",
            "value_non_contact: 0, 103, 103, 103, 0, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103\n",
            "value_contact: 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103\n",
            "value_scratch: 0, 103, 103, 103, 0, 103, 103, -, 103, 103, -, 103, 103, 103, 103\n",
            "value_waiting: 103, 103, 103, 103, 103, 0, 103, 103, 103, 103, 103, 103, -, 103, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 354/1000 --- L(Train): 0.0162962 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 85):\n",
            "value_action[t+1] = 0.0 1 + 1.001 value_action[t] + -0.001 chosen + -0.0 sig_action + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.002 prev_non_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 1.001 value_grooming[t] + 0.01 chosen + -0.001 sig_action + 0.01 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 0.997 value_non_contact[t] + 0.0 chosen + 0.001 sig_action + -0.478 sig_grooming + 0.002 sig_non_contact + -0.002 sig_contact + -0.001 sig_scratch + -0.003 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.033 1 + 0.999 value_contact[t] + -0.002 chosen + 0.002 sig_action + -0.003 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.001 value_scratch[t] + -0.0 chosen + 0.002 sig_action + -0.122 sig_grooming + 0.0 sig_non_contact + -0.0 sig_contact + -0.002 sig_waiting + -0.001 prev_action + -0.001 prev_non_contact + 0.001 prev_contact + 0.002 prev_scratch + -0.003 prev_waiting \n",
            "value_waiting[t+1] = 0.01 1 + 0.998 value_waiting[t] + 0.002 chosen + 0.0 sig_action + -0.001 sig_grooming + 0.215 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + -0.003 prev_non_contact + -0.001 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, -, 104, 104\n",
            "value_grooming: 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104\n",
            "value_non_contact: 0, 104, 104, 104, 0, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104\n",
            "value_contact: 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104, 104\n",
            "value_scratch: 0, 104, 104, 104, 0, 104, 104, -, 104, 104, -, 104, 104, 104, 104\n",
            "value_waiting: 104, 104, 104, 104, 104, 0, 104, 104, 104, 104, 104, 104, -, 104, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 355/1000 --- L(Train): 0.0162996 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 84):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + -0.0 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.002 prev_non_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.007 1 + 1.001 value_grooming[t] + 0.008 chosen + 0.01 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.001 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 0.997 value_non_contact[t] + -0.001 chosen + -0.0 sig_action + -0.478 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + -0.0 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.03 1 + 1.0 value_contact[t] + -0.002 chosen + 0.002 sig_action + -0.002 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + 0.001 chosen + 0.001 sig_action + -0.122 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + -0.001 sig_waiting + -0.0 prev_action + -0.002 prev_non_contact + -0.0 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.01 1 + 0.998 value_waiting[t] + 0.001 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.213 sig_non_contact + -0.0 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.002 prev_non_contact + -0.0 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, -, 105, 105\n",
            "value_grooming: 105, 105, 105, -, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105\n",
            "value_non_contact: 0, 105, 105, 105, 0, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105\n",
            "value_contact: 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105, 105\n",
            "value_scratch: 0, 105, 105, 105, 0, 105, 105, -, 105, 105, -, 105, 105, 105, 105\n",
            "value_waiting: 105, 105, 105, 105, 105, 0, 105, 105, 105, 105, 105, 105, -, 105, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 356/1000 --- L(Train): 0.0162742 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 83):\n",
            "value_action[t+1] = -0.002 1 + 1.0 value_action[t] + 0.002 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.008 1 + 1.001 value_grooming[t] + 0.007 chosen + 0.01 sig_grooming + -0.005 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.0 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 0.997 value_non_contact[t] + -0.001 chosen + -0.0 sig_action + -0.478 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.0 sig_waiting + 0.002 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.03 1 + 1.001 value_contact[t] + -0.002 chosen + 0.002 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.0 prev_action + 0.002 prev_grooming + 0.002 prev_non_contact + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.998 value_scratch[t] + 0.001 chosen + -0.002 sig_action + -0.122 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + 0.001 sig_waiting + 0.002 prev_action + -0.002 prev_non_contact + 0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.009 1 + 0.998 value_waiting[t] + -0.002 chosen + -0.0 sig_action + -0.001 sig_grooming + 0.212 sig_non_contact + 0.002 sig_contact + 0.0 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.002 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, -, 106, 106\n",
            "value_grooming: 106, 106, 106, -, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106\n",
            "value_non_contact: 0, 106, 106, 106, 0, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106\n",
            "value_contact: 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106, 106\n",
            "value_scratch: 0, 106, 106, 106, 0, 106, 106, -, 106, 106, -, 106, -, 106, 106\n",
            "value_waiting: 106, 106, 106, 106, 106, 0, 106, 106, 106, 106, 106, 106, -, 106, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 357/1000 --- L(Train): 0.0163030 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 82):\n",
            "value_action[t+1] = -0.001 1 + 1.001 value_action[t] + 0.002 chosen + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.008 1 + 1.0 value_grooming[t] + 0.005 chosen + 0.009 sig_grooming + -0.006 sig_non_contact + 0.001 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 0.997 value_non_contact[t] + 0.001 chosen + 0.001 sig_action + -0.478 sig_grooming + 0.0 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.032 1 + 1.002 value_contact[t] + -0.001 chosen + 0.001 sig_action + 0.001 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.998 value_scratch[t] + -0.001 chosen + -0.003 sig_action + -0.122 sig_grooming + 0.0 sig_non_contact + 0.0 sig_contact + 0.002 sig_waiting + 0.002 prev_action + -0.001 prev_non_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.008 1 + 0.999 value_waiting[t] + -0.003 chosen + 0.001 sig_action + -0.001 sig_grooming + 0.21 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.003 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.002 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 107, 107, 107, -, 107, 107, 107, 107, 107, 107, 107, 107, -, 107, 107\n",
            "value_grooming: 107, 107, 107, -, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107\n",
            "value_non_contact: 0, 107, 107, 107, 0, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107\n",
            "value_contact: 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107, 107\n",
            "value_scratch: 0, 107, 107, 107, 0, 107, 107, -, 107, 107, -, 107, -, 107, 107\n",
            "value_waiting: 107, 107, 107, 107, 107, 0, 107, 107, 107, 107, 107, 107, -, 107, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 358/1000 --- L(Train): 0.0163105 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 81):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + 0.002 chosen + 0.009 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.002 prev_non_contact + 0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.008 1 + 0.999 value_grooming[t] + 0.003 chosen + 0.008 sig_grooming + -0.007 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 0.999 value_non_contact[t] + 0.002 chosen + 0.001 sig_action + -0.478 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.035 1 + 1.001 value_contact[t] + 0.002 chosen + -0.002 sig_action + 0.001 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 0.999 value_scratch[t] + -0.001 chosen + -0.002 sig_action + -0.122 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + 0.001 sig_waiting + 0.002 prev_action + 0.001 prev_non_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.007 1 + 1.001 value_waiting[t] + -0.002 chosen + 0.001 sig_action + 0.001 sig_grooming + 0.209 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.002 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 108, -, 108, -, 108, 108, 108, 108, 108, 108, 108, 108, -, 108, 108\n",
            "value_grooming: 108, 108, 108, -, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108\n",
            "value_non_contact: 0, 108, 108, 108, 0, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108\n",
            "value_contact: 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108, 108\n",
            "value_scratch: 0, 108, 108, 108, 0, 108, 108, -, 108, 108, -, 108, -, 108, 108\n",
            "value_waiting: 108, 108, 108, 108, 108, 0, 108, 108, 108, 108, 108, 108, -, 108, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 359/1000 --- L(Train): 0.0163150 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 80):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + 0.001 chosen + 0.01 sig_grooming + -0.018 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.003 prev_non_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.007 1 + 1.0 value_grooming[t] + 0.001 chosen + 0.007 sig_grooming + -0.007 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 1.0 value_non_contact[t] + 0.003 chosen + 0.0 sig_action + -0.478 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.0 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + 0.003 chosen + -0.003 sig_action + -0.0 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + -0.0 prev_action + -0.002 prev_grooming + -0.003 prev_non_contact + 0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + 0.0 chosen + -0.001 sig_action + -0.122 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + -0.0 sig_waiting + 0.0 prev_action + 0.002 prev_non_contact + -0.003 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.005 1 + 1.002 value_waiting[t] + -0.001 chosen + -0.0 sig_action + -0.0 sig_grooming + 0.208 sig_non_contact + 0.001 sig_contact + -0.0 sig_scratch + -0.003 sig_waiting + 0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 109, -, 109, -, 109, 109, 109, 109, 109, 109, 109, 109, -, 109, 109\n",
            "value_grooming: 109, 109, 109, -, 109, 109, 109, 109, 109, 109, 109, -, 109, 109, 109\n",
            "value_non_contact: 0, 109, 109, 109, 0, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109\n",
            "value_contact: 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 109\n",
            "value_scratch: 0, 109, 109, 109, 0, 109, 109, -, 109, 109, -, 109, -, 109, 109\n",
            "value_waiting: 109, 109, 109, 109, 109, 0, 109, 109, 109, 109, 109, 109, -, 109, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 360/1000 --- L(Train): 0.0162698 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 79):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + -0.002 chosen + 0.009 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.003 prev_non_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.007 1 + 1.001 value_grooming[t] + -0.001 chosen + 0.006 sig_grooming + -0.007 sig_non_contact + 0.0 sig_contact + -0.0 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.002 prev_contact + 0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 1.0 value_non_contact[t] + 0.002 chosen + -0.002 sig_action + -0.478 sig_grooming + 0.0 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.0 prev_grooming + 0.0 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.042 1 + 0.999 value_contact[t] + 0.003 chosen + -0.002 sig_action + -0.001 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.0 prev_action + -0.002 prev_grooming + -0.003 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + -0.0 chosen + 0.001 sig_action + -0.122 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + -0.0 sig_waiting + -0.002 prev_action + 0.002 prev_non_contact + -0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.004 1 + 1.002 value_waiting[t] + 0.001 chosen + 0.0 sig_action + -0.001 sig_grooming + 0.207 sig_non_contact + -0.002 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + -0.002 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 110, -, 110, -, 110, 110, 110, 110, 110, 110, 110, 110, -, 110, 110\n",
            "value_grooming: 110, 110, 110, -, 110, 110, 110, 110, 110, 110, 110, -, 110, 110, 110\n",
            "value_non_contact: 0, 110, 110, 110, 0, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110\n",
            "value_contact: 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110, 110\n",
            "value_scratch: 0, -, 110, 110, 0, 110, 110, -, 110, 110, -, 110, -, 110, 110\n",
            "value_waiting: 110, 110, 110, 110, 110, 0, 110, 110, 110, 110, 110, 110, -, 110, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 361/1000 --- L(Train): 0.0163016 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 78):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + -0.003 chosen + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.006 1 + 1.001 value_grooming[t] + 0.002 chosen + 0.004 sig_grooming + -0.006 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.003 prev_contact + -0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 1.0 value_non_contact[t] + 0.002 chosen + -0.002 sig_action + -0.478 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + -0.003 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.044 1 + 1.0 value_contact[t] + 0.001 chosen + -0.001 sig_action + -0.002 sig_grooming + 0.0 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + 0.001 chosen + 0.001 sig_action + -0.122 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + 0.001 sig_waiting + -0.003 prev_action + 0.0 prev_non_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.003 1 + 1.0 value_waiting[t] + 0.001 chosen + -0.001 sig_action + -0.0 sig_grooming + 0.206 sig_non_contact + -0.003 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.003 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 111, -, 111, -, 111, 111, 111, 111, 111, 111, 111, 111, -, -, 111\n",
            "value_grooming: 111, 111, 111, -, 111, 111, 111, 111, 111, 111, 111, -, 111, 111, 111\n",
            "value_non_contact: 0, 111, 111, 111, 0, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111\n",
            "value_contact: 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111, 111\n",
            "value_scratch: 0, -, 111, 111, 0, 111, 111, -, 111, 111, -, 111, -, 111, 111\n",
            "value_waiting: 111, 111, 111, 111, 111, 0, 111, 111, 111, 111, 111, 111, -, 111, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 362/1000 --- L(Train): 0.0163147 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 77):\n",
            "value_action[t+1] = -0.002 1 + 1.0 value_action[t] + -0.002 chosen + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.001 prev_non_contact + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.005 1 + 1.001 value_grooming[t] + 0.004 chosen + 0.003 sig_grooming + -0.005 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.003 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 0.999 value_non_contact[t] + 0.001 chosen + -0.002 sig_action + -0.478 sig_grooming + 0.0 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.003 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.044 1 + 1.0 value_contact[t] + -0.001 chosen + 0.001 sig_action + -0.001 sig_grooming + -0.001 sig_non_contact + -0.003 sig_contact + -0.003 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + 0.001 chosen + 0.001 sig_action + -0.122 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + 0.001 sig_waiting + -0.003 prev_action + -0.002 prev_non_contact + 0.001 prev_scratch + 0.0 prev_waiting \n",
            "value_waiting[t+1] = 0.002 1 + 0.998 value_waiting[t] + 0.001 chosen + -0.0 sig_action + 0.0 sig_grooming + 0.206 sig_non_contact + -0.003 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.003 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 112, -, 112, -, 112, 112, 112, 112, 112, 112, 112, 112, -, -, 112\n",
            "value_grooming: 112, 112, 112, -, 112, 112, 112, 112, 112, 112, 112, -, 112, 112, 112\n",
            "value_non_contact: 0, 112, 112, 112, 0, 112, 112, 112, -, 112, 112, 112, 112, 112, 112\n",
            "value_contact: 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112, 112\n",
            "value_scratch: 0, -, 112, 112, 0, 112, 112, -, 112, 112, -, 112, -, 112, 112\n",
            "value_waiting: 112, 112, 112, 112, 112, 0, 112, 112, 112, 112, 112, 112, -, 112, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 363/1000 --- L(Train): 0.0163163 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 76):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + -0.001 chosen + 0.008 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + 0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.004 1 + 0.999 value_grooming[t] + 0.005 chosen + 0.002 sig_grooming + -0.003 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 0.998 value_non_contact[t] + -0.001 chosen + -0.001 sig_action + -0.478 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.001 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.043 1 + 1.0 value_contact[t] + -0.001 chosen + 0.001 sig_action + 0.0 sig_grooming + -0.002 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.003 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + -0.001 chosen + -0.0 sig_action + -0.122 sig_grooming + -0.001 sig_non_contact + 0.003 sig_contact + -0.001 sig_waiting + -0.002 prev_action + -0.003 prev_non_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 0.997 value_waiting[t] + -0.0 chosen + 0.001 sig_action + -0.001 sig_grooming + 0.206 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + -0.001 prev_non_contact + -0.002 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 113, -, 113, -, 113, 113, 113, 113, 113, 113, 113, 113, -, -, 113\n",
            "value_grooming: 113, 113, 113, -, 113, 113, 113, 113, 113, 113, 113, -, 113, 113, 113\n",
            "value_non_contact: 0, 113, 113, 113, 0, 113, 113, 113, -, 113, 113, 113, 113, 113, 113\n",
            "value_contact: 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113, 113\n",
            "value_scratch: 0, -, 113, 113, 0, 113, 113, -, 113, 113, -, 113, -, 113, 113\n",
            "value_waiting: 113, 113, 113, 113, 113, 0, 113, 113, 113, 113, -, 113, -, 113, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 364/1000 --- L(Train): 0.0162910 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 75):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + 0.001 chosen + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_non_contact + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 0.998 value_grooming[t] + 0.007 chosen + 0.001 sig_grooming + -0.001 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.001 prev_contact + 0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.373 1 + 0.998 value_non_contact[t] + -0.001 chosen + 0.002 sig_action + -0.478 sig_grooming + -0.001 sig_contact + 0.0 sig_scratch + 0.0 prev_action + -0.001 prev_grooming + 0.001 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 1.0 value_contact[t] + -0.001 chosen + 0.001 sig_action + -0.0 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.003 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + -0.001 chosen + -0.0 sig_action + -0.122 sig_grooming + 0.002 sig_non_contact + 0.003 sig_contact + -0.001 sig_waiting + 0.0 prev_action + -0.003 prev_non_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.001 1 + 0.997 value_waiting[t] + -0.0 chosen + 0.001 sig_action + -0.001 sig_grooming + 0.206 sig_non_contact + 0.0 sig_contact + -0.002 sig_scratch + 0.001 sig_waiting + 0.0 prev_action + -0.001 prev_non_contact + 0.0 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 114, -, 114, -, 114, 114, 114, 114, 114, 114, 114, 114, -, -, 114\n",
            "value_grooming: 114, 114, 114, -, 114, 114, 114, 114, 114, 114, 114, -, 114, 114, 114\n",
            "value_non_contact: 0, 114, 114, 114, 0, -, 114, 114, -, 114, 114, 114, 114, 114, 114\n",
            "value_contact: 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114, 114\n",
            "value_scratch: 0, -, 114, 114, 0, 114, 114, -, 114, 114, -, 114, -, 114, 114\n",
            "value_waiting: 114, 114, 114, 114, 114, 0, 114, 114, 114, 114, -, 114, -, 114, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 365/1000 --- L(Train): 0.0162703 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 74):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + 0.001 chosen + 0.01 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 0.998 value_grooming[t] + 0.008 chosen + -0.0 sig_grooming + 0.002 sig_non_contact + -0.0 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_contact + -0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.372 1 + 0.998 value_non_contact[t] + 0.001 chosen + 0.003 sig_action + -0.478 sig_grooming + 0.0 sig_contact + -0.001 sig_scratch + 0.001 prev_action + 0.0 prev_grooming + -0.0 prev_non_contact + -0.003 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.001 value_contact[t] + 0.0 chosen + -0.0 sig_action + -0.0 sig_grooming + 0.0 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + 0.003 prev_contact + 0.003 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + 0.0 chosen + 0.001 sig_action + -0.122 sig_grooming + 0.003 sig_non_contact + 0.001 sig_contact + 0.0 sig_waiting + 0.001 prev_action + -0.001 prev_non_contact + -0.0 prev_scratch \n",
            "value_waiting[t+1] = 0.001 1 + 0.998 value_waiting[t] + 0.001 chosen + -0.0 sig_action + -0.001 sig_grooming + 0.207 sig_non_contact + 0.001 sig_contact + -0.003 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + 0.0 prev_non_contact + 0.001 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 115, -, 115, -, 115, 115, 115, 115, 115, 115, 115, 115, -, -, 115\n",
            "value_grooming: 115, 115, 115, -, 115, 115, 115, 115, 115, 115, 115, -, 115, 115, 115\n",
            "value_non_contact: 0, 115, 115, 115, 0, -, 115, 115, -, 115, 115, 115, 115, 115, 115\n",
            "value_contact: 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115, 115\n",
            "value_scratch: 0, -, 115, 115, 0, 115, 115, -, 115, 115, -, 115, -, 115, -\n",
            "value_waiting: 115, 115, 115, 115, 115, 0, 115, 115, 115, 115, -, 115, -, 115, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 366/1000 --- L(Train): 0.0162724 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 73):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + 0.001 chosen + 0.009 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.0 prev_non_contact + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.0 value_grooming[t] + 0.009 chosen + 0.003 sig_grooming + 0.003 sig_non_contact + -0.0 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_non_contact[t+1] = -0.372 1 + 1.0 value_non_contact[t] + 0.003 chosen + 0.002 sig_action + -0.478 sig_grooming + -0.0 sig_contact + -0.001 sig_scratch + 0.001 prev_action + 0.0 prev_grooming + -0.002 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.034 1 + 1.0 value_contact[t] + 0.0 chosen + -0.0 sig_action + 0.0 sig_grooming + 0.0 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.0 prev_non_contact + 0.002 prev_contact + 0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + 0.0 chosen + 0.0 sig_action + -0.122 sig_grooming + 0.004 sig_non_contact + -0.001 sig_contact + 0.0 sig_waiting + 0.001 prev_action + 0.001 prev_non_contact + -0.0 prev_scratch \n",
            "value_waiting[t+1] = 0.001 1 + 0.999 value_waiting[t] + 0.0 chosen + 0.0 sig_action + -0.0 sig_grooming + 0.208 sig_non_contact + 0.001 sig_contact + -0.002 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + 0.0 prev_non_contact + 0.001 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 116, -, 116, -, 116, 116, 116, 116, 116, 116, 116, 116, -, -, 116\n",
            "value_grooming: 116, 116, 116, -, 116, 116, 116, 116, 116, 116, 116, -, 116, 116, 116\n",
            "value_non_contact: 0, 116, 116, 116, 0, -, 116, 116, -, 116, 116, -, 116, 116, 116\n",
            "value_contact: 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116\n",
            "value_scratch: 0, -, 116, 116, 0, 116, 116, -, 116, 116, -, 116, -, 116, -\n",
            "value_waiting: 116, 116, 116, 116, 116, 0, 116, 116, 116, 116, -, 116, -, 116, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 367/1000 --- L(Train): 0.0162532 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 72):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + -0.0 chosen + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + -0.001 prev_waiting \n",
            "value_grooming[t+1] = -0.001 1 + 1.002 value_grooming[t] + 0.01 chosen + 0.006 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.0 prev_contact + -0.001 prev_scratch \n",
            "value_non_contact[t+1] = -0.372 1 + 1.001 value_non_contact[t] + 0.003 chosen + 0.001 sig_action + -0.478 sig_grooming + 0.001 sig_contact + 0.001 sig_scratch + -0.0 prev_action + -0.001 prev_grooming + -0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.033 1 + 0.999 value_contact[t] + -0.001 chosen + 0.001 sig_action + -0.001 sig_grooming + -0.0 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + -0.001 chosen + -0.001 sig_action + -0.122 sig_grooming + 0.004 sig_non_contact + -0.001 sig_contact + -0.001 sig_waiting + -0.0 prev_action + 0.001 prev_non_contact + 0.001 prev_scratch \n",
            "value_waiting[t+1] = 0.001 1 + 1.002 value_waiting[t] + -0.001 chosen + -0.001 sig_action + 0.001 sig_grooming + 0.21 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.001 prev_non_contact + -0.0 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 117, -, 117, -, 117, 117, 117, 117, 117, 117, 117, 117, -, -, 117\n",
            "value_grooming: 117, 117, 117, -, 117, 117, 117, 117, 117, 117, 117, -, 117, 117, -\n",
            "value_non_contact: 0, 117, 117, 117, 0, -, 117, 117, -, 117, 117, -, 117, 117, 117\n",
            "value_contact: 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117, 117\n",
            "value_scratch: 0, -, 117, 117, 0, 117, 117, -, 117, 117, -, 117, -, 117, -\n",
            "value_waiting: 117, 117, 117, 117, 117, 0, 117, 117, 117, 117, -, 117, -, 117, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 368/1000 --- L(Train): 0.0162408 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 71):\n",
            "value_action[t+1] = -0.002 1 + 1.0 value_action[t] + -0.0 chosen + 0.008 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.002 value_grooming[t] + 0.011 chosen + 0.008 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_contact + -0.001 prev_scratch \n",
            "value_non_contact[t+1] = -0.372 1 + 1.001 value_non_contact[t] + 0.003 chosen + -0.001 sig_action + -0.478 sig_grooming + 0.001 sig_contact + 0.001 sig_scratch + -0.0 prev_action + -0.001 prev_grooming + 0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.033 1 + 0.999 value_contact[t] + -0.0 chosen + 0.0 sig_action + -0.001 sig_grooming + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + -0.001 chosen + -0.001 sig_action + -0.122 sig_grooming + 0.003 sig_non_contact + -0.001 sig_contact + -0.001 sig_waiting + -0.001 prev_action + 0.001 prev_non_contact + 0.0 prev_scratch \n",
            "value_waiting[t+1] = 0.002 1 + 1.003 value_waiting[t] + -0.001 chosen + -0.001 sig_action + 0.001 sig_grooming + 0.211 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + 0.0 sig_waiting + 0.001 prev_action + -0.001 prev_non_contact + -0.0 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 118, -, 118, -, 118, 118, 118, 118, 118, 118, 118, 118, -, -, 118\n",
            "value_grooming: 118, 118, 118, -, 118, 118, 118, 118, 118, 118, 118, -, 118, 118, -\n",
            "value_non_contact: 0, 118, 118, 118, 0, -, 118, 118, -, 118, 118, -, 118, 118, 118\n",
            "value_contact: 118, 118, 118, 118, 118, -, 118, 118, 118, 118, 118, 118, 118, 118, 118\n",
            "value_scratch: 0, -, 118, 118, 0, 118, 118, -, 118, 118, -, 118, -, 118, -\n",
            "value_waiting: 118, 118, 118, 118, 118, 0, 118, 118, 118, 118, -, 118, -, 118, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 369/1000 --- L(Train): 0.0162395 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 70):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + 0.0 chosen + 0.008 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 1.002 value_grooming[t] + 0.011 chosen + 0.01 sig_grooming + -0.004 sig_non_contact + 0.0 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.0 prev_contact + 0.001 prev_scratch \n",
            "value_non_contact[t+1] = -0.372 1 + 0.999 value_non_contact[t] + 0.003 chosen + -0.001 sig_action + -0.478 sig_grooming + -0.001 sig_contact + -0.0 sig_scratch + 0.0 prev_action + -0.0 prev_grooming + 0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.034 1 + 0.999 value_contact[t] + 0.001 chosen + -0.001 sig_action + -0.001 sig_grooming + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + -0.0 chosen + 0.0 sig_action + -0.122 sig_grooming + 0.002 sig_non_contact + 0.0 sig_contact + -0.0 sig_waiting + 0.0 prev_action + -0.001 prev_scratch \n",
            "value_waiting[t+1] = 0.002 1 + 1.003 value_waiting[t] + 0.0 chosen + 0.001 sig_action + -0.002 sig_grooming + 0.213 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.0 prev_non_contact + 0.0 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 119, -, 119, -, 119, 119, 119, 119, 119, 119, 119, 119, -, -, 119\n",
            "value_grooming: 119, 119, 119, -, 119, 119, 119, 119, 119, 119, 119, -, 119, 119, -\n",
            "value_non_contact: 0, 119, 119, 119, 0, -, 119, 119, -, 119, 119, -, 119, 119, 119\n",
            "value_contact: 119, 119, 119, 119, 119, -, 119, 119, 119, 119, 119, 119, 119, 119, 119\n",
            "value_scratch: 0, -, 119, 119, 0, 119, 119, -, 119, 119, -, -, -, 119, -\n",
            "value_waiting: 119, 119, 119, 119, 119, 0, 119, 119, 119, 119, -, 119, -, 119, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 370/1000 --- L(Train): 0.0162302 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 69):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + 0.0 chosen + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 1.001 value_grooming[t] + 0.011 chosen + 0.011 sig_grooming + -0.005 sig_non_contact + -0.002 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.0 prev_contact + 0.001 prev_scratch \n",
            "value_non_contact[t+1] = -0.372 1 + 0.997 value_non_contact[t] + 0.002 chosen + -0.001 sig_action + -0.478 sig_grooming + -0.001 sig_contact + 0.0 prev_action + 0.002 prev_grooming + 0.001 prev_contact + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 1.001 value_contact[t] + 0.001 chosen + -0.001 sig_action + -0.0 sig_grooming + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.002 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + 0.002 chosen + 0.0 sig_action + -0.122 sig_grooming + 0.0 sig_non_contact + 0.0 sig_contact + 0.002 sig_waiting + 0.0 prev_action + -0.001 prev_scratch \n",
            "value_waiting[t+1] = 0.002 1 + 1.002 value_waiting[t] + -0.0 chosen + 0.001 sig_action + -0.003 sig_grooming + 0.214 sig_non_contact + 0.0 sig_contact + 0.001 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + 0.0 prev_non_contact + 0.0 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 120, -, 120, -, 120, 120, 120, 120, 120, 120, 120, 120, -, -, 120\n",
            "value_grooming: 120, 120, 120, -, 120, 120, 120, 120, 120, 120, 120, -, 120, 120, -\n",
            "value_non_contact: 0, 120, 120, 120, 0, -, 120, -, -, 120, 120, -, 120, 120, 120\n",
            "value_contact: 120, 120, 120, 120, 120, -, 120, 120, 120, 120, 120, 120, 120, 120, 120\n",
            "value_scratch: 0, -, 120, 120, 0, 120, 120, -, 120, 120, -, -, -, 120, -\n",
            "value_waiting: 120, 120, 120, 120, 120, 0, 120, 120, 120, 120, -, 120, -, 120, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 371/1000 --- L(Train): 0.0162318 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 68):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + -0.001 chosen + 0.01 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + 0.0 prev_non_contact + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 0.998 value_grooming[t] + 0.011 chosen + 0.012 sig_grooming + -0.005 sig_non_contact + -0.002 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_contact + -0.0 prev_scratch \n",
            "value_non_contact[t+1] = -0.372 1 + 0.997 value_non_contact[t] + 0.0 chosen + 0.0 sig_action + -0.478 sig_grooming + 0.0 sig_contact + -0.001 prev_action + 0.002 prev_grooming + -0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.002 value_contact[t] + -0.0 chosen + 0.0 sig_action + 0.001 sig_grooming + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.002 prev_action + 0.0 prev_grooming + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + 0.002 chosen + -0.001 sig_action + -0.122 sig_grooming + -0.002 sig_non_contact + -0.0 sig_contact + 0.002 sig_waiting + -0.001 prev_action + 0.0 prev_scratch \n",
            "value_waiting[t+1] = 0.002 1 + 1.0 value_waiting[t] + 0.001 chosen + -0.0 sig_action + -0.004 sig_grooming + 0.215 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + -0.001 prev_non_contact + -0.001 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 121, -, 121, -, 121, 121, 121, 121, 121, 121, 121, 121, -, -, 121\n",
            "value_grooming: 121, 121, 121, -, 121, 121, 121, 121, 121, 121, 121, -, 121, 121, -\n",
            "value_non_contact: 0, 121, 121, 121, 0, -, 121, -, -, 121, 121, -, 121, 121, 121\n",
            "value_contact: 121, 121, 121, 121, 121, -, 121, 121, 121, 121, 121, -, 121, 121, 121\n",
            "value_scratch: 0, -, 121, 121, 0, 121, 121, -, 121, 121, -, -, -, 121, -\n",
            "value_waiting: 121, 121, 121, 121, 121, 0, 121, 121, 121, 121, -, 121, -, 121, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 372/1000 --- L(Train): 0.0162437 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 67):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + -0.001 chosen + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_non_contact + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 0.997 value_grooming[t] + 0.01 chosen + 0.013 sig_grooming + -0.005 sig_non_contact + -0.002 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_contact + 0.0 prev_scratch \n",
            "value_non_contact[t+1] = -0.372 1 + 0.997 value_non_contact[t] + -0.002 chosen + 0.0 sig_action + -0.478 sig_grooming + 0.0 sig_contact + -0.001 prev_action + 0.002 prev_grooming + -0.0 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.041 1 + 1.001 value_contact[t] + 0.0 chosen + -0.0 sig_action + 0.001 sig_grooming + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.002 prev_action + 0.0 prev_contact + 0.0 prev_scratch + 0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + 0.002 chosen + -0.001 sig_action + -0.122 sig_grooming + -0.002 sig_non_contact + -0.0 sig_contact + 0.002 sig_waiting + -0.001 prev_action + -0.0 prev_scratch \n",
            "value_waiting[t+1] = 0.003 1 + 0.999 value_waiting[t] + 0.001 chosen + 0.0 sig_action + -0.004 sig_grooming + 0.216 sig_non_contact + -0.001 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_non_contact + -0.001 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 122, -, 122, -, 122, 122, 122, 122, 122, 122, 122, 122, -, -, 122\n",
            "value_grooming: 122, 122, 122, -, 122, 122, 122, 122, 122, 122, 122, -, 122, 122, -\n",
            "value_non_contact: 0, 122, 122, 122, 0, -, 122, -, -, 122, 122, -, 122, 122, 122\n",
            "value_contact: 122, 122, 122, 122, 122, -, 122, 122, 122, 122, -, -, 122, 122, 122\n",
            "value_scratch: 0, -, 122, 122, 0, 122, 122, -, 122, 122, -, -, -, 122, -\n",
            "value_waiting: 122, 122, 122, 122, 122, 0, 122, 122, 122, 122, -, 122, -, 122, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 373/1000 --- L(Train): 0.0162300 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 66):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + -0.0 chosen + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_non_contact + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 0.997 value_grooming[t] + 0.009 chosen + 0.013 sig_grooming + -0.004 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.0 prev_contact + -0.001 prev_scratch \n",
            "value_non_contact[t+1] = -0.372 1 + 0.997 value_non_contact[t] + -0.002 chosen + -0.001 sig_action + -0.478 sig_grooming + -0.001 sig_contact + -0.0 prev_action + 0.001 prev_grooming + 0.001 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.042 1 + 1.0 value_contact[t] + -0.001 chosen + 0.001 sig_action + -0.002 sig_grooming + -0.0 sig_contact + -0.0 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + 0.001 chosen + -0.0 sig_action + -0.122 sig_grooming + 0.0 sig_non_contact + 0.001 sig_contact + 0.001 sig_waiting + -0.0 prev_action + 0.001 prev_scratch \n",
            "value_waiting[t+1] = 0.003 1 + 0.999 value_waiting[t] + -0.001 chosen + -0.001 sig_action + -0.004 sig_grooming + 0.217 sig_non_contact + -0.0 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.0 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 123, -, 123, -, 123, 123, 123, 123, 123, 123, 123, 123, -, -, 123\n",
            "value_grooming: 123, 123, 123, -, 123, 123, 123, 123, 123, 123, 123, -, 123, 123, -\n",
            "value_non_contact: 0, 123, 123, 123, 0, -, 123, -, -, 123, 123, -, 123, 123, 123\n",
            "value_contact: 123, 123, 123, 123, 123, -, 123, 123, 123, 123, -, -, 123, 123, 123\n",
            "value_scratch: 0, -, 123, 123, 0, 123, 123, -, 123, 123, -, -, -, 123, -\n",
            "value_waiting: 123, 123, 123, 123, 123, 0, 123, 123, 123, 123, -, -, -, 123, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 374/1000 --- L(Train): 0.0162138 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 65):\n",
            "value_action[t+1] = -0.002 1 + 1.0 value_action[t] + 0.002 chosen + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.0 prev_non_contact + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.0 1 + 0.998 value_grooming[t] + 0.008 chosen + 0.012 sig_grooming + -0.003 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.002 prev_contact + -0.001 prev_scratch \n",
            "value_non_contact[t+1] = -0.372 1 + 0.999 value_non_contact[t] + -0.0 sig_action + -0.478 sig_grooming + -0.001 sig_contact + 0.002 prev_action + -0.002 prev_grooming + 0.0 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.042 1 + 0.999 value_contact[t] + -0.0 chosen + 0.001 sig_action + -0.003 sig_grooming + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + 0.002 prev_action + -0.0 prev_contact + -0.0 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + -0.002 chosen + 0.002 sig_action + -0.122 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + -0.002 sig_waiting + 0.002 prev_action + 0.001 prev_scratch \n",
            "value_waiting[t+1] = 0.003 1 + 1.0 value_waiting[t] + -0.001 chosen + -0.001 sig_action + -0.003 sig_grooming + 0.218 sig_non_contact + 0.002 sig_contact + 0.0 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.002 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 124, -, 124, -, 124, 124, 124, 124, 124, 124, 124, 124, -, -, 124\n",
            "value_grooming: 124, 124, 124, -, 124, 124, 124, 124, 124, 124, 124, -, 124, 124, -\n",
            "value_non_contact: 0, 124, -, 124, 0, -, 124, -, -, 124, 124, -, 124, 124, 124\n",
            "value_contact: 124, 124, 124, 124, 124, -, 124, 124, 124, 124, -, -, 124, 124, 124\n",
            "value_scratch: 0, -, 124, 124, 0, 124, 124, -, 124, 124, -, -, -, 124, -\n",
            "value_waiting: 124, 124, 124, 124, 124, 0, 124, 124, 124, 124, -, -, -, 124, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 375/1000 --- L(Train): 0.0162449 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 64):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + 0.002 chosen + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + 0.0 prev_waiting \n",
            "value_grooming[t+1] = -0.001 1 + 1.0 value_grooming[t] + 0.006 chosen + 0.012 sig_grooming + -0.001 sig_non_contact + 0.003 sig_contact + -0.002 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.002 prev_contact + 0.001 prev_scratch \n",
            "value_non_contact[t+1] = -0.372 1 + 1.0 value_non_contact[t] + 0.001 sig_action + -0.479 sig_grooming + -0.0 sig_contact + 0.002 prev_action + -0.003 prev_grooming + -0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.041 1 + 1.0 value_contact[t] + 0.001 chosen + -0.001 sig_action + -0.003 sig_grooming + 0.002 sig_contact + 0.002 sig_scratch + 0.0 sig_waiting + 0.003 prev_action + 0.001 prev_contact + 0.001 prev_scratch + -0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + -0.003 chosen + 0.002 sig_action + -0.122 sig_grooming + 0.001 sig_non_contact + 0.0 sig_contact + -0.002 sig_waiting + 0.002 prev_action + -0.001 prev_scratch \n",
            "value_waiting[t+1] = 0.003 1 + 1.0 value_waiting[t] + 0.0 chosen + 0.001 sig_action + -0.002 sig_grooming + 0.218 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + -0.0 prev_action + 0.002 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 125, -, 125, -, 125, 125, 125, 125, 125, 125, 125, 125, -, -, 125\n",
            "value_grooming: 125, 125, 125, -, 125, 125, 125, 125, 125, 125, 125, -, 125, 125, -\n",
            "value_non_contact: 0, 125, -, 125, 0, -, 125, -, -, 125, 125, -, 125, 125, 125\n",
            "value_contact: 125, 125, 125, 125, 125, -, 125, 125, 125, 125, -, -, 125, 125, 125\n",
            "value_scratch: 0, -, 125, 125, 0, 125, 125, -, 125, 125, -, -, -, 125, -\n",
            "value_waiting: 125, -, 125, 125, 125, 0, 125, 125, 125, 125, -, -, -, 125, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 376/1000 --- L(Train): 0.0162525 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 63):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + 0.002 chosen + 0.009 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + -0.001 prev_non_contact + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.002 value_grooming[t] + 0.005 chosen + 0.011 sig_grooming + 0.001 sig_non_contact + 0.002 sig_contact + -0.002 sig_scratch + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.002 prev_contact + 0.001 prev_scratch \n",
            "value_non_contact[t+1] = -0.372 1 + 1.0 value_non_contact[t] + 0.001 sig_action + -0.479 sig_grooming + 0.002 sig_contact + 0.002 prev_action + -0.002 prev_grooming + -0.001 prev_contact + 0.002 prev_scratch + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] + 0.001 chosen + -0.001 sig_action + -0.003 sig_grooming + 0.002 sig_contact + 0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + -0.002 chosen + 0.002 sig_action + -0.122 sig_grooming + 0.001 sig_non_contact + -0.002 sig_contact + -0.002 sig_waiting + 0.002 prev_action + -0.001 prev_scratch \n",
            "value_waiting[t+1] = 0.002 1 + 1.0 value_waiting[t] + 0.001 sig_action + 0.0 sig_grooming + 0.218 sig_non_contact + 0.002 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.0 prev_action + 0.002 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 126, -, 126, -, 126, 126, 126, 126, 126, 126, 126, 126, -, -, 126\n",
            "value_grooming: 126, 126, 126, -, 126, 126, 126, 126, 126, 126, 126, -, 126, 126, -\n",
            "value_non_contact: 0, 126, -, 126, 0, -, 126, -, -, 126, 126, -, 126, 126, 126\n",
            "value_contact: 126, 126, 126, 126, 126, -, 126, 126, 126, 126, -, -, 126, 126, 126\n",
            "value_scratch: 0, -, 126, 126, 0, 126, 126, -, 126, 126, -, -, -, 126, -\n",
            "value_waiting: 126, -, -, 126, 126, 0, 126, 126, 126, 126, -, -, -, 126, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 377/1000 --- L(Train): 0.0162526 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 62):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + 0.001 chosen + 0.01 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.0 prev_non_contact + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 1.003 value_grooming[t] + 0.003 chosen + 0.01 sig_grooming + 0.001 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_contact + -0.0 prev_scratch \n",
            "value_non_contact[t+1] = -0.372 1 + 1.0 value_non_contact[t] + -0.0 sig_action + -0.479 sig_grooming + 0.002 sig_contact + 0.001 prev_action + -0.001 prev_grooming + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 1.0 value_contact[t] + -0.0 chosen + 0.0 sig_action + -0.002 sig_grooming + 0.001 sig_contact + 0.0 sig_scratch + -0.002 sig_waiting + 0.001 prev_action + -0.0 prev_contact + -0.0 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + -0.001 chosen + 0.001 sig_action + -0.122 sig_grooming + 0.0 sig_non_contact + -0.002 sig_contact + -0.001 sig_waiting + 0.0 prev_action + 0.0 prev_scratch \n",
            "value_waiting[t+1] = 0.002 1 + 1.0 value_waiting[t] + -0.0 sig_action + 0.0 sig_grooming + 0.218 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.001 prev_action + 0.001 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 127, -, 127, -, 127, 127, 127, 127, 127, 127, 127, 127, -, -, 127\n",
            "value_grooming: 127, 127, 127, -, 127, 127, 127, 127, 127, 127, 127, -, 127, 127, -\n",
            "value_non_contact: 0, 127, -, 127, 0, -, 127, -, -, 127, 127, -, -, 127, 127\n",
            "value_contact: 127, 127, 127, 127, 127, -, 127, 127, 127, 127, -, -, 127, 127, 127\n",
            "value_scratch: 0, -, 127, 127, 0, 127, 127, -, 127, 127, -, -, -, 127, -\n",
            "value_waiting: 127, -, -, 127, 127, 0, 127, 127, 127, 127, -, -, -, 127, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 378/1000 --- L(Train): 0.0162227 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 61):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + -0.002 chosen + 0.009 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.0 prev_non_contact + -0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 1.003 value_grooming[t] + 0.002 chosen + 0.009 sig_grooming + -0.0 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.002 prev_contact + -0.0 prev_scratch \n",
            "value_non_contact[t+1] = -0.372 1 + 0.999 value_non_contact[t] + 0.0 sig_action + -0.479 sig_grooming + 0.002 sig_contact + -0.002 prev_action + 0.001 prev_grooming + -0.002 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.034 1 + 1.0 value_contact[t] + 0.0 chosen + 0.0 sig_action + -0.001 sig_grooming + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + 0.0 prev_contact + 0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + 0.001 chosen + -0.002 sig_action + -0.122 sig_grooming + -0.001 sig_non_contact + -0.002 sig_contact + 0.001 sig_waiting + -0.002 prev_action + 0.0 prev_scratch \n",
            "value_waiting[t+1] = 0.001 1 + 1.0 value_waiting[t] + -0.0 sig_action + -0.002 sig_grooming + 0.218 sig_non_contact + -0.002 sig_contact + 0.0 sig_waiting + -0.001 prev_action + -0.002 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 128, -, 128, -, 128, 128, 128, 128, 128, 128, 128, 128, -, -, 128\n",
            "value_grooming: 128, 128, 128, -, 128, 128, 128, 128, 128, 128, 128, -, 128, 128, -\n",
            "value_non_contact: 0, 128, -, 128, 0, -, 128, -, -, 128, 128, -, -, 128, 128\n",
            "value_contact: 128, 128, 128, 128, 128, -, 128, 128, 128, 128, -, -, 128, 128, 128\n",
            "value_scratch: 0, -, 128, 128, 0, 128, 128, -, 128, 128, -, -, -, 128, -\n",
            "value_waiting: 128, -, -, 128, 128, 0, 128, -, 128, 128, -, -, -, 128, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 379/1000 --- L(Train): 0.0162385 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 60):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + -0.003 chosen + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.001 prev_non_contact + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 1.002 value_grooming[t] + 0.0 chosen + 0.008 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + 0.002 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.003 prev_contact + 0.001 prev_scratch \n",
            "value_non_contact[t+1] = -0.371 1 + 0.998 value_non_contact[t] + -0.001 sig_action + -0.479 sig_grooming + 0.001 sig_contact + -0.003 prev_action + 0.001 prev_grooming + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.034 1 + 0.999 value_contact[t] + -0.001 chosen + -0.001 sig_action + 0.001 sig_grooming + -0.003 sig_contact + -0.003 sig_scratch + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + 0.001 chosen + -0.003 sig_action + -0.122 sig_grooming + -0.001 sig_non_contact + -0.001 sig_contact + 0.002 sig_waiting + -0.003 prev_action + -0.001 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.001 sig_action + -0.003 sig_grooming + 0.217 sig_non_contact + -0.003 sig_contact + -0.001 sig_waiting + 0.001 prev_action + -0.003 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 129, -, 129, -, 129, 129, 129, 129, 129, 129, 129, 129, -, -, 129\n",
            "value_grooming: 129, 129, 129, -, 129, 129, 129, 129, 129, 129, 129, -, 129, 129, -\n",
            "value_non_contact: 0, 129, -, 129, 0, -, 129, -, -, 129, 129, -, -, 129, 129\n",
            "value_contact: 129, 129, 129, 129, 129, -, 129, 129, 129, 129, -, -, 129, 129, 129\n",
            "value_scratch: 0, -, 129, 129, 0, 129, 129, -, 129, 129, -, -, -, 129, -\n",
            "value_waiting: -, -, -, 129, 129, 0, 129, -, 129, 129, -, -, -, 129, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 380/1000 --- L(Train): 0.0162532 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 59):\n",
            "value_action[t+1] = -0.002 1 + 1.0 value_action[t] + -0.002 chosen + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + 0.001 prev_non_contact + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 1.0 value_grooming[t] + -0.001 chosen + 0.007 sig_grooming + -0.002 sig_non_contact + -0.001 sig_contact + 0.001 sig_scratch + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.003 prev_contact + 0.001 prev_scratch \n",
            "value_non_contact[t+1] = -0.371 1 + 0.998 value_non_contact[t] + -0.001 sig_action + -0.479 sig_grooming + -0.002 sig_contact + -0.003 prev_action + 0.001 prev_grooming + -0.002 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.034 1 + 0.999 value_contact[t] + -0.001 chosen + -0.001 sig_action + 0.001 sig_grooming + -0.003 sig_contact + -0.003 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + -0.001 prev_contact + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + 0.001 chosen + -0.002 sig_action + -0.122 sig_grooming + 0.002 sig_non_contact + 0.002 sig_contact + 0.001 sig_waiting + -0.003 prev_action + -0.001 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.001 sig_action + -0.003 sig_grooming + 0.217 sig_non_contact + -0.003 sig_contact + -0.001 sig_waiting + 0.001 prev_action + -0.003 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 130, -, 130, -, 130, 130, 130, 130, 130, 130, 130, 130, -, -, 130\n",
            "value_grooming: 130, -, 130, -, 130, 130, 130, 130, 130, 130, 130, -, 130, 130, -\n",
            "value_non_contact: 0, 130, -, 130, 0, -, 130, -, -, 130, 130, -, -, 130, 130\n",
            "value_contact: 130, 130, 130, 130, 130, -, 130, 130, 130, 130, -, -, 130, 130, 130\n",
            "value_scratch: 0, -, 130, 130, 0, 130, 130, -, 130, 130, -, -, -, 130, -\n",
            "value_waiting: -, -, -, 130, 130, 0, 130, -, 130, 130, -, -, -, 130, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 381/1000 --- L(Train): 0.0162498 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 58):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + -0.001 chosen + 0.008 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + -0.001 prev_non_contact + 0.003 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 1.0 value_grooming[t] + 0.002 chosen + 0.006 sig_grooming + -0.001 sig_non_contact + 0.0 sig_contact + -0.001 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.001 prev_contact + 0.0 prev_scratch \n",
            "value_non_contact[t+1] = -0.371 1 + 0.998 value_non_contact[t] + 0.001 sig_action + -0.479 sig_grooming + -0.003 sig_contact + -0.001 prev_action + -0.0 prev_grooming + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 0.999 value_contact[t] + 0.001 chosen + -0.0 sig_action + -0.001 sig_grooming + -0.002 sig_contact + -0.002 sig_scratch + 0.003 sig_waiting + 0.0 prev_action + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + -0.0 chosen + -0.001 sig_action + -0.122 sig_grooming + 0.003 sig_non_contact + 0.003 sig_contact + -0.0 sig_waiting + -0.002 prev_action + -0.0 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.0 sig_action + -0.003 sig_grooming + 0.217 sig_non_contact + -0.001 sig_contact + -0.0 sig_waiting + -0.0 prev_action + -0.002 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 131, -, 131, -, 131, 131, 131, 131, 131, 131, 131, 131, -, -, 131\n",
            "value_grooming: 131, -, 131, -, 131, 131, 131, -, 131, 131, 131, -, 131, 131, -\n",
            "value_non_contact: 0, 131, -, 131, 0, -, 131, -, -, 131, 131, -, -, 131, 131\n",
            "value_contact: 131, 131, 131, 131, 131, -, 131, 131, 131, 131, -, -, 131, 131, 131\n",
            "value_scratch: 0, -, 131, 131, 0, 131, 131, -, 131, 131, -, -, -, 131, -\n",
            "value_waiting: -, -, -, 131, 131, 0, 131, -, 131, 131, -, -, -, 131, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 382/1000 --- L(Train): 0.0162246 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 57):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + 0.001 chosen + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + -0.001 prev_non_contact + 0.002 prev_waiting \n",
            "value_grooming[t+1] = 0.003 1 + 1.0 value_grooming[t] + 0.004 chosen + 0.005 sig_grooming + -0.0 sig_non_contact + 0.0 sig_contact + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.001 prev_contact + -0.002 prev_scratch \n",
            "value_non_contact[t+1] = -0.371 1 + 0.999 value_non_contact[t] + 0.001 sig_action + -0.479 sig_grooming + -0.002 sig_contact + 0.0 prev_action + -0.0 prev_grooming + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.001 value_contact[t] + 0.001 chosen + 0.002 sig_action + -0.002 sig_grooming + 0.0 sig_contact + 0.0 sig_scratch + 0.003 sig_waiting + 0.0 prev_action + 0.001 prev_contact + 0.001 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + -0.0 chosen + 0.001 sig_action + -0.122 sig_grooming + 0.004 sig_non_contact + 0.003 sig_contact + -0.0 sig_waiting + 0.0 prev_action + 0.002 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + -0.002 sig_action + -0.002 sig_grooming + 0.216 sig_non_contact + 0.0 sig_contact + 0.002 sig_waiting + 0.0 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 132, -, 132, -, 132, 132, 132, 132, 132, 132, 132, 132, -, -, 132\n",
            "value_grooming: 132, -, 132, -, 132, 132, 132, -, 132, 132, 132, -, 132, 132, -\n",
            "value_non_contact: 0, 132, -, 132, 0, -, 132, -, -, 132, 132, -, -, 132, 132\n",
            "value_contact: 132, 132, 132, 132, 132, -, 132, 132, 132, 132, -, -, 132, 132, 132\n",
            "value_scratch: 0, -, 132, 132, 0, 132, 132, -, 132, 132, -, -, -, 132, -\n",
            "value_waiting: -, -, -, 132, 132, 0, 132, -, 132, -, -, -, -, 132, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 383/1000 --- L(Train): 0.0162041 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 56):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + 0.001 chosen + 0.01 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.0 prev_non_contact + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 1.0 value_grooming[t] + 0.006 chosen + 0.004 sig_grooming + 0.001 sig_non_contact + -0.001 sig_contact + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_contact + -0.002 prev_scratch \n",
            "value_non_contact[t+1] = -0.371 1 + 1.001 value_non_contact[t] + -0.0 sig_action + -0.479 sig_grooming + -0.001 sig_contact + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 1.002 value_contact[t] + 0.002 sig_action + -0.002 sig_grooming + 0.001 sig_contact + 0.001 sig_scratch + 0.002 sig_waiting + -0.001 prev_action + -0.0 prev_contact + -0.0 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + 0.001 chosen + 0.001 sig_action + -0.122 sig_grooming + 0.004 sig_non_contact + 0.001 sig_contact + 0.001 sig_waiting + 0.001 prev_action + 0.002 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + -0.002 sig_action + -0.001 sig_grooming + 0.216 sig_non_contact + 0.001 sig_contact + 0.002 sig_waiting + 0.001 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 133, -, 133, -, 133, 133, 133, 133, 133, 133, 133, 133, -, -, 133\n",
            "value_grooming: 133, -, 133, -, 133, 133, 133, -, 133, 133, 133, -, 133, 133, -\n",
            "value_non_contact: 0, 133, -, 133, 0, -, 133, -, -, 133, 133, -, -, 133, 133\n",
            "value_contact: 133, 133, -, 133, 133, -, 133, 133, 133, 133, -, -, 133, 133, 133\n",
            "value_scratch: 0, -, 133, 133, 0, 133, 133, -, 133, 133, -, -, -, 133, -\n",
            "value_waiting: -, -, -, 133, 133, 0, 133, -, 133, -, -, -, -, 133, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 384/1000 --- L(Train): 0.0162178 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 55):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + 0.001 chosen + 0.009 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.002 1 + 1.0 value_grooming[t] + 0.008 chosen + 0.003 sig_grooming + 0.001 sig_non_contact + -0.0 sig_contact + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_contact + -0.002 prev_scratch \n",
            "value_non_contact[t+1] = -0.371 1 + 1.0 value_non_contact[t] + -0.0 sig_action + -0.479 sig_grooming + 0.001 sig_contact + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.041 1 + 1.001 value_contact[t] + 0.002 sig_action + -0.002 sig_grooming + 0.001 sig_contact + 0.001 sig_scratch + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_contact + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + 0.0 chosen + 0.001 sig_action + -0.122 sig_grooming + 0.003 sig_non_contact + -0.001 sig_contact + 0.001 sig_waiting + 0.001 prev_action + 0.002 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + -0.002 sig_action + 0.001 sig_grooming + 0.216 sig_non_contact + 0.001 sig_contact + 0.002 sig_waiting + 0.001 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 134, -, 134, -, 134, 134, 134, 134, 134, 134, 134, -, -, -, 134\n",
            "value_grooming: 134, -, 134, -, 134, 134, 134, -, 134, 134, 134, -, 134, 134, -\n",
            "value_non_contact: 0, 134, -, 134, 0, -, 134, -, -, 134, 134, -, -, 134, 134\n",
            "value_contact: 134, 134, -, 134, 134, -, 134, 134, 134, 134, -, -, 134, 134, 134\n",
            "value_scratch: 0, -, 134, 134, 0, 134, 134, -, 134, 134, -, -, -, 134, -\n",
            "value_waiting: -, -, -, 134, 134, 0, 134, -, 134, -, -, -, -, 134, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 385/1000 --- L(Train): 0.0161961 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 54):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + -0.0 chosen + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.001 1 + 1.0 value_grooming[t] + 0.01 chosen + 0.002 sig_grooming + -0.002 sig_non_contact + 0.001 sig_contact + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.0 prev_contact + -0.001 prev_scratch \n",
            "value_non_contact[t+1] = -0.371 1 + 0.998 value_non_contact[t] + 0.001 sig_action + -0.479 sig_grooming + 0.001 sig_contact + -0.0 prev_action + -0.001 prev_grooming + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.041 1 + 1.0 value_contact[t] + 0.001 sig_action + -0.001 sig_grooming + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + -0.001 chosen + -0.122 sig_grooming + 0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_waiting + -0.0 prev_action + 0.001 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + -0.001 sig_action + 0.001 sig_grooming + 0.215 sig_non_contact + -0.0 sig_contact + 0.001 sig_waiting + -0.0 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 135, -, 135, -, 135, 135, 135, 135, 135, 135, 135, -, -, -, 135\n",
            "value_grooming: 135, -, 135, -, 135, 135, 135, -, 135, 135, 135, -, 135, 135, -\n",
            "value_non_contact: 0, 135, -, 135, 0, -, 135, -, -, 135, 135, -, -, 135, 135\n",
            "value_contact: 135, 135, -, 135, 135, -, 135, 135, 135, 135, -, -, 135, 135, 135\n",
            "value_scratch: 0, -, 135, -, 0, 135, 135, -, 135, 135, -, -, -, 135, -\n",
            "value_waiting: -, -, -, 135, 135, 0, 135, -, 135, -, -, -, -, 135, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 386/1000 --- L(Train): 0.0161867 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 53):\n",
            "value_action[t+1] = -0.002 1 + 1.0 value_action[t] + -0.0 chosen + 0.008 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.011 chosen + 0.001 sig_grooming + -0.003 sig_non_contact + 0.001 sig_contact + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_contact + 0.002 prev_scratch \n",
            "value_non_contact[t+1] = -0.371 1 + 0.997 value_non_contact[t] + 0.001 sig_action + -0.479 sig_grooming + 0.001 sig_contact + -0.0 prev_action + -0.001 prev_grooming + -0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 1.0 value_contact[t] + -0.002 sig_action + 0.001 sig_grooming + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + -0.001 chosen + -0.122 sig_grooming + 0.0 sig_non_contact + -0.001 sig_contact + -0.001 sig_waiting + -0.001 prev_action + -0.002 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.002 sig_action + -0.001 sig_grooming + 0.215 sig_non_contact + -0.0 sig_contact + -0.002 sig_waiting + -0.0 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 136, -, 136, -, 136, 136, 136, 136, 136, 136, 136, -, -, -, 136\n",
            "value_grooming: -, -, 136, -, 136, 136, 136, -, 136, 136, 136, -, 136, 136, -\n",
            "value_non_contact: 0, 136, -, 136, 0, -, 136, -, -, 136, 136, -, -, 136, 136\n",
            "value_contact: 136, 136, -, 136, 136, -, 136, 136, 136, 136, -, -, 136, 136, 136\n",
            "value_scratch: 0, -, 136, -, 0, 136, 136, -, 136, 136, -, -, -, 136, -\n",
            "value_waiting: -, -, -, 136, 136, 0, 136, -, 136, -, -, -, -, 136, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 387/1000 --- L(Train): 0.0161887 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 52):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + 0.0 chosen + 0.008 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.012 chosen + -0.004 sig_non_contact + -0.0 sig_contact + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.0 prev_contact + 0.003 prev_scratch \n",
            "value_non_contact[t+1] = -0.371 1 + 0.996 value_non_contact[t] + 0.0 sig_action + -0.479 sig_grooming + -0.0 sig_contact + 0.0 prev_action + 0.0 prev_grooming + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + -0.003 sig_action + 0.001 sig_grooming + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + 0.0 prev_contact + 0.0 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + 0.0 chosen + -0.122 sig_grooming + -0.002 sig_non_contact + 0.0 sig_contact + 0.0 sig_waiting + 0.0 prev_action + -0.003 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.003 sig_action + -0.002 sig_grooming + 0.215 sig_non_contact + 0.0 sig_contact + -0.003 sig_waiting + 0.0 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 137, -, 137, -, 137, 137, 137, 137, 137, 137, 137, -, -, -, 137\n",
            "value_grooming: -, -, 137, -, -, 137, 137, -, 137, 137, 137, -, 137, 137, -\n",
            "value_non_contact: 0, 137, -, 137, 0, -, 137, -, -, 137, 137, -, -, 137, 137\n",
            "value_contact: 137, 137, -, 137, 137, -, 137, 137, 137, 137, -, -, 137, 137, 137\n",
            "value_scratch: 0, -, 137, -, 0, 137, 137, -, 137, 137, -, -, -, 137, -\n",
            "value_waiting: -, -, -, 137, 137, 0, 137, -, 137, -, -, -, -, 137, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 388/1000 --- L(Train): 0.0161813 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 51):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + 0.0 chosen + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.0 prev_waiting \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.013 chosen + -0.004 sig_non_contact + 0.0 sig_contact + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.0 prev_contact + 0.002 prev_scratch \n",
            "value_non_contact[t+1] = -0.371 1 + 0.996 value_non_contact[t] + -0.002 sig_action + -0.479 sig_grooming + -0.0 sig_contact + 0.0 prev_action + 0.0 prev_scratch + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] + -0.002 sig_action + -0.001 sig_grooming + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + 0.0 prev_action + -0.002 prev_contact + -0.002 prev_scratch + -0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + -0.0 chosen + -0.122 sig_grooming + -0.002 sig_non_contact + 0.0 sig_contact + 0.0 sig_waiting + 0.0 prev_action + -0.002 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.003 sig_action + -0.003 sig_grooming + 0.215 sig_non_contact + 0.0 sig_contact + -0.002 sig_waiting + 0.0 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 138, -, 138, -, 138, 138, 138, 138, 138, 138, 138, -, -, -, 138\n",
            "value_grooming: -, -, 138, -, -, 138, 138, -, 138, 138, 138, -, 138, 138, -\n",
            "value_non_contact: 0, 138, -, 138, 0, -, 138, -, -, 138, -, -, -, 138, 138\n",
            "value_contact: 138, 138, -, 138, 138, -, 138, 138, 138, 138, -, -, 138, 138, 138\n",
            "value_scratch: 0, -, 138, -, 0, 138, 138, -, 138, 138, -, -, -, 138, -\n",
            "value_waiting: -, -, -, 138, 138, 0, 138, -, 138, -, -, -, -, 138, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 389/1000 --- L(Train): 0.0161745 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 50):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + -0.001 chosen + 0.01 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.013 chosen + -0.003 sig_non_contact + -0.001 sig_contact + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_contact + 0.001 prev_scratch \n",
            "value_non_contact[t+1] = -0.371 1 + 0.997 value_non_contact[t] + -0.002 sig_action + -0.479 sig_grooming + 0.001 sig_contact + -0.001 prev_action + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.001 value_contact[t] + -0.001 sig_action + -0.002 sig_grooming + -0.001 sig_contact + -0.001 sig_scratch + -0.0 sig_waiting + -0.001 prev_action + -0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + 0.001 chosen + -0.122 sig_grooming + -0.0 sig_contact + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.001 sig_action + -0.002 sig_grooming + 0.215 sig_non_contact + -0.001 sig_contact + -0.001 sig_waiting + -0.001 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 139, -, 139, -, 139, 139, 139, 139, 139, 139, 139, -, -, -, 139\n",
            "value_grooming: -, -, 139, -, -, 139, 139, -, 139, 139, 139, -, 139, 139, -\n",
            "value_non_contact: 0, 139, -, 139, 0, -, 139, -, -, 139, -, -, -, 139, 139\n",
            "value_contact: 139, 139, -, 139, 139, -, 139, 139, 139, 139, -, -, 139, 139, 139\n",
            "value_scratch: 0, -, 139, -, 0, -, 139, -, 139, 139, -, -, -, 139, -\n",
            "value_waiting: -, -, -, 139, 139, 0, 139, -, 139, -, -, -, -, 139, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 390/1000 --- L(Train): 0.0161935 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 49):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + -0.001 chosen + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_waiting \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.014 chosen + -0.002 sig_non_contact + -0.001 sig_contact + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_contact + -0.001 prev_scratch \n",
            "value_non_contact[t+1] = -0.371 1 + 0.998 value_non_contact[t] + -0.002 sig_action + -0.479 sig_grooming + 0.0 sig_contact + -0.001 prev_action + -0.001 prev_scratch + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 1.0 value_contact[t] + 0.001 sig_action + -0.003 sig_grooming + -0.001 sig_contact + -0.001 sig_scratch + -0.001 prev_action + -0.002 prev_contact + -0.002 prev_scratch + 0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.239 1 + 1.0 value_scratch[t] + 0.001 chosen + -0.122 sig_grooming + -0.0 sig_contact + -0.001 sig_waiting + -0.001 prev_action + 0.001 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + -0.001 sig_action + -0.002 sig_grooming + 0.215 sig_non_contact + -0.001 sig_contact + 0.001 sig_waiting + -0.001 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 140, -, 140, -, 140, 140, 140, 140, 140, 140, 140, -, -, -, 140\n",
            "value_grooming: -, -, 140, -, -, 140, 140, -, 140, 140, 140, -, 140, 140, -\n",
            "value_non_contact: 0, 140, -, 140, 0, -, 140, -, -, 140, -, -, -, 140, 140\n",
            "value_contact: 140, 140, -, 140, 140, -, 140, 140, -, 140, -, -, 140, 140, 140\n",
            "value_scratch: 0, -, 140, -, 0, -, 140, -, 140, 140, -, -, -, 140, -\n",
            "value_waiting: -, -, -, 140, 140, 0, 140, -, 140, -, -, -, -, 140, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 391/1000 --- L(Train): 0.0161851 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 48):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + -0.0 chosen + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.014 chosen + -0.0 sig_non_contact + 0.001 sig_contact + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.0 prev_contact + -0.001 prev_scratch \n",
            "value_non_contact[t+1] = -0.371 1 + 1.0 value_non_contact[t] + -0.001 sig_action + -0.479 sig_grooming + -0.001 sig_contact + -0.0 prev_action + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 0.999 value_contact[t] + 0.001 sig_action + -0.002 sig_grooming + -0.0 sig_contact + -0.0 sig_scratch + 0.001 prev_action + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + -0.001 chosen + -0.122 sig_grooming + 0.001 sig_contact + -0.0 sig_waiting + -0.0 prev_action + 0.001 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + -0.001 sig_action + -0.0 sig_grooming + 0.215 sig_non_contact + -0.0 sig_contact + 0.001 sig_waiting + -0.0 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 141, -, 141, -, 141, 141, 141, 141, 141, 141, 141, -, -, -, 141\n",
            "value_grooming: -, -, 141, -, -, 141, 141, -, 141, 141, 141, -, 141, 141, -\n",
            "value_non_contact: 0, 141, -, 141, 0, -, 141, -, -, 141, -, -, -, -, 141\n",
            "value_contact: 141, 141, -, 141, 141, -, 141, 141, -, 141, -, -, 141, 141, 141\n",
            "value_scratch: 0, -, 141, -, 0, -, 141, -, 141, 141, -, -, -, 141, -\n",
            "value_waiting: -, -, -, 141, 141, 0, 141, -, 141, -, -, -, -, 141, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 392/1000 --- L(Train): 0.0161702 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 47):\n",
            "value_action[t+1] = -0.002 1 + 1.0 value_action[t] + 0.002 chosen + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.001 prev_waiting \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.014 chosen + 0.002 sig_non_contact + 0.001 sig_contact + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.002 prev_contact + -0.001 prev_scratch \n",
            "value_non_contact[t+1] = -0.371 1 + 1.002 value_non_contact[t] + 0.002 sig_action + -0.479 sig_grooming + -0.001 sig_contact + 0.002 prev_action + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.035 1 + 0.999 value_contact[t] + 0.001 sig_action + -0.001 sig_grooming + 0.002 sig_contact + 0.002 sig_scratch + 0.002 prev_contact + 0.002 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + -0.001 chosen + -0.122 sig_grooming + 0.001 sig_contact + 0.002 sig_waiting + 0.002 prev_action + 0.001 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + -0.001 sig_action + 0.001 sig_grooming + 0.215 sig_non_contact + 0.002 sig_contact + 0.001 sig_waiting + 0.002 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 142, -, 142, -, 142, 142, 142, 142, 142, 142, 142, -, -, -, 142\n",
            "value_grooming: -, -, 142, -, -, 142, 142, -, 142, 142, 142, -, 142, 142, -\n",
            "value_non_contact: 0, 142, -, 142, 0, -, 142, -, -, 142, -, -, -, -, 142\n",
            "value_contact: 142, 142, -, 142, 142, -, 142, 142, -, -, -, -, 142, 142, 142\n",
            "value_scratch: 0, -, 142, -, 0, -, 142, -, 142, 142, -, -, -, 142, -\n",
            "value_waiting: -, -, -, 142, 142, 0, 142, -, 142, -, -, -, -, 142, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 393/1000 --- L(Train): 0.0162032 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 46):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + 0.002 chosen + 0.008 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.014 chosen + 0.002 sig_non_contact + -0.0 sig_contact + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.002 prev_contact + 0.0 prev_scratch \n",
            "value_non_contact[t+1] = -0.371 1 + 1.002 value_non_contact[t] + 0.003 sig_action + -0.479 sig_grooming + 0.0 sig_contact + 0.002 prev_action + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 1.0 value_contact[t] + -0.0 sig_action + -0.0 sig_grooming + 0.002 sig_contact + 0.002 sig_scratch + 0.003 prev_contact + 0.003 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + 0.0 chosen + -0.122 sig_grooming + 0.0 sig_contact + 0.002 sig_waiting + 0.002 prev_action + -0.0 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.0 sig_action + 0.001 sig_grooming + 0.215 sig_non_contact + 0.002 sig_contact + -0.0 sig_waiting + 0.002 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 143, -, 143, -, 143, 143, 143, 143, 143, 143, 143, -, -, -, -\n",
            "value_grooming: -, -, 143, -, -, 143, 143, -, 143, 143, 143, -, 143, 143, -\n",
            "value_non_contact: 0, 143, -, 143, 0, -, 143, -, -, 143, -, -, -, -, 143\n",
            "value_contact: 143, 143, -, 143, 143, -, 143, 143, -, -, -, -, 143, 143, 143\n",
            "value_scratch: 0, -, 143, -, 0, -, 143, -, 143, 143, -, -, -, 143, -\n",
            "value_waiting: -, -, -, 143, 143, 0, 143, -, 143, -, -, -, -, 143, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 394/1000 --- L(Train): 0.0162056 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 45):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + 0.002 chosen + 0.009 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.013 chosen + -0.0 sig_contact + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.002 prev_contact + 0.0 prev_scratch \n",
            "value_non_contact[t+1] = -0.371 1 + 1.0 value_non_contact[t] + 0.002 sig_action + -0.479 sig_grooming + -0.0 sig_contact + 0.002 prev_action + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.001 value_contact[t] + -0.0 sig_action + 0.002 sig_grooming + 0.002 sig_contact + 0.002 sig_scratch + 0.002 prev_contact + 0.002 prev_scratch + 0.0 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + -0.0 chosen + -0.122 sig_grooming + -0.002 sig_contact + 0.002 sig_waiting + 0.002 prev_action + -0.0 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.0 sig_action + -0.001 sig_grooming + 0.216 sig_non_contact + 0.002 sig_contact + -0.0 sig_waiting + 0.002 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 144, -, 144, -, 144, 144, 144, 144, 144, 144, 144, -, -, -, -\n",
            "value_grooming: -, -, 144, -, -, -, 144, -, 144, 144, 144, -, 144, 144, -\n",
            "value_non_contact: 0, 144, -, 144, 0, -, 144, -, -, 144, -, -, -, -, 144\n",
            "value_contact: 144, 144, -, 144, 144, -, 144, 144, -, -, -, -, 144, 144, 144\n",
            "value_scratch: 0, -, 144, -, 0, -, 144, -, 144, 144, -, -, -, 144, -\n",
            "value_waiting: -, -, -, 144, 144, 0, 144, -, 144, -, -, -, -, 144, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 395/1000 --- L(Train): 0.0161945 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 44):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + 0.001 chosen + 0.01 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.013 chosen + 0.001 sig_contact + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_contact + -0.001 prev_scratch \n",
            "value_non_contact[t+1] = -0.371 1 + 0.997 value_non_contact[t] + 0.001 sig_action + -0.479 sig_grooming + 0.001 sig_contact + 0.001 prev_action + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.002 value_contact[t] + 0.001 sig_action + 0.002 sig_grooming + 0.001 sig_contact + 0.0 sig_scratch + 0.001 prev_contact + 0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + 0.001 chosen + -0.122 sig_grooming + -0.002 sig_contact + 0.001 sig_waiting + 0.001 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + -0.001 sig_action + -0.002 sig_grooming + 0.216 sig_non_contact + 0.001 sig_contact + 0.001 sig_waiting + 0.001 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 145, -, 145, -, 145, 145, 145, 145, 145, 145, 145, -, -, -, -\n",
            "value_grooming: -, -, 145, -, -, -, 145, -, 145, 145, 145, -, 145, 145, -\n",
            "value_non_contact: 0, 145, -, 145, 0, -, 145, -, -, 145, -, -, -, -, 145\n",
            "value_contact: 145, 145, -, 145, 145, -, 145, 145, -, -, -, -, 145, 145, 145\n",
            "value_scratch: 0, -, 145, -, 0, -, 145, -, 145, -, -, -, -, 145, -\n",
            "value_waiting: -, -, -, 145, 145, 0, 145, -, 145, -, -, -, -, 145, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 396/1000 --- L(Train): 0.0161699 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 43):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + -0.002 chosen + 0.009 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.012 chosen + 0.001 sig_contact + -0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.002 prev_contact + -0.0 prev_scratch \n",
            "value_non_contact[t+1] = -0.37 1 + 0.995 value_non_contact[t] + -0.001 sig_action + -0.479 sig_grooming + 0.001 sig_contact + -0.002 prev_action + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 1.002 value_contact[t] + 0.0 sig_action + -0.002 sig_contact + -0.002 sig_scratch + -0.001 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + 0.001 chosen + -0.122 sig_grooming + -0.002 sig_contact + -0.002 sig_waiting + 0.0 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + -0.0 sig_action + -0.003 sig_grooming + 0.216 sig_non_contact + -0.002 sig_contact + 0.0 sig_waiting + -0.002 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 146, -, 146, -, 146, 146, 146, 146, 146, 146, 146, -, -, -, -\n",
            "value_grooming: -, -, 146, -, -, -, 146, -, 146, 146, 146, -, 146, 146, -\n",
            "value_non_contact: 0, 146, -, 146, 0, -, 146, -, -, 146, -, -, -, -, 146\n",
            "value_contact: 146, 146, -, 146, -, -, 146, 146, -, -, -, -, 146, 146, 146\n",
            "value_scratch: 0, -, 146, -, 0, -, 146, -, 146, -, -, -, -, 146, -\n",
            "value_waiting: -, -, -, 146, 146, 0, 146, -, 146, -, -, -, -, 146, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 397/1000 --- L(Train): 0.0161871 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 42):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + -0.003 chosen + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.012 chosen + 0.0 sig_contact + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.003 prev_contact + 0.001 prev_scratch \n",
            "value_non_contact[t+1] = -0.37 1 + 0.993 value_non_contact[t] + -0.001 sig_action + -0.479 sig_grooming + -0.001 sig_contact + -0.003 prev_action + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.041 1 + 1.0 value_contact[t] + -0.001 sig_action + -0.003 sig_contact + -0.003 sig_scratch + -0.001 prev_contact + -0.001 prev_scratch \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + -0.001 chosen + -0.122 sig_grooming + -0.001 sig_contact + -0.002 sig_waiting + -0.001 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.001 sig_action + -0.002 sig_grooming + 0.216 sig_non_contact + -0.003 sig_contact + -0.001 sig_waiting + -0.003 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 147, -, 147, -, 147, 147, 147, 147, 147, 147, 147, -, -, -, -\n",
            "value_grooming: -, -, 147, -, -, -, 147, -, 147, 147, 147, -, 147, 147, -\n",
            "value_non_contact: 0, 147, -, 147, 0, -, 147, -, -, 147, -, -, -, -, 147\n",
            "value_contact: 147, 147, -, 147, -, -, 147, 147, -, -, -, -, 147, 147, -\n",
            "value_scratch: 0, -, 147, -, 0, -, 147, -, 147, -, -, -, -, 147, -\n",
            "value_waiting: -, -, -, 147, 147, 0, 147, -, 147, -, -, -, -, 147, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 398/1000 --- L(Train): 0.0161995 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 41):\n",
            "value_action[t+1] = -0.002 1 + 1.0 value_action[t] + -0.002 chosen + 0.008 sig_grooming + -0.019 sig_non_contact + 0.003 sig_contact + 0.003 sig_scratch + 0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.011 chosen + -0.002 sig_contact + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.003 prev_contact + 0.001 prev_scratch \n",
            "value_non_contact[t+1] = -0.37 1 + 0.993 value_non_contact[t] + -0.001 sig_action + -0.48 sig_grooming + -0.001 sig_contact + -0.003 prev_action + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.041 1 + 0.998 value_contact[t] + -0.001 sig_action + -0.003 sig_contact + -0.003 sig_scratch + -0.001 prev_contact + -0.001 prev_scratch \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + -0.122 sig_grooming + 0.002 sig_contact + -0.002 sig_waiting + -0.001 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.001 sig_action + -0.002 sig_grooming + 0.216 sig_non_contact + -0.003 sig_contact + -0.001 sig_waiting + -0.003 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 148, -, 148, -, 148, 148, 148, 148, 148, 148, 148, -, -, -, -\n",
            "value_grooming: -, -, 148, -, -, -, 148, -, 148, 148, 148, -, 148, 148, -\n",
            "value_non_contact: 0, 148, -, 148, 0, -, 148, -, -, 148, -, -, -, -, 148\n",
            "value_contact: 148, 148, -, 148, -, -, 148, 148, -, -, -, -, 148, 148, -\n",
            "value_scratch: 0, -, -, -, 0, -, 148, -, 148, -, -, -, -, 148, -\n",
            "value_waiting: -, -, -, 148, 148, 0, 148, -, 148, -, -, -, -, 148, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 399/1000 --- L(Train): 0.0161970 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 40):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + -0.001 chosen + 0.008 sig_grooming + -0.019 sig_non_contact + 0.002 sig_contact + 0.002 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.002 prev_grooming \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.011 chosen + -0.002 sig_contact + -0.001 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.001 prev_contact + -0.0 prev_scratch \n",
            "value_non_contact[t+1] = -0.37 1 + 0.993 value_non_contact[t] + 0.0 sig_action + -0.48 sig_grooming + 0.0 sig_contact + -0.001 prev_action + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 0.997 value_contact[t] + 0.0 sig_action + -0.002 sig_contact + -0.002 sig_scratch + 0.0 prev_contact + 0.0 prev_scratch \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + -0.122 sig_grooming + 0.003 sig_contact + -0.001 sig_waiting + 0.0 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + -0.0 sig_grooming + 0.216 sig_non_contact + -0.001 sig_contact + 0.0 sig_waiting + -0.002 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 149, -, 149, -, 149, 149, 149, 149, 149, 149, 149, -, -, -, -\n",
            "value_grooming: -, -, 149, -, -, -, 149, -, 149, 149, 149, -, 149, 149, -\n",
            "value_non_contact: 0, 149, -, 149, 0, -, 149, -, -, 149, -, -, -, -, 149\n",
            "value_contact: 149, 149, -, 149, -, -, 149, 149, -, -, -, -, 149, 149, -\n",
            "value_scratch: 0, -, -, -, 0, -, 149, -, 149, -, -, -, -, 149, -\n",
            "value_waiting: -, -, -, -, 149, 0, 149, -, 149, -, -, -, -, 149, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 400/1000 --- L(Train): 0.0161834 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 39):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + 0.001 chosen + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.01 chosen + -0.002 sig_contact + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.001 prev_contact + 0.0 prev_scratch \n",
            "value_non_contact[t+1] = -0.371 1 + 0.993 value_non_contact[t] + 0.0 sig_action + -0.48 sig_grooming + 0.0 sig_contact + 0.0 prev_action + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 0.997 value_contact[t] + 0.0 sig_contact + 0.0 sig_scratch + 0.0 prev_contact + 0.0 prev_scratch \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + -0.122 sig_grooming + 0.003 sig_contact + 0.001 sig_waiting + -0.0 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.001 sig_grooming + 0.217 sig_non_contact + 0.0 sig_contact + -0.0 sig_waiting + 0.0 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 150, -, 150, -, 150, 150, 150, 150, 150, 150, 150, -, -, -, -\n",
            "value_grooming: -, -, 150, -, -, -, 150, -, 150, 150, 150, -, 150, 150, -\n",
            "value_non_contact: 0, 150, -, 150, 0, -, 150, -, -, 150, -, -, -, -, 150\n",
            "value_contact: 150, 150, -, -, -, -, 150, 150, -, -, -, -, 150, 150, -\n",
            "value_scratch: 0, -, -, -, 0, -, 150, -, 150, -, -, -, -, 150, -\n",
            "value_waiting: -, -, -, -, 150, 0, 150, -, 150, -, -, -, -, 150, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 401/1000 --- L(Train): 0.0161588 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 38):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + 0.001 chosen + 0.01 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.009 chosen + -0.001 sig_contact + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_contact + -0.001 prev_scratch \n",
            "value_non_contact[t+1] = -0.371 1 + 0.994 value_non_contact[t] + -0.48 sig_grooming + -0.001 sig_contact + 0.001 prev_action + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 0.998 value_contact[t] + 0.001 sig_contact + 0.001 sig_scratch + -0.001 prev_contact + -0.001 prev_scratch \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + -0.122 sig_grooming + 0.001 sig_contact + 0.002 sig_waiting + 0.001 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.001 sig_grooming + 0.217 sig_non_contact + 0.001 sig_contact + 0.001 sig_waiting + 0.001 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 151, -, 151, -, 151, 151, 151, 151, 151, 151, 151, -, -, -, -\n",
            "value_grooming: -, -, 151, -, -, -, 151, -, 151, 151, 151, -, 151, 151, -\n",
            "value_non_contact: 0, 151, -, -, 0, -, 151, -, -, 151, -, -, -, -, 151\n",
            "value_contact: 151, 151, -, -, -, -, 151, 151, -, -, -, -, 151, 151, -\n",
            "value_scratch: 0, -, -, -, 0, -, 151, -, 151, -, -, -, -, 151, -\n",
            "value_waiting: -, -, -, -, 151, 0, 151, -, 151, -, -, -, -, 151, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 402/1000 --- L(Train): 0.0161774 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 37):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + 0.001 chosen + 0.009 sig_grooming + -0.019 sig_non_contact + -0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.009 chosen + 0.002 sig_contact + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + 0.001 prev_contact + -0.001 prev_scratch \n",
            "value_non_contact[t+1] = -0.371 1 + 0.996 value_non_contact[t] + -0.48 sig_grooming + -0.001 sig_contact + 0.001 prev_action + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + 0.001 sig_contact + 0.001 sig_scratch + -0.0 prev_contact + -0.0 prev_scratch \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + -0.122 sig_grooming + -0.001 sig_contact + 0.001 sig_waiting + 0.001 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + -0.001 sig_grooming + 0.217 sig_non_contact + 0.001 sig_contact + 0.001 sig_waiting + 0.001 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 152, -, 152, -, 152, 152, 152, 152, 152, 152, 152, -, -, -, -\n",
            "value_grooming: -, -, 152, -, -, -, 152, -, 152, 152, 152, -, 152, 152, -\n",
            "value_non_contact: 0, 152, -, -, 0, -, 152, -, -, 152, -, -, -, -, 152\n",
            "value_contact: 152, -, -, -, -, -, 152, 152, -, -, -, -, 152, 152, -\n",
            "value_scratch: 0, -, -, -, 0, -, 152, -, 152, -, -, -, -, 152, -\n",
            "value_waiting: -, -, -, -, 152, 0, 152, -, 152, -, -, -, -, 152, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 403/1000 --- L(Train): 0.0161637 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 36):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + -0.0 chosen + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.008 chosen + 0.003 sig_contact + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.0 prev_contact + 0.001 prev_scratch \n",
            "value_non_contact[t+1] = -0.371 1 + 0.998 value_non_contact[t] + -0.48 sig_grooming + -0.0 sig_contact + -0.0 prev_action + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + -0.0 sig_contact + -0.0 sig_scratch + 0.001 prev_contact + 0.001 prev_scratch \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + -0.122 sig_grooming + -0.001 sig_contact + -0.001 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + -0.002 sig_grooming + 0.217 sig_non_contact + -0.0 sig_contact + -0.001 sig_waiting + -0.0 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 153, -, 153, -, 153, 153, 153, 153, 153, 153, 153, -, -, -, -\n",
            "value_grooming: -, -, 153, -, -, -, 153, -, 153, 153, 153, -, 153, 153, -\n",
            "value_non_contact: 0, 153, -, -, 0, -, 153, -, -, 153, -, -, -, -, 153\n",
            "value_contact: 153, -, -, -, -, -, 153, 153, -, -, -, -, 153, 153, -\n",
            "value_scratch: 0, -, -, -, 0, -, 153, -, -, -, -, -, -, 153, -\n",
            "value_waiting: -, -, -, -, 153, 0, 153, -, 153, -, -, -, -, 153, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 404/1000 --- L(Train): 0.0161593 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 35):\n",
            "value_action[t+1] = -0.002 1 + 1.0 value_action[t] + 0.008 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.0 sig_scratch + 0.0 sig_waiting + -0.0 prev_action + -0.001 prev_grooming \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.007 chosen + 0.002 sig_contact + -0.0 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.0 prev_contact + 0.001 prev_scratch \n",
            "value_non_contact[t+1] = -0.371 1 + 1.001 value_non_contact[t] + -0.48 sig_grooming + 0.002 sig_contact + -0.0 prev_action + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.036 1 + 1.0 value_contact[t] + -0.001 sig_contact + -0.001 sig_scratch + 0.001 prev_contact + 0.001 prev_scratch \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + -0.122 sig_grooming + -0.001 sig_contact + -0.001 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + -0.003 sig_grooming + 0.217 sig_non_contact + -0.0 sig_contact + -0.001 sig_waiting + -0.0 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 154, -, -, -, 154, 154, 154, 154, 154, 154, 154, -, -, -, -\n",
            "value_grooming: -, -, 154, -, -, -, 154, -, 154, 154, 154, -, 154, 154, -\n",
            "value_non_contact: 0, 154, -, -, 0, -, 154, -, -, 154, -, -, -, -, 154\n",
            "value_contact: 154, -, -, -, -, -, 154, 154, -, -, -, -, 154, 154, -\n",
            "value_scratch: 0, -, -, -, 0, -, 154, -, -, -, -, -, -, 154, -\n",
            "value_waiting: -, -, -, -, 154, 0, 154, -, 154, -, -, -, -, 154, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 405/1000 --- L(Train): 0.0161551 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 34):\n",
            "value_action[t+1] = -0.001 1 + 1.0 value_action[t] + 0.008 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.007 chosen + 0.001 sig_contact + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.0 prev_contact + -0.0 prev_scratch \n",
            "value_non_contact[t+1] = -0.371 1 + 1.002 value_non_contact[t] + -0.48 sig_grooming + 0.002 sig_contact + 0.0 prev_action + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + 0.0 sig_contact + 0.0 sig_scratch + -0.0 prev_contact \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + -0.122 sig_grooming + 0.0 sig_contact + 0.0 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + -0.002 sig_grooming + 0.217 sig_non_contact + 0.0 sig_contact + 0.0 sig_waiting + 0.0 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 155, -, -, -, 155, 155, 155, 155, 155, 155, 155, -, -, -, -\n",
            "value_grooming: -, -, 155, -, -, -, 155, -, 155, 155, 155, -, 155, 155, -\n",
            "value_non_contact: 0, 155, -, -, 0, -, 155, -, -, 155, -, -, -, -, 155\n",
            "value_contact: 155, -, -, -, -, -, 155, 155, -, -, -, -, 155, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, 155, -, -, -, -, -, -, 155, -\n",
            "value_waiting: -, -, -, -, 155, 0, 155, -, 155, -, -, -, -, 155, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 406/1000 --- L(Train): 0.0161573 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 33):\n",
            "value_action[t+1] = 0.0 1 + 1.0 value_action[t] + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_contact + -0.0 sig_scratch + -0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.006 chosen + -0.001 sig_contact + 0.0 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.0 prev_contact \n",
            "value_non_contact[t+1] = -0.371 1 + 1.0 value_non_contact[t] + -0.48 sig_grooming + 0.002 sig_contact + 0.0 prev_action + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + 0.0 sig_contact + 0.0 sig_scratch + 0.0 prev_contact \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + -0.122 sig_grooming + 0.0 sig_contact + 0.0 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + -0.002 sig_grooming + 0.217 sig_non_contact + 0.0 sig_contact + 0.0 sig_waiting + 0.0 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 156, -, -, -, 156, 156, 156, 156, 156, 156, 156, -, -, -, -\n",
            "value_grooming: -, -, 156, -, -, -, 156, -, 156, 156, 156, -, 156, -, -\n",
            "value_non_contact: 0, 156, -, -, 0, -, 156, -, -, 156, -, -, -, -, 156\n",
            "value_contact: 156, -, -, -, -, -, 156, 156, -, -, -, -, 156, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, 156, -, -, -, -, -, -, 156, -\n",
            "value_waiting: -, -, -, -, 156, 0, 156, -, 156, -, -, -, -, 156, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 407/1000 --- L(Train): 0.0161488 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 32):\n",
            "value_action[t+1] = 0.001 1 + 1.0 value_action[t] + 0.01 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.005 chosen + -0.001 sig_contact + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_contact \n",
            "value_non_contact[t+1] = -0.371 1 + 0.997 value_non_contact[t] + -0.48 sig_grooming + 0.001 sig_contact + -0.001 prev_action + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] + -0.001 sig_contact + -0.001 sig_scratch + -0.001 prev_contact \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + -0.122 sig_grooming + -0.001 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + -0.0 sig_grooming + 0.217 sig_non_contact + -0.001 sig_contact + -0.001 sig_waiting + -0.001 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: 157, -, -, -, 157, 157, 157, 157, 157, 157, 157, -, -, -, -\n",
            "value_grooming: -, -, 157, -, -, -, 157, -, 157, 157, 157, -, 157, -, -\n",
            "value_non_contact: 0, 157, -, -, 0, -, 157, -, -, 157, -, -, -, -, 157\n",
            "value_contact: 157, -, -, -, -, -, 157, 157, -, -, -, -, 157, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, 157, -\n",
            "value_waiting: -, -, -, -, 157, 0, 157, -, 157, -, -, -, -, 157, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 408/1000 --- L(Train): 0.0161701 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 31):\n",
            "value_action[t+1] = 1.0 value_action[t] + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_contact + 0.001 sig_scratch + 0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.005 chosen + -0.001 sig_contact + -0.001 sig_waiting + -0.001 prev_action + -0.001 prev_grooming + -0.001 prev_contact \n",
            "value_non_contact[t+1] = -0.371 1 + 0.995 value_non_contact[t] + -0.48 sig_grooming + -0.002 sig_contact + -0.001 prev_action + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + -0.001 sig_contact + -0.001 sig_scratch + -0.001 prev_contact \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + -0.122 sig_grooming + -0.001 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.001 sig_grooming + 0.216 sig_non_contact + -0.001 sig_contact + -0.001 sig_waiting + -0.001 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, 158, 158, 158, 158, 158, 158, 158, -, -, -, -\n",
            "value_grooming: -, -, 158, -, -, -, 158, -, 158, 158, 158, -, 158, -, -\n",
            "value_non_contact: 0, 158, -, -, 0, -, 158, -, -, 158, -, -, -, -, 158\n",
            "value_contact: 158, -, -, -, -, -, 158, 158, -, -, -, -, 158, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, 158, -\n",
            "value_waiting: -, -, -, -, 158, 0, 158, -, 158, -, -, -, -, 158, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 409/1000 --- L(Train): 0.0161694 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 30):\n",
            "value_action[t+1] = 1.0 value_action[t] + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_contact + 0.0 sig_scratch + -0.0 prev_action + -0.0 prev_grooming \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.005 chosen + 0.0 sig_contact + -0.0 sig_waiting + -0.0 prev_action + -0.0 prev_grooming + -0.0 prev_contact \n",
            "value_non_contact[t+1] = -0.371 1 + 0.994 value_non_contact[t] + -0.48 sig_grooming + -0.003 sig_contact + -0.0 prev_action + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + -0.0 sig_contact + -0.0 sig_scratch + 0.001 prev_contact \n",
            "value_scratch[t+1] = -0.238 1 + 1.0 value_scratch[t] + -0.123 sig_grooming + -0.0 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.001 sig_grooming + 0.216 sig_non_contact + -0.0 sig_contact + -0.0 sig_waiting + -0.0 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, 159, 159, 159, 159, -, 159, 159, -, -, -, -\n",
            "value_grooming: -, -, 159, -, -, -, 159, -, 159, 159, 159, -, 159, -, -\n",
            "value_non_contact: 0, 159, -, -, 0, -, 159, -, -, 159, -, -, -, -, 159\n",
            "value_contact: 159, -, -, -, -, -, 159, 159, -, -, -, -, 159, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, 159, -\n",
            "value_waiting: -, -, -, -, 159, 0, 159, -, 159, -, -, -, -, 159, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 410/1000 --- L(Train): 0.0161622 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 29):\n",
            "value_action[t+1] = 1.0 value_action[t] + 0.007 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.002 prev_action + 0.002 prev_grooming \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.004 chosen + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.002 prev_contact \n",
            "value_non_contact[t+1] = -0.371 1 + 0.994 value_non_contact[t] + -0.48 sig_grooming + -0.002 sig_contact + 0.002 prev_action + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.04 1 + 1.0 value_contact[t] + 0.002 sig_contact + 0.002 sig_scratch + 0.001 prev_contact \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming + 0.002 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + -0.001 sig_grooming + 0.216 sig_non_contact + 0.002 sig_contact + 0.002 sig_waiting + 0.002 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, 160, 160, 160, 160, -, 160, 160, -, -, -, -\n",
            "value_grooming: -, -, 160, -, -, -, -, -, 160, 160, 160, -, 160, -, -\n",
            "value_non_contact: 0, 160, -, -, 0, -, 160, -, -, 160, -, -, -, -, 160\n",
            "value_contact: 160, -, -, -, -, -, 160, 160, -, -, -, -, 160, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, 160, -\n",
            "value_waiting: -, -, -, -, 160, 0, 160, -, 160, -, -, -, -, 160, -\n",
            "================================================================================\n",
            "================================================================================\n",
            "Epoch 411/1000 --- L(Train): 0.0161811 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 28):\n",
            "value_action[t+1] = 1.0 value_action[t] + 0.007 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.002 prev_action + 0.002 prev_grooming \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.004 chosen + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.002 prev_contact \n",
            "value_non_contact[t+1] = -0.371 1 + 0.994 value_non_contact[t] + -0.48 sig_grooming + -0.001 sig_contact + 0.002 prev_action + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + 0.002 sig_contact + 0.002 sig_scratch \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming + 0.002 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + -0.002 sig_grooming + 0.216 sig_non_contact + 0.002 sig_contact + 0.002 sig_waiting + 0.002 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, 161, 161, 161, 161, -, 161, 161, -, -, -, -\n",
            "value_grooming: -, -, 161, -, -, -, -, -, 161, 161, 161, -, 161, -, -\n",
            "value_non_contact: 0, 161, -, -, 0, -, 161, -, -, 161, -, -, -, -, 161\n",
            "value_contact: 161, -, -, -, -, -, 161, 161, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, 161, -\n",
            "value_waiting: -, -, -, -, 161, 0, 161, -, 161, -, -, -, -, 161, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
            "Epoch 412/1000 --- L(Train): 0.0161897 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 27):\n",
            "value_action[t+1] = 1.0 value_action[t] + 0.007 sig_grooming + -0.019 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + 0.002 prev_action + 0.002 prev_grooming \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.004 chosen + 0.002 sig_waiting + 0.002 prev_action + 0.002 prev_grooming + 0.002 prev_contact \n",
            "value_non_contact[t+1] = -0.371 1 + 0.995 value_non_contact[t] + -0.48 sig_grooming + 0.002 prev_action + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + 0.002 sig_contact + 0.002 sig_scratch \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming + 0.002 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + -0.003 sig_grooming + 0.216 sig_non_contact + 0.002 sig_contact + 0.002 sig_waiting + 0.002 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, 162, 162, 162, 162, -, 162, 162, -, -, -, -\n",
            "value_grooming: -, -, 162, -, -, -, -, -, 162, 162, 162, -, 162, -, -\n",
            "value_non_contact: 0, 162, -, -, 0, -, -, -, -, 162, -, -, -, -, 162\n",
            "value_contact: 162, -, -, -, -, -, 162, 162, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, 162, -\n",
            "value_waiting: -, -, -, -, 162, 0, 162, -, 162, -, -, -, -, 162, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 413/1000 --- L(Train): 0.0161925 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 26):\n",
            "value_action[t+1] = 1.0 value_action[t] + 0.008 sig_grooming + -0.019 sig_non_contact + -0.001 sig_scratch + 0.001 prev_action + 0.0 prev_grooming \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.004 chosen + 0.001 sig_waiting + 0.001 prev_action + 0.0 prev_grooming + 0.001 prev_contact \n",
            "value_non_contact[t+1] = -0.371 1 + 0.996 value_non_contact[t] + -0.48 sig_grooming + 0.001 prev_action + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] + 0.001 sig_contact + 0.0 sig_scratch \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming + 0.001 prev_scratch \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + -0.003 sig_grooming + 0.216 sig_non_contact + 0.001 sig_contact + 0.001 sig_waiting + 0.001 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, 163, 163, -, 163, -, 163, 163, -, -, -, -\n",
            "value_grooming: -, -, 163, -, -, -, -, -, 163, 163, 163, -, 163, -, -\n",
            "value_non_contact: 0, 163, -, -, 0, -, -, -, -, 163, -, -, -, -, 163\n",
            "value_contact: 163, -, -, -, -, -, 163, 163, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, 163, -\n",
            "value_waiting: -, -, -, -, 163, 0, 163, -, 163, -, -, -, -, 163, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 414/1000 --- L(Train): 0.0162016 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 25):\n",
            "value_action[t+1] = 1.0 value_action[t] + 0.009 sig_grooming + -0.019 sig_non_contact + 0.002 sig_scratch + -0.002 prev_action + -0.002 prev_grooming \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.004 chosen + -0.002 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.002 prev_contact \n",
            "value_non_contact[t+1] = -0.371 1 + 0.998 value_non_contact[t] + -0.48 sig_grooming + -0.002 prev_action + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] + -0.002 sig_contact + -0.002 sig_scratch \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + -0.002 sig_grooming + 0.216 sig_non_contact + -0.002 sig_contact + -0.002 sig_waiting + -0.002 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, 164, 164, -, 164, -, 164, 164, -, -, -, -\n",
            "value_grooming: -, -, 164, -, -, -, -, -, 164, 164, 164, -, 164, -, -\n",
            "value_non_contact: 0, 164, -, -, 0, -, -, -, -, 164, -, -, -, -, 164\n",
            "value_contact: 164, -, -, -, -, -, 164, 164, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, 164, 0, 164, -, 164, -, -, -, -, 164, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 415/1000 --- L(Train): 0.0162041 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 24):\n",
            "value_action[t+1] = 1.0 value_action[t] + 0.009 sig_grooming + -0.019 sig_non_contact + 0.003 sig_scratch + -0.003 prev_action + -0.003 prev_grooming \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.003 chosen + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.003 prev_contact \n",
            "value_non_contact[t+1] = -0.371 1 + 1.0 value_non_contact[t] + -0.48 sig_grooming + -0.003 prev_action + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + -0.003 sig_contact + -0.003 sig_scratch \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + -0.001 sig_grooming + 0.216 sig_non_contact + -0.003 sig_contact + -0.003 sig_waiting + -0.003 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, 165, 165, -, 165, -, 165, 165, -, -, -, -\n",
            "value_grooming: -, -, 165, -, -, -, -, -, 165, 165, 165, -, 165, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, 165, -, -, -, -, 165\n",
            "value_contact: 165, -, -, -, -, -, 165, 165, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, 165, 0, 165, -, 165, -, -, -, -, 165, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 416/1000 --- L(Train): 0.0162261 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 23):\n",
            "value_action[t+1] = 1.0 value_action[t] + 0.009 sig_grooming + -0.019 sig_non_contact + 0.003 sig_scratch + -0.003 prev_action + -0.003 prev_grooming \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.003 chosen + -0.003 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.003 prev_contact \n",
            "value_non_contact[t+1] = -0.371 1 + 1.0 value_non_contact[t] + -0.48 sig_grooming + -0.003 prev_action + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.037 1 + 1.0 value_contact[t] + -0.003 sig_contact + -0.003 sig_scratch \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact + -0.003 sig_contact + -0.002 sig_waiting + -0.003 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, 166, 166, -, 166, -, 166, 166, -, -, -, -\n",
            "value_grooming: -, -, 166, -, -, -, -, -, 166, 166, 166, -, 166, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, 166, -, -, -, -, 166\n",
            "value_contact: 166, -, -, -, -, -, 166, 166, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, 166, -, 166, -, -, -, -, 166, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 417/1000 --- L(Train): 0.0162374 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 23):\n",
            "value_action[t+1] = 1.0 value_action[t] + 0.009 sig_grooming + -0.019 sig_non_contact + 0.002 sig_scratch + -0.001 prev_action + -0.002 prev_grooming \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.004 chosen + -0.001 sig_waiting + -0.002 prev_action + -0.002 prev_grooming + -0.001 prev_contact \n",
            "value_non_contact[t+1] = -0.371 1 + 1.0 value_non_contact[t] + -0.48 sig_grooming + -0.001 prev_action + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] + -0.002 sig_contact + -0.002 sig_scratch \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact + -0.001 sig_contact + -0.002 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, 167, 167, -, 167, -, 167, 167, -, -, -, -\n",
            "value_grooming: -, -, 167, -, -, -, -, -, 167, 167, 167, -, 167, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, 167, -, -, -, -, 167\n",
            "value_contact: 167, -, -, -, -, -, 167, 167, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, 167, -, -, -, -, -, -, 167, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 418/1000 --- L(Train): 0.0162483 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 22):\n",
            "value_action[t+1] = 1.0 value_action[t] + 0.008 sig_grooming + -0.019 sig_non_contact + -0.0 sig_scratch + 0.001 prev_action + 0.0 prev_grooming \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.004 chosen + 0.001 sig_waiting + 0.0 prev_action + 0.0 prev_grooming + 0.001 prev_contact \n",
            "value_non_contact[t+1] = -0.371 1 + 1.0 value_non_contact[t] + -0.48 sig_grooming + 0.0 prev_action + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] + 0.0 sig_contact \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact + 0.0 sig_contact + 0.0 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, 168, 168, -, 168, -, 168, 168, -, -, -, -\n",
            "value_grooming: -, -, 168, -, -, -, -, -, 168, 168, 168, -, 168, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, 168, -, -, -, -, 168\n",
            "value_contact: 168, -, -, -, -, -, 168, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, 168, -, -, -, -, -, -, 168, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 419/1000 --- L(Train): 0.0162520 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 21):\n",
            "value_action[t+1] = 1.0 value_action[t] + 0.008 sig_grooming + -0.019 sig_non_contact + -0.001 sig_scratch + 0.001 prev_action + 0.001 prev_grooming \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.004 chosen + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_contact \n",
            "value_non_contact[t+1] = -0.371 1 + 1.0 value_non_contact[t] + -0.48 sig_grooming + 0.001 prev_action + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] + 0.001 sig_contact \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact + 0.001 sig_contact + 0.001 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, 169, 169, -, 169, -, 169, 169, -, -, -, -\n",
            "value_grooming: -, -, 169, -, -, -, -, -, 169, 169, -, -, 169, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, 169, -, -, -, -, 169\n",
            "value_contact: 169, -, -, -, -, -, 169, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, 169, -, -, -, -, -, -, 169, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 420/1000 --- L(Train): 0.0162741 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 21):\n",
            "value_action[t+1] = 1.0 value_action[t] + 0.007 sig_grooming + -0.019 sig_non_contact + -0.001 sig_scratch + 0.001 prev_action \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.004 chosen + 0.001 sig_waiting + 0.001 prev_action + 0.001 prev_contact \n",
            "value_non_contact[t+1] = -0.371 1 + 1.0 value_non_contact[t] + -0.48 sig_grooming + 0.001 prev_action + -0.001 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + 0.001 sig_contact \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact + 0.001 sig_contact + 0.001 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, 170, 170, -, 170, -, 170, -, -, -, -, -\n",
            "value_grooming: -, -, 170, -, -, -, -, -, 170, 170, -, -, 170, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, 170, -, -, -, -, 170\n",
            "value_contact: 170, -, -, -, -, -, 170, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, 170, -, -, -, -, -, -, 170, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 421/1000 --- L(Train): 0.0162805 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 20):\n",
            "value_action[t+1] = 1.0 value_action[t] + 0.007 sig_grooming + -0.019 sig_non_contact + 0.0 sig_scratch + -0.0 prev_action \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.004 chosen + -0.0 sig_waiting + -0.0 prev_action \n",
            "value_non_contact[t+1] = -0.371 1 + 1.0 value_non_contact[t] + -0.48 sig_grooming + -0.0 prev_action + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + -0.0 sig_contact \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact + -0.0 sig_contact + -0.0 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, 171, 171, -, 171, -, 171, -, -, -, -, -\n",
            "value_grooming: -, -, 171, -, -, -, -, -, 171, 171, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, 171, -, -, -, -, 171\n",
            "value_contact: 171, -, -, -, -, -, 171, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, 171, -, -, -, -, -, -, 171, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 422/1000 --- L(Train): 0.0162919 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 20):\n",
            "value_action[t+1] = 1.0 value_action[t] + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_scratch + -0.0 prev_action \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.004 chosen + -0.001 prev_action \n",
            "value_non_contact[t+1] = -0.371 1 + 1.0 value_non_contact[t] + -0.48 sig_grooming + -0.0 prev_action + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + -0.001 sig_contact \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact + -0.0 sig_contact + -0.0 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, 172, 172, -, 172, -, 172, -, -, -, -, -\n",
            "value_grooming: -, -, 172, -, -, -, -, -, -, 172, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, 172, -, -, -, -, 172\n",
            "value_contact: 172, -, -, -, -, -, 172, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, 172, -, -, -, -, -, -, 172, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 423/1000 --- L(Train): 0.0162838 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 19):\n",
            "value_action[t+1] = 1.0 value_action[t] + 0.008 sig_grooming + -0.019 sig_non_contact + -0.0 sig_scratch + 0.0 prev_action \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.004 chosen \n",
            "value_non_contact[t+1] = -0.371 1 + 1.0 value_non_contact[t] + -0.48 sig_grooming + 0.0 prev_action + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] + 0.0 sig_contact \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact + 0.0 sig_contact + 0.0 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, 173, 173, -, 173, -, 173, -, -, -, -, -\n",
            "value_grooming: -, -, 173, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, 173, -, -, -, -, 173\n",
            "value_contact: 173, -, -, -, -, -, 173, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, 173, -, -, -, -, -, -, 173, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 424/1000 --- L(Train): 0.0162878 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 19):\n",
            "value_action[t+1] = 1.0 value_action[t] + 0.009 sig_grooming + -0.019 sig_non_contact + -0.0 sig_scratch + 0.0 prev_action \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.005 chosen \n",
            "value_non_contact[t+1] = -0.371 1 + 1.0 value_non_contact[t] + -0.48 sig_grooming + 0.0 prev_action + -0.0 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact + 0.0 sig_contact + 0.0 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, 174, 174, -, 174, -, 174, -, -, -, -, -\n",
            "value_grooming: -, -, 174, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, 174, -, -, -, -, 174\n",
            "value_contact: 174, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, 174, -, -, -, -, -, -, 174, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 425/1000 --- L(Train): 0.0162818 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 19):\n",
            "value_action[t+1] = 1.0 value_action[t] + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_scratch \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.005 chosen \n",
            "value_non_contact[t+1] = -0.371 1 + 1.0 value_non_contact[t] + -0.48 sig_grooming + -0.001 prev_action + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact + -0.001 sig_contact + -0.001 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, 175, 175, -, 175, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, 175, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, 175, -, -, -, -, 175\n",
            "value_contact: 175, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, 175, -, -, -, -, -, -, 175, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 426/1000 --- L(Train): 0.0162888 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 19):\n",
            "value_action[t+1] = 1.0 value_action[t] + 0.009 sig_grooming + -0.019 sig_non_contact + 0.001 sig_scratch \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.005 chosen \n",
            "value_non_contact[t+1] = -0.37 1 + 1.0 value_non_contact[t] + -0.48 sig_grooming + 0.001 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact + -0.001 sig_contact + -0.001 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, 176, 176, -, 176, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, 176, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, 176\n",
            "value_contact: 176, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, 176, -, -, -, -, -, -, 176, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 427/1000 --- L(Train): 0.0162802 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] + 0.008 sig_grooming + -0.019 sig_non_contact + 0.0 sig_scratch \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.005 chosen \n",
            "value_non_contact[t+1] = -0.37 1 + 1.0 value_non_contact[t] + -0.48 sig_grooming + 0.0 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact + -0.0 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, 177, 177, -, 177, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, 177, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, 177\n",
            "value_contact: 177, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, 177, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 428/1000 --- L(Train): 0.0162795 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] + 0.008 sig_grooming + -0.019 sig_non_contact \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.005 chosen \n",
            "value_non_contact[t+1] = -0.37 1 + 1.0 value_non_contact[t] + -0.48 sig_grooming + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact + 0.002 prev_scratch \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, 178, 178, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, 178, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, 178\n",
            "value_contact: 178, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, 178, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 429/1000 --- L(Train): 0.0162778 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] + 0.008 sig_grooming + -0.019 sig_non_contact \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.006 chosen \n",
            "value_non_contact[t+1] = -0.37 1 + 1.0 value_non_contact[t] + -0.48 sig_grooming + -0.002 prev_waiting \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, 179, 179, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, 179, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, 179\n",
            "value_contact: 179, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 430/1000 --- L(Train): 0.0162765 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] + 0.008 sig_grooming + -0.019 sig_non_contact \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] + 0.006 chosen \n",
            "value_non_contact[t+1] = -0.37 1 + 1.0 value_non_contact[t] + -0.48 sig_grooming \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, 180, 180, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, 180, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: 180, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 431/1000 --- L(Train): 0.0162656 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] + 0.008 sig_grooming + -0.019 sig_non_contact \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.37 1 + 1.0 value_non_contact[t] + -0.48 sig_grooming \n",
            "value_contact[t+1] = -0.038 1 + 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, 181, 181, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: 181, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 432/1000 --- L(Train): 0.0162707 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] + -0.019 sig_non_contact \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.37 1 + 1.0 value_non_contact[t] + -0.48 sig_grooming \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, 182, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: 182, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 433/1000 --- L(Train): 0.0162646 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.37 1 + 1.0 value_non_contact[t] + -0.48 sig_grooming \n",
            "value_contact[t+1] = -0.039 1 + 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: 183, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 434/1000 --- L(Train): 0.0162662 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.37 1 + 1.0 value_non_contact[t] + -0.48 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 435/1000 --- L(Train): 0.0162544 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.37 1 + 1.0 value_non_contact[t] + -0.48 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 436/1000 --- L(Train): 0.0162598 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.37 1 + 1.0 value_non_contact[t] + -0.48 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 437/1000 --- L(Train): 0.0162610 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.48 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 438/1000 --- L(Train): 0.0162739 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.48 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 439/1000 --- L(Train): 0.0162594 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.48 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 440/1000 --- L(Train): 0.0162581 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.481 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 441/1000 --- L(Train): 0.0162517 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.481 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 442/1000 --- L(Train): 0.0162498 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.481 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 443/1000 --- L(Train): 0.0162471 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.481 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 444/1000 --- L(Train): 0.0162545 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.481 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 445/1000 --- L(Train): 0.0162415 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.481 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 446/1000 --- L(Train): 0.0162483 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.481 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 447/1000 --- L(Train): 0.0162479 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.481 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 448/1000 --- L(Train): 0.0162423 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.481 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 449/1000 --- L(Train): 0.0162295 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.481 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 450/1000 --- L(Train): 0.0162381 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.481 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 451/1000 --- L(Train): 0.0162328 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.481 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 452/1000 --- L(Train): 0.0162342 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.481 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 453/1000 --- L(Train): 0.0162271 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.481 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 454/1000 --- L(Train): 0.0162285 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.481 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 455/1000 --- L(Train): 0.0162205 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.481 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 456/1000 --- L(Train): 0.0162396 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.482 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 457/1000 --- L(Train): 0.0162317 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.482 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 458/1000 --- L(Train): 0.0162336 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.482 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 459/1000 --- L(Train): 0.0162258 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.482 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 460/1000 --- L(Train): 0.0162239 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.482 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 461/1000 --- L(Train): 0.0162198 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.482 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 462/1000 --- L(Train): 0.0162251 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.482 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 463/1000 --- L(Train): 0.0162105 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.482 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 464/1000 --- L(Train): 0.0162183 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.482 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 465/1000 --- L(Train): 0.0162231 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.482 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 466/1000 --- L(Train): 0.0162229 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.482 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 467/1000 --- L(Train): 0.0162072 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.482 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 468/1000 --- L(Train): 0.0162117 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.482 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 469/1000 --- L(Train): 0.0162090 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.482 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 470/1000 --- L(Train): 0.0162056 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.482 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 471/1000 --- L(Train): 0.0162030 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.482 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 472/1000 --- L(Train): 0.0162087 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.482 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 473/1000 --- L(Train): 0.0161999 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.369 1 + 1.0 value_non_contact[t] + -0.482 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 474/1000 --- L(Train): 0.0162184 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.482 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 475/1000 --- L(Train): 0.0162100 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.482 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 476/1000 --- L(Train): 0.0162052 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.482 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 477/1000 --- L(Train): 0.0161996 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.482 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 478/1000 --- L(Train): 0.0162006 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.482 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 479/1000 --- L(Train): 0.0161916 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.482 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 480/1000 --- L(Train): 0.0162022 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.482 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 481/1000 --- L(Train): 0.0161978 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.482 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 482/1000 --- L(Train): 0.0161946 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.482 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 483/1000 --- L(Train): 0.0161941 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 484/1000 --- L(Train): 0.0161943 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 485/1000 --- L(Train): 0.0161834 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 486/1000 --- L(Train): 0.0161912 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 487/1000 --- L(Train): 0.0161844 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 488/1000 --- L(Train): 0.0161914 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 489/1000 --- L(Train): 0.0161924 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 490/1000 --- L(Train): 0.0161988 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 491/1000 --- L(Train): 0.0161840 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 492/1000 --- L(Train): 0.0162000 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 493/1000 --- L(Train): 0.0162027 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 494/1000 --- L(Train): 0.0162039 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 495/1000 --- L(Train): 0.0161829 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 496/1000 --- L(Train): 0.0161924 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 497/1000 --- L(Train): 0.0161967 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 498/1000 --- L(Train): 0.0161965 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 499/1000 --- L(Train): 0.0161827 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 500/1000 --- L(Train): 0.0161854 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 501/1000 --- L(Train): 0.0161900 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 502/1000 --- L(Train): 0.0161828 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 18):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 503/1000 --- L(Train): 0.0161670 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 504/1000 --- L(Train): 0.0161730 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 505/1000 --- L(Train): 0.0161720 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 506/1000 --- L(Train): 0.0161781 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 507/1000 --- L(Train): 0.0161671 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 508/1000 --- L(Train): 0.0161750 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 509/1000 --- L(Train): 0.0161730 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 510/1000 --- L(Train): 0.0161854 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 511/1000 --- L(Train): 0.0161824 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 512/1000 --- L(Train): 0.0161872 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 513/1000 --- L(Train): 0.0161699 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 514/1000 --- L(Train): 0.0161771 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 515/1000 --- L(Train): 0.0161801 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 516/1000 --- L(Train): 0.0161815 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 517/1000 --- L(Train): 0.0161683 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 518/1000 --- L(Train): 0.0161763 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 519/1000 --- L(Train): 0.0161776 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 520/1000 --- L(Train): 0.0161695 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 521/1000 --- L(Train): 0.0161565 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 522/1000 --- L(Train): 0.0161652 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 523/1000 --- L(Train): 0.0161645 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 524/1000 --- L(Train): 0.0161736 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 525/1000 --- L(Train): 0.0161625 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 526/1000 --- L(Train): 0.0161670 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 527/1000 --- L(Train): 0.0161667 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 528/1000 --- L(Train): 0.0161873 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 529/1000 --- L(Train): 0.0161813 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 530/1000 --- L(Train): 0.0161866 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 531/1000 --- L(Train): 0.0161709 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 532/1000 --- L(Train): 0.0161661 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 533/1000 --- L(Train): 0.0161712 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 534/1000 --- L(Train): 0.0161784 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 535/1000 --- L(Train): 0.0161571 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 536/1000 --- L(Train): 0.0161666 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 537/1000 --- L(Train): 0.0161763 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 538/1000 --- L(Train): 0.0161635 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 539/1000 --- L(Train): 0.0161477 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 540/1000 --- L(Train): 0.0161566 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 541/1000 --- L(Train): 0.0161553 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 542/1000 --- L(Train): 0.0161583 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 543/1000 --- L(Train): 0.0161462 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 544/1000 --- L(Train): 0.0161540 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 545/1000 --- L(Train): 0.0161579 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 546/1000 --- L(Train): 0.0161756 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 547/1000 --- L(Train): 0.0161602 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 548/1000 --- L(Train): 0.0161616 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 549/1000 --- L(Train): 0.0161617 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 550/1000 --- L(Train): 0.0161538 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 551/1000 --- L(Train): 0.0161471 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 552/1000 --- L(Train): 0.0161591 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 553/1000 --- L(Train): 0.0161508 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 554/1000 --- L(Train): 0.0161538 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 555/1000 --- L(Train): 0.0161567 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 556/1000 --- L(Train): 0.0161540 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 557/1000 --- L(Train): 0.0161448 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 558/1000 --- L(Train): 0.0161592 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 559/1000 --- L(Train): 0.0161509 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 560/1000 --- L(Train): 0.0161558 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 561/1000 --- L(Train): 0.0161506 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 562/1000 --- L(Train): 0.0161572 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 563/1000 --- L(Train): 0.0161523 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 564/1000 --- L(Train): 0.0161660 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 565/1000 --- L(Train): 0.0161558 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 566/1000 --- L(Train): 0.0161513 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 567/1000 --- L(Train): 0.0161465 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 568/1000 --- L(Train): 0.0161491 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 569/1000 --- L(Train): 0.0161458 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 570/1000 --- L(Train): 0.0161518 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 571/1000 --- L(Train): 0.0161389 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 572/1000 --- L(Train): 0.0161396 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 573/1000 --- L(Train): 0.0161502 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 574/1000 --- L(Train): 0.0161495 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 575/1000 --- L(Train): 0.0161273 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 576/1000 --- L(Train): 0.0161437 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 577/1000 --- L(Train): 0.0161486 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 578/1000 --- L(Train): 0.0161505 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 579/1000 --- L(Train): 0.0161393 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 580/1000 --- L(Train): 0.0161486 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 581/1000 --- L(Train): 0.0161434 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 582/1000 --- L(Train): 0.0161570 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 583/1000 --- L(Train): 0.0161515 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 584/1000 --- L(Train): 0.0161537 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 585/1000 --- L(Train): 0.0161446 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 586/1000 --- L(Train): 0.0161493 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 587/1000 --- L(Train): 0.0161449 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 588/1000 --- L(Train): 0.0161468 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 589/1000 --- L(Train): 0.0161389 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 590/1000 --- L(Train): 0.0161427 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 591/1000 --- L(Train): 0.0161449 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 592/1000 --- L(Train): 0.0161437 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 593/1000 --- L(Train): 0.0161261 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 594/1000 --- L(Train): 0.0161315 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 595/1000 --- L(Train): 0.0161321 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 596/1000 --- L(Train): 0.0161380 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 597/1000 --- L(Train): 0.0161296 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 598/1000 --- L(Train): 0.0161391 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 599/1000 --- L(Train): 0.0161346 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 600/1000 --- L(Train): 0.0161447 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 601/1000 --- L(Train): 0.0161415 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 602/1000 --- L(Train): 0.0161455 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 603/1000 --- L(Train): 0.0161361 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 604/1000 --- L(Train): 0.0161399 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 605/1000 --- L(Train): 0.0161367 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 606/1000 --- L(Train): 0.0161382 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 607/1000 --- L(Train): 0.0161267 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 608/1000 --- L(Train): 0.0161335 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 609/1000 --- L(Train): 0.0161379 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 610/1000 --- L(Train): 0.0161332 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 611/1000 --- L(Train): 0.0161176 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 612/1000 --- L(Train): 0.0161218 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 613/1000 --- L(Train): 0.0161299 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 614/1000 --- L(Train): 0.0161316 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 615/1000 --- L(Train): 0.0161135 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 616/1000 --- L(Train): 0.0161253 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 617/1000 --- L(Train): 0.0161321 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 618/1000 --- L(Train): 0.0161492 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 619/1000 --- L(Train): 0.0161371 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 620/1000 --- L(Train): 0.0161425 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 621/1000 --- L(Train): 0.0161359 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 622/1000 --- L(Train): 0.0161340 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 623/1000 --- L(Train): 0.0161284 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 624/1000 --- L(Train): 0.0161415 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 625/1000 --- L(Train): 0.0161329 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 626/1000 --- L(Train): 0.0161388 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 627/1000 --- L(Train): 0.0161358 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 628/1000 --- L(Train): 0.0161278 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 629/1000 --- L(Train): 0.0161184 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 630/1000 --- L(Train): 0.0161232 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 631/1000 --- L(Train): 0.0161197 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 632/1000 --- L(Train): 0.0161217 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 633/1000 --- L(Train): 0.0161175 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 634/1000 --- L(Train): 0.0161211 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 635/1000 --- L(Train): 0.0161156 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 636/1000 --- L(Train): 0.0161340 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 637/1000 --- L(Train): 0.0161279 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 638/1000 --- L(Train): 0.0161314 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 639/1000 --- L(Train): 0.0161214 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 640/1000 --- L(Train): 0.0161273 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 641/1000 --- L(Train): 0.0161287 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 642/1000 --- L(Train): 0.0161389 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 643/1000 --- L(Train): 0.0161252 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 644/1000 --- L(Train): 0.0161267 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 645/1000 --- L(Train): 0.0161294 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 646/1000 --- L(Train): 0.0161243 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "================================================================================\n",
            "Epoch 647/1000 --- L(Train): 0.0161134 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
            "Epoch 648/1000 --- L(Train): 0.0161219 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 649/1000 --- L(Train): 0.0161160 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 650/1000 --- L(Train): 0.0161169 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 651/1000 --- L(Train): 0.0161168 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 652/1000 --- L(Train): 0.0161210 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 653/1000 --- L(Train): 0.0161146 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 654/1000 --- L(Train): 0.0161356 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 655/1000 --- L(Train): 0.0161250 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 656/1000 --- L(Train): 0.0161325 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 657/1000 --- L(Train): 0.0161277 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 658/1000 --- L(Train): 0.0161323 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 659/1000 --- L(Train): 0.0161258 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 660/1000 --- L(Train): 0.0161321 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 661/1000 --- L(Train): 0.0161240 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 662/1000 --- L(Train): 0.0161211 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 663/1000 --- L(Train): 0.0161192 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 664/1000 --- L(Train): 0.0161207 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 665/1000 --- L(Train): 0.0161124 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 666/1000 --- L(Train): 0.0161208 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 667/1000 --- L(Train): 0.0161105 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 668/1000 --- L(Train): 0.0161134 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 669/1000 --- L(Train): 0.0161177 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 670/1000 --- L(Train): 0.0161177 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 671/1000 --- L(Train): 0.0161053 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 672/1000 --- L(Train): 0.0161247 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 673/1000 --- L(Train): 0.0161222 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 674/1000 --- L(Train): 0.0161233 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 675/1000 --- L(Train): 0.0161101 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 676/1000 --- L(Train): 0.0161108 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 677/1000 --- L(Train): 0.0161160 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 678/1000 --- L(Train): 0.0161202 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 679/1000 --- L(Train): 0.0161094 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 680/1000 --- L(Train): 0.0161160 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 681/1000 --- L(Train): 0.0161196 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 682/1000 --- L(Train): 0.0161153 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 683/1000 --- L(Train): 0.0161017 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 684/1000 --- L(Train): 0.0161120 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 685/1000 --- L(Train): 0.0161107 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 686/1000 --- L(Train): 0.0161205 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 687/1000 --- L(Train): 0.0161115 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 688/1000 --- L(Train): 0.0161181 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 689/1000 --- L(Train): 0.0161170 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 690/1000 --- L(Train): 0.0161295 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 691/1000 --- L(Train): 0.0161228 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 692/1000 --- L(Train): 0.0161247 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 693/1000 --- L(Train): 0.0161143 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 694/1000 --- L(Train): 0.0161159 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 695/1000 --- L(Train): 0.0161144 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 696/1000 --- L(Train): 0.0161215 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 697/1000 --- L(Train): 0.0161118 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 698/1000 --- L(Train): 0.0161166 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 699/1000 --- L(Train): 0.0161163 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 700/1000 --- L(Train): 0.0161113 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 701/1000 --- L(Train): 0.0161007 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 702/1000 --- L(Train): 0.0161094 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 703/1000 --- L(Train): 0.0161040 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 704/1000 --- L(Train): 0.0161127 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 705/1000 --- L(Train): 0.0161064 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 706/1000 --- L(Train): 0.0161132 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 707/1000 --- L(Train): 0.0161104 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 708/1000 --- L(Train): 0.0161257 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 709/1000 --- L(Train): 0.0161213 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 710/1000 --- L(Train): 0.0161209 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 711/1000 --- L(Train): 0.0161090 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 712/1000 --- L(Train): 0.0161098 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 713/1000 --- L(Train): 0.0161106 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 714/1000 --- L(Train): 0.0161183 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 715/1000 --- L(Train): 0.0161036 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 716/1000 --- L(Train): 0.0161108 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 717/1000 --- L(Train): 0.0161182 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 718/1000 --- L(Train): 0.0161122 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 719/1000 --- L(Train): 0.0160934 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 720/1000 --- L(Train): 0.0161057 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 721/1000 --- L(Train): 0.0161071 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 722/1000 --- L(Train): 0.0161107 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 723/1000 --- L(Train): 0.0161051 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 724/1000 --- L(Train): 0.0161104 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 725/1000 --- L(Train): 0.0161047 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 726/1000 --- L(Train): 0.0161201 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 727/1000 --- L(Train): 0.0161131 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 728/1000 --- L(Train): 0.0161168 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 729/1000 --- L(Train): 0.0161085 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 730/1000 --- L(Train): 0.0161115 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 731/1000 --- L(Train): 0.0161106 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 732/1000 --- L(Train): 0.0161148 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 733/1000 --- L(Train): 0.0161025 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 734/1000 --- L(Train): 0.0161083 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 735/1000 --- L(Train): 0.0161110 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 736/1000 --- L(Train): 0.0161101 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 737/1000 --- L(Train): 0.0160959 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 738/1000 --- L(Train): 0.0161058 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 739/1000 --- L(Train): 0.0161042 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 740/1000 --- L(Train): 0.0161037 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 741/1000 --- L(Train): 0.0160995 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 742/1000 --- L(Train): 0.0161013 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 743/1000 --- L(Train): 0.0160942 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 744/1000 --- L(Train): 0.0161158 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 745/1000 --- L(Train): 0.0161153 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 746/1000 --- L(Train): 0.0161171 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 747/1000 --- L(Train): 0.0161010 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 748/1000 --- L(Train): 0.0161045 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 749/1000 --- L(Train): 0.0161096 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 750/1000 --- L(Train): 0.0161131 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 751/1000 --- L(Train): 0.0160968 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 752/1000 --- L(Train): 0.0161064 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 753/1000 --- L(Train): 0.0161168 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 754/1000 --- L(Train): 0.0161143 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 755/1000 --- L(Train): 0.0160916 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 756/1000 --- L(Train): 0.0160984 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 757/1000 --- L(Train): 0.0161050 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 758/1000 --- L(Train): 0.0161054 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 759/1000 --- L(Train): 0.0160929 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 760/1000 --- L(Train): 0.0161032 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 761/1000 --- L(Train): 0.0161024 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 762/1000 --- L(Train): 0.0161146 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 763/1000 --- L(Train): 0.0161067 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 764/1000 --- L(Train): 0.0161094 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 765/1000 --- L(Train): 0.0160997 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 766/1000 --- L(Train): 0.0161052 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 767/1000 --- L(Train): 0.0161054 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 768/1000 --- L(Train): 0.0161144 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 769/1000 --- L(Train): 0.0161059 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 770/1000 --- L(Train): 0.0161062 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 771/1000 --- L(Train): 0.0161065 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 772/1000 --- L(Train): 0.0161029 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 773/1000 --- L(Train): 0.0160935 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 774/1000 --- L(Train): 0.0161035 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 775/1000 --- L(Train): 0.0160967 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 776/1000 --- L(Train): 0.0161056 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 777/1000 --- L(Train): 0.0161007 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 778/1000 --- L(Train): 0.0161086 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 779/1000 --- L(Train): 0.0161054 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 780/1000 --- L(Train): 0.0161189 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 781/1000 --- L(Train): 0.0161104 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 782/1000 --- L(Train): 0.0161150 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 783/1000 --- L(Train): 0.0161068 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 784/1000 --- L(Train): 0.0161098 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 785/1000 --- L(Train): 0.0161058 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 786/1000 --- L(Train): 0.0161126 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 787/1000 --- L(Train): 0.0160993 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 788/1000 --- L(Train): 0.0161027 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 789/1000 --- L(Train): 0.0161092 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 790/1000 --- L(Train): 0.0160994 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 791/1000 --- L(Train): 0.0160847 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 792/1000 --- L(Train): 0.0160932 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 793/1000 --- L(Train): 0.0160932 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 794/1000 --- L(Train): 0.0160985 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 795/1000 --- L(Train): 0.0160875 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 796/1000 --- L(Train): 0.0160974 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 797/1000 --- L(Train): 0.0161019 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 798/1000 --- L(Train): 0.0161196 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 799/1000 --- L(Train): 0.0161061 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 800/1000 --- L(Train): 0.0161106 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 801/1000 --- L(Train): 0.0161086 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 802/1000 --- L(Train): 0.0161053 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 803/1000 --- L(Train): 0.0160965 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 804/1000 --- L(Train): 0.0161078 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 805/1000 --- L(Train): 0.0161010 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 806/1000 --- L(Train): 0.0161005 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 807/1000 --- L(Train): 0.0161006 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 808/1000 --- L(Train): 0.0160968 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 809/1000 --- L(Train): 0.0160892 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 810/1000 --- L(Train): 0.0160979 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 811/1000 --- L(Train): 0.0160949 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 812/1000 --- L(Train): 0.0160961 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 813/1000 --- L(Train): 0.0160921 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 814/1000 --- L(Train): 0.0160991 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 815/1000 --- L(Train): 0.0160902 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 816/1000 --- L(Train): 0.0161153 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 817/1000 --- L(Train): 0.0161115 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 818/1000 --- L(Train): 0.0161165 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "================================================================================\n",
            "Epoch 819/1000 --- L(Train): 0.0161069 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
            "Epoch 820/1000 --- L(Train): 0.0161078 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 821/1000 --- L(Train): 0.0161026 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 822/1000 --- L(Train): 0.0161108 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 823/1000 --- L(Train): 0.0161012 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 824/1000 --- L(Train): 0.0161055 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 825/1000 --- L(Train): 0.0161069 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 826/1000 --- L(Train): 0.0161051 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 827/1000 --- L(Train): 0.0160930 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 828/1000 --- L(Train): 0.0160956 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 829/1000 --- L(Train): 0.0160934 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 830/1000 --- L(Train): 0.0160932 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 831/1000 --- L(Train): 0.0160856 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 832/1000 --- L(Train): 0.0160948 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 833/1000 --- L(Train): 0.0160939 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 834/1000 --- L(Train): 0.0161089 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 835/1000 --- L(Train): 0.0161002 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 836/1000 --- L(Train): 0.0161042 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 837/1000 --- L(Train): 0.0160991 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 838/1000 --- L(Train): 0.0161044 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 839/1000 --- L(Train): 0.0160979 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 840/1000 --- L(Train): 0.0161063 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 841/1000 --- L(Train): 0.0161007 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 842/1000 --- L(Train): 0.0161021 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 843/1000 --- L(Train): 0.0160998 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 844/1000 --- L(Train): 0.0160974 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 845/1000 --- L(Train): 0.0160899 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 846/1000 --- L(Train): 0.0160922 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 847/1000 --- L(Train): 0.0160874 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 848/1000 --- L(Train): 0.0160959 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 849/1000 --- L(Train): 0.0160916 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 850/1000 --- L(Train): 0.0160996 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 851/1000 --- L(Train): 0.0160926 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 852/1000 --- L(Train): 0.0161081 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 853/1000 --- L(Train): 0.0161057 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 854/1000 --- L(Train): 0.0161132 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 855/1000 --- L(Train): 0.0160988 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 856/1000 --- L(Train): 0.0161068 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 857/1000 --- L(Train): 0.0161086 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 858/1000 --- L(Train): 0.0161113 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 859/1000 --- L(Train): 0.0160970 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 860/1000 --- L(Train): 0.0161014 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 861/1000 --- L(Train): 0.0161063 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 862/1000 --- L(Train): 0.0161002 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 863/1000 --- L(Train): 0.0160856 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 864/1000 --- L(Train): 0.0160953 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 865/1000 --- L(Train): 0.0160943 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 866/1000 --- L(Train): 0.0160994 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 867/1000 --- L(Train): 0.0160914 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 868/1000 --- L(Train): 0.0160940 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 869/1000 --- L(Train): 0.0160897 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 870/1000 --- L(Train): 0.0161068 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 871/1000 --- L(Train): 0.0161015 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 872/1000 --- L(Train): 0.0161019 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 873/1000 --- L(Train): 0.0160923 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 874/1000 --- L(Train): 0.0160923 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 875/1000 --- L(Train): 0.0160942 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 876/1000 --- L(Train): 0.0160999 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 877/1000 --- L(Train): 0.0160859 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 878/1000 --- L(Train): 0.0160909 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 879/1000 --- L(Train): 0.0160977 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 880/1000 --- L(Train): 0.0160932 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 881/1000 --- L(Train): 0.0160804 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 882/1000 --- L(Train): 0.0160941 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 883/1000 --- L(Train): 0.0160906 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 884/1000 --- L(Train): 0.0160994 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 885/1000 --- L(Train): 0.0160948 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 886/1000 --- L(Train): 0.0161006 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 887/1000 --- L(Train): 0.0160925 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 888/1000 --- L(Train): 0.0161163 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 889/1000 --- L(Train): 0.0161154 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 890/1000 --- L(Train): 0.0161120 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 891/1000 --- L(Train): 0.0160980 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 892/1000 --- L(Train): 0.0160964 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 893/1000 --- L(Train): 0.0161010 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 894/1000 --- L(Train): 0.0161060 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 895/1000 --- L(Train): 0.0160841 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 896/1000 --- L(Train): 0.0160911 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 897/1000 --- L(Train): 0.0161024 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 898/1000 --- L(Train): 0.0160996 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 899/1000 --- L(Train): 0.0160829 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 900/1000 --- L(Train): 0.0160929 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 901/1000 --- L(Train): 0.0160927 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 902/1000 --- L(Train): 0.0160930 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 903/1000 --- L(Train): 0.0160848 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 904/1000 --- L(Train): 0.0160991 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 905/1000 --- L(Train): 0.0160942 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 906/1000 --- L(Train): 0.0161151 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 907/1000 --- L(Train): 0.0161051 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 908/1000 --- L(Train): 0.0161030 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 909/1000 --- L(Train): 0.0160990 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 910/1000 --- L(Train): 0.0160965 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 911/1000 --- L(Train): 0.0160918 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 912/1000 --- L(Train): 0.0160980 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 913/1000 --- L(Train): 0.0160905 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 914/1000 --- L(Train): 0.0160921 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 915/1000 --- L(Train): 0.0160922 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 916/1000 --- L(Train): 0.0160881 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 917/1000 --- L(Train): 0.0160797 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 918/1000 --- L(Train): 0.0160904 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 919/1000 --- L(Train): 0.0160877 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 920/1000 --- L(Train): 0.0160975 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 921/1000 --- L(Train): 0.0160920 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 922/1000 --- L(Train): 0.0161005 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 923/1000 --- L(Train): 0.0160937 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 924/1000 --- L(Train): 0.0161112 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 925/1000 --- L(Train): 0.0161056 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 926/1000 --- L(Train): 0.0161088 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 927/1000 --- L(Train): 0.0160979 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 928/1000 --- L(Train): 0.0160996 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 929/1000 --- L(Train): 0.0161004 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 930/1000 --- L(Train): 0.0161018 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 931/1000 --- L(Train): 0.0160885 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 932/1000 --- L(Train): 0.0160947 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 933/1000 --- L(Train): 0.0160990 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 934/1000 --- L(Train): 0.0160963 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 935/1000 --- L(Train): 0.0160779 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 936/1000 --- L(Train): 0.0160875 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 937/1000 --- L(Train): 0.0160913 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 938/1000 --- L(Train): 0.0160961 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 939/1000 --- L(Train): 0.0160843 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 940/1000 --- L(Train): 0.0160888 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 941/1000 --- L(Train): 0.0160876 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 942/1000 --- L(Train): 0.0161018 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 943/1000 --- L(Train): 0.0160973 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 944/1000 --- L(Train): 0.0161043 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 945/1000 --- L(Train): 0.0160919 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 946/1000 --- L(Train): 0.0160920 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 947/1000 --- L(Train): 0.0160940 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 948/1000 --- L(Train): 0.0160983 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 949/1000 --- L(Train): 0.0160905 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 950/1000 --- L(Train): 0.0160957 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 951/1000 --- L(Train): 0.0160963 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 952/1000 --- L(Train): 0.0160934 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 953/1000 --- L(Train): 0.0160835 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 954/1000 --- L(Train): 0.0160949 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 955/1000 --- L(Train): 0.0160895 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 956/1000 --- L(Train): 0.0160981 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 957/1000 --- L(Train): 0.0160908 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 958/1000 --- L(Train): 0.0160942 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 959/1000 --- L(Train): 0.0160910 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 960/1000 --- L(Train): 0.0161064 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 961/1000 --- L(Train): 0.0160997 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 962/1000 --- L(Train): 0.0161020 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 963/1000 --- L(Train): 0.0160922 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 964/1000 --- L(Train): 0.0160911 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 965/1000 --- L(Train): 0.0160922 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 966/1000 --- L(Train): 0.0160999 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 967/1000 --- L(Train): 0.0160854 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 968/1000 --- L(Train): 0.0160945 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 969/1000 --- L(Train): 0.0161006 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 970/1000 --- L(Train): 0.0160955 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 971/1000 --- L(Train): 0.0160798 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 972/1000 --- L(Train): 0.0160902 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 973/1000 --- L(Train): 0.0160908 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 974/1000 --- L(Train): 0.0160961 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 975/1000 --- L(Train): 0.0160813 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 976/1000 --- L(Train): 0.0160925 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 977/1000 --- L(Train): 0.0161004 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 978/1000 --- L(Train): 0.0161147 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 979/1000 --- L(Train): 0.0160978 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 980/1000 --- L(Train): 0.0160983 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 981/1000 --- L(Train): 0.0160973 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 982/1000 --- L(Train): 0.0160906 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 983/1000 --- L(Train): 0.0160827 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 984/1000 --- L(Train): 0.0160957 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 985/1000 --- L(Train): 0.0160888 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 986/1000 --- L(Train): 0.0160951 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 987/1000 --- L(Train): 0.0160956 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 988/1000 --- L(Train): 0.0160908 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 989/1000 --- L(Train): 0.0160789 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 990/1000 --- L(Train): 0.0160905 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 991/1000 --- L(Train): 0.0160866 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 992/1000 --- L(Train): 0.0160947 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 993/1000 --- L(Train): 0.0160904 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 994/1000 --- L(Train): 0.0160966 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 995/1000 --- L(Train): 0.0160912 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 996/1000 --- L(Train): 0.0161059 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 997/1000 --- L(Train): 0.0160983 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 998/1000 --- L(Train): 0.0160989 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 999/1000 --- L(Train): 0.0160913 --- L(Val, SINDy): 0.0000000 --- Time: 0.01s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 1000/1000 --- L(Train): 0.0160935 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\u001b[H\u001b[2J================================================================================\n",
            "Epoch 1001/1000 --- L(Train): 0.0160892 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
            "--------------------------------------------------------------------------------\n",
            "SPICE Model (Coefficients: 17):\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n",
            "Cutoff patience:\n",
            "value_action: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_grooming: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_non_contact: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_contact: -, -, -, -, -, -, -, -, -, -, -, -, -, -, -\n",
            "value_scratch: 0, -, -, -, 0, -, -, -, -, -, -, -, -, -, -\n",
            "value_waiting: -, -, -, -, -, 0, -, -, -, -, -, -, -, -, -\n",
            "================================================================================\n",
            "\n",
            "Training result:\n",
            "L(Train): 1.5131233 --- L(Val, RNN): 1.4749963 --- L(Val, SINDy): 1.4996758\n",
            "\n",
            "RNN training finished.\n",
            "Training took 45.43 seconds.\n",
            "Saving SPICE model to ../params/hwang2025/test.pkl...\n",
            "================================================================================\n",
            "\n",
            "Training complete!\n",
            "\n",
            "Example SPICE model (participant 0):\n",
            "--------------------------------------------------------------------------------\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 1.0 value_grooming[t] \n",
            "value_non_contact[t+1] = -0.368 1 + 1.0 value_non_contact[t] + -0.483 sig_grooming \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.237 1 + 1.0 value_scratch[t] + -0.123 sig_grooming \n",
            "value_waiting[t+1] = 1.0 value_waiting[t] + 0.216 sig_non_contact \n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#test\n",
        "\n",
        "estimator = SpiceEstimator(\n",
        "        # model paramaeters\n",
        "        rnn_class=SPICERNN,\n",
        "        spice_config=spice_config,\n",
        "        n_actions=6,\n",
        "        # n_items=6,\n",
        "        n_participants=n_participants,\n",
        "        n_experiments=1,\n",
        "            \n",
        "        # rnn training parameters\n",
        "        epochs=10,  # --> try: 1000 --> 4000\n",
        "        warmup_steps=10,  # if epochs==4000: warmup_steps=1000\n",
        "        l2_rnn=0.00001,\n",
        "        learning_rate=0.01,\n",
        "            \n",
        "        # sindy fitting parameters\n",
        "        sindy_weight=0.001,\n",
        "        sindy_threshold=0.05,  # try: 0.1\n",
        "        sindy_threshold_frequency=1,\n",
        "        sindy_threshold_terms=1,\n",
        "        sindy_cutoff_patience=100,\n",
        "        sindy_epochs=1000,\n",
        "        sindy_alpha=0.0001,  # try: 0.00001, 0.001\n",
        "        sindy_library_polynomial_degree=1,\n",
        "            \n",
        "        verbose=True,\n",
        "        device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
        "        save_path_spice=f\"../params/hwang2025/test.pkl\",\n",
        "    )\n",
        "\n",
        "    #print(f\"\\nStarting training on {estimator.device}...\")\n",
        "print(f\"\\nStarting training\")\n",
        "print(\"=\" * 80)\n",
        "estimator.fit(dataset_train.xs, dataset_train.ys, dataset_test.xs, dataset_test.ys)\n",
        "    # estimator.load_spice(args.model)\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nTraining complete!\")\n",
        "\n",
        "    # Print example SPICE model for first participant\n",
        "print(\"\\nExample SPICE model (participant 0):\")\n",
        "print(\"-\" * 80)\n",
        "estimator.print_spice_model(participant_id=0)\n",
        "print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(311, 1, 1, 90)\n"
          ]
        }
      ],
      "source": [
        "coefs = []\n",
        "for module in estimator.rnn_model.sindy_coefficients.keys():\n",
        "    coefs.append(estimator.rnn_model.sindy_coefficients[module].detach().cpu().numpy())\n",
        "coefs = np.concatenate(coefs, axis=-1)\n",
        "print(coefs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SPICE for Ape 0 -> Ape 2:\n",
            "value_action[t+1] = 0.081 1 + 0.477 value_action[t] + -0.062 chosen + -0.061 sig_action + 0.158 sig_grooming \n",
            "value_grooming[t+1] = 0.664 1 + 0.06 value_grooming[t] + -0.163 chosen + 0.058 sig_action + -0.15 sig_grooming \n",
            "value_non_contact[t+1] = -0.613 1 + 0.561 value_non_contact[t] \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.542 1 + 0.335 value_scratch[t] \n",
            "value_waiting[t+1] = 0.591 1 + -0.392 value_waiting[t] + 0.239 chosen + 0.245 sig_waiting \n",
            "\n",
            "SPICE for Ape 0 -> Ape 5:\n",
            "value_action[t+1] = 1.0 value_action[t] \n",
            "value_grooming[t+1] = 0.054 1 + 0.038 value_grooming[t] + 0.204 sig_action + 0.172 sig_waiting \n",
            "value_non_contact[t+1] = -0.953 1 + 0.267 value_non_contact[t] \n",
            "value_contact[t+1] = 1.0 value_contact[t] \n",
            "value_scratch[t+1] = -0.339 1 + 0.571 value_scratch[t] \n",
            "value_waiting[t+1] = 0.229 1 + -0.646 value_waiting[t] + 0.247 chosen + -0.368 sig_grooming + 0.247 sig_waiting \n"
          ]
        }
      ],
      "source": [
        "print(\"SPICE for Ape 0 -> Ape 2:\")\n",
        "estimator.print_spice_model(1)\n",
        "\n",
        "print(\"\\nSPICE for Ape 0 -> Ape 5:\")\n",
        "estimator.print_spice_model(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load trained model\n",
        "path_model = \"../params/hwang2025/spice_ep10_warm100_th0.05_alpha0.01.pkl\"\n",
        "\n",
        "estimator = SpiceEstimator(\n",
        "            # model paramaeters\n",
        "            rnn_class=SPICERNN,\n",
        "            spice_config=spice_config,\n",
        "            n_actions=6,\n",
        "            # n_items=6,\n",
        "            n_participants=n_participants,\n",
        "            n_experiments=1,\n",
        "            sindy_ensemble_size=1,\n",
        ")\n",
        "estimator.load_spice(path_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "value_action[t+1] = 0.065 1 + 1.003 value_action[t] + 0.001 chosen + 0.002 sig_action + 0.047 sig_grooming + -0.007 sig_non_contact + -0.002 sig_contact + -0.003 sig_scratch + 0.001 sig_waiting + 0.001 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + -0.001 prev_contact + 0.003 prev_scratch + 0.001 prev_waiting \n",
            "value_grooming[t+1] = -0.087 1 + 1.003 value_grooming[t] + 0.005 chosen + 0.001 sig_action + 0.008 sig_grooming + -0.096 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.002 sig_waiting + -0.001 prev_action + 0.002 prev_grooming + 0.001 prev_non_contact + 0.001 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_non_contact[t+1] = -0.03 1 + 0.996 value_non_contact[t] + 0.097 chosen + -0.002 sig_action + -0.091 sig_grooming + 0.097 sig_non_contact + -0.002 sig_contact + -0.002 sig_scratch + -0.002 sig_waiting + 0.002 prev_action + -0.002 prev_grooming + 0.003 prev_non_contact + -0.002 prev_contact + 0.001 prev_scratch + 0.003 prev_waiting \n",
            "value_contact[t+1] = -0.103 1 + 0.999 value_contact[t] + -0.003 chosen + 0.003 sig_action + -0.1 sig_grooming + 0.009 sig_non_contact + 0.003 sig_contact + -0.002 sig_scratch + -0.001 sig_waiting + -0.003 prev_action + -0.003 prev_grooming + -0.001 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_scratch[t+1] = -0.042 1 + 0.997 value_scratch[t] + 0.003 chosen + 0.001 sig_action + -0.002 sig_grooming + 0.002 sig_non_contact + 0.001 sig_contact + -0.001 sig_scratch + -0.001 sig_waiting + 0.003 prev_action + -0.002 prev_grooming + -0.002 prev_non_contact + 0.001 prev_contact + 0.003 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.032 1 + 0.999 value_waiting[t] + 0.003 chosen + -0.001 sig_action + 0.001 sig_grooming + 0.002 sig_non_contact + -0.003 sig_contact + 0.002 sig_scratch + -0.001 sig_waiting + 0.002 prev_action + -0.001 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + -0.002 prev_scratch + -0.001 prev_waiting \n",
            "tensor([[ 0.0653,  0.0030,  0.0009,  0.0015,  0.0474, -0.0073, -0.0016, -0.0029,\n",
            "          0.0009,  0.0011, -0.0017, -0.0016, -0.0009,  0.0031,  0.0012]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "['1', 'value_action', 'chosen', 'sig_action', 'sig_grooming', 'sig_non_contact', 'sig_contact', 'sig_scratch', 'sig_waiting', 'prev_action', 'prev_grooming', 'prev_non_contact', 'prev_contact', 'prev_scratch', 'prev_waiting']\n"
          ]
        }
      ],
      "source": [
        "estimator.print_spice_model(participant_id=0)\n",
        "print(estimator.rnn_model.sindy_coefficients['value_action'][0, 0] * estimator.rnn_model.sindy_coefficients_presence['value_action'][0, 0])\n",
        "print(estimator.rnn_model.sindy_candidate_terms['value_action'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GRU for benchmarking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Classic GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "sys.path.append('../..')\n",
        "from weinhardt2025.benchmarking.benchmarking_gru import GRU, training, setup_agent_gru\n",
        "\n",
        "path_gru = '../../weinhardt2025/params/hwang2025/gru_hwang2025.pkl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs = 1000\n",
        "\n",
        "gru = GRU(n_actions=n_actions, additional_inputs=4).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(gru.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000: L(Train): 1.8450233936309814; L(Test): 1.615799069404602\n",
            "Epoch 2/1000: L(Train): 1.6100212335586548; L(Test): 1.5714551210403442\n",
            "Epoch 3/1000: L(Train): 1.5765694379806519; L(Test): 1.5537710189819336\n",
            "Epoch 4/1000: L(Train): 1.5597003698349; L(Test): 1.5473741292953491\n",
            "Epoch 5/1000: L(Train): 1.5524648427963257; L(Test): 1.5423420667648315\n",
            "Epoch 6/1000: L(Train): 1.536084532737732; L(Test): 1.5303282737731934\n",
            "Epoch 7/1000: L(Train): 1.5336699485778809; L(Test): 1.5257753133773804\n",
            "Epoch 8/1000: L(Train): 1.5419871807098389; L(Test): 1.5267796516418457\n",
            "Epoch 9/1000: L(Train): 1.537778377532959; L(Test): 1.5281466245651245\n",
            "Epoch 10/1000: L(Train): 1.5261372327804565; L(Test): 1.528973937034607\n",
            "Epoch 11/1000: L(Train): 1.5250424146652222; L(Test): 1.5277245044708252\n",
            "Epoch 12/1000: L(Train): 1.531541347503662; L(Test): 1.5261781215667725\n",
            "Epoch 13/1000: L(Train): 1.5367588996887207; L(Test): 1.5246026515960693\n",
            "Epoch 14/1000: L(Train): 1.5256296396255493; L(Test): 1.5235520601272583\n",
            "Epoch 15/1000: L(Train): 1.5332297086715698; L(Test): 1.5229450464248657\n",
            "Epoch 16/1000: L(Train): 1.5259791612625122; L(Test): 1.52190363407135\n",
            "Epoch 17/1000: L(Train): 1.5373233556747437; L(Test): 1.520835518836975\n",
            "Epoch 18/1000: L(Train): 1.5439870357513428; L(Test): 1.5195461511611938\n",
            "Epoch 19/1000: L(Train): 1.5320686101913452; L(Test): 1.517568588256836\n",
            "Epoch 20/1000: L(Train): 1.5322787761688232; L(Test): 1.5199509859085083\n",
            "Epoch 21/1000: L(Train): 1.5221072435379028; L(Test): 1.515228033065796\n",
            "Epoch 22/1000: L(Train): 1.514228343963623; L(Test): 1.5119410753250122\n",
            "Epoch 23/1000: L(Train): 1.52308988571167; L(Test): 1.5108646154403687\n",
            "Epoch 24/1000: L(Train): 1.5300548076629639; L(Test): 1.505557656288147\n",
            "Epoch 25/1000: L(Train): 1.5139331817626953; L(Test): 1.5028892755508423\n",
            "Epoch 26/1000: L(Train): 1.5238232612609863; L(Test): 1.499183177947998\n",
            "Epoch 27/1000: L(Train): 1.5132404565811157; L(Test): 1.4940797090530396\n",
            "Epoch 28/1000: L(Train): 1.5086323022842407; L(Test): 1.4911081790924072\n",
            "Epoch 29/1000: L(Train): 1.5223112106323242; L(Test): 1.4871352910995483\n",
            "Epoch 30/1000: L(Train): 1.5158967971801758; L(Test): 1.4860293865203857\n",
            "Epoch 31/1000: L(Train): 1.5009679794311523; L(Test): 1.4813613891601562\n",
            "Epoch 32/1000: L(Train): 1.503038763999939; L(Test): 1.4755271673202515\n",
            "Epoch 33/1000: L(Train): 1.483715295791626; L(Test): 1.4710332155227661\n",
            "Epoch 34/1000: L(Train): 1.4797439575195312; L(Test): 1.4673656225204468\n",
            "Epoch 35/1000: L(Train): 1.4815419912338257; L(Test): 1.4646949768066406\n",
            "Epoch 36/1000: L(Train): 1.4660648107528687; L(Test): 1.4585663080215454\n",
            "Epoch 37/1000: L(Train): 1.4742295742034912; L(Test): 1.451366901397705\n",
            "Epoch 38/1000: L(Train): 1.4810477495193481; L(Test): 1.4462411403656006\n",
            "Epoch 39/1000: L(Train): 1.4533932209014893; L(Test): 1.4415719509124756\n",
            "Epoch 40/1000: L(Train): 1.4585676193237305; L(Test): 1.4372141361236572\n",
            "Epoch 41/1000: L(Train): 1.4483102560043335; L(Test): 1.4340293407440186\n",
            "Epoch 42/1000: L(Train): 1.4522827863693237; L(Test): 1.4310815334320068\n",
            "Epoch 43/1000: L(Train): 1.4433221817016602; L(Test): 1.427972674369812\n",
            "Epoch 44/1000: L(Train): 1.4356480836868286; L(Test): 1.4276553392410278\n",
            "Epoch 45/1000: L(Train): 1.443992018699646; L(Test): 1.4239672422409058\n",
            "Epoch 46/1000: L(Train): 1.4316647052764893; L(Test): 1.4219615459442139\n",
            "Epoch 47/1000: L(Train): 1.44195556640625; L(Test): 1.4181569814682007\n",
            "Epoch 48/1000: L(Train): 1.441266417503357; L(Test): 1.4175342321395874\n",
            "Epoch 49/1000: L(Train): 1.4239081144332886; L(Test): 1.4172933101654053\n",
            "Epoch 50/1000: L(Train): 1.4263341426849365; L(Test): 1.4139604568481445\n",
            "Epoch 51/1000: L(Train): 1.4305405616760254; L(Test): 1.4100483655929565\n",
            "Epoch 52/1000: L(Train): 1.427093744277954; L(Test): 1.407683253288269\n",
            "Epoch 53/1000: L(Train): 1.4168533086776733; L(Test): 1.4060605764389038\n",
            "Epoch 54/1000: L(Train): 1.4023051261901855; L(Test): 1.403354287147522\n",
            "Epoch 55/1000: L(Train): 1.4186985492706299; L(Test): 1.4015244245529175\n",
            "Epoch 56/1000: L(Train): 1.428196668624878; L(Test): 1.399896264076233\n",
            "Epoch 57/1000: L(Train): 1.4193503856658936; L(Test): 1.400057315826416\n",
            "Epoch 58/1000: L(Train): 1.413794755935669; L(Test): 1.3960866928100586\n",
            "Epoch 59/1000: L(Train): 1.4160549640655518; L(Test): 1.3936353921890259\n",
            "Epoch 60/1000: L(Train): 1.4234890937805176; L(Test): 1.3920639753341675\n",
            "Epoch 61/1000: L(Train): 1.3974534273147583; L(Test): 1.3903496265411377\n",
            "Epoch 62/1000: L(Train): 1.3851232528686523; L(Test): 1.3885505199432373\n",
            "Epoch 63/1000: L(Train): 1.3986127376556396; L(Test): 1.3869959115982056\n",
            "Epoch 64/1000: L(Train): 1.400568962097168; L(Test): 1.3852192163467407\n",
            "Epoch 65/1000: L(Train): 1.4135419130325317; L(Test): 1.3841352462768555\n",
            "Epoch 66/1000: L(Train): 1.3844022750854492; L(Test): 1.3822827339172363\n",
            "Epoch 67/1000: L(Train): 1.4105778932571411; L(Test): 1.3808975219726562\n",
            "Epoch 68/1000: L(Train): 1.4045097827911377; L(Test): 1.379940152168274\n",
            "Epoch 69/1000: L(Train): 1.3724710941314697; L(Test): 1.3780436515808105\n",
            "Epoch 70/1000: L(Train): 1.4211876392364502; L(Test): 1.3793731927871704\n",
            "Epoch 71/1000: L(Train): 1.3883873224258423; L(Test): 1.3750827312469482\n",
            "Epoch 72/1000: L(Train): 1.392352819442749; L(Test): 1.3763618469238281\n",
            "Epoch 73/1000: L(Train): 1.3823375701904297; L(Test): 1.372765302658081\n",
            "Epoch 74/1000: L(Train): 1.381582260131836; L(Test): 1.3730947971343994\n",
            "Epoch 75/1000: L(Train): 1.3747820854187012; L(Test): 1.3705813884735107\n",
            "Epoch 76/1000: L(Train): 1.4021278619766235; L(Test): 1.3699573278427124\n",
            "Epoch 77/1000: L(Train): 1.3811522722244263; L(Test): 1.368067979812622\n",
            "Epoch 78/1000: L(Train): 1.3753581047058105; L(Test): 1.3665077686309814\n",
            "Epoch 79/1000: L(Train): 1.3995472192764282; L(Test): 1.3683266639709473\n",
            "Epoch 80/1000: L(Train): 1.3888202905654907; L(Test): 1.366599202156067\n",
            "Epoch 81/1000: L(Train): 1.3889222145080566; L(Test): 1.3637681007385254\n",
            "Epoch 82/1000: L(Train): 1.3674087524414062; L(Test): 1.3645524978637695\n",
            "Epoch 83/1000: L(Train): 1.3737655878067017; L(Test): 1.3619270324707031\n",
            "Epoch 84/1000: L(Train): 1.378024697303772; L(Test): 1.3622715473175049\n",
            "Epoch 85/1000: L(Train): 1.3582707643508911; L(Test): 1.3626573085784912\n",
            "Epoch 86/1000: L(Train): 1.393804907798767; L(Test): 1.3596793413162231\n",
            "Epoch 87/1000: L(Train): 1.3676598072052002; L(Test): 1.3604787588119507\n",
            "Epoch 88/1000: L(Train): 1.3766132593154907; L(Test): 1.3573987483978271\n",
            "Epoch 89/1000: L(Train): 1.3622968196868896; L(Test): 1.356385350227356\n",
            "Epoch 90/1000: L(Train): 1.361655592918396; L(Test): 1.3556207418441772\n",
            "Epoch 91/1000: L(Train): 1.3799691200256348; L(Test): 1.3534561395645142\n",
            "Epoch 92/1000: L(Train): 1.369303822517395; L(Test): 1.3528518676757812\n",
            "Epoch 93/1000: L(Train): 1.3274883031845093; L(Test): 1.3530851602554321\n",
            "Epoch 94/1000: L(Train): 1.3655478954315186; L(Test): 1.35072660446167\n",
            "Epoch 95/1000: L(Train): 1.3444753885269165; L(Test): 1.351331353187561\n",
            "Epoch 96/1000: L(Train): 1.364539623260498; L(Test): 1.3509838581085205\n",
            "Epoch 97/1000: L(Train): 1.361662745475769; L(Test): 1.350022315979004\n",
            "Epoch 98/1000: L(Train): 1.3775389194488525; L(Test): 1.3500118255615234\n",
            "Epoch 99/1000: L(Train): 1.3703007698059082; L(Test): 1.3490803241729736\n",
            "Epoch 100/1000: L(Train): 1.3669854402542114; L(Test): 1.3464488983154297\n",
            "Epoch 101/1000: L(Train): 1.3643258810043335; L(Test): 1.3464114665985107\n",
            "Epoch 102/1000: L(Train): 1.368238091468811; L(Test): 1.3470022678375244\n",
            "Epoch 103/1000: L(Train): 1.3502033948898315; L(Test): 1.344627857208252\n",
            "Epoch 104/1000: L(Train): 1.3536111116409302; L(Test): 1.3469746112823486\n",
            "Epoch 105/1000: L(Train): 1.3441845178604126; L(Test): 1.345833420753479\n",
            "Epoch 106/1000: L(Train): 1.3229438066482544; L(Test): 1.3444750308990479\n",
            "Epoch 107/1000: L(Train): 1.3769209384918213; L(Test): 1.3442124128341675\n",
            "Epoch 108/1000: L(Train): 1.3618841171264648; L(Test): 1.343116283416748\n",
            "Epoch 109/1000: L(Train): 1.3734641075134277; L(Test): 1.3421413898468018\n",
            "Epoch 110/1000: L(Train): 1.351917028427124; L(Test): 1.3410433530807495\n",
            "Epoch 111/1000: L(Train): 1.347260594367981; L(Test): 1.3400429487228394\n",
            "Epoch 112/1000: L(Train): 1.3567214012145996; L(Test): 1.339828610420227\n",
            "Epoch 113/1000: L(Train): 1.35023832321167; L(Test): 1.3387649059295654\n",
            "Epoch 114/1000: L(Train): 1.334662914276123; L(Test): 1.337939739227295\n",
            "Epoch 115/1000: L(Train): 1.33929443359375; L(Test): 1.3375777006149292\n",
            "Epoch 116/1000: L(Train): 1.3591679334640503; L(Test): 1.3367193937301636\n",
            "Epoch 117/1000: L(Train): 1.3407243490219116; L(Test): 1.3360956907272339\n",
            "Epoch 118/1000: L(Train): 1.3589006662368774; L(Test): 1.3357104063034058\n",
            "Epoch 119/1000: L(Train): 1.3545923233032227; L(Test): 1.3364369869232178\n",
            "Epoch 120/1000: L(Train): 1.3370933532714844; L(Test): 1.3344184160232544\n",
            "Epoch 121/1000: L(Train): 1.3766698837280273; L(Test): 1.332258701324463\n",
            "Epoch 122/1000: L(Train): 1.3469150066375732; L(Test): 1.3325494527816772\n",
            "Epoch 123/1000: L(Train): 1.3478031158447266; L(Test): 1.332759141921997\n",
            "Epoch 124/1000: L(Train): 1.3530406951904297; L(Test): 1.3346171379089355\n",
            "Epoch 125/1000: L(Train): 1.3430341482162476; L(Test): 1.3316829204559326\n",
            "Epoch 126/1000: L(Train): 1.3546937704086304; L(Test): 1.331079363822937\n",
            "Epoch 127/1000: L(Train): 1.3557385206222534; L(Test): 1.3300693035125732\n",
            "Epoch 128/1000: L(Train): 1.3561534881591797; L(Test): 1.3279067277908325\n",
            "Epoch 129/1000: L(Train): 1.3462462425231934; L(Test): 1.3294146060943604\n",
            "Epoch 130/1000: L(Train): 1.3604167699813843; L(Test): 1.3263275623321533\n",
            "Epoch 131/1000: L(Train): 1.3627232313156128; L(Test): 1.325575590133667\n",
            "Epoch 132/1000: L(Train): 1.3410260677337646; L(Test): 1.3257888555526733\n",
            "Epoch 133/1000: L(Train): 1.3554651737213135; L(Test): 1.3259775638580322\n",
            "Epoch 134/1000: L(Train): 1.3562231063842773; L(Test): 1.3284426927566528\n",
            "Epoch 135/1000: L(Train): 1.3474328517913818; L(Test): 1.3254114389419556\n",
            "Epoch 136/1000: L(Train): 1.3562690019607544; L(Test): 1.3255366086959839\n",
            "Epoch 137/1000: L(Train): 1.3539235591888428; L(Test): 1.3256068229675293\n",
            "Epoch 138/1000: L(Train): 1.3535747528076172; L(Test): 1.323269009590149\n",
            "Epoch 139/1000: L(Train): 1.3414748907089233; L(Test): 1.3262660503387451\n",
            "Epoch 140/1000: L(Train): 1.364356517791748; L(Test): 1.3251187801361084\n",
            "Epoch 141/1000: L(Train): 1.3264347314834595; L(Test): 1.3197619915008545\n",
            "Epoch 142/1000: L(Train): 1.3268892765045166; L(Test): 1.3237206935882568\n",
            "Epoch 143/1000: L(Train): 1.3503444194793701; L(Test): 1.3195124864578247\n",
            "Epoch 144/1000: L(Train): 1.3212571144104004; L(Test): 1.3197426795959473\n",
            "Epoch 145/1000: L(Train): 1.3577739000320435; L(Test): 1.3204452991485596\n",
            "Epoch 146/1000: L(Train): 1.3257838487625122; L(Test): 1.3175458908081055\n",
            "Epoch 147/1000: L(Train): 1.3210234642028809; L(Test): 1.3173643350601196\n",
            "Epoch 148/1000: L(Train): 1.3667151927947998; L(Test): 1.3154982328414917\n",
            "Epoch 149/1000: L(Train): 1.3279662132263184; L(Test): 1.3164795637130737\n",
            "Epoch 150/1000: L(Train): 1.3367236852645874; L(Test): 1.3159290552139282\n",
            "Epoch 151/1000: L(Train): 1.3486610651016235; L(Test): 1.3131358623504639\n",
            "Epoch 152/1000: L(Train): 1.329262375831604; L(Test): 1.3144440650939941\n",
            "Epoch 153/1000: L(Train): 1.3353263139724731; L(Test): 1.3126146793365479\n",
            "Epoch 154/1000: L(Train): 1.318056344985962; L(Test): 1.312022089958191\n",
            "Epoch 155/1000: L(Train): 1.3337855339050293; L(Test): 1.3125120401382446\n",
            "Epoch 156/1000: L(Train): 1.337372899055481; L(Test): 1.309462547302246\n",
            "Epoch 157/1000: L(Train): 1.3265544176101685; L(Test): 1.310538411140442\n",
            "Epoch 158/1000: L(Train): 1.34122896194458; L(Test): 1.3131569623947144\n",
            "Epoch 159/1000: L(Train): 1.316444754600525; L(Test): 1.3107988834381104\n",
            "Epoch 160/1000: L(Train): 1.3109514713287354; L(Test): 1.3122562170028687\n",
            "Epoch 161/1000: L(Train): 1.3405877351760864; L(Test): 1.311132550239563\n",
            "Epoch 162/1000: L(Train): 1.3080077171325684; L(Test): 1.309015154838562\n",
            "Epoch 163/1000: L(Train): 1.3319988250732422; L(Test): 1.3077136278152466\n",
            "Epoch 164/1000: L(Train): 1.3349859714508057; L(Test): 1.307783603668213\n",
            "Epoch 165/1000: L(Train): 1.3336371183395386; L(Test): 1.3072395324707031\n",
            "Epoch 166/1000: L(Train): 1.3093887567520142; L(Test): 1.3062280416488647\n",
            "Epoch 167/1000: L(Train): 1.3320660591125488; L(Test): 1.3044066429138184\n",
            "Epoch 168/1000: L(Train): 1.3533501625061035; L(Test): 1.307397484779358\n",
            "Epoch 169/1000: L(Train): 1.3324946165084839; L(Test): 1.304213523864746\n",
            "Epoch 170/1000: L(Train): 1.341666579246521; L(Test): 1.305206298828125\n",
            "Epoch 171/1000: L(Train): 1.3087347745895386; L(Test): 1.309217929840088\n",
            "Epoch 172/1000: L(Train): 1.3414332866668701; L(Test): 1.3071647882461548\n",
            "Epoch 173/1000: L(Train): 1.3261966705322266; L(Test): 1.3026014566421509\n",
            "Epoch 174/1000: L(Train): 1.3218635320663452; L(Test): 1.3064488172531128\n",
            "Epoch 175/1000: L(Train): 1.351152777671814; L(Test): 1.3059793710708618\n",
            "Epoch 176/1000: L(Train): 1.3173974752426147; L(Test): 1.302470088005066\n",
            "Epoch 177/1000: L(Train): 1.348020315170288; L(Test): 1.3022266626358032\n",
            "Epoch 178/1000: L(Train): 1.3347663879394531; L(Test): 1.302962064743042\n",
            "Epoch 179/1000: L(Train): 1.3313937187194824; L(Test): 1.2990604639053345\n",
            "Epoch 180/1000: L(Train): 1.3272204399108887; L(Test): 1.3009165525436401\n",
            "Epoch 181/1000: L(Train): 1.3248610496520996; L(Test): 1.2996728420257568\n",
            "Epoch 182/1000: L(Train): 1.3129459619522095; L(Test): 1.2985173463821411\n",
            "Epoch 183/1000: L(Train): 1.3170444965362549; L(Test): 1.3023004531860352\n",
            "Epoch 184/1000: L(Train): 1.3251348733901978; L(Test): 1.297095775604248\n",
            "Epoch 185/1000: L(Train): 1.3129029273986816; L(Test): 1.301869511604309\n",
            "Epoch 186/1000: L(Train): 1.335354208946228; L(Test): 1.2977949380874634\n",
            "Epoch 187/1000: L(Train): 1.313530683517456; L(Test): 1.2954524755477905\n",
            "Epoch 188/1000: L(Train): 1.3151543140411377; L(Test): 1.2982993125915527\n",
            "Epoch 189/1000: L(Train): 1.3125470876693726; L(Test): 1.2941313982009888\n",
            "Epoch 190/1000: L(Train): 1.3322763442993164; L(Test): 1.295275330543518\n",
            "Epoch 191/1000: L(Train): 1.332222580909729; L(Test): 1.299765944480896\n",
            "Epoch 192/1000: L(Train): 1.3415632247924805; L(Test): 1.2963995933532715\n",
            "Epoch 193/1000: L(Train): 1.3231889009475708; L(Test): 1.2924617528915405\n",
            "Epoch 194/1000: L(Train): 1.325417160987854; L(Test): 1.297134518623352\n",
            "Epoch 195/1000: L(Train): 1.338549017906189; L(Test): 1.2929060459136963\n",
            "Epoch 196/1000: L(Train): 1.2910263538360596; L(Test): 1.294044017791748\n",
            "Epoch 197/1000: L(Train): 1.3144986629486084; L(Test): 1.2955005168914795\n",
            "Epoch 198/1000: L(Train): 1.3316278457641602; L(Test): 1.2898029088974\n",
            "Epoch 199/1000: L(Train): 1.3152992725372314; L(Test): 1.290327548980713\n",
            "Epoch 200/1000: L(Train): 1.321101427078247; L(Test): 1.2915518283843994\n",
            "Epoch 201/1000: L(Train): 1.3250784873962402; L(Test): 1.2872294187545776\n",
            "Epoch 202/1000: L(Train): 1.3009432554244995; L(Test): 1.2878875732421875\n",
            "Epoch 203/1000: L(Train): 1.3160988092422485; L(Test): 1.28767991065979\n",
            "Epoch 204/1000: L(Train): 1.3110418319702148; L(Test): 1.2858514785766602\n",
            "Epoch 205/1000: L(Train): 1.311096429824829; L(Test): 1.2825325727462769\n",
            "Epoch 206/1000: L(Train): 1.3075124025344849; L(Test): 1.2833372354507446\n",
            "Epoch 207/1000: L(Train): 1.3160754442214966; L(Test): 1.2851682901382446\n",
            "Epoch 208/1000: L(Train): 1.3109686374664307; L(Test): 1.2829687595367432\n",
            "Epoch 209/1000: L(Train): 1.2837152481079102; L(Test): 1.282833456993103\n",
            "Epoch 210/1000: L(Train): 1.3183188438415527; L(Test): 1.2821322679519653\n",
            "Epoch 211/1000: L(Train): 1.3122494220733643; L(Test): 1.2790417671203613\n",
            "Epoch 212/1000: L(Train): 1.3083516359329224; L(Test): 1.2791978120803833\n",
            "Epoch 213/1000: L(Train): 1.2878485918045044; L(Test): 1.2789921760559082\n",
            "Epoch 214/1000: L(Train): 1.3169993162155151; L(Test): 1.2775413990020752\n",
            "Epoch 215/1000: L(Train): 1.2922263145446777; L(Test): 1.2766928672790527\n",
            "Epoch 216/1000: L(Train): 1.3150027990341187; L(Test): 1.2776035070419312\n",
            "Epoch 217/1000: L(Train): 1.276751160621643; L(Test): 1.2757648229599\n",
            "Epoch 218/1000: L(Train): 1.3072566986083984; L(Test): 1.2737619876861572\n",
            "Epoch 219/1000: L(Train): 1.2858377695083618; L(Test): 1.2736210823059082\n",
            "Epoch 220/1000: L(Train): 1.3112080097198486; L(Test): 1.273138403892517\n",
            "Epoch 221/1000: L(Train): 1.293709397315979; L(Test): 1.271457314491272\n",
            "Epoch 222/1000: L(Train): 1.2772732973098755; L(Test): 1.2705326080322266\n",
            "Epoch 223/1000: L(Train): 1.2710094451904297; L(Test): 1.270600438117981\n",
            "Epoch 224/1000: L(Train): 1.3150724172592163; L(Test): 1.2704108953475952\n",
            "Epoch 225/1000: L(Train): 1.2835198640823364; L(Test): 1.268468976020813\n",
            "Epoch 226/1000: L(Train): 1.290794014930725; L(Test): 1.2684661149978638\n",
            "Epoch 227/1000: L(Train): 1.2893246412277222; L(Test): 1.267873764038086\n",
            "Epoch 228/1000: L(Train): 1.2979806661605835; L(Test): 1.268126368522644\n",
            "Epoch 229/1000: L(Train): 1.3011887073516846; L(Test): 1.2663689851760864\n",
            "Epoch 230/1000: L(Train): 1.296673059463501; L(Test): 1.2656898498535156\n",
            "Epoch 231/1000: L(Train): 1.2887498140335083; L(Test): 1.2667386531829834\n",
            "Epoch 232/1000: L(Train): 1.2796999216079712; L(Test): 1.2660472393035889\n",
            "Epoch 233/1000: L(Train): 1.3109805583953857; L(Test): 1.267281174659729\n",
            "Epoch 234/1000: L(Train): 1.269342303276062; L(Test): 1.2638535499572754\n",
            "Epoch 235/1000: L(Train): 1.2946494817733765; L(Test): 1.2623186111450195\n",
            "Epoch 236/1000: L(Train): 1.2989321947097778; L(Test): 1.2603329420089722\n",
            "Epoch 237/1000: L(Train): 1.2918869256973267; L(Test): 1.2619446516036987\n",
            "Epoch 238/1000: L(Train): 1.2939540147781372; L(Test): 1.2605894804000854\n",
            "Epoch 239/1000: L(Train): 1.2707875967025757; L(Test): 1.259251356124878\n",
            "Epoch 240/1000: L(Train): 1.2874706983566284; L(Test): 1.2612779140472412\n",
            "Epoch 241/1000: L(Train): 1.2933155298233032; L(Test): 1.2566170692443848\n",
            "Epoch 242/1000: L(Train): 1.272635817527771; L(Test): 1.2595248222351074\n",
            "Epoch 243/1000: L(Train): 1.2752878665924072; L(Test): 1.2592334747314453\n",
            "Epoch 244/1000: L(Train): 1.2765278816223145; L(Test): 1.2570757865905762\n",
            "Epoch 245/1000: L(Train): 1.2977197170257568; L(Test): 1.2578866481781006\n",
            "Epoch 246/1000: L(Train): 1.2860270738601685; L(Test): 1.2534494400024414\n",
            "Epoch 247/1000: L(Train): 1.2798880338668823; L(Test): 1.2556360960006714\n",
            "Epoch 248/1000: L(Train): 1.2888715267181396; L(Test): 1.2524741888046265\n",
            "Epoch 249/1000: L(Train): 1.2591688632965088; L(Test): 1.252419114112854\n",
            "Epoch 250/1000: L(Train): 1.2816154956817627; L(Test): 1.2522809505462646\n",
            "Epoch 251/1000: L(Train): 1.2747012376785278; L(Test): 1.2547698020935059\n",
            "Epoch 252/1000: L(Train): 1.2880491018295288; L(Test): 1.2540842294692993\n",
            "Epoch 253/1000: L(Train): 1.2803667783737183; L(Test): 1.2509691715240479\n",
            "Epoch 254/1000: L(Train): 1.299882173538208; L(Test): 1.2519240379333496\n",
            "Epoch 255/1000: L(Train): 1.2733594179153442; L(Test): 1.2505007982254028\n",
            "Epoch 256/1000: L(Train): 1.297217845916748; L(Test): 1.2490373849868774\n",
            "Epoch 257/1000: L(Train): 1.292663812637329; L(Test): 1.248784065246582\n",
            "Epoch 258/1000: L(Train): 1.2678983211517334; L(Test): 1.2478362321853638\n",
            "Epoch 259/1000: L(Train): 1.2612937688827515; L(Test): 1.2475007772445679\n",
            "Epoch 260/1000: L(Train): 1.2768747806549072; L(Test): 1.2466405630111694\n",
            "Epoch 261/1000: L(Train): 1.2863630056381226; L(Test): 1.2456423044204712\n",
            "Epoch 262/1000: L(Train): 1.267698049545288; L(Test): 1.248008131980896\n",
            "Epoch 263/1000: L(Train): 1.2633293867111206; L(Test): 1.2453677654266357\n",
            "Epoch 264/1000: L(Train): 1.293782353401184; L(Test): 1.2428741455078125\n",
            "Epoch 265/1000: L(Train): 1.2618372440338135; L(Test): 1.2427414655685425\n",
            "Epoch 266/1000: L(Train): 1.2698534727096558; L(Test): 1.2412718534469604\n",
            "Epoch 267/1000: L(Train): 1.2610787153244019; L(Test): 1.2439085245132446\n",
            "Epoch 268/1000: L(Train): 1.2821530103683472; L(Test): 1.242035984992981\n",
            "Epoch 269/1000: L(Train): 1.2897530794143677; L(Test): 1.2399368286132812\n",
            "Epoch 270/1000: L(Train): 1.2814682722091675; L(Test): 1.2399927377700806\n",
            "Epoch 271/1000: L(Train): 1.2867813110351562; L(Test): 1.241979718208313\n",
            "Epoch 272/1000: L(Train): 1.2614794969558716; L(Test): 1.2394918203353882\n",
            "Epoch 273/1000: L(Train): 1.251946210861206; L(Test): 1.2386093139648438\n",
            "Epoch 274/1000: L(Train): 1.257601261138916; L(Test): 1.2365864515304565\n",
            "Epoch 275/1000: L(Train): 1.2798517942428589; L(Test): 1.2374271154403687\n",
            "Epoch 276/1000: L(Train): 1.283010482788086; L(Test): 1.235706090927124\n",
            "Epoch 277/1000: L(Train): 1.2829209566116333; L(Test): 1.2336405515670776\n",
            "Epoch 278/1000: L(Train): 1.2807990312576294; L(Test): 1.2323925495147705\n",
            "Epoch 279/1000: L(Train): 1.2943533658981323; L(Test): 1.2312473058700562\n",
            "Epoch 280/1000: L(Train): 1.255784511566162; L(Test): 1.2306901216506958\n",
            "Epoch 281/1000: L(Train): 1.2809679508209229; L(Test): 1.2304695844650269\n",
            "Epoch 282/1000: L(Train): 1.2706890106201172; L(Test): 1.2308764457702637\n",
            "Epoch 283/1000: L(Train): 1.2929452657699585; L(Test): 1.230377435684204\n",
            "Epoch 284/1000: L(Train): 1.269789695739746; L(Test): 1.2272109985351562\n",
            "Epoch 285/1000: L(Train): 1.240785837173462; L(Test): 1.2277913093566895\n",
            "Epoch 286/1000: L(Train): 1.2306660413742065; L(Test): 1.2293782234191895\n",
            "Epoch 287/1000: L(Train): 1.2737330198287964; L(Test): 1.2263023853302002\n",
            "Epoch 288/1000: L(Train): 1.2519562244415283; L(Test): 1.2284539937973022\n",
            "Epoch 289/1000: L(Train): 1.2539623975753784; L(Test): 1.226457953453064\n",
            "Epoch 290/1000: L(Train): 1.2730937004089355; L(Test): 1.224398136138916\n",
            "Epoch 291/1000: L(Train): 1.2560864686965942; L(Test): 1.2230956554412842\n",
            "Epoch 292/1000: L(Train): 1.252378225326538; L(Test): 1.2210896015167236\n",
            "Epoch 293/1000: L(Train): 1.2685012817382812; L(Test): 1.2213406562805176\n",
            "Epoch 294/1000: L(Train): 1.247752070426941; L(Test): 1.219163417816162\n",
            "Epoch 295/1000: L(Train): 1.267926812171936; L(Test): 1.221227765083313\n",
            "Epoch 296/1000: L(Train): 1.2622973918914795; L(Test): 1.2220749855041504\n",
            "Epoch 297/1000: L(Train): 1.2569128274917603; L(Test): 1.2193154096603394\n",
            "Epoch 298/1000: L(Train): 1.247001051902771; L(Test): 1.2207825183868408\n",
            "Epoch 299/1000: L(Train): 1.232564091682434; L(Test): 1.2182806730270386\n",
            "Epoch 300/1000: L(Train): 1.2596993446350098; L(Test): 1.2168515920639038\n",
            "Epoch 301/1000: L(Train): 1.2528499364852905; L(Test): 1.2137523889541626\n",
            "Epoch 302/1000: L(Train): 1.2289214134216309; L(Test): 1.2157032489776611\n",
            "Epoch 303/1000: L(Train): 1.2493220567703247; L(Test): 1.2127890586853027\n",
            "Epoch 304/1000: L(Train): 1.2570314407348633; L(Test): 1.2175956964492798\n",
            "Epoch 305/1000: L(Train): 1.2626992464065552; L(Test): 1.2151583433151245\n",
            "Epoch 306/1000: L(Train): 1.2654337882995605; L(Test): 1.2171530723571777\n",
            "Epoch 307/1000: L(Train): 1.270440936088562; L(Test): 1.2173188924789429\n",
            "Epoch 308/1000: L(Train): 1.2417598962783813; L(Test): 1.2194201946258545\n",
            "Epoch 309/1000: L(Train): 1.2903509140014648; L(Test): 1.2143274545669556\n",
            "Epoch 310/1000: L(Train): 1.2452349662780762; L(Test): 1.2132858037948608\n",
            "Epoch 311/1000: L(Train): 1.2537405490875244; L(Test): 1.2145980596542358\n",
            "Epoch 312/1000: L(Train): 1.2542403936386108; L(Test): 1.2121765613555908\n",
            "Epoch 313/1000: L(Train): 1.2524200677871704; L(Test): 1.2165403366088867\n",
            "Epoch 314/1000: L(Train): 1.2411928176879883; L(Test): 1.2161900997161865\n",
            "Epoch 315/1000: L(Train): 1.2460880279541016; L(Test): 1.2119357585906982\n",
            "Epoch 316/1000: L(Train): 1.234246850013733; L(Test): 1.2102162837982178\n",
            "Epoch 317/1000: L(Train): 1.2579454183578491; L(Test): 1.2111499309539795\n",
            "Epoch 318/1000: L(Train): 1.260341763496399; L(Test): 1.2063119411468506\n",
            "Epoch 319/1000: L(Train): 1.2689930200576782; L(Test): 1.2075755596160889\n",
            "Epoch 320/1000: L(Train): 1.25887131690979; L(Test): 1.2092186212539673\n",
            "Epoch 321/1000: L(Train): 1.2266165018081665; L(Test): 1.2052738666534424\n",
            "Epoch 322/1000: L(Train): 1.2285234928131104; L(Test): 1.2034555673599243\n",
            "Epoch 323/1000: L(Train): 1.2418931722640991; L(Test): 1.2048182487487793\n",
            "Epoch 324/1000: L(Train): 1.253452181816101; L(Test): 1.2021373510360718\n",
            "Epoch 325/1000: L(Train): 1.2382270097732544; L(Test): 1.2022230625152588\n",
            "Epoch 326/1000: L(Train): 1.2292588949203491; L(Test): 1.2033774852752686\n",
            "Epoch 327/1000: L(Train): 1.2413856983184814; L(Test): 1.1988661289215088\n",
            "Epoch 328/1000: L(Train): 1.225075364112854; L(Test): 1.1998311281204224\n",
            "Epoch 329/1000: L(Train): 1.256493091583252; L(Test): 1.2006638050079346\n",
            "Epoch 330/1000: L(Train): 1.245193600654602; L(Test): 1.209885597229004\n",
            "Epoch 331/1000: L(Train): 1.2617982625961304; L(Test): 1.1995980739593506\n",
            "Epoch 332/1000: L(Train): 1.2928497791290283; L(Test): 1.2038887739181519\n",
            "Epoch 333/1000: L(Train): 1.2445048093795776; L(Test): 1.1981055736541748\n",
            "Epoch 334/1000: L(Train): 1.2596921920776367; L(Test): 1.2004733085632324\n",
            "Epoch 335/1000: L(Train): 1.2574962377548218; L(Test): 1.1980445384979248\n",
            "Epoch 336/1000: L(Train): 1.2263013124465942; L(Test): 1.1961122751235962\n",
            "Epoch 337/1000: L(Train): 1.2110416889190674; L(Test): 1.1977424621582031\n",
            "Epoch 338/1000: L(Train): 1.2499016523361206; L(Test): 1.1941630840301514\n",
            "Epoch 339/1000: L(Train): 1.2144395112991333; L(Test): 1.1945219039916992\n",
            "Epoch 340/1000: L(Train): 1.219767689704895; L(Test): 1.196555733680725\n",
            "Epoch 341/1000: L(Train): 1.2331023216247559; L(Test): 1.197942852973938\n",
            "Epoch 342/1000: L(Train): 1.2330564260482788; L(Test): 1.1938172578811646\n",
            "Epoch 343/1000: L(Train): 1.2341258525848389; L(Test): 1.1930276155471802\n",
            "Epoch 344/1000: L(Train): 1.2722980976104736; L(Test): 1.1935471296310425\n",
            "Epoch 345/1000: L(Train): 1.2136809825897217; L(Test): 1.1968631744384766\n",
            "Epoch 346/1000: L(Train): 1.238731026649475; L(Test): 1.1980081796646118\n",
            "Epoch 347/1000: L(Train): 1.2635400295257568; L(Test): 1.1916043758392334\n",
            "Epoch 348/1000: L(Train): 1.231680989265442; L(Test): 1.1883018016815186\n",
            "Epoch 349/1000: L(Train): 1.2082030773162842; L(Test): 1.1906462907791138\n",
            "Epoch 350/1000: L(Train): 1.2345733642578125; L(Test): 1.190463662147522\n",
            "Epoch 351/1000: L(Train): 1.244584321975708; L(Test): 1.1906275749206543\n",
            "Epoch 352/1000: L(Train): 1.265721321105957; L(Test): 1.1882058382034302\n",
            "Epoch 353/1000: L(Train): 1.236229419708252; L(Test): 1.1859118938446045\n",
            "Epoch 354/1000: L(Train): 1.228432536125183; L(Test): 1.1871188879013062\n",
            "Epoch 355/1000: L(Train): 1.231060266494751; L(Test): 1.1854888200759888\n",
            "Epoch 356/1000: L(Train): 1.2145824432373047; L(Test): 1.1843316555023193\n",
            "Epoch 357/1000: L(Train): 1.2166333198547363; L(Test): 1.1826783418655396\n",
            "Epoch 358/1000: L(Train): 1.2348021268844604; L(Test): 1.1836845874786377\n",
            "Epoch 359/1000: L(Train): 1.2476248741149902; L(Test): 1.1830906867980957\n",
            "Epoch 360/1000: L(Train): 1.2376106977462769; L(Test): 1.1829582452774048\n",
            "Epoch 361/1000: L(Train): 1.2172696590423584; L(Test): 1.1855169534683228\n",
            "Epoch 362/1000: L(Train): 1.2367298603057861; L(Test): 1.181596040725708\n",
            "Epoch 363/1000: L(Train): 1.2408442497253418; L(Test): 1.1826726198196411\n",
            "Epoch 364/1000: L(Train): 1.2093545198440552; L(Test): 1.1885521411895752\n",
            "Epoch 365/1000: L(Train): 1.2381128072738647; L(Test): 1.1859890222549438\n",
            "Epoch 366/1000: L(Train): 1.2193113565444946; L(Test): 1.1868590116500854\n",
            "Epoch 367/1000: L(Train): 1.2445517778396606; L(Test): 1.1806495189666748\n",
            "Epoch 368/1000: L(Train): 1.2185654640197754; L(Test): 1.1822388172149658\n",
            "Epoch 369/1000: L(Train): 1.2425670623779297; L(Test): 1.1867525577545166\n",
            "Epoch 370/1000: L(Train): 1.2313555479049683; L(Test): 1.1820863485336304\n",
            "Epoch 371/1000: L(Train): 1.2423573732376099; L(Test): 1.1802314519882202\n",
            "Epoch 372/1000: L(Train): 1.2234809398651123; L(Test): 1.1791558265686035\n",
            "Epoch 373/1000: L(Train): 1.2077977657318115; L(Test): 1.1800627708435059\n",
            "Epoch 374/1000: L(Train): 1.2334705591201782; L(Test): 1.1887837648391724\n",
            "Epoch 375/1000: L(Train): 1.2166965007781982; L(Test): 1.1799122095108032\n",
            "Epoch 376/1000: L(Train): 1.2647799253463745; L(Test): 1.1763008832931519\n",
            "Epoch 377/1000: L(Train): 1.209252953529358; L(Test): 1.1794488430023193\n",
            "Epoch 378/1000: L(Train): 1.223556399345398; L(Test): 1.174855351448059\n",
            "Epoch 379/1000: L(Train): 1.2117429971694946; L(Test): 1.1791496276855469\n",
            "Epoch 380/1000: L(Train): 1.2348120212554932; L(Test): 1.1802133321762085\n",
            "Epoch 381/1000: L(Train): 1.2258473634719849; L(Test): 1.1744171380996704\n",
            "Epoch 382/1000: L(Train): 1.2383408546447754; L(Test): 1.171800971031189\n",
            "Epoch 383/1000: L(Train): 1.2663253545761108; L(Test): 1.1725329160690308\n",
            "Epoch 384/1000: L(Train): 1.211548089981079; L(Test): 1.172041416168213\n",
            "Epoch 385/1000: L(Train): 1.2140856981277466; L(Test): 1.1723580360412598\n",
            "Epoch 386/1000: L(Train): 1.1961549520492554; L(Test): 1.1714131832122803\n",
            "Epoch 387/1000: L(Train): 1.2304925918579102; L(Test): 1.1728262901306152\n",
            "Epoch 388/1000: L(Train): 1.2549821138381958; L(Test): 1.1711175441741943\n",
            "Epoch 389/1000: L(Train): 1.2125693559646606; L(Test): 1.1697824001312256\n",
            "Epoch 390/1000: L(Train): 1.2028303146362305; L(Test): 1.17030930519104\n",
            "Epoch 391/1000: L(Train): 1.2022324800491333; L(Test): 1.1696518659591675\n",
            "Epoch 392/1000: L(Train): 1.214028239250183; L(Test): 1.1718100309371948\n",
            "Epoch 393/1000: L(Train): 1.2372530698776245; L(Test): 1.1703869104385376\n",
            "Epoch 394/1000: L(Train): 1.2323439121246338; L(Test): 1.1680364608764648\n",
            "Epoch 395/1000: L(Train): 1.2426788806915283; L(Test): 1.1669622659683228\n",
            "Epoch 396/1000: L(Train): 1.1910384893417358; L(Test): 1.167436957359314\n",
            "Epoch 397/1000: L(Train): 1.2461919784545898; L(Test): 1.1674635410308838\n",
            "Epoch 398/1000: L(Train): 1.1869077682495117; L(Test): 1.172499656677246\n",
            "Epoch 399/1000: L(Train): 1.221497654914856; L(Test): 1.1652110815048218\n",
            "Epoch 400/1000: L(Train): 1.2028695344924927; L(Test): 1.1699819564819336\n",
            "Epoch 401/1000: L(Train): 1.2114665508270264; L(Test): 1.1684283018112183\n",
            "Epoch 402/1000: L(Train): 1.235398769378662; L(Test): 1.173032283782959\n",
            "Epoch 403/1000: L(Train): 1.2337980270385742; L(Test): 1.1722484827041626\n",
            "Epoch 404/1000: L(Train): 1.2368050813674927; L(Test): 1.1724231243133545\n",
            "Epoch 405/1000: L(Train): 1.2143752574920654; L(Test): 1.1712125539779663\n",
            "Epoch 406/1000: L(Train): 1.199767827987671; L(Test): 1.169002890586853\n",
            "Epoch 407/1000: L(Train): 1.2084589004516602; L(Test): 1.171190619468689\n",
            "Epoch 408/1000: L(Train): 1.2602230310440063; L(Test): 1.166550636291504\n",
            "Epoch 409/1000: L(Train): 1.2033811807632446; L(Test): 1.1683458089828491\n",
            "Epoch 410/1000: L(Train): 1.2192221879959106; L(Test): 1.1687369346618652\n",
            "Epoch 411/1000: L(Train): 1.218811273574829; L(Test): 1.167843222618103\n",
            "Epoch 412/1000: L(Train): 1.2306939363479614; L(Test): 1.1629890203475952\n",
            "Epoch 413/1000: L(Train): 1.2291144132614136; L(Test): 1.160580039024353\n",
            "Epoch 414/1000: L(Train): 1.194756269454956; L(Test): 1.1601632833480835\n",
            "Epoch 415/1000: L(Train): 1.2015650272369385; L(Test): 1.1587830781936646\n",
            "Epoch 416/1000: L(Train): 1.2037700414657593; L(Test): 1.1604771614074707\n",
            "Epoch 417/1000: L(Train): 1.1951664686203003; L(Test): 1.1597133874893188\n",
            "Epoch 418/1000: L(Train): 1.2107625007629395; L(Test): 1.160739541053772\n",
            "Epoch 419/1000: L(Train): 1.2089264392852783; L(Test): 1.1580790281295776\n",
            "Epoch 420/1000: L(Train): 1.188804030418396; L(Test): 1.155466079711914\n",
            "Epoch 421/1000: L(Train): 1.2278136014938354; L(Test): 1.1550815105438232\n",
            "Epoch 422/1000: L(Train): 1.2229647636413574; L(Test): 1.158483862876892\n",
            "Epoch 423/1000: L(Train): 1.1956332921981812; L(Test): 1.157012701034546\n",
            "Epoch 424/1000: L(Train): 1.2220661640167236; L(Test): 1.1543079614639282\n",
            "Epoch 425/1000: L(Train): 1.1987725496292114; L(Test): 1.153210163116455\n",
            "Epoch 426/1000: L(Train): 1.2261669635772705; L(Test): 1.1539332866668701\n",
            "Epoch 427/1000: L(Train): 1.2120784521102905; L(Test): 1.1576181650161743\n",
            "Epoch 428/1000: L(Train): 1.1700495481491089; L(Test): 1.1566827297210693\n",
            "Epoch 429/1000: L(Train): 1.1933740377426147; L(Test): 1.1540248394012451\n",
            "Epoch 430/1000: L(Train): 1.1873127222061157; L(Test): 1.1550084352493286\n",
            "Epoch 431/1000: L(Train): 1.214622974395752; L(Test): 1.1523231267929077\n",
            "Epoch 432/1000: L(Train): 1.2303797006607056; L(Test): 1.158575415611267\n",
            "Epoch 433/1000: L(Train): 1.194800853729248; L(Test): 1.1563332080841064\n",
            "Epoch 434/1000: L(Train): 1.2147964239120483; L(Test): 1.1538679599761963\n",
            "Epoch 435/1000: L(Train): 1.193117380142212; L(Test): 1.1522842645645142\n",
            "Epoch 436/1000: L(Train): 1.182802677154541; L(Test): 1.1506829261779785\n",
            "Epoch 437/1000: L(Train): 1.2308018207550049; L(Test): 1.1498298645019531\n",
            "Epoch 438/1000: L(Train): 1.1762398481369019; L(Test): 1.153110384941101\n",
            "Epoch 439/1000: L(Train): 1.189327597618103; L(Test): 1.1526057720184326\n",
            "Epoch 440/1000: L(Train): 1.1966142654418945; L(Test): 1.150883436203003\n",
            "Epoch 441/1000: L(Train): 1.181751012802124; L(Test): 1.1521977186203003\n",
            "Epoch 442/1000: L(Train): 1.1756519079208374; L(Test): 1.1491029262542725\n",
            "Epoch 443/1000: L(Train): 1.1586344242095947; L(Test): 1.1554745435714722\n",
            "Epoch 444/1000: L(Train): 1.2108961343765259; L(Test): 1.1487128734588623\n",
            "Epoch 445/1000: L(Train): 1.2304081916809082; L(Test): 1.147295594215393\n",
            "Epoch 446/1000: L(Train): 1.2077512741088867; L(Test): 1.1485962867736816\n",
            "Epoch 447/1000: L(Train): 1.214195728302002; L(Test): 1.1514222621917725\n",
            "Epoch 448/1000: L(Train): 1.1963622570037842; L(Test): 1.1538735628128052\n",
            "Epoch 449/1000: L(Train): 1.182400107383728; L(Test): 1.1482350826263428\n",
            "Epoch 450/1000: L(Train): 1.1960110664367676; L(Test): 1.1509448289871216\n",
            "Epoch 451/1000: L(Train): 1.193350076675415; L(Test): 1.149769902229309\n",
            "Epoch 452/1000: L(Train): 1.216795802116394; L(Test): 1.156823992729187\n",
            "Epoch 453/1000: L(Train): 1.18992280960083; L(Test): 1.151792287826538\n",
            "Epoch 454/1000: L(Train): 1.1990032196044922; L(Test): 1.1499640941619873\n",
            "Epoch 455/1000: L(Train): 1.206163763999939; L(Test): 1.145588755607605\n",
            "Epoch 456/1000: L(Train): 1.192399024963379; L(Test): 1.1462135314941406\n",
            "Epoch 457/1000: L(Train): 1.2016313076019287; L(Test): 1.148247480392456\n",
            "Epoch 458/1000: L(Train): 1.2312318086624146; L(Test): 1.148445963859558\n",
            "Epoch 459/1000: L(Train): 1.1803841590881348; L(Test): 1.1477158069610596\n",
            "Epoch 460/1000: L(Train): 1.2177367210388184; L(Test): 1.1509164571762085\n",
            "Epoch 461/1000: L(Train): 1.2097078561782837; L(Test): 1.1438614130020142\n",
            "Epoch 462/1000: L(Train): 1.199202299118042; L(Test): 1.1492689847946167\n",
            "Epoch 463/1000: L(Train): 1.1878186464309692; L(Test): 1.145961880683899\n",
            "Epoch 464/1000: L(Train): 1.2054619789123535; L(Test): 1.1439907550811768\n",
            "Epoch 465/1000: L(Train): 1.2005661725997925; L(Test): 1.145032286643982\n",
            "Epoch 466/1000: L(Train): 1.2159733772277832; L(Test): 1.1454275846481323\n",
            "Epoch 467/1000: L(Train): 1.2138276100158691; L(Test): 1.149760127067566\n",
            "Epoch 468/1000: L(Train): 1.203161358833313; L(Test): 1.1467572450637817\n",
            "Epoch 469/1000: L(Train): 1.1816956996917725; L(Test): 1.145820140838623\n",
            "Epoch 470/1000: L(Train): 1.1978033781051636; L(Test): 1.1482503414154053\n",
            "Epoch 471/1000: L(Train): 1.1906174421310425; L(Test): 1.141991138458252\n",
            "Epoch 472/1000: L(Train): 1.1735690832138062; L(Test): 1.1473405361175537\n",
            "Epoch 473/1000: L(Train): 1.2045732736587524; L(Test): 1.1508581638336182\n",
            "Epoch 474/1000: L(Train): 1.2013561725616455; L(Test): 1.1473382711410522\n",
            "Epoch 475/1000: L(Train): 1.1974658966064453; L(Test): 1.1449170112609863\n",
            "Epoch 476/1000: L(Train): 1.2207002639770508; L(Test): 1.1488432884216309\n",
            "Epoch 477/1000: L(Train): 1.2132893800735474; L(Test): 1.1441200971603394\n",
            "Epoch 478/1000: L(Train): 1.1588869094848633; L(Test): 1.1460410356521606\n",
            "Epoch 479/1000: L(Train): 1.2031118869781494; L(Test): 1.1469966173171997\n",
            "Epoch 480/1000: L(Train): 1.2000845670700073; L(Test): 1.147745966911316\n",
            "Epoch 481/1000: L(Train): 1.2172082662582397; L(Test): 1.142662525177002\n",
            "Epoch 482/1000: L(Train): 1.2061512470245361; L(Test): 1.1446396112442017\n",
            "Epoch 483/1000: L(Train): 1.1855206489562988; L(Test): 1.1465736627578735\n",
            "Epoch 484/1000: L(Train): 1.219557523727417; L(Test): 1.146887183189392\n",
            "Epoch 485/1000: L(Train): 1.1855006217956543; L(Test): 1.1480225324630737\n",
            "Epoch 486/1000: L(Train): 1.2036768198013306; L(Test): 1.1480865478515625\n",
            "Epoch 487/1000: L(Train): 1.1732988357543945; L(Test): 1.146992802619934\n",
            "Epoch 488/1000: L(Train): 1.2102173566818237; L(Test): 1.1406993865966797\n",
            "Epoch 489/1000: L(Train): 1.2141554355621338; L(Test): 1.1385772228240967\n",
            "Epoch 490/1000: L(Train): 1.1958595514297485; L(Test): 1.1419413089752197\n",
            "Epoch 491/1000: L(Train): 1.2002698183059692; L(Test): 1.1484005451202393\n",
            "Epoch 492/1000: L(Train): 1.1937510967254639; L(Test): 1.136040449142456\n",
            "Epoch 493/1000: L(Train): 1.2148138284683228; L(Test): 1.1423248052597046\n",
            "Epoch 494/1000: L(Train): 1.1749062538146973; L(Test): 1.146867275238037\n",
            "Epoch 495/1000: L(Train): 1.1894402503967285; L(Test): 1.143779993057251\n",
            "Epoch 496/1000: L(Train): 1.1690946817398071; L(Test): 1.1460943222045898\n",
            "Epoch 497/1000: L(Train): 1.1783720254898071; L(Test): 1.1450995206832886\n",
            "Epoch 498/1000: L(Train): 1.2040404081344604; L(Test): 1.1416658163070679\n",
            "Epoch 499/1000: L(Train): 1.1874850988388062; L(Test): 1.1418631076812744\n",
            "Epoch 500/1000: L(Train): 1.2166634798049927; L(Test): 1.1378962993621826\n",
            "Epoch 501/1000: L(Train): 1.189811110496521; L(Test): 1.1393357515335083\n",
            "Epoch 502/1000: L(Train): 1.2027039527893066; L(Test): 1.138930082321167\n",
            "Epoch 503/1000: L(Train): 1.1964044570922852; L(Test): 1.1391494274139404\n",
            "Epoch 504/1000: L(Train): 1.1856929063796997; L(Test): 1.1419554948806763\n",
            "Epoch 505/1000: L(Train): 1.2074211835861206; L(Test): 1.1387805938720703\n",
            "Epoch 506/1000: L(Train): 1.1979879140853882; L(Test): 1.1353346109390259\n",
            "Epoch 507/1000: L(Train): 1.1814055442810059; L(Test): 1.1349220275878906\n",
            "Epoch 508/1000: L(Train): 1.2128407955169678; L(Test): 1.1362278461456299\n",
            "Epoch 509/1000: L(Train): 1.2137858867645264; L(Test): 1.1372538805007935\n",
            "Epoch 510/1000: L(Train): 1.1858783960342407; L(Test): 1.1349388360977173\n",
            "Epoch 511/1000: L(Train): 1.1586555242538452; L(Test): 1.1352055072784424\n",
            "Epoch 512/1000: L(Train): 1.2170934677124023; L(Test): 1.1341270208358765\n",
            "Epoch 513/1000: L(Train): 1.2083619832992554; L(Test): 1.1373659372329712\n",
            "Epoch 514/1000: L(Train): 1.205718755722046; L(Test): 1.1382092237472534\n",
            "Epoch 515/1000: L(Train): 1.1645931005477905; L(Test): 1.132327914237976\n",
            "Epoch 516/1000: L(Train): 1.1774146556854248; L(Test): 1.1394292116165161\n",
            "Epoch 517/1000: L(Train): 1.2073673009872437; L(Test): 1.1303938627243042\n",
            "Epoch 518/1000: L(Train): 1.1880115270614624; L(Test): 1.1350101232528687\n",
            "Epoch 519/1000: L(Train): 1.177087426185608; L(Test): 1.1346157789230347\n",
            "Epoch 520/1000: L(Train): 1.184686541557312; L(Test): 1.1314959526062012\n",
            "Epoch 521/1000: L(Train): 1.215331792831421; L(Test): 1.132151484489441\n",
            "Epoch 522/1000: L(Train): 1.2267619371414185; L(Test): 1.130151629447937\n",
            "Epoch 523/1000: L(Train): 1.1935946941375732; L(Test): 1.131253719329834\n",
            "Epoch 524/1000: L(Train): 1.1976724863052368; L(Test): 1.129995346069336\n",
            "Epoch 525/1000: L(Train): 1.1729423999786377; L(Test): 1.125307559967041\n",
            "Epoch 526/1000: L(Train): 1.1812182664871216; L(Test): 1.1280723810195923\n",
            "Epoch 527/1000: L(Train): 1.1945958137512207; L(Test): 1.1286001205444336\n",
            "Epoch 528/1000: L(Train): 1.1936399936676025; L(Test): 1.1289658546447754\n",
            "Epoch 529/1000: L(Train): 1.1778769493103027; L(Test): 1.1278512477874756\n",
            "Epoch 530/1000: L(Train): 1.179455041885376; L(Test): 1.1306768655776978\n",
            "Epoch 531/1000: L(Train): 1.1919574737548828; L(Test): 1.1331405639648438\n",
            "Epoch 532/1000: L(Train): 1.1688448190689087; L(Test): 1.1336109638214111\n",
            "Epoch 533/1000: L(Train): 1.193346381187439; L(Test): 1.1299041509628296\n",
            "Epoch 534/1000: L(Train): 1.1941814422607422; L(Test): 1.1310404539108276\n",
            "Epoch 535/1000: L(Train): 1.1896089315414429; L(Test): 1.1291593313217163\n",
            "Epoch 536/1000: L(Train): 1.1644749641418457; L(Test): 1.128501296043396\n",
            "Epoch 537/1000: L(Train): 1.164660930633545; L(Test): 1.1298582553863525\n",
            "Epoch 538/1000: L(Train): 1.185584545135498; L(Test): 1.1310951709747314\n",
            "Epoch 539/1000: L(Train): 1.1821174621582031; L(Test): 1.1309301853179932\n",
            "Epoch 540/1000: L(Train): 1.2015513181686401; L(Test): 1.1312586069107056\n",
            "Epoch 541/1000: L(Train): 1.1782082319259644; L(Test): 1.1300636529922485\n",
            "Epoch 542/1000: L(Train): 1.2020703554153442; L(Test): 1.1285024881362915\n",
            "Epoch 543/1000: L(Train): 1.2112596035003662; L(Test): 1.1276254653930664\n",
            "Epoch 544/1000: L(Train): 1.1849244832992554; L(Test): 1.1339534521102905\n",
            "Epoch 545/1000: L(Train): 1.1922667026519775; L(Test): 1.12751042842865\n",
            "Epoch 546/1000: L(Train): 1.170472502708435; L(Test): 1.14177405834198\n",
            "Epoch 547/1000: L(Train): 1.1955887079238892; L(Test): 1.1347227096557617\n",
            "Epoch 548/1000: L(Train): 1.177592158317566; L(Test): 1.1329996585845947\n",
            "Epoch 549/1000: L(Train): 1.2061673402786255; L(Test): 1.1340646743774414\n",
            "Epoch 550/1000: L(Train): 1.1886725425720215; L(Test): 1.1372820138931274\n",
            "Epoch 551/1000: L(Train): 1.2101621627807617; L(Test): 1.127564549446106\n",
            "Epoch 552/1000: L(Train): 1.2037653923034668; L(Test): 1.136043667793274\n",
            "Epoch 553/1000: L(Train): 1.2038743495941162; L(Test): 1.1325749158859253\n",
            "Epoch 554/1000: L(Train): 1.1865105628967285; L(Test): 1.1292939186096191\n",
            "Epoch 555/1000: L(Train): 1.221606969833374; L(Test): 1.1266943216323853\n",
            "Epoch 556/1000: L(Train): 1.182076096534729; L(Test): 1.1323637962341309\n",
            "Epoch 557/1000: L(Train): 1.1689586639404297; L(Test): 1.134473443031311\n",
            "Epoch 558/1000: L(Train): 1.185608983039856; L(Test): 1.12993323802948\n",
            "Epoch 559/1000: L(Train): 1.1716207265853882; L(Test): 1.1339958906173706\n",
            "Epoch 560/1000: L(Train): 1.203411340713501; L(Test): 1.1287033557891846\n",
            "Epoch 561/1000: L(Train): 1.214097261428833; L(Test): 1.135603666305542\n",
            "Epoch 562/1000: L(Train): 1.1837992668151855; L(Test): 1.142886757850647\n",
            "Epoch 563/1000: L(Train): 1.1850666999816895; L(Test): 1.136976718902588\n",
            "Epoch 564/1000: L(Train): 1.190896987915039; L(Test): 1.1315476894378662\n",
            "Epoch 565/1000: L(Train): 1.208272099494934; L(Test): 1.130350112915039\n",
            "Epoch 566/1000: L(Train): 1.1986311674118042; L(Test): 1.128584623336792\n",
            "Epoch 567/1000: L(Train): 1.2049065828323364; L(Test): 1.1299214363098145\n",
            "Epoch 568/1000: L(Train): 1.1885324716567993; L(Test): 1.1339162588119507\n",
            "Epoch 569/1000: L(Train): 1.1729819774627686; L(Test): 1.123254656791687\n",
            "Epoch 570/1000: L(Train): 1.1774388551712036; L(Test): 1.1267623901367188\n",
            "Epoch 571/1000: L(Train): 1.2036718130111694; L(Test): 1.1253820657730103\n",
            "Epoch 572/1000: L(Train): 1.146547794342041; L(Test): 1.1276592016220093\n",
            "Epoch 573/1000: L(Train): 1.2104865312576294; L(Test): 1.1283990144729614\n",
            "Epoch 574/1000: L(Train): 1.1711113452911377; L(Test): 1.1254687309265137\n",
            "Epoch 575/1000: L(Train): 1.1999951601028442; L(Test): 1.122599720954895\n",
            "Epoch 576/1000: L(Train): 1.184315800666809; L(Test): 1.1201567649841309\n",
            "Epoch 577/1000: L(Train): 1.1645885705947876; L(Test): 1.1213926076889038\n",
            "Epoch 578/1000: L(Train): 1.2041926383972168; L(Test): 1.1247265338897705\n",
            "Epoch 579/1000: L(Train): 1.1890538930892944; L(Test): 1.1297718286514282\n",
            "Epoch 580/1000: L(Train): 1.1988050937652588; L(Test): 1.125259280204773\n",
            "Epoch 581/1000: L(Train): 1.1815048456192017; L(Test): 1.1254501342773438\n",
            "Epoch 582/1000: L(Train): 1.1998909711837769; L(Test): 1.1236733198165894\n",
            "Epoch 583/1000: L(Train): 1.1570563316345215; L(Test): 1.1215720176696777\n",
            "Epoch 584/1000: L(Train): 1.1723453998565674; L(Test): 1.1227874755859375\n",
            "Epoch 585/1000: L(Train): 1.2055710554122925; L(Test): 1.1195688247680664\n",
            "Epoch 586/1000: L(Train): 1.1709028482437134; L(Test): 1.1291067600250244\n",
            "Epoch 587/1000: L(Train): 1.1911855936050415; L(Test): 1.1218845844268799\n",
            "Epoch 588/1000: L(Train): 1.1904489994049072; L(Test): 1.123586893081665\n",
            "Epoch 589/1000: L(Train): 1.165555477142334; L(Test): 1.121700406074524\n",
            "Epoch 590/1000: L(Train): 1.1764295101165771; L(Test): 1.1173866987228394\n",
            "Epoch 591/1000: L(Train): 1.162755012512207; L(Test): 1.119454026222229\n",
            "Epoch 592/1000: L(Train): 1.1784471273422241; L(Test): 1.1170414686203003\n",
            "Epoch 593/1000: L(Train): 1.1994948387145996; L(Test): 1.1182142496109009\n",
            "Epoch 594/1000: L(Train): 1.156209111213684; L(Test): 1.1176233291625977\n",
            "Epoch 595/1000: L(Train): 1.1768642663955688; L(Test): 1.117408037185669\n",
            "Epoch 596/1000: L(Train): 1.1558946371078491; L(Test): 1.114578366279602\n",
            "Epoch 597/1000: L(Train): 1.1714507341384888; L(Test): 1.115417718887329\n",
            "Epoch 598/1000: L(Train): 1.1964207887649536; L(Test): 1.116613507270813\n",
            "Epoch 599/1000: L(Train): 1.1866536140441895; L(Test): 1.1236332654953003\n",
            "Epoch 600/1000: L(Train): 1.1464717388153076; L(Test): 1.122897982597351\n",
            "Epoch 601/1000: L(Train): 1.1828045845031738; L(Test): 1.1189759969711304\n",
            "Epoch 602/1000: L(Train): 1.1911648511886597; L(Test): 1.1178550720214844\n",
            "Epoch 603/1000: L(Train): 1.1589241027832031; L(Test): 1.1171263456344604\n",
            "Epoch 604/1000: L(Train): 1.1805431842803955; L(Test): 1.1154446601867676\n",
            "Epoch 605/1000: L(Train): 1.1758860349655151; L(Test): 1.114524245262146\n",
            "Epoch 606/1000: L(Train): 1.1437549591064453; L(Test): 1.1176319122314453\n",
            "Epoch 607/1000: L(Train): 1.1722826957702637; L(Test): 1.114013671875\n",
            "Epoch 608/1000: L(Train): 1.1779749393463135; L(Test): 1.113661289215088\n",
            "Epoch 609/1000: L(Train): 1.1707539558410645; L(Test): 1.1124942302703857\n",
            "Epoch 610/1000: L(Train): 1.1718757152557373; L(Test): 1.1156425476074219\n",
            "Epoch 611/1000: L(Train): 1.170366883277893; L(Test): 1.1182968616485596\n",
            "Epoch 612/1000: L(Train): 1.1715989112854004; L(Test): 1.1164847612380981\n",
            "Epoch 613/1000: L(Train): 1.195428729057312; L(Test): 1.115413784980774\n",
            "Epoch 614/1000: L(Train): 1.1711379289627075; L(Test): 1.1172682046890259\n",
            "Epoch 615/1000: L(Train): 1.1931626796722412; L(Test): 1.1244736909866333\n",
            "Epoch 616/1000: L(Train): 1.1849008798599243; L(Test): 1.1225138902664185\n",
            "Epoch 617/1000: L(Train): 1.1805977821350098; L(Test): 1.125700831413269\n",
            "Epoch 618/1000: L(Train): 1.1951608657836914; L(Test): 1.1285176277160645\n",
            "Epoch 619/1000: L(Train): 1.2057137489318848; L(Test): 1.1278542280197144\n",
            "Epoch 620/1000: L(Train): 1.1864190101623535; L(Test): 1.1206403970718384\n",
            "Epoch 621/1000: L(Train): 1.1604373455047607; L(Test): 1.1404341459274292\n",
            "Epoch 622/1000: L(Train): 1.1679039001464844; L(Test): 1.138993501663208\n",
            "Epoch 623/1000: L(Train): 1.1721004247665405; L(Test): 1.1189231872558594\n",
            "Epoch 624/1000: L(Train): 1.183000087738037; L(Test): 1.1473979949951172\n",
            "Epoch 625/1000: L(Train): 1.1902326345443726; L(Test): 1.1533628702163696\n",
            "Epoch 626/1000: L(Train): 1.213820457458496; L(Test): 1.136106252670288\n",
            "Epoch 627/1000: L(Train): 1.170940637588501; L(Test): 1.149984359741211\n",
            "Epoch 628/1000: L(Train): 1.1991627216339111; L(Test): 1.1620090007781982\n",
            "Epoch 629/1000: L(Train): 1.2203806638717651; L(Test): 1.1446775197982788\n",
            "Epoch 630/1000: L(Train): 1.1742528676986694; L(Test): 1.1445338726043701\n",
            "Epoch 631/1000: L(Train): 1.2144556045532227; L(Test): 1.1568349599838257\n",
            "Epoch 632/1000: L(Train): 1.1902453899383545; L(Test): 1.1568598747253418\n",
            "Epoch 633/1000: L(Train): 1.217976689338684; L(Test): 1.154558777809143\n",
            "Epoch 634/1000: L(Train): 1.1999526023864746; L(Test): 1.1500040292739868\n",
            "Epoch 635/1000: L(Train): 1.200176477432251; L(Test): 1.1467992067337036\n",
            "Epoch 636/1000: L(Train): 1.2284271717071533; L(Test): 1.1485824584960938\n",
            "Epoch 637/1000: L(Train): 1.1727595329284668; L(Test): 1.15475594997406\n",
            "Epoch 638/1000: L(Train): 1.2406036853790283; L(Test): 1.154823899269104\n",
            "Epoch 639/1000: L(Train): 1.2057231664657593; L(Test): 1.152475357055664\n",
            "Epoch 640/1000: L(Train): 1.2026487588882446; L(Test): 1.1474745273590088\n",
            "Epoch 641/1000: L(Train): 1.1960382461547852; L(Test): 1.1480153799057007\n",
            "Epoch 642/1000: L(Train): 1.2139770984649658; L(Test): 1.1465085744857788\n",
            "Epoch 643/1000: L(Train): 1.2213704586029053; L(Test): 1.140020728111267\n",
            "Epoch 644/1000: L(Train): 1.1664377450942993; L(Test): 1.1538236141204834\n",
            "Epoch 645/1000: L(Train): 1.1987191438674927; L(Test): 1.148794412612915\n",
            "Epoch 646/1000: L(Train): 1.1860278844833374; L(Test): 1.1396428346633911\n",
            "Epoch 647/1000: L(Train): 1.1946357488632202; L(Test): 1.146750569343567\n",
            "Epoch 648/1000: L(Train): 1.2060564756393433; L(Test): 1.1488126516342163\n",
            "Epoch 649/1000: L(Train): 1.2310121059417725; L(Test): 1.1435201168060303\n",
            "Epoch 650/1000: L(Train): 1.186949372291565; L(Test): 1.1455882787704468\n",
            "Epoch 651/1000: L(Train): 1.1949139833450317; L(Test): 1.1452146768569946\n",
            "Epoch 652/1000: L(Train): 1.1748360395431519; L(Test): 1.1398718357086182\n",
            "Epoch 653/1000: L(Train): 1.193153977394104; L(Test): 1.1445021629333496\n",
            "Epoch 654/1000: L(Train): 1.2022275924682617; L(Test): 1.1405540704727173\n",
            "Epoch 655/1000: L(Train): 1.1986083984375; L(Test): 1.13517427444458\n",
            "Epoch 656/1000: L(Train): 1.2101237773895264; L(Test): 1.1354594230651855\n",
            "Epoch 657/1000: L(Train): 1.171099066734314; L(Test): 1.1321616172790527\n",
            "Epoch 658/1000: L(Train): 1.2077257633209229; L(Test): 1.1347345113754272\n",
            "Epoch 659/1000: L(Train): 1.1831852197647095; L(Test): 1.132280707359314\n",
            "Epoch 660/1000: L(Train): 1.217956304550171; L(Test): 1.1320455074310303\n",
            "Epoch 661/1000: L(Train): 1.1764194965362549; L(Test): 1.1322368383407593\n",
            "Epoch 662/1000: L(Train): 1.2023712396621704; L(Test): 1.1303364038467407\n",
            "Epoch 663/1000: L(Train): 1.1908022165298462; L(Test): 1.130013108253479\n",
            "Epoch 664/1000: L(Train): 1.1843006610870361; L(Test): 1.1269633769989014\n",
            "Epoch 665/1000: L(Train): 1.1996192932128906; L(Test): 1.127206802368164\n",
            "Epoch 666/1000: L(Train): 1.178565263748169; L(Test): 1.125288963317871\n",
            "Epoch 667/1000: L(Train): 1.202142357826233; L(Test): 1.121789574623108\n",
            "Epoch 668/1000: L(Train): 1.1720483303070068; L(Test): 1.1234805583953857\n",
            "Epoch 669/1000: L(Train): 1.172956943511963; L(Test): 1.1242796182632446\n",
            "Epoch 670/1000: L(Train): 1.1698548793792725; L(Test): 1.1227326393127441\n",
            "Epoch 671/1000: L(Train): 1.157248616218567; L(Test): 1.1198093891143799\n",
            "Epoch 672/1000: L(Train): 1.1535530090332031; L(Test): 1.1195459365844727\n",
            "Epoch 673/1000: L(Train): 1.1772029399871826; L(Test): 1.1173408031463623\n",
            "Epoch 674/1000: L(Train): 1.1633758544921875; L(Test): 1.1198595762252808\n",
            "Epoch 675/1000: L(Train): 1.1792669296264648; L(Test): 1.116074562072754\n",
            "Epoch 676/1000: L(Train): 1.1787595748901367; L(Test): 1.112756609916687\n",
            "Epoch 677/1000: L(Train): 1.167151927947998; L(Test): 1.1179803609848022\n",
            "Epoch 678/1000: L(Train): 1.2187405824661255; L(Test): 1.1153396368026733\n",
            "Epoch 679/1000: L(Train): 1.1748853921890259; L(Test): 1.1158641576766968\n",
            "Epoch 680/1000: L(Train): 1.1882942914962769; L(Test): 1.1167857646942139\n",
            "Epoch 681/1000: L(Train): 1.182618260383606; L(Test): 1.111181378364563\n",
            "Epoch 682/1000: L(Train): 1.1826205253601074; L(Test): 1.11318838596344\n",
            "Epoch 683/1000: L(Train): 1.1910513639450073; L(Test): 1.1138502359390259\n",
            "Epoch 684/1000: L(Train): 1.1459521055221558; L(Test): 1.1113100051879883\n",
            "Epoch 685/1000: L(Train): 1.131524920463562; L(Test): 1.1194853782653809\n",
            "Epoch 686/1000: L(Train): 1.1802730560302734; L(Test): 1.1161202192306519\n",
            "Epoch 687/1000: L(Train): 1.1948434114456177; L(Test): 1.1120003461837769\n",
            "Epoch 688/1000: L(Train): 1.1876813173294067; L(Test): 1.1144556999206543\n",
            "Epoch 689/1000: L(Train): 1.1618146896362305; L(Test): 1.1142888069152832\n",
            "Epoch 690/1000: L(Train): 1.163442611694336; L(Test): 1.1175243854522705\n",
            "Epoch 691/1000: L(Train): 1.1696279048919678; L(Test): 1.114242434501648\n",
            "Epoch 692/1000: L(Train): 1.1876912117004395; L(Test): 1.111396074295044\n",
            "Epoch 693/1000: L(Train): 1.1484788656234741; L(Test): 1.1118789911270142\n",
            "Epoch 694/1000: L(Train): 1.1614811420440674; L(Test): 1.1162159442901611\n",
            "Epoch 695/1000: L(Train): 1.1861724853515625; L(Test): 1.111943244934082\n",
            "Epoch 696/1000: L(Train): 1.1725038290023804; L(Test): 1.1114733219146729\n",
            "Epoch 697/1000: L(Train): 1.1866602897644043; L(Test): 1.1121138334274292\n",
            "Epoch 698/1000: L(Train): 1.160075068473816; L(Test): 1.1148285865783691\n",
            "Epoch 699/1000: L(Train): 1.2044726610183716; L(Test): 1.1235697269439697\n",
            "Epoch 700/1000: L(Train): 1.1680887937545776; L(Test): 1.116864562034607\n",
            "Epoch 701/1000: L(Train): 1.2088077068328857; L(Test): 1.1099272966384888\n",
            "Epoch 702/1000: L(Train): 1.1700243949890137; L(Test): 1.1132818460464478\n",
            "Epoch 703/1000: L(Train): 1.1605355739593506; L(Test): 1.1104482412338257\n",
            "Epoch 704/1000: L(Train): 1.1832634210586548; L(Test): 1.1104395389556885\n",
            "Epoch 705/1000: L(Train): 1.1792207956314087; L(Test): 1.11123526096344\n",
            "Epoch 706/1000: L(Train): 1.1771280765533447; L(Test): 1.107744574546814\n",
            "Epoch 707/1000: L(Train): 1.154492974281311; L(Test): 1.11087965965271\n",
            "Epoch 708/1000: L(Train): 1.1804879903793335; L(Test): 1.108389973640442\n",
            "Epoch 709/1000: L(Train): 1.181995153427124; L(Test): 1.107717514038086\n",
            "Epoch 710/1000: L(Train): 1.1960082054138184; L(Test): 1.1069384813308716\n",
            "Epoch 711/1000: L(Train): 1.1570557355880737; L(Test): 1.1027475595474243\n",
            "Epoch 712/1000: L(Train): 1.1696784496307373; L(Test): 1.1045207977294922\n",
            "Epoch 713/1000: L(Train): 1.2275190353393555; L(Test): 1.103472352027893\n",
            "Epoch 714/1000: L(Train): 1.1545464992523193; L(Test): 1.1063206195831299\n",
            "Epoch 715/1000: L(Train): 1.1814899444580078; L(Test): 1.1089749336242676\n",
            "Epoch 716/1000: L(Train): 1.1684504747390747; L(Test): 1.106581449508667\n",
            "Epoch 717/1000: L(Train): 1.1828303337097168; L(Test): 1.1051561832427979\n",
            "Epoch 718/1000: L(Train): 1.178542971611023; L(Test): 1.1029852628707886\n",
            "Epoch 719/1000: L(Train): 1.1523075103759766; L(Test): 1.1006253957748413\n",
            "Epoch 720/1000: L(Train): 1.1605976819992065; L(Test): 1.1018611192703247\n",
            "Epoch 721/1000: L(Train): 1.1562395095825195; L(Test): 1.1017084121704102\n",
            "Epoch 722/1000: L(Train): 1.1643445491790771; L(Test): 1.103242039680481\n",
            "Epoch 723/1000: L(Train): 1.1646082401275635; L(Test): 1.1022053956985474\n",
            "Epoch 724/1000: L(Train): 1.2029659748077393; L(Test): 1.101088285446167\n",
            "Epoch 725/1000: L(Train): 1.1614220142364502; L(Test): 1.0984431505203247\n",
            "Epoch 726/1000: L(Train): 1.1659129858016968; L(Test): 1.098846673965454\n",
            "Epoch 727/1000: L(Train): 1.164703607559204; L(Test): 1.1011172533035278\n",
            "Epoch 728/1000: L(Train): 1.1446548700332642; L(Test): 1.099672555923462\n",
            "Epoch 729/1000: L(Train): 1.122179627418518; L(Test): 1.0995166301727295\n",
            "Epoch 730/1000: L(Train): 1.1723219156265259; L(Test): 1.1030213832855225\n",
            "Epoch 731/1000: L(Train): 1.1892999410629272; L(Test): 1.10405695438385\n",
            "Epoch 732/1000: L(Train): 1.1807467937469482; L(Test): 1.1017019748687744\n",
            "Epoch 733/1000: L(Train): 1.1620219945907593; L(Test): 1.0952937602996826\n",
            "Epoch 734/1000: L(Train): 1.155759334564209; L(Test): 1.098191261291504\n",
            "Epoch 735/1000: L(Train): 1.1619449853897095; L(Test): 1.096544623374939\n",
            "Epoch 736/1000: L(Train): 1.150485873222351; L(Test): 1.0962262153625488\n",
            "Epoch 737/1000: L(Train): 1.1713205575942993; L(Test): 1.09552001953125\n",
            "Epoch 738/1000: L(Train): 1.1657658815383911; L(Test): 1.0961683988571167\n",
            "Epoch 739/1000: L(Train): 1.1514941453933716; L(Test): 1.0960429906845093\n",
            "Epoch 740/1000: L(Train): 1.1181507110595703; L(Test): 1.0953736305236816\n",
            "Epoch 741/1000: L(Train): 1.1783860921859741; L(Test): 1.0918300151824951\n",
            "Epoch 742/1000: L(Train): 1.2028589248657227; L(Test): 1.1019611358642578\n",
            "Epoch 743/1000: L(Train): 1.1335618495941162; L(Test): 1.1020641326904297\n",
            "Epoch 744/1000: L(Train): 1.1485518217086792; L(Test): 1.0925178527832031\n",
            "Epoch 745/1000: L(Train): 1.1354838609695435; L(Test): 1.1010481119155884\n",
            "Epoch 746/1000: L(Train): 1.1781024932861328; L(Test): 1.0949710607528687\n",
            "Epoch 747/1000: L(Train): 1.12661612033844; L(Test): 1.099112868309021\n",
            "Epoch 748/1000: L(Train): 1.1465883255004883; L(Test): 1.106035828590393\n",
            "Epoch 749/1000: L(Train): 1.185239315032959; L(Test): 1.0978431701660156\n",
            "Epoch 750/1000: L(Train): 1.1850993633270264; L(Test): 1.1013870239257812\n",
            "Epoch 751/1000: L(Train): 1.1874619722366333; L(Test): 1.1054021120071411\n",
            "Epoch 752/1000: L(Train): 1.1576493978500366; L(Test): 1.1008108854293823\n",
            "Epoch 753/1000: L(Train): 1.2005021572113037; L(Test): 1.1009501218795776\n",
            "Epoch 754/1000: L(Train): 1.1335771083831787; L(Test): 1.0998923778533936\n",
            "Epoch 755/1000: L(Train): 1.1676998138427734; L(Test): 1.0968520641326904\n",
            "Epoch 756/1000: L(Train): 1.162949562072754; L(Test): 1.1026700735092163\n",
            "Epoch 757/1000: L(Train): 1.179365634918213; L(Test): 1.0969655513763428\n",
            "Epoch 758/1000: L(Train): 1.1628742218017578; L(Test): 1.1020147800445557\n",
            "Epoch 759/1000: L(Train): 1.173133134841919; L(Test): 1.0985240936279297\n",
            "Epoch 760/1000: L(Train): 1.1673433780670166; L(Test): 1.0970174074172974\n",
            "Epoch 761/1000: L(Train): 1.133270263671875; L(Test): 1.0954465866088867\n",
            "Epoch 762/1000: L(Train): 1.180418848991394; L(Test): 1.0974668264389038\n",
            "Epoch 763/1000: L(Train): 1.184743881225586; L(Test): 1.0984803438186646\n",
            "Epoch 764/1000: L(Train): 1.1607024669647217; L(Test): 1.1188405752182007\n",
            "Epoch 765/1000: L(Train): 1.1864354610443115; L(Test): 1.1164648532867432\n",
            "Epoch 766/1000: L(Train): 1.1897914409637451; L(Test): 1.111881971359253\n",
            "Epoch 767/1000: L(Train): 1.2073410749435425; L(Test): 1.1124974489212036\n",
            "Epoch 768/1000: L(Train): 1.1834028959274292; L(Test): 1.1231642961502075\n",
            "Epoch 769/1000: L(Train): 1.1766220331192017; L(Test): 1.1386842727661133\n",
            "Epoch 770/1000: L(Train): 1.1886529922485352; L(Test): 1.140577793121338\n",
            "Epoch 771/1000: L(Train): 1.1888628005981445; L(Test): 1.1499906778335571\n",
            "Epoch 772/1000: L(Train): 1.2139490842819214; L(Test): 1.1567226648330688\n",
            "Epoch 773/1000: L(Train): 1.2249071598052979; L(Test): 1.1628186702728271\n",
            "Epoch 774/1000: L(Train): 1.2261148691177368; L(Test): 1.1626107692718506\n",
            "Epoch 775/1000: L(Train): 1.2064143419265747; L(Test): 1.1706007719039917\n",
            "Epoch 776/1000: L(Train): 1.2445212602615356; L(Test): 1.1762464046478271\n",
            "Epoch 777/1000: L(Train): 1.2460814714431763; L(Test): 1.1833536624908447\n",
            "Epoch 778/1000: L(Train): 1.2336573600769043; L(Test): 1.1785516738891602\n",
            "Epoch 779/1000: L(Train): 1.2258155345916748; L(Test): 1.1749500036239624\n",
            "Epoch 780/1000: L(Train): 1.2238640785217285; L(Test): 1.1724601984024048\n",
            "Epoch 781/1000: L(Train): 1.231856107711792; L(Test): 1.1728063821792603\n",
            "Epoch 782/1000: L(Train): 1.2368433475494385; L(Test): 1.1797329187393188\n",
            "Epoch 783/1000: L(Train): 1.2465544939041138; L(Test): 1.18043053150177\n",
            "Epoch 784/1000: L(Train): 1.2337427139282227; L(Test): 1.1845052242279053\n",
            "Epoch 785/1000: L(Train): 1.2456374168395996; L(Test): 1.1906473636627197\n",
            "Epoch 786/1000: L(Train): 1.2375906705856323; L(Test): 1.1943089962005615\n",
            "Epoch 787/1000: L(Train): 1.2518972158432007; L(Test): 1.1863046884536743\n",
            "Epoch 788/1000: L(Train): 1.2513684034347534; L(Test): 1.1758583784103394\n",
            "Epoch 789/1000: L(Train): 1.2145353555679321; L(Test): 1.1700178384780884\n",
            "Epoch 790/1000: L(Train): 1.2306256294250488; L(Test): 1.173384666442871\n",
            "Epoch 791/1000: L(Train): 1.2343671321868896; L(Test): 1.1721559762954712\n",
            "Epoch 792/1000: L(Train): 1.2302069664001465; L(Test): 1.1661853790283203\n",
            "Epoch 793/1000: L(Train): 1.2185776233673096; L(Test): 1.1755492687225342\n",
            "Epoch 794/1000: L(Train): 1.2174543142318726; L(Test): 1.1802791357040405\n",
            "Epoch 795/1000: L(Train): 1.2390916347503662; L(Test): 1.1854071617126465\n",
            "Epoch 796/1000: L(Train): 1.228561282157898; L(Test): 1.1900492906570435\n",
            "Epoch 797/1000: L(Train): 1.2325621843338013; L(Test): 1.189104676246643\n",
            "Epoch 798/1000: L(Train): 1.2466895580291748; L(Test): 1.1918885707855225\n",
            "Epoch 799/1000: L(Train): 1.2492696046829224; L(Test): 1.1951019763946533\n",
            "Epoch 800/1000: L(Train): 1.2441818714141846; L(Test): 1.1959275007247925\n",
            "Epoch 801/1000: L(Train): 1.2392438650131226; L(Test): 1.215678095817566\n",
            "Epoch 802/1000: L(Train): 1.2722612619400024; L(Test): 1.2148083448410034\n",
            "Epoch 803/1000: L(Train): 1.252265214920044; L(Test): 1.2065486907958984\n",
            "Epoch 804/1000: L(Train): 1.2490378618240356; L(Test): 1.2300395965576172\n",
            "Epoch 805/1000: L(Train): 1.2464721202850342; L(Test): 1.2373591661453247\n",
            "Epoch 806/1000: L(Train): 1.26459538936615; L(Test): 1.2351382970809937\n",
            "Epoch 807/1000: L(Train): 1.2632654905319214; L(Test): 1.2378588914871216\n",
            "Epoch 808/1000: L(Train): 1.3180534839630127; L(Test): 1.2301709651947021\n",
            "Epoch 809/1000: L(Train): 1.276308536529541; L(Test): 1.2368377447128296\n",
            "Epoch 810/1000: L(Train): 1.2790919542312622; L(Test): 1.2480418682098389\n",
            "Epoch 811/1000: L(Train): 1.2847782373428345; L(Test): 1.2498652935028076\n",
            "Epoch 812/1000: L(Train): 1.303194522857666; L(Test): 1.245205283164978\n",
            "Epoch 813/1000: L(Train): 1.287175178527832; L(Test): 1.2448158264160156\n",
            "Epoch 814/1000: L(Train): 1.273593544960022; L(Test): 1.244654655456543\n",
            "Epoch 815/1000: L(Train): 1.2852873802185059; L(Test): 1.2473198175430298\n",
            "Epoch 816/1000: L(Train): 1.278557300567627; L(Test): 1.2528283596038818\n",
            "Epoch 817/1000: L(Train): 1.2828482389450073; L(Test): 1.2462990283966064\n",
            "Epoch 818/1000: L(Train): 1.3070977926254272; L(Test): 1.240398645401001\n",
            "Epoch 819/1000: L(Train): 1.2936729192733765; L(Test): 1.235358715057373\n",
            "Epoch 820/1000: L(Train): 1.2855831384658813; L(Test): 1.2326231002807617\n",
            "Epoch 821/1000: L(Train): 1.2769615650177002; L(Test): 1.2312864065170288\n",
            "Epoch 822/1000: L(Train): 1.2544589042663574; L(Test): 1.2333617210388184\n",
            "Epoch 823/1000: L(Train): 1.2700668573379517; L(Test): 1.233972191810608\n",
            "Epoch 824/1000: L(Train): 1.2832355499267578; L(Test): 1.2274261713027954\n",
            "Epoch 825/1000: L(Train): 1.2560604810714722; L(Test): 1.2204076051712036\n",
            "Epoch 826/1000: L(Train): 1.2698686122894287; L(Test): 1.2195546627044678\n",
            "Epoch 827/1000: L(Train): 1.259799599647522; L(Test): 1.2194002866744995\n",
            "Epoch 828/1000: L(Train): 1.2471201419830322; L(Test): 1.2205935716629028\n",
            "Epoch 829/1000: L(Train): 1.265146255493164; L(Test): 1.219224452972412\n",
            "Epoch 830/1000: L(Train): 1.2568415403366089; L(Test): 1.2161173820495605\n",
            "Epoch 831/1000: L(Train): 1.277767300605774; L(Test): 1.209402084350586\n",
            "Epoch 832/1000: L(Train): 1.2695488929748535; L(Test): 1.2097699642181396\n",
            "Epoch 833/1000: L(Train): 1.2589017152786255; L(Test): 1.2095484733581543\n",
            "Epoch 834/1000: L(Train): 1.244441032409668; L(Test): 1.2069389820098877\n",
            "Epoch 835/1000: L(Train): 1.254807472229004; L(Test): 1.2055866718292236\n",
            "Epoch 836/1000: L(Train): 1.2629674673080444; L(Test): 1.2042478322982788\n",
            "Epoch 837/1000: L(Train): 1.2477836608886719; L(Test): 1.2016935348510742\n",
            "Epoch 838/1000: L(Train): 1.225386381149292; L(Test): 1.1991987228393555\n",
            "Epoch 839/1000: L(Train): 1.2316056489944458; L(Test): 1.197558879852295\n",
            "Epoch 840/1000: L(Train): 1.2638715505599976; L(Test): 1.1956875324249268\n",
            "Epoch 841/1000: L(Train): 1.2429711818695068; L(Test): 1.1913028955459595\n",
            "Epoch 842/1000: L(Train): 1.222807765007019; L(Test): 1.1912487745285034\n",
            "Epoch 843/1000: L(Train): 1.2157074213027954; L(Test): 1.1963306665420532\n",
            "Epoch 844/1000: L(Train): 1.2435929775238037; L(Test): 1.1954551935195923\n",
            "Epoch 845/1000: L(Train): 1.222288966178894; L(Test): 1.1862050294876099\n",
            "Epoch 846/1000: L(Train): 1.2245844602584839; L(Test): 1.1862480640411377\n",
            "Epoch 847/1000: L(Train): 1.2377225160598755; L(Test): 1.1891549825668335\n",
            "Epoch 848/1000: L(Train): 1.242785096168518; L(Test): 1.1889119148254395\n",
            "Epoch 849/1000: L(Train): 1.23622727394104; L(Test): 1.1887253522872925\n",
            "Epoch 850/1000: L(Train): 1.2193337678909302; L(Test): 1.1842962503433228\n",
            "Epoch 851/1000: L(Train): 1.2089253664016724; L(Test): 1.1811761856079102\n",
            "Epoch 852/1000: L(Train): 1.2396960258483887; L(Test): 1.182786226272583\n",
            "Epoch 853/1000: L(Train): 1.238236904144287; L(Test): 1.1778913736343384\n",
            "Epoch 854/1000: L(Train): 1.238741159439087; L(Test): 1.172882318496704\n",
            "Epoch 855/1000: L(Train): 1.212051272392273; L(Test): 1.1714744567871094\n",
            "Epoch 856/1000: L(Train): 1.2171522378921509; L(Test): 1.1717894077301025\n",
            "Epoch 857/1000: L(Train): 1.2016428709030151; L(Test): 1.1715933084487915\n",
            "Epoch 858/1000: L(Train): 1.2168171405792236; L(Test): 1.1697956323623657\n",
            "Epoch 859/1000: L(Train): 1.2340832948684692; L(Test): 1.1679514646530151\n",
            "Epoch 860/1000: L(Train): 1.2382614612579346; L(Test): 1.1650875806808472\n",
            "Epoch 861/1000: L(Train): 1.2181936502456665; L(Test): 1.1636946201324463\n",
            "Epoch 862/1000: L(Train): 1.1959706544876099; L(Test): 1.1656172275543213\n",
            "Epoch 863/1000: L(Train): 1.2375948429107666; L(Test): 1.1630430221557617\n",
            "Epoch 864/1000: L(Train): 1.2303179502487183; L(Test): 1.1725660562515259\n",
            "Epoch 865/1000: L(Train): 1.2351783514022827; L(Test): 1.2009806632995605\n",
            "Epoch 866/1000: L(Train): 1.275094985961914; L(Test): 1.2037842273712158\n",
            "Epoch 867/1000: L(Train): 1.251052737236023; L(Test): 1.2119818925857544\n",
            "Epoch 868/1000: L(Train): 1.2493120431900024; L(Test): 1.2317641973495483\n",
            "Epoch 869/1000: L(Train): 1.2816054821014404; L(Test): 1.2423776388168335\n",
            "Epoch 870/1000: L(Train): 1.2882181406021118; L(Test): 1.2514609098434448\n",
            "Epoch 871/1000: L(Train): 1.2732868194580078; L(Test): 1.2609922885894775\n",
            "Epoch 872/1000: L(Train): 1.3007431030273438; L(Test): 1.2595300674438477\n",
            "Epoch 873/1000: L(Train): 1.293991208076477; L(Test): 1.2476726770401\n",
            "Epoch 874/1000: L(Train): 1.2949848175048828; L(Test): 1.2520250082015991\n",
            "Epoch 875/1000: L(Train): 1.3177406787872314; L(Test): 1.2515003681182861\n",
            "Epoch 876/1000: L(Train): 1.3096848726272583; L(Test): 1.2464293241500854\n",
            "Epoch 877/1000: L(Train): 1.2862170934677124; L(Test): 1.2487176656723022\n",
            "Epoch 878/1000: L(Train): 1.32258939743042; L(Test): 1.2490419149398804\n",
            "Epoch 879/1000: L(Train): 1.3025262355804443; L(Test): 1.244472861289978\n",
            "Epoch 880/1000: L(Train): 1.2724004983901978; L(Test): 1.246984839439392\n",
            "Epoch 881/1000: L(Train): 1.2972538471221924; L(Test): 1.2608145475387573\n",
            "Epoch 882/1000: L(Train): 1.3031792640686035; L(Test): 1.260251522064209\n",
            "Epoch 883/1000: L(Train): 1.3186312913894653; L(Test): 1.2634822130203247\n",
            "Epoch 884/1000: L(Train): 1.3002170324325562; L(Test): 1.267983317375183\n",
            "Epoch 885/1000: L(Train): 1.314149022102356; L(Test): 1.2735540866851807\n",
            "Epoch 886/1000: L(Train): 1.3067184686660767; L(Test): 1.2709014415740967\n",
            "Epoch 887/1000: L(Train): 1.3445746898651123; L(Test): 1.2730764150619507\n",
            "Epoch 888/1000: L(Train): 1.305540680885315; L(Test): 1.2732512950897217\n",
            "Epoch 889/1000: L(Train): 1.300890326499939; L(Test): 1.2711286544799805\n",
            "Epoch 890/1000: L(Train): 1.3176430463790894; L(Test): 1.2685776948928833\n",
            "Epoch 891/1000: L(Train): 1.2866954803466797; L(Test): 1.2673227787017822\n",
            "Epoch 892/1000: L(Train): 1.2752851247787476; L(Test): 1.2609829902648926\n",
            "Epoch 893/1000: L(Train): 1.2989829778671265; L(Test): 1.2622907161712646\n",
            "Epoch 894/1000: L(Train): 1.294506311416626; L(Test): 1.2614527940750122\n",
            "Epoch 895/1000: L(Train): 1.3070119619369507; L(Test): 1.2533042430877686\n",
            "Epoch 896/1000: L(Train): 1.2868586778640747; L(Test): 1.2572991847991943\n",
            "Epoch 897/1000: L(Train): 1.2855801582336426; L(Test): 1.258918046951294\n",
            "Epoch 898/1000: L(Train): 1.3060325384140015; L(Test): 1.2564308643341064\n",
            "Epoch 899/1000: L(Train): 1.2885289192199707; L(Test): 1.256851077079773\n",
            "Epoch 900/1000: L(Train): 1.2808040380477905; L(Test): 1.2621246576309204\n",
            "Epoch 901/1000: L(Train): 1.3015416860580444; L(Test): 1.2613403797149658\n",
            "Epoch 902/1000: L(Train): 1.2758989334106445; L(Test): 1.256093144416809\n",
            "Epoch 903/1000: L(Train): 1.2777948379516602; L(Test): 1.2554022073745728\n",
            "Epoch 904/1000: L(Train): 1.2818472385406494; L(Test): 1.2519023418426514\n",
            "Epoch 905/1000: L(Train): 1.2765852212905884; L(Test): 1.2477771043777466\n",
            "Epoch 906/1000: L(Train): 1.2955721616744995; L(Test): 1.2456204891204834\n",
            "Epoch 907/1000: L(Train): 1.2794493436813354; L(Test): 1.24582040309906\n",
            "Epoch 908/1000: L(Train): 1.2961797714233398; L(Test): 1.2443767786026\n",
            "Epoch 909/1000: L(Train): 1.3016058206558228; L(Test): 1.2399441003799438\n",
            "Epoch 910/1000: L(Train): 1.2625675201416016; L(Test): 1.2386834621429443\n",
            "Epoch 911/1000: L(Train): 1.263978123664856; L(Test): 1.2368777990341187\n",
            "Epoch 912/1000: L(Train): 1.2661212682724; L(Test): 1.2334126234054565\n",
            "Epoch 913/1000: L(Train): 1.2730554342269897; L(Test): 1.2330832481384277\n",
            "Epoch 914/1000: L(Train): 1.2714334726333618; L(Test): 1.2332590818405151\n",
            "Epoch 915/1000: L(Train): 1.285781979560852; L(Test): 1.229614019393921\n",
            "Epoch 916/1000: L(Train): 1.2673931121826172; L(Test): 1.2251673936843872\n",
            "Epoch 917/1000: L(Train): 1.271122932434082; L(Test): 1.2247906923294067\n",
            "Epoch 918/1000: L(Train): 1.264270544052124; L(Test): 1.2246246337890625\n",
            "Epoch 919/1000: L(Train): 1.2313662767410278; L(Test): 1.2232953310012817\n",
            "Epoch 920/1000: L(Train): 1.2258716821670532; L(Test): 1.22079598903656\n",
            "Epoch 921/1000: L(Train): 1.2660412788391113; L(Test): 1.2199068069458008\n",
            "Epoch 922/1000: L(Train): 1.2492365837097168; L(Test): 1.2175430059432983\n",
            "Epoch 923/1000: L(Train): 1.232816219329834; L(Test): 1.2164196968078613\n",
            "Epoch 924/1000: L(Train): 1.2487475872039795; L(Test): 1.2154968976974487\n",
            "Epoch 925/1000: L(Train): 1.2663242816925049; L(Test): 1.213996171951294\n",
            "Epoch 926/1000: L(Train): 1.27847421169281; L(Test): 1.213202714920044\n",
            "Epoch 927/1000: L(Train): 1.2446613311767578; L(Test): 1.2121198177337646\n",
            "Epoch 928/1000: L(Train): 1.284574031829834; L(Test): 1.2091596126556396\n",
            "Epoch 929/1000: L(Train): 1.230899453163147; L(Test): 1.208438515663147\n",
            "Epoch 930/1000: L(Train): 1.2514665126800537; L(Test): 1.2069429159164429\n",
            "Epoch 931/1000: L(Train): 1.2673258781433105; L(Test): 1.2065271139144897\n",
            "Epoch 932/1000: L(Train): 1.2512916326522827; L(Test): 1.2057218551635742\n",
            "Epoch 933/1000: L(Train): 1.245342493057251; L(Test): 1.203824758529663\n",
            "Epoch 934/1000: L(Train): 1.2724850177764893; L(Test): 1.2034578323364258\n",
            "Epoch 935/1000: L(Train): 1.2546868324279785; L(Test): 1.2023379802703857\n",
            "Epoch 936/1000: L(Train): 1.2577279806137085; L(Test): 1.2020312547683716\n",
            "Epoch 937/1000: L(Train): 1.248288869857788; L(Test): 1.2023106813430786\n",
            "Epoch 938/1000: L(Train): 1.2441900968551636; L(Test): 1.1995882987976074\n",
            "Epoch 939/1000: L(Train): 1.2407352924346924; L(Test): 1.197130560874939\n",
            "Epoch 940/1000: L(Train): 1.2134273052215576; L(Test): 1.1991349458694458\n",
            "Epoch 941/1000: L(Train): 1.2606480121612549; L(Test): 1.195962905883789\n",
            "Epoch 942/1000: L(Train): 1.2355328798294067; L(Test): 1.19412362575531\n",
            "Epoch 943/1000: L(Train): 1.2306396961212158; L(Test): 1.1962424516677856\n",
            "Epoch 944/1000: L(Train): 1.2391126155853271; L(Test): 1.1944667100906372\n",
            "Epoch 945/1000: L(Train): 1.23585844039917; L(Test): 1.193839192390442\n",
            "Epoch 946/1000: L(Train): 1.2646089792251587; L(Test): 1.1925603151321411\n",
            "Epoch 947/1000: L(Train): 1.2459163665771484; L(Test): 1.189747929573059\n",
            "Epoch 948/1000: L(Train): 1.226528286933899; L(Test): 1.1890740394592285\n",
            "Epoch 949/1000: L(Train): 1.22981595993042; L(Test): 1.1880030632019043\n",
            "Epoch 950/1000: L(Train): 1.237189531326294; L(Test): 1.1863067150115967\n",
            "Epoch 951/1000: L(Train): 1.2488842010498047; L(Test): 1.18538498878479\n",
            "Epoch 952/1000: L(Train): 1.2368462085723877; L(Test): 1.1841528415679932\n",
            "Epoch 953/1000: L(Train): 1.2081605195999146; L(Test): 1.1822036504745483\n",
            "Epoch 954/1000: L(Train): 1.2219111919403076; L(Test): 1.1816610097885132\n",
            "Epoch 955/1000: L(Train): 1.2431105375289917; L(Test): 1.1821482181549072\n",
            "Epoch 956/1000: L(Train): 1.2253267765045166; L(Test): 1.1799222230911255\n",
            "Epoch 957/1000: L(Train): 1.218062400817871; L(Test): 1.178743600845337\n",
            "Epoch 958/1000: L(Train): 1.23318350315094; L(Test): 1.1771997213363647\n",
            "Epoch 959/1000: L(Train): 1.2313497066497803; L(Test): 1.1773029565811157\n",
            "Epoch 960/1000: L(Train): 1.2331056594848633; L(Test): 1.1765131950378418\n",
            "Epoch 961/1000: L(Train): 1.2218486070632935; L(Test): 1.1769357919692993\n",
            "Epoch 962/1000: L(Train): 1.2224235534667969; L(Test): 1.175665259361267\n",
            "Epoch 963/1000: L(Train): 1.2271780967712402; L(Test): 1.1743377447128296\n",
            "Epoch 964/1000: L(Train): 1.2310172319412231; L(Test): 1.17350172996521\n",
            "Epoch 965/1000: L(Train): 1.2336241006851196; L(Test): 1.1734029054641724\n",
            "Epoch 966/1000: L(Train): 1.2324414253234863; L(Test): 1.1769094467163086\n",
            "Epoch 967/1000: L(Train): 1.219624400138855; L(Test): 1.1756253242492676\n",
            "Epoch 968/1000: L(Train): 1.2246030569076538; L(Test): 1.1726018190383911\n",
            "Epoch 969/1000: L(Train): 1.238608717918396; L(Test): 1.1739883422851562\n",
            "Epoch 970/1000: L(Train): 1.2348846197128296; L(Test): 1.1756043434143066\n",
            "Epoch 971/1000: L(Train): 1.2287262678146362; L(Test): 1.1728966236114502\n",
            "Epoch 972/1000: L(Train): 1.2389206886291504; L(Test): 1.1755328178405762\n",
            "Epoch 973/1000: L(Train): 1.2224490642547607; L(Test): 1.183917760848999\n",
            "Epoch 974/1000: L(Train): 1.2276567220687866; L(Test): 1.1796151399612427\n",
            "Epoch 975/1000: L(Train): 1.2325767278671265; L(Test): 1.1745678186416626\n",
            "Epoch 976/1000: L(Train): 1.2062454223632812; L(Test): 1.179360270500183\n",
            "Epoch 977/1000: L(Train): 1.21011483669281; L(Test): 1.1853843927383423\n",
            "Epoch 978/1000: L(Train): 1.2231402397155762; L(Test): 1.1794816255569458\n",
            "Epoch 979/1000: L(Train): 1.2503093481063843; L(Test): 1.1750056743621826\n",
            "Epoch 980/1000: L(Train): 1.2294775247573853; L(Test): 1.1749155521392822\n",
            "Epoch 981/1000: L(Train): 1.2235121726989746; L(Test): 1.1773606538772583\n",
            "Epoch 982/1000: L(Train): 1.2104344367980957; L(Test): 1.1755390167236328\n",
            "Epoch 983/1000: L(Train): 1.2134193181991577; L(Test): 1.172272801399231\n",
            "Epoch 984/1000: L(Train): 1.2250269651412964; L(Test): 1.1731857061386108\n",
            "Epoch 985/1000: L(Train): 1.2218998670578003; L(Test): 1.176079273223877\n",
            "Epoch 986/1000: L(Train): 1.2065067291259766; L(Test): 1.1801118850708008\n",
            "Epoch 987/1000: L(Train): 1.2137277126312256; L(Test): 1.180317997932434\n",
            "Epoch 988/1000: L(Train): 1.2309249639511108; L(Test): 1.1801810264587402\n",
            "Epoch 989/1000: L(Train): 1.2215361595153809; L(Test): 1.1755797863006592\n",
            "Epoch 990/1000: L(Train): 1.219464898109436; L(Test): 1.1734659671783447\n",
            "Epoch 991/1000: L(Train): 1.2328747510910034; L(Test): 1.171620488166809\n",
            "Epoch 992/1000: L(Train): 1.2432254552841187; L(Test): 1.17225182056427\n",
            "Epoch 993/1000: L(Train): 1.2259206771850586; L(Test): 1.1718900203704834\n",
            "Epoch 994/1000: L(Train): 1.2359583377838135; L(Test): 1.1722142696380615\n",
            "Epoch 995/1000: L(Train): 1.2325609922409058; L(Test): 1.173812747001648\n",
            "Epoch 996/1000: L(Train): 1.2205501794815063; L(Test): 1.1691182851791382\n",
            "Epoch 997/1000: L(Train): 1.2200334072113037; L(Test): 1.1706091165542603\n",
            "Epoch 998/1000: L(Train): 1.1959797143936157; L(Test): 1.170612096786499\n",
            "Epoch 999/1000: L(Train): 1.2053160667419434; L(Test): 1.1690382957458496\n",
            "Epoch 1000/1000: L(Train): 1.2244669198989868; L(Test): 1.169694185256958\n",
            "Trained GRU parameters saved to ../../weinhardt2025/params/hwang2025/gru_hwang2025.pkl\n"
          ]
        }
      ],
      "source": [
        "gru = training(\n",
        "    gru=gru,\n",
        "    optimizer=optimizer,\n",
        "    dataset_train=dataset_train,\n",
        "    dataset_test=dataset_test,\n",
        "    epochs=epochs,\n",
        "    )\n",
        "\n",
        "torch.save(gru.state_dict(), path_gru)\n",
        "print(\"Trained GRU parameters saved to \" + path_gru)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "gru_agent = setup_agent_gru(path_gru, gru)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GRU with participant embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GRUEmbed(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, n_actions, n_participants, additional_inputs: int = 0, hidden_size: int = 32, **kwargs):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.gru_features = hidden_size\n",
        "        self.n_actions = n_actions\n",
        "        self.additional_inputs = additional_inputs\n",
        "        self.embed_size = 8\n",
        "        \n",
        "        self.embedding = torch.nn.Embedding(n_participants, self.embed_size)\n",
        "        \n",
        "        self.linear_in = torch.nn.Linear(in_features=n_actions+1+additional_inputs+2*self.embed_size, out_features=hidden_size)\n",
        "        self.dropout = torch.nn.Dropout(0.1)\n",
        "        self.gru = torch.nn.GRU(input_size=hidden_size, hidden_size=hidden_size, batch_first=True)\n",
        "        self.linear_out = torch.nn.Linear(in_features=hidden_size, out_features=n_actions)\n",
        "        \n",
        "    def forward(self, inputs, state=None):\n",
        "        \n",
        "        id1 = inputs[..., 2*self.n_actions+1].long()\n",
        "        id2 = inputs[..., 2*self.n_actions+2].long()\n",
        "        \n",
        "        embed1 = self.embedding(id1)\n",
        "        embed2 = self.embedding(id2)\n",
        "        \n",
        "        actions = inputs[..., :self.n_actions]\n",
        "        rewards = inputs[..., self.n_actions:2*self.n_actions].nan_to_num(0).sum(dim=-1, keepdims=True)\n",
        "        additional_inputs = inputs[..., self.n_actions*2+2:self.n_actions*2+2+self.additional_inputs]\n",
        "        inputs = torch.concat((actions, rewards, additional_inputs, embed1, embed2), dim=-1)\n",
        "        \n",
        "        if state is not None and len(inputs.shape) == 3:\n",
        "            state = state.reshape(1, 1, self.gru_features)\n",
        "        \n",
        "        y = self.linear_in(inputs.nan_to_num(0))\n",
        "        y = self.dropout(y)\n",
        "        y, state = self.gru(y, state)\n",
        "        y = self.dropout(y)\n",
        "        y = self.linear_out(y)\n",
        "        return y, state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "epochs = 1000\n",
        "\n",
        "path_gru_embed = '../../weinhardt2025/params/hwang2025/gruembed_hwang2025.pkl'\n",
        "gru_embed = GRUEmbed(n_actions=n_actions, additional_inputs=4, n_participants=n_participants).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(gru_embed.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000: L(Train): 1.7963544130325317; L(Test): 1.6245155334472656\n",
            "Epoch 2/1000: L(Train): 1.6320685148239136; L(Test): 1.5594172477722168\n",
            "Epoch 3/1000: L(Train): 1.562958836555481; L(Test): 1.5424312353134155\n",
            "Epoch 4/1000: L(Train): 1.5491691827774048; L(Test): 1.5212664604187012\n",
            "Epoch 5/1000: L(Train): 1.52802312374115; L(Test): 1.499481439590454\n",
            "Epoch 6/1000: L(Train): 1.528749942779541; L(Test): 1.491908073425293\n",
            "Epoch 7/1000: L(Train): 1.4831535816192627; L(Test): 1.4890773296356201\n",
            "Epoch 8/1000: L(Train): 1.514981985092163; L(Test): 1.4789822101593018\n",
            "Epoch 9/1000: L(Train): 1.4808125495910645; L(Test): 1.4688146114349365\n",
            "Epoch 10/1000: L(Train): 1.4836866855621338; L(Test): 1.4608713388442993\n",
            "Epoch 11/1000: L(Train): 1.4646198749542236; L(Test): 1.4555153846740723\n",
            "Epoch 12/1000: L(Train): 1.4493154287338257; L(Test): 1.4519315958023071\n",
            "Epoch 13/1000: L(Train): 1.4477206468582153; L(Test): 1.4423831701278687\n",
            "Epoch 14/1000: L(Train): 1.4444985389709473; L(Test): 1.435379981994629\n",
            "Epoch 15/1000: L(Train): 1.455626368522644; L(Test): 1.4218741655349731\n",
            "Epoch 16/1000: L(Train): 1.4291678667068481; L(Test): 1.4126756191253662\n",
            "Epoch 17/1000: L(Train): 1.4157915115356445; L(Test): 1.4047279357910156\n",
            "Epoch 18/1000: L(Train): 1.3998769521713257; L(Test): 1.392954707145691\n",
            "Epoch 19/1000: L(Train): 1.4073386192321777; L(Test): 1.3865758180618286\n",
            "Epoch 20/1000: L(Train): 1.3804956674575806; L(Test): 1.378989815711975\n",
            "Epoch 21/1000: L(Train): 1.3790175914764404; L(Test): 1.3719171285629272\n",
            "Epoch 22/1000: L(Train): 1.398157000541687; L(Test): 1.3667651414871216\n",
            "Epoch 23/1000: L(Train): 1.3618619441986084; L(Test): 1.3620270490646362\n",
            "Epoch 24/1000: L(Train): 1.378832221031189; L(Test): 1.3594534397125244\n",
            "Epoch 25/1000: L(Train): 1.372680425643921; L(Test): 1.3566982746124268\n",
            "Epoch 26/1000: L(Train): 1.3727115392684937; L(Test): 1.3525930643081665\n",
            "Epoch 27/1000: L(Train): 1.34601628780365; L(Test): 1.3508493900299072\n",
            "Epoch 28/1000: L(Train): 1.3556777238845825; L(Test): 1.3489813804626465\n",
            "Epoch 29/1000: L(Train): 1.3535815477371216; L(Test): 1.3469266891479492\n",
            "Epoch 30/1000: L(Train): 1.3409761190414429; L(Test): 1.3467433452606201\n",
            "Epoch 31/1000: L(Train): 1.3740153312683105; L(Test): 1.3436024188995361\n",
            "Epoch 32/1000: L(Train): 1.3498986959457397; L(Test): 1.3431951999664307\n",
            "Epoch 33/1000: L(Train): 1.344584584236145; L(Test): 1.3434219360351562\n",
            "Epoch 34/1000: L(Train): 1.3591532707214355; L(Test): 1.340120792388916\n",
            "Epoch 35/1000: L(Train): 1.3372328281402588; L(Test): 1.335438847541809\n",
            "Epoch 36/1000: L(Train): 1.3475896120071411; L(Test): 1.3336423635482788\n",
            "Epoch 37/1000: L(Train): 1.3623967170715332; L(Test): 1.332780361175537\n",
            "Epoch 38/1000: L(Train): 1.364891529083252; L(Test): 1.3313279151916504\n",
            "Epoch 39/1000: L(Train): 1.3219987154006958; L(Test): 1.3312959671020508\n",
            "Epoch 40/1000: L(Train): 1.3415099382400513; L(Test): 1.3294986486434937\n",
            "Epoch 41/1000: L(Train): 1.3331745862960815; L(Test): 1.327210783958435\n",
            "Epoch 42/1000: L(Train): 1.3470616340637207; L(Test): 1.326506495475769\n",
            "Epoch 43/1000: L(Train): 1.3642168045043945; L(Test): 1.3255620002746582\n",
            "Epoch 44/1000: L(Train): 1.3367964029312134; L(Test): 1.3242560625076294\n",
            "Epoch 45/1000: L(Train): 1.377947449684143; L(Test): 1.3233094215393066\n",
            "Epoch 46/1000: L(Train): 1.3399641513824463; L(Test): 1.321651577949524\n",
            "Epoch 47/1000: L(Train): 1.338250756263733; L(Test): 1.3209201097488403\n",
            "Epoch 48/1000: L(Train): 1.3398858308792114; L(Test): 1.3204089403152466\n",
            "Epoch 49/1000: L(Train): 1.33566415309906; L(Test): 1.3193541765213013\n",
            "Epoch 50/1000: L(Train): 1.3259731531143188; L(Test): 1.319279670715332\n",
            "Epoch 51/1000: L(Train): 1.3221033811569214; L(Test): 1.3178234100341797\n",
            "Epoch 52/1000: L(Train): 1.3069405555725098; L(Test): 1.3149657249450684\n",
            "Epoch 53/1000: L(Train): 1.3377737998962402; L(Test): 1.3136295080184937\n",
            "Epoch 54/1000: L(Train): 1.3285211324691772; L(Test): 1.313310980796814\n",
            "Epoch 55/1000: L(Train): 1.3262875080108643; L(Test): 1.3129640817642212\n",
            "Epoch 56/1000: L(Train): 1.330462098121643; L(Test): 1.3114322423934937\n",
            "Epoch 57/1000: L(Train): 1.3391348123550415; L(Test): 1.3095791339874268\n",
            "Epoch 58/1000: L(Train): 1.3145253658294678; L(Test): 1.3080230951309204\n",
            "Epoch 59/1000: L(Train): 1.3115555047988892; L(Test): 1.3068188428878784\n",
            "Epoch 60/1000: L(Train): 1.304378628730774; L(Test): 1.305980920791626\n",
            "Epoch 61/1000: L(Train): 1.341819167137146; L(Test): 1.3050140142440796\n",
            "Epoch 62/1000: L(Train): 1.3382296562194824; L(Test): 1.304911732673645\n",
            "Epoch 63/1000: L(Train): 1.294877529144287; L(Test): 1.3047136068344116\n",
            "Epoch 64/1000: L(Train): 1.3018529415130615; L(Test): 1.3020521402359009\n",
            "Epoch 65/1000: L(Train): 1.3063691854476929; L(Test): 1.3000152111053467\n",
            "Epoch 66/1000: L(Train): 1.3086298704147339; L(Test): 1.2987016439437866\n",
            "Epoch 67/1000: L(Train): 1.3052877187728882; L(Test): 1.297800064086914\n",
            "Epoch 68/1000: L(Train): 1.2924352884292603; L(Test): 1.2963675260543823\n",
            "Epoch 69/1000: L(Train): 1.293007493019104; L(Test): 1.2955732345581055\n",
            "Epoch 70/1000: L(Train): 1.2977017164230347; L(Test): 1.2945445775985718\n",
            "Epoch 71/1000: L(Train): 1.3094027042388916; L(Test): 1.292261004447937\n",
            "Epoch 72/1000: L(Train): 1.3054487705230713; L(Test): 1.2908332347869873\n",
            "Epoch 73/1000: L(Train): 1.3131664991378784; L(Test): 1.2903268337249756\n",
            "Epoch 74/1000: L(Train): 1.294939398765564; L(Test): 1.2887835502624512\n",
            "Epoch 75/1000: L(Train): 1.3101015090942383; L(Test): 1.285773754119873\n",
            "Epoch 76/1000: L(Train): 1.2556805610656738; L(Test): 1.2845349311828613\n",
            "Epoch 77/1000: L(Train): 1.3019853830337524; L(Test): 1.2832932472229004\n",
            "Epoch 78/1000: L(Train): 1.297711968421936; L(Test): 1.2815461158752441\n",
            "Epoch 79/1000: L(Train): 1.3102107048034668; L(Test): 1.279360055923462\n",
            "Epoch 80/1000: L(Train): 1.3159382343292236; L(Test): 1.2777756452560425\n",
            "Epoch 81/1000: L(Train): 1.2933716773986816; L(Test): 1.2763385772705078\n",
            "Epoch 82/1000: L(Train): 1.276703119277954; L(Test): 1.2738703489303589\n",
            "Epoch 83/1000: L(Train): 1.3055306673049927; L(Test): 1.2725245952606201\n",
            "Epoch 84/1000: L(Train): 1.2933058738708496; L(Test): 1.2715744972229004\n",
            "Epoch 85/1000: L(Train): 1.2792688608169556; L(Test): 1.2702378034591675\n",
            "Epoch 86/1000: L(Train): 1.2779868841171265; L(Test): 1.2678890228271484\n",
            "Epoch 87/1000: L(Train): 1.2848460674285889; L(Test): 1.2656431198120117\n",
            "Epoch 88/1000: L(Train): 1.2981363534927368; L(Test): 1.2646688222885132\n",
            "Epoch 89/1000: L(Train): 1.2918728590011597; L(Test): 1.2641346454620361\n",
            "Epoch 90/1000: L(Train): 1.2775075435638428; L(Test): 1.262373447418213\n",
            "Epoch 91/1000: L(Train): 1.2800456285476685; L(Test): 1.2599554061889648\n",
            "Epoch 92/1000: L(Train): 1.2617719173431396; L(Test): 1.260643482208252\n",
            "Epoch 93/1000: L(Train): 1.2899425029754639; L(Test): 1.2573187351226807\n",
            "Epoch 94/1000: L(Train): 1.2858009338378906; L(Test): 1.2552045583724976\n",
            "Epoch 95/1000: L(Train): 1.2814836502075195; L(Test): 1.2563577890396118\n",
            "Epoch 96/1000: L(Train): 1.2793442010879517; L(Test): 1.2547624111175537\n",
            "Epoch 97/1000: L(Train): 1.28380286693573; L(Test): 1.2513347864151\n",
            "Epoch 98/1000: L(Train): 1.247367262840271; L(Test): 1.2491401433944702\n",
            "Epoch 99/1000: L(Train): 1.2646584510803223; L(Test): 1.2494357824325562\n",
            "Epoch 100/1000: L(Train): 1.2796951532363892; L(Test): 1.2471085786819458\n",
            "Epoch 101/1000: L(Train): 1.2652391195297241; L(Test): 1.2448346614837646\n",
            "Epoch 102/1000: L(Train): 1.2650960683822632; L(Test): 1.2443851232528687\n",
            "Epoch 103/1000: L(Train): 1.2556979656219482; L(Test): 1.243849754333496\n",
            "Epoch 104/1000: L(Train): 1.252456545829773; L(Test): 1.240662932395935\n",
            "Epoch 105/1000: L(Train): 1.2773594856262207; L(Test): 1.237957239151001\n",
            "Epoch 106/1000: L(Train): 1.2617050409317017; L(Test): 1.2366961240768433\n",
            "Epoch 107/1000: L(Train): 1.2517529726028442; L(Test): 1.2354803085327148\n",
            "Epoch 108/1000: L(Train): 1.2430378198623657; L(Test): 1.2331520318984985\n",
            "Epoch 109/1000: L(Train): 1.2479263544082642; L(Test): 1.2307639122009277\n",
            "Epoch 110/1000: L(Train): 1.244358777999878; L(Test): 1.2305622100830078\n",
            "Epoch 111/1000: L(Train): 1.2430661916732788; L(Test): 1.230090856552124\n",
            "Epoch 112/1000: L(Train): 1.290833592414856; L(Test): 1.227400541305542\n",
            "Epoch 113/1000: L(Train): 1.2352286577224731; L(Test): 1.2277151346206665\n",
            "Epoch 114/1000: L(Train): 1.2559483051300049; L(Test): 1.2233881950378418\n",
            "Epoch 115/1000: L(Train): 1.2317728996276855; L(Test): 1.2233086824417114\n",
            "Epoch 116/1000: L(Train): 1.2393144369125366; L(Test): 1.2226264476776123\n",
            "Epoch 117/1000: L(Train): 1.244739055633545; L(Test): 1.2185816764831543\n",
            "Epoch 118/1000: L(Train): 1.2354326248168945; L(Test): 1.2211076021194458\n",
            "Epoch 119/1000: L(Train): 1.2511171102523804; L(Test): 1.2178040742874146\n",
            "Epoch 120/1000: L(Train): 1.2560731172561646; L(Test): 1.2126413583755493\n",
            "Epoch 121/1000: L(Train): 1.2441279888153076; L(Test): 1.212687611579895\n",
            "Epoch 122/1000: L(Train): 1.2521893978118896; L(Test): 1.2107497453689575\n",
            "Epoch 123/1000: L(Train): 1.2407132387161255; L(Test): 1.2096773386001587\n",
            "Epoch 124/1000: L(Train): 1.2169462442398071; L(Test): 1.2094547748565674\n",
            "Epoch 125/1000: L(Train): 1.23102867603302; L(Test): 1.2050647735595703\n",
            "Epoch 126/1000: L(Train): 1.222594976425171; L(Test): 1.203143835067749\n",
            "Epoch 127/1000: L(Train): 1.2189724445343018; L(Test): 1.2027631998062134\n",
            "Epoch 128/1000: L(Train): 1.2267993688583374; L(Test): 1.1995012760162354\n",
            "Epoch 129/1000: L(Train): 1.2187573909759521; L(Test): 1.2001104354858398\n",
            "Epoch 130/1000: L(Train): 1.2099820375442505; L(Test): 1.1981595754623413\n",
            "Epoch 131/1000: L(Train): 1.2258012294769287; L(Test): 1.195008397102356\n",
            "Epoch 132/1000: L(Train): 1.234833002090454; L(Test): 1.1929888725280762\n",
            "Epoch 133/1000: L(Train): 1.1856127977371216; L(Test): 1.191932201385498\n",
            "Epoch 134/1000: L(Train): 1.2269223928451538; L(Test): 1.189336895942688\n",
            "Epoch 135/1000: L(Train): 1.2380198240280151; L(Test): 1.187852382659912\n",
            "Epoch 136/1000: L(Train): 1.228490948677063; L(Test): 1.186131477355957\n",
            "Epoch 137/1000: L(Train): 1.2002121210098267; L(Test): 1.1856695413589478\n",
            "Epoch 138/1000: L(Train): 1.2254587411880493; L(Test): 1.1846868991851807\n",
            "Epoch 139/1000: L(Train): 1.2212599515914917; L(Test): 1.183034062385559\n",
            "Epoch 140/1000: L(Train): 1.2280778884887695; L(Test): 1.1797376871109009\n",
            "Epoch 141/1000: L(Train): 1.2423142194747925; L(Test): 1.1787911653518677\n",
            "Epoch 142/1000: L(Train): 1.2245498895645142; L(Test): 1.1784439086914062\n",
            "Epoch 143/1000: L(Train): 1.2026559114456177; L(Test): 1.1754035949707031\n",
            "Epoch 144/1000: L(Train): 1.219982624053955; L(Test): 1.174545407295227\n",
            "Epoch 145/1000: L(Train): 1.2016514539718628; L(Test): 1.1724475622177124\n",
            "Epoch 146/1000: L(Train): 1.2138071060180664; L(Test): 1.168860912322998\n",
            "Epoch 147/1000: L(Train): 1.1951100826263428; L(Test): 1.168209433555603\n",
            "Epoch 148/1000: L(Train): 1.206273078918457; L(Test): 1.1666178703308105\n",
            "Epoch 149/1000: L(Train): 1.2094004154205322; L(Test): 1.1636263132095337\n",
            "Epoch 150/1000: L(Train): 1.1900837421417236; L(Test): 1.1620490550994873\n",
            "Epoch 151/1000: L(Train): 1.1735652685165405; L(Test): 1.1593488454818726\n",
            "Epoch 152/1000: L(Train): 1.2230547666549683; L(Test): 1.1570428609848022\n",
            "Epoch 153/1000: L(Train): 1.1711657047271729; L(Test): 1.156922698020935\n",
            "Epoch 154/1000: L(Train): 1.1955513954162598; L(Test): 1.1570268869400024\n",
            "Epoch 155/1000: L(Train): 1.1862068176269531; L(Test): 1.1549543142318726\n",
            "Epoch 156/1000: L(Train): 1.1848788261413574; L(Test): 1.152879238128662\n",
            "Epoch 157/1000: L(Train): 1.2130793333053589; L(Test): 1.151411771774292\n",
            "Epoch 158/1000: L(Train): 1.174360990524292; L(Test): 1.1491340398788452\n",
            "Epoch 159/1000: L(Train): 1.1965091228485107; L(Test): 1.1476807594299316\n",
            "Epoch 160/1000: L(Train): 1.1912119388580322; L(Test): 1.1452308893203735\n",
            "Epoch 161/1000: L(Train): 1.17510986328125; L(Test): 1.1436587572097778\n",
            "Epoch 162/1000: L(Train): 1.1748753786087036; L(Test): 1.1428618431091309\n",
            "Epoch 163/1000: L(Train): 1.173346996307373; L(Test): 1.1426936388015747\n",
            "Epoch 164/1000: L(Train): 1.1697261333465576; L(Test): 1.1422021389007568\n",
            "Epoch 165/1000: L(Train): 1.1627602577209473; L(Test): 1.1380281448364258\n",
            "Epoch 166/1000: L(Train): 1.1857972145080566; L(Test): 1.1359959840774536\n",
            "Epoch 167/1000: L(Train): 1.1851152181625366; L(Test): 1.1351252794265747\n",
            "Epoch 168/1000: L(Train): 1.1678345203399658; L(Test): 1.1312907934188843\n",
            "Epoch 169/1000: L(Train): 1.1942510604858398; L(Test): 1.1305491924285889\n",
            "Epoch 170/1000: L(Train): 1.1921049356460571; L(Test): 1.1296391487121582\n",
            "Epoch 171/1000: L(Train): 1.1735447645187378; L(Test): 1.1270486116409302\n",
            "Epoch 172/1000: L(Train): 1.1704291105270386; L(Test): 1.1265913248062134\n",
            "Epoch 173/1000: L(Train): 1.1766154766082764; L(Test): 1.1230117082595825\n",
            "Epoch 174/1000: L(Train): 1.1859475374221802; L(Test): 1.12134850025177\n",
            "Epoch 175/1000: L(Train): 1.1593780517578125; L(Test): 1.120597004890442\n",
            "Epoch 176/1000: L(Train): 1.1843699216842651; L(Test): 1.1164606809616089\n",
            "Epoch 177/1000: L(Train): 1.1553544998168945; L(Test): 1.1152278184890747\n",
            "Epoch 178/1000: L(Train): 1.174636721611023; L(Test): 1.1136376857757568\n",
            "Epoch 179/1000: L(Train): 1.1466732025146484; L(Test): 1.1118212938308716\n",
            "Epoch 180/1000: L(Train): 1.1635257005691528; L(Test): 1.1099913120269775\n",
            "Epoch 181/1000: L(Train): 1.1772427558898926; L(Test): 1.107202410697937\n",
            "Epoch 182/1000: L(Train): 1.179115653038025; L(Test): 1.1082730293273926\n",
            "Epoch 183/1000: L(Train): 1.1566540002822876; L(Test): 1.1094263792037964\n",
            "Epoch 184/1000: L(Train): 1.1740379333496094; L(Test): 1.1053069829940796\n",
            "Epoch 185/1000: L(Train): 1.145973801612854; L(Test): 1.1041730642318726\n",
            "Epoch 186/1000: L(Train): 1.1508384943008423; L(Test): 1.103529691696167\n",
            "Epoch 187/1000: L(Train): 1.1509599685668945; L(Test): 1.10015070438385\n",
            "Epoch 188/1000: L(Train): 1.1430641412734985; L(Test): 1.0987110137939453\n",
            "Epoch 189/1000: L(Train): 1.168160319328308; L(Test): 1.0966721773147583\n",
            "Epoch 190/1000: L(Train): 1.1591039896011353; L(Test): 1.0989830493927002\n",
            "Epoch 191/1000: L(Train): 1.15912663936615; L(Test): 1.096381664276123\n",
            "Epoch 192/1000: L(Train): 1.1588249206542969; L(Test): 1.090405821800232\n",
            "Epoch 193/1000: L(Train): 1.152523159980774; L(Test): 1.0894924402236938\n",
            "Epoch 194/1000: L(Train): 1.1423078775405884; L(Test): 1.0882773399353027\n",
            "Epoch 195/1000: L(Train): 1.1380505561828613; L(Test): 1.0873371362686157\n",
            "Epoch 196/1000: L(Train): 1.1348986625671387; L(Test): 1.0877114534378052\n",
            "Epoch 197/1000: L(Train): 1.135880470275879; L(Test): 1.082277536392212\n",
            "Epoch 198/1000: L(Train): 1.146130084991455; L(Test): 1.078279972076416\n",
            "Epoch 199/1000: L(Train): 1.124398946762085; L(Test): 1.078779697418213\n",
            "Epoch 200/1000: L(Train): 1.134878158569336; L(Test): 1.0763005018234253\n",
            "Epoch 201/1000: L(Train): 1.1542060375213623; L(Test): 1.0762250423431396\n",
            "Epoch 202/1000: L(Train): 1.1300840377807617; L(Test): 1.075369119644165\n",
            "Epoch 203/1000: L(Train): 1.1252083778381348; L(Test): 1.0711361169815063\n",
            "Epoch 204/1000: L(Train): 1.1239161491394043; L(Test): 1.0694643259048462\n",
            "Epoch 205/1000: L(Train): 1.1303881406784058; L(Test): 1.069845199584961\n",
            "Epoch 206/1000: L(Train): 1.1375114917755127; L(Test): 1.069061517715454\n",
            "Epoch 207/1000: L(Train): 1.1388198137283325; L(Test): 1.0703723430633545\n",
            "Epoch 208/1000: L(Train): 1.1164265871047974; L(Test): 1.0658479928970337\n",
            "Epoch 209/1000: L(Train): 1.1146529912948608; L(Test): 1.0622658729553223\n",
            "Epoch 210/1000: L(Train): 1.1084179878234863; L(Test): 1.0643548965454102\n",
            "Epoch 211/1000: L(Train): 1.1334096193313599; L(Test): 1.0596022605895996\n",
            "Epoch 212/1000: L(Train): 1.1359834671020508; L(Test): 1.0573257207870483\n",
            "Epoch 213/1000: L(Train): 1.1441986560821533; L(Test): 1.0582027435302734\n",
            "Epoch 214/1000: L(Train): 1.1141468286514282; L(Test): 1.0562117099761963\n",
            "Epoch 215/1000: L(Train): 1.1422736644744873; L(Test): 1.0534474849700928\n",
            "Epoch 216/1000: L(Train): 1.111303448677063; L(Test): 1.0497361421585083\n",
            "Epoch 217/1000: L(Train): 1.1425045728683472; L(Test): 1.0474374294281006\n",
            "Epoch 218/1000: L(Train): 1.1047704219818115; L(Test): 1.0485270023345947\n",
            "Epoch 219/1000: L(Train): 1.1302374601364136; L(Test): 1.047928810119629\n",
            "Epoch 220/1000: L(Train): 1.1333616971969604; L(Test): 1.0451632738113403\n",
            "Epoch 221/1000: L(Train): 1.133365511894226; L(Test): 1.043091893196106\n",
            "Epoch 222/1000: L(Train): 1.083341121673584; L(Test): 1.0396983623504639\n",
            "Epoch 223/1000: L(Train): 1.1152267456054688; L(Test): 1.0373175144195557\n",
            "Epoch 224/1000: L(Train): 1.1143913269042969; L(Test): 1.038235068321228\n",
            "Epoch 225/1000: L(Train): 1.0952398777008057; L(Test): 1.0368539094924927\n",
            "Epoch 226/1000: L(Train): 1.0853289365768433; L(Test): 1.0357460975646973\n",
            "Epoch 227/1000: L(Train): 1.098210334777832; L(Test): 1.03450608253479\n",
            "Epoch 228/1000: L(Train): 1.1231178045272827; L(Test): 1.032869577407837\n",
            "Epoch 229/1000: L(Train): 1.1166115999221802; L(Test): 1.0323469638824463\n",
            "Epoch 230/1000: L(Train): 1.1087979078292847; L(Test): 1.0312480926513672\n",
            "Epoch 231/1000: L(Train): 1.1088382005691528; L(Test): 1.030874252319336\n",
            "Epoch 232/1000: L(Train): 1.1103650331497192; L(Test): 1.0269359350204468\n",
            "Epoch 233/1000: L(Train): 1.1048495769500732; L(Test): 1.025809407234192\n",
            "Epoch 234/1000: L(Train): 1.1054103374481201; L(Test): 1.0234389305114746\n",
            "Epoch 235/1000: L(Train): 1.0956799983978271; L(Test): 1.0239737033843994\n",
            "Epoch 236/1000: L(Train): 1.0972920656204224; L(Test): 1.0265713930130005\n",
            "Epoch 237/1000: L(Train): 1.0797932147979736; L(Test): 1.0232809782028198\n",
            "Epoch 238/1000: L(Train): 1.1221280097961426; L(Test): 1.0178661346435547\n",
            "Epoch 239/1000: L(Train): 1.0840085744857788; L(Test): 1.018262505531311\n",
            "Epoch 240/1000: L(Train): 1.0897411108016968; L(Test): 1.0187150239944458\n",
            "Epoch 241/1000: L(Train): 1.106510877609253; L(Test): 1.0145001411437988\n",
            "Epoch 242/1000: L(Train): 1.0768988132476807; L(Test): 1.0124844312667847\n",
            "Epoch 243/1000: L(Train): 1.0938576459884644; L(Test): 1.0127887725830078\n",
            "Epoch 244/1000: L(Train): 1.0764623880386353; L(Test): 1.011148452758789\n",
            "Epoch 245/1000: L(Train): 1.0797377824783325; L(Test): 1.0104117393493652\n",
            "Epoch 246/1000: L(Train): 1.0715491771697998; L(Test): 1.007529377937317\n",
            "Epoch 247/1000: L(Train): 1.0911922454833984; L(Test): 1.007863998413086\n",
            "Epoch 248/1000: L(Train): 1.0984396934509277; L(Test): 1.0049749612808228\n",
            "Epoch 249/1000: L(Train): 1.0853465795516968; L(Test): 0.9984045028686523\n",
            "Epoch 250/1000: L(Train): 1.0913429260253906; L(Test): 0.9970604181289673\n",
            "Epoch 251/1000: L(Train): 1.09878408908844; L(Test): 1.0007981061935425\n",
            "Epoch 252/1000: L(Train): 1.103295922279358; L(Test): 0.998289942741394\n",
            "Epoch 253/1000: L(Train): 1.1027299165725708; L(Test): 0.9983875155448914\n",
            "Epoch 254/1000: L(Train): 1.0718332529067993; L(Test): 0.9987859129905701\n",
            "Epoch 255/1000: L(Train): 1.089633822441101; L(Test): 0.9980974197387695\n",
            "Epoch 256/1000: L(Train): 1.084769368171692; L(Test): 0.999212920665741\n",
            "Epoch 257/1000: L(Train): 1.0829520225524902; L(Test): 0.9940429925918579\n",
            "Epoch 258/1000: L(Train): 1.072245717048645; L(Test): 0.9959332346916199\n",
            "Epoch 259/1000: L(Train): 1.0832951068878174; L(Test): 0.9965040683746338\n",
            "Epoch 260/1000: L(Train): 1.088376760482788; L(Test): 0.9952409267425537\n",
            "Epoch 261/1000: L(Train): 1.083846092224121; L(Test): 0.9938225150108337\n",
            "Epoch 262/1000: L(Train): 1.0842341184616089; L(Test): 0.9913289546966553\n",
            "Epoch 263/1000: L(Train): 1.0755064487457275; L(Test): 0.9895660281181335\n",
            "Epoch 264/1000: L(Train): 1.0886714458465576; L(Test): 0.9887170791625977\n",
            "Epoch 265/1000: L(Train): 1.076612949371338; L(Test): 0.9839876890182495\n",
            "Epoch 266/1000: L(Train): 1.0599448680877686; L(Test): 0.980888843536377\n",
            "Epoch 267/1000: L(Train): 1.0968977212905884; L(Test): 0.9794958233833313\n",
            "Epoch 268/1000: L(Train): 1.0717527866363525; L(Test): 0.9801391959190369\n",
            "Epoch 269/1000: L(Train): 1.0778462886810303; L(Test): 0.9818646907806396\n",
            "Epoch 270/1000: L(Train): 1.0451877117156982; L(Test): 0.979987621307373\n",
            "Epoch 271/1000: L(Train): 1.0812737941741943; L(Test): 0.9784567952156067\n",
            "Epoch 272/1000: L(Train): 1.038955807685852; L(Test): 0.9777501225471497\n",
            "Epoch 273/1000: L(Train): 1.0657405853271484; L(Test): 0.9793723821640015\n",
            "Epoch 274/1000: L(Train): 1.0833226442337036; L(Test): 0.974869966506958\n",
            "Epoch 275/1000: L(Train): 1.0840808153152466; L(Test): 0.9789881706237793\n",
            "Epoch 276/1000: L(Train): 1.0791512727737427; L(Test): 0.9749605655670166\n",
            "Epoch 277/1000: L(Train): 1.076037049293518; L(Test): 0.9775635600090027\n",
            "Epoch 278/1000: L(Train): 1.0669498443603516; L(Test): 0.9769771695137024\n",
            "Epoch 279/1000: L(Train): 1.0926752090454102; L(Test): 0.9719918966293335\n",
            "Epoch 280/1000: L(Train): 1.0745378732681274; L(Test): 0.9699298143386841\n",
            "Epoch 281/1000: L(Train): 1.0604994297027588; L(Test): 0.9725578427314758\n",
            "Epoch 282/1000: L(Train): 1.0514827966690063; L(Test): 0.9719236493110657\n",
            "Epoch 283/1000: L(Train): 1.0465798377990723; L(Test): 0.9778924584388733\n",
            "Epoch 284/1000: L(Train): 1.088290810585022; L(Test): 0.9766966700553894\n",
            "Epoch 285/1000: L(Train): 1.0478627681732178; L(Test): 0.9733187556266785\n",
            "Epoch 286/1000: L(Train): 1.0712999105453491; L(Test): 0.9742127656936646\n",
            "Epoch 287/1000: L(Train): 1.075078010559082; L(Test): 0.9696664214134216\n",
            "Epoch 288/1000: L(Train): 1.0737155675888062; L(Test): 0.9676006436347961\n",
            "Epoch 289/1000: L(Train): 1.0705677270889282; L(Test): 0.9675382375717163\n",
            "Epoch 290/1000: L(Train): 1.0847680568695068; L(Test): 0.9672473669052124\n",
            "Epoch 291/1000: L(Train): 1.0655739307403564; L(Test): 0.9630856513977051\n",
            "Epoch 292/1000: L(Train): 1.0475003719329834; L(Test): 0.9641542434692383\n",
            "Epoch 293/1000: L(Train): 1.0481584072113037; L(Test): 0.967987596988678\n",
            "Epoch 294/1000: L(Train): 1.0561563968658447; L(Test): 0.9643576741218567\n",
            "Epoch 295/1000: L(Train): 1.071399211883545; L(Test): 0.9618127942085266\n",
            "Epoch 296/1000: L(Train): 1.0648866891860962; L(Test): 0.9625862836837769\n",
            "Epoch 297/1000: L(Train): 1.0551323890686035; L(Test): 0.9650400280952454\n",
            "Epoch 298/1000: L(Train): 1.0680967569351196; L(Test): 0.9644362330436707\n",
            "Epoch 299/1000: L(Train): 1.0745878219604492; L(Test): 0.9602238535881042\n",
            "Epoch 300/1000: L(Train): 1.0613689422607422; L(Test): 0.9599278569221497\n",
            "Epoch 301/1000: L(Train): 1.0260456800460815; L(Test): 0.9620658755302429\n",
            "Epoch 302/1000: L(Train): 1.0686341524124146; L(Test): 0.9593542814254761\n",
            "Epoch 303/1000: L(Train): 1.054971694946289; L(Test): 0.9606128334999084\n",
            "Epoch 304/1000: L(Train): 1.0611257553100586; L(Test): 0.9617462158203125\n",
            "Epoch 305/1000: L(Train): 1.0545259714126587; L(Test): 0.9559140801429749\n",
            "Epoch 306/1000: L(Train): 1.0551265478134155; L(Test): 0.9563954472541809\n",
            "Epoch 307/1000: L(Train): 1.0591846704483032; L(Test): 0.9590713977813721\n",
            "Epoch 308/1000: L(Train): 1.0447659492492676; L(Test): 0.9593408107757568\n",
            "Epoch 309/1000: L(Train): 1.0732523202896118; L(Test): 0.958908200263977\n",
            "Epoch 310/1000: L(Train): 1.0694303512573242; L(Test): 0.9587323069572449\n",
            "Epoch 311/1000: L(Train): 1.0388187170028687; L(Test): 0.9542905688285828\n",
            "Epoch 312/1000: L(Train): 1.0585510730743408; L(Test): 0.950196385383606\n",
            "Epoch 313/1000: L(Train): 1.0398069620132446; L(Test): 0.9514350295066833\n",
            "Epoch 314/1000: L(Train): 1.0440583229064941; L(Test): 0.9494819045066833\n",
            "Epoch 315/1000: L(Train): 1.0453052520751953; L(Test): 0.9501806497573853\n",
            "Epoch 316/1000: L(Train): 1.0585050582885742; L(Test): 0.9521397352218628\n",
            "Epoch 317/1000: L(Train): 1.0452988147735596; L(Test): 0.9473901391029358\n",
            "Epoch 318/1000: L(Train): 1.0497325658798218; L(Test): 0.9486587047576904\n",
            "Epoch 319/1000: L(Train): 1.0634387731552124; L(Test): 0.9519686102867126\n",
            "Epoch 320/1000: L(Train): 1.0652520656585693; L(Test): 0.9450289011001587\n",
            "Epoch 321/1000: L(Train): 1.0418901443481445; L(Test): 0.944799542427063\n",
            "Epoch 322/1000: L(Train): 1.0448241233825684; L(Test): 0.9489665627479553\n",
            "Epoch 323/1000: L(Train): 1.0611001253128052; L(Test): 0.9480620622634888\n",
            "Epoch 324/1000: L(Train): 1.0429444313049316; L(Test): 0.9459388852119446\n",
            "Epoch 325/1000: L(Train): 1.0553417205810547; L(Test): 0.9450162053108215\n",
            "Epoch 326/1000: L(Train): 1.0422183275222778; L(Test): 0.9390509724617004\n",
            "Epoch 327/1000: L(Train): 1.0536437034606934; L(Test): 0.9374909996986389\n",
            "Epoch 328/1000: L(Train): 1.0301374197006226; L(Test): 0.9385032653808594\n",
            "Epoch 329/1000: L(Train): 1.044671654701233; L(Test): 0.9409700036048889\n",
            "Epoch 330/1000: L(Train): 1.0379434823989868; L(Test): 0.9406293034553528\n",
            "Epoch 331/1000: L(Train): 1.034125804901123; L(Test): 0.9388678073883057\n",
            "Epoch 332/1000: L(Train): 1.037886142730713; L(Test): 0.9372237920761108\n",
            "Epoch 333/1000: L(Train): 1.0379164218902588; L(Test): 0.9342917203903198\n",
            "Epoch 334/1000: L(Train): 1.0230969190597534; L(Test): 0.9370196461677551\n",
            "Epoch 335/1000: L(Train): 1.046822190284729; L(Test): 0.9370105862617493\n",
            "Epoch 336/1000: L(Train): 1.0503612756729126; L(Test): 0.9356957077980042\n",
            "Epoch 337/1000: L(Train): 1.0842918157577515; L(Test): 0.9354982376098633\n",
            "Epoch 338/1000: L(Train): 1.0429441928863525; L(Test): 0.9351984858512878\n",
            "Epoch 339/1000: L(Train): 1.0621423721313477; L(Test): 0.9325231909751892\n",
            "Epoch 340/1000: L(Train): 1.0552582740783691; L(Test): 0.9302264451980591\n",
            "Epoch 341/1000: L(Train): 1.0409475564956665; L(Test): 0.9325487613677979\n",
            "Epoch 342/1000: L(Train): 1.0264307260513306; L(Test): 0.9353916049003601\n",
            "Epoch 343/1000: L(Train): 1.0393092632293701; L(Test): 0.9335833787918091\n",
            "Epoch 344/1000: L(Train): 1.0544095039367676; L(Test): 0.9349068403244019\n",
            "Epoch 345/1000: L(Train): 1.0344793796539307; L(Test): 0.9299265146255493\n",
            "Epoch 346/1000: L(Train): 1.0537725687026978; L(Test): 0.9261071681976318\n",
            "Epoch 347/1000: L(Train): 1.0181647539138794; L(Test): 0.9286759495735168\n",
            "Epoch 348/1000: L(Train): 1.018717646598816; L(Test): 0.9283735752105713\n",
            "Epoch 349/1000: L(Train): 1.0155194997787476; L(Test): 0.9245133399963379\n",
            "Epoch 350/1000: L(Train): 1.0296928882598877; L(Test): 0.9216702580451965\n",
            "Epoch 351/1000: L(Train): 1.0279778242111206; L(Test): 0.9249604940414429\n",
            "Epoch 352/1000: L(Train): 1.0392067432403564; L(Test): 0.9227698445320129\n",
            "Epoch 353/1000: L(Train): 1.0367913246154785; L(Test): 0.9252657294273376\n",
            "Epoch 354/1000: L(Train): 1.0249829292297363; L(Test): 0.9238480925559998\n",
            "Epoch 355/1000: L(Train): 1.0274549722671509; L(Test): 0.9224340319633484\n",
            "Epoch 356/1000: L(Train): 1.022810697555542; L(Test): 0.921157956123352\n",
            "Epoch 357/1000: L(Train): 1.0348060131072998; L(Test): 0.9221879243850708\n",
            "Epoch 358/1000: L(Train): 1.0106092691421509; L(Test): 0.9205870628356934\n",
            "Epoch 359/1000: L(Train): 1.006062626838684; L(Test): 0.9199818968772888\n",
            "Epoch 360/1000: L(Train): 1.0314651727676392; L(Test): 0.9241361618041992\n",
            "Epoch 361/1000: L(Train): 1.0284900665283203; L(Test): 0.9268139600753784\n",
            "Epoch 362/1000: L(Train): 1.039427638053894; L(Test): 0.923640251159668\n",
            "Epoch 363/1000: L(Train): 1.0618749856948853; L(Test): 0.9227985739707947\n",
            "Epoch 364/1000: L(Train): 1.0271613597869873; L(Test): 0.9243164658546448\n",
            "Epoch 365/1000: L(Train): 1.0439337491989136; L(Test): 0.9265043139457703\n",
            "Epoch 366/1000: L(Train): 1.0419856309890747; L(Test): 0.9278973937034607\n",
            "Epoch 367/1000: L(Train): 1.0120924711227417; L(Test): 0.9327504634857178\n",
            "Epoch 368/1000: L(Train): 1.0392590761184692; L(Test): 0.9292470812797546\n",
            "Epoch 369/1000: L(Train): 1.0204771757125854; L(Test): 0.927400529384613\n",
            "Epoch 370/1000: L(Train): 1.0194578170776367; L(Test): 0.9308483004570007\n",
            "Epoch 371/1000: L(Train): 1.0159096717834473; L(Test): 0.9266403317451477\n",
            "Epoch 372/1000: L(Train): 1.0343338251113892; L(Test): 0.9287598133087158\n",
            "Epoch 373/1000: L(Train): 1.0388926267623901; L(Test): 0.9227929711341858\n",
            "Epoch 374/1000: L(Train): 1.02580726146698; L(Test): 0.9220936894416809\n",
            "Epoch 375/1000: L(Train): 1.0251117944717407; L(Test): 0.9220426678657532\n",
            "Epoch 376/1000: L(Train): 1.0225131511688232; L(Test): 0.9263265132904053\n",
            "Epoch 377/1000: L(Train): 1.0142155885696411; L(Test): 0.9349302053451538\n",
            "Epoch 378/1000: L(Train): 1.060383915901184; L(Test): 0.9186866879463196\n",
            "Epoch 379/1000: L(Train): 1.034979224205017; L(Test): 0.9192578792572021\n",
            "Epoch 380/1000: L(Train): 1.0210524797439575; L(Test): 0.9227240681648254\n",
            "Epoch 381/1000: L(Train): 1.0172165632247925; L(Test): 0.9167143106460571\n",
            "Epoch 382/1000: L(Train): 1.0468409061431885; L(Test): 0.9182772040367126\n",
            "Epoch 383/1000: L(Train): 1.0301722288131714; L(Test): 0.917687714099884\n",
            "Epoch 384/1000: L(Train): 1.0183154344558716; L(Test): 0.9132019877433777\n",
            "Epoch 385/1000: L(Train): 1.025407075881958; L(Test): 0.9131532311439514\n",
            "Epoch 386/1000: L(Train): 1.0117727518081665; L(Test): 0.9095871448516846\n",
            "Epoch 387/1000: L(Train): 1.0118861198425293; L(Test): 0.9129628539085388\n",
            "Epoch 388/1000: L(Train): 1.0095951557159424; L(Test): 0.9163858294487\n",
            "Epoch 389/1000: L(Train): 1.029518485069275; L(Test): 0.9088535308837891\n",
            "Epoch 390/1000: L(Train): 1.0027519464492798; L(Test): 0.9109352231025696\n",
            "Epoch 391/1000: L(Train): 1.0488700866699219; L(Test): 0.9108218550682068\n",
            "Epoch 392/1000: L(Train): 1.0299166440963745; L(Test): 0.9059582352638245\n",
            "Epoch 393/1000: L(Train): 1.0377516746520996; L(Test): 0.9068096280097961\n",
            "Epoch 394/1000: L(Train): 1.0241121053695679; L(Test): 0.9072359204292297\n",
            "Epoch 395/1000: L(Train): 1.0201598405838013; L(Test): 0.9064536690711975\n",
            "Epoch 396/1000: L(Train): 1.0133111476898193; L(Test): 0.905088484287262\n",
            "Epoch 397/1000: L(Train): 1.0262614488601685; L(Test): 0.9043209552764893\n",
            "Epoch 398/1000: L(Train): 1.0188199281692505; L(Test): 0.9031615853309631\n",
            "Epoch 399/1000: L(Train): 1.0062133073806763; L(Test): 0.9062968492507935\n",
            "Epoch 400/1000: L(Train): 1.0145528316497803; L(Test): 0.9113197922706604\n",
            "Epoch 401/1000: L(Train): 1.029839277267456; L(Test): 0.9067429304122925\n",
            "Epoch 402/1000: L(Train): 1.0146790742874146; L(Test): 0.9077123403549194\n",
            "Epoch 403/1000: L(Train): 1.035829782485962; L(Test): 0.9115874171257019\n",
            "Epoch 404/1000: L(Train): 1.004675269126892; L(Test): 0.906281054019928\n",
            "Epoch 405/1000: L(Train): 1.0154623985290527; L(Test): 0.9019774198532104\n",
            "Epoch 406/1000: L(Train): 1.0157278776168823; L(Test): 0.9026777744293213\n",
            "Epoch 407/1000: L(Train): 1.022172451019287; L(Test): 0.9037349224090576\n",
            "Epoch 408/1000: L(Train): 1.0273264646530151; L(Test): 0.9052717089653015\n",
            "Epoch 409/1000: L(Train): 1.0343736410140991; L(Test): 0.906486988067627\n",
            "Epoch 410/1000: L(Train): 0.9869061708450317; L(Test): 0.9013766646385193\n",
            "Epoch 411/1000: L(Train): 1.035656452178955; L(Test): 0.8976039886474609\n",
            "Epoch 412/1000: L(Train): 1.0129597187042236; L(Test): 0.8993752598762512\n",
            "Epoch 413/1000: L(Train): 0.993400514125824; L(Test): 0.9003666043281555\n",
            "Epoch 414/1000: L(Train): 1.0115282535552979; L(Test): 0.8984682559967041\n",
            "Epoch 415/1000: L(Train): 1.0240122079849243; L(Test): 0.8963757753372192\n",
            "Epoch 416/1000: L(Train): 1.019822359085083; L(Test): 0.8970991969108582\n",
            "Epoch 417/1000: L(Train): 1.011021375656128; L(Test): 0.8951740264892578\n",
            "Epoch 418/1000: L(Train): 1.0297844409942627; L(Test): 0.8939710855484009\n",
            "Epoch 419/1000: L(Train): 1.0059443712234497; L(Test): 0.8941354751586914\n",
            "Epoch 420/1000: L(Train): 1.0084067583084106; L(Test): 0.8926378488540649\n",
            "Epoch 421/1000: L(Train): 1.018080234527588; L(Test): 0.8919325470924377\n",
            "Epoch 422/1000: L(Train): 1.0086899995803833; L(Test): 0.8952459692955017\n",
            "Epoch 423/1000: L(Train): 1.020387887954712; L(Test): 0.8954020738601685\n",
            "Epoch 424/1000: L(Train): 0.9936673045158386; L(Test): 0.8919224143028259\n",
            "Epoch 425/1000: L(Train): 1.0074232816696167; L(Test): 0.8909253478050232\n",
            "Epoch 426/1000: L(Train): 1.0193352699279785; L(Test): 0.8891348242759705\n",
            "Epoch 427/1000: L(Train): 1.0009874105453491; L(Test): 0.887881875038147\n",
            "Epoch 428/1000: L(Train): 1.006771206855774; L(Test): 0.8862924575805664\n",
            "Epoch 429/1000: L(Train): 0.9767910838127136; L(Test): 0.8859440684318542\n",
            "Epoch 430/1000: L(Train): 1.0222872495651245; L(Test): 0.888393759727478\n",
            "Epoch 431/1000: L(Train): 1.0210925340652466; L(Test): 0.8887673020362854\n",
            "Epoch 432/1000: L(Train): 1.0075494050979614; L(Test): 0.8874853253364563\n",
            "Epoch 433/1000: L(Train): 1.0229730606079102; L(Test): 0.8844060301780701\n",
            "Epoch 434/1000: L(Train): 0.9944714903831482; L(Test): 0.8897420763969421\n",
            "Epoch 435/1000: L(Train): 1.0039184093475342; L(Test): 0.8910056948661804\n",
            "Epoch 436/1000: L(Train): 1.0437954664230347; L(Test): 0.8879601955413818\n",
            "Epoch 437/1000: L(Train): 0.9886112809181213; L(Test): 0.8956828713417053\n",
            "Epoch 438/1000: L(Train): 1.0002102851867676; L(Test): 0.8932262063026428\n",
            "Epoch 439/1000: L(Train): 1.0177503824234009; L(Test): 0.8894377946853638\n",
            "Epoch 440/1000: L(Train): 1.0236009359359741; L(Test): 0.8936775326728821\n",
            "Epoch 441/1000: L(Train): 1.0223487615585327; L(Test): 0.8884999752044678\n",
            "Epoch 442/1000: L(Train): 0.9982548356056213; L(Test): 0.8851177096366882\n",
            "Epoch 443/1000: L(Train): 1.0167275667190552; L(Test): 0.8843039870262146\n",
            "Epoch 444/1000: L(Train): 0.9961462616920471; L(Test): 0.885623574256897\n",
            "Epoch 445/1000: L(Train): 0.9886631369590759; L(Test): 0.8868240118026733\n",
            "Epoch 446/1000: L(Train): 1.011939525604248; L(Test): 0.8876969218254089\n",
            "Epoch 447/1000: L(Train): 0.9907259345054626; L(Test): 0.8874351978302002\n",
            "Epoch 448/1000: L(Train): 0.9974341988563538; L(Test): 0.8858957290649414\n",
            "Epoch 449/1000: L(Train): 1.0194941759109497; L(Test): 0.8859701156616211\n",
            "Epoch 450/1000: L(Train): 0.9982824325561523; L(Test): 0.8849729895591736\n",
            "Epoch 451/1000: L(Train): 1.0147616863250732; L(Test): 0.878995418548584\n",
            "Epoch 452/1000: L(Train): 1.0087114572525024; L(Test): 0.8795680999755859\n",
            "Epoch 453/1000: L(Train): 0.9969907999038696; L(Test): 0.8801896572113037\n",
            "Epoch 454/1000: L(Train): 0.9707506895065308; L(Test): 0.8833937048912048\n",
            "Epoch 455/1000: L(Train): 1.002888798713684; L(Test): 0.885922908782959\n",
            "Epoch 456/1000: L(Train): 0.9931305050849915; L(Test): 0.8846156597137451\n",
            "Epoch 457/1000: L(Train): 0.9813600182533264; L(Test): 0.8785131573677063\n",
            "Epoch 458/1000: L(Train): 1.0001966953277588; L(Test): 0.8776182532310486\n",
            "Epoch 459/1000: L(Train): 0.9984472393989563; L(Test): 0.8766545653343201\n",
            "Epoch 460/1000: L(Train): 0.994428277015686; L(Test): 0.8773424625396729\n",
            "Epoch 461/1000: L(Train): 1.0239720344543457; L(Test): 0.8778378367424011\n",
            "Epoch 462/1000: L(Train): 1.0097439289093018; L(Test): 0.8814370632171631\n",
            "Epoch 463/1000: L(Train): 0.9971239566802979; L(Test): 0.8818720579147339\n",
            "Epoch 464/1000: L(Train): 1.0050435066223145; L(Test): 0.8816080689430237\n",
            "Epoch 465/1000: L(Train): 1.0125540494918823; L(Test): 0.8814017176628113\n",
            "Epoch 466/1000: L(Train): 0.9961807131767273; L(Test): 0.8817929029464722\n",
            "Epoch 467/1000: L(Train): 0.9965395331382751; L(Test): 0.8781909942626953\n",
            "Epoch 468/1000: L(Train): 0.9726072549819946; L(Test): 0.8764159083366394\n",
            "Epoch 469/1000: L(Train): 0.991460382938385; L(Test): 0.881775975227356\n",
            "Epoch 470/1000: L(Train): 0.9889560341835022; L(Test): 0.8839516639709473\n",
            "Epoch 471/1000: L(Train): 1.0134905576705933; L(Test): 0.8850662112236023\n",
            "Epoch 472/1000: L(Train): 1.0203133821487427; L(Test): 0.8809276223182678\n",
            "Epoch 473/1000: L(Train): 1.0091588497161865; L(Test): 0.881523609161377\n",
            "Epoch 474/1000: L(Train): 0.9981132745742798; L(Test): 0.8819518089294434\n",
            "Epoch 475/1000: L(Train): 0.987419068813324; L(Test): 0.8756228089332581\n",
            "Epoch 476/1000: L(Train): 1.00882089138031; L(Test): 0.8793217539787292\n",
            "Epoch 477/1000: L(Train): 0.994224488735199; L(Test): 0.881506085395813\n",
            "Epoch 478/1000: L(Train): 0.9883120059967041; L(Test): 0.8792473077774048\n",
            "Epoch 479/1000: L(Train): 1.0146914720535278; L(Test): 0.8822831511497498\n",
            "Epoch 480/1000: L(Train): 1.000412106513977; L(Test): 0.8823053240776062\n",
            "Epoch 481/1000: L(Train): 1.0038330554962158; L(Test): 0.8788107633590698\n",
            "Epoch 482/1000: L(Train): 0.9982421398162842; L(Test): 0.8770616054534912\n",
            "Epoch 483/1000: L(Train): 0.9874400496482849; L(Test): 0.8811728358268738\n",
            "Epoch 484/1000: L(Train): 1.0182154178619385; L(Test): 0.8880940079689026\n",
            "Epoch 485/1000: L(Train): 1.0204603672027588; L(Test): 0.886268675327301\n",
            "Epoch 486/1000: L(Train): 0.9981971979141235; L(Test): 0.8762766718864441\n",
            "Epoch 487/1000: L(Train): 1.0093284845352173; L(Test): 0.8781445026397705\n",
            "Epoch 488/1000: L(Train): 0.9788010120391846; L(Test): 0.8794870376586914\n",
            "Epoch 489/1000: L(Train): 1.0017774105072021; L(Test): 0.8756389021873474\n",
            "Epoch 490/1000: L(Train): 0.9889771342277527; L(Test): 0.8782349824905396\n",
            "Epoch 491/1000: L(Train): 1.0170989036560059; L(Test): 0.8794875144958496\n",
            "Epoch 492/1000: L(Train): 1.000781536102295; L(Test): 0.8783290982246399\n",
            "Epoch 493/1000: L(Train): 1.0218122005462646; L(Test): 0.8819169402122498\n",
            "Epoch 494/1000: L(Train): 0.9969659447669983; L(Test): 0.8798139095306396\n",
            "Epoch 495/1000: L(Train): 1.0093556642532349; L(Test): 0.8729997873306274\n",
            "Epoch 496/1000: L(Train): 0.9802635908126831; L(Test): 0.8793242573738098\n",
            "Epoch 497/1000: L(Train): 0.993011474609375; L(Test): 0.8819115161895752\n",
            "Epoch 498/1000: L(Train): 0.9968258738517761; L(Test): 0.8780177235603333\n",
            "Epoch 499/1000: L(Train): 0.9977666735649109; L(Test): 0.8729832768440247\n",
            "Epoch 500/1000: L(Train): 0.988802969455719; L(Test): 0.8716016411781311\n",
            "Epoch 501/1000: L(Train): 0.9912670254707336; L(Test): 0.8740281462669373\n",
            "Epoch 502/1000: L(Train): 0.994376540184021; L(Test): 0.8738703727722168\n",
            "Epoch 503/1000: L(Train): 0.9770415425300598; L(Test): 0.8742137551307678\n",
            "Epoch 504/1000: L(Train): 1.0031359195709229; L(Test): 0.875673234462738\n",
            "Epoch 505/1000: L(Train): 1.0029189586639404; L(Test): 0.8707359433174133\n",
            "Epoch 506/1000: L(Train): 1.0068223476409912; L(Test): 0.8722554445266724\n",
            "Epoch 507/1000: L(Train): 1.0037285089492798; L(Test): 0.8774830102920532\n",
            "Epoch 508/1000: L(Train): 0.9852818846702576; L(Test): 0.8781171441078186\n",
            "Epoch 509/1000: L(Train): 1.010101079940796; L(Test): 0.871652364730835\n",
            "Epoch 510/1000: L(Train): 1.0087107419967651; L(Test): 0.8691179752349854\n",
            "Epoch 511/1000: L(Train): 0.9926760792732239; L(Test): 0.8739082217216492\n",
            "Epoch 512/1000: L(Train): 1.016926646232605; L(Test): 0.872736394405365\n",
            "Epoch 513/1000: L(Train): 1.0194758176803589; L(Test): 0.868475615978241\n",
            "Epoch 514/1000: L(Train): 0.9756802320480347; L(Test): 0.8741888403892517\n",
            "Epoch 515/1000: L(Train): 1.0278083086013794; L(Test): 0.8763103485107422\n",
            "Epoch 516/1000: L(Train): 1.011155605316162; L(Test): 0.8726006150245667\n",
            "Epoch 517/1000: L(Train): 0.988381028175354; L(Test): 0.8727720379829407\n",
            "Epoch 518/1000: L(Train): 1.0011831521987915; L(Test): 0.8768584132194519\n",
            "Epoch 519/1000: L(Train): 0.9936004877090454; L(Test): 0.8713433146476746\n",
            "Epoch 520/1000: L(Train): 0.9761555790901184; L(Test): 0.867942750453949\n",
            "Epoch 521/1000: L(Train): 0.9950848817825317; L(Test): 0.8676794171333313\n",
            "Epoch 522/1000: L(Train): 0.9784179925918579; L(Test): 0.8652539253234863\n",
            "Epoch 523/1000: L(Train): 0.9795516133308411; L(Test): 0.8685545325279236\n",
            "Epoch 524/1000: L(Train): 0.9701192378997803; L(Test): 0.8733721375465393\n",
            "Epoch 525/1000: L(Train): 0.9862021207809448; L(Test): 0.8737477660179138\n",
            "Epoch 526/1000: L(Train): 0.9797925353050232; L(Test): 0.8733294606208801\n",
            "Epoch 527/1000: L(Train): 0.9871148467063904; L(Test): 0.8717971444129944\n",
            "Epoch 528/1000: L(Train): 1.0103546380996704; L(Test): 0.8732576370239258\n",
            "Epoch 529/1000: L(Train): 0.9737156629562378; L(Test): 0.8740968704223633\n",
            "Epoch 530/1000: L(Train): 1.0065081119537354; L(Test): 0.8693379163742065\n",
            "Epoch 531/1000: L(Train): 1.0041725635528564; L(Test): 0.8687024712562561\n",
            "Epoch 532/1000: L(Train): 0.9725819230079651; L(Test): 0.8714421987533569\n",
            "Epoch 533/1000: L(Train): 0.9825924634933472; L(Test): 0.8684042692184448\n",
            "Epoch 534/1000: L(Train): 0.9949511885643005; L(Test): 0.8629034757614136\n",
            "Epoch 535/1000: L(Train): 0.9893215894699097; L(Test): 0.8642151355743408\n",
            "Epoch 536/1000: L(Train): 0.986089825630188; L(Test): 0.8664035797119141\n",
            "Epoch 537/1000: L(Train): 1.0241129398345947; L(Test): 0.864495038986206\n",
            "Epoch 538/1000: L(Train): 1.0051454305648804; L(Test): 0.8651214241981506\n",
            "Epoch 539/1000: L(Train): 0.9782970547676086; L(Test): 0.8680298328399658\n",
            "Epoch 540/1000: L(Train): 1.0108433961868286; L(Test): 0.8680852055549622\n",
            "Epoch 541/1000: L(Train): 1.004560112953186; L(Test): 0.8705515265464783\n",
            "Epoch 542/1000: L(Train): 0.9774162173271179; L(Test): 0.8700563907623291\n",
            "Epoch 543/1000: L(Train): 0.9826470613479614; L(Test): 0.8688750267028809\n",
            "Epoch 544/1000: L(Train): 1.0018185377120972; L(Test): 0.8695101141929626\n",
            "Epoch 545/1000: L(Train): 1.0103402137756348; L(Test): 0.8689650297164917\n",
            "Epoch 546/1000: L(Train): 1.021446943283081; L(Test): 0.8705369234085083\n",
            "Epoch 547/1000: L(Train): 0.9862120151519775; L(Test): 0.872843861579895\n",
            "Epoch 548/1000: L(Train): 1.0013821125030518; L(Test): 0.8734599947929382\n",
            "Epoch 549/1000: L(Train): 0.9747397303581238; L(Test): 0.8715981841087341\n",
            "Epoch 550/1000: L(Train): 0.984160840511322; L(Test): 0.8708876967430115\n",
            "Epoch 551/1000: L(Train): 1.019655466079712; L(Test): 0.8701015114784241\n",
            "Epoch 552/1000: L(Train): 0.9668356776237488; L(Test): 0.8737502098083496\n",
            "Epoch 553/1000: L(Train): 1.0064090490341187; L(Test): 0.8748142719268799\n",
            "Epoch 554/1000: L(Train): 1.008670687675476; L(Test): 0.8758791089057922\n",
            "Epoch 555/1000: L(Train): 1.0032508373260498; L(Test): 0.8765798211097717\n",
            "Epoch 556/1000: L(Train): 1.0090397596359253; L(Test): 0.8766182065010071\n",
            "Epoch 557/1000: L(Train): 1.0143582820892334; L(Test): 0.8774160146713257\n",
            "Epoch 558/1000: L(Train): 1.010671615600586; L(Test): 0.8755778670310974\n",
            "Epoch 559/1000: L(Train): 0.9925775527954102; L(Test): 0.8727359771728516\n",
            "Epoch 560/1000: L(Train): 0.9801784157752991; L(Test): 0.8721452951431274\n",
            "Epoch 561/1000: L(Train): 0.9820429682731628; L(Test): 0.8707097172737122\n",
            "Epoch 562/1000: L(Train): 1.022560715675354; L(Test): 0.8698036074638367\n",
            "Epoch 563/1000: L(Train): 0.9653181433677673; L(Test): 0.8704812526702881\n",
            "Epoch 564/1000: L(Train): 0.9958926439285278; L(Test): 0.8707999587059021\n",
            "Epoch 565/1000: L(Train): 1.0109726190567017; L(Test): 0.8663060665130615\n",
            "Epoch 566/1000: L(Train): 0.9966132044792175; L(Test): 0.862236738204956\n",
            "Epoch 567/1000: L(Train): 0.9926021099090576; L(Test): 0.863798975944519\n",
            "Epoch 568/1000: L(Train): 0.9723437428474426; L(Test): 0.8656803965568542\n",
            "Epoch 569/1000: L(Train): 0.9932801127433777; L(Test): 0.8647056818008423\n",
            "Epoch 570/1000: L(Train): 0.9911542534828186; L(Test): 0.8589522242546082\n",
            "Epoch 571/1000: L(Train): 1.011315107345581; L(Test): 0.8562638759613037\n",
            "Epoch 572/1000: L(Train): 0.9733166694641113; L(Test): 0.8617919683456421\n",
            "Epoch 573/1000: L(Train): 0.9900298118591309; L(Test): 0.8605818152427673\n",
            "Epoch 574/1000: L(Train): 1.0028630495071411; L(Test): 0.8575926423072815\n",
            "Epoch 575/1000: L(Train): 0.9739578366279602; L(Test): 0.8588812947273254\n",
            "Epoch 576/1000: L(Train): 0.9774096012115479; L(Test): 0.8606371879577637\n",
            "Epoch 577/1000: L(Train): 0.9810104966163635; L(Test): 0.8638612031936646\n",
            "Epoch 578/1000: L(Train): 0.992565929889679; L(Test): 0.8663644194602966\n",
            "Epoch 579/1000: L(Train): 0.9934914708137512; L(Test): 0.8614858984947205\n",
            "Epoch 580/1000: L(Train): 0.9784708023071289; L(Test): 0.8582959175109863\n",
            "Epoch 581/1000: L(Train): 0.9894006848335266; L(Test): 0.8616015315055847\n",
            "Epoch 582/1000: L(Train): 0.972825288772583; L(Test): 0.8611141443252563\n",
            "Epoch 583/1000: L(Train): 1.0090224742889404; L(Test): 0.8596766591072083\n",
            "Epoch 584/1000: L(Train): 1.0000642538070679; L(Test): 0.857809841632843\n",
            "Epoch 585/1000: L(Train): 0.9815744757652283; L(Test): 0.8626822829246521\n",
            "Epoch 586/1000: L(Train): 0.9953199028968811; L(Test): 0.8644928932189941\n",
            "Epoch 587/1000: L(Train): 0.9901529550552368; L(Test): 0.855294942855835\n",
            "Epoch 588/1000: L(Train): 0.967714250087738; L(Test): 0.8549537658691406\n",
            "Epoch 589/1000: L(Train): 0.9926320910453796; L(Test): 0.8678769469261169\n",
            "Epoch 590/1000: L(Train): 0.9736299514770508; L(Test): 0.8678109645843506\n",
            "Epoch 591/1000: L(Train): 0.9962924718856812; L(Test): 0.865740180015564\n",
            "Epoch 592/1000: L(Train): 0.9939270615577698; L(Test): 0.8601779937744141\n",
            "Epoch 593/1000: L(Train): 0.9682040214538574; L(Test): 0.8652467727661133\n",
            "Epoch 594/1000: L(Train): 0.9941582083702087; L(Test): 0.8726479411125183\n",
            "Epoch 595/1000: L(Train): 1.005071997642517; L(Test): 0.8646766543388367\n",
            "Epoch 596/1000: L(Train): 1.0001150369644165; L(Test): 0.8634089231491089\n",
            "Epoch 597/1000: L(Train): 0.9945356845855713; L(Test): 0.8690247535705566\n",
            "Epoch 598/1000: L(Train): 0.996894896030426; L(Test): 0.8703504800796509\n",
            "Epoch 599/1000: L(Train): 0.9929193258285522; L(Test): 0.871533989906311\n",
            "Epoch 600/1000: L(Train): 1.0054833889007568; L(Test): 0.8718565106391907\n",
            "Epoch 601/1000: L(Train): 0.9687830209732056; L(Test): 0.8689068555831909\n",
            "Epoch 602/1000: L(Train): 0.9970137476921082; L(Test): 0.864947497844696\n",
            "Epoch 603/1000: L(Train): 0.9734085202217102; L(Test): 0.8613157868385315\n",
            "Epoch 604/1000: L(Train): 0.9905065894126892; L(Test): 0.8600285649299622\n",
            "Epoch 605/1000: L(Train): 1.0043878555297852; L(Test): 0.8615694046020508\n",
            "Epoch 606/1000: L(Train): 0.9983059763908386; L(Test): 0.8595700263977051\n",
            "Epoch 607/1000: L(Train): 0.9909080266952515; L(Test): 0.8579998016357422\n",
            "Epoch 608/1000: L(Train): 0.991075336933136; L(Test): 0.8623958230018616\n",
            "Epoch 609/1000: L(Train): 0.9989742040634155; L(Test): 0.8623251914978027\n",
            "Epoch 610/1000: L(Train): 0.9994596838951111; L(Test): 0.8565337061882019\n",
            "Epoch 611/1000: L(Train): 0.9896004796028137; L(Test): 0.8574234247207642\n",
            "Epoch 612/1000: L(Train): 0.974435031414032; L(Test): 0.8609359860420227\n",
            "Epoch 613/1000: L(Train): 0.9811809659004211; L(Test): 0.860001802444458\n",
            "Epoch 614/1000: L(Train): 0.9704976081848145; L(Test): 0.8603867292404175\n",
            "Epoch 615/1000: L(Train): 0.9746652841567993; L(Test): 0.8606281280517578\n",
            "Epoch 616/1000: L(Train): 0.9766237735748291; L(Test): 0.855903148651123\n",
            "Epoch 617/1000: L(Train): 0.9823758006095886; L(Test): 0.852256178855896\n",
            "Epoch 618/1000: L(Train): 0.9846894145011902; L(Test): 0.855472981929779\n",
            "Epoch 619/1000: L(Train): 0.9780867099761963; L(Test): 0.8567709922790527\n",
            "Epoch 620/1000: L(Train): 0.9935746192932129; L(Test): 0.8549475073814392\n",
            "Epoch 621/1000: L(Train): 0.9692512154579163; L(Test): 0.8537197709083557\n",
            "Epoch 622/1000: L(Train): 0.9690938591957092; L(Test): 0.8487131595611572\n",
            "Epoch 623/1000: L(Train): 0.9825158715248108; L(Test): 0.8457421660423279\n",
            "Epoch 624/1000: L(Train): 0.9732333421707153; L(Test): 0.8480373024940491\n",
            "Epoch 625/1000: L(Train): 0.9610112309455872; L(Test): 0.8493759632110596\n",
            "Epoch 626/1000: L(Train): 0.9916837811470032; L(Test): 0.8474627733230591\n",
            "Epoch 627/1000: L(Train): 0.9773061275482178; L(Test): 0.8448993563652039\n",
            "Epoch 628/1000: L(Train): 0.9925110340118408; L(Test): 0.8472022414207458\n",
            "Epoch 629/1000: L(Train): 0.9738361239433289; L(Test): 0.8465871810913086\n",
            "Epoch 630/1000: L(Train): 0.9430639147758484; L(Test): 0.8479774594306946\n",
            "Epoch 631/1000: L(Train): 0.956231951713562; L(Test): 0.848059892654419\n",
            "Epoch 632/1000: L(Train): 0.9930806159973145; L(Test): 0.8445786833763123\n",
            "Epoch 633/1000: L(Train): 0.9592310190200806; L(Test): 0.842735230922699\n",
            "Epoch 634/1000: L(Train): 0.9653165340423584; L(Test): 0.8425509929656982\n",
            "Epoch 635/1000: L(Train): 0.9565842151641846; L(Test): 0.8415793180465698\n",
            "Epoch 636/1000: L(Train): 0.9755271077156067; L(Test): 0.8374935388565063\n",
            "Epoch 637/1000: L(Train): 0.9608176946640015; L(Test): 0.8410413861274719\n",
            "Epoch 638/1000: L(Train): 0.965980052947998; L(Test): 0.8476262092590332\n",
            "Epoch 639/1000: L(Train): 0.975692093372345; L(Test): 0.8455478549003601\n",
            "Epoch 640/1000: L(Train): 0.9680161476135254; L(Test): 0.8419262170791626\n",
            "Epoch 641/1000: L(Train): 0.9768044352531433; L(Test): 0.8423282504081726\n",
            "Epoch 642/1000: L(Train): 0.9862695336341858; L(Test): 0.8420777320861816\n",
            "Epoch 643/1000: L(Train): 0.9849973917007446; L(Test): 0.8397614359855652\n",
            "Epoch 644/1000: L(Train): 0.9540755748748779; L(Test): 0.8352870941162109\n",
            "Epoch 645/1000: L(Train): 0.9678768515586853; L(Test): 0.8350498676300049\n",
            "Epoch 646/1000: L(Train): 0.9744085669517517; L(Test): 0.8418294191360474\n",
            "Epoch 647/1000: L(Train): 0.9765370488166809; L(Test): 0.8429346084594727\n",
            "Epoch 648/1000: L(Train): 1.0130200386047363; L(Test): 0.8405001759529114\n",
            "Epoch 649/1000: L(Train): 0.9785655736923218; L(Test): 0.8353996276855469\n",
            "Epoch 650/1000: L(Train): 0.9798225164413452; L(Test): 0.8336037993431091\n",
            "Epoch 651/1000: L(Train): 0.9867220520973206; L(Test): 0.8386518359184265\n",
            "Epoch 652/1000: L(Train): 0.966754138469696; L(Test): 0.8428385257720947\n",
            "Epoch 653/1000: L(Train): 0.9949294328689575; L(Test): 0.8379389643669128\n",
            "Epoch 654/1000: L(Train): 0.9806048274040222; L(Test): 0.8359419703483582\n",
            "Epoch 655/1000: L(Train): 0.9597748517990112; L(Test): 0.8409720063209534\n",
            "Epoch 656/1000: L(Train): 0.9776495695114136; L(Test): 0.8469196557998657\n",
            "Epoch 657/1000: L(Train): 0.9649620056152344; L(Test): 0.8519138097763062\n",
            "Epoch 658/1000: L(Train): 1.0064829587936401; L(Test): 0.8468539118766785\n",
            "Epoch 659/1000: L(Train): 0.9895851612091064; L(Test): 0.8411132097244263\n",
            "Epoch 660/1000: L(Train): 1.002274513244629; L(Test): 0.844185471534729\n",
            "Epoch 661/1000: L(Train): 0.9734554290771484; L(Test): 0.8492022156715393\n",
            "Epoch 662/1000: L(Train): 1.0106661319732666; L(Test): 0.8494901061058044\n",
            "Epoch 663/1000: L(Train): 1.0064690113067627; L(Test): 0.8471845984458923\n",
            "Epoch 664/1000: L(Train): 0.960669994354248; L(Test): 0.8489783406257629\n",
            "Epoch 665/1000: L(Train): 0.9716061353683472; L(Test): 0.8527527451515198\n",
            "Epoch 666/1000: L(Train): 0.9722355604171753; L(Test): 0.8515223264694214\n",
            "Epoch 667/1000: L(Train): 1.000514030456543; L(Test): 0.847377359867096\n",
            "Epoch 668/1000: L(Train): 0.9670326709747314; L(Test): 0.8451972603797913\n",
            "Epoch 669/1000: L(Train): 0.9923281073570251; L(Test): 0.8415074944496155\n",
            "Epoch 670/1000: L(Train): 0.9610397219657898; L(Test): 0.8423096537590027\n",
            "Epoch 671/1000: L(Train): 0.9947900176048279; L(Test): 0.8432261943817139\n",
            "Epoch 672/1000: L(Train): 0.9890511631965637; L(Test): 0.8436505198478699\n",
            "Epoch 673/1000: L(Train): 0.9658649563789368; L(Test): 0.8483537435531616\n",
            "Epoch 674/1000: L(Train): 0.9834799766540527; L(Test): 0.8562924265861511\n",
            "Epoch 675/1000: L(Train): 0.9656206965446472; L(Test): 0.8606283068656921\n",
            "Epoch 676/1000: L(Train): 0.9718651175498962; L(Test): 0.859982430934906\n",
            "Epoch 677/1000: L(Train): 1.004579782485962; L(Test): 0.8585158586502075\n",
            "Epoch 678/1000: L(Train): 1.0000662803649902; L(Test): 0.8570334911346436\n",
            "Epoch 679/1000: L(Train): 0.9966986179351807; L(Test): 0.8577815294265747\n",
            "Epoch 680/1000: L(Train): 0.9870738983154297; L(Test): 0.8562569618225098\n",
            "Epoch 681/1000: L(Train): 0.9967637062072754; L(Test): 0.8522528409957886\n",
            "Epoch 682/1000: L(Train): 0.9761006832122803; L(Test): 0.852983295917511\n",
            "Epoch 683/1000: L(Train): 0.9935207366943359; L(Test): 0.8548498749732971\n",
            "Epoch 684/1000: L(Train): 0.9682016968727112; L(Test): 0.850845217704773\n",
            "Epoch 685/1000: L(Train): 0.9794798493385315; L(Test): 0.8590583801269531\n",
            "Epoch 686/1000: L(Train): 0.9938859343528748; L(Test): 0.8614062070846558\n",
            "Epoch 687/1000: L(Train): 0.9950000643730164; L(Test): 0.8514343500137329\n",
            "Epoch 688/1000: L(Train): 1.0013303756713867; L(Test): 0.8493330478668213\n",
            "Epoch 689/1000: L(Train): 0.9683093428611755; L(Test): 0.8516162037849426\n",
            "Epoch 690/1000: L(Train): 0.965662956237793; L(Test): 0.847080409526825\n",
            "Epoch 691/1000: L(Train): 0.9865694642066956; L(Test): 0.8439006209373474\n",
            "Epoch 692/1000: L(Train): 0.9779435396194458; L(Test): 0.8460028171539307\n",
            "Epoch 693/1000: L(Train): 0.9668128490447998; L(Test): 0.8500806093215942\n",
            "Epoch 694/1000: L(Train): 0.9751589298248291; L(Test): 0.8491297960281372\n",
            "Epoch 695/1000: L(Train): 0.9694979190826416; L(Test): 0.8436715006828308\n",
            "Epoch 696/1000: L(Train): 0.9778795838356018; L(Test): 0.8448596596717834\n",
            "Epoch 697/1000: L(Train): 0.9554867148399353; L(Test): 0.8509195446968079\n",
            "Epoch 698/1000: L(Train): 0.9634416103363037; L(Test): 0.853024423122406\n",
            "Epoch 699/1000: L(Train): 0.9614020586013794; L(Test): 0.8462746739387512\n",
            "Epoch 700/1000: L(Train): 0.964592456817627; L(Test): 0.8390231728553772\n",
            "Epoch 701/1000: L(Train): 0.9648342728614807; L(Test): 0.8346906304359436\n",
            "Epoch 702/1000: L(Train): 0.9659566879272461; L(Test): 0.8373327255249023\n",
            "Epoch 703/1000: L(Train): 0.9835418462753296; L(Test): 0.8354476094245911\n",
            "Epoch 704/1000: L(Train): 0.9773587584495544; L(Test): 0.8301110863685608\n",
            "Epoch 705/1000: L(Train): 0.9426184296607971; L(Test): 0.8310494422912598\n",
            "Epoch 706/1000: L(Train): 0.9491772651672363; L(Test): 0.8381558060646057\n",
            "Epoch 707/1000: L(Train): 0.9725706577301025; L(Test): 0.8390302062034607\n",
            "Epoch 708/1000: L(Train): 0.9732196927070618; L(Test): 0.8340983390808105\n",
            "Epoch 709/1000: L(Train): 0.9564196467399597; L(Test): 0.830391526222229\n",
            "Epoch 710/1000: L(Train): 0.9682130217552185; L(Test): 0.8298945426940918\n",
            "Epoch 711/1000: L(Train): 0.9787123799324036; L(Test): 0.8320920467376709\n",
            "Epoch 712/1000: L(Train): 0.9604257941246033; L(Test): 0.833962619304657\n",
            "Epoch 713/1000: L(Train): 0.9931220412254333; L(Test): 0.8329178690910339\n",
            "Epoch 714/1000: L(Train): 0.9561878442764282; L(Test): 0.8313846588134766\n",
            "Epoch 715/1000: L(Train): 0.9788464307785034; L(Test): 0.8332067728042603\n",
            "Epoch 716/1000: L(Train): 0.962364673614502; L(Test): 0.8335735201835632\n",
            "Epoch 717/1000: L(Train): 0.9702264070510864; L(Test): 0.830647885799408\n",
            "Epoch 718/1000: L(Train): 0.9805862903594971; L(Test): 0.8347492814064026\n",
            "Epoch 719/1000: L(Train): 0.9591265916824341; L(Test): 0.8329718708992004\n",
            "Epoch 720/1000: L(Train): 0.9938203692436218; L(Test): 0.8391551375389099\n",
            "Epoch 721/1000: L(Train): 0.9853358864784241; L(Test): 0.8448776006698608\n",
            "Epoch 722/1000: L(Train): 0.9879398345947266; L(Test): 0.838004469871521\n",
            "Epoch 723/1000: L(Train): 0.9589886665344238; L(Test): 0.8412225842475891\n",
            "Epoch 724/1000: L(Train): 0.9804836511611938; L(Test): 0.8463382124900818\n",
            "Epoch 725/1000: L(Train): 0.9873751401901245; L(Test): 0.8419856429100037\n",
            "Epoch 726/1000: L(Train): 0.9736828804016113; L(Test): 0.8398191332817078\n",
            "Epoch 727/1000: L(Train): 0.9643335342407227; L(Test): 0.8461898565292358\n",
            "Epoch 728/1000: L(Train): 0.9902846217155457; L(Test): 0.8480060696601868\n",
            "Epoch 729/1000: L(Train): 0.9720296263694763; L(Test): 0.841489315032959\n",
            "Epoch 730/1000: L(Train): 1.0131356716156006; L(Test): 0.8409065008163452\n",
            "Epoch 731/1000: L(Train): 0.959260106086731; L(Test): 0.8446177244186401\n",
            "Epoch 732/1000: L(Train): 0.9807024002075195; L(Test): 0.8438690304756165\n",
            "Epoch 733/1000: L(Train): 0.9541406631469727; L(Test): 0.8470198512077332\n",
            "Epoch 734/1000: L(Train): 0.9973057508468628; L(Test): 0.8535356521606445\n",
            "Epoch 735/1000: L(Train): 0.9730926752090454; L(Test): 0.8599562644958496\n",
            "Epoch 736/1000: L(Train): 0.9725227355957031; L(Test): 0.8560258746147156\n",
            "Epoch 737/1000: L(Train): 0.9669359922409058; L(Test): 0.8503576517105103\n",
            "Epoch 738/1000: L(Train): 0.9907705187797546; L(Test): 0.8474658131599426\n",
            "Epoch 739/1000: L(Train): 0.9460908770561218; L(Test): 0.8493784070014954\n",
            "Epoch 740/1000: L(Train): 0.985047459602356; L(Test): 0.8458899259567261\n",
            "Epoch 741/1000: L(Train): 0.9842818379402161; L(Test): 0.8420440554618835\n",
            "Epoch 742/1000: L(Train): 0.9761393070220947; L(Test): 0.8436021208763123\n",
            "Epoch 743/1000: L(Train): 0.9659704566001892; L(Test): 0.8443127870559692\n",
            "Epoch 744/1000: L(Train): 0.9790441393852234; L(Test): 0.8415175676345825\n",
            "Epoch 745/1000: L(Train): 0.9675102829933167; L(Test): 0.8413836359977722\n",
            "Epoch 746/1000: L(Train): 0.9737029671669006; L(Test): 0.8439850807189941\n",
            "Epoch 747/1000: L(Train): 0.977904736995697; L(Test): 0.848461925983429\n",
            "Epoch 748/1000: L(Train): 0.9368952512741089; L(Test): 0.8494341969490051\n",
            "Epoch 749/1000: L(Train): 0.9757363200187683; L(Test): 0.8462282419204712\n",
            "Epoch 750/1000: L(Train): 0.9767854809761047; L(Test): 0.8430396914482117\n",
            "Epoch 751/1000: L(Train): 0.9917440414428711; L(Test): 0.8395757079124451\n",
            "Epoch 752/1000: L(Train): 0.9909772872924805; L(Test): 0.8358955383300781\n",
            "Epoch 753/1000: L(Train): 0.9767875075340271; L(Test): 0.8356068730354309\n",
            "Epoch 754/1000: L(Train): 0.9740483164787292; L(Test): 0.8364166021347046\n",
            "Epoch 755/1000: L(Train): 0.9955825209617615; L(Test): 0.8378742933273315\n",
            "Epoch 756/1000: L(Train): 0.9561344385147095; L(Test): 0.8378794193267822\n",
            "Epoch 757/1000: L(Train): 0.971529483795166; L(Test): 0.8381086587905884\n",
            "Epoch 758/1000: L(Train): 0.9709645509719849; L(Test): 0.8361555337905884\n",
            "Epoch 759/1000: L(Train): 0.9763972759246826; L(Test): 0.8309792280197144\n",
            "Epoch 760/1000: L(Train): 0.9681509137153625; L(Test): 0.8273955583572388\n",
            "Epoch 761/1000: L(Train): 0.9744554758071899; L(Test): 0.8292602896690369\n",
            "Epoch 762/1000: L(Train): 0.9627755880355835; L(Test): 0.8336070775985718\n",
            "Epoch 763/1000: L(Train): 0.9520160555839539; L(Test): 0.8348270654678345\n",
            "Epoch 764/1000: L(Train): 0.9619467258453369; L(Test): 0.8333600163459778\n",
            "Epoch 765/1000: L(Train): 0.9683257341384888; L(Test): 0.8322780132293701\n",
            "Epoch 766/1000: L(Train): 0.9668663740158081; L(Test): 0.8305756449699402\n",
            "Epoch 767/1000: L(Train): 1.0015184879302979; L(Test): 0.828779935836792\n",
            "Epoch 768/1000: L(Train): 0.9781264662742615; L(Test): 0.8315349221229553\n",
            "Epoch 769/1000: L(Train): 0.9720818996429443; L(Test): 0.828597366809845\n",
            "Epoch 770/1000: L(Train): 0.9692226648330688; L(Test): 0.8244420886039734\n",
            "Epoch 771/1000: L(Train): 0.9674421548843384; L(Test): 0.8243841528892517\n",
            "Epoch 772/1000: L(Train): 0.9700900912284851; L(Test): 0.8262843489646912\n",
            "Epoch 773/1000: L(Train): 0.9814695119857788; L(Test): 0.8258148431777954\n",
            "Epoch 774/1000: L(Train): 0.9455588459968567; L(Test): 0.8265781402587891\n",
            "Epoch 775/1000: L(Train): 0.9587066173553467; L(Test): 0.8254626989364624\n",
            "Epoch 776/1000: L(Train): 0.9715762138366699; L(Test): 0.8220929503440857\n",
            "Epoch 777/1000: L(Train): 0.9538954496383667; L(Test): 0.8240710496902466\n",
            "Epoch 778/1000: L(Train): 0.9598060846328735; L(Test): 0.8271499872207642\n",
            "Epoch 779/1000: L(Train): 0.9342167377471924; L(Test): 0.8292858600616455\n",
            "Epoch 780/1000: L(Train): 0.9514696598052979; L(Test): 0.8297939300537109\n",
            "Epoch 781/1000: L(Train): 0.9479978084564209; L(Test): 0.8246325254440308\n",
            "Epoch 782/1000: L(Train): 0.972061812877655; L(Test): 0.8226420283317566\n",
            "Epoch 783/1000: L(Train): 0.9532370567321777; L(Test): 0.8248379826545715\n",
            "Epoch 784/1000: L(Train): 0.9461635947227478; L(Test): 0.8245362639427185\n",
            "Epoch 785/1000: L(Train): 0.9413551688194275; L(Test): 0.8241522312164307\n",
            "Epoch 786/1000: L(Train): 0.9785014390945435; L(Test): 0.8256849050521851\n",
            "Epoch 787/1000: L(Train): 0.9411702752113342; L(Test): 0.8246277570724487\n",
            "Epoch 788/1000: L(Train): 0.969549298286438; L(Test): 0.8222551345825195\n",
            "Epoch 789/1000: L(Train): 0.9379744529724121; L(Test): 0.8231386542320251\n",
            "Epoch 790/1000: L(Train): 0.9533159136772156; L(Test): 0.8262408375740051\n",
            "Epoch 791/1000: L(Train): 0.9366822242736816; L(Test): 0.8236091732978821\n",
            "Epoch 792/1000: L(Train): 0.9552793502807617; L(Test): 0.8210411667823792\n",
            "Epoch 793/1000: L(Train): 0.9592461585998535; L(Test): 0.8250346183776855\n",
            "Epoch 794/1000: L(Train): 0.9750159382820129; L(Test): 0.8264111876487732\n",
            "Epoch 795/1000: L(Train): 0.9735198616981506; L(Test): 0.8201817870140076\n",
            "Epoch 796/1000: L(Train): 0.9668762683868408; L(Test): 0.8173603415489197\n",
            "Epoch 797/1000: L(Train): 0.9621346592903137; L(Test): 0.8202741742134094\n",
            "Epoch 798/1000: L(Train): 0.9652204513549805; L(Test): 0.8234850168228149\n",
            "Epoch 799/1000: L(Train): 0.9611121416091919; L(Test): 0.8214205503463745\n",
            "Epoch 800/1000: L(Train): 0.9743800759315491; L(Test): 0.8243911266326904\n",
            "Epoch 801/1000: L(Train): 0.9653621315956116; L(Test): 0.8265038728713989\n",
            "Epoch 802/1000: L(Train): 0.9812222123146057; L(Test): 0.8231557607650757\n",
            "Epoch 803/1000: L(Train): 0.9570825695991516; L(Test): 0.8235201239585876\n",
            "Epoch 804/1000: L(Train): 0.9528445601463318; L(Test): 0.8247044086456299\n",
            "Epoch 805/1000: L(Train): 0.9604589343070984; L(Test): 0.8275991678237915\n",
            "Epoch 806/1000: L(Train): 0.9432644248008728; L(Test): 0.8302223086357117\n",
            "Epoch 807/1000: L(Train): 0.9696649312973022; L(Test): 0.8287591934204102\n",
            "Epoch 808/1000: L(Train): 0.9944482445716858; L(Test): 0.8270671963691711\n",
            "Epoch 809/1000: L(Train): 0.9508596658706665; L(Test): 0.8267273306846619\n",
            "Epoch 810/1000: L(Train): 0.9725157022476196; L(Test): 0.8270447850227356\n",
            "Epoch 811/1000: L(Train): 0.9632171392440796; L(Test): 0.8264080882072449\n",
            "Epoch 812/1000: L(Train): 0.9599534273147583; L(Test): 0.8237116932868958\n",
            "Epoch 813/1000: L(Train): 0.9513479471206665; L(Test): 0.8212437033653259\n",
            "Epoch 814/1000: L(Train): 0.9539337158203125; L(Test): 0.823773205280304\n",
            "Epoch 815/1000: L(Train): 0.958215594291687; L(Test): 0.8235980868339539\n",
            "Epoch 816/1000: L(Train): 0.9610205888748169; L(Test): 0.8232573866844177\n",
            "Epoch 817/1000: L(Train): 0.9514837861061096; L(Test): 0.8237938284873962\n",
            "Epoch 818/1000: L(Train): 0.9709494113922119; L(Test): 0.8247104287147522\n",
            "Epoch 819/1000: L(Train): 0.9453637599945068; L(Test): 0.8213326930999756\n",
            "Epoch 820/1000: L(Train): 0.9662860631942749; L(Test): 0.817864179611206\n",
            "Epoch 821/1000: L(Train): 0.9413667917251587; L(Test): 0.8177628517150879\n",
            "Epoch 822/1000: L(Train): 0.9535930752754211; L(Test): 0.8200387954711914\n",
            "Epoch 823/1000: L(Train): 0.956046998500824; L(Test): 0.818133533000946\n",
            "Epoch 824/1000: L(Train): 0.9523559212684631; L(Test): 0.8147238492965698\n",
            "Epoch 825/1000: L(Train): 0.9593560099601746; L(Test): 0.8132931590080261\n",
            "Epoch 826/1000: L(Train): 0.9598889350891113; L(Test): 0.8123654723167419\n",
            "Epoch 827/1000: L(Train): 0.9408089518547058; L(Test): 0.8153349757194519\n",
            "Epoch 828/1000: L(Train): 0.9561375379562378; L(Test): 0.8193696737289429\n",
            "Epoch 829/1000: L(Train): 0.9531274437904358; L(Test): 0.8207113742828369\n",
            "Epoch 830/1000: L(Train): 0.9341322183609009; L(Test): 0.8186458945274353\n",
            "Epoch 831/1000: L(Train): 0.9690427780151367; L(Test): 0.8179101347923279\n",
            "Epoch 832/1000: L(Train): 0.928888738155365; L(Test): 0.819534420967102\n",
            "Epoch 833/1000: L(Train): 0.9563955664634705; L(Test): 0.8165774941444397\n",
            "Epoch 834/1000: L(Train): 0.9434915781021118; L(Test): 0.8099822998046875\n",
            "Epoch 835/1000: L(Train): 0.9335254430770874; L(Test): 0.8106005191802979\n",
            "Epoch 836/1000: L(Train): 0.9504841566085815; L(Test): 0.8152884840965271\n",
            "Epoch 837/1000: L(Train): 0.9740606546401978; L(Test): 0.8148477673530579\n",
            "Epoch 838/1000: L(Train): 0.9795958995819092; L(Test): 0.8137692809104919\n",
            "Epoch 839/1000: L(Train): 0.949799656867981; L(Test): 0.8140135407447815\n",
            "Epoch 840/1000: L(Train): 0.9597152471542358; L(Test): 0.8106741905212402\n",
            "Epoch 841/1000: L(Train): 0.9502218961715698; L(Test): 0.8100095987319946\n",
            "Epoch 842/1000: L(Train): 0.9620925188064575; L(Test): 0.8160843253135681\n",
            "Epoch 843/1000: L(Train): 0.959405243396759; L(Test): 0.8131999373435974\n",
            "Epoch 844/1000: L(Train): 0.9476261138916016; L(Test): 0.8077591061592102\n",
            "Epoch 845/1000: L(Train): 0.9555867910385132; L(Test): 0.8143478035926819\n",
            "Epoch 846/1000: L(Train): 0.9612723588943481; L(Test): 0.8180049061775208\n",
            "Epoch 847/1000: L(Train): 0.9879670739173889; L(Test): 0.8122611045837402\n",
            "Epoch 848/1000: L(Train): 0.9517958760261536; L(Test): 0.8115403056144714\n",
            "Epoch 849/1000: L(Train): 0.9649538993835449; L(Test): 0.8151218891143799\n",
            "Epoch 850/1000: L(Train): 0.9516873359680176; L(Test): 0.8078362345695496\n",
            "Epoch 851/1000: L(Train): 0.939321756362915; L(Test): 0.8085986971855164\n",
            "Epoch 852/1000: L(Train): 0.9498689770698547; L(Test): 0.8145418763160706\n",
            "Epoch 853/1000: L(Train): 0.9708821773529053; L(Test): 0.8133417963981628\n",
            "Epoch 854/1000: L(Train): 0.9512959122657776; L(Test): 0.8178021907806396\n",
            "Epoch 855/1000: L(Train): 0.9535898566246033; L(Test): 0.8325433135032654\n",
            "Epoch 856/1000: L(Train): 1.0015591382980347; L(Test): 0.8335477113723755\n",
            "Epoch 857/1000: L(Train): 0.9633902907371521; L(Test): 0.8240266442298889\n",
            "Epoch 858/1000: L(Train): 0.9859739542007446; L(Test): 0.8229954242706299\n",
            "Epoch 859/1000: L(Train): 0.9681203961372375; L(Test): 0.8267806768417358\n",
            "Epoch 860/1000: L(Train): 0.9641780853271484; L(Test): 0.8273277878761292\n",
            "Epoch 861/1000: L(Train): 0.9556677341461182; L(Test): 0.823963463306427\n",
            "Epoch 862/1000: L(Train): 0.9613368511199951; L(Test): 0.8175964951515198\n",
            "Epoch 863/1000: L(Train): 0.9735410809516907; L(Test): 0.8199959397315979\n",
            "Epoch 864/1000: L(Train): 0.9548237919807434; L(Test): 0.8216437101364136\n",
            "Epoch 865/1000: L(Train): 0.9370561242103577; L(Test): 0.8208367228507996\n",
            "Epoch 866/1000: L(Train): 0.9568459987640381; L(Test): 0.820764422416687\n",
            "Epoch 867/1000: L(Train): 0.953289270401001; L(Test): 0.8196243643760681\n",
            "Epoch 868/1000: L(Train): 0.9651004672050476; L(Test): 0.8202905058860779\n",
            "Epoch 869/1000: L(Train): 0.9746036529541016; L(Test): 0.8212034702301025\n",
            "Epoch 870/1000: L(Train): 0.9518064260482788; L(Test): 0.8174824714660645\n",
            "Epoch 871/1000: L(Train): 0.9551727771759033; L(Test): 0.81345134973526\n",
            "Epoch 872/1000: L(Train): 0.9717980623245239; L(Test): 0.8122146129608154\n",
            "Epoch 873/1000: L(Train): 0.9372645020484924; L(Test): 0.8132737874984741\n",
            "Epoch 874/1000: L(Train): 0.9357435703277588; L(Test): 0.8136717081069946\n",
            "Epoch 875/1000: L(Train): 0.9598459601402283; L(Test): 0.8130095601081848\n",
            "Epoch 876/1000: L(Train): 0.9426106810569763; L(Test): 0.8138159513473511\n",
            "Epoch 877/1000: L(Train): 0.9668827652931213; L(Test): 0.8116716742515564\n",
            "Epoch 878/1000: L(Train): 0.9603760242462158; L(Test): 0.807248055934906\n",
            "Epoch 879/1000: L(Train): 0.9384676814079285; L(Test): 0.8079777359962463\n",
            "Epoch 880/1000: L(Train): 0.9427006244659424; L(Test): 0.806808590888977\n",
            "Epoch 881/1000: L(Train): 0.9604091048240662; L(Test): 0.8038948774337769\n",
            "Epoch 882/1000: L(Train): 0.9435824155807495; L(Test): 0.8072172999382019\n",
            "Epoch 883/1000: L(Train): 0.9364737868309021; L(Test): 0.8079579472541809\n",
            "Epoch 884/1000: L(Train): 0.9463129639625549; L(Test): 0.8074910640716553\n",
            "Epoch 885/1000: L(Train): 0.9500277042388916; L(Test): 0.8104186058044434\n",
            "Epoch 886/1000: L(Train): 0.957793116569519; L(Test): 0.8094295263290405\n",
            "Epoch 887/1000: L(Train): 0.9469589591026306; L(Test): 0.8071168065071106\n",
            "Epoch 888/1000: L(Train): 0.9563650488853455; L(Test): 0.8088375329971313\n",
            "Epoch 889/1000: L(Train): 0.9606202244758606; L(Test): 0.8098260760307312\n",
            "Epoch 890/1000: L(Train): 0.952007532119751; L(Test): 0.8102275729179382\n",
            "Epoch 891/1000: L(Train): 0.9669487476348877; L(Test): 0.80678790807724\n",
            "Epoch 892/1000: L(Train): 0.9471779465675354; L(Test): 0.8056168556213379\n",
            "Epoch 893/1000: L(Train): 0.9558759331703186; L(Test): 0.8047388792037964\n",
            "Epoch 894/1000: L(Train): 0.9464925527572632; L(Test): 0.8043076395988464\n",
            "Epoch 895/1000: L(Train): 0.9317197799682617; L(Test): 0.8018184900283813\n",
            "Epoch 896/1000: L(Train): 0.9405174255371094; L(Test): 0.8027498722076416\n",
            "Epoch 897/1000: L(Train): 0.9465579390525818; L(Test): 0.8054152727127075\n",
            "Epoch 898/1000: L(Train): 0.9472159147262573; L(Test): 0.8037328720092773\n",
            "Epoch 899/1000: L(Train): 0.9411765933036804; L(Test): 0.8011164665222168\n",
            "Epoch 900/1000: L(Train): 0.9322018027305603; L(Test): 0.8027337789535522\n",
            "Epoch 901/1000: L(Train): 0.9710614681243896; L(Test): 0.8085625171661377\n",
            "Epoch 902/1000: L(Train): 0.9501651525497437; L(Test): 0.8067039251327515\n",
            "Epoch 903/1000: L(Train): 0.9635052680969238; L(Test): 0.8030741214752197\n",
            "Epoch 904/1000: L(Train): 0.9370350241661072; L(Test): 0.8062638640403748\n",
            "Epoch 905/1000: L(Train): 0.9392724633216858; L(Test): 0.810131847858429\n",
            "Epoch 906/1000: L(Train): 0.9685397744178772; L(Test): 0.806908905506134\n",
            "Epoch 907/1000: L(Train): 0.9792835116386414; L(Test): 0.8048292398452759\n",
            "Epoch 908/1000: L(Train): 0.9433100819587708; L(Test): 0.8054402470588684\n",
            "Epoch 909/1000: L(Train): 0.9281582236289978; L(Test): 0.8080967664718628\n",
            "Epoch 910/1000: L(Train): 0.9645675420761108; L(Test): 0.8117263317108154\n",
            "Epoch 911/1000: L(Train): 0.9640161991119385; L(Test): 0.8148052096366882\n",
            "Epoch 912/1000: L(Train): 0.9685623049736023; L(Test): 0.8120083212852478\n",
            "Epoch 913/1000: L(Train): 0.9498350024223328; L(Test): 0.8082944750785828\n",
            "Epoch 914/1000: L(Train): 0.9436718225479126; L(Test): 0.805780827999115\n",
            "Epoch 915/1000: L(Train): 0.9491061568260193; L(Test): 0.8076705932617188\n",
            "Epoch 916/1000: L(Train): 0.9445810317993164; L(Test): 0.808577299118042\n",
            "Epoch 917/1000: L(Train): 0.9299640655517578; L(Test): 0.8032765984535217\n",
            "Epoch 918/1000: L(Train): 0.9278122782707214; L(Test): 0.8018026351928711\n",
            "Epoch 919/1000: L(Train): 0.9336845874786377; L(Test): 0.8050486445426941\n",
            "Epoch 920/1000: L(Train): 0.9406540393829346; L(Test): 0.8072121739387512\n",
            "Epoch 921/1000: L(Train): 0.9940845966339111; L(Test): 0.8078259825706482\n",
            "Epoch 922/1000: L(Train): 0.9314173460006714; L(Test): 0.8059937953948975\n",
            "Epoch 923/1000: L(Train): 0.9360504746437073; L(Test): 0.800883412361145\n",
            "Epoch 924/1000: L(Train): 0.9503704905509949; L(Test): 0.8003055453300476\n",
            "Epoch 925/1000: L(Train): 0.928581953048706; L(Test): 0.804020345211029\n",
            "Epoch 926/1000: L(Train): 0.9639161825180054; L(Test): 0.8040806651115417\n",
            "Epoch 927/1000: L(Train): 0.9272601008415222; L(Test): 0.8015983700752258\n",
            "Epoch 928/1000: L(Train): 0.9448989629745483; L(Test): 0.8078453540802002\n",
            "Epoch 929/1000: L(Train): 0.9636023640632629; L(Test): 0.8094826936721802\n",
            "Epoch 930/1000: L(Train): 0.9490358829498291; L(Test): 0.8049082159996033\n",
            "Epoch 931/1000: L(Train): 0.9435647130012512; L(Test): 0.8059330582618713\n",
            "Epoch 932/1000: L(Train): 0.9619945287704468; L(Test): 0.8098219633102417\n",
            "Epoch 933/1000: L(Train): 0.9434732794761658; L(Test): 0.8076775074005127\n",
            "Epoch 934/1000: L(Train): 0.9662848114967346; L(Test): 0.8049328327178955\n",
            "Epoch 935/1000: L(Train): 0.9464200735092163; L(Test): 0.8075316548347473\n",
            "Epoch 936/1000: L(Train): 0.9327389597892761; L(Test): 0.8068902492523193\n",
            "Epoch 937/1000: L(Train): 0.9518951177597046; L(Test): 0.8034413456916809\n",
            "Epoch 938/1000: L(Train): 0.976327657699585; L(Test): 0.8018168210983276\n",
            "Epoch 939/1000: L(Train): 0.9663819074630737; L(Test): 0.8041765093803406\n",
            "Epoch 940/1000: L(Train): 0.947740375995636; L(Test): 0.8050022125244141\n",
            "Epoch 941/1000: L(Train): 0.9275847673416138; L(Test): 0.8066830635070801\n",
            "Epoch 942/1000: L(Train): 0.9568913578987122; L(Test): 0.8107228875160217\n",
            "Epoch 943/1000: L(Train): 0.9639992713928223; L(Test): 0.8104799389839172\n",
            "Epoch 944/1000: L(Train): 0.9625449180603027; L(Test): 0.8081406354904175\n",
            "Epoch 945/1000: L(Train): 0.9403769969940186; L(Test): 0.8097864985466003\n",
            "Epoch 946/1000: L(Train): 0.9519592523574829; L(Test): 0.8104007244110107\n",
            "Epoch 947/1000: L(Train): 0.9220699667930603; L(Test): 0.8117647767066956\n",
            "Epoch 948/1000: L(Train): 0.9658997058868408; L(Test): 0.8168457746505737\n",
            "Epoch 949/1000: L(Train): 0.9517341256141663; L(Test): 0.8157628178596497\n",
            "Epoch 950/1000: L(Train): 0.9557300209999084; L(Test): 0.8144367337226868\n",
            "Epoch 951/1000: L(Train): 0.9638327360153198; L(Test): 0.8118952512741089\n",
            "Epoch 952/1000: L(Train): 0.9454613327980042; L(Test): 0.8128977417945862\n",
            "Epoch 953/1000: L(Train): 0.9561299681663513; L(Test): 0.8153132200241089\n",
            "Epoch 954/1000: L(Train): 0.9479331970214844; L(Test): 0.8203921318054199\n",
            "Epoch 955/1000: L(Train): 0.9783477783203125; L(Test): 0.8257284164428711\n",
            "Epoch 956/1000: L(Train): 0.976076602935791; L(Test): 0.8248152136802673\n",
            "Epoch 957/1000: L(Train): 0.975701630115509; L(Test): 0.8174384236335754\n",
            "Epoch 958/1000: L(Train): 0.9787923693656921; L(Test): 0.819591224193573\n",
            "Epoch 959/1000: L(Train): 0.9837167859077454; L(Test): 0.8260328769683838\n",
            "Epoch 960/1000: L(Train): 0.9726430773735046; L(Test): 0.8258197903633118\n",
            "Epoch 961/1000: L(Train): 0.9769729971885681; L(Test): 0.8270269632339478\n",
            "Epoch 962/1000: L(Train): 0.9571009278297424; L(Test): 0.8238067626953125\n",
            "Epoch 963/1000: L(Train): 0.994720995426178; L(Test): 0.8228123188018799\n",
            "Epoch 964/1000: L(Train): 0.9718960523605347; L(Test): 0.8269088864326477\n",
            "Epoch 965/1000: L(Train): 0.9517298340797424; L(Test): 0.8282286524772644\n",
            "Epoch 966/1000: L(Train): 0.9671708345413208; L(Test): 0.8295081257820129\n",
            "Epoch 967/1000: L(Train): 0.9523305296897888; L(Test): 0.8292699456214905\n",
            "Epoch 968/1000: L(Train): 0.974141001701355; L(Test): 0.8289811611175537\n",
            "Epoch 969/1000: L(Train): 0.9897161722183228; L(Test): 0.8315474987030029\n",
            "Epoch 970/1000: L(Train): 0.9748055338859558; L(Test): 0.8289846777915955\n",
            "Epoch 971/1000: L(Train): 0.9495146870613098; L(Test): 0.8223781585693359\n",
            "Epoch 972/1000: L(Train): 0.9620258808135986; L(Test): 0.8206532597541809\n",
            "Epoch 973/1000: L(Train): 0.9641487002372742; L(Test): 0.8189496397972107\n",
            "Epoch 974/1000: L(Train): 0.9740936160087585; L(Test): 0.8173511028289795\n",
            "Epoch 975/1000: L(Train): 0.9686780571937561; L(Test): 0.8148096203804016\n",
            "Epoch 976/1000: L(Train): 0.9536697268486023; L(Test): 0.8142602443695068\n",
            "Epoch 977/1000: L(Train): 0.9581127166748047; L(Test): 0.8140813112258911\n",
            "Epoch 978/1000: L(Train): 0.9750596880912781; L(Test): 0.8177610635757446\n",
            "Epoch 979/1000: L(Train): 0.9562777876853943; L(Test): 0.819124162197113\n",
            "Epoch 980/1000: L(Train): 0.955494225025177; L(Test): 0.8194625377655029\n",
            "Epoch 981/1000: L(Train): 0.9472946524620056; L(Test): 0.8218141794204712\n",
            "Epoch 982/1000: L(Train): 0.9780497550964355; L(Test): 0.8194381594657898\n",
            "Epoch 983/1000: L(Train): 0.964013397693634; L(Test): 0.8108903169631958\n",
            "Epoch 984/1000: L(Train): 0.9511227607727051; L(Test): 0.8136797547340393\n",
            "Epoch 985/1000: L(Train): 0.9383059144020081; L(Test): 0.8225332498550415\n",
            "Epoch 986/1000: L(Train): 0.9897819757461548; L(Test): 0.8196349740028381\n",
            "Epoch 987/1000: L(Train): 0.9498898983001709; L(Test): 0.8125575184822083\n",
            "Epoch 988/1000: L(Train): 0.938801646232605; L(Test): 0.8116778135299683\n",
            "Epoch 989/1000: L(Train): 0.9221264123916626; L(Test): 0.8101612329483032\n",
            "Epoch 990/1000: L(Train): 0.9606496691703796; L(Test): 0.8103456497192383\n",
            "Epoch 991/1000: L(Train): 0.9623206853866577; L(Test): 0.8117791414260864\n",
            "Epoch 992/1000: L(Train): 0.9568508267402649; L(Test): 0.8112065196037292\n",
            "Epoch 993/1000: L(Train): 0.9443584680557251; L(Test): 0.8059371113777161\n",
            "Epoch 994/1000: L(Train): 0.9505060315132141; L(Test): 0.8033239245414734\n",
            "Epoch 995/1000: L(Train): 0.9688906073570251; L(Test): 0.8063607215881348\n",
            "Epoch 996/1000: L(Train): 0.9488552808761597; L(Test): 0.807479977607727\n",
            "Epoch 997/1000: L(Train): 0.9442760348320007; L(Test): 0.8037934899330139\n",
            "Epoch 998/1000: L(Train): 0.9475081562995911; L(Test): 0.8014367818832397\n",
            "Epoch 999/1000: L(Train): 0.9514909386634827; L(Test): 0.800024688243866\n",
            "Epoch 1000/1000: L(Train): 0.9593673348426819; L(Test): 0.7978023290634155\n",
            "Trained GRU+Embedding parameters saved to ../../weinhardt2025/params/hwang2025/gruembed_hwang2025.pkl\n"
          ]
        }
      ],
      "source": [
        "gru_embed = training(\n",
        "    gru=gru_embed,\n",
        "    optimizer=optimizer,\n",
        "    dataset_train=dataset_train,\n",
        "    dataset_test=dataset_test,\n",
        "    epochs=epochs,\n",
        "    )\n",
        "\n",
        "torch.save(gru_embed.state_dict(), path_gru_embed)\n",
        "print(\"Trained GRU+Embedding parameters saved to \" + path_gru_embed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "gru_embed_agent = setup_agent_gru(path_gru_embed, gru_embed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot choice dynamics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "value_action[t+1] = 0.0 1 + 1.005 value_action[t] + -0.006 chosen + 0.003 sig_action + 0.019 sig_grooming + 0.002 sig_non_contact + -0.004 sig_contact + -0.001 sig_scratch + 0.005 sig_waiting + 0.001 prev_action + 0.001 prev_grooming + -0.002 prev_non_contact + -0.002 prev_contact + -0.001 prev_scratch + -0.001 prev_waiting \n",
            "value_grooming[t+1] = 0.107 1 + 0.893 value_grooming[t] + -0.045 chosen + 0.104 sig_action + -0.045 sig_grooming + 0.002 sig_non_contact + 0.106 sig_contact + 0.002 sig_scratch + -0.025 sig_waiting + 0.003 prev_action + -0.003 prev_grooming + -0.003 prev_non_contact + -0.001 prev_contact + -0.003 prev_scratch + 0.003 prev_waiting \n",
            "value_non_contact[t+1] = -0.107 1 + 0.934 value_non_contact[t] + 0.001 chosen + -0.003 sig_action + -0.106 sig_grooming + -0.002 sig_non_contact + 0.006 sig_contact + -0.003 sig_scratch + -0.003 sig_waiting + -0.001 prev_action + -0.002 prev_grooming + 0.001 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + 0.002 prev_waiting \n",
            "value_contact[t+1] = -0.001 1 + 0.996 value_contact[t] + 0.0 chosen + 0.002 sig_action + -0.002 sig_grooming + -0.001 sig_non_contact + 0.002 sig_contact + -0.003 sig_scratch + -0.005 sig_waiting + -0.002 prev_action + 0.001 prev_grooming + -0.001 prev_non_contact + 0.002 prev_contact + 0.001 prev_scratch + -0.002 prev_waiting \n",
            "value_scratch[t+1] = -0.084 1 + 0.952 value_scratch[t] + 0.003 chosen + -0.002 sig_action + -0.095 sig_grooming + 0.003 sig_non_contact + -0.003 sig_contact + -0.001 sig_scratch + 0.039 sig_waiting + -0.001 prev_action + 0.001 prev_grooming + 0.002 prev_non_contact + -0.001 prev_contact + 0.003 prev_scratch + 0.001 prev_waiting \n",
            "value_waiting[t+1] = 0.016 1 + 1.001 value_waiting[t] + -0.001 chosen + -0.015 sig_action + 0.059 sig_grooming + -0.003 sig_non_contact + 0.004 sig_contact + -0.002 sig_scratch + -0.011 sig_waiting + 0.003 prev_action + -0.003 prev_grooming + 0.002 prev_non_contact + 0.003 prev_contact + 0.003 prev_scratch + 0.003 prev_waiting \n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x1000 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from spice import plot_session\n",
        "\n",
        "# plotting\n",
        "session_id = 1\n",
        "\n",
        "estimator.print_spice_model(session_id)\n",
        "\n",
        "agents = {\n",
        "    # add baseline agent here\n",
        "    'rnn': estimator.rnn_agent,\n",
        "    'spice': estimator.spice_agent,\n",
        "    # 'baseline': baseline_agent,\n",
        "    'gru': gru_agent,\n",
        "    'gru_embed': gru_embed_agent,\n",
        "}\n",
        "\n",
        "fig, axs = plot_session(agents, dataset.xs[session_id], signals_to_plot=[], display_choice=1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chance level accuracy: 0.1667 (16.67%)\n",
            "Random predictions loss: 1.8761\n"
          ]
        }
      ],
      "source": [
        "# chance level predictions\n",
        "\n",
        "num_actions = 6\n",
        "num_samples = 311*144\n",
        "chance_accuracy = 1 / num_actions\n",
        "print(f\"Chance level accuracy: {chance_accuracy:.4f} ({1/num_actions:.2%})\")\n",
        "\n",
        "# create random predictions for comparison in next cell\n",
        "random_predictions = torch.randint(0, num_actions, (num_samples,))\n",
        "random_predictions = torch.nn.functional.one_hot(random_predictions, num_classes=num_actions).float()\n",
        "\n",
        "labels_flat = dataset.ys[..., 1].reshape(-1).nan_to_num(0).long()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "loss_random = criterion(random_predictions, labels_flat)\n",
        "print(f\"Random predictions loss: {loss_random.item():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SPICE Loss: 1.6079895496368408\n",
            "GRU Loss: 1.1697009801864624\n"
          ]
        }
      ],
      "source": [
        "# evaluate the models by getting their predictions on the real data and comparing the CE loss\n",
        "\n",
        "estimator.rnn_model.eval(use_sindy=True)\n",
        "estimator.rnn_model.init_state(batch_size=dataset.xs.shape[0])\n",
        "logits_spice = estimator.rnn_model(dataset.xs, prev_state=None, batch_first=True)[0]\n",
        "\n",
        "gru.eval()\n",
        "gru.to(torch.device('cpu'))\n",
        "with torch.no_grad():\n",
        "    logits_gru, state_gru = gru(dataset.xs)\n",
        "    \n",
        "nan_mask = ~dataset.xs[:, :, 0].reshape(-1).isnan()\n",
        "\n",
        "logits_spice_flat = logits_spice.reshape(-1, 6)\n",
        "logits_gru_flat = logits_gru.reshape(-1, 6)\n",
        "labels_flat = torch.argmax(dataset.ys, dim=-1).reshape(-1).nan_to_num(0).long()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "loss_spice = criterion(logits_spice_flat[nan_mask], labels_flat[nan_mask])\n",
        "loss_gru = criterion(logits_gru_flat[nan_mask], labels_flat[nan_mask])\n",
        "\n",
        "print(f\"SPICE Loss: {loss_spice.item()}\")\n",
        "print(f\"GRU Loss: {loss_gru.item()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TO-DO:\n",
        "\n",
        "1. **implement some logic to ignore SigAct_ID1 == 5 (waiting)** \n",
        "\n",
        "-> nothing to predict here\n",
        "\n",
        "-> whenever SigAct_ID1[t+1] == 5: Don't let the RNN predict because there's actually nothing to predict\n",
        "\n",
        "2. **add reversed blocks in csv file (ID1<->ID2) to double the amount of predictable data:**\n",
        "\n",
        "ID1,Dominan0 rank_ID1,ID2,Dominan0 rank_ID2,SigAct_ID1,SigAct_ID2,interaction_id,community_id,Grooming_ID1,Grooming_ID2\n",
        "\n",
        "Original block:\n",
        "\n",
        "13,13,6,6,1.0,5.0,1,0,1,0\n",
        "\n",
        "13,13,6,6,2.0,5.0,1,0,0,0\n",
        "\n",
        "13,13,6,6,0.0,5.0,1,0,0,0\n",
        "\n",
        "Add reversed block:\n",
        "\n",
        "6,6,13,13,5.0,1.0,1,0,0,1\n",
        "\n",
        "6,6,13,13,5.0,2.0,1,0,0,0\n",
        "\n",
        "6,6,13,13,5.0,0.0,1,0,0,0\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "spice",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
