{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tf7jlYw4NA0v",
    "outputId": "0969ca34-675d-422e-cbfb-7387d9bcd8ad"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/whyhardt/SPICE.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oXIbg826NS5i",
    "outputId": "3825864a-cb2d-4ad5-f2e5-79a4e81dfc3e"
   },
   "outputs": [],
   "source": [
    "# !pip install -e SPICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "f0uVlABYznR5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from spice.estimator import SpiceEstimator, SpiceDataset\n",
    "from spice.resources.spice_utils import SpiceConfig\n",
    "from spice.utils.convert_dataset import convert_dataset\n",
    "from spice.resources.rnn import BaseRNN\n",
    "\n",
    "# For custom RNN\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data first with the `convert_dataset` method. This method returns a `SpiceDataset` object which we can use right away "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: torch.Size([277, 299, 11])\n",
      "Number of participants: 277\n",
      "Number of actions in dataset: 2\n",
      "Number of additional inputs: 4\n"
     ]
    }
   ],
   "source": [
    "# Load your data\n",
    "dataset = convert_dataset(\n",
    "    file = '../data/augustat2025/augustat2025.csv',\n",
    "    df_participant_id='participant_id',\n",
    "    df_choice='choice',\n",
    "    df_reward='reward',\n",
    "    additional_inputs=['shown_at_0', 'shown_at_1'],\n",
    "    timeshift_additional_inputs=False,\n",
    "    )\n",
    "\n",
    "# instead of timeshift add the predictor states shown_at_0 and shown_at_1 of the next trial to the inputs\n",
    "xs = dataset.xs[:, :-1]\n",
    "ys = dataset.ys[:, :-1]\n",
    "shown_next = dataset.xs[:, 1:, 2*2:-3]\n",
    "xs = torch.concat((xs[..., :-3], shown_next, xs[..., -3:]), dim=-1)\n",
    "dataset = SpiceDataset(xs, ys)\n",
    "\n",
    "# structure of dataset:\n",
    "# dataset has two main attributes: xs -> inputs; ys -> targets (next action)\n",
    "# shape: (n_participants*n_blocks*n_experiments, n_timesteps, features)\n",
    "# features are (n_actions * action, n_actions * reward, n_additional_inputs * additional_input, block_number, experiment_id, participant_id)\n",
    "\n",
    "# in order to set up the participant embedding we have to compute the number of unique participants in our data \n",
    "# to get the number of participants n_participants we do:\n",
    "n_participants = len(dataset.xs[..., -1].unique())\n",
    "\n",
    "print(f\"Shape of dataset: {dataset.xs.shape}\")\n",
    "print(f\"Number of participants: {n_participants}\")\n",
    "n_actions = dataset.ys.shape[-1]\n",
    "print(f\"Number of actions in dataset: {n_actions}\")\n",
    "print(f\"Number of additional inputs: {dataset.xs.shape[-1]-2*n_actions-3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to define the configuration for SPICE with a `SpiceConfig` object.\n",
    "\n",
    "The `SpiceConfig` takes as arguments \n",
    "1. `library_setup (dict)`: Defining the variable names of each module.\n",
    "2. `memory_state (dict)`: Defining the memory state variables and their initial values.\n",
    "3. `states_in_logit (list)`: Defining which of the memory state variables are used later for the logit computation. This is necessary for some background processes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spice_config = SpiceConfig(\n",
    "    library_setup={\n",
    "        'value_reward_chosen': ['reward'],\n",
    "        'value_reward_not_chosen': [],\n",
    "        'value_reward_not_displayed': [],\n",
    "    },\n",
    "    \n",
    "    memory_state={\n",
    "        'value_reward': 0.5,\n",
    "        },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we are going to define the SPICE model which is a child of the `BaseRNN` and `torch.nn.Module` class and takes as required arguments:\n",
    "1. `spice_config (SpiceConfig)`: previously defined SpiceConfig object\n",
    "2. `n_actions (int)`: number of possible actions in your dataset (including non-displayed ones if applicable).\n",
    "3. `n_participants (int)`: number of participants in your dataset.\n",
    "\n",
    "As usual for a `torch.nn.Module` we have to define at least the `__init__` method and the `forward` method.\n",
    "The `forward` method gets called when computing a forward pass through the model and takes as inputs `(inputs (SpiceDataset.xs), prev_state (dict, default: None), batch_first (bool, default: False))` and returns `(logits (torch.Tensor, shape: (n_participants*n_blocks*n_experiments, timesteps, n_actions)), updated_state (dict))`. Two necessary method calls inside the forward pass are:\n",
    "1. `self.init_forward_pass(inputs, prev_state, batch_first) -> SpiceSignals`: returns a `SpiceSignals` object which carries all relevant information already processed.\n",
    "2. `self.post_forward_pass(SpiceSignals, batch_first) -> SpiceSignals`: does some re-arranging of the logits to adhere to `batch_first`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPICERNN(BaseRNN):\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        n_actions, \n",
    "        spice_config, \n",
    "        n_participants, \n",
    "        n_items,\n",
    "        use_sindy=False, \n",
    "        **kwargs):\n",
    "        super().__init__(\n",
    "            n_actions=n_actions, \n",
    "            spice_config=spice_config,\n",
    "            n_participants=n_participants, \n",
    "            n_items=n_items, \n",
    "            embedding_size=32,\n",
    "            sindy_ensemble_size=1,\n",
    "            use_sindy=use_sindy,\n",
    "            )\n",
    "\n",
    "        self.participant_embedding = self.setup_embedding(num_embeddings=n_participants, embedding_size=self.embedding_size)\n",
    "\n",
    "        self.submodules_rnn['value_reward_chosen'] = self.setup_module(1+self.embedding_size)\n",
    "        self.submodules_rnn['value_reward_not_chosen'] = self.setup_module(self.embedding_size)\n",
    "        self.submodules_rnn['value_reward_not_displayed'] = self.setup_module(self.embedding_size)\n",
    "\n",
    "    def forward(self, inputs, prev_state, batch_first=False):\n",
    "\n",
    "        spice_signals = self.init_forward_pass(inputs, prev_state, batch_first)\n",
    "\n",
    "        # Get shown items (raw indices) - these are time-shifted, so they refer to the NEXT trial\n",
    "        shown_at_0_current = spice_signals.additional_inputs[..., 0].long()\n",
    "        shown_at_1_current = spice_signals.additional_inputs[..., 1].long()\n",
    "        shown_at_0_next = spice_signals.additional_inputs[..., 2].long()\n",
    "        shown_at_1_next = spice_signals.additional_inputs[..., 3].long()\n",
    "\n",
    "        participant_embeddings = self.participant_embedding(spice_signals.participant_ids)\n",
    "\n",
    "        for timestep in spice_signals.timesteps:\n",
    "\n",
    "            # Transform input data from action space to item space\n",
    "\n",
    "            # Determine which action was chosen\n",
    "            action_idx = spice_signals.actions[timestep].argmax(dim=-1)\n",
    "\n",
    "            # Map to item indices using current trial's shown items\n",
    "            item_chosen_idx = torch.where(action_idx == 0, shown_at_0_current[timestep], shown_at_1_current[timestep])\n",
    "            item_not_chosen_idx = torch.where(action_idx == 1, shown_at_0_current[timestep], shown_at_1_current[timestep])\n",
    "\n",
    "            # Create one-hot masks\n",
    "            item_chosen_onehot = torch.nn.functional.one_hot(item_chosen_idx, num_classes=self.n_items).float()\n",
    "            item_not_chosen_onehot = torch.nn.functional.one_hot(item_not_chosen_idx, num_classes=self.n_items).float()\n",
    "            item_not_displayed_onehot = 1 - (item_chosen_onehot + item_not_chosen_onehot)\n",
    "\n",
    "            # Map rewards from action space to item space\n",
    "            reward_action = spice_signals.rewards[timestep, :]  # shape: (batch, n_actions)\n",
    "\n",
    "            # Create reward tensor in item space (batch, n_items)\n",
    "            reward_item = torch.zeros(reward_action.shape[0], self.n_items, device=reward_action.device)\n",
    "\n",
    "            # Scatter rewards to the corresponding items:\n",
    "            # Item at shown_at_0_current gets reward for action 0\n",
    "            # Item at shown_at_1_current gets reward for action 1\n",
    "            reward_item.scatter_(1, shown_at_0_current[timestep].unsqueeze(-1), reward_action[:, 0].unsqueeze(-1))\n",
    "            reward_item.scatter_(1, shown_at_1_current[timestep].unsqueeze(-1), reward_action[:, 1].unsqueeze(-1))\n",
    "            \n",
    "            # Update chosen\n",
    "            self.call_module(\n",
    "                key_module='value_reward_chosen',\n",
    "                key_state='value_reward',\n",
    "                action_mask=item_chosen_onehot,\n",
    "                inputs=reward_item,\n",
    "                participant_index=spice_signals.participant_ids,\n",
    "                participant_embedding=participant_embeddings,\n",
    "            )\n",
    "\n",
    "            # Update not chosen\n",
    "            self.call_module(\n",
    "                key_module='value_reward_not_chosen',\n",
    "                key_state='value_reward',\n",
    "                action_mask=item_not_chosen_onehot,\n",
    "                inputs=None,\n",
    "                participant_index=spice_signals.participant_ids,\n",
    "                participant_embedding=participant_embeddings,\n",
    "            )\n",
    "\n",
    "            # Update not displayed\n",
    "            self.call_module(\n",
    "                key_module='value_reward_not_displayed',\n",
    "                key_state='value_reward',\n",
    "                action_mask=item_not_displayed_onehot,\n",
    "                inputs=None,\n",
    "                participant_index=spice_signals.participant_ids,\n",
    "                participant_embedding=participant_embeddings,\n",
    "            )\n",
    "\n",
    "            # Transform values from item space to action space for NEXT trial (for prediction)\n",
    "            # Use the time-shifted items (next trial's items)\n",
    "            value_at_0 = torch.gather(self.state['value_reward'], 1, shown_at_0_next[timestep].unsqueeze(-1))\n",
    "            value_at_1 = torch.gather(self.state['value_reward'], 1, shown_at_1_next[timestep].unsqueeze(-1))\n",
    "\n",
    "            # log action values\n",
    "            spice_signals.logits[timestep] = torch.concat([value_at_0, value_at_1], dim=-1)\n",
    "\n",
    "        spice_signals = self.post_forward_pass(spice_signals, batch_first)\n",
    "\n",
    "        return spice_signals.logits, self.get_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's setup now the `SpiceEstimator` object and fit it to the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "id": "3EnmDiUMWq6e",
    "outputId": "e53b1bbd-4173-4d2c-bcdc-15832bc31bd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training on cpu...\n",
      "================================================================================\n",
      "\n",
      "Training the RNN...\n",
      "Epoch 12/100 --- L(Train): 0.5929404; Time: 1.43s; Convergence: 8.60e-03\r"
     ]
    }
   ],
   "source": [
    "estimator = SpiceEstimator(\n",
    "        # model paramaeters\n",
    "        rnn_class=SPICERNN,\n",
    "        spice_config=spice_config,\n",
    "        n_actions=2,\n",
    "        n_items=6,\n",
    "        n_participants=n_participants,\n",
    "        \n",
    "        # training parameters\n",
    "        epochs=100,\n",
    "        learning_rate=0.1,\n",
    "        l2_rnn=0.00001,\n",
    "        l2_sindy=0.00001,\n",
    "        \n",
    "        sindy_epochs=10,\n",
    "        sindy_weight=0.,#1,  # --> sindy_weight=0: SINDy coefficient optimization not activated; not necessary as long as SPICERNN does not learn\n",
    "        sindy_threshold=0.05,\n",
    "        sindy_threshold_frequency=100,\n",
    "        sindy_library_polynomial_degree=2,\n",
    "        \n",
    "        verbose=True,\n",
    "        save_path_spice='../params/augustat2025/spice_augustat2025.pkl',\n",
    "    )\n",
    "\n",
    "print(f\"\\nStarting training on {estimator.device}...\")\n",
    "print(\"=\" * 80)\n",
    "estimator.fit(dataset.xs, dataset.ys)\n",
    "# estimator.load_spice(args.model)\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nTraining complete!\")\n",
    "\n",
    "# Print example SPICE model for first participant\n",
    "print(\"\\nExample SPICE model (participant 0):\")\n",
    "print(\"-\" * 80)\n",
    "estimator.print_spice_model(participant_id=0)\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's code up a general RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, n_items, n_actions):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.gru_features = 32\n",
    "        self.n_items = n_items\n",
    "        self.n_actions = n_actions\n",
    "        \n",
    "        self.linear_in = torch.nn.Linear(in_features=input_size, out_features=self.gru_features)\n",
    "        self.gru = torch.nn.GRU(input_size=self.gru_features,hidden_size=n_items, batch_first=True)\n",
    "        self.linear_out = torch.nn.Linear(in_features=n_items, out_features=n_items)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        # Get item pairs (already 0-indexed in CSV, no need to subtract 1)\n",
    "        item_pairs = inputs[..., 2*self.n_actions:2*self.n_actions+2]\n",
    "        \n",
    "        y = self.linear_in(inputs.nan_to_num(0))\n",
    "        y, _ = self.gru(y)\n",
    "        y = self.linear_out(y)\n",
    "        \n",
    "        item1_values = torch.gather(y, 2, item_pairs[..., 0].unsqueeze(-1).nan_to_num(0).long())\n",
    "        item2_values = torch.gather(y, 2, item_pairs[..., 1].unsqueeze(-1).nan_to_num(0).long())\n",
    "        \n",
    "        # Stack to create logits for the pair\n",
    "        logits = torch.cat([item1_values, item2_values], dim=-1)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "model = GRU(dataset.xs.shape[-1], 6, 2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    logits = model(dataset.xs)\n",
    "    \n",
    "    # Reshape for loss computation\n",
    "    # FIX: Use .isnan() instead of != torch.nan (NaN != NaN is always True!)\n",
    "    valid_mask = ~dataset.xs[:, :, 0].reshape(-1).isnan()\n",
    "    logits_flat = logits.reshape(-1, 2)\n",
    "    labels_flat = dataset.ys[..., 1].reshape(-1).nan_to_num(0).long()\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = criterion(logits_flat[valid_mask], labels_flat[valid_mask])\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}: Loss: {loss.item()}\", end='\\r')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "spice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
