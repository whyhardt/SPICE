{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tf7jlYw4NA0v",
    "outputId": "0969ca34-675d-422e-cbfb-7387d9bcd8ad"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/whyhardt/SPICE.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oXIbg826NS5i",
    "outputId": "3825864a-cb2d-4ad5-f2e5-79a4e81dfc3e"
   },
   "outputs": [],
   "source": [
    "# !pip install -e SPICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "f0uVlABYznR5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For custom RNN\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data first with the `convert_dataset` method. This method returns a `SpiceDataset` object which we can use right away "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: torch.Size([277, 299, 9])\n",
      "Number of participants: 277\n",
      "Number of items in dataset: 6\n",
      "Number of actions in dataset: 2\n",
      "Number of additional inputs: 2\n"
     ]
    }
   ],
   "source": [
    "from spice import SpiceDataset, convert_dataset\n",
    "\n",
    "# Load your data\n",
    "dataset = convert_dataset(\n",
    "    file = '../data/augustat2025/augustat2025.csv',\n",
    "    df_participant_id='participant_id',\n",
    "    df_choice='choice',\n",
    "    df_reward='reward',\n",
    "    additional_inputs=['shown_at_0', 'shown_at_1'],\n",
    "    timeshift_additional_inputs=True,\n",
    "    )\n",
    "\n",
    "n_actions = dataset.ys.shape[-1]\n",
    "n_items = dataset.xs[..., 2*n_actions+1].nan_to_num(-1).max().int() + 1\n",
    "# in order to set up the participant embedding we have to compute the number of unique participants in our data \n",
    "# to get the number of participants n_participants we do:\n",
    "n_participants = len(dataset.xs[..., -1].unique())\n",
    "\n",
    "# instead of timeshift add the predictor states shown_at_0 and shown_at_1 of the next trial to the inputs\n",
    "# xs = dataset.xs[:, :-1]\n",
    "# ys = dataset.ys[:, :-1]\n",
    "# shown_next = dataset.xs[:, 1:, 2*2:-3]\n",
    "# xs = torch.concat((xs[..., :-3], shown_next, xs[..., -3:]), dim=-1)\n",
    "# dataset = SpiceDataset(xs, ys)\n",
    "\n",
    "# structure of dataset:\n",
    "# dataset has two main attributes: xs -> inputs; ys -> targets (next action)\n",
    "# shape: (n_participants*n_blocks*n_experiments, n_timesteps, features)\n",
    "# features are (n_actions * action, n_actions * reward, n_additional_inputs * additional_input, block_number, experiment_id, participant_id)\n",
    "print(f\"Shape of dataset: {dataset.xs.shape}\")\n",
    "print(f\"Number of participants: {n_participants}\")\n",
    "print(f\"Number of items in dataset: {n_items}\")\n",
    "print(f\"Number of actions in dataset: {n_actions}\")\n",
    "print(f\"Number of additional inputs: {dataset.xs.shape[-1]-2*n_actions-3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPICE setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to define the configuration for SPICE with a `SpiceConfig` object.\n",
    "\n",
    "The `SpiceConfig` takes as arguments \n",
    "1. `library_setup (dict)`: Defining the variable names of each module.\n",
    "2. `memory_state (dict)`: Defining the memory state variables and their initial values.\n",
    "3. `states_in_logit (list)`: Defining which of the memory state variables are used later for the logit computation. This is necessary for some background processes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spice import SpiceConfig\n",
    "\n",
    "spice_config = SpiceConfig(\n",
    "    library_setup={\n",
    "        'value_reward_chosen': ['reward'],\n",
    "        'value_reward_not_chosen': [],\n",
    "        'value_reward_not_displayed': [],\n",
    "    },\n",
    "    \n",
    "    memory_state={\n",
    "        'value_reward': 0.0,\n",
    "        },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we are going to define the SPICE model which is a child of the `BaseRNN` and `torch.nn.Module` class and takes as required arguments:\n",
    "1. `spice_config (SpiceConfig)`: previously defined SpiceConfig object\n",
    "2. `n_actions (int)`: number of possible actions in your dataset (including non-displayed ones if applicable).\n",
    "3. `n_participants (int)`: number of participants in your dataset.\n",
    "\n",
    "As usual for a `torch.nn.Module` we have to define at least the `__init__` method and the `forward` method.\n",
    "The `forward` method gets called when computing a forward pass through the model and takes as inputs `(inputs (SpiceDataset.xs), prev_state (dict, default: None), batch_first (bool, default: False))` and returns `(logits (torch.Tensor, shape: (n_participants*n_blocks*n_experiments, timesteps, n_actions)), updated_state (dict))`. Two necessary method calls inside the forward pass are:\n",
    "1. `self.init_forward_pass(inputs, prev_state, batch_first) -> SpiceSignals`: returns a `SpiceSignals` object which carries all relevant information already processed.\n",
    "2. `self.post_forward_pass(SpiceSignals, batch_first) -> SpiceSignals`: does some re-arranging of the logits to adhere to `batch_first`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spice import BaseRNN\n",
    "\n",
    "\n",
    "class SPICERNN(BaseRNN):\n",
    "\n",
    "    def __init__(self, spice_config, n_items, n_actions, n_participants, **kwargs):\n",
    "        super().__init__(spice_config=spice_config, n_items=n_items, n_actions=n_actions, n_participants=n_participants, **kwargs)\n",
    "        \n",
    "        self.participant_embedding = self.setup_embedding(num_embeddings=n_participants, embedding_size=self.embedding_size)\n",
    "\n",
    "        self.setup_module(key_module='value_reward_chosen', input_size=1+self.embedding_size)\n",
    "        self.setup_module(key_module='value_reward_not_chosen', input_size=self.embedding_size)\n",
    "        self.setup_module(key_module='value_reward_not_displayed', input_size=self.embedding_size)\n",
    "\n",
    "    def forward(self, inputs, prev_state, batch_first=False):\n",
    "\n",
    "        spice_signals = self.init_forward_pass(inputs, prev_state, batch_first)\n",
    "\n",
    "        # Get shown items (raw indices) - these are time-shifted, so they refer to the NEXT trial\n",
    "        shown_at_0_current = spice_signals.additional_inputs[..., 0].long()\n",
    "        shown_at_1_current = spice_signals.additional_inputs[..., 1].long()\n",
    "        shown_at_0_next = spice_signals.additional_inputs[..., 0].long()\n",
    "        shown_at_1_next = spice_signals.additional_inputs[..., 1].long()\n",
    "\n",
    "        participant_embeddings = self.participant_embedding(spice_signals.participant_ids)\n",
    "\n",
    "        for timestep in spice_signals.timesteps:\n",
    "\n",
    "            # Transform input data from action space to item space\n",
    "\n",
    "            # Determine which action was chosen\n",
    "            action_idx = spice_signals.actions[timestep].argmax(dim=-1)\n",
    "\n",
    "            # Map to item indices using current trial's shown items\n",
    "            item_chosen_idx = torch.where(action_idx == 0, shown_at_0_current[timestep], shown_at_1_current[timestep])\n",
    "            item_not_chosen_idx = torch.where(action_idx == 1, shown_at_0_current[timestep], shown_at_1_current[timestep])\n",
    "\n",
    "            # Create one-hot masks\n",
    "            item_chosen_onehot = torch.nn.functional.one_hot(item_chosen_idx, num_classes=self.n_items).float()\n",
    "            item_not_chosen_onehot = torch.nn.functional.one_hot(item_not_chosen_idx, num_classes=self.n_items).float()\n",
    "            item_not_displayed_onehot = 1 - (item_chosen_onehot + item_not_chosen_onehot)\n",
    "\n",
    "            # Map rewards from action space to item space\n",
    "            reward_action = spice_signals.rewards[timestep, :]  # shape: (batch, n_actions)\n",
    "\n",
    "            # Create reward tensor in item space (batch, n_items)\n",
    "            reward_item = torch.zeros(reward_action.shape[0], self.n_items, device=reward_action.device)\n",
    "\n",
    "            # Scatter rewards to the corresponding items:\n",
    "            # Item at shown_at_0_current gets reward for action 0\n",
    "            # Item at shown_at_1_current gets reward for action 1\n",
    "            reward_item.scatter_(1, shown_at_0_current[timestep].unsqueeze(-1), reward_action[:, 0].unsqueeze(-1))\n",
    "            reward_item.scatter_(1, shown_at_1_current[timestep].unsqueeze(-1), reward_action[:, 1].unsqueeze(-1))\n",
    "            \n",
    "            # Update chosen\n",
    "            self.call_module(\n",
    "                key_module='value_reward_chosen',\n",
    "                key_state='value_reward',\n",
    "                action_mask=item_chosen_onehot,\n",
    "                inputs=reward_item,\n",
    "                participant_index=spice_signals.participant_ids,\n",
    "                participant_embedding=participant_embeddings,\n",
    "            )\n",
    "\n",
    "            # Update not chosen\n",
    "            self.call_module(\n",
    "                key_module='value_reward_not_chosen',\n",
    "                key_state='value_reward',\n",
    "                action_mask=item_not_chosen_onehot,\n",
    "                inputs=None,\n",
    "                participant_index=spice_signals.participant_ids,\n",
    "                participant_embedding=participant_embeddings,\n",
    "            )\n",
    "\n",
    "            # Update not displayed\n",
    "            self.call_module(\n",
    "                key_module='value_reward_not_displayed',\n",
    "                key_state='value_reward',\n",
    "                action_mask=item_not_displayed_onehot,\n",
    "                inputs=None,\n",
    "                participant_index=spice_signals.participant_ids,\n",
    "                participant_embedding=participant_embeddings,\n",
    "            )\n",
    "\n",
    "            # Transform values from item space to action space for NEXT trial (for prediction)\n",
    "            # Use the time-shifted items (next trial's items)\n",
    "            value_at_0 = torch.gather(self.state['value_reward'], 1, shown_at_0_next[timestep].unsqueeze(-1))\n",
    "            value_at_1 = torch.gather(self.state['value_reward'], 1, shown_at_1_next[timestep].unsqueeze(-1))\n",
    "\n",
    "            # log action values\n",
    "            spice_signals.logits[timestep] = torch.concat([value_at_0, value_at_1], dim=-1)\n",
    "\n",
    "        spice_signals = self.post_forward_pass(spice_signals, batch_first)\n",
    "\n",
    "        return spice_signals.logits, self.get_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's setup now the `SpiceEstimator` object and fit it to the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spice import SpiceEstimator\n",
    "\n",
    "path_spice = '../params/augustat2025/spice_augustat2025.pkl'\n",
    "\n",
    "estimator = SpiceEstimator(\n",
    "        # model paramaeters\n",
    "        rnn_class=SPICERNN,\n",
    "        spice_config=spice_config,\n",
    "        n_actions=n_actions,\n",
    "        n_items=n_items,\n",
    "        n_participants=n_participants,\n",
    "        \n",
    "        # rnn training parameters\n",
    "        epochs=10,\n",
    "        warmup_steps=200,\n",
    "        learning_rate=0.01,\n",
    "        \n",
    "        # sindy fitting parameters\n",
    "        sindy_weight=0.1,\n",
    "        sindy_threshold=0.05,\n",
    "        sindy_threshold_frequency=1,\n",
    "        sindy_threshold_terms=1,\n",
    "        sindy_cutoff_patience=100,\n",
    "        sindy_epochs=100,\n",
    "        sindy_alpha=0.0001,\n",
    "        sindy_library_polynomial_degree=2,\n",
    "        sindy_ensemble_size=1,\n",
    "        \n",
    "        # additional generalization parameters\n",
    "        bagging=True,\n",
    "        scheduler=True,\n",
    "        \n",
    "        verbose=True,\n",
    "        save_path_spice=path_spice,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 582
    },
    "id": "3EnmDiUMWq6e",
    "outputId": "e53b1bbd-4173-4d2c-bcdc-15832bc31bd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training on cpu...\n",
      "================================================================================\n",
      "\n",
      "Training the RNN...\n",
      "================================================================================\n",
      "Epoch 1/10 --- L(Train): 0.7623225 --- Time: 1.45s; --- Convergence: 6.19e-01; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = 0.011 1 + 0.99 value_reward_chosen[t] + 0.009 reward + 0.008 value_reward_chosen^2 + -0.008 value_reward_chosen*reward + 0.01 reward^2 \n",
      "value_reward_not_chosen[t+1] = -0.01 1 + 1.009 value_reward_not_chosen[t] + -0.007 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.01 1 + 0.992 value_reward_not_displayed[t] + 0.008 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 2/10 --- L(Train): 0.7340470 --- Time: 1.97s; --- Convergence: 3.24e-01; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = 0.018 1 + 0.984 value_reward_chosen[t] + 0.015 reward + 0.013 value_reward_chosen^2 + -0.014 value_reward_chosen*reward + 0.017 reward^2 \n",
      "value_reward_not_chosen[t+1] = -0.017 1 + 1.016 value_reward_not_chosen[t] + -0.012 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.016 1 + 0.985 value_reward_not_displayed[t] + 0.013 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 3/10 --- L(Train): 0.7177609 --- Time: 1.31s; --- Convergence: 1.70e-01; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = 0.018 1 + 0.982 value_reward_chosen[t] + 0.023 reward + 0.016 value_reward_chosen^2 + -0.021 value_reward_chosen*reward + 0.025 reward^2 \n",
      "value_reward_not_chosen[t+1] = -0.014 1 + 1.013 value_reward_not_chosen[t] + -0.009 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.011 1 + 0.978 value_reward_not_displayed[t] + 0.02 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 4/10 --- L(Train): 0.7095754 --- Time: 1.27s; --- Convergence: 8.91e-02; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = 0.013 1 + 0.986 value_reward_chosen[t] + 0.025 reward + 0.014 value_reward_chosen^2 + -0.025 value_reward_chosen*reward + 0.027 reward^2 \n",
      "value_reward_not_chosen[t+1] = -0.007 1 + 1.006 value_reward_not_chosen[t] + -0.003 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.009 1 + 0.97 value_reward_not_displayed[t] + 0.028 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 5/10 --- L(Train): 0.7071975 --- Time: 1.33s; --- Convergence: 4.57e-02; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = 0.006 1 + 0.992 value_reward_chosen[t] + 0.021 reward + 0.008 value_reward_chosen^2 + -0.022 value_reward_chosen*reward + 0.022 reward^2 \n",
      "value_reward_not_chosen[t+1] = -0.0 1 + 0.999 value_reward_not_chosen[t] + 0.004 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.012 1 + 0.961 value_reward_not_displayed[t] + 0.036 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 6/10 --- L(Train): 0.7077256 --- Time: 1.96s; --- Convergence: 2.31e-02; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = 0.0 1 + 0.998 value_reward_chosen[t] + 0.017 reward + 0.004 value_reward_chosen^2 + -0.02 value_reward_chosen*reward + 0.018 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.006 1 + 0.993 value_reward_not_chosen[t] + 0.009 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.014 1 + 0.954 value_reward_not_displayed[t] + 0.043 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 7/10 --- L(Train): 0.7063870 --- Time: 1.62s; --- Convergence: 1.22e-02; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.007 1 + 1.004 value_reward_chosen[t] + 0.011 reward + -0.002 value_reward_chosen^2 + -0.017 value_reward_chosen*reward + 0.012 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.013 1 + 0.986 value_reward_not_chosen[t] + 0.017 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.01 1 + 0.948 value_reward_not_displayed[t] + 0.05 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 8/10 --- L(Train): 0.7021267 --- Time: 2.85s; --- Convergence: 8.25e-03; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.014 1 + 1.012 value_reward_chosen[t] + 0.004 reward + -0.008 value_reward_chosen^2 + -0.017 value_reward_chosen*reward + 0.005 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.021 1 + 0.978 value_reward_not_chosen[t] + 0.024 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.008 1 + 0.94 value_reward_not_displayed[t] + 0.058 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 9/10 --- L(Train): 0.7023913 --- Time: 2.14s; --- Convergence: 4.25e-03; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.021 1 + 1.018 value_reward_chosen[t] + -0.003 reward + -0.013 value_reward_chosen^2 + -0.016 value_reward_chosen*reward + -0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.028 1 + 0.971 value_reward_not_chosen[t] + 0.031 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.007 1 + 0.933 value_reward_not_displayed[t] + 0.066 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 10/10 --- L(Train): 0.6999871 --- Time: 2.20s; --- Convergence: 3.33e-03; LR: 1.00e-02; Metric: inf; Bad epochs: 0/100\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.027 1 + 1.024 value_reward_chosen[t] + -0.008 reward + -0.018 value_reward_chosen^2 + -0.016 value_reward_chosen*reward + -0.007 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.034 1 + 0.964 value_reward_not_chosen[t] + 0.038 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.005 1 + 0.927 value_reward_not_displayed[t] + 0.072 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "Maximum number of training epochs reached.\n",
      "Model did not converge yet.\n",
      "\n",
      "================================================================================\n",
      "Starting second stage SINDy fitting (threshold=0.05, single model)\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 1/100 --- L(Train): 0.0649233 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.009 1 + 0.991 value_reward_chosen[t] + -0.01 reward + 0.01 value_reward_chosen^2 + 0.01 value_reward_chosen*reward + -0.01 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.011 1 + 0.99 value_reward_not_chosen[t] + 0.009 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.01 1 + 0.988 value_reward_not_displayed[t] + -0.009 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 2/100 --- L(Train): 0.0622815 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.018 1 + 0.982 value_reward_chosen[t] + -0.012 reward + 0.008 value_reward_chosen^2 + 0.005 value_reward_chosen*reward + -0.011 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.021 1 + 0.98 value_reward_not_chosen[t] + 0.01 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.02 1 + 0.978 value_reward_not_displayed[t] + -0.007 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 3/100 --- L(Train): 0.0598675 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.026 1 + 0.973 value_reward_chosen[t] + -0.009 reward + 0.004 value_reward_chosen^2 + -0.003 value_reward_chosen*reward + -0.008 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.031 1 + 0.971 value_reward_not_chosen[t] + 0.008 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.029 1 + 0.968 value_reward_not_displayed[t] + -0.001 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 4/100 --- L(Train): 0.0577274 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.034 1 + 0.964 value_reward_chosen[t] + -0.004 reward + -0.002 value_reward_chosen^2 + -0.008 value_reward_chosen*reward + -0.003 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.04 1 + 0.961 value_reward_not_chosen[t] + 0.004 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.036 1 + 0.958 value_reward_not_displayed[t] + 0.006 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 5/100 --- L(Train): 0.0558577 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.042 1 + 0.955 value_reward_chosen[t] + 0.002 reward + -0.005 value_reward_chosen^2 + -0.012 value_reward_chosen*reward + 0.004 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.05 1 + 0.953 value_reward_not_chosen[t] + -0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.043 1 + 0.948 value_reward_not_displayed[t] + 0.01 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 6/100 --- L(Train): 0.0542166 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.049 1 + 0.946 value_reward_chosen[t] + 0.007 reward + -0.005 value_reward_chosen^2 + -0.014 value_reward_chosen*reward + 0.008 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.06 1 + 0.946 value_reward_not_chosen[t] + -0.002 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.047 1 + 0.938 value_reward_not_displayed[t] + 0.012 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 7/100 --- L(Train): 0.0527359 --- L(Val, SINDy): 0.0000000 --- Time: 0.02s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.057 1 + 0.937 value_reward_chosen[t] + 0.012 reward + -0.003 value_reward_chosen^2 + -0.016 value_reward_chosen*reward + 0.012 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.069 1 + 0.941 value_reward_not_chosen[t] + -0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.048 1 + 0.928 value_reward_not_displayed[t] + 0.013 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 8/100 --- L(Train): 0.0513864 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.064 1 + 0.929 value_reward_chosen[t] + 0.015 reward + 0.001 value_reward_chosen^2 + -0.016 value_reward_chosen*reward + 0.014 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.079 1 + 0.938 value_reward_not_chosen[t] + 0.002 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.048 1 + 0.918 value_reward_not_displayed[t] + 0.012 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 9/100 --- L(Train): 0.0501548 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.071 1 + 0.92 value_reward_chosen[t] + 0.018 reward + 0.002 value_reward_chosen^2 + -0.016 value_reward_chosen*reward + 0.015 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.088 1 + 0.937 value_reward_not_chosen[t] + 0.003 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.047 1 + 0.908 value_reward_not_displayed[t] + 0.01 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 10/100 --- L(Train): 0.0490203 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.078 1 + 0.911 value_reward_chosen[t] + 0.021 reward + 0.001 value_reward_chosen^2 + -0.015 value_reward_chosen*reward + 0.015 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.097 1 + 0.938 value_reward_not_chosen[t] + 0.002 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.045 1 + 0.898 value_reward_not_displayed[t] + 0.008 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 11/100 --- L(Train): 0.0479696 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.084 1 + 0.902 value_reward_chosen[t] + 0.023 reward + -0.001 value_reward_chosen^2 + -0.013 value_reward_chosen*reward + 0.015 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.106 1 + 0.941 value_reward_not_chosen[t] + 0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.042 1 + 0.888 value_reward_not_displayed[t] + 0.005 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 12/100 --- L(Train): 0.0469894 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.089 1 + 0.893 value_reward_chosen[t] + 0.026 reward + -0.001 value_reward_chosen^2 + -0.011 value_reward_chosen*reward + 0.015 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.114 1 + 0.946 value_reward_not_chosen[t] + -0.002 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.039 1 + 0.878 value_reward_not_displayed[t] + 0.0 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 13/100 --- L(Train): 0.0460628 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.094 1 + 0.885 value_reward_chosen[t] + 0.028 reward + 0.0 value_reward_chosen^2 + -0.008 value_reward_chosen*reward + 0.014 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.123 1 + 0.952 value_reward_not_chosen[t] + -0.003 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.036 1 + 0.868 value_reward_not_displayed[t] + -0.004 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 14/100 --- L(Train): 0.0451804 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.097 1 + 0.876 value_reward_chosen[t] + 0.032 reward + -0.0 value_reward_chosen^2 + -0.005 value_reward_chosen*reward + 0.014 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.131 1 + 0.958 value_reward_not_chosen[t] + -0.003 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.034 1 + 0.858 value_reward_not_displayed[t] + -0.006 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 15/100 --- L(Train): 0.0443327 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.099 1 + 0.867 value_reward_chosen[t] + 0.035 reward + 0.001 value_reward_chosen^2 + -0.002 value_reward_chosen*reward + 0.013 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.138 1 + 0.966 value_reward_not_chosen[t] + -0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.032 1 + 0.848 value_reward_not_displayed[t] + -0.006 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 16/100 --- L(Train): 0.0435139 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.101 1 + 0.857 value_reward_chosen[t] + 0.039 reward + 0.0 value_reward_chosen^2 + 0.002 value_reward_chosen*reward + 0.012 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.145 1 + 0.974 value_reward_not_chosen[t] + 0.002 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.032 1 + 0.838 value_reward_not_displayed[t] + -0.004 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 17/100 --- L(Train): 0.0427213 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.102 1 + 0.848 value_reward_chosen[t] + 0.043 reward + -0.001 value_reward_chosen^2 + 0.002 value_reward_chosen*reward + 0.012 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.152 1 + 0.983 value_reward_not_chosen[t] + 0.003 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.032 1 + 0.828 value_reward_not_displayed[t] + -0.001 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 18/100 --- L(Train): 0.0419508 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.102 1 + 0.839 value_reward_chosen[t] + 0.047 reward + -0.001 value_reward_chosen^2 + 0.0 value_reward_chosen*reward + 0.01 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.158 1 + 0.993 value_reward_not_chosen[t] + 0.004 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.033 1 + 0.819 value_reward_not_displayed[t] + 0.003 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 19/100 --- L(Train): 0.0412020 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.102 1 + 0.83 value_reward_chosen[t] + 0.05 reward + -0.0 value_reward_chosen^2 + -0.004 value_reward_chosen*reward + 0.009 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.164 1 + 1.002 value_reward_not_chosen[t] + 0.002 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.034 1 + 0.809 value_reward_not_displayed[t] + 0.006 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 20/100 --- L(Train): 0.0404739 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.102 1 + 0.822 value_reward_chosen[t] + 0.053 reward + 0.002 value_reward_chosen^2 + -0.006 value_reward_chosen*reward + 0.007 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.17 1 + 1.007 value_reward_not_chosen[t] + 0.0 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.037 1 + 0.799 value_reward_not_displayed[t] + 0.007 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 21/100 --- L(Train): 0.0397634 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.102 1 + 0.813 value_reward_chosen[t] + 0.055 reward + 0.002 value_reward_chosen^2 + -0.008 value_reward_chosen*reward + 0.004 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.175 1 + 1.008 value_reward_not_chosen[t] + -0.003 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.039 1 + 0.789 value_reward_not_displayed[t] + 0.008 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 22/100 --- L(Train): 0.0390683 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.101 1 + 0.804 value_reward_chosen[t] + 0.057 reward + 0.002 value_reward_chosen^2 + -0.009 value_reward_chosen*reward + 0.0 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.179 1 + 1.006 value_reward_not_chosen[t] + -0.004 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.042 1 + 0.78 value_reward_not_displayed[t] + 0.007 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 23/100 --- L(Train): 0.0383906 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.101 1 + 0.795 value_reward_chosen[t] + 0.058 reward + 0.0 value_reward_chosen^2 + -0.01 value_reward_chosen*reward + -0.003 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.183 1 + 1.003 value_reward_not_chosen[t] + -0.004 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.045 1 + 0.77 value_reward_not_displayed[t] + 0.006 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 24/100 --- L(Train): 0.0377320 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.101 1 + 0.786 value_reward_chosen[t] + 0.059 reward + -0.002 value_reward_chosen^2 + -0.01 value_reward_chosen*reward + -0.005 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.186 1 + 0.998 value_reward_not_chosen[t] + -0.003 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.047 1 + 0.76 value_reward_not_displayed[t] + 0.004 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 25/100 --- L(Train): 0.0370899 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.101 1 + 0.778 value_reward_chosen[t] + 0.06 reward + -0.003 value_reward_chosen^2 + -0.009 value_reward_chosen*reward + -0.005 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.189 1 + 0.995 value_reward_not_chosen[t] + -0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.05 1 + 0.751 value_reward_not_displayed[t] + 0.001 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 0, 0, 0\n",
      "value_reward_not_chosen: 0, 0, 0\n",
      "value_reward_not_displayed: 0, 0, 0\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 26/100 --- L(Train): 0.0364623 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.101 1 + 0.769 value_reward_chosen[t] + 0.06 reward + -0.003 value_reward_chosen^2 + -0.007 value_reward_chosen*reward + -0.004 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.191 1 + 0.994 value_reward_not_chosen[t] + 0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.051 1 + 0.741 value_reward_not_displayed[t] + -0.002 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 1, 1, 1\n",
      "value_reward_not_chosen: 0, 1, 1\n",
      "value_reward_not_displayed: 0, 0, 1\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 27/100 --- L(Train): 0.0358501 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.1 1 + 0.761 value_reward_chosen[t] + 0.059 reward + -0.002 value_reward_chosen^2 + -0.005 value_reward_chosen*reward + -0.002 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.193 1 + 0.994 value_reward_not_chosen[t] + 0.003 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.052 1 + 0.732 value_reward_not_displayed[t] + -0.003 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 2, 2, 2\n",
      "value_reward_not_chosen: 0, 2, 2\n",
      "value_reward_not_displayed: 0, 0, 2\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 28/100 --- L(Train): 0.0352520 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.101 1 + 0.753 value_reward_chosen[t] + 0.058 reward + -0.0 value_reward_chosen^2 + -0.003 value_reward_chosen*reward + 0.002 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.194 1 + 0.996 value_reward_not_chosen[t] + 0.003 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.052 1 + 0.722 value_reward_not_displayed[t] + -0.003 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 3, 3, 3\n",
      "value_reward_not_chosen: 0, 3, 3\n",
      "value_reward_not_displayed: 0, 0, 3\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 29/100 --- L(Train): 0.0346674 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.101 1 + 0.745 value_reward_chosen[t] + 0.056 reward + 0.003 value_reward_chosen^2 + -0.0 value_reward_chosen*reward + 0.003 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.195 1 + 0.999 value_reward_not_chosen[t] + 0.002 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.052 1 + 0.712 value_reward_not_displayed[t] + -0.001 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 4, 4, 4\n",
      "value_reward_not_chosen: 0, 4, 4\n",
      "value_reward_not_displayed: 0, 0, 4\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 30/100 --- L(Train): 0.0340967 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.102 1 + 0.736 value_reward_chosen[t] + 0.054 reward + 0.004 value_reward_chosen^2 + 0.003 value_reward_chosen*reward + 0.004 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.195 1 + 1.002 value_reward_not_chosen[t] + 0.0 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.051 1 + 0.703 value_reward_not_displayed[t] + 0.002 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 5, 5, 5\n",
      "value_reward_not_chosen: 0, 5, 5\n",
      "value_reward_not_displayed: 0, 0, 5\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 31/100 --- L(Train): 0.0335402 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.103 1 + 0.728 value_reward_chosen[t] + 0.051 reward + 0.004 value_reward_chosen^2 + 0.004 value_reward_chosen*reward + 0.004 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.195 1 + 1.004 value_reward_not_chosen[t] + -0.003 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.05 1 + 0.693 value_reward_not_displayed[t] + 0.004 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 0, 6, 6, 6\n",
      "value_reward_not_chosen: 0, 6, 6\n",
      "value_reward_not_displayed: 0, 0, 6\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 32/100 --- L(Train): 0.0329972 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.104 1 + 0.721 value_reward_chosen[t] + 0.047 reward + 0.003 value_reward_chosen^2 + 0.003 value_reward_chosen*reward + 0.002 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.195 1 + 1.004 value_reward_not_chosen[t] + -0.004 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.05 1 + 0.684 value_reward_not_displayed[t] + 0.005 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 1, 7, 7, 7\n",
      "value_reward_not_chosen: 0, 7, 7\n",
      "value_reward_not_displayed: 1, 0, 7\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 33/100 --- L(Train): 0.0324668 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.105 1 + 0.713 value_reward_chosen[t] + 0.044 reward + 0.002 value_reward_chosen^2 + 0.0 value_reward_chosen*reward + 0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.194 1 + 1.003 value_reward_not_chosen[t] + -0.004 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.049 1 + 0.674 value_reward_not_displayed[t] + 0.004 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 2, 8, 8, 8\n",
      "value_reward_not_chosen: 0, 8, 8\n",
      "value_reward_not_displayed: 2, 0, 8\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 34/100 --- L(Train): 0.0319477 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.105 1 + 0.705 value_reward_chosen[t] + 0.042 reward + -0.001 value_reward_chosen^2 + -0.004 value_reward_chosen*reward + -0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.193 1 + 1.0 value_reward_not_chosen[t] + -0.004 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.048 1 + 0.665 value_reward_not_displayed[t] + 0.004 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 3, 9, 9, 9\n",
      "value_reward_not_chosen: 0, 9, 9\n",
      "value_reward_not_displayed: 3, 0, 9\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 35/100 --- L(Train): 0.0314407 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.105 1 + 0.697 value_reward_chosen[t] + 0.041 reward + -0.002 value_reward_chosen^2 + -0.007 value_reward_chosen*reward + -0.0 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.192 1 + 0.996 value_reward_not_chosen[t] + -0.002 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.048 1 + 0.656 value_reward_not_displayed[t] + 0.002 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 4, 10, 10, 10\n",
      "value_reward_not_chosen: 0, 10, 10\n",
      "value_reward_not_displayed: 4, 0, 10\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 36/100 --- L(Train): 0.0309463 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.104 1 + 0.689 value_reward_chosen[t] + 0.04 reward + -0.002 value_reward_chosen^2 + -0.01 value_reward_chosen*reward + 0.002 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.19 1 + 0.994 value_reward_not_chosen[t] + 0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.049 1 + 0.646 value_reward_not_displayed[t] + -0.0 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 5, 11, 11, 11\n",
      "value_reward_not_chosen: 0, 11, 11\n",
      "value_reward_not_displayed: 5, 0, 11\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 37/100 --- L(Train): 0.0304645 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.103 1 + 0.681 value_reward_chosen[t] + 0.039 reward + -0.001 value_reward_chosen^2 + -0.011 value_reward_chosen*reward + 0.003 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.188 1 + 0.993 value_reward_not_chosen[t] + 0.002 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.049 1 + 0.637 value_reward_not_displayed[t] + -0.001 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 6, 12, 12, 12\n",
      "value_reward_not_chosen: 0, 12, 12\n",
      "value_reward_not_displayed: 6, 0, 12\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 38/100 --- L(Train): 0.0299935 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.102 1 + 0.674 value_reward_chosen[t] + 0.039 reward + 0.0 value_reward_chosen^2 + -0.012 value_reward_chosen*reward + 0.004 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.186 1 + 0.993 value_reward_not_chosen[t] + 0.002 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.05 1 + 0.628 value_reward_not_displayed[t] + -0.0 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 7, 13, 13, 13\n",
      "value_reward_not_chosen: 0, 13, 13\n",
      "value_reward_not_displayed: 0, 0, 13\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 39/100 --- L(Train): 0.0295338 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.1 1 + 0.666 value_reward_chosen[t] + 0.039 reward + 0.001 value_reward_chosen^2 + -0.012 value_reward_chosen*reward + 0.005 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.184 1 + 0.995 value_reward_not_chosen[t] + 0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.052 1 + 0.619 value_reward_not_displayed[t] + 0.002 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 8, 14, 14, 14\n",
      "value_reward_not_chosen: 0, 14, 14\n",
      "value_reward_not_displayed: 0, 0, 14\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 40/100 --- L(Train): 0.0290829 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.099 1 + 0.659 value_reward_chosen[t] + 0.038 reward + 0.001 value_reward_chosen^2 + -0.012 value_reward_chosen*reward + 0.004 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.182 1 + 0.997 value_reward_not_chosen[t] + -0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.053 1 + 0.609 value_reward_not_displayed[t] + 0.003 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 9, 15, 15, 15\n",
      "value_reward_not_chosen: 0, 15, 15\n",
      "value_reward_not_displayed: 0, 0, 15\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 41/100 --- L(Train): 0.0286422 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.099 1 + 0.651 value_reward_chosen[t] + 0.037 reward + -0.001 value_reward_chosen^2 + -0.011 value_reward_chosen*reward + 0.003 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.18 1 + 1.0 value_reward_not_chosen[t] + -0.002 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.055 1 + 0.6 value_reward_not_displayed[t] + 0.003 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 10, 16, 16, 16\n",
      "value_reward_not_chosen: 0, 16, 16\n",
      "value_reward_not_displayed: 0, 0, 16\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 42/100 --- L(Train): 0.0282109 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.098 1 + 0.644 value_reward_chosen[t] + 0.036 reward + -0.001 value_reward_chosen^2 + -0.009 value_reward_chosen*reward + 0.002 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.178 1 + 1.002 value_reward_not_chosen[t] + -0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.056 1 + 0.591 value_reward_not_displayed[t] + 0.002 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 11, 17, 17, 17\n",
      "value_reward_not_chosen: 0, 17, 17\n",
      "value_reward_not_displayed: 0, 0, 17\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 43/100 --- L(Train): 0.0277889 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.098 1 + 0.637 value_reward_chosen[t] + 0.035 reward + -0.001 value_reward_chosen^2 + -0.007 value_reward_chosen*reward + -0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.176 1 + 1.001 value_reward_not_chosen[t] + 0.0 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.057 1 + 0.582 value_reward_not_displayed[t] + 0.0 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 12, 18, 18, 18\n",
      "value_reward_not_chosen: 0, 18, 18\n",
      "value_reward_not_displayed: 0, 0, 18\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 44/100 --- L(Train): 0.0273767 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.098 1 + 0.63 value_reward_chosen[t] + 0.034 reward + 0.001 value_reward_chosen^2 + -0.004 value_reward_chosen*reward + -0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.174 1 + 0.999 value_reward_not_chosen[t] + 0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.058 1 + 0.573 value_reward_not_displayed[t] + -0.002 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 13, 19, 19, 19\n",
      "value_reward_not_chosen: 0, 19, 19\n",
      "value_reward_not_displayed: 0, 0, 19\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 45/100 --- L(Train): 0.0269742 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.098 1 + 0.623 value_reward_chosen[t] + 0.033 reward + 0.002 value_reward_chosen^2 + -0.001 value_reward_chosen*reward + 0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.172 1 + 0.999 value_reward_not_chosen[t] + -0.0 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.059 1 + 0.564 value_reward_not_displayed[t] + -0.003 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 14, 20, 20, 20\n",
      "value_reward_not_chosen: 0, 20, 20\n",
      "value_reward_not_displayed: 0, 0, 20\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 46/100 --- L(Train): 0.0265798 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.098 1 + 0.616 value_reward_chosen[t] + 0.032 reward + 0.001 value_reward_chosen^2 + 0.002 value_reward_chosen*reward + 0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.17 1 + 0.999 value_reward_not_chosen[t] + 0.0 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.06 1 + 0.555 value_reward_not_displayed[t] + -0.002 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 15, 21, 21, 21\n",
      "value_reward_not_chosen: 0, 21, 21\n",
      "value_reward_not_displayed: 0, 0, 21\n",
      "================================================================================\n",
      "================================================================================\n",
      "Epoch 47/100 --- L(Train): 0.0261936 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.097 1 + 0.609 value_reward_chosen[t] + 0.032 reward + -0.001 value_reward_chosen^2 + 0.004 value_reward_chosen*reward + 0.002 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.169 1 + 1.0 value_reward_not_chosen[t] + -0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.06 1 + 0.546 value_reward_not_displayed[t] + 0.0 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 16, 22, 22, 22\n",
      "value_reward_not_chosen: 0, 22, 22\n",
      "value_reward_not_displayed: 0, 0, 22\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2J================================================================================\n",
      "Epoch 48/100 --- L(Train): 0.0258156 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.098 1 + 0.603 value_reward_chosen[t] + 0.031 reward + -0.001 value_reward_chosen^2 + 0.003 value_reward_chosen*reward + 0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.167 1 + 1.0 value_reward_not_chosen[t] + -0.0 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.06 1 + 0.537 value_reward_not_displayed[t] + 0.001 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 17, 23, 23, 23\n",
      "value_reward_not_chosen: 0, 23, 23\n",
      "value_reward_not_displayed: 0, 0, 23\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 49/100 --- L(Train): 0.0254445 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.098 1 + 0.596 value_reward_chosen[t] + 0.031 reward + -0.0 value_reward_chosen^2 + 0.001 value_reward_chosen*reward + 0.0 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.166 1 + 1.0 value_reward_not_chosen[t] + 0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.06 1 + 0.528 value_reward_not_displayed[t] + 0.001 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 18, 24, 24, 24\n",
      "value_reward_not_chosen: 0, 24, 24\n",
      "value_reward_not_displayed: 0, 0, 24\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 50/100 --- L(Train): 0.0250810 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.098 1 + 0.59 value_reward_chosen[t] + 0.031 reward + 0.001 value_reward_chosen^2 + -0.003 value_reward_chosen*reward + -0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.165 1 + 0.999 value_reward_not_chosen[t] + 0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.06 1 + 0.519 value_reward_not_displayed[t] + 0.0 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 19, 25, 25, 25\n",
      "value_reward_not_chosen: 0, 25, 25\n",
      "value_reward_not_displayed: 0, 0, 25\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 51/100 --- L(Train): 0.0247245 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.098 1 + 0.583 value_reward_chosen[t] + 0.03 reward + 0.002 value_reward_chosen^2 + -0.005 value_reward_chosen*reward + -0.0 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.164 1 + 0.999 value_reward_not_chosen[t] + 0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.06 1 + 0.51 value_reward_not_displayed[t] + -0.001 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 20, 26, 26, 26\n",
      "value_reward_not_chosen: 0, 26, 26\n",
      "value_reward_not_displayed: 0, 0, 26\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 52/100 --- L(Train): 0.0243751 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.098 1 + 0.577 value_reward_chosen[t] + 0.03 reward + 0.001 value_reward_chosen^2 + -0.007 value_reward_chosen*reward + 0.002 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.163 1 + 0.999 value_reward_not_chosen[t] + -0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.06 1 + 0.502 value_reward_not_displayed[t] + -0.001 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 21, 27, 27, 27\n",
      "value_reward_not_chosen: 0, 27, 27\n",
      "value_reward_not_displayed: 0, 0, 27\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 53/100 --- L(Train): 0.0240326 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.099 1 + 0.571 value_reward_chosen[t] + 0.03 reward + -0.001 value_reward_chosen^2 + -0.008 value_reward_chosen*reward + 0.003 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.162 1 + 1.001 value_reward_not_chosen[t] + -0.002 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.06 1 + 0.493 value_reward_not_displayed[t] + 0.0 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 22, 28, 28, 28\n",
      "value_reward_not_chosen: 0, 28, 28\n",
      "value_reward_not_displayed: 0, 0, 28\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 54/100 --- L(Train): 0.0236974 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.1 1 + 0.565 value_reward_chosen[t] + 0.03 reward + -0.001 value_reward_chosen^2 + -0.008 value_reward_chosen*reward + 0.003 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.162 1 + 1.0 value_reward_not_chosen[t] + -0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.061 1 + 0.484 value_reward_not_displayed[t] + 0.0 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 23, 29, 29, 29\n",
      "value_reward_not_chosen: 0, 29, 29\n",
      "value_reward_not_displayed: 0, 0, 29\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 55/100 --- L(Train): 0.0233692 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.101 1 + 0.559 value_reward_chosen[t] + 0.029 reward + -0.001 value_reward_chosen^2 + -0.008 value_reward_chosen*reward + 0.003 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.161 1 + 0.999 value_reward_not_chosen[t] + 0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.062 1 + 0.475 value_reward_not_displayed[t] + -0.0 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 24, 30, 30, 30\n",
      "value_reward_not_chosen: 0, 30, 30\n",
      "value_reward_not_displayed: 0, 0, 30\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 56/100 --- L(Train): 0.0230477 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.102 1 + 0.553 value_reward_chosen[t] + 0.028 reward + 0.001 value_reward_chosen^2 + -0.007 value_reward_chosen*reward + 0.002 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.161 1 + 0.998 value_reward_not_chosen[t] + 0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.062 1 + 0.467 value_reward_not_displayed[t] + 0.0 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 25, 31, 31, 31\n",
      "value_reward_not_chosen: 0, 31, 31\n",
      "value_reward_not_displayed: 0, 0, 31\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 57/100 --- L(Train): 0.0227322 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.103 1 + 0.548 value_reward_chosen[t] + 0.028 reward + 0.001 value_reward_chosen^2 + -0.005 value_reward_chosen*reward + 0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.161 1 + 0.998 value_reward_not_chosen[t] + 0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.063 1 + 0.458 value_reward_not_displayed[t] + 0.0 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 26, 32, 32, 32\n",
      "value_reward_not_chosen: 0, 32, 32\n",
      "value_reward_not_displayed: 0, 0, 32\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 58/100 --- L(Train): 0.0224229 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.103 1 + 0.542 value_reward_chosen[t] + 0.027 reward + 0.001 value_reward_chosen^2 + -0.003 value_reward_chosen*reward + -0.0 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.161 1 + 0.999 value_reward_not_chosen[t] + -0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.064 1 + 0.45 value_reward_not_displayed[t] + -0.001 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 27, 33, 33, 33\n",
      "value_reward_not_chosen: 0, 33, 33\n",
      "value_reward_not_displayed: 0, 0, 33\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 59/100 --- L(Train): 0.0221205 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.104 1 + 0.537 value_reward_chosen[t] + 0.028 reward + -0.001 value_reward_chosen^2 + 0.0 value_reward_chosen*reward + 0.0 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.161 1 + 1.0 value_reward_not_chosen[t] + -0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.065 1 + 0.441 value_reward_not_displayed[t] + -0.0 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 28, 34, 34, 34\n",
      "value_reward_not_chosen: 0, 34, 34\n",
      "value_reward_not_displayed: 0, 0, 34\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 60/100 --- L(Train): 0.0218227 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.104 1 + 0.531 value_reward_chosen[t] + 0.029 reward + -0.001 value_reward_chosen^2 + 0.001 value_reward_chosen*reward + 0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.162 1 + 1.0 value_reward_not_chosen[t] + -0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.066 1 + 0.433 value_reward_not_displayed[t] + 0.001 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 29, 35, 35, 35\n",
      "value_reward_not_chosen: 0, 35, 35\n",
      "value_reward_not_displayed: 0, 0, 35\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 61/100 --- L(Train): 0.0215308 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.103 1 + 0.526 value_reward_chosen[t] + 0.03 reward + -0.001 value_reward_chosen^2 + -0.0 value_reward_chosen*reward + 0.0 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.162 1 + 1.001 value_reward_not_chosen[t] + 0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.067 1 + 0.424 value_reward_not_displayed[t] + 0.002 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 30, 36, 36, 36\n",
      "value_reward_not_chosen: 0, 36, 36\n",
      "value_reward_not_displayed: 0, 0, 36\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 62/100 --- L(Train): 0.0212454 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.103 1 + 0.52 value_reward_chosen[t] + 0.031 reward + 0.001 value_reward_chosen^2 + -0.0 value_reward_chosen*reward + -0.0 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.163 1 + 1.0 value_reward_not_chosen[t] + 0.002 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.067 1 + 0.416 value_reward_not_displayed[t] + 0.002 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 31, 37, 37, 37\n",
      "value_reward_not_chosen: 0, 37, 37\n",
      "value_reward_not_displayed: 0, 0, 37\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 63/100 --- L(Train): 0.0209667 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.103 1 + 0.515 value_reward_chosen[t] + 0.032 reward + 0.001 value_reward_chosen^2 + 0.0 value_reward_chosen*reward + 0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.163 1 + 0.999 value_reward_not_chosen[t] + 0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.068 1 + 0.408 value_reward_not_displayed[t] + 0.001 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 32, 38, 38, 38\n",
      "value_reward_not_chosen: 0, 38, 38\n",
      "value_reward_not_displayed: 0, 0, 38\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 64/100 --- L(Train): 0.0206921 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.103 1 + 0.51 value_reward_chosen[t] + 0.032 reward + 0.0 value_reward_chosen^2 + -0.001 value_reward_chosen*reward + 0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.164 1 + 1.0 value_reward_not_chosen[t] + -0.0 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.068 1 + 0.399 value_reward_not_displayed[t] + -0.001 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 33, 39, 39, 39\n",
      "value_reward_not_chosen: 0, 39, 39\n",
      "value_reward_not_displayed: 0, 0, 39\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 65/100 --- L(Train): 0.0204220 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.104 1 + 0.505 value_reward_chosen[t] + 0.033 reward + -0.001 value_reward_chosen^2 + -0.001 value_reward_chosen*reward + 0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.164 1 + 0.999 value_reward_not_chosen[t] + -0.0 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.068 1 + 0.391 value_reward_not_displayed[t] + -0.001 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 34, 40, 40, 40\n",
      "value_reward_not_chosen: 0, 40, 40\n",
      "value_reward_not_displayed: 0, 0, 40\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 66/100 --- L(Train): 0.0201577 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.104 1 + 0.5 value_reward_chosen[t] + 0.033 reward + -0.002 value_reward_chosen^2 + -0.001 value_reward_chosen*reward + -0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.165 1 + 0.999 value_reward_not_chosen[t] + 0.0 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.069 1 + 0.383 value_reward_not_displayed[t] + -0.001 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 35, 41, 41, 41\n",
      "value_reward_not_chosen: 0, 41, 41\n",
      "value_reward_not_displayed: 0, 0, 41\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 67/100 --- L(Train): 0.0198985 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.105 1 + 0.496 value_reward_chosen[t] + 0.032 reward + -0.001 value_reward_chosen^2 + 0.0 value_reward_chosen*reward + -0.0 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.166 1 + 1.0 value_reward_not_chosen[t] + 0.0 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.069 1 + 0.374 value_reward_not_displayed[t] + 0.002 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 36, 42, 42, 42\n",
      "value_reward_not_chosen: 0, 42, 42\n",
      "value_reward_not_displayed: 0, 0, 42\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 68/100 --- L(Train): 0.0196445 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.106 1 + 0.491 value_reward_chosen[t] + 0.032 reward + 0.0 value_reward_chosen^2 + -0.001 value_reward_chosen*reward + 0.002 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.166 1 + 0.999 value_reward_not_chosen[t] + -0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.069 1 + 0.366 value_reward_not_displayed[t] + 0.003 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 37, 43, 43, 43\n",
      "value_reward_not_chosen: 0, 43, 43\n",
      "value_reward_not_displayed: 0, 0, 43\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 69/100 --- L(Train): 0.0193956 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.107 1 + 0.487 value_reward_chosen[t] + 0.031 reward + 0.0 value_reward_chosen^2 + -0.0 value_reward_chosen*reward + 0.003 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.167 1 + 1.0 value_reward_not_chosen[t] + -0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.07 1 + 0.358 value_reward_not_displayed[t] + 0.003 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 38, 44, 44, 44\n",
      "value_reward_not_chosen: 0, 44, 44\n",
      "value_reward_not_displayed: 0, 0, 44\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 70/100 --- L(Train): 0.0191509 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.108 1 + 0.482 value_reward_chosen[t] + 0.03 reward + -0.0 value_reward_chosen^2 + 0.0 value_reward_chosen*reward + 0.003 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.168 1 + 1.0 value_reward_not_chosen[t] + -0.0 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.07 1 + 0.35 value_reward_not_displayed[t] + 0.002 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 39, 45, 45, 45\n",
      "value_reward_not_chosen: 0, 45, 45\n",
      "value_reward_not_displayed: 0, 0, 45\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 71/100 --- L(Train): 0.0189109 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.109 1 + 0.478 value_reward_chosen[t] + 0.029 reward + 0.0 value_reward_chosen^2 + -0.0 value_reward_chosen*reward + 0.003 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.168 1 + 1.0 value_reward_not_chosen[t] + 0.002 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.071 1 + 0.342 value_reward_not_displayed[t] + 0.0 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 40, 46, 46, 46\n",
      "value_reward_not_chosen: 0, 46, 46\n",
      "value_reward_not_displayed: 0, 0, 46\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 72/100 --- L(Train): 0.0186753 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.11 1 + 0.474 value_reward_chosen[t] + 0.028 reward + -0.001 value_reward_chosen^2 + -0.0 value_reward_chosen*reward + 0.002 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.169 1 + 1.0 value_reward_not_chosen[t] + 0.002 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.071 1 + 0.334 value_reward_not_displayed[t] + -0.002 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 41, 47, 47, 47\n",
      "value_reward_not_chosen: 0, 47, 47\n",
      "value_reward_not_displayed: 0, 0, 47\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 73/100 --- L(Train): 0.0184441 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.11 1 + 0.47 value_reward_chosen[t] + 0.028 reward + -0.0 value_reward_chosen^2 + 0.0 value_reward_chosen*reward + 0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.169 1 + 0.999 value_reward_not_chosen[t] + 0.002 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.072 1 + 0.326 value_reward_not_displayed[t] + -0.003 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 42, 48, 48, 48\n",
      "value_reward_not_chosen: 0, 48, 48\n",
      "value_reward_not_displayed: 0, 0, 48\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 74/100 --- L(Train): 0.0182177 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.11 1 + 0.466 value_reward_chosen[t] + 0.028 reward + 0.001 value_reward_chosen^2 + -0.001 value_reward_chosen*reward + 0.0 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.169 1 + 0.999 value_reward_not_chosen[t] + 0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.073 1 + 0.318 value_reward_not_displayed[t] + -0.002 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 43, 49, 49, 49\n",
      "value_reward_not_chosen: 0, 49, 49\n",
      "value_reward_not_displayed: 0, 0, 49\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 75/100 --- L(Train): 0.0179954 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.109 1 + 0.461 value_reward_chosen[t] + 0.029 reward + 0.001 value_reward_chosen^2 + -0.001 value_reward_chosen*reward + -0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.17 1 + 0.999 value_reward_not_chosen[t] + -0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.073 1 + 0.31 value_reward_not_displayed[t] + -0.0 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 44, 50, 50, 50\n",
      "value_reward_not_chosen: 0, 50, 50\n",
      "value_reward_not_displayed: 0, 0, 50\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 76/100 --- L(Train): 0.0177772 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.109 1 + 0.458 value_reward_chosen[t] + 0.03 reward + 0.0 value_reward_chosen^2 + -0.0 value_reward_chosen*reward + -0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.17 1 + 1.001 value_reward_not_chosen[t] + -0.002 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.074 1 + 0.302 value_reward_not_displayed[t] + 0.002 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 45, 51, 51, 51\n",
      "value_reward_not_chosen: 0, 51, 51\n",
      "value_reward_not_displayed: 0, 0, 51\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 77/100 --- L(Train): 0.0175625 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.108 1 + 0.454 value_reward_chosen[t] + 0.031 reward + -0.001 value_reward_chosen^2 + 0.001 value_reward_chosen*reward + 0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.17 1 + 1.0 value_reward_not_chosen[t] + -0.002 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.075 1 + 0.294 value_reward_not_displayed[t] + 0.004 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 46, 52, 52, 52\n",
      "value_reward_not_chosen: 0, 52, 52\n",
      "value_reward_not_displayed: 0, 0, 52\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 78/100 --- L(Train): 0.0173520 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.107 1 + 0.45 value_reward_chosen[t] + 0.032 reward + -0.002 value_reward_chosen^2 + 0.0 value_reward_chosen*reward + 0.002 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.17 1 + 0.999 value_reward_not_chosen[t] + -0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.075 1 + 0.287 value_reward_not_displayed[t] + 0.005 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 47, 53, 53, 53\n",
      "value_reward_not_chosen: 0, 53, 53\n",
      "value_reward_not_displayed: 0, 0, 53\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 79/100 --- L(Train): 0.0171454 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.107 1 + 0.446 value_reward_chosen[t] + 0.032 reward + -0.001 value_reward_chosen^2 + -0.002 value_reward_chosen*reward + 0.003 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.171 1 + 0.998 value_reward_not_chosen[t] + 0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.076 1 + 0.279 value_reward_not_displayed[t] + 0.004 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 48, 54, 54, 54\n",
      "value_reward_not_chosen: 0, 54, 54\n",
      "value_reward_not_displayed: 0, 0, 54\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 80/100 --- L(Train): 0.0169418 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.107 1 + 0.443 value_reward_chosen[t] + 0.031 reward + -0.0 value_reward_chosen^2 + -0.003 value_reward_chosen*reward + 0.002 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.171 1 + 0.999 value_reward_not_chosen[t] + 0.002 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.076 1 + 0.271 value_reward_not_displayed[t] + 0.003 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 49, 55, 55, 55\n",
      "value_reward_not_chosen: 0, 55, 55\n",
      "value_reward_not_displayed: 0, 0, 55\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 81/100 --- L(Train): 0.0167417 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.108 1 + 0.439 value_reward_chosen[t] + 0.03 reward + 0.002 value_reward_chosen^2 + -0.003 value_reward_chosen*reward + 0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.171 1 + 1.0 value_reward_not_chosen[t] + 0.002 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.076 1 + 0.264 value_reward_not_displayed[t] + 0.001 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 50, 56, 56, 56\n",
      "value_reward_not_chosen: 0, 56, 56\n",
      "value_reward_not_displayed: 0, 0, 56\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 82/100 --- L(Train): 0.0165461 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.109 1 + 0.436 value_reward_chosen[t] + 0.029 reward + 0.003 value_reward_chosen^2 + -0.002 value_reward_chosen*reward + -0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.171 1 + 1.001 value_reward_not_chosen[t] + 0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.077 1 + 0.256 value_reward_not_displayed[t] + -0.001 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 51, 57, 57, 57\n",
      "value_reward_not_chosen: 0, 57, 57\n",
      "value_reward_not_displayed: 0, 0, 57\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 83/100 --- L(Train): 0.0163545 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.11 1 + 0.433 value_reward_chosen[t] + 0.027 reward + 0.003 value_reward_chosen^2 + -0.001 value_reward_chosen*reward + -0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.17 1 + 1.002 value_reward_not_chosen[t] + -0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.077 1 + 0.248 value_reward_not_displayed[t] + -0.002 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 52, 58, 58, 58\n",
      "value_reward_not_chosen: 0, 58, 58\n",
      "value_reward_not_displayed: 0, 0, 58\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 84/100 --- L(Train): 0.0161656 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.11 1 + 0.43 value_reward_chosen[t] + 0.027 reward + 0.002 value_reward_chosen^2 + 0.001 value_reward_chosen*reward + 0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.17 1 + 1.0 value_reward_not_chosen[t] + -0.002 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.077 1 + 0.241 value_reward_not_displayed[t] + -0.002 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 53, 59, 59, 59\n",
      "value_reward_not_chosen: 0, 59, 59\n",
      "value_reward_not_displayed: 0, 0, 59\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 85/100 --- L(Train): 0.0159792 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.111 1 + 0.427 value_reward_chosen[t] + 0.027 reward + -0.0 value_reward_chosen^2 + 0.001 value_reward_chosen*reward + 0.002 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.17 1 + 0.998 value_reward_not_chosen[t] + -0.002 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.078 1 + 0.233 value_reward_not_displayed[t] + -0.0 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 54, 60, 60, 60\n",
      "value_reward_not_chosen: 0, 60, 60\n",
      "value_reward_not_displayed: 0, 0, 60\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 86/100 --- L(Train): 0.0157971 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.11 1 + 0.424 value_reward_chosen[t] + 0.027 reward + -0.001 value_reward_chosen^2 + -0.0 value_reward_chosen*reward + 0.003 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.17 1 + 0.997 value_reward_not_chosen[t] + -0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.078 1 + 0.226 value_reward_not_displayed[t] + 0.002 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 55, 61, 61, 61\n",
      "value_reward_not_chosen: 0, 61, 61\n",
      "value_reward_not_displayed: 0, 0, 61\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 87/100 --- L(Train): 0.0156191 --- L(Val, SINDy): 0.0000000 --- Time: 0.04s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.11 1 + 0.421 value_reward_chosen[t] + 0.027 reward + -0.001 value_reward_chosen^2 + -0.001 value_reward_chosen*reward + 0.003 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.17 1 + 0.996 value_reward_not_chosen[t] + 0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.079 1 + 0.218 value_reward_not_displayed[t] + 0.003 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 56, 62, 62, 62\n",
      "value_reward_not_chosen: 0, 62, 62\n",
      "value_reward_not_displayed: 0, 0, 62\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 88/100 --- L(Train): 0.0154439 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.11 1 + 0.418 value_reward_chosen[t] + 0.027 reward + 0.001 value_reward_chosen^2 + -0.001 value_reward_chosen*reward + 0.002 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.169 1 + 0.996 value_reward_not_chosen[t] + 0.002 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.079 1 + 0.211 value_reward_not_displayed[t] + 0.004 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 57, 63, 63, 63\n",
      "value_reward_not_chosen: 0, 63, 63\n",
      "value_reward_not_displayed: 0, 0, 63\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 89/100 --- L(Train): 0.0152710 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.11 1 + 0.415 value_reward_chosen[t] + 0.027 reward + 0.001 value_reward_chosen^2 + 0.0 value_reward_chosen*reward + 0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.169 1 + 0.998 value_reward_not_chosen[t] + 0.002 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.08 1 + 0.204 value_reward_not_displayed[t] + 0.003 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 58, 64, 64, 64\n",
      "value_reward_not_chosen: 0, 64, 64\n",
      "value_reward_not_displayed: 0, 0, 64\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 90/100 --- L(Train): 0.0151010 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.11 1 + 0.413 value_reward_chosen[t] + 0.027 reward + -0.0 value_reward_chosen^2 + -0.0 value_reward_chosen*reward + 0.0 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.169 1 + 1.0 value_reward_not_chosen[t] + 0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.08 1 + 0.196 value_reward_not_displayed[t] + 0.002 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 59, 65, 65, 65\n",
      "value_reward_not_chosen: 0, 65, 65\n",
      "value_reward_not_displayed: 0, 0, 65\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 91/100 --- L(Train): 0.0149337 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.11 1 + 0.41 value_reward_chosen[t] + 0.027 reward + -0.0 value_reward_chosen^2 + -0.0 value_reward_chosen*reward + -0.002 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.169 1 + 1.002 value_reward_not_chosen[t] + -0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.081 1 + 0.189 value_reward_not_displayed[t] + -0.0 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 60, 66, 66, 66\n",
      "value_reward_not_chosen: 0, 66, 66\n",
      "value_reward_not_displayed: 0, 0, 66\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 92/100 --- L(Train): 0.0147698 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.109 1 + 0.407 value_reward_chosen[t] + 0.028 reward + 0.001 value_reward_chosen^2 + 0.001 value_reward_chosen*reward + -0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.169 1 + 1.003 value_reward_not_chosen[t] + -0.002 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.082 1 + 0.182 value_reward_not_displayed[t] + -0.001 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 61, 67, 67, 67\n",
      "value_reward_not_chosen: 0, 67, 67\n",
      "value_reward_not_displayed: 0, 0, 67\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 93/100 --- L(Train): 0.0146090 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.109 1 + 0.405 value_reward_chosen[t] + 0.028 reward + 0.001 value_reward_chosen^2 + -0.0 value_reward_chosen*reward + 0.0 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.168 1 + 1.002 value_reward_not_chosen[t] + -0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.082 1 + 0.175 value_reward_not_displayed[t] + -0.0 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 62, 68, 68, 68\n",
      "value_reward_not_chosen: 0, 68, 68\n",
      "value_reward_not_displayed: 0, 0, 68\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 94/100 --- L(Train): 0.0144512 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.109 1 + 0.403 value_reward_chosen[t] + 0.028 reward + 0.0 value_reward_chosen^2 + 0.0 value_reward_chosen*reward + 0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.168 1 + 1.0 value_reward_not_chosen[t] + 0.0 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.082 1 + 0.168 value_reward_not_displayed[t] + 0.002 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 63, 69, 69, 69\n",
      "value_reward_not_chosen: 0, 69, 69\n",
      "value_reward_not_displayed: 0, 0, 69\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 95/100 --- L(Train): 0.0142963 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.109 1 + 0.4 value_reward_chosen[t] + 0.028 reward + -0.002 value_reward_chosen^2 + -0.001 value_reward_chosen*reward + 0.002 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.168 1 + 0.997 value_reward_not_chosen[t] + 0.0 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.083 1 + 0.16 value_reward_not_displayed[t] + 0.002 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 64, 70, 70, 70\n",
      "value_reward_not_chosen: 0, 70, 70\n",
      "value_reward_not_displayed: 0, 0, 70\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 96/100 --- L(Train): 0.0141434 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.109 1 + 0.398 value_reward_chosen[t] + 0.028 reward + -0.002 value_reward_chosen^2 + -0.002 value_reward_chosen*reward + 0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.168 1 + 0.995 value_reward_not_chosen[t] + -0.0 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.083 1 + 0.153 value_reward_not_displayed[t] + 0.002 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 65, 71, 71, 71\n",
      "value_reward_not_chosen: 0, 71, 71\n",
      "value_reward_not_displayed: 0, 0, 71\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 97/100 --- L(Train): 0.0139934 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.11 1 + 0.396 value_reward_chosen[t] + 0.027 reward + -0.002 value_reward_chosen^2 + -0.002 value_reward_chosen*reward + -0.0 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.168 1 + 0.994 value_reward_not_chosen[t] + -0.0 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.084 1 + 0.146 value_reward_not_displayed[t] + 0.001 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 66, 72, 72, 72\n",
      "value_reward_not_chosen: 0, 72, 72\n",
      "value_reward_not_displayed: 0, 0, 72\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 98/100 --- L(Train): 0.0138461 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.111 1 + 0.394 value_reward_chosen[t] + 0.026 reward + -0.001 value_reward_chosen^2 + -0.001 value_reward_chosen*reward + 0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.168 1 + 0.994 value_reward_not_chosen[t] + 0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.084 1 + 0.139 value_reward_not_displayed[t] + -0.001 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 67, 73, 73, 73\n",
      "value_reward_not_chosen: 0, 73, 73\n",
      "value_reward_not_displayed: 0, 0, 73\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 99/100 --- L(Train): 0.0137014 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.111 1 + 0.392 value_reward_chosen[t] + 0.026 reward + 0.001 value_reward_chosen^2 + 0.001 value_reward_chosen*reward + 0.001 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.168 1 + 0.994 value_reward_not_chosen[t] + 0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.084 1 + 0.132 value_reward_not_displayed[t] + -0.002 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 68, 74, 74, 74\n",
      "value_reward_not_chosen: 0, 74, 74\n",
      "value_reward_not_displayed: 0, 0, 74\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 100/100 --- L(Train): 0.0135601 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.112 1 + 0.39 value_reward_chosen[t] + 0.025 reward + 0.002 value_reward_chosen^2 + 0.001 value_reward_chosen*reward + 0.0 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.168 1 + 0.996 value_reward_not_chosen[t] + 0.0 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.085 1 + 0.126 value_reward_not_displayed[t] + -0.001 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 69, 75, 75, 75\n",
      "value_reward_not_chosen: 0, 75, 75\n",
      "value_reward_not_displayed: 0, 0, 75\n",
      "================================================================================\n",
      "\u001b[H\u001b[2J================================================================================\n",
      "Epoch 101/100 --- L(Train): 0.0134214 --- L(Val, SINDy): 0.0000000 --- Time: 0.03s;\n",
      "--------------------------------------------------------------------------------\n",
      "SPICE Model (Coefficients: 12):\n",
      "value_reward_chosen[t+1] = -0.112 1 + 0.388 value_reward_chosen[t] + 0.026 reward + 0.002 value_reward_chosen^2 + -0.0 value_reward_chosen*reward + -0.0 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.168 1 + 0.998 value_reward_not_chosen[t] + -0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.085 1 + 0.119 value_reward_not_displayed[t] + 0.001 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n",
      "Cutoff patience:\n",
      "value_reward_chosen: 0, 0, 70, 76, 76, 76\n",
      "value_reward_not_chosen: 0, 76, 76\n",
      "value_reward_not_displayed: 0, 0, 76\n",
      "================================================================================\n",
      "\n",
      "Training result:\n",
      "L(Train): 0.6999871 --- LR: 1.0000000e-02\n",
      "\n",
      "RNN training finished.\n",
      "Training took 22.22 seconds.\n",
      "Saving SPICE model to ../params/augustat2025/spice_augustat2025.pkl...\n",
      "================================================================================\n",
      "\n",
      "Training complete!\n",
      "\n",
      "Example SPICE model (participant 0):\n",
      "--------------------------------------------------------------------------------\n",
      "value_reward_chosen[t+1] = -0.112 1 + 0.388 value_reward_chosen[t] + 0.026 reward + 0.002 value_reward_chosen^2 + -0.0 value_reward_chosen*reward + -0.0 reward^2 \n",
      "value_reward_not_chosen[t+1] = 0.168 1 + 0.998 value_reward_not_chosen[t] + -0.001 value_reward_not_chosen^2 \n",
      "value_reward_not_displayed[t+1] = -0.085 1 + 0.119 value_reward_not_displayed[t] + 0.001 value_reward_not_displayed^2 \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nStarting training on {estimator.device}...\")\n",
    "print(\"=\" * 80)\n",
    "estimator.fit(dataset.xs, dataset.ys)\n",
    "# estimator.load_spice(args.model)\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nTraining complete!\")\n",
    "\n",
    "# Print example SPICE model for first participant\n",
    "print(\"\\nExample SPICE model (participant 0):\")\n",
    "print(\"-\" * 80)\n",
    "estimator.print_spice_model(participant_id=0)\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.load_spice(path_spice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU for benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's code up a general RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../..')\n",
    "from weinhardt2025.benchmarking.benchmarking_gru import training, setup_agent_gru\n",
    "\n",
    "path_gru = '../../weinhardt2025/params/augustat2025/gru_augustat2025.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU specifications:\n",
    "# 1. In order to function seamlessly with the rest of the framework the GRU has to output (logits, hidden_state)\n",
    "# 2. Because of the task type (more items to remember than displayed for action; n_items > n_actions):\n",
    "#   2.1 The GRU computes the action values for all items at each timestep (chosen, not chosen but displayed, and not displayed)\n",
    "#   2.2 To facilitate selection only among the shown options, the GRU has to map the values from the item space (all values) to the action space (only displayed ones)\n",
    "\n",
    "class GRU(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_actions, n_items, additional_inputs: int = 0, hidden_size: int = 32, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.gru_features = hidden_size\n",
    "        self.n_items = n_items\n",
    "        self.n_actions = n_actions\n",
    "        self.additional_inputs = additional_inputs\n",
    "\n",
    "        self.linear_in = torch.nn.Linear(in_features=n_actions+1+additional_inputs, out_features=hidden_size)\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "        self.gru = torch.nn.GRU(input_size=hidden_size, hidden_size=hidden_size, batch_first=True)\n",
    "        self.linear_out = torch.nn.Linear(in_features=hidden_size, out_features=n_items)\n",
    "        \n",
    "    def forward(self, inputs, state=None):\n",
    "        \n",
    "        actions = inputs[..., :self.n_actions]\n",
    "        rewards = inputs[..., self.n_actions:2*self.n_actions].nan_to_num(0).sum(dim=-1, keepdims=True)\n",
    "        item_pairs = inputs[..., self.n_actions*2:self.n_actions*2+self.additional_inputs]\n",
    "        inputs = torch.concat((actions, rewards, item_pairs), dim=-1)\n",
    "        \n",
    "        # Get item pairs\n",
    "        # item_pairs = inputs[..., 3*self.n_actions:3*self.n_actions+2]\n",
    "        \n",
    "        if state is not None and len(inputs.shape) == 3:\n",
    "            state = state.reshape(1, 1, self.gru_features)\n",
    "        \n",
    "        y = self.linear_in(inputs.nan_to_num(0))\n",
    "        y = self.dropout(y)\n",
    "        y, state = self.gru(y, state)\n",
    "        y = self.dropout(y)\n",
    "        y = self.linear_out(y)\n",
    "        \n",
    "        # map values from item space into action space to determine the next action based on the shown options\n",
    "        item1_values = torch.gather(y, 2, item_pairs[..., 0].unsqueeze(-1).nan_to_num(0).long())\n",
    "        item2_values = torch.gather(y, 2, item_pairs[..., 1].unsqueeze(-1).nan_to_num(0).long())\n",
    "        y = torch.cat([item1_values, item2_values], dim=-1)\n",
    "        \n",
    "        return y, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "\n",
    "gru = GRU(n_actions=n_actions, n_items=n_items, additional_inputs=2).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(gru.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000: L(Train): 0.7009412050247192; L(Test): 0.5093771815299988\n",
      "Epoch 2/10000: L(Train): 0.5227321982383728; L(Test): 0.45035237073898315\n",
      "Epoch 3/10000: L(Train): 0.44902223348617554; L(Test): 0.4551859498023987\n",
      "Epoch 4/10000: L(Train): 0.4612513780593872; L(Test): 0.4627416431903839\n",
      "Epoch 5/10000: L(Train): 0.4827776551246643; L(Test): 0.46277356147766113\n",
      "Epoch 6/10000: L(Train): 0.48096445202827454; L(Test): 0.45957043766975403\n",
      "Epoch 7/10000: L(Train): 0.4847868084907532; L(Test): 0.4574134051799774\n",
      "Epoch 8/10000: L(Train): 0.4624394178390503; L(Test): 0.45383220911026\n",
      "Epoch 9/10000: L(Train): 0.45397713780403137; L(Test): 0.44826045632362366\n",
      "Epoch 10/10000: L(Train): 0.44171079993247986; L(Test): 0.4440813958644867\n",
      "Epoch 11/10000: L(Train): 0.4446544945240021; L(Test): 0.4442868232727051\n",
      "Epoch 12/10000: L(Train): 0.45118066668510437; L(Test): 0.44706982374191284\n",
      "Epoch 13/10000: L(Train): 0.4523163437843323; L(Test): 0.4489726424217224\n",
      "Epoch 14/10000: L(Train): 0.45999959111213684; L(Test): 0.44822999835014343\n",
      "Epoch 15/10000: L(Train): 0.465218186378479; L(Test): 0.4458584189414978\n",
      "Epoch 16/10000: L(Train): 0.43876373767852783; L(Test): 0.44379812479019165\n",
      "Epoch 17/10000: L(Train): 0.45125746726989746; L(Test): 0.44192051887512207\n",
      "Epoch 18/10000: L(Train): 0.44450467824935913; L(Test): 0.44110509753227234\n",
      "Epoch 19/10000: L(Train): 0.43744564056396484; L(Test): 0.442231684923172\n",
      "Epoch 20/10000: L(Train): 0.450239360332489; L(Test): 0.44354766607284546\n",
      "Epoch 21/10000: L(Train): 0.43546563386917114; L(Test): 0.4435935914516449\n",
      "Epoch 22/10000: L(Train): 0.454960435628891; L(Test): 0.4427170753479004\n",
      "Epoch 23/10000: L(Train): 0.43527546525001526; L(Test): 0.442249059677124\n",
      "Epoch 24/10000: L(Train): 0.4379778206348419; L(Test): 0.44177356362342834\n",
      "Epoch 25/10000: L(Train): 0.44578444957733154; L(Test): 0.44111883640289307\n",
      "Epoch 26/10000: L(Train): 0.43722373247146606; L(Test): 0.44082415103912354\n",
      "Epoch 27/10000: L(Train): 0.4339310824871063; L(Test): 0.44108691811561584\n",
      "Epoch 28/10000: L(Train): 0.4498254656791687; L(Test): 0.4410203993320465\n",
      "Epoch 29/10000: L(Train): 0.4587562680244446; L(Test): 0.44080832600593567\n",
      "Epoch 30/10000: L(Train): 0.4547145664691925; L(Test): 0.4413139820098877\n",
      "Epoch 31/10000: L(Train): 0.4529002010822296; L(Test): 0.44231748580932617\n",
      "Epoch 32/10000: L(Train): 0.4452674090862274; L(Test): 0.4418236315250397\n",
      "Epoch 33/10000: L(Train): 0.46094557642936707; L(Test): 0.4409583806991577\n",
      "Epoch 34/10000: L(Train): 0.44392991065979004; L(Test): 0.4399525821208954\n",
      "Epoch 35/10000: L(Train): 0.4345436096191406; L(Test): 0.4390634596347809\n",
      "Epoch 36/10000: L(Train): 0.4460248351097107; L(Test): 0.4386904835700989\n",
      "Epoch 37/10000: L(Train): 0.447551965713501; L(Test): 0.43872907757759094\n",
      "Epoch 38/10000: L(Train): 0.4480140209197998; L(Test): 0.4386950731277466\n",
      "Epoch 39/10000: L(Train): 0.4368491768836975; L(Test): 0.4388112723827362\n",
      "Epoch 40/10000: L(Train): 0.45320767164230347; L(Test): 0.4387889802455902\n",
      "Epoch 41/10000: L(Train): 0.453782856464386; L(Test): 0.43845394253730774\n",
      "Epoch 42/10000: L(Train): 0.4483170807361603; L(Test): 0.4378770887851715\n",
      "Epoch 43/10000: L(Train): 0.43778809905052185; L(Test): 0.4369561970233917\n",
      "Epoch 44/10000: L(Train): 0.44223257899284363; L(Test): 0.43649083375930786\n",
      "Epoch 45/10000: L(Train): 0.4259742498397827; L(Test): 0.4364241063594818\n",
      "Epoch 46/10000: L(Train): 0.4406750202178955; L(Test): 0.4361006021499634\n",
      "Epoch 47/10000: L(Train): 0.43386369943618774; L(Test): 0.4359012246131897\n",
      "Epoch 48/10000: L(Train): 0.439875990152359; L(Test): 0.4355930984020233\n",
      "Epoch 49/10000: L(Train): 0.44619473814964294; L(Test): 0.4351940453052521\n",
      "Epoch 50/10000: L(Train): 0.4370135962963104; L(Test): 0.4351314306259155\n",
      "Epoch 51/10000: L(Train): 0.41913509368896484; L(Test): 0.4342185854911804\n",
      "Epoch 52/10000: L(Train): 0.45101475715637207; L(Test): 0.43389859795570374\n",
      "Epoch 53/10000: L(Train): 0.4242211878299713; L(Test): 0.43465104699134827\n",
      "Epoch 54/10000: L(Train): 0.4254041314125061; L(Test): 0.43589985370635986\n",
      "Epoch 55/10000: L(Train): 0.4394903779029846; L(Test): 0.4338546693325043\n",
      "Epoch 56/10000: L(Train): 0.431304395198822; L(Test): 0.4324433505535126\n",
      "Epoch 57/10000: L(Train): 0.4232172667980194; L(Test): 0.43206554651260376\n",
      "Epoch 58/10000: L(Train): 0.4336589574813843; L(Test): 0.43126362562179565\n",
      "Epoch 59/10000: L(Train): 0.4346182942390442; L(Test): 0.43055295944213867\n",
      "Epoch 60/10000: L(Train): 0.43505069613456726; L(Test): 0.4302920699119568\n",
      "Epoch 61/10000: L(Train): 0.41735586524009705; L(Test): 0.43080344796180725\n",
      "Epoch 62/10000: L(Train): 0.45130667090415955; L(Test): 0.4298098683357239\n",
      "Epoch 63/10000: L(Train): 0.4369317293167114; L(Test): 0.42865777015686035\n",
      "Epoch 64/10000: L(Train): 0.4245985746383667; L(Test): 0.42790740728378296\n",
      "Epoch 65/10000: L(Train): 0.42485371232032776; L(Test): 0.4278489947319031\n",
      "Epoch 66/10000: L(Train): 0.41726577281951904; L(Test): 0.427569180727005\n",
      "Epoch 67/10000: L(Train): 0.431184858083725; L(Test): 0.42648816108703613\n",
      "Epoch 68/10000: L(Train): 0.4235926568508148; L(Test): 0.4255824685096741\n",
      "Epoch 69/10000: L(Train): 0.42815643548965454; L(Test): 0.42436712980270386\n",
      "Epoch 70/10000: L(Train): 0.4356839656829834; L(Test): 0.4231845736503601\n",
      "Epoch 71/10000: L(Train): 0.4187542796134949; L(Test): 0.4228828549385071\n",
      "Epoch 72/10000: L(Train): 0.43128547072410583; L(Test): 0.422012060880661\n",
      "Epoch 73/10000: L(Train): 0.41804277896881104; L(Test): 0.4212321639060974\n",
      "Epoch 74/10000: L(Train): 0.4336419105529785; L(Test): 0.42014485597610474\n",
      "Epoch 75/10000: L(Train): 0.4277339279651642; L(Test): 0.4187041223049164\n",
      "Epoch 76/10000: L(Train): 0.42752566933631897; L(Test): 0.41841521859169006\n",
      "Epoch 77/10000: L(Train): 0.4294669032096863; L(Test): 0.41926902532577515\n",
      "Epoch 78/10000: L(Train): 0.4223593473434448; L(Test): 0.426057368516922\n",
      "Epoch 79/10000: L(Train): 0.4382439851760864; L(Test): 0.4157922863960266\n",
      "Epoch 80/10000: L(Train): 0.4284869432449341; L(Test): 0.4308311641216278\n",
      "Epoch 81/10000: L(Train): 0.44573503732681274; L(Test): 0.4162271022796631\n",
      "Epoch 82/10000: L(Train): 0.4424580931663513; L(Test): 0.4222225248813629\n",
      "Epoch 83/10000: L(Train): 0.416385293006897; L(Test): 0.4174354374408722\n",
      "Epoch 84/10000: L(Train): 0.4246486723423004; L(Test): 0.41533708572387695\n",
      "Epoch 85/10000: L(Train): 0.42165622115135193; L(Test): 0.4191621243953705\n",
      "Epoch 86/10000: L(Train): 0.43026554584503174; L(Test): 0.41354814171791077\n",
      "Epoch 87/10000: L(Train): 0.4006400406360626; L(Test): 0.4156067371368408\n",
      "Epoch 88/10000: L(Train): 0.4133434593677521; L(Test): 0.41718384623527527\n",
      "Epoch 89/10000: L(Train): 0.4427392780780792; L(Test): 0.41077715158462524\n",
      "Epoch 90/10000: L(Train): 0.4262033700942993; L(Test): 0.4178752601146698\n",
      "Epoch 91/10000: L(Train): 0.4187677800655365; L(Test): 0.4112115800380707\n",
      "Epoch 92/10000: L(Train): 0.4002666473388672; L(Test): 0.4120813310146332\n",
      "Epoch 93/10000: L(Train): 0.4095635712146759; L(Test): 0.417201429605484\n",
      "Epoch 94/10000: L(Train): 0.422500342130661; L(Test): 0.410238116979599\n",
      "Epoch 95/10000: L(Train): 0.4039073586463928; L(Test): 0.40819475054740906\n",
      "Epoch 96/10000: L(Train): 0.41599661111831665; L(Test): 0.4131421446800232\n",
      "Epoch 97/10000: L(Train): 0.4027574956417084; L(Test): 0.40622004866600037\n",
      "Epoch 98/10000: L(Train): 0.41217005252838135; L(Test): 0.4105182886123657\n",
      "Epoch 99/10000: L(Train): 0.4260024428367615; L(Test): 0.4094858765602112\n",
      "Epoch 100/10000: L(Train): 0.4226561188697815; L(Test): 0.4045896828174591\n",
      "Epoch 101/10000: L(Train): 0.4059939384460449; L(Test): 0.40692126750946045\n",
      "Epoch 102/10000: L(Train): 0.4222649335861206; L(Test): 0.40420201420783997\n",
      "Epoch 103/10000: L(Train): 0.40021219849586487; L(Test): 0.4038532078266144\n",
      "Epoch 104/10000: L(Train): 0.41102027893066406; L(Test): 0.4068326950073242\n",
      "Epoch 105/10000: L(Train): 0.39521491527557373; L(Test): 0.4030579924583435\n",
      "Epoch 106/10000: L(Train): 0.40575140714645386; L(Test): 0.39969533681869507\n",
      "Epoch 107/10000: L(Train): 0.4069362282752991; L(Test): 0.40143096446990967\n",
      "Epoch 108/10000: L(Train): 0.41905584931373596; L(Test): 0.39845192432403564\n",
      "Epoch 109/10000: L(Train): 0.3952282965183258; L(Test): 0.3985061049461365\n",
      "Epoch 110/10000: L(Train): 0.38875851035118103; L(Test): 0.4012378454208374\n",
      "Epoch 111/10000: L(Train): 0.39736777544021606; L(Test): 0.3980501890182495\n",
      "Epoch 112/10000: L(Train): 0.41789913177490234; L(Test): 0.39470770955085754\n",
      "Epoch 113/10000: L(Train): 0.38965335488319397; L(Test): 0.39583757519721985\n",
      "Epoch 114/10000: L(Train): 0.39400020241737366; L(Test): 0.3926505148410797\n",
      "Epoch 115/10000: L(Train): 0.4054977595806122; L(Test): 0.39411380887031555\n",
      "Epoch 116/10000: L(Train): 0.40512731671333313; L(Test): 0.3931506872177124\n",
      "Epoch 117/10000: L(Train): 0.3857390284538269; L(Test): 0.3906117081642151\n",
      "Epoch 118/10000: L(Train): 0.3868666887283325; L(Test): 0.3900100588798523\n",
      "Epoch 119/10000: L(Train): 0.39115816354751587; L(Test): 0.3891175091266632\n",
      "Epoch 120/10000: L(Train): 0.384254515171051; L(Test): 0.38841092586517334\n",
      "Epoch 121/10000: L(Train): 0.39760905504226685; L(Test): 0.3878881633281708\n",
      "Epoch 122/10000: L(Train): 0.40488022565841675; L(Test): 0.3868464529514313\n",
      "Epoch 123/10000: L(Train): 0.3776090443134308; L(Test): 0.3858090341091156\n",
      "Epoch 124/10000: L(Train): 0.3811964690685272; L(Test): 0.3850773572921753\n",
      "Epoch 125/10000: L(Train): 0.39114516973495483; L(Test): 0.38456231355667114\n",
      "Epoch 126/10000: L(Train): 0.39059922099113464; L(Test): 0.3843330144882202\n",
      "Epoch 127/10000: L(Train): 0.37702521681785583; L(Test): 0.3841291069984436\n",
      "Epoch 128/10000: L(Train): 0.38129833340644836; L(Test): 0.38322946429252625\n",
      "Epoch 129/10000: L(Train): 0.3884556293487549; L(Test): 0.3821931481361389\n",
      "Epoch 130/10000: L(Train): 0.3803269863128662; L(Test): 0.3814178705215454\n",
      "Epoch 131/10000: L(Train): 0.39004918932914734; L(Test): 0.38086917996406555\n",
      "Epoch 132/10000: L(Train): 0.3897850513458252; L(Test): 0.3803902566432953\n",
      "Epoch 133/10000: L(Train): 0.3855087161064148; L(Test): 0.37981370091438293\n",
      "Epoch 134/10000: L(Train): 0.37002134323120117; L(Test): 0.3795424997806549\n",
      "Epoch 135/10000: L(Train): 0.38701948523521423; L(Test): 0.37890011072158813\n",
      "Epoch 136/10000: L(Train): 0.3782612681388855; L(Test): 0.3780021369457245\n",
      "Epoch 137/10000: L(Train): 0.37412455677986145; L(Test): 0.37738144397735596\n",
      "Epoch 138/10000: L(Train): 0.38934528827667236; L(Test): 0.3767702579498291\n",
      "Epoch 139/10000: L(Train): 0.3613097369670868; L(Test): 0.3764788508415222\n",
      "Epoch 140/10000: L(Train): 0.4021282196044922; L(Test): 0.375963032245636\n",
      "Epoch 141/10000: L(Train): 0.3766900599002838; L(Test): 0.37520644068717957\n",
      "Epoch 142/10000: L(Train): 0.38859042525291443; L(Test): 0.37446117401123047\n",
      "Epoch 143/10000: L(Train): 0.3673839867115021; L(Test): 0.3738415539264679\n",
      "Epoch 144/10000: L(Train): 0.3654648959636688; L(Test): 0.3735451400279999\n",
      "Epoch 145/10000: L(Train): 0.3790828585624695; L(Test): 0.3732090890407562\n",
      "Epoch 146/10000: L(Train): 0.38289719820022583; L(Test): 0.37225714325904846\n",
      "Epoch 147/10000: L(Train): 0.38549625873565674; L(Test): 0.3712816536426544\n",
      "Epoch 148/10000: L(Train): 0.3755831718444824; L(Test): 0.37062352895736694\n",
      "Epoch 149/10000: L(Train): 0.37484925985336304; L(Test): 0.3701349198818207\n",
      "Epoch 150/10000: L(Train): 0.39012208580970764; L(Test): 0.36986207962036133\n",
      "Epoch 151/10000: L(Train): 0.3604351580142975; L(Test): 0.3691837191581726\n",
      "Epoch 152/10000: L(Train): 0.3632676601409912; L(Test): 0.3683779835700989\n",
      "Epoch 153/10000: L(Train): 0.3891221582889557; L(Test): 0.36735349893569946\n",
      "Epoch 154/10000: L(Train): 0.3831978738307953; L(Test): 0.3668270707130432\n",
      "Epoch 155/10000: L(Train): 0.3764697313308716; L(Test): 0.36631500720977783\n",
      "Epoch 156/10000: L(Train): 0.37338998913764954; L(Test): 0.3658517301082611\n",
      "Epoch 157/10000: L(Train): 0.390698105096817; L(Test): 0.36496567726135254\n",
      "Epoch 158/10000: L(Train): 0.3732754588127136; L(Test): 0.3643600046634674\n",
      "Epoch 159/10000: L(Train): 0.35738298296928406; L(Test): 0.36433911323547363\n",
      "Epoch 160/10000: L(Train): 0.3637964725494385; L(Test): 0.3637045919895172\n",
      "Epoch 161/10000: L(Train): 0.3687950372695923; L(Test): 0.36315885186195374\n",
      "Epoch 162/10000: L(Train): 0.3666681945323944; L(Test): 0.3623078167438507\n",
      "Epoch 163/10000: L(Train): 0.3658871054649353; L(Test): 0.3616441488265991\n",
      "Epoch 164/10000: L(Train): 0.37016546726226807; L(Test): 0.3617839813232422\n",
      "Epoch 165/10000: L(Train): 0.3883345425128937; L(Test): 0.3604770302772522\n",
      "Epoch 166/10000: L(Train): 0.36496642231941223; L(Test): 0.3602113425731659\n",
      "Epoch 167/10000: L(Train): 0.3757156729698181; L(Test): 0.3600311279296875\n",
      "Epoch 168/10000: L(Train): 0.35876375436782837; L(Test): 0.35967621207237244\n",
      "Epoch 169/10000: L(Train): 0.3702950179576874; L(Test): 0.3593882620334625\n",
      "Epoch 170/10000: L(Train): 0.35572290420532227; L(Test): 0.3587453365325928\n",
      "Epoch 171/10000: L(Train): 0.36654552817344666; L(Test): 0.35754966735839844\n",
      "Epoch 172/10000: L(Train): 0.35682016611099243; L(Test): 0.3566780388355255\n",
      "Epoch 173/10000: L(Train): 0.35971158742904663; L(Test): 0.356540709733963\n",
      "Epoch 174/10000: L(Train): 0.3503991663455963; L(Test): 0.3575470447540283\n",
      "Epoch 175/10000: L(Train): 0.3628172278404236; L(Test): 0.3560519516468048\n",
      "Epoch 176/10000: L(Train): 0.3503324091434479; L(Test): 0.3547574281692505\n",
      "Epoch 177/10000: L(Train): 0.3596172034740448; L(Test): 0.3543702960014343\n",
      "Epoch 178/10000: L(Train): 0.36501070857048035; L(Test): 0.35382944345474243\n",
      "Epoch 179/10000: L(Train): 0.3602435290813446; L(Test): 0.3536774218082428\n",
      "Epoch 180/10000: L(Train): 0.34997832775115967; L(Test): 0.3539147675037384\n",
      "Epoch 181/10000: L(Train): 0.3736366331577301; L(Test): 0.35280969738960266\n",
      "Epoch 182/10000: L(Train): 0.35575300455093384; L(Test): 0.3519372045993805\n",
      "Epoch 183/10000: L(Train): 0.3566439747810364; L(Test): 0.3515394330024719\n",
      "Epoch 184/10000: L(Train): 0.3786211311817169; L(Test): 0.35124072432518005\n",
      "Epoch 185/10000: L(Train): 0.38065865635871887; L(Test): 0.35081371665000916\n",
      "Epoch 186/10000: L(Train): 0.3511413633823395; L(Test): 0.35097768902778625\n",
      "Epoch 187/10000: L(Train): 0.3633245527744293; L(Test): 0.35093188285827637\n",
      "Epoch 188/10000: L(Train): 0.35524821281433105; L(Test): 0.350227415561676\n",
      "Epoch 189/10000: L(Train): 0.3545393943786621; L(Test): 0.34977591037750244\n",
      "Epoch 190/10000: L(Train): 0.35099196434020996; L(Test): 0.3496420979499817\n",
      "Epoch 191/10000: L(Train): 0.34858670830726624; L(Test): 0.34987494349479675\n",
      "Epoch 192/10000: L(Train): 0.34720852971076965; L(Test): 0.3492448329925537\n",
      "Epoch 193/10000: L(Train): 0.3449532389640808; L(Test): 0.34851551055908203\n",
      "Epoch 194/10000: L(Train): 0.3628554940223694; L(Test): 0.348151296377182\n",
      "Epoch 195/10000: L(Train): 0.3577488958835602; L(Test): 0.3482501208782196\n",
      "Epoch 196/10000: L(Train): 0.34457531571388245; L(Test): 0.34832438826560974\n",
      "Epoch 197/10000: L(Train): 0.3648231625556946; L(Test): 0.3470773696899414\n",
      "Epoch 198/10000: L(Train): 0.3401477038860321; L(Test): 0.34686118364334106\n",
      "Epoch 199/10000: L(Train): 0.3491676449775696; L(Test): 0.34734416007995605\n",
      "Epoch 200/10000: L(Train): 0.3589440882205963; L(Test): 0.3462173342704773\n",
      "Epoch 201/10000: L(Train): 0.3423311710357666; L(Test): 0.3460492491722107\n",
      "Epoch 202/10000: L(Train): 0.3523176610469818; L(Test): 0.34646451473236084\n",
      "Epoch 203/10000: L(Train): 0.36817583441734314; L(Test): 0.3460400104522705\n",
      "Epoch 204/10000: L(Train): 0.34995001554489136; L(Test): 0.3456008732318878\n",
      "Epoch 205/10000: L(Train): 0.34736043214797974; L(Test): 0.3452702462673187\n",
      "Epoch 206/10000: L(Train): 0.350042462348938; L(Test): 0.34493154287338257\n",
      "Epoch 207/10000: L(Train): 0.35104966163635254; L(Test): 0.3443644344806671\n",
      "Epoch 208/10000: L(Train): 0.3571126461029053; L(Test): 0.34420108795166016\n",
      "Epoch 209/10000: L(Train): 0.36057737469673157; L(Test): 0.3441915512084961\n",
      "Epoch 210/10000: L(Train): 0.3391802906990051; L(Test): 0.34456807374954224\n",
      "Epoch 211/10000: L(Train): 0.355013906955719; L(Test): 0.344037801027298\n",
      "Epoch 212/10000: L(Train): 0.3364254832267761; L(Test): 0.3432576656341553\n",
      "Epoch 213/10000: L(Train): 0.32970041036605835; L(Test): 0.34286656975746155\n",
      "Epoch 214/10000: L(Train): 0.34469351172447205; L(Test): 0.34253454208374023\n",
      "Epoch 215/10000: L(Train): 0.33217573165893555; L(Test): 0.34245049953460693\n",
      "Epoch 216/10000: L(Train): 0.3401719927787781; L(Test): 0.34186530113220215\n",
      "Epoch 217/10000: L(Train): 0.34680354595184326; L(Test): 0.3415645360946655\n",
      "Epoch 218/10000: L(Train): 0.3418622314929962; L(Test): 0.34244126081466675\n",
      "Epoch 219/10000: L(Train): 0.343598335981369; L(Test): 0.34108901023864746\n",
      "Epoch 220/10000: L(Train): 0.3464031219482422; L(Test): 0.340374618768692\n",
      "Epoch 221/10000: L(Train): 0.3407113254070282; L(Test): 0.34049198031425476\n",
      "Epoch 222/10000: L(Train): 0.3605094254016876; L(Test): 0.3415628969669342\n",
      "Epoch 223/10000: L(Train): 0.34139513969421387; L(Test): 0.3401065468788147\n",
      "Epoch 224/10000: L(Train): 0.33554279804229736; L(Test): 0.3394152820110321\n",
      "Epoch 225/10000: L(Train): 0.34279340505599976; L(Test): 0.33921873569488525\n",
      "Epoch 226/10000: L(Train): 0.34326788783073425; L(Test): 0.33893612027168274\n",
      "Epoch 227/10000: L(Train): 0.3336699604988098; L(Test): 0.338680237531662\n",
      "Epoch 228/10000: L(Train): 0.3407609760761261; L(Test): 0.3384247124195099\n",
      "Epoch 229/10000: L(Train): 0.34556108713150024; L(Test): 0.3378007709980011\n",
      "Epoch 230/10000: L(Train): 0.36653241515159607; L(Test): 0.33744001388549805\n",
      "Epoch 231/10000: L(Train): 0.33827638626098633; L(Test): 0.33799535036087036\n",
      "Epoch 232/10000: L(Train): 0.3636646270751953; L(Test): 0.33685651421546936\n",
      "Epoch 233/10000: L(Train): 0.3388581871986389; L(Test): 0.33616867661476135\n",
      "Epoch 234/10000: L(Train): 0.34431371092796326; L(Test): 0.3359808921813965\n",
      "Epoch 235/10000: L(Train): 0.34713804721832275; L(Test): 0.3360300064086914\n",
      "Epoch 236/10000: L(Train): 0.3614262342453003; L(Test): 0.33584967255592346\n",
      "Epoch 237/10000: L(Train): 0.35430893301963806; L(Test): 0.33490803837776184\n",
      "Epoch 238/10000: L(Train): 0.33837154507637024; L(Test): 0.3346869945526123\n",
      "Epoch 239/10000: L(Train): 0.34232401847839355; L(Test): 0.33465683460235596\n",
      "Epoch 240/10000: L(Train): 0.3272857367992401; L(Test): 0.33400341868400574\n",
      "Epoch 241/10000: L(Train): 0.3411467373371124; L(Test): 0.3334251046180725\n",
      "Epoch 242/10000: L(Train): 0.34545183181762695; L(Test): 0.3328130543231964\n",
      "Epoch 243/10000: L(Train): 0.350298136472702; L(Test): 0.3325345516204834\n",
      "Epoch 244/10000: L(Train): 0.33667486906051636; L(Test): 0.3322616219520569\n",
      "Epoch 245/10000: L(Train): 0.349403977394104; L(Test): 0.33200469613075256\n",
      "Epoch 246/10000: L(Train): 0.3457694947719574; L(Test): 0.33164718747138977\n",
      "Epoch 247/10000: L(Train): 0.3433457612991333; L(Test): 0.3311814069747925\n",
      "Epoch 248/10000: L(Train): 0.3364783227443695; L(Test): 0.3308500349521637\n",
      "Epoch 249/10000: L(Train): 0.314999520778656; L(Test): 0.33191826939582825\n",
      "Epoch 250/10000: L(Train): 0.33063945174217224; L(Test): 0.33028486371040344\n",
      "Epoch 251/10000: L(Train): 0.336925745010376; L(Test): 0.3298400640487671\n",
      "Epoch 252/10000: L(Train): 0.34295517206192017; L(Test): 0.33039504289627075\n",
      "Epoch 253/10000: L(Train): 0.34393787384033203; L(Test): 0.3301752805709839\n",
      "Epoch 254/10000: L(Train): 0.3199045956134796; L(Test): 0.3293398320674896\n",
      "Epoch 255/10000: L(Train): 0.3237406015396118; L(Test): 0.3291912376880646\n",
      "Epoch 256/10000: L(Train): 0.332078754901886; L(Test): 0.3291794955730438\n",
      "Epoch 257/10000: L(Train): 0.346844881772995; L(Test): 0.32833626866340637\n",
      "Epoch 258/10000: L(Train): 0.3430176377296448; L(Test): 0.3279811143875122\n",
      "Epoch 259/10000: L(Train): 0.34906911849975586; L(Test): 0.3279392719268799\n",
      "Epoch 260/10000: L(Train): 0.3435180187225342; L(Test): 0.3275405168533325\n",
      "Epoch 261/10000: L(Train): 0.326474130153656; L(Test): 0.32724931836128235\n",
      "Epoch 262/10000: L(Train): 0.32623109221458435; L(Test): 0.3285370171070099\n",
      "Epoch 263/10000: L(Train): 0.3297995924949646; L(Test): 0.3270147740840912\n",
      "Epoch 264/10000: L(Train): 0.337910532951355; L(Test): 0.32708263397216797\n",
      "Epoch 265/10000: L(Train): 0.3386158347129822; L(Test): 0.3269389867782593\n",
      "Epoch 266/10000: L(Train): 0.34850385785102844; L(Test): 0.3280540406703949\n",
      "Epoch 267/10000: L(Train): 0.3251682221889496; L(Test): 0.3255164623260498\n",
      "Epoch 268/10000: L(Train): 0.3376455008983612; L(Test): 0.3261420428752899\n",
      "Epoch 269/10000: L(Train): 0.3560531735420227; L(Test): 0.32571426033973694\n",
      "Epoch 270/10000: L(Train): 0.3302827775478363; L(Test): 0.32588979601860046\n",
      "Epoch 271/10000: L(Train): 0.32973992824554443; L(Test): 0.325001060962677\n",
      "Epoch 272/10000: L(Train): 0.3345148265361786; L(Test): 0.32429227232933044\n",
      "Epoch 273/10000: L(Train): 0.33276131749153137; L(Test): 0.32526546716690063\n",
      "Epoch 274/10000: L(Train): 0.3208122253417969; L(Test): 0.32580339908599854\n",
      "Epoch 275/10000: L(Train): 0.32669323682785034; L(Test): 0.3239400386810303\n",
      "Epoch 276/10000: L(Train): 0.3202604651451111; L(Test): 0.3250170648097992\n",
      "Epoch 277/10000: L(Train): 0.335337370634079; L(Test): 0.32530689239501953\n",
      "Epoch 278/10000: L(Train): 0.3321957290172577; L(Test): 0.32429254055023193\n",
      "Epoch 279/10000: L(Train): 0.31641343235969543; L(Test): 0.3239079713821411\n",
      "Epoch 280/10000: L(Train): 0.3187462389469147; L(Test): 0.32314062118530273\n",
      "Epoch 281/10000: L(Train): 0.3268119692802429; L(Test): 0.32278046011924744\n",
      "Epoch 282/10000: L(Train): 0.3255038261413574; L(Test): 0.3236663341522217\n",
      "Epoch 283/10000: L(Train): 0.3317203223705292; L(Test): 0.3225114047527313\n",
      "Epoch 284/10000: L(Train): 0.32229307293891907; L(Test): 0.3220880925655365\n",
      "Epoch 285/10000: L(Train): 0.31979966163635254; L(Test): 0.32309213280677795\n",
      "Epoch 286/10000: L(Train): 0.3353370130062103; L(Test): 0.3215654492378235\n",
      "Epoch 287/10000: L(Train): 0.33215460181236267; L(Test): 0.3215605616569519\n",
      "Epoch 288/10000: L(Train): 0.328419029712677; L(Test): 0.32197460532188416\n",
      "Epoch 289/10000: L(Train): 0.31546664237976074; L(Test): 0.32390138506889343\n",
      "Epoch 290/10000: L(Train): 0.3237898349761963; L(Test): 0.32080990076065063\n",
      "Epoch 291/10000: L(Train): 0.3386003375053406; L(Test): 0.32160595059394836\n",
      "Epoch 292/10000: L(Train): 0.32595294713974; L(Test): 0.3203929662704468\n",
      "Epoch 293/10000: L(Train): 0.33246609568595886; L(Test): 0.3218657374382019\n",
      "Epoch 294/10000: L(Train): 0.3261162042617798; L(Test): 0.3200887143611908\n",
      "Epoch 295/10000: L(Train): 0.3191884756088257; L(Test): 0.31965920329093933\n",
      "Epoch 296/10000: L(Train): 0.3312723636627197; L(Test): 0.31985822319984436\n",
      "Epoch 297/10000: L(Train): 0.34421414136886597; L(Test): 0.3198377788066864\n",
      "Epoch 298/10000: L(Train): 0.323862761259079; L(Test): 0.319438636302948\n",
      "Epoch 299/10000: L(Train): 0.3181908130645752; L(Test): 0.3191324472427368\n",
      "Epoch 300/10000: L(Train): 0.32388418912887573; L(Test): 0.31873297691345215\n",
      "Epoch 301/10000: L(Train): 0.33630815148353577; L(Test): 0.31876417994499207\n",
      "Epoch 302/10000: L(Train): 0.30346256494522095; L(Test): 0.31883785128593445\n",
      "Epoch 303/10000: L(Train): 0.3339678645133972; L(Test): 0.3181318938732147\n",
      "Epoch 304/10000: L(Train): 0.33532631397247314; L(Test): 0.3178597390651703\n",
      "Epoch 305/10000: L(Train): 0.31833624839782715; L(Test): 0.3185172975063324\n",
      "Epoch 306/10000: L(Train): 0.3432116210460663; L(Test): 0.3174916207790375\n",
      "Epoch 307/10000: L(Train): 0.3171028792858124; L(Test): 0.31732863187789917\n",
      "Epoch 308/10000: L(Train): 0.3217936158180237; L(Test): 0.3181833028793335\n",
      "Epoch 309/10000: L(Train): 0.3148905336856842; L(Test): 0.31770843267440796\n",
      "Epoch 310/10000: L(Train): 0.32201749086380005; L(Test): 0.31685692071914673\n",
      "Epoch 311/10000: L(Train): 0.31759387254714966; L(Test): 0.3166882395744324\n",
      "Epoch 312/10000: L(Train): 0.3249129056930542; L(Test): 0.31720471382141113\n",
      "Epoch 313/10000: L(Train): 0.3244667947292328; L(Test): 0.3164213001728058\n",
      "Epoch 314/10000: L(Train): 0.3256077468395233; L(Test): 0.3162217438220978\n",
      "Epoch 315/10000: L(Train): 0.3118979334831238; L(Test): 0.3162647485733032\n",
      "Epoch 316/10000: L(Train): 0.3314109742641449; L(Test): 0.3156266212463379\n",
      "Epoch 317/10000: L(Train): 0.33803969621658325; L(Test): 0.3160749673843384\n",
      "Epoch 318/10000: L(Train): 0.3232598304748535; L(Test): 0.316298246383667\n",
      "Epoch 319/10000: L(Train): 0.32737958431243896; L(Test): 0.31580808758735657\n",
      "Epoch 320/10000: L(Train): 0.3274725675582886; L(Test): 0.31515267491340637\n",
      "Epoch 321/10000: L(Train): 0.3155018389225006; L(Test): 0.3154154121875763\n",
      "Epoch 322/10000: L(Train): 0.32030391693115234; L(Test): 0.315753310918808\n",
      "Epoch 323/10000: L(Train): 0.3107229471206665; L(Test): 0.3144674003124237\n",
      "Epoch 324/10000: L(Train): 0.32234910130500793; L(Test): 0.314454048871994\n",
      "Epoch 325/10000: L(Train): 0.3077804148197174; L(Test): 0.31554728746414185\n",
      "Epoch 326/10000: L(Train): 0.32631462812423706; L(Test): 0.31427717208862305\n",
      "Epoch 327/10000: L(Train): 0.3363970220088959; L(Test): 0.3140318691730499\n",
      "Epoch 328/10000: L(Train): 0.33895716071128845; L(Test): 0.31379958987236023\n",
      "Epoch 329/10000: L(Train): 0.3039151728153229; L(Test): 0.3139128088951111\n",
      "Epoch 330/10000: L(Train): 0.3257449269294739; L(Test): 0.31405511498451233\n",
      "Epoch 331/10000: L(Train): 0.3356584310531616; L(Test): 0.3126060664653778\n",
      "Epoch 332/10000: L(Train): 0.3337789475917816; L(Test): 0.3133394420146942\n",
      "Epoch 333/10000: L(Train): 0.33182618021965027; L(Test): 0.3133792281150818\n",
      "Epoch 334/10000: L(Train): 0.31279808282852173; L(Test): 0.31311315298080444\n",
      "Epoch 335/10000: L(Train): 0.3145943284034729; L(Test): 0.31498411297798157\n",
      "Epoch 336/10000: L(Train): 0.3141848146915436; L(Test): 0.31258684396743774\n",
      "Epoch 337/10000: L(Train): 0.31697961688041687; L(Test): 0.31205615401268005\n",
      "Epoch 338/10000: L(Train): 0.3263338506221771; L(Test): 0.31250613927841187\n",
      "Epoch 339/10000: L(Train): 0.3367752730846405; L(Test): 0.31322360038757324\n",
      "Epoch 340/10000: L(Train): 0.3189060091972351; L(Test): 0.31171470880508423\n",
      "Epoch 341/10000: L(Train): 0.3339163064956665; L(Test): 0.31140825152397156\n",
      "Epoch 342/10000: L(Train): 0.30514609813690186; L(Test): 0.3150385022163391\n",
      "Epoch 343/10000: L(Train): 0.3139953017234802; L(Test): 0.31199175119400024\n",
      "Epoch 344/10000: L(Train): 0.31340664625167847; L(Test): 0.31131109595298767\n",
      "Epoch 345/10000: L(Train): 0.3129090964794159; L(Test): 0.3114253878593445\n",
      "Epoch 346/10000: L(Train): 0.30713140964508057; L(Test): 0.31242215633392334\n",
      "Epoch 347/10000: L(Train): 0.3219969868659973; L(Test): 0.3104509115219116\n",
      "Epoch 348/10000: L(Train): 0.3219633400440216; L(Test): 0.310258150100708\n",
      "Epoch 349/10000: L(Train): 0.3193565309047699; L(Test): 0.3121415078639984\n",
      "Epoch 350/10000: L(Train): 0.3334801197052002; L(Test): 0.31018200516700745\n",
      "Epoch 351/10000: L(Train): 0.3286669850349426; L(Test): 0.31041744351387024\n",
      "Epoch 352/10000: L(Train): 0.31461286544799805; L(Test): 0.3109843134880066\n",
      "Epoch 353/10000: L(Train): 0.3095828592777252; L(Test): 0.3119024634361267\n",
      "Epoch 354/10000: L(Train): 0.3315836489200592; L(Test): 0.3097352385520935\n",
      "Epoch 355/10000: L(Train): 0.3234606981277466; L(Test): 0.3101023733615875\n",
      "Epoch 356/10000: L(Train): 0.335360050201416; L(Test): 0.31154051423072815\n",
      "Epoch 357/10000: L(Train): 0.33194413781166077; L(Test): 0.31088459491729736\n",
      "Epoch 358/10000: L(Train): 0.32721883058547974; L(Test): 0.30957868695259094\n",
      "Epoch 359/10000: L(Train): 0.3270314931869507; L(Test): 0.3084142804145813\n",
      "Epoch 360/10000: L(Train): 0.2988823652267456; L(Test): 0.3123871088027954\n",
      "Epoch 361/10000: L(Train): 0.3226402699947357; L(Test): 0.30907848477363586\n",
      "Epoch 362/10000: L(Train): 0.29944300651550293; L(Test): 0.3084091544151306\n",
      "Epoch 363/10000: L(Train): 0.3370322585105896; L(Test): 0.3084006905555725\n",
      "Epoch 364/10000: L(Train): 0.319710373878479; L(Test): 0.3096274137496948\n",
      "Epoch 365/10000: L(Train): 0.3051224648952484; L(Test): 0.3086681067943573\n",
      "Epoch 366/10000: L(Train): 0.3127312958240509; L(Test): 0.3080998957157135\n",
      "Epoch 367/10000: L(Train): 0.3211214244365692; L(Test): 0.3069107234477997\n",
      "Epoch 368/10000: L(Train): 0.3214084804058075; L(Test): 0.3095034658908844\n",
      "Epoch 369/10000: L(Train): 0.31899112462997437; L(Test): 0.30789265036582947\n",
      "Epoch 370/10000: L(Train): 0.32264015078544617; L(Test): 0.3073054850101471\n",
      "Epoch 371/10000: L(Train): 0.3128908574581146; L(Test): 0.30762696266174316\n",
      "Epoch 372/10000: L(Train): 0.3201574683189392; L(Test): 0.30750787258148193\n",
      "Epoch 373/10000: L(Train): 0.31763485074043274; L(Test): 0.3078951835632324\n",
      "Epoch 374/10000: L(Train): 0.3125200867652893; L(Test): 0.3067390024662018\n",
      "Epoch 375/10000: L(Train): 0.305965781211853; L(Test): 0.30624401569366455\n",
      "Epoch 376/10000: L(Train): 0.31690749526023865; L(Test): 0.306483656167984\n",
      "Epoch 377/10000: L(Train): 0.31654664874076843; L(Test): 0.30598974227905273\n",
      "Epoch 378/10000: L(Train): 0.3103949725627899; L(Test): 0.30532729625701904\n",
      "Epoch 379/10000: L(Train): 0.32414764165878296; L(Test): 0.30535006523132324\n",
      "Epoch 380/10000: L(Train): 0.3087574243545532; L(Test): 0.30655717849731445\n",
      "Epoch 381/10000: L(Train): 0.3091081976890564; L(Test): 0.3058050572872162\n",
      "Epoch 382/10000: L(Train): 0.30835428833961487; L(Test): 0.30560097098350525\n",
      "Epoch 383/10000: L(Train): 0.3133154511451721; L(Test): 0.3047544062137604\n",
      "Epoch 384/10000: L(Train): 0.3211940824985504; L(Test): 0.30618715286254883\n",
      "Epoch 385/10000: L(Train): 0.3160415589809418; L(Test): 0.3042661249637604\n",
      "Epoch 386/10000: L(Train): 0.30732396245002747; L(Test): 0.30379870533943176\n",
      "Epoch 387/10000: L(Train): 0.3169192969799042; L(Test): 0.3044261932373047\n",
      "Epoch 388/10000: L(Train): 0.3160954713821411; L(Test): 0.30446919798851013\n",
      "Epoch 389/10000: L(Train): 0.29607126116752625; L(Test): 0.3035595715045929\n",
      "Epoch 390/10000: L(Train): 0.3376472294330597; L(Test): 0.30404984951019287\n",
      "Epoch 391/10000: L(Train): 0.3089061975479126; L(Test): 0.30478498339653015\n",
      "Epoch 392/10000: L(Train): 0.30960699915885925; L(Test): 0.3049694895744324\n",
      "Epoch 393/10000: L(Train): 0.29688048362731934; L(Test): 0.30277013778686523\n",
      "Epoch 394/10000: L(Train): 0.30519652366638184; L(Test): 0.3026648163795471\n",
      "Epoch 395/10000: L(Train): 0.3243613839149475; L(Test): 0.30407774448394775\n",
      "Epoch 396/10000: L(Train): 0.3186044991016388; L(Test): 0.30338260531425476\n",
      "Epoch 397/10000: L(Train): 0.3090972900390625; L(Test): 0.3019746243953705\n",
      "Epoch 398/10000: L(Train): 0.3201409578323364; L(Test): 0.3021739721298218\n",
      "Epoch 399/10000: L(Train): 0.3042709529399872; L(Test): 0.30404120683670044\n",
      "Epoch 400/10000: L(Train): 0.2891150712966919; L(Test): 0.302330881357193\n",
      "Epoch 401/10000: L(Train): 0.30919820070266724; L(Test): 0.3018460273742676\n",
      "Epoch 402/10000: L(Train): 0.32876792550086975; L(Test): 0.30125370621681213\n",
      "Epoch 403/10000: L(Train): 0.3367743492126465; L(Test): 0.3018326759338379\n",
      "Epoch 404/10000: L(Train): 0.30002543330192566; L(Test): 0.3010155260562897\n",
      "Epoch 405/10000: L(Train): 0.3011645972728729; L(Test): 0.30079180002212524\n",
      "Epoch 406/10000: L(Train): 0.307861328125; L(Test): 0.3007359206676483\n",
      "Epoch 407/10000: L(Train): 0.323208212852478; L(Test): 0.30132198333740234\n",
      "Epoch 408/10000: L(Train): 0.31473445892333984; L(Test): 0.30063045024871826\n",
      "Epoch 409/10000: L(Train): 0.3080745339393616; L(Test): 0.3001842200756073\n",
      "Epoch 410/10000: L(Train): 0.3209910988807678; L(Test): 0.29986196756362915\n",
      "Epoch 411/10000: L(Train): 0.310320109128952; L(Test): 0.2996785044670105\n",
      "Epoch 412/10000: L(Train): 0.33043569326400757; L(Test): 0.2993019223213196\n",
      "Epoch 413/10000: L(Train): 0.32221218943595886; L(Test): 0.2991420328617096\n",
      "Epoch 414/10000: L(Train): 0.32525599002838135; L(Test): 0.29959753155708313\n",
      "Epoch 415/10000: L(Train): 0.31248554587364197; L(Test): 0.2990783154964447\n",
      "Epoch 416/10000: L(Train): 0.3238791227340698; L(Test): 0.299043744802475\n",
      "Epoch 417/10000: L(Train): 0.31051966547966003; L(Test): 0.3000684380531311\n",
      "Epoch 418/10000: L(Train): 0.3233943581581116; L(Test): 0.2994828522205353\n",
      "Epoch 419/10000: L(Train): 0.3147789537906647; L(Test): 0.29863405227661133\n",
      "Epoch 420/10000: L(Train): 0.2929290235042572; L(Test): 0.29927927255630493\n",
      "Epoch 421/10000: L(Train): 0.3258589208126068; L(Test): 0.29875174164772034\n",
      "Epoch 422/10000: L(Train): 0.31398022174835205; L(Test): 0.29802945256233215\n",
      "Epoch 423/10000: L(Train): 0.31663039326667786; L(Test): 0.29871106147766113\n",
      "Epoch 424/10000: L(Train): 0.2944612503051758; L(Test): 0.2983974516391754\n",
      "Epoch 425/10000: L(Train): 0.3167494833469391; L(Test): 0.29782822728157043\n",
      "Epoch 426/10000: L(Train): 0.3050368130207062; L(Test): 0.2980962097644806\n",
      "Epoch 427/10000: L(Train): 0.3031430244445801; L(Test): 0.29768696427345276\n",
      "Epoch 428/10000: L(Train): 0.3125435411930084; L(Test): 0.29731231927871704\n",
      "Epoch 429/10000: L(Train): 0.3246583044528961; L(Test): 0.29739752411842346\n",
      "Epoch 430/10000: L(Train): 0.3139839172363281; L(Test): 0.2977887988090515\n",
      "Epoch 431/10000: L(Train): 0.29950952529907227; L(Test): 0.2970924973487854\n",
      "Epoch 432/10000: L(Train): 0.31073877215385437; L(Test): 0.2971627414226532\n",
      "Epoch 433/10000: L(Train): 0.31743451952934265; L(Test): 0.29795974493026733\n",
      "Epoch 434/10000: L(Train): 0.3077651858329773; L(Test): 0.2974773347377777\n",
      "Epoch 435/10000: L(Train): 0.3158319294452667; L(Test): 0.298100084066391\n",
      "Epoch 436/10000: L(Train): 0.31559300422668457; L(Test): 0.3010331988334656\n",
      "Epoch 437/10000: L(Train): 0.3067544996738434; L(Test): 0.29688602685928345\n",
      "Epoch 438/10000: L(Train): 0.30105510354042053; L(Test): 0.29781001806259155\n",
      "Epoch 439/10000: L(Train): 0.30566924810409546; L(Test): 0.29803285002708435\n",
      "Epoch 440/10000: L(Train): 0.31554821133613586; L(Test): 0.2989065945148468\n",
      "Epoch 441/10000: L(Train): 0.3297497630119324; L(Test): 0.2965851426124573\n",
      "Epoch 442/10000: L(Train): 0.31420138478279114; L(Test): 0.29541078209877014\n",
      "Epoch 443/10000: L(Train): 0.3031415343284607; L(Test): 0.29869234561920166\n",
      "Epoch 444/10000: L(Train): 0.28534215688705444; L(Test): 0.29787468910217285\n",
      "Epoch 445/10000: L(Train): 0.29678237438201904; L(Test): 0.2960711419582367\n",
      "Epoch 446/10000: L(Train): 0.29780152440071106; L(Test): 0.2962629795074463\n",
      "Epoch 447/10000: L(Train): 0.3125230073928833; L(Test): 0.29766061902046204\n",
      "Epoch 448/10000: L(Train): 0.3243030905723572; L(Test): 0.2971954941749573\n",
      "Epoch 449/10000: L(Train): 0.2948245406150818; L(Test): 0.2948761284351349\n",
      "Epoch 450/10000: L(Train): 0.29618319869041443; L(Test): 0.2948428690433502\n",
      "Epoch 451/10000: L(Train): 0.3071413040161133; L(Test): 0.29542121291160583\n",
      "Epoch 452/10000: L(Train): 0.2972966432571411; L(Test): 0.2961343228816986\n",
      "Epoch 453/10000: L(Train): 0.3099890649318695; L(Test): 0.2940564453601837\n",
      "Epoch 454/10000: L(Train): 0.3082655072212219; L(Test): 0.2945168614387512\n",
      "Epoch 455/10000: L(Train): 0.29948529601097107; L(Test): 0.29478150606155396\n",
      "Epoch 456/10000: L(Train): 0.29302874207496643; L(Test): 0.2953050136566162\n",
      "Epoch 457/10000: L(Train): 0.31340619921684265; L(Test): 0.29340481758117676\n",
      "Epoch 458/10000: L(Train): 0.3180849850177765; L(Test): 0.2933391332626343\n",
      "Epoch 459/10000: L(Train): 0.3136756122112274; L(Test): 0.29376789927482605\n",
      "Epoch 460/10000: L(Train): 0.2904071807861328; L(Test): 0.2942485809326172\n",
      "Epoch 461/10000: L(Train): 0.30359867215156555; L(Test): 0.2929576635360718\n",
      "Epoch 462/10000: L(Train): 0.3095565140247345; L(Test): 0.2932252585887909\n",
      "Epoch 463/10000: L(Train): 0.2873360514640808; L(Test): 0.293433278799057\n",
      "Epoch 464/10000: L(Train): 0.29884573817253113; L(Test): 0.2952059507369995\n",
      "Epoch 465/10000: L(Train): 0.30534127354621887; L(Test): 0.2919411063194275\n",
      "Epoch 466/10000: L(Train): 0.2940678000450134; L(Test): 0.29214349389076233\n",
      "Epoch 467/10000: L(Train): 0.3196793794631958; L(Test): 0.2922808527946472\n",
      "Epoch 468/10000: L(Train): 0.3091593384742737; L(Test): 0.29297515749931335\n",
      "Epoch 469/10000: L(Train): 0.28870218992233276; L(Test): 0.29204440116882324\n",
      "Epoch 470/10000: L(Train): 0.31043675541877747; L(Test): 0.29167041182518005\n",
      "Epoch 471/10000: L(Train): 0.304931104183197; L(Test): 0.291477233171463\n",
      "Epoch 472/10000: L(Train): 0.29359036684036255; L(Test): 0.2926516532897949\n",
      "Epoch 473/10000: L(Train): 0.30390554666519165; L(Test): 0.2912348508834839\n",
      "Epoch 474/10000: L(Train): 0.29989001154899597; L(Test): 0.29078036546707153\n",
      "Epoch 475/10000: L(Train): 0.29825007915496826; L(Test): 0.29113298654556274\n",
      "Epoch 476/10000: L(Train): 0.2971031963825226; L(Test): 0.2916499674320221\n",
      "Epoch 477/10000: L(Train): 0.3138172924518585; L(Test): 0.2907726466655731\n",
      "Epoch 478/10000: L(Train): 0.28350335359573364; L(Test): 0.29074421525001526\n",
      "Epoch 479/10000: L(Train): 0.31260210275650024; L(Test): 0.28981372714042664\n",
      "Epoch 480/10000: L(Train): 0.31156402826309204; L(Test): 0.290058434009552\n",
      "Epoch 481/10000: L(Train): 0.30894166231155396; L(Test): 0.2901638448238373\n",
      "Epoch 482/10000: L(Train): 0.2949499189853668; L(Test): 0.28998294472694397\n",
      "Epoch 483/10000: L(Train): 0.31639060378074646; L(Test): 0.2898826003074646\n",
      "Epoch 484/10000: L(Train): 0.307871550321579; L(Test): 0.29056259989738464\n",
      "Epoch 485/10000: L(Train): 0.2966105043888092; L(Test): 0.2910987138748169\n",
      "Epoch 486/10000: L(Train): 0.300580769777298; L(Test): 0.28986266255378723\n",
      "Epoch 487/10000: L(Train): 0.3107227385044098; L(Test): 0.2892487943172455\n",
      "Epoch 488/10000: L(Train): 0.30058905482292175; L(Test): 0.28893589973449707\n",
      "Epoch 489/10000: L(Train): 0.3061133623123169; L(Test): 0.2898375988006592\n",
      "Epoch 490/10000: L(Train): 0.29371389746665955; L(Test): 0.2887694537639618\n",
      "Epoch 491/10000: L(Train): 0.31578028202056885; L(Test): 0.28903064131736755\n",
      "Epoch 492/10000: L(Train): 0.297725647687912; L(Test): 0.28880709409713745\n",
      "Epoch 493/10000: L(Train): 0.2970142364501953; L(Test): 0.2885574698448181\n",
      "Epoch 494/10000: L(Train): 0.2965136766433716; L(Test): 0.28838902711868286\n",
      "Epoch 495/10000: L(Train): 0.3000074625015259; L(Test): 0.28797560930252075\n",
      "Epoch 496/10000: L(Train): 0.30386313796043396; L(Test): 0.28837281465530396\n",
      "Epoch 497/10000: L(Train): 0.29090723395347595; L(Test): 0.2882104516029358\n",
      "Epoch 498/10000: L(Train): 0.322628378868103; L(Test): 0.2880135476589203\n",
      "Epoch 499/10000: L(Train): 0.30719637870788574; L(Test): 0.28824570775032043\n",
      "Epoch 500/10000: L(Train): 0.29194751381874084; L(Test): 0.28810274600982666\n",
      "Epoch 501/10000: L(Train): 0.3017944395542145; L(Test): 0.28681468963623047\n",
      "Epoch 502/10000: L(Train): 0.2988888621330261; L(Test): 0.28677091002464294\n",
      "Epoch 503/10000: L(Train): 0.30359652638435364; L(Test): 0.2874627709388733\n",
      "Epoch 504/10000: L(Train): 0.3055639863014221; L(Test): 0.28643423318862915\n",
      "Epoch 505/10000: L(Train): 0.307476282119751; L(Test): 0.28686344623565674\n",
      "Epoch 506/10000: L(Train): 0.29417309165000916; L(Test): 0.28755223751068115\n",
      "Epoch 507/10000: L(Train): 0.2958345115184784; L(Test): 0.28672507405281067\n",
      "Epoch 508/10000: L(Train): 0.3030773401260376; L(Test): 0.28621217608451843\n",
      "Epoch 509/10000: L(Train): 0.310907244682312; L(Test): 0.28610965609550476\n",
      "Epoch 510/10000: L(Train): 0.29941073060035706; L(Test): 0.28680774569511414\n",
      "Epoch 511/10000: L(Train): 0.30282729864120483; L(Test): 0.28616422414779663\n",
      "Epoch 512/10000: L(Train): 0.29198649525642395; L(Test): 0.2855840027332306\n",
      "Epoch 513/10000: L(Train): 0.3037179112434387; L(Test): 0.28531336784362793\n",
      "Epoch 514/10000: L(Train): 0.3257060647010803; L(Test): 0.2867017984390259\n",
      "Epoch 515/10000: L(Train): 0.2983936369419098; L(Test): 0.28543621301651\n",
      "Epoch 516/10000: L(Train): 0.303327739238739; L(Test): 0.28539249300956726\n",
      "Epoch 517/10000: L(Train): 0.29724347591400146; L(Test): 0.2873168885707855\n",
      "Epoch 518/10000: L(Train): 0.3017115890979767; L(Test): 0.2859326899051666\n",
      "Epoch 519/10000: L(Train): 0.29941481351852417; L(Test): 0.2858680784702301\n",
      "Epoch 520/10000: L(Train): 0.29551398754119873; L(Test): 0.2853950560092926\n",
      "Epoch 521/10000: L(Train): 0.3098306953907013; L(Test): 0.28527602553367615\n",
      "Epoch 522/10000: L(Train): 0.30992254614830017; L(Test): 0.2858394682407379\n",
      "Epoch 523/10000: L(Train): 0.3115213215351105; L(Test): 0.28557583689689636\n",
      "Epoch 524/10000: L(Train): 0.3091316223144531; L(Test): 0.2863294184207916\n",
      "Epoch 525/10000: L(Train): 0.3162038028240204; L(Test): 0.28549715876579285\n",
      "Epoch 526/10000: L(Train): 0.2926838994026184; L(Test): 0.28510385751724243\n",
      "Epoch 527/10000: L(Train): 0.3022763133049011; L(Test): 0.2852165997028351\n",
      "Epoch 528/10000: L(Train): 0.28449326753616333; L(Test): 0.28435519337654114\n",
      "Epoch 529/10000: L(Train): 0.28480568528175354; L(Test): 0.28429773449897766\n",
      "Epoch 530/10000: L(Train): 0.29778966307640076; L(Test): 0.28347063064575195\n",
      "Epoch 531/10000: L(Train): 0.29701343178749084; L(Test): 0.28472021222114563\n",
      "Epoch 532/10000: L(Train): 0.29538285732269287; L(Test): 0.28448396921157837\n",
      "Epoch 533/10000: L(Train): 0.2968980669975281; L(Test): 0.28401705622673035\n",
      "Epoch 534/10000: L(Train): 0.3119068741798401; L(Test): 0.28487628698349\n",
      "Epoch 535/10000: L(Train): 0.29563000798225403; L(Test): 0.28350648283958435\n",
      "Epoch 536/10000: L(Train): 0.29627054929733276; L(Test): 0.28289443254470825\n",
      "Epoch 537/10000: L(Train): 0.31712856888771057; L(Test): 0.2832430303096771\n",
      "Epoch 538/10000: L(Train): 0.28389230370521545; L(Test): 0.2842472195625305\n",
      "Epoch 539/10000: L(Train): 0.27772581577301025; L(Test): 0.283274382352829\n",
      "Epoch 540/10000: L(Train): 0.28977832198143005; L(Test): 0.28268712759017944\n",
      "Epoch 541/10000: L(Train): 0.28534868359565735; L(Test): 0.28253546357154846\n",
      "Epoch 542/10000: L(Train): 0.2978055775165558; L(Test): 0.28203073143959045\n",
      "Epoch 543/10000: L(Train): 0.31246665120124817; L(Test): 0.2825145423412323\n",
      "Epoch 544/10000: L(Train): 0.298542857170105; L(Test): 0.28305158019065857\n",
      "Epoch 545/10000: L(Train): 0.29789644479751587; L(Test): 0.2827586233615875\n",
      "Epoch 546/10000: L(Train): 0.29527536034584045; L(Test): 0.2823178768157959\n",
      "Epoch 547/10000: L(Train): 0.3042342960834503; L(Test): 0.2831443250179291\n",
      "Epoch 548/10000: L(Train): 0.30460023880004883; L(Test): 0.28188756108283997\n",
      "Epoch 549/10000: L(Train): 0.30190232396125793; L(Test): 0.2815244197845459\n",
      "Epoch 550/10000: L(Train): 0.29176416993141174; L(Test): 0.2821004390716553\n",
      "Epoch 551/10000: L(Train): 0.29072409868240356; L(Test): 0.28156137466430664\n",
      "Epoch 552/10000: L(Train): 0.3113190531730652; L(Test): 0.2816503047943115\n",
      "Epoch 553/10000: L(Train): 0.29749196767807007; L(Test): 0.28244784474372864\n",
      "Epoch 554/10000: L(Train): 0.2901890277862549; L(Test): 0.2831949293613434\n",
      "Epoch 555/10000: L(Train): 0.2947124242782593; L(Test): 0.2812531888484955\n",
      "Epoch 556/10000: L(Train): 0.28714242577552795; L(Test): 0.2814761698246002\n",
      "Epoch 557/10000: L(Train): 0.3029893636703491; L(Test): 0.2827618420124054\n",
      "Epoch 558/10000: L(Train): 0.3004104495048523; L(Test): 0.2813556492328644\n",
      "Epoch 559/10000: L(Train): 0.2952272593975067; L(Test): 0.2812281847000122\n",
      "Epoch 560/10000: L(Train): 0.29558029770851135; L(Test): 0.28088414669036865\n",
      "Epoch 561/10000: L(Train): 0.2928554117679596; L(Test): 0.2823857069015503\n",
      "Epoch 562/10000: L(Train): 0.2922112047672272; L(Test): 0.2802460193634033\n",
      "Epoch 563/10000: L(Train): 0.2908412516117096; L(Test): 0.2803669273853302\n",
      "Epoch 564/10000: L(Train): 0.30374079942703247; L(Test): 0.2809284031391144\n",
      "Epoch 565/10000: L(Train): 0.27898430824279785; L(Test): 0.2812652587890625\n",
      "Epoch 566/10000: L(Train): 0.3095546066761017; L(Test): 0.2804786264896393\n",
      "Epoch 567/10000: L(Train): 0.288666695356369; L(Test): 0.28087472915649414\n",
      "Epoch 568/10000: L(Train): 0.2882120907306671; L(Test): 0.2822099030017853\n",
      "Epoch 569/10000: L(Train): 0.2790522575378418; L(Test): 0.280661016702652\n",
      "Epoch 570/10000: L(Train): 0.30539584159851074; L(Test): 0.28018054366111755\n",
      "Epoch 571/10000: L(Train): 0.2976703643798828; L(Test): 0.2808343470096588\n",
      "Epoch 572/10000: L(Train): 0.27977997064590454; L(Test): 0.28108707070350647\n",
      "Epoch 573/10000: L(Train): 0.297472208738327; L(Test): 0.28021878004074097\n",
      "Epoch 574/10000: L(Train): 0.30251529812812805; L(Test): 0.279803067445755\n",
      "Epoch 575/10000: L(Train): 0.29322806000709534; L(Test): 0.2824242413043976\n",
      "Epoch 576/10000: L(Train): 0.30534598231315613; L(Test): 0.2804376482963562\n",
      "Epoch 577/10000: L(Train): 0.29020822048187256; L(Test): 0.2798250615596771\n",
      "Epoch 578/10000: L(Train): 0.3024076819419861; L(Test): 0.28110694885253906\n",
      "Epoch 579/10000: L(Train): 0.30218204855918884; L(Test): 0.2803228795528412\n",
      "Epoch 580/10000: L(Train): 0.28839075565338135; L(Test): 0.2800695598125458\n",
      "Epoch 581/10000: L(Train): 0.30535250902175903; L(Test): 0.27897804975509644\n",
      "Epoch 582/10000: L(Train): 0.2944086790084839; L(Test): 0.2809516191482544\n",
      "Epoch 583/10000: L(Train): 0.28203245997428894; L(Test): 0.2801840007305145\n",
      "Epoch 584/10000: L(Train): 0.27801352739334106; L(Test): 0.28047141432762146\n",
      "Epoch 585/10000: L(Train): 0.28617769479751587; L(Test): 0.2789691686630249\n",
      "Epoch 586/10000: L(Train): 0.28428539633750916; L(Test): 0.27982279658317566\n",
      "Epoch 587/10000: L(Train): 0.2919672131538391; L(Test): 0.2794322073459625\n",
      "Epoch 588/10000: L(Train): 0.2953435182571411; L(Test): 0.27870869636535645\n",
      "Epoch 589/10000: L(Train): 0.2884541153907776; L(Test): 0.2790234386920929\n",
      "Epoch 590/10000: L(Train): 0.2838468551635742; L(Test): 0.2789600193500519\n",
      "Epoch 591/10000: L(Train): 0.29211971163749695; L(Test): 0.27963462471961975\n",
      "Epoch 592/10000: L(Train): 0.30292707681655884; L(Test): 0.27890315651893616\n",
      "Epoch 593/10000: L(Train): 0.290326327085495; L(Test): 0.280408650636673\n",
      "Epoch 594/10000: L(Train): 0.2882053256034851; L(Test): 0.28026220202445984\n",
      "Epoch 595/10000: L(Train): 0.286909282207489; L(Test): 0.2787972688674927\n",
      "Epoch 596/10000: L(Train): 0.2901744544506073; L(Test): 0.2787354588508606\n",
      "Epoch 597/10000: L(Train): 0.2820453345775604; L(Test): 0.2789887487888336\n",
      "Epoch 598/10000: L(Train): 0.3145904242992401; L(Test): 0.2778994143009186\n",
      "Epoch 599/10000: L(Train): 0.29040348529815674; L(Test): 0.27812597155570984\n",
      "Epoch 600/10000: L(Train): 0.2894299626350403; L(Test): 0.27881985902786255\n",
      "Epoch 601/10000: L(Train): 0.2869126796722412; L(Test): 0.27798718214035034\n",
      "Epoch 602/10000: L(Train): 0.29133501648902893; L(Test): 0.2776145935058594\n",
      "Epoch 603/10000: L(Train): 0.2794698476791382; L(Test): 0.27786242961883545\n",
      "Epoch 604/10000: L(Train): 0.28759878873825073; L(Test): 0.2783503234386444\n",
      "Epoch 605/10000: L(Train): 0.31448954343795776; L(Test): 0.2768182158470154\n",
      "Epoch 606/10000: L(Train): 0.29632773995399475; L(Test): 0.2777653932571411\n",
      "Epoch 607/10000: L(Train): 0.28445205092430115; L(Test): 0.27848875522613525\n",
      "Epoch 608/10000: L(Train): 0.3055214285850525; L(Test): 0.27751412987709045\n",
      "Epoch 609/10000: L(Train): 0.2900639772415161; L(Test): 0.2770046293735504\n",
      "Epoch 610/10000: L(Train): 0.286443293094635; L(Test): 0.27646294236183167\n",
      "Epoch 611/10000: L(Train): 0.303995281457901; L(Test): 0.2778787910938263\n",
      "Epoch 612/10000: L(Train): 0.28872936964035034; L(Test): 0.27674680948257446\n",
      "Epoch 613/10000: L(Train): 0.26922908425331116; L(Test): 0.2766857147216797\n",
      "Epoch 614/10000: L(Train): 0.2823050320148468; L(Test): 0.2759353220462799\n",
      "Epoch 615/10000: L(Train): 0.2969930171966553; L(Test): 0.2764105200767517\n",
      "Epoch 616/10000: L(Train): 0.2935243248939514; L(Test): 0.27612894773483276\n",
      "Epoch 617/10000: L(Train): 0.2864682972431183; L(Test): 0.2758966386318207\n",
      "Epoch 618/10000: L(Train): 0.29255035519599915; L(Test): 0.2760523557662964\n",
      "Epoch 619/10000: L(Train): 0.28698158264160156; L(Test): 0.27582499384880066\n",
      "Epoch 620/10000: L(Train): 0.285832017660141; L(Test): 0.2764236629009247\n",
      "Epoch 621/10000: L(Train): 0.28629541397094727; L(Test): 0.27596309781074524\n",
      "Epoch 622/10000: L(Train): 0.2904520332813263; L(Test): 0.2757149040699005\n",
      "Epoch 623/10000: L(Train): 0.3007286787033081; L(Test): 0.2757212519645691\n",
      "Epoch 624/10000: L(Train): 0.3134879767894745; L(Test): 0.275280237197876\n",
      "Epoch 625/10000: L(Train): 0.2930275499820709; L(Test): 0.27547961473464966\n",
      "Epoch 626/10000: L(Train): 0.284101277589798; L(Test): 0.27508148550987244\n",
      "Epoch 627/10000: L(Train): 0.28835660219192505; L(Test): 0.27576953172683716\n",
      "Epoch 628/10000: L(Train): 0.27611809968948364; L(Test): 0.2748115062713623\n",
      "Epoch 629/10000: L(Train): 0.29177865386009216; L(Test): 0.2750159204006195\n",
      "Epoch 630/10000: L(Train): 0.2890282869338989; L(Test): 0.27567335963249207\n",
      "Epoch 631/10000: L(Train): 0.30262118577957153; L(Test): 0.2744370400905609\n",
      "Epoch 632/10000: L(Train): 0.2834906578063965; L(Test): 0.27481958270072937\n",
      "Epoch 633/10000: L(Train): 0.3047269582748413; L(Test): 0.2756568491458893\n",
      "Epoch 634/10000: L(Train): 0.29066091775894165; L(Test): 0.27567145228385925\n",
      "Epoch 635/10000: L(Train): 0.279446542263031; L(Test): 0.2745436728000641\n",
      "Epoch 636/10000: L(Train): 0.28289252519607544; L(Test): 0.2744847238063812\n",
      "Epoch 637/10000: L(Train): 0.2711305022239685; L(Test): 0.2759235203266144\n",
      "Epoch 638/10000: L(Train): 0.29274460673332214; L(Test): 0.275100976228714\n",
      "Epoch 639/10000: L(Train): 0.29151976108551025; L(Test): 0.27406084537506104\n",
      "Epoch 640/10000: L(Train): 0.281392365694046; L(Test): 0.27446219325065613\n",
      "Epoch 641/10000: L(Train): 0.2933615446090698; L(Test): 0.274564653635025\n",
      "Epoch 642/10000: L(Train): 0.2764207422733307; L(Test): 0.27415725588798523\n",
      "Epoch 643/10000: L(Train): 0.2991342544555664; L(Test): 0.2738461196422577\n",
      "Epoch 644/10000: L(Train): 0.2783546447753906; L(Test): 0.27380985021591187\n",
      "Epoch 645/10000: L(Train): 0.2899320721626282; L(Test): 0.27450695633888245\n",
      "Epoch 646/10000: L(Train): 0.2929299771785736; L(Test): 0.2735048830509186\n",
      "Epoch 647/10000: L(Train): 0.29765447974205017; L(Test): 0.2734619081020355\n",
      "Epoch 648/10000: L(Train): 0.29587534070014954; L(Test): 0.2736314535140991\n",
      "Epoch 649/10000: L(Train): 0.2889111638069153; L(Test): 0.273483008146286\n",
      "Epoch 650/10000: L(Train): 0.29093167185783386; L(Test): 0.27266010642051697\n",
      "Epoch 651/10000: L(Train): 0.2876393496990204; L(Test): 0.2728358507156372\n",
      "Epoch 652/10000: L(Train): 0.3039144277572632; L(Test): 0.2728915810585022\n",
      "Epoch 653/10000: L(Train): 0.275185763835907; L(Test): 0.2730148136615753\n",
      "Epoch 654/10000: L(Train): 0.28022798895835876; L(Test): 0.2729206085205078\n",
      "Epoch 655/10000: L(Train): 0.2818382978439331; L(Test): 0.27297553420066833\n",
      "Epoch 656/10000: L(Train): 0.2788936197757721; L(Test): 0.2735394537448883\n",
      "Epoch 657/10000: L(Train): 0.2838899791240692; L(Test): 0.2727085053920746\n",
      "Epoch 658/10000: L(Train): 0.2898366153240204; L(Test): 0.274457722902298\n",
      "Epoch 659/10000: L(Train): 0.28999820351600647; L(Test): 0.2726440727710724\n",
      "Epoch 660/10000: L(Train): 0.31172484159469604; L(Test): 0.27413997054100037\n",
      "Epoch 661/10000: L(Train): 0.3060328960418701; L(Test): 0.27283501625061035\n",
      "Epoch 662/10000: L(Train): 0.299247145652771; L(Test): 0.27208662033081055\n",
      "Epoch 663/10000: L(Train): 0.29767513275146484; L(Test): 0.27402016520500183\n",
      "Epoch 664/10000: L(Train): 0.29861128330230713; L(Test): 0.2724072337150574\n",
      "Epoch 665/10000: L(Train): 0.293425589799881; L(Test): 0.2734402120113373\n",
      "Epoch 666/10000: L(Train): 0.29297295212745667; L(Test): 0.27182409167289734\n",
      "Epoch 667/10000: L(Train): 0.2921050190925598; L(Test): 0.27290764451026917\n",
      "Epoch 668/10000: L(Train): 0.28412926197052; L(Test): 0.2733459770679474\n",
      "Epoch 669/10000: L(Train): 0.291871577501297; L(Test): 0.27284374833106995\n",
      "Epoch 670/10000: L(Train): 0.2826460599899292; L(Test): 0.27295055985450745\n",
      "Epoch 671/10000: L(Train): 0.2902793884277344; L(Test): 0.27366894483566284\n",
      "Epoch 672/10000: L(Train): 0.28647351264953613; L(Test): 0.27509474754333496\n",
      "Epoch 673/10000: L(Train): 0.2903377115726471; L(Test): 0.27244994044303894\n",
      "Epoch 674/10000: L(Train): 0.268232524394989; L(Test): 0.2730107009410858\n",
      "Epoch 675/10000: L(Train): 0.2791518270969391; L(Test): 0.27271905541419983\n",
      "Epoch 676/10000: L(Train): 0.2931041121482849; L(Test): 0.2739143967628479\n",
      "Epoch 677/10000: L(Train): 0.28666919469833374; L(Test): 0.2747418284416199\n",
      "Epoch 678/10000: L(Train): 0.30503079295158386; L(Test): 0.27243515849113464\n",
      "Epoch 679/10000: L(Train): 0.27157139778137207; L(Test): 0.27369585633277893\n",
      "Epoch 680/10000: L(Train): 0.28587061166763306; L(Test): 0.2726843059062958\n",
      "Epoch 681/10000: L(Train): 0.298048198223114; L(Test): 0.2736503779888153\n",
      "Epoch 682/10000: L(Train): 0.298008531332016; L(Test): 0.27266719937324524\n",
      "Epoch 683/10000: L(Train): 0.28506872057914734; L(Test): 0.2729179263114929\n",
      "Epoch 684/10000: L(Train): 0.30501455068588257; L(Test): 0.2737327516078949\n",
      "Epoch 685/10000: L(Train): 0.2784354090690613; L(Test): 0.27349990606307983\n",
      "Epoch 686/10000: L(Train): 0.2799535095691681; L(Test): 0.27271127700805664\n",
      "Epoch 687/10000: L(Train): 0.2778976261615753; L(Test): 0.2722574770450592\n",
      "Epoch 688/10000: L(Train): 0.2805674374103546; L(Test): 0.2720352113246918\n",
      "Epoch 689/10000: L(Train): 0.3057159185409546; L(Test): 0.2722013294696808\n",
      "Epoch 690/10000: L(Train): 0.28574010729789734; L(Test): 0.2720757722854614\n",
      "Epoch 691/10000: L(Train): 0.28696778416633606; L(Test): 0.271842360496521\n",
      "Epoch 692/10000: L(Train): 0.2849379777908325; L(Test): 0.27215099334716797\n",
      "Epoch 693/10000: L(Train): 0.2892938554286957; L(Test): 0.2722857594490051\n",
      "Epoch 694/10000: L(Train): 0.28313255310058594; L(Test): 0.2704092860221863\n",
      "Epoch 695/10000: L(Train): 0.2788558900356293; L(Test): 0.27102214097976685\n",
      "Epoch 696/10000: L(Train): 0.2909798324108124; L(Test): 0.27283015847206116\n",
      "Epoch 697/10000: L(Train): 0.29404526948928833; L(Test): 0.27186569571495056\n",
      "Epoch 698/10000: L(Train): 0.2929534614086151; L(Test): 0.2720141112804413\n",
      "Epoch 699/10000: L(Train): 0.2875417172908783; L(Test): 0.27134889364242554\n",
      "Epoch 700/10000: L(Train): 0.30060845613479614; L(Test): 0.2732278108596802\n",
      "Epoch 701/10000: L(Train): 0.29414114356040955; L(Test): 0.27212998270988464\n",
      "Epoch 702/10000: L(Train): 0.2923341393470764; L(Test): 0.27080386877059937\n",
      "Epoch 703/10000: L(Train): 0.2956603765487671; L(Test): 0.27072882652282715\n",
      "Epoch 704/10000: L(Train): 0.2829751670360565; L(Test): 0.2732611894607544\n",
      "Epoch 705/10000: L(Train): 0.2779524624347687; L(Test): 0.2720014452934265\n",
      "Epoch 706/10000: L(Train): 0.2995225787162781; L(Test): 0.27120858430862427\n",
      "Epoch 707/10000: L(Train): 0.2955187261104584; L(Test): 0.2709367871284485\n",
      "Epoch 708/10000: L(Train): 0.29979386925697327; L(Test): 0.27234911918640137\n",
      "Epoch 709/10000: L(Train): 0.2932755649089813; L(Test): 0.2701495289802551\n",
      "Epoch 710/10000: L(Train): 0.28844332695007324; L(Test): 0.27092182636260986\n",
      "Epoch 711/10000: L(Train): 0.2841363251209259; L(Test): 0.27082791924476624\n",
      "Epoch 712/10000: L(Train): 0.27858251333236694; L(Test): 0.27245596051216125\n",
      "Epoch 713/10000: L(Train): 0.2812190353870392; L(Test): 0.270108163356781\n",
      "Epoch 714/10000: L(Train): 0.2734763026237488; L(Test): 0.27046966552734375\n",
      "Epoch 715/10000: L(Train): 0.27796339988708496; L(Test): 0.2709389626979828\n",
      "Epoch 716/10000: L(Train): 0.29483920335769653; L(Test): 0.27210259437561035\n",
      "Epoch 717/10000: L(Train): 0.28277063369750977; L(Test): 0.2724975049495697\n",
      "Epoch 718/10000: L(Train): 0.27972412109375; L(Test): 0.2705645263195038\n",
      "Epoch 719/10000: L(Train): 0.2907089591026306; L(Test): 0.27091458439826965\n",
      "Epoch 720/10000: L(Train): 0.2864049971103668; L(Test): 0.2718636691570282\n",
      "Epoch 721/10000: L(Train): 0.2844545245170593; L(Test): 0.26933181285858154\n",
      "Epoch 722/10000: L(Train): 0.29736706614494324; L(Test): 0.2703976035118103\n",
      "Epoch 723/10000: L(Train): 0.2828730344772339; L(Test): 0.27002912759780884\n",
      "Epoch 724/10000: L(Train): 0.2902117967605591; L(Test): 0.2710636258125305\n",
      "Epoch 725/10000: L(Train): 0.28864771127700806; L(Test): 0.26897862553596497\n",
      "Epoch 726/10000: L(Train): 0.2963137626647949; L(Test): 0.26968786120414734\n",
      "Epoch 727/10000: L(Train): 0.28698208928108215; L(Test): 0.26898837089538574\n",
      "Epoch 728/10000: L(Train): 0.2918270528316498; L(Test): 0.27042508125305176\n",
      "Epoch 729/10000: L(Train): 0.29401350021362305; L(Test): 0.27002060413360596\n",
      "Epoch 730/10000: L(Train): 0.28710660338401794; L(Test): 0.27057600021362305\n",
      "Epoch 731/10000: L(Train): 0.2869613468647003; L(Test): 0.26988109946250916\n",
      "Epoch 732/10000: L(Train): 0.28622516989707947; L(Test): 0.2699212431907654\n",
      "Epoch 733/10000: L(Train): 0.29555749893188477; L(Test): 0.26965922117233276\n",
      "Epoch 734/10000: L(Train): 0.2892337739467621; L(Test): 0.2690829038619995\n",
      "Epoch 735/10000: L(Train): 0.29643598198890686; L(Test): 0.2686316668987274\n",
      "Epoch 736/10000: L(Train): 0.2888585329055786; L(Test): 0.2694244384765625\n",
      "Epoch 737/10000: L(Train): 0.2812340557575226; L(Test): 0.2697826027870178\n",
      "Epoch 738/10000: L(Train): 0.2983790338039398; L(Test): 0.2679250240325928\n",
      "Epoch 739/10000: L(Train): 0.2868908643722534; L(Test): 0.26796409487724304\n",
      "Epoch 740/10000: L(Train): 0.28955110907554626; L(Test): 0.26852235198020935\n",
      "Epoch 741/10000: L(Train): 0.27911075949668884; L(Test): 0.2692033052444458\n",
      "Epoch 742/10000: L(Train): 0.27268368005752563; L(Test): 0.2686464488506317\n",
      "Epoch 743/10000: L(Train): 0.3014942705631256; L(Test): 0.2684347331523895\n",
      "Epoch 744/10000: L(Train): 0.2947452962398529; L(Test): 0.26857438683509827\n",
      "Epoch 745/10000: L(Train): 0.2873341143131256; L(Test): 0.2687128782272339\n",
      "Epoch 746/10000: L(Train): 0.2730371356010437; L(Test): 0.26789677143096924\n",
      "Epoch 747/10000: L(Train): 0.2750105857849121; L(Test): 0.2684301733970642\n",
      "Epoch 748/10000: L(Train): 0.2841885983943939; L(Test): 0.26873263716697693\n",
      "Epoch 749/10000: L(Train): 0.2939629554748535; L(Test): 0.26742303371429443\n",
      "Epoch 750/10000: L(Train): 0.2753687798976898; L(Test): 0.2685609459877014\n",
      "Epoch 751/10000: L(Train): 0.291592538356781; L(Test): 0.2694266140460968\n",
      "Epoch 752/10000: L(Train): 0.28662192821502686; L(Test): 0.2689725458621979\n",
      "Epoch 753/10000: L(Train): 0.2832101285457611; L(Test): 0.2672169804573059\n",
      "Epoch 754/10000: L(Train): 0.2804487645626068; L(Test): 0.26756784319877625\n",
      "Epoch 755/10000: L(Train): 0.28676632046699524; L(Test): 0.2686668336391449\n",
      "Epoch 756/10000: L(Train): 0.2962709367275238; L(Test): 0.26694455742836\n",
      "Epoch 757/10000: L(Train): 0.30404114723205566; L(Test): 0.26735958456993103\n",
      "Epoch 758/10000: L(Train): 0.29167571663856506; L(Test): 0.2672152519226074\n",
      "Epoch 759/10000: L(Train): 0.25830426812171936; L(Test): 0.2691183388233185\n",
      "Epoch 760/10000: L(Train): 0.30198225378990173; L(Test): 0.267461895942688\n",
      "Epoch 761/10000: L(Train): 0.2797413766384125; L(Test): 0.2683178782463074\n",
      "Epoch 762/10000: L(Train): 0.27570629119873047; L(Test): 0.2684497833251953\n",
      "Epoch 763/10000: L(Train): 0.29617780447006226; L(Test): 0.26949959993362427\n",
      "Epoch 764/10000: L(Train): 0.28944316506385803; L(Test): 0.26683804392814636\n",
      "Epoch 765/10000: L(Train): 0.2930663824081421; L(Test): 0.26859331130981445\n",
      "Epoch 766/10000: L(Train): 0.2982373833656311; L(Test): 0.2675571143627167\n",
      "Epoch 767/10000: L(Train): 0.2863326370716095; L(Test): 0.2692156136035919\n",
      "Epoch 768/10000: L(Train): 0.28784388303756714; L(Test): 0.26726338267326355\n",
      "Epoch 769/10000: L(Train): 0.29579174518585205; L(Test): 0.268490731716156\n",
      "Epoch 770/10000: L(Train): 0.28728023171424866; L(Test): 0.26737600564956665\n",
      "Epoch 771/10000: L(Train): 0.2720242440700531; L(Test): 0.2698742151260376\n",
      "Epoch 772/10000: L(Train): 0.28268739581108093; L(Test): 0.2670181393623352\n",
      "Epoch 773/10000: L(Train): 0.27061375975608826; L(Test): 0.2677413821220398\n",
      "Epoch 774/10000: L(Train): 0.2719782590866089; L(Test): 0.26743972301483154\n",
      "Epoch 775/10000: L(Train): 0.2907058000564575; L(Test): 0.26842832565307617\n",
      "Epoch 776/10000: L(Train): 0.28924885392189026; L(Test): 0.26733145117759705\n",
      "Epoch 777/10000: L(Train): 0.282705694437027; L(Test): 0.2673191726207733\n",
      "Epoch 778/10000: L(Train): 0.2758733034133911; L(Test): 0.26668667793273926\n",
      "Epoch 779/10000: L(Train): 0.2961847186088562; L(Test): 0.26668521761894226\n",
      "Epoch 780/10000: L(Train): 0.27386122941970825; L(Test): 0.2661284804344177\n",
      "Epoch 781/10000: L(Train): 0.2862567901611328; L(Test): 0.2664068043231964\n",
      "Epoch 782/10000: L(Train): 0.2754870355129242; L(Test): 0.26617708802223206\n",
      "Epoch 783/10000: L(Train): 0.2896968722343445; L(Test): 0.26653435826301575\n",
      "Epoch 784/10000: L(Train): 0.26474007964134216; L(Test): 0.2662983238697052\n",
      "Epoch 785/10000: L(Train): 0.2806299328804016; L(Test): 0.26616111397743225\n",
      "Epoch 786/10000: L(Train): 0.26425880193710327; L(Test): 0.26665666699409485\n",
      "Epoch 787/10000: L(Train): 0.27023574709892273; L(Test): 0.2663484513759613\n",
      "Epoch 788/10000: L(Train): 0.2809259593486786; L(Test): 0.26592034101486206\n",
      "Epoch 789/10000: L(Train): 0.2804800868034363; L(Test): 0.26590046286582947\n",
      "Epoch 790/10000: L(Train): 0.2874439060688019; L(Test): 0.2653757631778717\n",
      "Epoch 791/10000: L(Train): 0.28814637660980225; L(Test): 0.26531335711479187\n",
      "Epoch 792/10000: L(Train): 0.27669742703437805; L(Test): 0.26563945412635803\n",
      "Epoch 793/10000: L(Train): 0.2926467955112457; L(Test): 0.2650561034679413\n",
      "Epoch 794/10000: L(Train): 0.29398277401924133; L(Test): 0.26505622267723083\n",
      "Epoch 795/10000: L(Train): 0.30703502893447876; L(Test): 0.2650863230228424\n",
      "Epoch 796/10000: L(Train): 0.2928500771522522; L(Test): 0.2660224437713623\n",
      "Epoch 797/10000: L(Train): 0.27600088715553284; L(Test): 0.2661934792995453\n",
      "Epoch 798/10000: L(Train): 0.2642068862915039; L(Test): 0.26504451036453247\n",
      "Epoch 799/10000: L(Train): 0.28195837140083313; L(Test): 0.2650897204875946\n",
      "Epoch 800/10000: L(Train): 0.278399795293808; L(Test): 0.26618894934654236\n",
      "Epoch 801/10000: L(Train): 0.30235981941223145; L(Test): 0.2650468647480011\n",
      "Epoch 802/10000: L(Train): 0.28648874163627625; L(Test): 0.26478198170661926\n",
      "Epoch 803/10000: L(Train): 0.271332323551178; L(Test): 0.2655520439147949\n",
      "Epoch 804/10000: L(Train): 0.27260878682136536; L(Test): 0.2653627097606659\n",
      "Epoch 805/10000: L(Train): 0.27214130759239197; L(Test): 0.2659724950790405\n",
      "Epoch 806/10000: L(Train): 0.2838934361934662; L(Test): 0.2644804120063782\n",
      "Epoch 807/10000: L(Train): 0.28569844365119934; L(Test): 0.2683418393135071\n",
      "Epoch 808/10000: L(Train): 0.2824578881263733; L(Test): 0.2655305862426758\n",
      "Epoch 809/10000: L(Train): 0.2830582857131958; L(Test): 0.2661052346229553\n",
      "Epoch 810/10000: L(Train): 0.28101351857185364; L(Test): 0.266145795583725\n",
      "Epoch 811/10000: L(Train): 0.2692006826400757; L(Test): 0.2681443989276886\n",
      "Epoch 812/10000: L(Train): 0.28638675808906555; L(Test): 0.26525288820266724\n",
      "Epoch 813/10000: L(Train): 0.2583959698677063; L(Test): 0.26603963971138\n",
      "Epoch 814/10000: L(Train): 0.29079920053482056; L(Test): 0.26667964458465576\n",
      "Epoch 815/10000: L(Train): 0.2840454578399658; L(Test): 0.2660391330718994\n",
      "Epoch 816/10000: L(Train): 0.2831985056400299; L(Test): 0.26468196511268616\n",
      "Epoch 817/10000: L(Train): 0.28362607955932617; L(Test): 0.26486441493034363\n",
      "Epoch 818/10000: L(Train): 0.29324308037757874; L(Test): 0.2656387686729431\n",
      "Epoch 819/10000: L(Train): 0.2724989652633667; L(Test): 0.2666952908039093\n",
      "Epoch 820/10000: L(Train): 0.2816227376461029; L(Test): 0.26588356494903564\n",
      "Epoch 821/10000: L(Train): 0.27190372347831726; L(Test): 0.26563578844070435\n",
      "Epoch 822/10000: L(Train): 0.278555691242218; L(Test): 0.265292763710022\n",
      "Epoch 823/10000: L(Train): 0.2913993299007416; L(Test): 0.26525014638900757\n",
      "Epoch 824/10000: L(Train): 0.2953658401966095; L(Test): 0.2646353244781494\n",
      "Epoch 825/10000: L(Train): 0.3062838315963745; L(Test): 0.2646777927875519\n",
      "Epoch 826/10000: L(Train): 0.2821683883666992; L(Test): 0.265082985162735\n",
      "Epoch 827/10000: L(Train): 0.27107512950897217; L(Test): 0.26532918214797974\n",
      "Epoch 828/10000: L(Train): 0.2898167371749878; L(Test): 0.26478150486946106\n",
      "Epoch 829/10000: L(Train): 0.2713434100151062; L(Test): 0.26597437262535095\n",
      "Epoch 830/10000: L(Train): 0.2782224714756012; L(Test): 0.26477888226509094\n",
      "Epoch 831/10000: L(Train): 0.28241613507270813; L(Test): 0.2650795578956604\n",
      "Epoch 832/10000: L(Train): 0.29925569891929626; L(Test): 0.26487380266189575\n",
      "Epoch 833/10000: L(Train): 0.2691837251186371; L(Test): 0.264690101146698\n",
      "Epoch 834/10000: L(Train): 0.27872413396835327; L(Test): 0.2648370862007141\n",
      "Epoch 835/10000: L(Train): 0.287598580121994; L(Test): 0.2643367350101471\n",
      "Epoch 836/10000: L(Train): 0.2926824688911438; L(Test): 0.26443353295326233\n",
      "Epoch 837/10000: L(Train): 0.2735152244567871; L(Test): 0.26463961601257324\n",
      "Epoch 838/10000: L(Train): 0.2935446798801422; L(Test): 0.2639234960079193\n",
      "Epoch 839/10000: L(Train): 0.29308441281318665; L(Test): 0.26400673389434814\n",
      "Epoch 840/10000: L(Train): 0.2783631980419159; L(Test): 0.26499560475349426\n",
      "Epoch 841/10000: L(Train): 0.2692567706108093; L(Test): 0.2646373212337494\n",
      "Epoch 842/10000: L(Train): 0.2922634780406952; L(Test): 0.26466280221939087\n",
      "Epoch 843/10000: L(Train): 0.27804484963417053; L(Test): 0.263875812292099\n",
      "Epoch 844/10000: L(Train): 0.28560560941696167; L(Test): 0.26347246766090393\n",
      "Epoch 845/10000: L(Train): 0.2726404368877411; L(Test): 0.26478299498558044\n",
      "Epoch 846/10000: L(Train): 0.28296712040901184; L(Test): 0.26314881443977356\n",
      "Epoch 847/10000: L(Train): 0.27749431133270264; L(Test): 0.26336127519607544\n",
      "Epoch 848/10000: L(Train): 0.2728523015975952; L(Test): 0.2647491693496704\n",
      "Epoch 849/10000: L(Train): 0.26809218525886536; L(Test): 0.2651542127132416\n",
      "Epoch 850/10000: L(Train): 0.2732544541358948; L(Test): 0.2636936902999878\n",
      "Epoch 851/10000: L(Train): 0.2850889265537262; L(Test): 0.26367810368537903\n",
      "Epoch 852/10000: L(Train): 0.27654218673706055; L(Test): 0.2640765905380249\n",
      "Epoch 853/10000: L(Train): 0.29212692379951477; L(Test): 0.2641342282295227\n",
      "Epoch 854/10000: L(Train): 0.29765579104423523; L(Test): 0.2627285122871399\n",
      "Epoch 855/10000: L(Train): 0.2826821506023407; L(Test): 0.262999564409256\n",
      "Epoch 856/10000: L(Train): 0.27868175506591797; L(Test): 0.26371774077415466\n",
      "Epoch 857/10000: L(Train): 0.2974502742290497; L(Test): 0.26354122161865234\n",
      "Epoch 858/10000: L(Train): 0.27551308274269104; L(Test): 0.26244258880615234\n",
      "Epoch 859/10000: L(Train): 0.28089970350265503; L(Test): 0.26342514157295227\n",
      "Epoch 860/10000: L(Train): 0.25864529609680176; L(Test): 0.26362866163253784\n",
      "Epoch 861/10000: L(Train): 0.27048972249031067; L(Test): 0.2630941867828369\n",
      "Epoch 862/10000: L(Train): 0.2749064564704895; L(Test): 0.2639238238334656\n",
      "Epoch 863/10000: L(Train): 0.2830682694911957; L(Test): 0.26230305433273315\n",
      "Epoch 864/10000: L(Train): 0.2865149974822998; L(Test): 0.2633313536643982\n",
      "Epoch 865/10000: L(Train): 0.27042287588119507; L(Test): 0.26409855484962463\n",
      "Epoch 866/10000: L(Train): 0.28361883759498596; L(Test): 0.26319172978401184\n",
      "Epoch 867/10000: L(Train): 0.27778375148773193; L(Test): 0.2631255090236664\n",
      "Epoch 868/10000: L(Train): 0.2984929382801056; L(Test): 0.26227447390556335\n",
      "Epoch 869/10000: L(Train): 0.281273752450943; L(Test): 0.2619982659816742\n",
      "Epoch 870/10000: L(Train): 0.2622475028038025; L(Test): 0.2623070478439331\n",
      "Epoch 871/10000: L(Train): 0.282250314950943; L(Test): 0.26228025555610657\n",
      "Epoch 872/10000: L(Train): 0.2976062297821045; L(Test): 0.26231300830841064\n",
      "Epoch 873/10000: L(Train): 0.29237449169158936; L(Test): 0.2623443007469177\n",
      "Epoch 874/10000: L(Train): 0.28380313515663147; L(Test): 0.26247933506965637\n",
      "Epoch 875/10000: L(Train): 0.28042200207710266; L(Test): 0.26403477787971497\n",
      "Epoch 876/10000: L(Train): 0.27631762623786926; L(Test): 0.2638840973377228\n",
      "Epoch 877/10000: L(Train): 0.27568504214286804; L(Test): 0.26405489444732666\n",
      "Epoch 878/10000: L(Train): 0.26402604579925537; L(Test): 0.2636665105819702\n",
      "Epoch 879/10000: L(Train): 0.2805284261703491; L(Test): 0.26367196440696716\n",
      "Epoch 880/10000: L(Train): 0.2699279487133026; L(Test): 0.2630152404308319\n",
      "Epoch 881/10000: L(Train): 0.2791382372379303; L(Test): 0.2632991671562195\n",
      "Epoch 882/10000: L(Train): 0.2624785900115967; L(Test): 0.2631421685218811\n",
      "Epoch 883/10000: L(Train): 0.27891531586647034; L(Test): 0.26281559467315674\n",
      "Epoch 884/10000: L(Train): 0.2790834605693817; L(Test): 0.264443963766098\n",
      "Epoch 885/10000: L(Train): 0.29106783866882324; L(Test): 0.2625376880168915\n",
      "Epoch 886/10000: L(Train): 0.268302857875824; L(Test): 0.26220497488975525\n",
      "Epoch 887/10000: L(Train): 0.2824100852012634; L(Test): 0.26424533128738403\n",
      "Epoch 888/10000: L(Train): 0.28909531235694885; L(Test): 0.2633296549320221\n",
      "Epoch 889/10000: L(Train): 0.2748347520828247; L(Test): 0.26244059205055237\n",
      "Epoch 890/10000: L(Train): 0.26967984437942505; L(Test): 0.26267772912979126\n",
      "Epoch 891/10000: L(Train): 0.27224481105804443; L(Test): 0.262443482875824\n",
      "Epoch 892/10000: L(Train): 0.2780575752258301; L(Test): 0.2619166076183319\n",
      "Epoch 893/10000: L(Train): 0.2776462137699127; L(Test): 0.26268306374549866\n",
      "Epoch 894/10000: L(Train): 0.2834857404232025; L(Test): 0.26247820258140564\n",
      "Epoch 895/10000: L(Train): 0.2847346365451813; L(Test): 0.2633865475654602\n",
      "Epoch 896/10000: L(Train): 0.2865559458732605; L(Test): 0.26308369636535645\n",
      "Epoch 897/10000: L(Train): 0.2789837419986725; L(Test): 0.2621040940284729\n",
      "Epoch 898/10000: L(Train): 0.2693113088607788; L(Test): 0.2612225115299225\n",
      "Epoch 899/10000: L(Train): 0.2834452986717224; L(Test): 0.26290246844291687\n",
      "Epoch 900/10000: L(Train): 0.2770056426525116; L(Test): 0.26391172409057617\n",
      "Epoch 901/10000: L(Train): 0.29171594977378845; L(Test): 0.2622182071208954\n",
      "Epoch 902/10000: L(Train): 0.2837667763233185; L(Test): 0.2617824971675873\n",
      "Epoch 903/10000: L(Train): 0.28053542971611023; L(Test): 0.26335999369621277\n",
      "Epoch 904/10000: L(Train): 0.2720452845096588; L(Test): 0.2620423138141632\n",
      "Epoch 905/10000: L(Train): 0.2809540331363678; L(Test): 0.2620176672935486\n",
      "Epoch 906/10000: L(Train): 0.2885114848613739; L(Test): 0.261848121881485\n",
      "Epoch 907/10000: L(Train): 0.2887861132621765; L(Test): 0.2624807059764862\n",
      "Epoch 908/10000: L(Train): 0.2782992720603943; L(Test): 0.26182374358177185\n",
      "Epoch 909/10000: L(Train): 0.2897838056087494; L(Test): 0.26153501868247986\n",
      "Epoch 910/10000: L(Train): 0.2847030758857727; L(Test): 0.26145386695861816\n",
      "Epoch 911/10000: L(Train): 0.2808980345726013; L(Test): 0.26272454857826233\n",
      "Epoch 912/10000: L(Train): 0.2811529040336609; L(Test): 0.2618615925312042\n",
      "Epoch 913/10000: L(Train): 0.2768869400024414; L(Test): 0.2610902786254883\n",
      "Epoch 914/10000: L(Train): 0.27330467104911804; L(Test): 0.26098188757896423\n",
      "Epoch 915/10000: L(Train): 0.2675277292728424; L(Test): 0.2622191309928894\n",
      "Epoch 916/10000: L(Train): 0.27343645691871643; L(Test): 0.26192426681518555\n",
      "Epoch 917/10000: L(Train): 0.27574995160102844; L(Test): 0.2608926594257355\n",
      "Epoch 918/10000: L(Train): 0.29194509983062744; L(Test): 0.2609209716320038\n",
      "Epoch 919/10000: L(Train): 0.29529914259910583; L(Test): 0.26193660497665405\n",
      "Epoch 920/10000: L(Train): 0.2901425063610077; L(Test): 0.26146966218948364\n",
      "Epoch 921/10000: L(Train): 0.28045085072517395; L(Test): 0.26146775484085083\n",
      "Epoch 922/10000: L(Train): 0.2754109501838684; L(Test): 0.26257893443107605\n",
      "Epoch 923/10000: L(Train): 0.2798254191875458; L(Test): 0.26292943954467773\n",
      "Epoch 924/10000: L(Train): 0.2701394557952881; L(Test): 0.26198405027389526\n",
      "Epoch 925/10000: L(Train): 0.2737695872783661; L(Test): 0.26151251792907715\n",
      "Epoch 926/10000: L(Train): 0.2818933129310608; L(Test): 0.26165443658828735\n",
      "Epoch 927/10000: L(Train): 0.2900194823741913; L(Test): 0.2622286379337311\n",
      "Epoch 928/10000: L(Train): 0.26466283202171326; L(Test): 0.2624867260456085\n",
      "Epoch 929/10000: L(Train): 0.2829677164554596; L(Test): 0.2617662250995636\n",
      "Epoch 930/10000: L(Train): 0.2791396975517273; L(Test): 0.2611986994743347\n",
      "Epoch 931/10000: L(Train): 0.2731187045574188; L(Test): 0.2618810534477234\n",
      "Epoch 932/10000: L(Train): 0.2778627574443817; L(Test): 0.2615494728088379\n",
      "Epoch 933/10000: L(Train): 0.272468239068985; L(Test): 0.2610279619693756\n",
      "Epoch 934/10000: L(Train): 0.2716738283634186; L(Test): 0.26068830490112305\n",
      "Epoch 935/10000: L(Train): 0.2743805944919586; L(Test): 0.2615053057670593\n",
      "Epoch 936/10000: L(Train): 0.2659931480884552; L(Test): 0.2613079845905304\n",
      "Epoch 937/10000: L(Train): 0.2809697687625885; L(Test): 0.2619642913341522\n",
      "Epoch 938/10000: L(Train): 0.2754918038845062; L(Test): 0.261594295501709\n",
      "Epoch 939/10000: L(Train): 0.2866704761981964; L(Test): 0.26204243302345276\n",
      "Epoch 940/10000: L(Train): 0.2771033048629761; L(Test): 0.261849969625473\n",
      "Epoch 941/10000: L(Train): 0.28075331449508667; L(Test): 0.2620725631713867\n",
      "Epoch 942/10000: L(Train): 0.27307817339897156; L(Test): 0.2607453763484955\n",
      "Epoch 943/10000: L(Train): 0.2753840684890747; L(Test): 0.2611958682537079\n",
      "Epoch 944/10000: L(Train): 0.28762906789779663; L(Test): 0.2617570459842682\n",
      "Epoch 945/10000: L(Train): 0.2852620482444763; L(Test): 0.26227760314941406\n",
      "Epoch 946/10000: L(Train): 0.291652649641037; L(Test): 0.26146239042282104\n",
      "Epoch 947/10000: L(Train): 0.27757012844085693; L(Test): 0.26164141297340393\n",
      "Epoch 948/10000: L(Train): 0.2792110741138458; L(Test): 0.2611599266529083\n",
      "Epoch 949/10000: L(Train): 0.2769707143306732; L(Test): 0.2605611979961395\n",
      "Epoch 950/10000: L(Train): 0.2700260579586029; L(Test): 0.26287251710891724\n",
      "Epoch 951/10000: L(Train): 0.27803927659988403; L(Test): 0.2612802982330322\n",
      "Epoch 952/10000: L(Train): 0.2817155420780182; L(Test): 0.2600422203540802\n",
      "Epoch 953/10000: L(Train): 0.28604069352149963; L(Test): 0.2605776786804199\n",
      "Epoch 954/10000: L(Train): 0.25916680693626404; L(Test): 0.2606219947338104\n",
      "Epoch 955/10000: L(Train): 0.2684347629547119; L(Test): 0.26045387983322144\n",
      "Epoch 956/10000: L(Train): 0.26799044013023376; L(Test): 0.26007959246635437\n",
      "Epoch 957/10000: L(Train): 0.27571892738342285; L(Test): 0.2605935037136078\n",
      "Epoch 958/10000: L(Train): 0.27805909514427185; L(Test): 0.2599506378173828\n",
      "Epoch 959/10000: L(Train): 0.2755456566810608; L(Test): 0.2597665786743164\n",
      "Epoch 960/10000: L(Train): 0.26635250449180603; L(Test): 0.2601737380027771\n",
      "Epoch 961/10000: L(Train): 0.27420666813850403; L(Test): 0.25974979996681213\n",
      "Epoch 962/10000: L(Train): 0.25859779119491577; L(Test): 0.26051345467567444\n",
      "Epoch 963/10000: L(Train): 0.27027246356010437; L(Test): 0.25914838910102844\n",
      "Epoch 964/10000: L(Train): 0.2818964719772339; L(Test): 0.26062723994255066\n",
      "Epoch 965/10000: L(Train): 0.2976416051387787; L(Test): 0.25945425033569336\n",
      "Epoch 966/10000: L(Train): 0.2816980183124542; L(Test): 0.25881972908973694\n",
      "Epoch 967/10000: L(Train): 0.27274641394615173; L(Test): 0.26024213433265686\n",
      "Epoch 968/10000: L(Train): 0.2795248329639435; L(Test): 0.25981366634368896\n",
      "Epoch 969/10000: L(Train): 0.2762921452522278; L(Test): 0.2608027160167694\n",
      "Epoch 970/10000: L(Train): 0.29201969504356384; L(Test): 0.259848028421402\n",
      "Epoch 971/10000: L(Train): 0.2849716544151306; L(Test): 0.2599477767944336\n",
      "Epoch 972/10000: L(Train): 0.2783657908439636; L(Test): 0.2589748501777649\n",
      "Epoch 973/10000: L(Train): 0.2691492438316345; L(Test): 0.26047012209892273\n",
      "Epoch 974/10000: L(Train): 0.2580474019050598; L(Test): 0.2602124810218811\n",
      "Epoch 975/10000: L(Train): 0.27328985929489136; L(Test): 0.2595137059688568\n",
      "Epoch 976/10000: L(Train): 0.2866363227367401; L(Test): 0.2590084671974182\n",
      "Epoch 977/10000: L(Train): 0.2871858775615692; L(Test): 0.26074910163879395\n",
      "Epoch 978/10000: L(Train): 0.27997449040412903; L(Test): 0.2586253583431244\n",
      "Epoch 979/10000: L(Train): 0.2738799452781677; L(Test): 0.2601090669631958\n",
      "Epoch 980/10000: L(Train): 0.27029451727867126; L(Test): 0.2596542537212372\n",
      "Epoch 981/10000: L(Train): 0.2845597267150879; L(Test): 0.25989511609077454\n",
      "Epoch 982/10000: L(Train): 0.2854771614074707; L(Test): 0.2591431736946106\n",
      "Epoch 983/10000: L(Train): 0.28352952003479004; L(Test): 0.2595495879650116\n",
      "Epoch 984/10000: L(Train): 0.27229782938957214; L(Test): 0.2608652114868164\n",
      "Epoch 985/10000: L(Train): 0.28835421800613403; L(Test): 0.25931286811828613\n",
      "Epoch 986/10000: L(Train): 0.27861589193344116; L(Test): 0.25991320610046387\n",
      "Epoch 987/10000: L(Train): 0.2705150842666626; L(Test): 0.2591328024864197\n",
      "Epoch 988/10000: L(Train): 0.2846977114677429; L(Test): 0.26010802388191223\n",
      "Epoch 989/10000: L(Train): 0.27722597122192383; L(Test): 0.26009705662727356\n",
      "Epoch 990/10000: L(Train): 0.2831399142742157; L(Test): 0.26069384813308716\n",
      "Epoch 991/10000: L(Train): 0.27574291825294495; L(Test): 0.2607901096343994\n",
      "Epoch 992/10000: L(Train): 0.28317028284072876; L(Test): 0.2601641118526459\n",
      "Epoch 993/10000: L(Train): 0.2654658854007721; L(Test): 0.2613763213157654\n",
      "Epoch 994/10000: L(Train): 0.2841673493385315; L(Test): 0.25950106978416443\n",
      "Epoch 995/10000: L(Train): 0.2831568717956543; L(Test): 0.2591400444507599\n",
      "Epoch 996/10000: L(Train): 0.2827029824256897; L(Test): 0.2596341371536255\n",
      "Epoch 997/10000: L(Train): 0.28370749950408936; L(Test): 0.25895872712135315\n",
      "Epoch 998/10000: L(Train): 0.2870093286037445; L(Test): 0.2589024305343628\n",
      "Epoch 999/10000: L(Train): 0.2674034833908081; L(Test): 0.2593344449996948\n",
      "Epoch 1000/10000: L(Train): 0.2665225565433502; L(Test): 0.25996536016464233\n",
      "Epoch 1001/10000: L(Train): 0.27943098545074463; L(Test): 0.25892403721809387\n",
      "Epoch 1002/10000: L(Train): 0.2775631546974182; L(Test): 0.25940388441085815\n",
      "Epoch 1003/10000: L(Train): 0.27581217885017395; L(Test): 0.25944116711616516\n",
      "Epoch 1004/10000: L(Train): 0.27309176325798035; L(Test): 0.25904253125190735\n",
      "Epoch 1005/10000: L(Train): 0.2870703935623169; L(Test): 0.2585357427597046\n",
      "Epoch 1006/10000: L(Train): 0.29325374960899353; L(Test): 0.2585142254829407\n",
      "Epoch 1007/10000: L(Train): 0.2748086154460907; L(Test): 0.25896820425987244\n",
      "Epoch 1008/10000: L(Train): 0.27215707302093506; L(Test): 0.25980475544929504\n",
      "Epoch 1009/10000: L(Train): 0.2685244679450989; L(Test): 0.2590399980545044\n",
      "Epoch 1010/10000: L(Train): 0.2623225748538971; L(Test): 0.25902292132377625\n",
      "Epoch 1011/10000: L(Train): 0.2800147235393524; L(Test): 0.25950148701667786\n",
      "Epoch 1012/10000: L(Train): 0.28647443652153015; L(Test): 0.25926995277404785\n",
      "Epoch 1013/10000: L(Train): 0.27238306403160095; L(Test): 0.25915616750717163\n",
      "Epoch 1014/10000: L(Train): 0.27842265367507935; L(Test): 0.259304404258728\n",
      "Epoch 1015/10000: L(Train): 0.2900717556476593; L(Test): 0.2590491473674774\n",
      "Epoch 1016/10000: L(Train): 0.26622846722602844; L(Test): 0.2601369321346283\n",
      "Epoch 1017/10000: L(Train): 0.2723355293273926; L(Test): 0.25891369581222534\n",
      "Epoch 1018/10000: L(Train): 0.28715091943740845; L(Test): 0.25991761684417725\n",
      "Epoch 1019/10000: L(Train): 0.294248104095459; L(Test): 0.25875788927078247\n",
      "Epoch 1020/10000: L(Train): 0.28442177176475525; L(Test): 0.2607150971889496\n",
      "Epoch 1021/10000: L(Train): 0.2749083340167999; L(Test): 0.2581728994846344\n",
      "Epoch 1022/10000: L(Train): 0.27312782406806946; L(Test): 0.2592875361442566\n",
      "Epoch 1023/10000: L(Train): 0.27650928497314453; L(Test): 0.2579813003540039\n",
      "Epoch 1024/10000: L(Train): 0.25812190771102905; L(Test): 0.26010286808013916\n",
      "Epoch 1025/10000: L(Train): 0.27869632840156555; L(Test): 0.2600904703140259\n",
      "Epoch 1026/10000: L(Train): 0.27551206946372986; L(Test): 0.2589684724807739\n",
      "Epoch 1027/10000: L(Train): 0.2870492935180664; L(Test): 0.25880879163742065\n",
      "Epoch 1028/10000: L(Train): 0.2787955105304718; L(Test): 0.25882837176322937\n",
      "Epoch 1029/10000: L(Train): 0.2782745957374573; L(Test): 0.2582196891307831\n",
      "Epoch 1030/10000: L(Train): 0.27927979826927185; L(Test): 0.258055716753006\n",
      "Epoch 1031/10000: L(Train): 0.2727053165435791; L(Test): 0.2586522400379181\n",
      "Epoch 1032/10000: L(Train): 0.2656033933162689; L(Test): 0.2578850984573364\n",
      "Epoch 1033/10000: L(Train): 0.29005569219589233; L(Test): 0.2572629451751709\n",
      "Epoch 1034/10000: L(Train): 0.28306737542152405; L(Test): 0.2578182816505432\n",
      "Epoch 1035/10000: L(Train): 0.2940048575401306; L(Test): 0.2582913041114807\n",
      "Epoch 1036/10000: L(Train): 0.2816648483276367; L(Test): 0.258190780878067\n",
      "Epoch 1037/10000: L(Train): 0.285232812166214; L(Test): 0.25737038254737854\n",
      "Epoch 1038/10000: L(Train): 0.2878133952617645; L(Test): 0.2574276328086853\n",
      "Epoch 1039/10000: L(Train): 0.287700355052948; L(Test): 0.2572670578956604\n",
      "Epoch 1040/10000: L(Train): 0.2814134657382965; L(Test): 0.2576853632926941\n",
      "Epoch 1041/10000: L(Train): 0.26454731822013855; L(Test): 0.2573666274547577\n",
      "Epoch 1042/10000: L(Train): 0.2652072012424469; L(Test): 0.2575310468673706\n",
      "Epoch 1043/10000: L(Train): 0.27052968740463257; L(Test): 0.2599964141845703\n",
      "Epoch 1044/10000: L(Train): 0.2765350043773651; L(Test): 0.25942742824554443\n",
      "Epoch 1045/10000: L(Train): 0.297094464302063; L(Test): 0.2586614191532135\n",
      "Epoch 1046/10000: L(Train): 0.27193722128868103; L(Test): 0.2628577649593353\n",
      "Epoch 1047/10000: L(Train): 0.2900031507015228; L(Test): 0.26088568568229675\n",
      "Epoch 1048/10000: L(Train): 0.2758932411670685; L(Test): 0.2593425512313843\n",
      "Epoch 1049/10000: L(Train): 0.2745037078857422; L(Test): 0.2601661682128906\n",
      "Epoch 1050/10000: L(Train): 0.2769802510738373; L(Test): 0.2624237537384033\n",
      "Epoch 1051/10000: L(Train): 0.3044965863227844; L(Test): 0.25972625613212585\n",
      "Epoch 1052/10000: L(Train): 0.26451295614242554; L(Test): 0.2598067820072174\n",
      "Epoch 1053/10000: L(Train): 0.2752362787723541; L(Test): 0.2602652907371521\n",
      "Epoch 1054/10000: L(Train): 0.2806364595890045; L(Test): 0.26143333315849304\n",
      "Epoch 1055/10000: L(Train): 0.3057859539985657; L(Test): 0.2595035135746002\n",
      "Epoch 1056/10000: L(Train): 0.28408974409103394; L(Test): 0.26215535402297974\n",
      "Epoch 1057/10000: L(Train): 0.2768639624118805; L(Test): 0.25961148738861084\n",
      "Epoch 1058/10000: L(Train): 0.271298885345459; L(Test): 0.2611607611179352\n",
      "Epoch 1059/10000: L(Train): 0.2864725887775421; L(Test): 0.2596833109855652\n",
      "Epoch 1060/10000: L(Train): 0.2745548486709595; L(Test): 0.25984835624694824\n",
      "Epoch 1061/10000: L(Train): 0.26990729570388794; L(Test): 0.2595403492450714\n",
      "Epoch 1062/10000: L(Train): 0.27738362550735474; L(Test): 0.2602035701274872\n",
      "Epoch 1063/10000: L(Train): 0.26729875802993774; L(Test): 0.2594667077064514\n",
      "Epoch 1064/10000: L(Train): 0.2860832214355469; L(Test): 0.25866565108299255\n",
      "Epoch 1065/10000: L(Train): 0.2948252260684967; L(Test): 0.2587742805480957\n",
      "Epoch 1066/10000: L(Train): 0.2841702699661255; L(Test): 0.2582372725009918\n",
      "Epoch 1067/10000: L(Train): 0.2688702344894409; L(Test): 0.25880345702171326\n",
      "Epoch 1068/10000: L(Train): 0.28869351744651794; L(Test): 0.2574828267097473\n",
      "Epoch 1069/10000: L(Train): 0.27210086584091187; L(Test): 0.2574555575847626\n",
      "Epoch 1070/10000: L(Train): 0.268142431974411; L(Test): 0.2563987374305725\n",
      "Epoch 1071/10000: L(Train): 0.2699212431907654; L(Test): 0.2581441402435303\n",
      "Epoch 1072/10000: L(Train): 0.2794044315814972; L(Test): 0.2570750415325165\n",
      "Epoch 1073/10000: L(Train): 0.2896115183830261; L(Test): 0.2580201029777527\n",
      "Epoch 1074/10000: L(Train): 0.2728608250617981; L(Test): 0.2567656934261322\n",
      "Epoch 1075/10000: L(Train): 0.2730816602706909; L(Test): 0.2604019045829773\n",
      "Epoch 1076/10000: L(Train): 0.2744235098361969; L(Test): 0.2580873966217041\n",
      "Epoch 1077/10000: L(Train): 0.2896044850349426; L(Test): 0.2570653557777405\n",
      "Epoch 1078/10000: L(Train): 0.2635050117969513; L(Test): 0.2566227912902832\n",
      "Epoch 1079/10000: L(Train): 0.28342491388320923; L(Test): 0.2574913799762726\n",
      "Epoch 1080/10000: L(Train): 0.28759878873825073; L(Test): 0.25875768065452576\n",
      "Epoch 1081/10000: L(Train): 0.26949161291122437; L(Test): 0.2563915550708771\n",
      "Epoch 1082/10000: L(Train): 0.2617422938346863; L(Test): 0.2579094171524048\n",
      "Epoch 1083/10000: L(Train): 0.2740984261035919; L(Test): 0.2573799788951874\n",
      "Epoch 1084/10000: L(Train): 0.28179171681404114; L(Test): 0.2578258514404297\n",
      "Epoch 1085/10000: L(Train): 0.2767074406147003; L(Test): 0.25737500190734863\n",
      "Epoch 1086/10000: L(Train): 0.27208226919174194; L(Test): 0.25744009017944336\n",
      "Epoch 1087/10000: L(Train): 0.26592305302619934; L(Test): 0.25629666447639465\n",
      "Epoch 1088/10000: L(Train): 0.2739071547985077; L(Test): 0.2582242786884308\n",
      "Epoch 1089/10000: L(Train): 0.285868376493454; L(Test): 0.25795310735702515\n",
      "Epoch 1090/10000: L(Train): 0.2763544023036957; L(Test): 0.2572883367538452\n",
      "Epoch 1091/10000: L(Train): 0.28055310249328613; L(Test): 0.25718560814857483\n",
      "Epoch 1092/10000: L(Train): 0.26570460200309753; L(Test): 0.2562747895717621\n",
      "Epoch 1093/10000: L(Train): 0.2731327712535858; L(Test): 0.2577681541442871\n",
      "Epoch 1094/10000: L(Train): 0.2666447162628174; L(Test): 0.25791412591934204\n",
      "Epoch 1095/10000: L(Train): 0.2846599519252777; L(Test): 0.25725606083869934\n",
      "Epoch 1096/10000: L(Train): 0.28298935294151306; L(Test): 0.2573752701282501\n",
      "Epoch 1097/10000: L(Train): 0.2645128071308136; L(Test): 0.25988084077835083\n",
      "Epoch 1098/10000: L(Train): 0.2933349013328552; L(Test): 0.2573430836200714\n",
      "Epoch 1099/10000: L(Train): 0.2965858280658722; L(Test): 0.2572936713695526\n",
      "Epoch 1100/10000: L(Train): 0.27735665440559387; L(Test): 0.25686293840408325\n",
      "Epoch 1101/10000: L(Train): 0.2822057902812958; L(Test): 0.25655466318130493\n",
      "Epoch 1102/10000: L(Train): 0.27605873346328735; L(Test): 0.2570400536060333\n",
      "Epoch 1103/10000: L(Train): 0.26245591044425964; L(Test): 0.2574804425239563\n",
      "Epoch 1104/10000: L(Train): 0.292800635099411; L(Test): 0.2569645941257477\n",
      "Epoch 1105/10000: L(Train): 0.2783501148223877; L(Test): 0.2569483518600464\n",
      "Epoch 1106/10000: L(Train): 0.2644188106060028; L(Test): 0.2573109567165375\n",
      "Epoch 1107/10000: L(Train): 0.2777985632419586; L(Test): 0.2565457820892334\n",
      "Epoch 1108/10000: L(Train): 0.2714866101741791; L(Test): 0.257607102394104\n",
      "Epoch 1109/10000: L(Train): 0.275821715593338; L(Test): 0.25749924778938293\n",
      "Epoch 1110/10000: L(Train): 0.26217618584632874; L(Test): 0.2573145925998688\n",
      "Epoch 1111/10000: L(Train): 0.27045702934265137; L(Test): 0.2574097514152527\n",
      "Epoch 1112/10000: L(Train): 0.2776298522949219; L(Test): 0.25604936480522156\n",
      "Epoch 1113/10000: L(Train): 0.26063668727874756; L(Test): 0.25658416748046875\n",
      "Epoch 1114/10000: L(Train): 0.26293307542800903; L(Test): 0.2569442391395569\n",
      "Epoch 1115/10000: L(Train): 0.26831114292144775; L(Test): 0.25639915466308594\n",
      "Epoch 1116/10000: L(Train): 0.27977094054222107; L(Test): 0.25713756680488586\n",
      "Epoch 1117/10000: L(Train): 0.2768707573413849; L(Test): 0.2572075128555298\n",
      "Epoch 1118/10000: L(Train): 0.26943904161453247; L(Test): 0.2564014196395874\n",
      "Epoch 1119/10000: L(Train): 0.2712532579898834; L(Test): 0.25556373596191406\n",
      "Epoch 1120/10000: L(Train): 0.281562864780426; L(Test): 0.2559767961502075\n",
      "Epoch 1121/10000: L(Train): 0.2704314589500427; L(Test): 0.25659945607185364\n",
      "Epoch 1122/10000: L(Train): 0.2772495448589325; L(Test): 0.25589320063591003\n",
      "Epoch 1123/10000: L(Train): 0.26957806944847107; L(Test): 0.25628870725631714\n",
      "Epoch 1124/10000: L(Train): 0.2610381245613098; L(Test): 0.25709837675094604\n",
      "Epoch 1125/10000: L(Train): 0.2669966220855713; L(Test): 0.2572878301143646\n",
      "Epoch 1126/10000: L(Train): 0.279646635055542; L(Test): 0.2570427656173706\n",
      "Epoch 1127/10000: L(Train): 0.28771862387657166; L(Test): 0.2567997872829437\n",
      "Epoch 1128/10000: L(Train): 0.26671451330184937; L(Test): 0.25612521171569824\n",
      "Epoch 1129/10000: L(Train): 0.27622801065444946; L(Test): 0.25699761509895325\n",
      "Epoch 1130/10000: L(Train): 0.2593569755554199; L(Test): 0.25652235746383667\n",
      "Epoch 1131/10000: L(Train): 0.28334352374076843; L(Test): 0.2575627267360687\n",
      "Epoch 1132/10000: L(Train): 0.2762017548084259; L(Test): 0.2562096118927002\n",
      "Epoch 1133/10000: L(Train): 0.27314695715904236; L(Test): 0.25653699040412903\n",
      "Epoch 1134/10000: L(Train): 0.27407538890838623; L(Test): 0.25756749510765076\n",
      "Epoch 1135/10000: L(Train): 0.26411712169647217; L(Test): 0.2553931176662445\n",
      "Epoch 1136/10000: L(Train): 0.2817832827568054; L(Test): 0.2563900053501129\n",
      "Epoch 1137/10000: L(Train): 0.2770870625972748; L(Test): 0.2554829716682434\n",
      "Epoch 1138/10000: L(Train): 0.2647896111011505; L(Test): 0.25659993290901184\n",
      "Epoch 1139/10000: L(Train): 0.2672996520996094; L(Test): 0.2559739649295807\n",
      "Epoch 1140/10000: L(Train): 0.26767295598983765; L(Test): 0.25521573424339294\n",
      "Epoch 1141/10000: L(Train): 0.2681140899658203; L(Test): 0.2553400695323944\n",
      "Epoch 1142/10000: L(Train): 0.2681255042552948; L(Test): 0.255257248878479\n",
      "Epoch 1143/10000: L(Train): 0.27838167548179626; L(Test): 0.25614649057388306\n",
      "Epoch 1144/10000: L(Train): 0.27061429619789124; L(Test): 0.2551923990249634\n",
      "Epoch 1145/10000: L(Train): 0.2799937427043915; L(Test): 0.2563825249671936\n",
      "Epoch 1146/10000: L(Train): 0.2694658041000366; L(Test): 0.25618740916252136\n",
      "Epoch 1147/10000: L(Train): 0.2770621180534363; L(Test): 0.2545509338378906\n",
      "Epoch 1148/10000: L(Train): 0.2851211726665497; L(Test): 0.2562776803970337\n",
      "Epoch 1149/10000: L(Train): 0.27922821044921875; L(Test): 0.25576308369636536\n",
      "Epoch 1150/10000: L(Train): 0.2619434595108032; L(Test): 0.2572389245033264\n",
      "Epoch 1151/10000: L(Train): 0.27265557646751404; L(Test): 0.2561761736869812\n",
      "Epoch 1152/10000: L(Train): 0.27924248576164246; L(Test): 0.2575741112232208\n",
      "Epoch 1153/10000: L(Train): 0.2694584131240845; L(Test): 0.2554977238178253\n",
      "Epoch 1154/10000: L(Train): 0.27766188979148865; L(Test): 0.2565959692001343\n",
      "Epoch 1155/10000: L(Train): 0.2827302813529968; L(Test): 0.2559519410133362\n",
      "Epoch 1156/10000: L(Train): 0.2906046509742737; L(Test): 0.2563494145870209\n",
      "Epoch 1157/10000: L(Train): 0.2770836055278778; L(Test): 0.2552512586116791\n",
      "Epoch 1158/10000: L(Train): 0.2730758488178253; L(Test): 0.25762856006622314\n",
      "Epoch 1159/10000: L(Train): 0.2801162600517273; L(Test): 0.25643861293792725\n",
      "Epoch 1160/10000: L(Train): 0.26987266540527344; L(Test): 0.2548188269138336\n",
      "Epoch 1161/10000: L(Train): 0.26319077610969543; L(Test): 0.2549055516719818\n",
      "Epoch 1162/10000: L(Train): 0.2747279107570648; L(Test): 0.25572195649147034\n",
      "Epoch 1163/10000: L(Train): 0.26524391770362854; L(Test): 0.255502849817276\n",
      "Epoch 1164/10000: L(Train): 0.25969478487968445; L(Test): 0.25527438521385193\n",
      "Epoch 1165/10000: L(Train): 0.27542927861213684; L(Test): 0.25477996468544006\n",
      "Epoch 1166/10000: L(Train): 0.2781818211078644; L(Test): 0.25542277097702026\n",
      "Epoch 1167/10000: L(Train): 0.26251718401908875; L(Test): 0.256324827671051\n",
      "Epoch 1168/10000: L(Train): 0.26843953132629395; L(Test): 0.2566884160041809\n",
      "Epoch 1169/10000: L(Train): 0.2715326249599457; L(Test): 0.2559185028076172\n",
      "Epoch 1170/10000: L(Train): 0.2853379249572754; L(Test): 0.2571406066417694\n",
      "Epoch 1171/10000: L(Train): 0.27122241258621216; L(Test): 0.2575366497039795\n",
      "Epoch 1172/10000: L(Train): 0.2797868549823761; L(Test): 0.256234735250473\n",
      "Epoch 1173/10000: L(Train): 0.28808653354644775; L(Test): 0.2562757134437561\n",
      "Epoch 1174/10000: L(Train): 0.27562999725341797; L(Test): 0.2556515038013458\n",
      "Epoch 1175/10000: L(Train): 0.24983027577400208; L(Test): 0.25634294748306274\n",
      "Epoch 1176/10000: L(Train): 0.26998060941696167; L(Test): 0.2559267580509186\n",
      "Epoch 1177/10000: L(Train): 0.28934329748153687; L(Test): 0.25613540410995483\n",
      "Epoch 1178/10000: L(Train): 0.2815275192260742; L(Test): 0.2563905417919159\n",
      "Epoch 1179/10000: L(Train): 0.26813143491744995; L(Test): 0.2561763525009155\n",
      "Epoch 1180/10000: L(Train): 0.2614961564540863; L(Test): 0.2557869255542755\n",
      "Epoch 1181/10000: L(Train): 0.2776578962802887; L(Test): 0.2555888295173645\n",
      "Epoch 1182/10000: L(Train): 0.2614981234073639; L(Test): 0.25516900420188904\n",
      "Epoch 1183/10000: L(Train): 0.2735411524772644; L(Test): 0.2551935315132141\n",
      "Epoch 1184/10000: L(Train): 0.28077432513237; L(Test): 0.2558354437351227\n",
      "Epoch 1185/10000: L(Train): 0.25722986459732056; L(Test): 0.2563749849796295\n",
      "Epoch 1186/10000: L(Train): 0.26342466473579407; L(Test): 0.25493496656417847\n",
      "Epoch 1187/10000: L(Train): 0.278949111700058; L(Test): 0.25471097230911255\n",
      "Epoch 1188/10000: L(Train): 0.2733726501464844; L(Test): 0.25542140007019043\n",
      "Epoch 1189/10000: L(Train): 0.2821410596370697; L(Test): 0.25490543246269226\n",
      "Epoch 1190/10000: L(Train): 0.2751922011375427; L(Test): 0.2547030448913574\n",
      "Epoch 1191/10000: L(Train): 0.264547735452652; L(Test): 0.2552405595779419\n",
      "Epoch 1192/10000: L(Train): 0.27306923270225525; L(Test): 0.25495240092277527\n",
      "Epoch 1193/10000: L(Train): 0.24138899147510529; L(Test): 0.25477656722068787\n",
      "Epoch 1194/10000: L(Train): 0.2606925368309021; L(Test): 0.2552364468574524\n",
      "Epoch 1195/10000: L(Train): 0.2868845462799072; L(Test): 0.2550019323825836\n",
      "Epoch 1196/10000: L(Train): 0.26319748163223267; L(Test): 0.25417718291282654\n",
      "Epoch 1197/10000: L(Train): 0.2696615159511566; L(Test): 0.25449123978614807\n",
      "Epoch 1198/10000: L(Train): 0.28018495440483093; L(Test): 0.2549334466457367\n",
      "Epoch 1199/10000: L(Train): 0.2588130831718445; L(Test): 0.2543787658214569\n",
      "Epoch 1200/10000: L(Train): 0.2826647460460663; L(Test): 0.25385329127311707\n",
      "Epoch 1201/10000: L(Train): 0.26723676919937134; L(Test): 0.2540470063686371\n",
      "Epoch 1202/10000: L(Train): 0.2680915296077728; L(Test): 0.25471392273902893\n",
      "Epoch 1203/10000: L(Train): 0.2673335671424866; L(Test): 0.254431813955307\n",
      "Epoch 1204/10000: L(Train): 0.25308555364608765; L(Test): 0.25507164001464844\n",
      "Epoch 1205/10000: L(Train): 0.2758258581161499; L(Test): 0.2549426555633545\n",
      "Epoch 1206/10000: L(Train): 0.2824309170246124; L(Test): 0.25527244806289673\n",
      "Epoch 1207/10000: L(Train): 0.28228622674942017; L(Test): 0.254641592502594\n",
      "Epoch 1208/10000: L(Train): 0.26492688059806824; L(Test): 0.25551939010620117\n",
      "Epoch 1209/10000: L(Train): 0.2933916449546814; L(Test): 0.2547833323478699\n",
      "Epoch 1210/10000: L(Train): 0.27659791707992554; L(Test): 0.254798024892807\n",
      "Epoch 1211/10000: L(Train): 0.2884660065174103; L(Test): 0.2548550069332123\n",
      "Epoch 1212/10000: L(Train): 0.25172725319862366; L(Test): 0.2544329762458801\n",
      "Epoch 1213/10000: L(Train): 0.27997827529907227; L(Test): 0.2538728713989258\n",
      "Epoch 1214/10000: L(Train): 0.26578134298324585; L(Test): 0.2541998028755188\n",
      "Epoch 1215/10000: L(Train): 0.26960399746894836; L(Test): 0.25476810336112976\n",
      "Epoch 1216/10000: L(Train): 0.2647356390953064; L(Test): 0.2544739246368408\n",
      "Epoch 1217/10000: L(Train): 0.26844409108161926; L(Test): 0.25470200181007385\n",
      "Epoch 1218/10000: L(Train): 0.27643460035324097; L(Test): 0.254754900932312\n",
      "Epoch 1219/10000: L(Train): 0.27582433819770813; L(Test): 0.2537113428115845\n",
      "Epoch 1220/10000: L(Train): 0.2701771557331085; L(Test): 0.2556089162826538\n",
      "Epoch 1221/10000: L(Train): 0.2983991205692291; L(Test): 0.253513365983963\n",
      "Epoch 1222/10000: L(Train): 0.27476903796195984; L(Test): 0.25508978962898254\n",
      "Epoch 1223/10000: L(Train): 0.2693318724632263; L(Test): 0.25396716594696045\n",
      "Epoch 1224/10000: L(Train): 0.266959011554718; L(Test): 0.2577538788318634\n",
      "Epoch 1225/10000: L(Train): 0.2827402353286743; L(Test): 0.2547024190425873\n",
      "Epoch 1226/10000: L(Train): 0.2788732051849365; L(Test): 0.2546921968460083\n",
      "Epoch 1227/10000: L(Train): 0.25610262155532837; L(Test): 0.2548016607761383\n",
      "Epoch 1228/10000: L(Train): 0.27157095074653625; L(Test): 0.2543564736843109\n",
      "Epoch 1229/10000: L(Train): 0.27505600452423096; L(Test): 0.2551495134830475\n",
      "Epoch 1230/10000: L(Train): 0.2743532657623291; L(Test): 0.2548079192638397\n",
      "Epoch 1231/10000: L(Train): 0.277480810880661; L(Test): 0.25397902727127075\n",
      "Epoch 1232/10000: L(Train): 0.2718324661254883; L(Test): 0.25481879711151123\n",
      "Epoch 1233/10000: L(Train): 0.270977646112442; L(Test): 0.25556808710098267\n",
      "Epoch 1234/10000: L(Train): 0.2730109393596649; L(Test): 0.25459975004196167\n",
      "Epoch 1235/10000: L(Train): 0.2617878317832947; L(Test): 0.2544684410095215\n",
      "Epoch 1236/10000: L(Train): 0.29070210456848145; L(Test): 0.2543511390686035\n",
      "Epoch 1237/10000: L(Train): 0.27143025398254395; L(Test): 0.2541239261627197\n",
      "Epoch 1238/10000: L(Train): 0.26455456018447876; L(Test): 0.25419801473617554\n",
      "Epoch 1239/10000: L(Train): 0.27698469161987305; L(Test): 0.2540172338485718\n",
      "Epoch 1240/10000: L(Train): 0.27285149693489075; L(Test): 0.25339168310165405\n",
      "Epoch 1241/10000: L(Train): 0.2796170711517334; L(Test): 0.254569947719574\n",
      "Epoch 1242/10000: L(Train): 0.2801665961742401; L(Test): 0.25450509786605835\n",
      "Epoch 1243/10000: L(Train): 0.28078851103782654; L(Test): 0.2544618248939514\n",
      "Epoch 1244/10000: L(Train): 0.27563849091529846; L(Test): 0.25501254200935364\n",
      "Epoch 1245/10000: L(Train): 0.2869799733161926; L(Test): 0.2542802691459656\n",
      "Epoch 1246/10000: L(Train): 0.2791498601436615; L(Test): 0.2544066905975342\n",
      "Epoch 1247/10000: L(Train): 0.27397283911705017; L(Test): 0.25512850284576416\n",
      "Epoch 1248/10000: L(Train): 0.27050191164016724; L(Test): 0.25526538491249084\n",
      "Epoch 1249/10000: L(Train): 0.27570974826812744; L(Test): 0.2546714246273041\n",
      "Epoch 1250/10000: L(Train): 0.2835255563259125; L(Test): 0.2555066645145416\n",
      "Epoch 1251/10000: L(Train): 0.2717041075229645; L(Test): 0.2553839683532715\n",
      "Epoch 1252/10000: L(Train): 0.28813695907592773; L(Test): 0.254702091217041\n",
      "Epoch 1253/10000: L(Train): 0.28247207403182983; L(Test): 0.2569664716720581\n",
      "Epoch 1254/10000: L(Train): 0.2688881754875183; L(Test): 0.25835472345352173\n",
      "Epoch 1255/10000: L(Train): 0.2729419469833374; L(Test): 0.25542187690734863\n",
      "Epoch 1256/10000: L(Train): 0.26749342679977417; L(Test): 0.25480228662490845\n",
      "Epoch 1257/10000: L(Train): 0.28039106726646423; L(Test): 0.2555485665798187\n",
      "Epoch 1258/10000: L(Train): 0.2655555009841919; L(Test): 0.25601059198379517\n",
      "Epoch 1259/10000: L(Train): 0.28139588236808777; L(Test): 0.2560180425643921\n",
      "Epoch 1260/10000: L(Train): 0.2849113941192627; L(Test): 0.25684481859207153\n",
      "Epoch 1261/10000: L(Train): 0.2784610986709595; L(Test): 0.2555959224700928\n",
      "Epoch 1262/10000: L(Train): 0.2649117410182953; L(Test): 0.25524136424064636\n",
      "Epoch 1263/10000: L(Train): 0.2717493176460266; L(Test): 0.25486961007118225\n",
      "Epoch 1264/10000: L(Train): 0.2638252377510071; L(Test): 0.2543499171733856\n",
      "Epoch 1265/10000: L(Train): 0.27561020851135254; L(Test): 0.25448980927467346\n",
      "Epoch 1266/10000: L(Train): 0.26472723484039307; L(Test): 0.25484657287597656\n",
      "Epoch 1267/10000: L(Train): 0.2635749876499176; L(Test): 0.2546340525150299\n",
      "Epoch 1268/10000: L(Train): 0.25989872217178345; L(Test): 0.25503459572792053\n",
      "Epoch 1269/10000: L(Train): 0.2693217694759369; L(Test): 0.2540372610092163\n",
      "Epoch 1270/10000: L(Train): 0.27212363481521606; L(Test): 0.254608690738678\n",
      "Epoch 1271/10000: L(Train): 0.27816835045814514; L(Test): 0.25498703122138977\n",
      "Epoch 1272/10000: L(Train): 0.2871687412261963; L(Test): 0.2544214427471161\n",
      "Epoch 1273/10000: L(Train): 0.25903165340423584; L(Test): 0.2555021643638611\n",
      "Epoch 1274/10000: L(Train): 0.285527765750885; L(Test): 0.25396960973739624\n",
      "Epoch 1275/10000: L(Train): 0.2658098638057709; L(Test): 0.25403207540512085\n",
      "Epoch 1276/10000: L(Train): 0.272418349981308; L(Test): 0.25470083951950073\n",
      "Epoch 1277/10000: L(Train): 0.2640145719051361; L(Test): 0.2569628357887268\n",
      "Epoch 1278/10000: L(Train): 0.28253257274627686; L(Test): 0.25699448585510254\n",
      "Epoch 1279/10000: L(Train): 0.2565140724182129; L(Test): 0.25618261098861694\n",
      "Epoch 1280/10000: L(Train): 0.278684139251709; L(Test): 0.25687870383262634\n",
      "Epoch 1281/10000: L(Train): 0.27848020195961; L(Test): 0.2570511996746063\n",
      "Epoch 1282/10000: L(Train): 0.28555336594581604; L(Test): 0.25634291768074036\n",
      "Epoch 1283/10000: L(Train): 0.26508286595344543; L(Test): 0.25546199083328247\n",
      "Epoch 1284/10000: L(Train): 0.271433562040329; L(Test): 0.25643298029899597\n",
      "Epoch 1285/10000: L(Train): 0.2740674614906311; L(Test): 0.25609055161476135\n",
      "Epoch 1286/10000: L(Train): 0.27295318245887756; L(Test): 0.25605079531669617\n",
      "Epoch 1287/10000: L(Train): 0.2886330187320709; L(Test): 0.25600433349609375\n",
      "Epoch 1288/10000: L(Train): 0.26921600103378296; L(Test): 0.2552542984485626\n",
      "Epoch 1289/10000: L(Train): 0.2718217968940735; L(Test): 0.25472491979599\n",
      "Epoch 1290/10000: L(Train): 0.2783888876438141; L(Test): 0.2551453411579132\n",
      "Epoch 1291/10000: L(Train): 0.2797306180000305; L(Test): 0.25483259558677673\n",
      "Epoch 1292/10000: L(Train): 0.28747907280921936; L(Test): 0.25498947501182556\n",
      "Epoch 1293/10000: L(Train): 0.2701507806777954; L(Test): 0.25448083877563477\n",
      "Epoch 1294/10000: L(Train): 0.27942609786987305; L(Test): 0.2547202408313751\n",
      "Epoch 1295/10000: L(Train): 0.28962376713752747; L(Test): 0.2546409070491791\n",
      "Epoch 1296/10000: L(Train): 0.270561546087265; L(Test): 0.2543123662471771\n",
      "Epoch 1297/10000: L(Train): 0.2639545500278473; L(Test): 0.25420114398002625\n",
      "Epoch 1298/10000: L(Train): 0.26528000831604004; L(Test): 0.25470027327537537\n",
      "Epoch 1299/10000: L(Train): 0.26932764053344727; L(Test): 0.25524356961250305\n",
      "Epoch 1300/10000: L(Train): 0.2609214186668396; L(Test): 0.2538815438747406\n",
      "Epoch 1301/10000: L(Train): 0.26849520206451416; L(Test): 0.25443893671035767\n",
      "Epoch 1302/10000: L(Train): 0.27361804246902466; L(Test): 0.2540670931339264\n",
      "Epoch 1303/10000: L(Train): 0.27636218070983887; L(Test): 0.25398632884025574\n",
      "Epoch 1304/10000: L(Train): 0.2740209400653839; L(Test): 0.2540249526500702\n",
      "Epoch 1305/10000: L(Train): 0.28677958250045776; L(Test): 0.25346431136131287\n",
      "Epoch 1306/10000: L(Train): 0.27954211831092834; L(Test): 0.2531614601612091\n",
      "Epoch 1307/10000: L(Train): 0.2767592668533325; L(Test): 0.2528221011161804\n",
      "Epoch 1308/10000: L(Train): 0.2766663730144501; L(Test): 0.2533852756023407\n",
      "Epoch 1309/10000: L(Train): 0.28128835558891296; L(Test): 0.25330808758735657\n",
      "Epoch 1310/10000: L(Train): 0.2846451699733734; L(Test): 0.25319191813468933\n",
      "Epoch 1311/10000: L(Train): 0.27896106243133545; L(Test): 0.25249171257019043\n",
      "Epoch 1312/10000: L(Train): 0.2618207037448883; L(Test): 0.25451257824897766\n",
      "Epoch 1313/10000: L(Train): 0.2666025757789612; L(Test): 0.25351130962371826\n",
      "Epoch 1314/10000: L(Train): 0.29871219396591187; L(Test): 0.2548718750476837\n",
      "Epoch 1315/10000: L(Train): 0.27917933464050293; L(Test): 0.2535703182220459\n",
      "Epoch 1316/10000: L(Train): 0.29126936197280884; L(Test): 0.254602313041687\n",
      "Epoch 1317/10000: L(Train): 0.2654426395893097; L(Test): 0.25465071201324463\n",
      "Epoch 1318/10000: L(Train): 0.27693870663642883; L(Test): 0.2532753348350525\n",
      "Epoch 1319/10000: L(Train): 0.27095645666122437; L(Test): 0.25338631868362427\n",
      "Epoch 1320/10000: L(Train): 0.2776964604854584; L(Test): 0.254177451133728\n",
      "Epoch 1321/10000: L(Train): 0.2690542936325073; L(Test): 0.25467148423194885\n",
      "Epoch 1322/10000: L(Train): 0.25352713465690613; L(Test): 0.2531008720397949\n",
      "Epoch 1323/10000: L(Train): 0.2741490304470062; L(Test): 0.25326111912727356\n",
      "Epoch 1324/10000: L(Train): 0.26882871985435486; L(Test): 0.25360941886901855\n",
      "Epoch 1325/10000: L(Train): 0.2704324424266815; L(Test): 0.2534645199775696\n",
      "Epoch 1326/10000: L(Train): 0.26902589201927185; L(Test): 0.2536117732524872\n",
      "Epoch 1327/10000: L(Train): 0.2708064615726471; L(Test): 0.25282806158065796\n",
      "Epoch 1328/10000: L(Train): 0.273570716381073; L(Test): 0.252820760011673\n",
      "Epoch 1329/10000: L(Train): 0.2752729654312134; L(Test): 0.25418969988822937\n",
      "Epoch 1330/10000: L(Train): 0.27665936946868896; L(Test): 0.2535489797592163\n",
      "Epoch 1331/10000: L(Train): 0.2661733031272888; L(Test): 0.2539873719215393\n",
      "Epoch 1332/10000: L(Train): 0.26912376284599304; L(Test): 0.2527446746826172\n",
      "Epoch 1333/10000: L(Train): 0.26903781294822693; L(Test): 0.2533738613128662\n",
      "Epoch 1334/10000: L(Train): 0.2855326533317566; L(Test): 0.2526596486568451\n",
      "Epoch 1335/10000: L(Train): 0.261698842048645; L(Test): 0.2526496946811676\n",
      "Epoch 1336/10000: L(Train): 0.2934153974056244; L(Test): 0.2538236081600189\n",
      "Epoch 1337/10000: L(Train): 0.26836809515953064; L(Test): 0.25296229124069214\n",
      "Epoch 1338/10000: L(Train): 0.26541516184806824; L(Test): 0.2534452974796295\n",
      "Epoch 1339/10000: L(Train): 0.26754677295684814; L(Test): 0.25377994775772095\n",
      "Epoch 1340/10000: L(Train): 0.27192026376724243; L(Test): 0.25395774841308594\n",
      "Epoch 1341/10000: L(Train): 0.27763673663139343; L(Test): 0.25467243790626526\n",
      "Epoch 1342/10000: L(Train): 0.27481916546821594; L(Test): 0.2533981204032898\n",
      "Epoch 1343/10000: L(Train): 0.28059765696525574; L(Test): 0.2534061372280121\n",
      "Epoch 1344/10000: L(Train): 0.27174612879753113; L(Test): 0.25362545251846313\n",
      "Epoch 1345/10000: L(Train): 0.2643122971057892; L(Test): 0.2537754476070404\n",
      "Epoch 1346/10000: L(Train): 0.27721983194351196; L(Test): 0.2535631060600281\n",
      "Epoch 1347/10000: L(Train): 0.2667270004749298; L(Test): 0.25342845916748047\n",
      "Epoch 1348/10000: L(Train): 0.27872878313064575; L(Test): 0.25299692153930664\n",
      "Epoch 1349/10000: L(Train): 0.26810893416404724; L(Test): 0.2539970576763153\n",
      "Epoch 1350/10000: L(Train): 0.2743595838546753; L(Test): 0.253728985786438\n",
      "Epoch 1351/10000: L(Train): 0.2648032605648041; L(Test): 0.25260382890701294\n",
      "Epoch 1352/10000: L(Train): 0.2621029317378998; L(Test): 0.25345003604888916\n",
      "Epoch 1353/10000: L(Train): 0.2772866189479828; L(Test): 0.2532117962837219\n",
      "Epoch 1354/10000: L(Train): 0.2736528515815735; L(Test): 0.2534129023551941\n",
      "Epoch 1355/10000: L(Train): 0.27407190203666687; L(Test): 0.2531426250934601\n",
      "Epoch 1356/10000: L(Train): 0.2760969400405884; L(Test): 0.25260689854621887\n",
      "Epoch 1357/10000: L(Train): 0.26886868476867676; L(Test): 0.2530997395515442\n",
      "Epoch 1358/10000: L(Train): 0.2670604884624481; L(Test): 0.2525022029876709\n",
      "Epoch 1359/10000: L(Train): 0.27750495076179504; L(Test): 0.25259527564048767\n",
      "Epoch 1360/10000: L(Train): 0.2755904793739319; L(Test): 0.2526637315750122\n",
      "Epoch 1361/10000: L(Train): 0.26972299814224243; L(Test): 0.2531604766845703\n",
      "Epoch 1362/10000: L(Train): 0.28045016527175903; L(Test): 0.25327208638191223\n",
      "Epoch 1363/10000: L(Train): 0.2743218243122101; L(Test): 0.2517766058444977\n",
      "Epoch 1364/10000: L(Train): 0.255197137594223; L(Test): 0.25191032886505127\n",
      "Epoch 1365/10000: L(Train): 0.25517380237579346; L(Test): 0.25240567326545715\n",
      "Epoch 1366/10000: L(Train): 0.29217275977134705; L(Test): 0.2520979940891266\n",
      "Epoch 1367/10000: L(Train): 0.27898648381233215; L(Test): 0.25263169407844543\n",
      "Epoch 1368/10000: L(Train): 0.27285265922546387; L(Test): 0.2527720630168915\n",
      "Epoch 1369/10000: L(Train): 0.27343064546585083; L(Test): 0.2531309425830841\n",
      "Epoch 1370/10000: L(Train): 0.27454283833503723; L(Test): 0.2532988488674164\n",
      "Epoch 1371/10000: L(Train): 0.27325010299682617; L(Test): 0.25325459241867065\n",
      "Epoch 1372/10000: L(Train): 0.25671279430389404; L(Test): 0.25310999155044556\n",
      "Epoch 1373/10000: L(Train): 0.2652105987071991; L(Test): 0.2528184950351715\n",
      "Epoch 1374/10000: L(Train): 0.28118976950645447; L(Test): 0.2526405453681946\n",
      "Epoch 1375/10000: L(Train): 0.27113884687423706; L(Test): 0.25180354714393616\n",
      "Epoch 1376/10000: L(Train): 0.28651782870292664; L(Test): 0.2527221441268921\n",
      "Epoch 1377/10000: L(Train): 0.27919191122055054; L(Test): 0.252979040145874\n",
      "Epoch 1378/10000: L(Train): 0.26102331280708313; L(Test): 0.25180551409721375\n",
      "Epoch 1379/10000: L(Train): 0.28922054171562195; L(Test): 0.2525519132614136\n",
      "Epoch 1380/10000: L(Train): 0.29043829441070557; L(Test): 0.2522517442703247\n",
      "Epoch 1381/10000: L(Train): 0.276595801115036; L(Test): 0.2523280084133148\n",
      "Epoch 1382/10000: L(Train): 0.26337701082229614; L(Test): 0.2536107301712036\n",
      "Epoch 1383/10000: L(Train): 0.2657950222492218; L(Test): 0.25347453355789185\n",
      "Epoch 1384/10000: L(Train): 0.2658332288265228; L(Test): 0.2526472508907318\n",
      "Epoch 1385/10000: L(Train): 0.26732850074768066; L(Test): 0.25345128774642944\n",
      "Epoch 1386/10000: L(Train): 0.27495086193084717; L(Test): 0.2531787157058716\n",
      "Epoch 1387/10000: L(Train): 0.2654302418231964; L(Test): 0.25274956226348877\n",
      "Epoch 1388/10000: L(Train): 0.2705787420272827; L(Test): 0.25249749422073364\n",
      "Epoch 1389/10000: L(Train): 0.27102500200271606; L(Test): 0.2519393265247345\n",
      "Epoch 1390/10000: L(Train): 0.26434311270713806; L(Test): 0.25183337926864624\n",
      "Epoch 1391/10000: L(Train): 0.2662951648235321; L(Test): 0.2523072361946106\n",
      "Epoch 1392/10000: L(Train): 0.26387813687324524; L(Test): 0.25235164165496826\n",
      "Epoch 1393/10000: L(Train): 0.2818169593811035; L(Test): 0.252197802066803\n",
      "Epoch 1394/10000: L(Train): 0.2564357817173004; L(Test): 0.2518913149833679\n",
      "Epoch 1395/10000: L(Train): 0.26371562480926514; L(Test): 0.2519192397594452\n",
      "Epoch 1396/10000: L(Train): 0.2659823000431061; L(Test): 0.2517741322517395\n",
      "Epoch 1397/10000: L(Train): 0.2647521495819092; L(Test): 0.25154635310173035\n",
      "Epoch 1398/10000: L(Train): 0.28262701630592346; L(Test): 0.2515004873275757\n",
      "Epoch 1399/10000: L(Train): 0.2640056908130646; L(Test): 0.25197142362594604\n",
      "Epoch 1400/10000: L(Train): 0.26757046580314636; L(Test): 0.2516126334667206\n",
      "Epoch 1401/10000: L(Train): 0.26890358328819275; L(Test): 0.2518153786659241\n",
      "Epoch 1402/10000: L(Train): 0.26315051317214966; L(Test): 0.2519163191318512\n",
      "Epoch 1403/10000: L(Train): 0.2561609447002411; L(Test): 0.2520957291126251\n",
      "Epoch 1404/10000: L(Train): 0.2775489389896393; L(Test): 0.2515135705471039\n",
      "Epoch 1405/10000: L(Train): 0.27103933691978455; L(Test): 0.2511085569858551\n",
      "Epoch 1406/10000: L(Train): 0.2710249423980713; L(Test): 0.2512156665325165\n",
      "Epoch 1407/10000: L(Train): 0.27077436447143555; L(Test): 0.2516501247882843\n",
      "Epoch 1408/10000: L(Train): 0.2541142404079437; L(Test): 0.25172966718673706\n",
      "Epoch 1409/10000: L(Train): 0.2734798192977905; L(Test): 0.25163066387176514\n",
      "Epoch 1410/10000: L(Train): 0.27286452054977417; L(Test): 0.2509914040565491\n",
      "Epoch 1411/10000: L(Train): 0.2654396593570709; L(Test): 0.2528926432132721\n",
      "Epoch 1412/10000: L(Train): 0.2688588798046112; L(Test): 0.2534809112548828\n",
      "Epoch 1413/10000: L(Train): 0.255688339471817; L(Test): 0.2543426752090454\n",
      "Epoch 1414/10000: L(Train): 0.2773299515247345; L(Test): 0.2528523802757263\n",
      "Epoch 1415/10000: L(Train): 0.2665110230445862; L(Test): 0.25441813468933105\n",
      "Epoch 1416/10000: L(Train): 0.2607141435146332; L(Test): 0.25361713767051697\n",
      "Epoch 1417/10000: L(Train): 0.2825283408164978; L(Test): 0.25243037939071655\n",
      "Epoch 1418/10000: L(Train): 0.28775039315223694; L(Test): 0.2511632442474365\n",
      "Epoch 1419/10000: L(Train): 0.2669872045516968; L(Test): 0.25280705094337463\n",
      "Epoch 1420/10000: L(Train): 0.26888835430145264; L(Test): 0.25223860144615173\n",
      "Epoch 1421/10000: L(Train): 0.2642122507095337; L(Test): 0.25300464034080505\n",
      "Epoch 1422/10000: L(Train): 0.2693847715854645; L(Test): 0.25384876132011414\n",
      "Epoch 1423/10000: L(Train): 0.28179940581321716; L(Test): 0.25196394324302673\n",
      "Epoch 1424/10000: L(Train): 0.26901495456695557; L(Test): 0.2526492476463318\n",
      "Epoch 1425/10000: L(Train): 0.28038719296455383; L(Test): 0.25210022926330566\n",
      "Epoch 1426/10000: L(Train): 0.2717360258102417; L(Test): 0.25201931595802307\n",
      "Epoch 1427/10000: L(Train): 0.2819744646549225; L(Test): 0.2520659565925598\n",
      "Epoch 1428/10000: L(Train): 0.2743392884731293; L(Test): 0.2525392770767212\n",
      "Epoch 1429/10000: L(Train): 0.2913306951522827; L(Test): 0.2522996664047241\n",
      "Epoch 1430/10000: L(Train): 0.2716878056526184; L(Test): 0.25278207659721375\n",
      "Epoch 1431/10000: L(Train): 0.2781234681606293; L(Test): 0.2520245313644409\n",
      "Epoch 1432/10000: L(Train): 0.2727857530117035; L(Test): 0.2524513602256775\n",
      "Epoch 1433/10000: L(Train): 0.2647511661052704; L(Test): 0.2523801922798157\n",
      "Epoch 1434/10000: L(Train): 0.2667953372001648; L(Test): 0.2514570355415344\n",
      "Epoch 1435/10000: L(Train): 0.26394739747047424; L(Test): 0.2513788044452667\n",
      "Epoch 1436/10000: L(Train): 0.264452189207077; L(Test): 0.252301424741745\n",
      "Epoch 1437/10000: L(Train): 0.27951526641845703; L(Test): 0.25263655185699463\n",
      "Epoch 1438/10000: L(Train): 0.26073965430259705; L(Test): 0.2524227201938629\n",
      "Epoch 1439/10000: L(Train): 0.2805582284927368; L(Test): 0.25254958868026733\n",
      "Epoch 1440/10000: L(Train): 0.2625897228717804; L(Test): 0.2540697753429413\n",
      "Epoch 1441/10000: L(Train): 0.27373695373535156; L(Test): 0.25364336371421814\n",
      "Epoch 1442/10000: L(Train): 0.2896901071071625; L(Test): 0.25171199440956116\n",
      "Epoch 1443/10000: L(Train): 0.2627224028110504; L(Test): 0.2545274794101715\n",
      "Epoch 1444/10000: L(Train): 0.2734426259994507; L(Test): 0.2531791925430298\n",
      "Epoch 1445/10000: L(Train): 0.2699185907840729; L(Test): 0.2548530399799347\n",
      "Epoch 1446/10000: L(Train): 0.2736314535140991; L(Test): 0.25261232256889343\n",
      "Epoch 1447/10000: L(Train): 0.27076008915901184; L(Test): 0.2535872459411621\n",
      "Epoch 1448/10000: L(Train): 0.28013163805007935; L(Test): 0.2519219219684601\n",
      "Epoch 1449/10000: L(Train): 0.28715839982032776; L(Test): 0.25229132175445557\n",
      "Epoch 1450/10000: L(Train): 0.2776761054992676; L(Test): 0.2529098391532898\n",
      "Epoch 1451/10000: L(Train): 0.27185893058776855; L(Test): 0.25302088260650635\n",
      "Epoch 1452/10000: L(Train): 0.26206421852111816; L(Test): 0.25161004066467285\n",
      "Epoch 1453/10000: L(Train): 0.2675454020500183; L(Test): 0.25367051362991333\n",
      "Epoch 1454/10000: L(Train): 0.27968496084213257; L(Test): 0.2528438866138458\n",
      "Epoch 1455/10000: L(Train): 0.2663271725177765; L(Test): 0.25187748670578003\n",
      "Epoch 1456/10000: L(Train): 0.26543888449668884; L(Test): 0.25095197558403015\n",
      "Epoch 1457/10000: L(Train): 0.2681404650211334; L(Test): 0.2519601285457611\n",
      "Epoch 1458/10000: L(Train): 0.27578115463256836; L(Test): 0.25162413716316223\n",
      "Epoch 1459/10000: L(Train): 0.2755524814128876; L(Test): 0.2515203058719635\n",
      "Epoch 1460/10000: L(Train): 0.26998239755630493; L(Test): 0.2525784373283386\n",
      "Epoch 1461/10000: L(Train): 0.2692406475543976; L(Test): 0.251874715089798\n",
      "Epoch 1462/10000: L(Train): 0.2825450897216797; L(Test): 0.2508884072303772\n",
      "Epoch 1463/10000: L(Train): 0.2695052921772003; L(Test): 0.25088876485824585\n",
      "Epoch 1464/10000: L(Train): 0.2579216957092285; L(Test): 0.25063616037368774\n",
      "Epoch 1465/10000: L(Train): 0.28061580657958984; L(Test): 0.250542551279068\n",
      "Epoch 1466/10000: L(Train): 0.2675778865814209; L(Test): 0.25074803829193115\n",
      "Epoch 1467/10000: L(Train): 0.2789784371852875; L(Test): 0.2509385347366333\n",
      "Epoch 1468/10000: L(Train): 0.2790329158306122; L(Test): 0.2513580024242401\n",
      "Epoch 1469/10000: L(Train): 0.2749471068382263; L(Test): 0.2506086528301239\n",
      "Epoch 1470/10000: L(Train): 0.2689792215824127; L(Test): 0.2510155439376831\n",
      "Epoch 1471/10000: L(Train): 0.27106431126594543; L(Test): 0.25074440240859985\n",
      "Epoch 1472/10000: L(Train): 0.26274970173835754; L(Test): 0.249884694814682\n",
      "Epoch 1473/10000: L(Train): 0.2670983076095581; L(Test): 0.25045686960220337\n",
      "Epoch 1474/10000: L(Train): 0.26474419236183167; L(Test): 0.25078657269477844\n",
      "Epoch 1475/10000: L(Train): 0.2931486666202545; L(Test): 0.24986504018306732\n",
      "Epoch 1476/10000: L(Train): 0.28589317202568054; L(Test): 0.25080734491348267\n",
      "Epoch 1477/10000: L(Train): 0.26730161905288696; L(Test): 0.2526305019855499\n",
      "Epoch 1478/10000: L(Train): 0.27900341153144836; L(Test): 0.25262224674224854\n",
      "Epoch 1479/10000: L(Train): 0.2655171751976013; L(Test): 0.25199148058891296\n",
      "Epoch 1480/10000: L(Train): 0.2663729786872864; L(Test): 0.25370848178863525\n",
      "Epoch 1481/10000: L(Train): 0.26036033034324646; L(Test): 0.25296488404273987\n",
      "Epoch 1482/10000: L(Train): 0.28026485443115234; L(Test): 0.2522798478603363\n",
      "Epoch 1483/10000: L(Train): 0.2808969020843506; L(Test): 0.2523430287837982\n",
      "Epoch 1484/10000: L(Train): 0.26279184222221375; L(Test): 0.25280916690826416\n",
      "Epoch 1485/10000: L(Train): 0.2757611572742462; L(Test): 0.2532083988189697\n",
      "Epoch 1486/10000: L(Train): 0.267132043838501; L(Test): 0.25374194979667664\n",
      "Epoch 1487/10000: L(Train): 0.2857699990272522; L(Test): 0.2532481551170349\n",
      "Epoch 1488/10000: L(Train): 0.2707604467868805; L(Test): 0.25367501378059387\n",
      "Epoch 1489/10000: L(Train): 0.2629750370979309; L(Test): 0.2545541226863861\n",
      "Epoch 1490/10000: L(Train): 0.26514244079589844; L(Test): 0.2531135678291321\n",
      "Epoch 1491/10000: L(Train): 0.2609909176826477; L(Test): 0.25313201546669006\n",
      "Epoch 1492/10000: L(Train): 0.2722749412059784; L(Test): 0.25318673253059387\n",
      "Epoch 1493/10000: L(Train): 0.26121148467063904; L(Test): 0.2534632980823517\n",
      "Epoch 1494/10000: L(Train): 0.2699667811393738; L(Test): 0.25293564796447754\n",
      "Epoch 1495/10000: L(Train): 0.2715035378932953; L(Test): 0.25391069054603577\n",
      "Epoch 1496/10000: L(Train): 0.27872347831726074; L(Test): 0.25308671593666077\n",
      "Epoch 1497/10000: L(Train): 0.26998063921928406; L(Test): 0.2521889805793762\n",
      "Epoch 1498/10000: L(Train): 0.2813740670681; L(Test): 0.25164926052093506\n",
      "Epoch 1499/10000: L(Train): 0.28055256605148315; L(Test): 0.2523006796836853\n",
      "Epoch 1500/10000: L(Train): 0.2812739312648773; L(Test): 0.25195807218551636\n",
      "Epoch 1501/10000: L(Train): 0.2809865176677704; L(Test): 0.253994882106781\n",
      "Epoch 1502/10000: L(Train): 0.2806262671947479; L(Test): 0.2540889084339142\n",
      "Epoch 1503/10000: L(Train): 0.26954877376556396; L(Test): 0.252032995223999\n",
      "Epoch 1504/10000: L(Train): 0.27749204635620117; L(Test): 0.2525307834148407\n",
      "Epoch 1505/10000: L(Train): 0.28310543298721313; L(Test): 0.2529279291629791\n",
      "Epoch 1506/10000: L(Train): 0.2822551429271698; L(Test): 0.25265368819236755\n",
      "Epoch 1507/10000: L(Train): 0.2695690393447876; L(Test): 0.2519649267196655\n",
      "Epoch 1508/10000: L(Train): 0.2747097611427307; L(Test): 0.2528782784938812\n",
      "Epoch 1509/10000: L(Train): 0.27391132712364197; L(Test): 0.25326961278915405\n",
      "Epoch 1510/10000: L(Train): 0.2826046645641327; L(Test): 0.25153210759162903\n",
      "Epoch 1511/10000: L(Train): 0.2673209011554718; L(Test): 0.25204628705978394\n",
      "Epoch 1512/10000: L(Train): 0.2685789167881012; L(Test): 0.2518962025642395\n",
      "Epoch 1513/10000: L(Train): 0.26764991879463196; L(Test): 0.25203531980514526\n",
      "Epoch 1514/10000: L(Train): 0.2738540470600128; L(Test): 0.25218647718429565\n",
      "Epoch 1515/10000: L(Train): 0.2690947949886322; L(Test): 0.2526237368583679\n",
      "Epoch 1516/10000: L(Train): 0.27438730001449585; L(Test): 0.2527676522731781\n",
      "Epoch 1517/10000: L(Train): 0.2675672471523285; L(Test): 0.2533687949180603\n",
      "Epoch 1518/10000: L(Train): 0.2758588492870331; L(Test): 0.25345906615257263\n",
      "Epoch 1519/10000: L(Train): 0.28341910243034363; L(Test): 0.25185340642929077\n",
      "Epoch 1520/10000: L(Train): 0.2638920843601227; L(Test): 0.2521044909954071\n",
      "Epoch 1521/10000: L(Train): 0.26428765058517456; L(Test): 0.2524920701980591\n",
      "Epoch 1522/10000: L(Train): 0.2636071443557739; L(Test): 0.2523801326751709\n",
      "Epoch 1523/10000: L(Train): 0.26123544573783875; L(Test): 0.25260287523269653\n",
      "Epoch 1524/10000: L(Train): 0.288019061088562; L(Test): 0.25362104177474976\n",
      "Epoch 1525/10000: L(Train): 0.2684871256351471; L(Test): 0.25431039929389954\n",
      "Epoch 1526/10000: L(Train): 0.2635035812854767; L(Test): 0.2532777190208435\n",
      "Epoch 1527/10000: L(Train): 0.269085168838501; L(Test): 0.25196927785873413\n",
      "Epoch 1528/10000: L(Train): 0.2642243206501007; L(Test): 0.2530275285243988\n",
      "Epoch 1529/10000: L(Train): 0.27703696489334106; L(Test): 0.2524219751358032\n",
      "Epoch 1530/10000: L(Train): 0.2685173451900482; L(Test): 0.25383856892585754\n",
      "Epoch 1531/10000: L(Train): 0.2663955092430115; L(Test): 0.2541641592979431\n",
      "Epoch 1532/10000: L(Train): 0.26847031712532043; L(Test): 0.2515902817249298\n",
      "Epoch 1533/10000: L(Train): 0.27975592017173767; L(Test): 0.2525051236152649\n",
      "Epoch 1534/10000: L(Train): 0.2778978645801544; L(Test): 0.2531917989253998\n",
      "Epoch 1535/10000: L(Train): 0.2709229290485382; L(Test): 0.25427767634391785\n",
      "Epoch 1536/10000: L(Train): 0.2693224847316742; L(Test): 0.25257495045661926\n",
      "Epoch 1537/10000: L(Train): 0.2876487374305725; L(Test): 0.2527329921722412\n",
      "Epoch 1538/10000: L(Train): 0.2701546251773834; L(Test): 0.2518751919269562\n",
      "Epoch 1539/10000: L(Train): 0.26770901679992676; L(Test): 0.2521907687187195\n",
      "Epoch 1540/10000: L(Train): 0.2610794007778168; L(Test): 0.2514498233795166\n",
      "Epoch 1541/10000: L(Train): 0.26763415336608887; L(Test): 0.25050291419029236\n",
      "Epoch 1542/10000: L(Train): 0.272394061088562; L(Test): 0.2514612674713135\n",
      "Epoch 1543/10000: L(Train): 0.2897111177444458; L(Test): 0.2508802115917206\n",
      "Epoch 1544/10000: L(Train): 0.27213823795318604; L(Test): 0.25171226263046265\n",
      "Epoch 1545/10000: L(Train): 0.2688267230987549; L(Test): 0.2503441572189331\n",
      "Epoch 1546/10000: L(Train): 0.2834620475769043; L(Test): 0.25077489018440247\n",
      "Epoch 1547/10000: L(Train): 0.26649919152259827; L(Test): 0.2508687376976013\n",
      "Epoch 1548/10000: L(Train): 0.2771260738372803; L(Test): 0.25124120712280273\n",
      "Epoch 1549/10000: L(Train): 0.2658998370170593; L(Test): 0.25050708651542664\n",
      "Epoch 1550/10000: L(Train): 0.2834697365760803; L(Test): 0.25011420249938965\n",
      "Epoch 1551/10000: L(Train): 0.27653151750564575; L(Test): 0.25024452805519104\n",
      "Epoch 1552/10000: L(Train): 0.2677674889564514; L(Test): 0.25056469440460205\n",
      "Epoch 1553/10000: L(Train): 0.2792099714279175; L(Test): 0.25056540966033936\n",
      "Epoch 1554/10000: L(Train): 0.26547056436538696; L(Test): 0.2516193985939026\n",
      "Epoch 1555/10000: L(Train): 0.26366207003593445; L(Test): 0.2507573068141937\n",
      "Epoch 1556/10000: L(Train): 0.271180659532547; L(Test): 0.2517198920249939\n",
      "Epoch 1557/10000: L(Train): 0.2651613652706146; L(Test): 0.2518196702003479\n",
      "Epoch 1558/10000: L(Train): 0.2773735821247101; L(Test): 0.2518719732761383\n",
      "Epoch 1559/10000: L(Train): 0.25254151225090027; L(Test): 0.2520909011363983\n",
      "Epoch 1560/10000: L(Train): 0.27306097745895386; L(Test): 0.25007981061935425\n",
      "Epoch 1561/10000: L(Train): 0.2654401361942291; L(Test): 0.25098446011543274\n",
      "Epoch 1562/10000: L(Train): 0.2705880105495453; L(Test): 0.2508670687675476\n",
      "Epoch 1563/10000: L(Train): 0.27774569392204285; L(Test): 0.25187546014785767\n",
      "Epoch 1564/10000: L(Train): 0.27066218852996826; L(Test): 0.25267478823661804\n",
      "Epoch 1565/10000: L(Train): 0.2780301570892334; L(Test): 0.25076669454574585\n",
      "Epoch 1566/10000: L(Train): 0.267886221408844; L(Test): 0.2516874372959137\n",
      "Epoch 1567/10000: L(Train): 0.27047044038772583; L(Test): 0.2513978183269501\n",
      "Epoch 1568/10000: L(Train): 0.2726111114025116; L(Test): 0.2503672242164612\n",
      "Epoch 1569/10000: L(Train): 0.2709003984928131; L(Test): 0.2503179609775543\n",
      "Epoch 1570/10000: L(Train): 0.2700809836387634; L(Test): 0.2503352761268616\n",
      "Epoch 1571/10000: L(Train): 0.26188763976097107; L(Test): 0.25055521726608276\n",
      "Epoch 1572/10000: L(Train): 0.2663402557373047; L(Test): 0.24996353685855865\n",
      "Epoch 1573/10000: L(Train): 0.27140703797340393; L(Test): 0.24939313530921936\n",
      "Epoch 1574/10000: L(Train): 0.2519553005695343; L(Test): 0.25011324882507324\n",
      "Epoch 1575/10000: L(Train): 0.2759813368320465; L(Test): 0.24929657578468323\n",
      "Epoch 1576/10000: L(Train): 0.26594939827919006; L(Test): 0.24870005249977112\n",
      "Epoch 1577/10000: L(Train): 0.2631280720233917; L(Test): 0.24892574548721313\n",
      "Epoch 1578/10000: L(Train): 0.2748463451862335; L(Test): 0.25326815247535706\n",
      "Epoch 1579/10000: L(Train): 0.2607536315917969; L(Test): 0.2523428797721863\n",
      "Epoch 1580/10000: L(Train): 0.279891699552536; L(Test): 0.25392845273017883\n",
      "Epoch 1581/10000: L(Train): 0.2682568430900574; L(Test): 0.2514049708843231\n",
      "Epoch 1582/10000: L(Train): 0.2748000919818878; L(Test): 0.2541358470916748\n",
      "Epoch 1583/10000: L(Train): 0.28078562021255493; L(Test): 0.2531101405620575\n",
      "Epoch 1584/10000: L(Train): 0.26805388927459717; L(Test): 0.2538282871246338\n",
      "Epoch 1585/10000: L(Train): 0.2773974537849426; L(Test): 0.254445344209671\n",
      "Epoch 1586/10000: L(Train): 0.2844541072845459; L(Test): 0.25367021560668945\n",
      "Epoch 1587/10000: L(Train): 0.2805970013141632; L(Test): 0.2540101408958435\n",
      "Epoch 1588/10000: L(Train): 0.2654916048049927; L(Test): 0.25166094303131104\n",
      "Epoch 1589/10000: L(Train): 0.26403942704200745; L(Test): 0.2521202266216278\n",
      "Epoch 1590/10000: L(Train): 0.25857090950012207; L(Test): 0.2514311969280243\n",
      "Epoch 1591/10000: L(Train): 0.2690757215023041; L(Test): 0.2549568712711334\n",
      "Epoch 1592/10000: L(Train): 0.2712911069393158; L(Test): 0.2534056603908539\n",
      "Epoch 1593/10000: L(Train): 0.27094611525535583; L(Test): 0.2517339885234833\n",
      "Epoch 1594/10000: L(Train): 0.2798251211643219; L(Test): 0.25148969888687134\n",
      "Epoch 1595/10000: L(Train): 0.2805006504058838; L(Test): 0.2521839439868927\n",
      "Epoch 1596/10000: L(Train): 0.26401984691619873; L(Test): 0.2529366612434387\n",
      "Epoch 1597/10000: L(Train): 0.27616268396377563; L(Test): 0.25147566199302673\n",
      "Epoch 1598/10000: L(Train): 0.269086629152298; L(Test): 0.2529769837856293\n",
      "Epoch 1599/10000: L(Train): 0.2693556547164917; L(Test): 0.2518264353275299\n",
      "Epoch 1600/10000: L(Train): 0.2757808566093445; L(Test): 0.25221067667007446\n",
      "Epoch 1601/10000: L(Train): 0.26729458570480347; L(Test): 0.2522522509098053\n",
      "Epoch 1602/10000: L(Train): 0.26788783073425293; L(Test): 0.2515178918838501\n",
      "Epoch 1603/10000: L(Train): 0.26477399468421936; L(Test): 0.25121423602104187\n",
      "Epoch 1604/10000: L(Train): 0.2710757255554199; L(Test): 0.2516503632068634\n",
      "Epoch 1605/10000: L(Train): 0.2704851031303406; L(Test): 0.2508777976036072\n",
      "Epoch 1606/10000: L(Train): 0.2611466646194458; L(Test): 0.25069117546081543\n",
      "Epoch 1607/10000: L(Train): 0.2726464867591858; L(Test): 0.2504969537258148\n",
      "Epoch 1608/10000: L(Train): 0.2620500922203064; L(Test): 0.2517623007297516\n",
      "Epoch 1609/10000: L(Train): 0.27167418599128723; L(Test): 0.25159722566604614\n",
      "Epoch 1610/10000: L(Train): 0.2867833375930786; L(Test): 0.24988381564617157\n",
      "Epoch 1611/10000: L(Train): 0.2843276262283325; L(Test): 0.25079086422920227\n",
      "Epoch 1612/10000: L(Train): 0.2562013268470764; L(Test): 0.2506924867630005\n",
      "Epoch 1613/10000: L(Train): 0.25653740763664246; L(Test): 0.2512669265270233\n",
      "Epoch 1614/10000: L(Train): 0.2803298234939575; L(Test): 0.25068172812461853\n",
      "Epoch 1615/10000: L(Train): 0.2512987554073334; L(Test): 0.251238077878952\n",
      "Epoch 1616/10000: L(Train): 0.25940585136413574; L(Test): 0.2508246600627899\n",
      "Epoch 1617/10000: L(Train): 0.27562350034713745; L(Test): 0.25050678849220276\n",
      "Epoch 1618/10000: L(Train): 0.267586886882782; L(Test): 0.2508564591407776\n",
      "Epoch 1619/10000: L(Train): 0.27980539202690125; L(Test): 0.25022563338279724\n",
      "Epoch 1620/10000: L(Train): 0.26492777466773987; L(Test): 0.2511674761772156\n",
      "Epoch 1621/10000: L(Train): 0.26914215087890625; L(Test): 0.2501576840877533\n",
      "Epoch 1622/10000: L(Train): 0.25854846835136414; L(Test): 0.2512938380241394\n",
      "Epoch 1623/10000: L(Train): 0.2664594054222107; L(Test): 0.2507929801940918\n",
      "Epoch 1624/10000: L(Train): 0.2614912986755371; L(Test): 0.25196200609207153\n",
      "Epoch 1625/10000: L(Train): 0.26552146673202515; L(Test): 0.2511384189128876\n",
      "Epoch 1626/10000: L(Train): 0.2887333631515503; L(Test): 0.251164048910141\n",
      "Epoch 1627/10000: L(Train): 0.26082831621170044; L(Test): 0.2538571357727051\n",
      "Epoch 1628/10000: L(Train): 0.27889201045036316; L(Test): 0.2510329782962799\n",
      "Epoch 1629/10000: L(Train): 0.2675739824771881; L(Test): 0.25160789489746094\n",
      "Epoch 1630/10000: L(Train): 0.29309090971946716; L(Test): 0.2502772808074951\n",
      "Epoch 1631/10000: L(Train): 0.26413413882255554; L(Test): 0.2509622871875763\n",
      "Epoch 1632/10000: L(Train): 0.27886253595352173; L(Test): 0.251186341047287\n",
      "Epoch 1633/10000: L(Train): 0.27573516964912415; L(Test): 0.24998997151851654\n",
      "Epoch 1634/10000: L(Train): 0.2801630198955536; L(Test): 0.2516438663005829\n",
      "Epoch 1635/10000: L(Train): 0.2584652304649353; L(Test): 0.25021079182624817\n",
      "Epoch 1636/10000: L(Train): 0.25120672583580017; L(Test): 0.2499024122953415\n",
      "Epoch 1637/10000: L(Train): 0.2674558758735657; L(Test): 0.24967126548290253\n",
      "Epoch 1638/10000: L(Train): 0.27595704793930054; L(Test): 0.24923045933246613\n",
      "Epoch 1639/10000: L(Train): 0.2616843283176422; L(Test): 0.24950891733169556\n",
      "Epoch 1640/10000: L(Train): 0.25542956590652466; L(Test): 0.249652698636055\n",
      "Epoch 1641/10000: L(Train): 0.27430015802383423; L(Test): 0.24979716539382935\n",
      "Epoch 1642/10000: L(Train): 0.2819018065929413; L(Test): 0.25001221895217896\n",
      "Epoch 1643/10000: L(Train): 0.25182294845581055; L(Test): 0.24998672306537628\n",
      "Epoch 1644/10000: L(Train): 0.2747359573841095; L(Test): 0.2496681809425354\n",
      "Epoch 1645/10000: L(Train): 0.2574596703052521; L(Test): 0.2494598627090454\n",
      "Epoch 1646/10000: L(Train): 0.2583804726600647; L(Test): 0.24919258058071136\n",
      "Epoch 1647/10000: L(Train): 0.27620112895965576; L(Test): 0.24870602786540985\n",
      "Epoch 1648/10000: L(Train): 0.2594439387321472; L(Test): 0.2503527104854584\n",
      "Epoch 1649/10000: L(Train): 0.2741020619869232; L(Test): 0.24980053305625916\n",
      "Epoch 1650/10000: L(Train): 0.26615288853645325; L(Test): 0.2501121461391449\n",
      "Epoch 1651/10000: L(Train): 0.27373555302619934; L(Test): 0.24914121627807617\n",
      "Epoch 1652/10000: L(Train): 0.25741058588027954; L(Test): 0.24875247478485107\n",
      "Epoch 1653/10000: L(Train): 0.25727277994155884; L(Test): 0.24956828355789185\n",
      "Epoch 1654/10000: L(Train): 0.2671591341495514; L(Test): 0.24957126379013062\n",
      "Epoch 1655/10000: L(Train): 0.2852799594402313; L(Test): 0.24940970540046692\n",
      "Epoch 1656/10000: L(Train): 0.26519444584846497; L(Test): 0.24957357347011566\n",
      "Epoch 1657/10000: L(Train): 0.2624199092388153; L(Test): 0.24883967638015747\n",
      "Epoch 1658/10000: L(Train): 0.2547638714313507; L(Test): 0.2498948872089386\n",
      "Epoch 1659/10000: L(Train): 0.27324703335762024; L(Test): 0.24945978820323944\n",
      "Epoch 1660/10000: L(Train): 0.25773850083351135; L(Test): 0.25016963481903076\n",
      "Epoch 1661/10000: L(Train): 0.27432405948638916; L(Test): 0.24980227649211884\n",
      "Epoch 1662/10000: L(Train): 0.26047956943511963; L(Test): 0.250986784696579\n",
      "Epoch 1663/10000: L(Train): 0.2540750205516815; L(Test): 0.25079718232154846\n",
      "Epoch 1664/10000: L(Train): 0.25081637501716614; L(Test): 0.2510541081428528\n",
      "Epoch 1665/10000: L(Train): 0.26982617378234863; L(Test): 0.25023993849754333\n",
      "Epoch 1666/10000: L(Train): 0.2652336657047272; L(Test): 0.2494807243347168\n",
      "Epoch 1667/10000: L(Train): 0.27102231979370117; L(Test): 0.2515363097190857\n",
      "Epoch 1668/10000: L(Train): 0.2723398208618164; L(Test): 0.25041934847831726\n",
      "Epoch 1669/10000: L(Train): 0.27675771713256836; L(Test): 0.2501055896282196\n",
      "Epoch 1670/10000: L(Train): 0.27360230684280396; L(Test): 0.2510560154914856\n",
      "Epoch 1671/10000: L(Train): 0.2651767134666443; L(Test): 0.2521663308143616\n",
      "Epoch 1672/10000: L(Train): 0.2676713764667511; L(Test): 0.25305065512657166\n",
      "Epoch 1673/10000: L(Train): 0.28326499462127686; L(Test): 0.250531405210495\n",
      "Epoch 1674/10000: L(Train): 0.2560206353664398; L(Test): 0.2503174841403961\n",
      "Epoch 1675/10000: L(Train): 0.25671517848968506; L(Test): 0.25000831484794617\n",
      "Epoch 1676/10000: L(Train): 0.2567448616027832; L(Test): 0.24994945526123047\n",
      "Epoch 1677/10000: L(Train): 0.2617403566837311; L(Test): 0.2505858242511749\n",
      "Epoch 1678/10000: L(Train): 0.2739190459251404; L(Test): 0.24994105100631714\n",
      "Epoch 1679/10000: L(Train): 0.26226508617401123; L(Test): 0.25018638372421265\n",
      "Epoch 1680/10000: L(Train): 0.2805424928665161; L(Test): 0.2499609887599945\n",
      "Epoch 1681/10000: L(Train): 0.27661335468292236; L(Test): 0.2517772614955902\n",
      "Epoch 1682/10000: L(Train): 0.27987703680992126; L(Test): 0.24971666932106018\n",
      "Epoch 1683/10000: L(Train): 0.25836798548698425; L(Test): 0.25112220644950867\n",
      "Epoch 1684/10000: L(Train): 0.25226324796676636; L(Test): 0.24959824979305267\n",
      "Epoch 1685/10000: L(Train): 0.27297577261924744; L(Test): 0.2516949474811554\n",
      "Epoch 1686/10000: L(Train): 0.27562591433525085; L(Test): 0.250521183013916\n",
      "Epoch 1687/10000: L(Train): 0.26479050517082214; L(Test): 0.24917340278625488\n",
      "Epoch 1688/10000: L(Train): 0.28514987230300903; L(Test): 0.24941860139369965\n",
      "Epoch 1689/10000: L(Train): 0.27655377984046936; L(Test): 0.250454306602478\n",
      "Epoch 1690/10000: L(Train): 0.26004406809806824; L(Test): 0.24941261112689972\n",
      "Epoch 1691/10000: L(Train): 0.2675821781158447; L(Test): 0.24841685593128204\n",
      "Epoch 1692/10000: L(Train): 0.26061177253723145; L(Test): 0.24992789328098297\n",
      "Epoch 1693/10000: L(Train): 0.2700578272342682; L(Test): 0.2500617504119873\n",
      "Epoch 1694/10000: L(Train): 0.26886260509490967; L(Test): 0.24980317056179047\n",
      "Epoch 1695/10000: L(Train): 0.2738185226917267; L(Test): 0.24967922270298004\n",
      "Epoch 1696/10000: L(Train): 0.25619980692863464; L(Test): 0.25017765164375305\n",
      "Epoch 1697/10000: L(Train): 0.2691327929496765; L(Test): 0.25021040439605713\n",
      "Epoch 1698/10000: L(Train): 0.24769900739192963; L(Test): 0.2498750388622284\n",
      "Epoch 1699/10000: L(Train): 0.25916701555252075; L(Test): 0.24990876019001007\n",
      "Epoch 1700/10000: L(Train): 0.2761875092983246; L(Test): 0.249447301030159\n",
      "Epoch 1701/10000: L(Train): 0.28659161925315857; L(Test): 0.24950145184993744\n",
      "Epoch 1702/10000: L(Train): 0.26396676898002625; L(Test): 0.2509193420410156\n",
      "Epoch 1703/10000: L(Train): 0.279163658618927; L(Test): 0.2504175007343292\n",
      "Epoch 1704/10000: L(Train): 0.2711425721645355; L(Test): 0.24925510585308075\n",
      "Epoch 1705/10000: L(Train): 0.2582884728908539; L(Test): 0.250855952501297\n",
      "Epoch 1706/10000: L(Train): 0.26755860447883606; L(Test): 0.25073543190956116\n",
      "Epoch 1707/10000: L(Train): 0.2665207087993622; L(Test): 0.2522156238555908\n",
      "Epoch 1708/10000: L(Train): 0.2843914031982422; L(Test): 0.2502814829349518\n",
      "Epoch 1709/10000: L(Train): 0.2635480463504791; L(Test): 0.248831644654274\n",
      "Epoch 1710/10000: L(Train): 0.26950234174728394; L(Test): 0.2499748170375824\n",
      "Epoch 1711/10000: L(Train): 0.2660088837146759; L(Test): 0.24991664290428162\n",
      "Epoch 1712/10000: L(Train): 0.2821860909461975; L(Test): 0.24968302249908447\n",
      "Epoch 1713/10000: L(Train): 0.26340317726135254; L(Test): 0.250731885433197\n",
      "Epoch 1714/10000: L(Train): 0.27885228395462036; L(Test): 0.24962088465690613\n",
      "Epoch 1715/10000: L(Train): 0.2784983813762665; L(Test): 0.24862176179885864\n",
      "Epoch 1716/10000: L(Train): 0.2653839886188507; L(Test): 0.25036776065826416\n",
      "Epoch 1717/10000: L(Train): 0.2648397386074066; L(Test): 0.25054267048835754\n",
      "Epoch 1718/10000: L(Train): 0.26851707696914673; L(Test): 0.2497483640909195\n",
      "Epoch 1719/10000: L(Train): 0.2896949350833893; L(Test): 0.24952805042266846\n",
      "Epoch 1720/10000: L(Train): 0.26397985219955444; L(Test): 0.25077512860298157\n",
      "Epoch 1721/10000: L(Train): 0.2699129283428192; L(Test): 0.2504469156265259\n",
      "Epoch 1722/10000: L(Train): 0.2601061761379242; L(Test): 0.24928143620491028\n",
      "Epoch 1723/10000: L(Train): 0.26309993863105774; L(Test): 0.2496582269668579\n",
      "Epoch 1724/10000: L(Train): 0.2664296627044678; L(Test): 0.24973970651626587\n",
      "Epoch 1725/10000: L(Train): 0.2771120071411133; L(Test): 0.24925951659679413\n",
      "Epoch 1726/10000: L(Train): 0.25838765501976013; L(Test): 0.24910040199756622\n",
      "Epoch 1727/10000: L(Train): 0.26802289485931396; L(Test): 0.24926038086414337\n",
      "Epoch 1728/10000: L(Train): 0.2565576732158661; L(Test): 0.2500844895839691\n",
      "Epoch 1729/10000: L(Train): 0.2619543671607971; L(Test): 0.2513556480407715\n",
      "Epoch 1730/10000: L(Train): 0.27585887908935547; L(Test): 0.24940182268619537\n",
      "Epoch 1731/10000: L(Train): 0.2729714512825012; L(Test): 0.24908974766731262\n",
      "Epoch 1732/10000: L(Train): 0.2694569230079651; L(Test): 0.24901768565177917\n",
      "Epoch 1733/10000: L(Train): 0.2728126645088196; L(Test): 0.24920593202114105\n",
      "Epoch 1734/10000: L(Train): 0.2664407193660736; L(Test): 0.24975454807281494\n",
      "Epoch 1735/10000: L(Train): 0.2711453437805176; L(Test): 0.24961122870445251\n",
      "Epoch 1736/10000: L(Train): 0.2649900019168854; L(Test): 0.24878115952014923\n",
      "Epoch 1737/10000: L(Train): 0.2730458080768585; L(Test): 0.2493845671415329\n",
      "Epoch 1738/10000: L(Train): 0.2698473632335663; L(Test): 0.24834005534648895\n",
      "Epoch 1739/10000: L(Train): 0.26492366194725037; L(Test): 0.24899713695049286\n",
      "Epoch 1740/10000: L(Train): 0.2686038911342621; L(Test): 0.24952363967895508\n",
      "Epoch 1741/10000: L(Train): 0.25631847977638245; L(Test): 0.24843405187129974\n",
      "Epoch 1742/10000: L(Train): 0.2689644992351532; L(Test): 0.24828779697418213\n",
      "Epoch 1743/10000: L(Train): 0.27012455463409424; L(Test): 0.2491668313741684\n",
      "Epoch 1744/10000: L(Train): 0.26812586188316345; L(Test): 0.24938322603702545\n",
      "Epoch 1745/10000: L(Train): 0.28242573142051697; L(Test): 0.2506214380264282\n",
      "Epoch 1746/10000: L(Train): 0.2726885974407196; L(Test): 0.2501552999019623\n",
      "Epoch 1747/10000: L(Train): 0.2650527060031891; L(Test): 0.250043660402298\n",
      "Epoch 1748/10000: L(Train): 0.2642436921596527; L(Test): 0.2499164491891861\n",
      "Epoch 1749/10000: L(Train): 0.25664323568344116; L(Test): 0.25023332238197327\n",
      "Epoch 1750/10000: L(Train): 0.2767712473869324; L(Test): 0.250996470451355\n",
      "Epoch 1751/10000: L(Train): 0.260000079870224; L(Test): 0.24946264922618866\n",
      "Epoch 1752/10000: L(Train): 0.2692703902721405; L(Test): 0.25009188055992126\n",
      "Epoch 1753/10000: L(Train): 0.2724723815917969; L(Test): 0.24895519018173218\n",
      "Epoch 1754/10000: L(Train): 0.2740887403488159; L(Test): 0.25124648213386536\n",
      "Epoch 1755/10000: L(Train): 0.27351921796798706; L(Test): 0.2508925199508667\n",
      "Epoch 1756/10000: L(Train): 0.2711411416530609; L(Test): 0.24882350862026215\n",
      "Epoch 1757/10000: L(Train): 0.2688128352165222; L(Test): 0.25008442997932434\n",
      "Epoch 1758/10000: L(Train): 0.27000856399536133; L(Test): 0.24988552927970886\n",
      "Epoch 1759/10000: L(Train): 0.273777037858963; L(Test): 0.2502700388431549\n",
      "Epoch 1760/10000: L(Train): 0.2516293525695801; L(Test): 0.2506455183029175\n",
      "Epoch 1761/10000: L(Train): 0.27565401792526245; L(Test): 0.24891971051692963\n",
      "Epoch 1762/10000: L(Train): 0.2822938859462738; L(Test): 0.24971406161785126\n",
      "Epoch 1763/10000: L(Train): 0.2769174873828888; L(Test): 0.25049301981925964\n",
      "Epoch 1764/10000: L(Train): 0.28292274475097656; L(Test): 0.24917271733283997\n",
      "Epoch 1765/10000: L(Train): 0.2793520390987396; L(Test): 0.248570054769516\n",
      "Epoch 1766/10000: L(Train): 0.26442235708236694; L(Test): 0.2490006387233734\n",
      "Epoch 1767/10000: L(Train): 0.2678057551383972; L(Test): 0.2490614652633667\n",
      "Epoch 1768/10000: L(Train): 0.2617645263671875; L(Test): 0.25143593549728394\n",
      "Epoch 1769/10000: L(Train): 0.2793630063533783; L(Test): 0.2495364397764206\n",
      "Epoch 1770/10000: L(Train): 0.27480271458625793; L(Test): 0.250483900308609\n",
      "Epoch 1771/10000: L(Train): 0.26953062415122986; L(Test): 0.2500652074813843\n",
      "Epoch 1772/10000: L(Train): 0.27135467529296875; L(Test): 0.25211411714553833\n",
      "Epoch 1773/10000: L(Train): 0.27620401978492737; L(Test): 0.2503912150859833\n",
      "Epoch 1774/10000: L(Train): 0.28629085421562195; L(Test): 0.2528707981109619\n",
      "Epoch 1775/10000: L(Train): 0.27870747447013855; L(Test): 0.25454282760620117\n",
      "Epoch 1776/10000: L(Train): 0.27248141169548035; L(Test): 0.25463777780532837\n",
      "Epoch 1777/10000: L(Train): 0.265500009059906; L(Test): 0.2523442804813385\n",
      "Epoch 1778/10000: L(Train): 0.2639956772327423; L(Test): 0.2538571059703827\n",
      "Epoch 1779/10000: L(Train): 0.2704041302204132; L(Test): 0.2536066770553589\n",
      "Epoch 1780/10000: L(Train): 0.2692866921424866; L(Test): 0.25305894017219543\n",
      "Epoch 1781/10000: L(Train): 0.2759788930416107; L(Test): 0.2518347203731537\n",
      "Epoch 1782/10000: L(Train): 0.2687319219112396; L(Test): 0.25346261262893677\n",
      "Epoch 1783/10000: L(Train): 0.2635386288166046; L(Test): 0.25478464365005493\n",
      "Epoch 1784/10000: L(Train): 0.2802700400352478; L(Test): 0.2528091073036194\n",
      "Epoch 1785/10000: L(Train): 0.2654018700122833; L(Test): 0.25535616278648376\n",
      "Epoch 1786/10000: L(Train): 0.2814916670322418; L(Test): 0.2535790503025055\n",
      "Epoch 1787/10000: L(Train): 0.264680951833725; L(Test): 0.25202590227127075\n",
      "Epoch 1788/10000: L(Train): 0.255820631980896; L(Test): 0.25286486744880676\n",
      "Epoch 1789/10000: L(Train): 0.27582064270973206; L(Test): 0.2534153163433075\n",
      "Epoch 1790/10000: L(Train): 0.2725691497325897; L(Test): 0.25132352113723755\n",
      "Epoch 1791/10000: L(Train): 0.257893830537796; L(Test): 0.2526729702949524\n",
      "Epoch 1792/10000: L(Train): 0.2664562165737152; L(Test): 0.2508877217769623\n",
      "Epoch 1793/10000: L(Train): 0.26482731103897095; L(Test): 0.2524765729904175\n",
      "Epoch 1794/10000: L(Train): 0.2800306975841522; L(Test): 0.252906858921051\n",
      "Epoch 1795/10000: L(Train): 0.28335705399513245; L(Test): 0.25070253014564514\n",
      "Epoch 1796/10000: L(Train): 0.27215301990509033; L(Test): 0.25082650780677795\n",
      "Epoch 1797/10000: L(Train): 0.2693420350551605; L(Test): 0.2515397071838379\n",
      "Epoch 1798/10000: L(Train): 0.28073564171791077; L(Test): 0.25109612941741943\n",
      "Epoch 1799/10000: L(Train): 0.26384955644607544; L(Test): 0.2507476806640625\n",
      "Epoch 1800/10000: L(Train): 0.28023144602775574; L(Test): 0.2510389983654022\n",
      "Epoch 1801/10000: L(Train): 0.25953492522239685; L(Test): 0.2500600516796112\n",
      "Epoch 1802/10000: L(Train): 0.272344172000885; L(Test): 0.24925166368484497\n",
      "Epoch 1803/10000: L(Train): 0.26157769560813904; L(Test): 0.249876469373703\n",
      "Epoch 1804/10000: L(Train): 0.2689923644065857; L(Test): 0.24975696206092834\n",
      "Epoch 1805/10000: L(Train): 0.2684258818626404; L(Test): 0.25002023577690125\n",
      "Epoch 1806/10000: L(Train): 0.27995097637176514; L(Test): 0.24924059212207794\n",
      "Epoch 1807/10000: L(Train): 0.2675277292728424; L(Test): 0.24967321753501892\n",
      "Epoch 1808/10000: L(Train): 0.27276626229286194; L(Test): 0.2477484941482544\n",
      "Epoch 1809/10000: L(Train): 0.26328611373901367; L(Test): 0.24797993898391724\n",
      "Epoch 1810/10000: L(Train): 0.28302279114723206; L(Test): 0.2484084665775299\n",
      "Epoch 1811/10000: L(Train): 0.2588120400905609; L(Test): 0.24881412088871002\n",
      "Epoch 1812/10000: L(Train): 0.26882925629615784; L(Test): 0.24847619235515594\n",
      "Epoch 1813/10000: L(Train): 0.2740316390991211; L(Test): 0.2489212304353714\n",
      "Epoch 1814/10000: L(Train): 0.28092294931411743; L(Test): 0.24930202960968018\n",
      "Epoch 1815/10000: L(Train): 0.2664172649383545; L(Test): 0.24866929650306702\n",
      "Epoch 1816/10000: L(Train): 0.27626940608024597; L(Test): 0.24851226806640625\n",
      "Epoch 1817/10000: L(Train): 0.25852733850479126; L(Test): 0.2489781379699707\n",
      "Epoch 1818/10000: L(Train): 0.2575084865093231; L(Test): 0.24885959923267365\n",
      "Epoch 1819/10000: L(Train): 0.26256063580513; L(Test): 0.24921071529388428\n",
      "Epoch 1820/10000: L(Train): 0.26489225029945374; L(Test): 0.24888326227664948\n",
      "Epoch 1821/10000: L(Train): 0.26511621475219727; L(Test): 0.24852254986763\n",
      "Epoch 1822/10000: L(Train): 0.2861529290676117; L(Test): 0.248186856508255\n",
      "Epoch 1823/10000: L(Train): 0.2436295598745346; L(Test): 0.24788573384284973\n",
      "Epoch 1824/10000: L(Train): 0.2700129747390747; L(Test): 0.2480962574481964\n",
      "Epoch 1825/10000: L(Train): 0.264361709356308; L(Test): 0.24818386137485504\n",
      "Epoch 1826/10000: L(Train): 0.2662386894226074; L(Test): 0.24766233563423157\n",
      "Epoch 1827/10000: L(Train): 0.25628069043159485; L(Test): 0.24821685254573822\n",
      "Epoch 1828/10000: L(Train): 0.2840321660041809; L(Test): 0.24796651303768158\n",
      "Epoch 1829/10000: L(Train): 0.2742622196674347; L(Test): 0.24813638627529144\n",
      "Epoch 1830/10000: L(Train): 0.2716890573501587; L(Test): 0.2475164234638214\n",
      "Epoch 1831/10000: L(Train): 0.2669773995876312; L(Test): 0.24711520969867706\n",
      "Epoch 1832/10000: L(Train): 0.25668179988861084; L(Test): 0.2474689483642578\n",
      "Epoch 1833/10000: L(Train): 0.2695308029651642; L(Test): 0.24691690504550934\n",
      "Epoch 1834/10000: L(Train): 0.2783748209476471; L(Test): 0.24706532061100006\n",
      "Epoch 1835/10000: L(Train): 0.26472142338752747; L(Test): 0.2470441609621048\n",
      "Epoch 1836/10000: L(Train): 0.2709876298904419; L(Test): 0.24729354679584503\n",
      "Epoch 1837/10000: L(Train): 0.26035556197166443; L(Test): 0.2469703108072281\n",
      "Epoch 1838/10000: L(Train): 0.27397626638412476; L(Test): 0.24743694067001343\n",
      "Epoch 1839/10000: L(Train): 0.291084349155426; L(Test): 0.24796445667743683\n",
      "Epoch 1840/10000: L(Train): 0.26571720838546753; L(Test): 0.24775557219982147\n",
      "Epoch 1841/10000: L(Train): 0.284501314163208; L(Test): 0.247990220785141\n",
      "Epoch 1842/10000: L(Train): 0.261941522359848; L(Test): 0.24751798808574677\n",
      "Epoch 1843/10000: L(Train): 0.27574557065963745; L(Test): 0.24827322363853455\n",
      "Epoch 1844/10000: L(Train): 0.2784123420715332; L(Test): 0.2481672167778015\n",
      "Epoch 1845/10000: L(Train): 0.2611689865589142; L(Test): 0.24933043122291565\n",
      "Epoch 1846/10000: L(Train): 0.2635355293750763; L(Test): 0.24947889149188995\n",
      "Epoch 1847/10000: L(Train): 0.25936460494995117; L(Test): 0.24829906225204468\n",
      "Epoch 1848/10000: L(Train): 0.26894012093544006; L(Test): 0.2479991912841797\n",
      "Epoch 1849/10000: L(Train): 0.26676273345947266; L(Test): 0.2485349476337433\n",
      "Epoch 1850/10000: L(Train): 0.27128276228904724; L(Test): 0.24820274114608765\n",
      "Epoch 1851/10000: L(Train): 0.25178393721580505; L(Test): 0.24835127592086792\n",
      "Epoch 1852/10000: L(Train): 0.26483413577079773; L(Test): 0.24735921621322632\n",
      "Epoch 1853/10000: L(Train): 0.27442196011543274; L(Test): 0.24826067686080933\n",
      "Epoch 1854/10000: L(Train): 0.2637781500816345; L(Test): 0.24851875007152557\n",
      "Epoch 1855/10000: L(Train): 0.2616675794124603; L(Test): 0.24785040318965912\n",
      "Epoch 1856/10000: L(Train): 0.2747061550617218; L(Test): 0.24867220222949982\n",
      "Epoch 1857/10000: L(Train): 0.27405303716659546; L(Test): 0.2479567527770996\n",
      "Epoch 1858/10000: L(Train): 0.2696547210216522; L(Test): 0.2469692975282669\n",
      "Epoch 1859/10000: L(Train): 0.26803722977638245; L(Test): 0.2473088502883911\n",
      "Epoch 1860/10000: L(Train): 0.25181832909584045; L(Test): 0.24691812694072723\n",
      "Epoch 1861/10000: L(Train): 0.24943499267101288; L(Test): 0.24650099873542786\n",
      "Epoch 1862/10000: L(Train): 0.2548547387123108; L(Test): 0.2468283325433731\n",
      "Epoch 1863/10000: L(Train): 0.2583821713924408; L(Test): 0.24743469059467316\n",
      "Epoch 1864/10000: L(Train): 0.25667765736579895; L(Test): 0.2484539896249771\n",
      "Epoch 1865/10000: L(Train): 0.26291322708129883; L(Test): 0.24887043237686157\n",
      "Epoch 1866/10000: L(Train): 0.26870471239089966; L(Test): 0.24875587224960327\n",
      "Epoch 1867/10000: L(Train): 0.275288850069046; L(Test): 0.24860018491744995\n",
      "Epoch 1868/10000: L(Train): 0.27315160632133484; L(Test): 0.24876265227794647\n",
      "Epoch 1869/10000: L(Train): 0.2627628743648529; L(Test): 0.24876713752746582\n",
      "Epoch 1870/10000: L(Train): 0.2591328024864197; L(Test): 0.24818310141563416\n",
      "Epoch 1871/10000: L(Train): 0.28703218698501587; L(Test): 0.24738092720508575\n",
      "Epoch 1872/10000: L(Train): 0.27225083112716675; L(Test): 0.2485787272453308\n",
      "Epoch 1873/10000: L(Train): 0.27555134892463684; L(Test): 0.24958598613739014\n",
      "Epoch 1874/10000: L(Train): 0.2750294804573059; L(Test): 0.24986982345581055\n",
      "Epoch 1875/10000: L(Train): 0.26632973551750183; L(Test): 0.24827894568443298\n",
      "Epoch 1876/10000: L(Train): 0.2639842629432678; L(Test): 0.2489871382713318\n",
      "Epoch 1877/10000: L(Train): 0.2797479033470154; L(Test): 0.2481207549571991\n",
      "Epoch 1878/10000: L(Train): 0.2692194879055023; L(Test): 0.2504565417766571\n",
      "Epoch 1879/10000: L(Train): 0.27478480339050293; L(Test): 0.24894654750823975\n",
      "Epoch 1880/10000: L(Train): 0.2710290253162384; L(Test): 0.2502744495868683\n",
      "Epoch 1881/10000: L(Train): 0.2666599154472351; L(Test): 0.2507530450820923\n",
      "Epoch 1882/10000: L(Train): 0.2929612398147583; L(Test): 0.2503105401992798\n",
      "Epoch 1883/10000: L(Train): 0.2738066017627716; L(Test): 0.25031915307044983\n",
      "Epoch 1884/10000: L(Train): 0.2792581021785736; L(Test): 0.24967218935489655\n",
      "Epoch 1885/10000: L(Train): 0.2656421959400177; L(Test): 0.2502182722091675\n",
      "Epoch 1886/10000: L(Train): 0.2575599253177643; L(Test): 0.24914714694023132\n",
      "Epoch 1887/10000: L(Train): 0.2737843096256256; L(Test): 0.25144559144973755\n",
      "Epoch 1888/10000: L(Train): 0.27901965379714966; L(Test): 0.250222384929657\n",
      "Epoch 1889/10000: L(Train): 0.2700996398925781; L(Test): 0.24945120513439178\n",
      "Epoch 1890/10000: L(Train): 0.2863512635231018; L(Test): 0.24898695945739746\n",
      "Epoch 1891/10000: L(Train): 0.2783242166042328; L(Test): 0.25123900175094604\n",
      "Epoch 1892/10000: L(Train): 0.25636935234069824; L(Test): 0.25088879466056824\n",
      "Epoch 1893/10000: L(Train): 0.2744559049606323; L(Test): 0.24775278568267822\n",
      "Epoch 1894/10000: L(Train): 0.27455562353134155; L(Test): 0.24935387074947357\n",
      "Epoch 1895/10000: L(Train): 0.2658819258213043; L(Test): 0.24901743233203888\n",
      "Epoch 1896/10000: L(Train): 0.2709119915962219; L(Test): 0.2508239150047302\n",
      "Epoch 1897/10000: L(Train): 0.2718863785266876; L(Test): 0.24827691912651062\n",
      "Epoch 1898/10000: L(Train): 0.26774755120277405; L(Test): 0.2490050494670868\n",
      "Epoch 1899/10000: L(Train): 0.26397326588630676; L(Test): 0.24836935102939606\n",
      "Epoch 1900/10000: L(Train): 0.2874623239040375; L(Test): 0.24900993704795837\n",
      "Epoch 1901/10000: L(Train): 0.27510201930999756; L(Test): 0.24915774166584015\n",
      "Epoch 1902/10000: L(Train): 0.2596184015274048; L(Test): 0.24855895340442657\n",
      "Epoch 1903/10000: L(Train): 0.27206096053123474; L(Test): 0.24828918278217316\n",
      "Epoch 1904/10000: L(Train): 0.2730632424354553; L(Test): 0.24735397100448608\n",
      "Epoch 1905/10000: L(Train): 0.2594709098339081; L(Test): 0.2487916350364685\n",
      "Epoch 1906/10000: L(Train): 0.2722195088863373; L(Test): 0.24726080894470215\n",
      "Epoch 1907/10000: L(Train): 0.2527483403682709; L(Test): 0.246761754155159\n",
      "Epoch 1908/10000: L(Train): 0.2547820508480072; L(Test): 0.247436061501503\n",
      "Epoch 1909/10000: L(Train): 0.2680976688861847; L(Test): 0.24825680255889893\n",
      "Epoch 1910/10000: L(Train): 0.26471346616744995; L(Test): 0.2485956996679306\n",
      "Epoch 1911/10000: L(Train): 0.27023014426231384; L(Test): 0.24822789430618286\n",
      "Epoch 1912/10000: L(Train): 0.25600361824035645; L(Test): 0.24770750105381012\n",
      "Epoch 1913/10000: L(Train): 0.27670541405677795; L(Test): 0.24777337908744812\n",
      "Epoch 1914/10000: L(Train): 0.26630154252052307; L(Test): 0.24794986844062805\n",
      "Epoch 1915/10000: L(Train): 0.27030497789382935; L(Test): 0.2480970323085785\n",
      "Epoch 1916/10000: L(Train): 0.2693902850151062; L(Test): 0.24884463846683502\n",
      "Epoch 1917/10000: L(Train): 0.2757481336593628; L(Test): 0.24820765852928162\n",
      "Epoch 1918/10000: L(Train): 0.2660520672798157; L(Test): 0.24829065799713135\n",
      "Epoch 1919/10000: L(Train): 0.2613556683063507; L(Test): 0.24798156321048737\n",
      "Epoch 1920/10000: L(Train): 0.29647448658943176; L(Test): 0.24871748685836792\n",
      "Epoch 1921/10000: L(Train): 0.2785111665725708; L(Test): 0.2482331246137619\n",
      "Epoch 1922/10000: L(Train): 0.26774704456329346; L(Test): 0.24781380593776703\n",
      "Epoch 1923/10000: L(Train): 0.27268385887145996; L(Test): 0.24766302108764648\n",
      "Epoch 1924/10000: L(Train): 0.2738350033760071; L(Test): 0.24743016064167023\n",
      "Epoch 1925/10000: L(Train): 0.27121615409851074; L(Test): 0.24794523417949677\n",
      "Epoch 1926/10000: L(Train): 0.27321743965148926; L(Test): 0.248369961977005\n",
      "Epoch 1927/10000: L(Train): 0.2701418995857239; L(Test): 0.24853824079036713\n",
      "Epoch 1928/10000: L(Train): 0.2595364451408386; L(Test): 0.24842926859855652\n",
      "Epoch 1929/10000: L(Train): 0.2677089273929596; L(Test): 0.2484767884016037\n",
      "Epoch 1930/10000: L(Train): 0.26507148146629333; L(Test): 0.24821923673152924\n",
      "Epoch 1931/10000: L(Train): 0.26004040241241455; L(Test): 0.24848288297653198\n",
      "Epoch 1932/10000: L(Train): 0.25938287377357483; L(Test): 0.24861998856067657\n",
      "Epoch 1933/10000: L(Train): 0.27791550755500793; L(Test): 0.24832196533679962\n",
      "Epoch 1934/10000: L(Train): 0.2612350285053253; L(Test): 0.24783460795879364\n",
      "Epoch 1935/10000: L(Train): 0.26554250717163086; L(Test): 0.24786654114723206\n",
      "Epoch 1936/10000: L(Train): 0.2622430622577667; L(Test): 0.24719861149787903\n",
      "Epoch 1937/10000: L(Train): 0.2595638334751129; L(Test): 0.2469838708639145\n",
      "Epoch 1938/10000: L(Train): 0.26818957924842834; L(Test): 0.24733704328536987\n",
      "Epoch 1939/10000: L(Train): 0.2622467577457428; L(Test): 0.24750882387161255\n",
      "Epoch 1940/10000: L(Train): 0.27341896295547485; L(Test): 0.24689947068691254\n",
      "Epoch 1941/10000: L(Train): 0.27330753207206726; L(Test): 0.24560831487178802\n",
      "Epoch 1942/10000: L(Train): 0.2613481283187866; L(Test): 0.24626560509204865\n",
      "Epoch 1943/10000: L(Train): 0.2724335193634033; L(Test): 0.24677710235118866\n",
      "Epoch 1944/10000: L(Train): 0.27065563201904297; L(Test): 0.24676784873008728\n",
      "Epoch 1945/10000: L(Train): 0.2794279158115387; L(Test): 0.24707269668579102\n",
      "Epoch 1946/10000: L(Train): 0.26062706112861633; L(Test): 0.24648389220237732\n",
      "Epoch 1947/10000: L(Train): 0.26971226930618286; L(Test): 0.24635016918182373\n",
      "Epoch 1948/10000: L(Train): 0.2704877257347107; L(Test): 0.2464778572320938\n",
      "Epoch 1949/10000: L(Train): 0.2783527374267578; L(Test): 0.24654243886470795\n",
      "Epoch 1950/10000: L(Train): 0.2697560787200928; L(Test): 0.2473282516002655\n",
      "Epoch 1951/10000: L(Train): 0.28543326258659363; L(Test): 0.24682161211967468\n",
      "Epoch 1952/10000: L(Train): 0.2676090896129608; L(Test): 0.24698662757873535\n",
      "Epoch 1953/10000: L(Train): 0.28538841009140015; L(Test): 0.24616172909736633\n",
      "Epoch 1954/10000: L(Train): 0.26228293776512146; L(Test): 0.24640628695487976\n",
      "Epoch 1955/10000: L(Train): 0.27904126048088074; L(Test): 0.24680893123149872\n",
      "Epoch 1956/10000: L(Train): 0.2497466653585434; L(Test): 0.24707545340061188\n",
      "Epoch 1957/10000: L(Train): 0.2655545175075531; L(Test): 0.2465677112340927\n",
      "Epoch 1958/10000: L(Train): 0.2649499773979187; L(Test): 0.2459668666124344\n",
      "Epoch 1959/10000: L(Train): 0.27005672454833984; L(Test): 0.24712949991226196\n",
      "Epoch 1960/10000: L(Train): 0.2949211597442627; L(Test): 0.2471461147069931\n",
      "Epoch 1961/10000: L(Train): 0.2715097665786743; L(Test): 0.2466859668493271\n",
      "Epoch 1962/10000: L(Train): 0.25677967071533203; L(Test): 0.24727320671081543\n",
      "Epoch 1963/10000: L(Train): 0.2769964039325714; L(Test): 0.2483341246843338\n",
      "Epoch 1964/10000: L(Train): 0.27052298188209534; L(Test): 0.24724900722503662\n",
      "Epoch 1965/10000: L(Train): 0.2684393525123596; L(Test): 0.24636489152908325\n",
      "Epoch 1966/10000: L(Train): 0.26637256145477295; L(Test): 0.24811960756778717\n",
      "Epoch 1967/10000: L(Train): 0.27217328548431396; L(Test): 0.2473633885383606\n",
      "Epoch 1968/10000: L(Train): 0.25867846608161926; L(Test): 0.24819974601268768\n",
      "Epoch 1969/10000: L(Train): 0.2802422344684601; L(Test): 0.24763116240501404\n",
      "Epoch 1970/10000: L(Train): 0.25859078764915466; L(Test): 0.24943354725837708\n",
      "Epoch 1971/10000: L(Train): 0.2763059139251709; L(Test): 0.24985212087631226\n",
      "Epoch 1972/10000: L(Train): 0.26039358973503113; L(Test): 0.24915921688079834\n",
      "Epoch 1973/10000: L(Train): 0.25630253553390503; L(Test): 0.24817998707294464\n",
      "Epoch 1974/10000: L(Train): 0.2595122456550598; L(Test): 0.24811898171901703\n",
      "Epoch 1975/10000: L(Train): 0.25892138481140137; L(Test): 0.24862733483314514\n",
      "Epoch 1976/10000: L(Train): 0.2716098427772522; L(Test): 0.25191110372543335\n",
      "Epoch 1977/10000: L(Train): 0.2733044922351837; L(Test): 0.25163137912750244\n",
      "Epoch 1978/10000: L(Train): 0.2664424777030945; L(Test): 0.25067052245140076\n",
      "Epoch 1979/10000: L(Train): 0.26584795117378235; L(Test): 0.2513919174671173\n",
      "Epoch 1980/10000: L(Train): 0.2728375494480133; L(Test): 0.2537894546985626\n",
      "Epoch 1981/10000: L(Train): 0.2710474133491516; L(Test): 0.25238490104675293\n",
      "Epoch 1982/10000: L(Train): 0.27642881870269775; L(Test): 0.2507302165031433\n",
      "Epoch 1983/10000: L(Train): 0.2819267809391022; L(Test): 0.2505798041820526\n",
      "Epoch 1984/10000: L(Train): 0.2824110984802246; L(Test): 0.25102296471595764\n",
      "Epoch 1985/10000: L(Train): 0.2600036561489105; L(Test): 0.24940286576747894\n",
      "Epoch 1986/10000: L(Train): 0.2658742666244507; L(Test): 0.2481716275215149\n",
      "Epoch 1987/10000: L(Train): 0.26769354939460754; L(Test): 0.2503543496131897\n",
      "Epoch 1988/10000: L(Train): 0.27682721614837646; L(Test): 0.2487078607082367\n",
      "Epoch 1989/10000: L(Train): 0.25954627990722656; L(Test): 0.249618798494339\n",
      "Epoch 1990/10000: L(Train): 0.2857792377471924; L(Test): 0.24788399040699005\n",
      "Epoch 1991/10000: L(Train): 0.2708249092102051; L(Test): 0.24876222014427185\n",
      "Epoch 1992/10000: L(Train): 0.284607470035553; L(Test): 0.2475082129240036\n",
      "Epoch 1993/10000: L(Train): 0.258983314037323; L(Test): 0.2488863468170166\n",
      "Epoch 1994/10000: L(Train): 0.2640021741390228; L(Test): 0.24885867536067963\n",
      "Epoch 1995/10000: L(Train): 0.2614591419696808; L(Test): 0.24708308279514313\n",
      "Epoch 1996/10000: L(Train): 0.26916083693504333; L(Test): 0.2477561980485916\n",
      "Epoch 1997/10000: L(Train): 0.28122657537460327; L(Test): 0.24785257875919342\n",
      "Epoch 1998/10000: L(Train): 0.27307984232902527; L(Test): 0.2498442828655243\n",
      "Epoch 1999/10000: L(Train): 0.2734653055667877; L(Test): 0.25094008445739746\n",
      "Epoch 2000/10000: L(Train): 0.26780906319618225; L(Test): 0.24973075091838837\n",
      "Epoch 2001/10000: L(Train): 0.2724950611591339; L(Test): 0.24922075867652893\n",
      "Epoch 2002/10000: L(Train): 0.27868592739105225; L(Test): 0.2483932375907898\n",
      "Epoch 2003/10000: L(Train): 0.26758238673210144; L(Test): 0.24998946487903595\n",
      "Epoch 2004/10000: L(Train): 0.27228301763534546; L(Test): 0.24990253150463104\n",
      "Epoch 2005/10000: L(Train): 0.27848607301712036; L(Test): 0.24790023267269135\n",
      "Epoch 2006/10000: L(Train): 0.2635156512260437; L(Test): 0.24878163635730743\n",
      "Epoch 2007/10000: L(Train): 0.2701263129711151; L(Test): 0.2487109750509262\n",
      "Epoch 2008/10000: L(Train): 0.2745101749897003; L(Test): 0.25051093101501465\n",
      "Epoch 2009/10000: L(Train): 0.2808457314968109; L(Test): 0.2483668327331543\n",
      "Epoch 2010/10000: L(Train): 0.25689810514450073; L(Test): 0.24788199365139008\n",
      "Epoch 2011/10000: L(Train): 0.24254672229290009; L(Test): 0.24759696424007416\n",
      "Epoch 2012/10000: L(Train): 0.2668725848197937; L(Test): 0.24957610666751862\n",
      "Epoch 2013/10000: L(Train): 0.2597042918205261; L(Test): 0.2476269155740738\n",
      "Epoch 2014/10000: L(Train): 0.2792975604534149; L(Test): 0.24849972128868103\n",
      "Epoch 2015/10000: L(Train): 0.26703929901123047; L(Test): 0.24781054258346558\n",
      "Epoch 2016/10000: L(Train): 0.2687194347381592; L(Test): 0.249966561794281\n",
      "Epoch 2017/10000: L(Train): 0.286359578371048; L(Test): 0.2487374246120453\n",
      "Epoch 2018/10000: L(Train): 0.27477478981018066; L(Test): 0.24721236526966095\n",
      "Epoch 2019/10000: L(Train): 0.2708796560764313; L(Test): 0.24691523611545563\n",
      "Epoch 2020/10000: L(Train): 0.2626681923866272; L(Test): 0.24750491976737976\n",
      "Epoch 2021/10000: L(Train): 0.25222399830818176; L(Test): 0.24860301613807678\n",
      "Epoch 2022/10000: L(Train): 0.2886580526828766; L(Test): 0.24696944653987885\n",
      "Epoch 2023/10000: L(Train): 0.2754751443862915; L(Test): 0.2476571947336197\n",
      "Epoch 2024/10000: L(Train): 0.2661032974720001; L(Test): 0.24774204194545746\n",
      "Epoch 2025/10000: L(Train): 0.25023433566093445; L(Test): 0.2477351725101471\n",
      "Epoch 2026/10000: L(Train): 0.2793685793876648; L(Test): 0.2484099566936493\n",
      "Epoch 2027/10000: L(Train): 0.27375635504722595; L(Test): 0.24856369197368622\n",
      "Epoch 2028/10000: L(Train): 0.2625221312046051; L(Test): 0.2471727728843689\n",
      "Epoch 2029/10000: L(Train): 0.2539656460285187; L(Test): 0.2474382072687149\n",
      "Epoch 2030/10000: L(Train): 0.2565402686595917; L(Test): 0.24866630136966705\n",
      "Epoch 2031/10000: L(Train): 0.26582440733909607; L(Test): 0.24741467833518982\n",
      "Epoch 2032/10000: L(Train): 0.2556472718715668; L(Test): 0.24756395816802979\n",
      "Epoch 2033/10000: L(Train): 0.2671877145767212; L(Test): 0.2469095140695572\n",
      "Epoch 2034/10000: L(Train): 0.2504589557647705; L(Test): 0.24700677394866943\n",
      "Epoch 2035/10000: L(Train): 0.26007279753685; L(Test): 0.247611865401268\n",
      "Epoch 2036/10000: L(Train): 0.25940796732902527; L(Test): 0.24780645966529846\n",
      "Epoch 2037/10000: L(Train): 0.2674596607685089; L(Test): 0.24610666930675507\n",
      "Epoch 2038/10000: L(Train): 0.2547000050544739; L(Test): 0.2459331750869751\n",
      "Epoch 2039/10000: L(Train): 0.2723569869995117; L(Test): 0.24658721685409546\n",
      "Epoch 2040/10000: L(Train): 0.26813557744026184; L(Test): 0.24750535190105438\n",
      "Epoch 2041/10000: L(Train): 0.25817450881004333; L(Test): 0.2470638006925583\n",
      "Epoch 2042/10000: L(Train): 0.2722965180873871; L(Test): 0.24752159416675568\n",
      "Epoch 2043/10000: L(Train): 0.2611946761608124; L(Test): 0.24769671261310577\n",
      "Epoch 2044/10000: L(Train): 0.2821151316165924; L(Test): 0.24661573767662048\n",
      "Epoch 2045/10000: L(Train): 0.25475046038627625; L(Test): 0.24618931114673615\n",
      "Epoch 2046/10000: L(Train): 0.27257436513900757; L(Test): 0.24644343554973602\n",
      "Epoch 2047/10000: L(Train): 0.2682752311229706; L(Test): 0.24660861492156982\n",
      "Epoch 2048/10000: L(Train): 0.26987960934638977; L(Test): 0.24593666195869446\n",
      "Epoch 2049/10000: L(Train): 0.26997706294059753; L(Test): 0.2461940050125122\n",
      "Epoch 2050/10000: L(Train): 0.2605436146259308; L(Test): 0.24680937826633453\n",
      "Epoch 2051/10000: L(Train): 0.2712656259536743; L(Test): 0.24676631391048431\n",
      "Epoch 2052/10000: L(Train): 0.2622160315513611; L(Test): 0.2461347132921219\n",
      "Epoch 2053/10000: L(Train): 0.2725542187690735; L(Test): 0.24607747793197632\n",
      "Epoch 2054/10000: L(Train): 0.2673247456550598; L(Test): 0.24620941281318665\n",
      "Epoch 2055/10000: L(Train): 0.25849878787994385; L(Test): 0.24710124731063843\n",
      "Epoch 2056/10000: L(Train): 0.271747350692749; L(Test): 0.2465040534734726\n",
      "Epoch 2057/10000: L(Train): 0.25102362036705017; L(Test): 0.2461254894733429\n",
      "Epoch 2058/10000: L(Train): 0.2646174132823944; L(Test): 0.24540434777736664\n",
      "Epoch 2059/10000: L(Train): 0.27505627274513245; L(Test): 0.24580058455467224\n",
      "Epoch 2060/10000: L(Train): 0.2722630798816681; L(Test): 0.24629709124565125\n",
      "Epoch 2061/10000: L(Train): 0.2790464162826538; L(Test): 0.24591784179210663\n",
      "Epoch 2062/10000: L(Train): 0.2543625831604004; L(Test): 0.24554196000099182\n",
      "Epoch 2063/10000: L(Train): 0.2576976716518402; L(Test): 0.2454945296049118\n",
      "Epoch 2064/10000: L(Train): 0.2539586126804352; L(Test): 0.245480015873909\n",
      "Epoch 2065/10000: L(Train): 0.25542452931404114; L(Test): 0.2457694262266159\n",
      "Epoch 2066/10000: L(Train): 0.2681692838668823; L(Test): 0.24652737379074097\n",
      "Epoch 2067/10000: L(Train): 0.271160364151001; L(Test): 0.2462579309940338\n",
      "Epoch 2068/10000: L(Train): 0.2718085050582886; L(Test): 0.24629420042037964\n",
      "Epoch 2069/10000: L(Train): 0.26445165276527405; L(Test): 0.24625034630298615\n",
      "Epoch 2070/10000: L(Train): 0.2636975646018982; L(Test): 0.24644319713115692\n",
      "Epoch 2071/10000: L(Train): 0.2657221257686615; L(Test): 0.2461223006248474\n",
      "Epoch 2072/10000: L(Train): 0.26956072449684143; L(Test): 0.2463211566209793\n",
      "Epoch 2073/10000: L(Train): 0.2555597424507141; L(Test): 0.24655693769454956\n",
      "Epoch 2074/10000: L(Train): 0.26489803194999695; L(Test): 0.24726229906082153\n",
      "Epoch 2075/10000: L(Train): 0.28120535612106323; L(Test): 0.24639646708965302\n",
      "Epoch 2076/10000: L(Train): 0.26102763414382935; L(Test): 0.24650584161281586\n",
      "Epoch 2077/10000: L(Train): 0.2606361210346222; L(Test): 0.24589486420154572\n",
      "Epoch 2078/10000: L(Train): 0.2612682282924652; L(Test): 0.2473454624414444\n",
      "Epoch 2079/10000: L(Train): 0.2791987955570221; L(Test): 0.2456788718700409\n",
      "Epoch 2080/10000: L(Train): 0.2654646337032318; L(Test): 0.24631039798259735\n",
      "Epoch 2081/10000: L(Train): 0.2629525065422058; L(Test): 0.2461555153131485\n",
      "Epoch 2082/10000: L(Train): 0.27068209648132324; L(Test): 0.24669887125492096\n",
      "Epoch 2083/10000: L(Train): 0.2772870361804962; L(Test): 0.24632324278354645\n",
      "Epoch 2084/10000: L(Train): 0.254569947719574; L(Test): 0.24558675289154053\n",
      "Epoch 2085/10000: L(Train): 0.27341294288635254; L(Test): 0.245771586894989\n",
      "Epoch 2086/10000: L(Train): 0.2753039598464966; L(Test): 0.2464381903409958\n",
      "Epoch 2087/10000: L(Train): 0.25954368710517883; L(Test): 0.246125265955925\n",
      "Epoch 2088/10000: L(Train): 0.2633216679096222; L(Test): 0.2459959089756012\n",
      "Epoch 2089/10000: L(Train): 0.25772690773010254; L(Test): 0.24623322486877441\n",
      "Epoch 2090/10000: L(Train): 0.27321553230285645; L(Test): 0.24671219289302826\n",
      "Epoch 2091/10000: L(Train): 0.27959463000297546; L(Test): 0.24623550474643707\n",
      "Epoch 2092/10000: L(Train): 0.2666337490081787; L(Test): 0.24674226343631744\n",
      "Epoch 2093/10000: L(Train): 0.26329541206359863; L(Test): 0.24828849732875824\n",
      "Epoch 2094/10000: L(Train): 0.26692959666252136; L(Test): 0.24898219108581543\n",
      "Epoch 2095/10000: L(Train): 0.2788449823856354; L(Test): 0.24859419465065002\n",
      "Epoch 2096/10000: L(Train): 0.2804705798625946; L(Test): 0.24716973304748535\n",
      "Epoch 2097/10000: L(Train): 0.25275173783302307; L(Test): 0.24682727456092834\n",
      "Epoch 2098/10000: L(Train): 0.2702835500240326; L(Test): 0.24708789587020874\n",
      "Epoch 2099/10000: L(Train): 0.2608550786972046; L(Test): 0.24727632105350494\n",
      "Epoch 2100/10000: L(Train): 0.2686709463596344; L(Test): 0.24768683314323425\n",
      "Epoch 2101/10000: L(Train): 0.27544793486595154; L(Test): 0.24704958498477936\n",
      "Epoch 2102/10000: L(Train): 0.25320249795913696; L(Test): 0.24859009683132172\n",
      "Epoch 2103/10000: L(Train): 0.26476603746414185; L(Test): 0.24807310104370117\n",
      "Epoch 2104/10000: L(Train): 0.28441324830055237; L(Test): 0.24863402545452118\n",
      "Epoch 2105/10000: L(Train): 0.27637046575546265; L(Test): 0.248703271150589\n",
      "Epoch 2106/10000: L(Train): 0.24104982614517212; L(Test): 0.251771479845047\n",
      "Epoch 2107/10000: L(Train): 0.28750142455101013; L(Test): 0.24880768358707428\n",
      "Epoch 2108/10000: L(Train): 0.26712101697921753; L(Test): 0.2500397264957428\n",
      "Epoch 2109/10000: L(Train): 0.267580509185791; L(Test): 0.2501148581504822\n",
      "Epoch 2110/10000: L(Train): 0.2825545072555542; L(Test): 0.25169190764427185\n",
      "Epoch 2111/10000: L(Train): 0.26855164766311646; L(Test): 0.24863789975643158\n",
      "Epoch 2112/10000: L(Train): 0.28000688552856445; L(Test): 0.2512696087360382\n",
      "Epoch 2113/10000: L(Train): 0.27634552121162415; L(Test): 0.2514650225639343\n",
      "Epoch 2114/10000: L(Train): 0.26633739471435547; L(Test): 0.25185802578926086\n",
      "Epoch 2115/10000: L(Train): 0.2607711851596832; L(Test): 0.2552817165851593\n",
      "Epoch 2116/10000: L(Train): 0.29548901319503784; L(Test): 0.25155237317085266\n",
      "Epoch 2117/10000: L(Train): 0.25692906975746155; L(Test): 0.25162532925605774\n",
      "Epoch 2118/10000: L(Train): 0.2647489607334137; L(Test): 0.2509758174419403\n",
      "Epoch 2119/10000: L(Train): 0.2777331471443176; L(Test): 0.25248852372169495\n",
      "Epoch 2120/10000: L(Train): 0.26717260479927063; L(Test): 0.25106313824653625\n",
      "Epoch 2121/10000: L(Train): 0.2819102108478546; L(Test): 0.25316372513771057\n",
      "Epoch 2122/10000: L(Train): 0.2937996983528137; L(Test): 0.2519181966781616\n",
      "Epoch 2123/10000: L(Train): 0.27140992879867554; L(Test): 0.2506392300128937\n",
      "Epoch 2124/10000: L(Train): 0.27259090542793274; L(Test): 0.25426846742630005\n",
      "Epoch 2125/10000: L(Train): 0.28545042872428894; L(Test): 0.25119978189468384\n",
      "Epoch 2126/10000: L(Train): 0.271828830242157; L(Test): 0.25152871012687683\n",
      "Epoch 2127/10000: L(Train): 0.27635079622268677; L(Test): 0.25049468874931335\n",
      "Epoch 2128/10000: L(Train): 0.2677345871925354; L(Test): 0.2533663809299469\n",
      "Epoch 2129/10000: L(Train): 0.28771504759788513; L(Test): 0.2537415027618408\n",
      "Epoch 2130/10000: L(Train): 0.2772757112979889; L(Test): 0.25001630187034607\n",
      "Epoch 2131/10000: L(Train): 0.2674669921398163; L(Test): 0.2507131099700928\n",
      "Epoch 2132/10000: L(Train): 0.2749970853328705; L(Test): 0.2503047287464142\n",
      "Epoch 2133/10000: L(Train): 0.26387450098991394; L(Test): 0.2523084282875061\n",
      "Epoch 2134/10000: L(Train): 0.2655741572380066; L(Test): 0.25039392709732056\n",
      "Epoch 2135/10000: L(Train): 0.26025936007499695; L(Test): 0.25053805112838745\n",
      "Epoch 2136/10000: L(Train): 0.26445624232292175; L(Test): 0.24857529997825623\n",
      "Epoch 2137/10000: L(Train): 0.2797616124153137; L(Test): 0.24773246049880981\n",
      "Epoch 2138/10000: L(Train): 0.26186618208885193; L(Test): 0.24901241064071655\n",
      "Epoch 2139/10000: L(Train): 0.2719777226448059; L(Test): 0.24797675013542175\n",
      "Epoch 2140/10000: L(Train): 0.2803497016429901; L(Test): 0.24748454988002777\n",
      "Epoch 2141/10000: L(Train): 0.2816190719604492; L(Test): 0.24724969267845154\n",
      "Epoch 2142/10000: L(Train): 0.2640075385570526; L(Test): 0.24721750617027283\n",
      "Epoch 2143/10000: L(Train): 0.26700299978256226; L(Test): 0.2490500658750534\n",
      "Epoch 2144/10000: L(Train): 0.270459920167923; L(Test): 0.24733930826187134\n",
      "Epoch 2145/10000: L(Train): 0.2528262436389923; L(Test): 0.24763919413089752\n",
      "Epoch 2146/10000: L(Train): 0.27014249563217163; L(Test): 0.24659055471420288\n",
      "Epoch 2147/10000: L(Train): 0.2693783938884735; L(Test): 0.24709299206733704\n",
      "Epoch 2148/10000: L(Train): 0.26378363370895386; L(Test): 0.2474641054868698\n",
      "Epoch 2149/10000: L(Train): 0.28501009941101074; L(Test): 0.24709589779376984\n",
      "Epoch 2150/10000: L(Train): 0.27254512906074524; L(Test): 0.24644140899181366\n",
      "Epoch 2151/10000: L(Train): 0.27645063400268555; L(Test): 0.24705635011196136\n",
      "Epoch 2152/10000: L(Train): 0.26770326495170593; L(Test): 0.2460935264825821\n",
      "Epoch 2153/10000: L(Train): 0.2511635422706604; L(Test): 0.24548481404781342\n",
      "Epoch 2154/10000: L(Train): 0.2620835304260254; L(Test): 0.24570980668067932\n",
      "Epoch 2155/10000: L(Train): 0.27979132533073425; L(Test): 0.24530360102653503\n",
      "Epoch 2156/10000: L(Train): 0.2641954720020294; L(Test): 0.24655050039291382\n",
      "Epoch 2157/10000: L(Train): 0.25691652297973633; L(Test): 0.24652308225631714\n",
      "Epoch 2158/10000: L(Train): 0.259852796792984; L(Test): 0.24631650745868683\n",
      "Epoch 2159/10000: L(Train): 0.260139524936676; L(Test): 0.24734479188919067\n",
      "Epoch 2160/10000: L(Train): 0.2675851881504059; L(Test): 0.2456996589899063\n",
      "Epoch 2161/10000: L(Train): 0.2718311846256256; L(Test): 0.24722595512866974\n",
      "Epoch 2162/10000: L(Train): 0.2618366479873657; L(Test): 0.24688488245010376\n",
      "Epoch 2163/10000: L(Train): 0.2778327465057373; L(Test): 0.24616825580596924\n",
      "Epoch 2164/10000: L(Train): 0.2580172121524811; L(Test): 0.24821721017360687\n",
      "Epoch 2165/10000: L(Train): 0.278871089220047; L(Test): 0.24675853550434113\n",
      "Epoch 2166/10000: L(Train): 0.2665635645389557; L(Test): 0.24754005670547485\n",
      "Epoch 2167/10000: L(Train): 0.2617477476596832; L(Test): 0.25012093782424927\n",
      "Epoch 2168/10000: L(Train): 0.27455851435661316; L(Test): 0.246781587600708\n",
      "Epoch 2169/10000: L(Train): 0.26179277896881104; L(Test): 0.24872252345085144\n",
      "Epoch 2170/10000: L(Train): 0.2705913782119751; L(Test): 0.24790211021900177\n",
      "Epoch 2171/10000: L(Train): 0.24403543770313263; L(Test): 0.24746572971343994\n",
      "Epoch 2172/10000: L(Train): 0.2572273910045624; L(Test): 0.24685050547122955\n",
      "Epoch 2173/10000: L(Train): 0.262592613697052; L(Test): 0.24763740599155426\n",
      "Epoch 2174/10000: L(Train): 0.25538673996925354; L(Test): 0.24682731926441193\n",
      "Epoch 2175/10000: L(Train): 0.25993070006370544; L(Test): 0.2480638474225998\n",
      "Epoch 2176/10000: L(Train): 0.2652049958705902; L(Test): 0.24929280579090118\n",
      "Epoch 2177/10000: L(Train): 0.27349019050598145; L(Test): 0.2464304119348526\n",
      "Epoch 2178/10000: L(Train): 0.25474756956100464; L(Test): 0.24652303755283356\n",
      "Epoch 2179/10000: L(Train): 0.255707710981369; L(Test): 0.2471957504749298\n",
      "Epoch 2180/10000: L(Train): 0.2758314609527588; L(Test): 0.24695315957069397\n",
      "Epoch 2181/10000: L(Train): 0.28131869435310364; L(Test): 0.24647071957588196\n",
      "Epoch 2182/10000: L(Train): 0.2643592655658722; L(Test): 0.24587221443653107\n",
      "Epoch 2183/10000: L(Train): 0.25403839349746704; L(Test): 0.2466849535703659\n",
      "Epoch 2184/10000: L(Train): 0.274318128824234; L(Test): 0.24817976355552673\n",
      "Epoch 2185/10000: L(Train): 0.264581561088562; L(Test): 0.24823704361915588\n",
      "Epoch 2186/10000: L(Train): 0.276175856590271; L(Test): 0.24919095635414124\n",
      "Epoch 2187/10000: L(Train): 0.27519547939300537; L(Test): 0.24918480217456818\n",
      "Epoch 2188/10000: L(Train): 0.27266764640808105; L(Test): 0.24816323816776276\n",
      "Epoch 2189/10000: L(Train): 0.267230749130249; L(Test): 0.24849161505699158\n",
      "Epoch 2190/10000: L(Train): 0.2758103609085083; L(Test): 0.2475220263004303\n",
      "Epoch 2191/10000: L(Train): 0.2786041796207428; L(Test): 0.2473185807466507\n",
      "Epoch 2192/10000: L(Train): 0.24803218245506287; L(Test): 0.2508019804954529\n",
      "Epoch 2193/10000: L(Train): 0.27410832047462463; L(Test): 0.25026679039001465\n",
      "Epoch 2194/10000: L(Train): 0.27246952056884766; L(Test): 0.24886029958724976\n",
      "Epoch 2195/10000: L(Train): 0.2687968313694; L(Test): 0.24820269644260406\n",
      "Epoch 2196/10000: L(Train): 0.2845085859298706; L(Test): 0.2499133050441742\n",
      "Epoch 2197/10000: L(Train): 0.270144522190094; L(Test): 0.24805773794651031\n",
      "Epoch 2198/10000: L(Train): 0.26872551441192627; L(Test): 0.24784229695796967\n",
      "Epoch 2199/10000: L(Train): 0.24546757340431213; L(Test): 0.24885743856430054\n",
      "Epoch 2200/10000: L(Train): 0.2775910198688507; L(Test): 0.24761809408664703\n",
      "Epoch 2201/10000: L(Train): 0.2749813199043274; L(Test): 0.2474851906299591\n",
      "Epoch 2202/10000: L(Train): 0.27149105072021484; L(Test): 0.24767984449863434\n",
      "Epoch 2203/10000: L(Train): 0.2786032557487488; L(Test): 0.24629679322242737\n",
      "Epoch 2204/10000: L(Train): 0.25006431341171265; L(Test): 0.2467639297246933\n",
      "Epoch 2205/10000: L(Train): 0.2639930844306946; L(Test): 0.24807286262512207\n",
      "Epoch 2206/10000: L(Train): 0.28307634592056274; L(Test): 0.24737216532230377\n",
      "Epoch 2207/10000: L(Train): 0.2638205885887146; L(Test): 0.2477937787771225\n",
      "Epoch 2208/10000: L(Train): 0.2755603790283203; L(Test): 0.2484632432460785\n",
      "Epoch 2209/10000: L(Train): 0.25479841232299805; L(Test): 0.24790164828300476\n",
      "Epoch 2210/10000: L(Train): 0.2697731852531433; L(Test): 0.24857722222805023\n",
      "Epoch 2211/10000: L(Train): 0.2655145823955536; L(Test): 0.2487432062625885\n",
      "Epoch 2212/10000: L(Train): 0.2653287947177887; L(Test): 0.24723000824451447\n",
      "Epoch 2213/10000: L(Train): 0.281673401594162; L(Test): 0.24566319584846497\n",
      "Epoch 2214/10000: L(Train): 0.2654329538345337; L(Test): 0.2456522285938263\n",
      "Epoch 2215/10000: L(Train): 0.28517240285873413; L(Test): 0.24628786742687225\n",
      "Epoch 2216/10000: L(Train): 0.25865042209625244; L(Test): 0.24657553434371948\n",
      "Epoch 2217/10000: L(Train): 0.26302918791770935; L(Test): 0.246183842420578\n",
      "Epoch 2218/10000: L(Train): 0.2789907157421112; L(Test): 0.2468077540397644\n",
      "Epoch 2219/10000: L(Train): 0.2587797939777374; L(Test): 0.2468486726284027\n",
      "Epoch 2220/10000: L(Train): 0.26564571261405945; L(Test): 0.24611546099185944\n",
      "Epoch 2221/10000: L(Train): 0.28044527769088745; L(Test): 0.24684041738510132\n",
      "Epoch 2222/10000: L(Train): 0.2592296302318573; L(Test): 0.24703843891620636\n",
      "Epoch 2223/10000: L(Train): 0.2750835418701172; L(Test): 0.24602174758911133\n",
      "Epoch 2224/10000: L(Train): 0.27336370944976807; L(Test): 0.2467336505651474\n",
      "Epoch 2225/10000: L(Train): 0.2605791985988617; L(Test): 0.24951598048210144\n",
      "Epoch 2226/10000: L(Train): 0.27726855874061584; L(Test): 0.24837692081928253\n",
      "Epoch 2227/10000: L(Train): 0.28189417719841003; L(Test): 0.24685531854629517\n",
      "Epoch 2228/10000: L(Train): 0.2763398289680481; L(Test): 0.2478308379650116\n",
      "Epoch 2229/10000: L(Train): 0.26300156116485596; L(Test): 0.24704143404960632\n",
      "Epoch 2230/10000: L(Train): 0.2665160298347473; L(Test): 0.24822673201560974\n",
      "Epoch 2231/10000: L(Train): 0.26732245087623596; L(Test): 0.24872323870658875\n",
      "Epoch 2232/10000: L(Train): 0.2865481376647949; L(Test): 0.249298557639122\n",
      "Epoch 2233/10000: L(Train): 0.27008169889450073; L(Test): 0.24764978885650635\n",
      "Epoch 2234/10000: L(Train): 0.26451098918914795; L(Test): 0.2505102753639221\n",
      "Epoch 2235/10000: L(Train): 0.2702007591724396; L(Test): 0.24909014999866486\n",
      "Epoch 2236/10000: L(Train): 0.28160208463668823; L(Test): 0.24854804575443268\n",
      "Epoch 2237/10000: L(Train): 0.26649826765060425; L(Test): 0.25116389989852905\n",
      "Epoch 2238/10000: L(Train): 0.2600913345813751; L(Test): 0.2506515681743622\n",
      "Epoch 2239/10000: L(Train): 0.2591951787471771; L(Test): 0.24898353219032288\n",
      "Epoch 2240/10000: L(Train): 0.2617337107658386; L(Test): 0.2511869966983795\n",
      "Epoch 2241/10000: L(Train): 0.270564466714859; L(Test): 0.24930782616138458\n",
      "Epoch 2242/10000: L(Train): 0.26055845618247986; L(Test): 0.24954624474048615\n",
      "Epoch 2243/10000: L(Train): 0.2852379381656647; L(Test): 0.24970869719982147\n",
      "Epoch 2244/10000: L(Train): 0.251740038394928; L(Test): 0.25144484639167786\n",
      "Epoch 2245/10000: L(Train): 0.27031227946281433; L(Test): 0.2513926029205322\n",
      "Epoch 2246/10000: L(Train): 0.2901041507720947; L(Test): 0.25032439827919006\n",
      "Epoch 2247/10000: L(Train): 0.2830524146556854; L(Test): 0.25128135085105896\n",
      "Epoch 2248/10000: L(Train): 0.27090638875961304; L(Test): 0.25359001755714417\n",
      "Epoch 2249/10000: L(Train): 0.26511242985725403; L(Test): 0.2509320080280304\n",
      "Epoch 2250/10000: L(Train): 0.26615002751350403; L(Test): 0.24823126196861267\n",
      "Epoch 2251/10000: L(Train): 0.25795939564704895; L(Test): 0.24999649822711945\n",
      "Epoch 2252/10000: L(Train): 0.26820817589759827; L(Test): 0.2491735965013504\n",
      "Epoch 2253/10000: L(Train): 0.27337968349456787; L(Test): 0.24931462109088898\n",
      "Epoch 2254/10000: L(Train): 0.2678576111793518; L(Test): 0.25268590450286865\n",
      "Epoch 2255/10000: L(Train): 0.266594260931015; L(Test): 0.2523494064807892\n",
      "Epoch 2256/10000: L(Train): 0.2786332964897156; L(Test): 0.2493596374988556\n",
      "Epoch 2257/10000: L(Train): 0.2788166105747223; L(Test): 0.2504946291446686\n",
      "Epoch 2258/10000: L(Train): 0.2637780010700226; L(Test): 0.25035127997398376\n",
      "Epoch 2259/10000: L(Train): 0.26402050256729126; L(Test): 0.25115731358528137\n",
      "Epoch 2260/10000: L(Train): 0.2665797173976898; L(Test): 0.24848820269107819\n",
      "Epoch 2261/10000: L(Train): 0.27182936668395996; L(Test): 0.2496466189622879\n",
      "Epoch 2262/10000: L(Train): 0.2825626730918884; L(Test): 0.24987918138504028\n",
      "Epoch 2263/10000: L(Train): 0.26813942193984985; L(Test): 0.24928642809391022\n",
      "Epoch 2264/10000: L(Train): 0.27199941873550415; L(Test): 0.24916189908981323\n",
      "Epoch 2265/10000: L(Train): 0.27804312109947205; L(Test): 0.24742382764816284\n",
      "Epoch 2266/10000: L(Train): 0.25710126757621765; L(Test): 0.24779744446277618\n",
      "Epoch 2267/10000: L(Train): 0.26330602169036865; L(Test): 0.24763068556785583\n",
      "Epoch 2268/10000: L(Train): 0.2718157172203064; L(Test): 0.2510300278663635\n",
      "Epoch 2269/10000: L(Train): 0.25985535979270935; L(Test): 0.2477612942457199\n",
      "Epoch 2270/10000: L(Train): 0.27606403827667236; L(Test): 0.24837900698184967\n",
      "Epoch 2271/10000: L(Train): 0.2781841456890106; L(Test): 0.24684520065784454\n",
      "Epoch 2272/10000: L(Train): 0.27753975987434387; L(Test): 0.24684907495975494\n",
      "Epoch 2273/10000: L(Train): 0.27678024768829346; L(Test): 0.24798941612243652\n",
      "Epoch 2274/10000: L(Train): 0.26307442784309387; L(Test): 0.24687208235263824\n",
      "Epoch 2275/10000: L(Train): 0.26852425932884216; L(Test): 0.24628446996212006\n",
      "Epoch 2276/10000: L(Train): 0.2780357301235199; L(Test): 0.24634303152561188\n",
      "Epoch 2277/10000: L(Train): 0.24771754443645477; L(Test): 0.24605999886989594\n",
      "Epoch 2278/10000: L(Train): 0.2631026804447174; L(Test): 0.2470771223306656\n",
      "Epoch 2279/10000: L(Train): 0.2711077630519867; L(Test): 0.2465411275625229\n",
      "Epoch 2280/10000: L(Train): 0.27053698897361755; L(Test): 0.24620305001735687\n",
      "Epoch 2281/10000: L(Train): 0.2633969783782959; L(Test): 0.24593709409236908\n",
      "Epoch 2282/10000: L(Train): 0.2632499635219574; L(Test): 0.24624259769916534\n",
      "Epoch 2283/10000: L(Train): 0.26584798097610474; L(Test): 0.24587801098823547\n",
      "Epoch 2284/10000: L(Train): 0.2634623348712921; L(Test): 0.2460656762123108\n",
      "Epoch 2285/10000: L(Train): 0.2736133337020874; L(Test): 0.24633841216564178\n",
      "Epoch 2286/10000: L(Train): 0.2674766480922699; L(Test): 0.24556981027126312\n",
      "Epoch 2287/10000: L(Train): 0.2698967158794403; L(Test): 0.24597077071666718\n",
      "Epoch 2288/10000: L(Train): 0.27847743034362793; L(Test): 0.24599719047546387\n",
      "Epoch 2289/10000: L(Train): 0.27008628845214844; L(Test): 0.24520058929920197\n",
      "Epoch 2290/10000: L(Train): 0.27264463901519775; L(Test): 0.24589446187019348\n",
      "Epoch 2291/10000: L(Train): 0.28964483737945557; L(Test): 0.24697527289390564\n",
      "Epoch 2292/10000: L(Train): 0.26339632272720337; L(Test): 0.24575082957744598\n",
      "Epoch 2293/10000: L(Train): 0.27173927426338196; L(Test): 0.2461945116519928\n",
      "Epoch 2294/10000: L(Train): 0.2767527997493744; L(Test): 0.2460641860961914\n",
      "Epoch 2295/10000: L(Train): 0.26144930720329285; L(Test): 0.24714061617851257\n",
      "Epoch 2296/10000: L(Train): 0.2800125777721405; L(Test): 0.24669504165649414\n",
      "Epoch 2297/10000: L(Train): 0.26648566126823425; L(Test): 0.24622276425361633\n",
      "Epoch 2298/10000: L(Train): 0.27090179920196533; L(Test): 0.24622447788715363\n",
      "Epoch 2299/10000: L(Train): 0.2713186740875244; L(Test): 0.24596045911312103\n",
      "Epoch 2300/10000: L(Train): 0.27088072896003723; L(Test): 0.2474295198917389\n",
      "Epoch 2301/10000: L(Train): 0.26229825615882874; L(Test): 0.24587756395339966\n",
      "Epoch 2302/10000: L(Train): 0.2726477384567261; L(Test): 0.2458571344614029\n",
      "Epoch 2303/10000: L(Train): 0.27646735310554504; L(Test): 0.2466774582862854\n",
      "Epoch 2304/10000: L(Train): 0.2796565294265747; L(Test): 0.2461303025484085\n",
      "Epoch 2305/10000: L(Train): 0.2613801062107086; L(Test): 0.24616184830665588\n",
      "Epoch 2306/10000: L(Train): 0.27530989050865173; L(Test): 0.24807220697402954\n",
      "Epoch 2307/10000: L(Train): 0.2618388831615448; L(Test): 0.2467624545097351\n",
      "Epoch 2308/10000: L(Train): 0.2615244388580322; L(Test): 0.24658089876174927\n",
      "Epoch 2309/10000: L(Train): 0.27631905674934387; L(Test): 0.24636797606945038\n",
      "Epoch 2310/10000: L(Train): 0.26799988746643066; L(Test): 0.24643157422542572\n",
      "Epoch 2311/10000: L(Train): 0.27049797773361206; L(Test): 0.24674251675605774\n",
      "Epoch 2312/10000: L(Train): 0.27900704741477966; L(Test): 0.24597883224487305\n",
      "Epoch 2313/10000: L(Train): 0.2698777914047241; L(Test): 0.24554921686649323\n",
      "Epoch 2314/10000: L(Train): 0.27134233713150024; L(Test): 0.24575017392635345\n",
      "Epoch 2315/10000: L(Train): 0.26446405053138733; L(Test): 0.24570947885513306\n",
      "Epoch 2316/10000: L(Train): 0.27122819423675537; L(Test): 0.24505995213985443\n",
      "Epoch 2317/10000: L(Train): 0.26229608058929443; L(Test): 0.24553684890270233\n",
      "Epoch 2318/10000: L(Train): 0.2638912498950958; L(Test): 0.24640433490276337\n",
      "Epoch 2319/10000: L(Train): 0.26734673976898193; L(Test): 0.24579238891601562\n",
      "Epoch 2320/10000: L(Train): 0.25680550932884216; L(Test): 0.2455247938632965\n",
      "Epoch 2321/10000: L(Train): 0.27159154415130615; L(Test): 0.2455555498600006\n",
      "Epoch 2322/10000: L(Train): 0.2723318636417389; L(Test): 0.2452237755060196\n",
      "Epoch 2323/10000: L(Train): 0.2725851535797119; L(Test): 0.24615797400474548\n",
      "Epoch 2324/10000: L(Train): 0.2617197632789612; L(Test): 0.246817946434021\n",
      "Epoch 2325/10000: L(Train): 0.26542237401008606; L(Test): 0.24673040211200714\n",
      "Epoch 2326/10000: L(Train): 0.2782413363456726; L(Test): 0.24565769731998444\n",
      "Epoch 2327/10000: L(Train): 0.26523450016975403; L(Test): 0.24692870676517487\n",
      "Epoch 2328/10000: L(Train): 0.2941945493221283; L(Test): 0.2459079623222351\n",
      "Epoch 2329/10000: L(Train): 0.2745337188243866; L(Test): 0.24628351628780365\n",
      "Epoch 2330/10000: L(Train): 0.26058876514434814; L(Test): 0.24571749567985535\n",
      "Epoch 2331/10000: L(Train): 0.25933876633644104; L(Test): 0.2456960380077362\n",
      "Epoch 2332/10000: L(Train): 0.2640245854854584; L(Test): 0.24478374421596527\n",
      "Epoch 2333/10000: L(Train): 0.2748153507709503; L(Test): 0.2469417154788971\n",
      "Epoch 2334/10000: L(Train): 0.24839337170124054; L(Test): 0.2471981793642044\n",
      "Epoch 2335/10000: L(Train): 0.2776079773902893; L(Test): 0.24613821506500244\n",
      "Epoch 2336/10000: L(Train): 0.2623448669910431; L(Test): 0.24743187427520752\n",
      "Epoch 2337/10000: L(Train): 0.2618538439273834; L(Test): 0.24657589197158813\n",
      "Epoch 2338/10000: L(Train): 0.2695629298686981; L(Test): 0.2470637559890747\n",
      "Epoch 2339/10000: L(Train): 0.2684958577156067; L(Test): 0.24682526290416718\n",
      "Epoch 2340/10000: L(Train): 0.25377437472343445; L(Test): 0.24673014879226685\n",
      "Epoch 2341/10000: L(Train): 0.2741531431674957; L(Test): 0.24571427702903748\n",
      "Epoch 2342/10000: L(Train): 0.27372175455093384; L(Test): 0.2481447458267212\n",
      "Epoch 2343/10000: L(Train): 0.26227548718452454; L(Test): 0.2475137561559677\n",
      "Epoch 2344/10000: L(Train): 0.2784903943538666; L(Test): 0.24874469637870789\n",
      "Epoch 2345/10000: L(Train): 0.27930954098701477; L(Test): 0.2481268048286438\n",
      "Epoch 2346/10000: L(Train): 0.26847904920578003; L(Test): 0.24689504504203796\n",
      "Epoch 2347/10000: L(Train): 0.26996418833732605; L(Test): 0.24860362708568573\n",
      "Epoch 2348/10000: L(Train): 0.2692515552043915; L(Test): 0.248651385307312\n",
      "Epoch 2349/10000: L(Train): 0.27443718910217285; L(Test): 0.24849645793437958\n",
      "Epoch 2350/10000: L(Train): 0.27757230401039124; L(Test): 0.2482828050851822\n",
      "Epoch 2351/10000: L(Train): 0.26140180230140686; L(Test): 0.24768847227096558\n",
      "Epoch 2352/10000: L(Train): 0.2711371183395386; L(Test): 0.24909420311450958\n",
      "Epoch 2353/10000: L(Train): 0.2758643627166748; L(Test): 0.24715693295001984\n",
      "Epoch 2354/10000: L(Train): 0.2593532204627991; L(Test): 0.24740079045295715\n",
      "Epoch 2355/10000: L(Train): 0.27241674065589905; L(Test): 0.24630406498908997\n",
      "Epoch 2356/10000: L(Train): 0.2648869752883911; L(Test): 0.2484510987997055\n",
      "Epoch 2357/10000: L(Train): 0.2653416693210602; L(Test): 0.24734173715114594\n",
      "Epoch 2358/10000: L(Train): 0.2643702030181885; L(Test): 0.2468523234128952\n",
      "Epoch 2359/10000: L(Train): 0.27295488119125366; L(Test): 0.24720245599746704\n",
      "Epoch 2360/10000: L(Train): 0.268187940120697; L(Test): 0.2459777444601059\n",
      "Epoch 2361/10000: L(Train): 0.26087766885757446; L(Test): 0.24681875109672546\n",
      "Epoch 2362/10000: L(Train): 0.26250436902046204; L(Test): 0.24622412025928497\n",
      "Epoch 2363/10000: L(Train): 0.25652480125427246; L(Test): 0.24625876545906067\n",
      "Epoch 2364/10000: L(Train): 0.2694927155971527; L(Test): 0.24621568620204926\n",
      "Epoch 2365/10000: L(Train): 0.2570991516113281; L(Test): 0.24577294290065765\n",
      "Epoch 2366/10000: L(Train): 0.2616765797138214; L(Test): 0.2454751580953598\n",
      "Epoch 2367/10000: L(Train): 0.2564734220504761; L(Test): 0.24643830955028534\n",
      "Epoch 2368/10000: L(Train): 0.2685597240924835; L(Test): 0.24662864208221436\n",
      "Epoch 2369/10000: L(Train): 0.2692747116088867; L(Test): 0.24574148654937744\n",
      "Epoch 2370/10000: L(Train): 0.2533052861690521; L(Test): 0.24669058620929718\n",
      "Epoch 2371/10000: L(Train): 0.2620408833026886; L(Test): 0.24730776250362396\n",
      "Epoch 2372/10000: L(Train): 0.2643638849258423; L(Test): 0.24632622301578522\n",
      "Epoch 2373/10000: L(Train): 0.2610940933227539; L(Test): 0.2463933378458023\n",
      "Epoch 2374/10000: L(Train): 0.2521064579486847; L(Test): 0.24566157162189484\n",
      "Epoch 2375/10000: L(Train): 0.2624967396259308; L(Test): 0.24564135074615479\n",
      "Epoch 2376/10000: L(Train): 0.2691507935523987; L(Test): 0.2463759332895279\n",
      "Epoch 2377/10000: L(Train): 0.26621994376182556; L(Test): 0.24493730068206787\n",
      "Epoch 2378/10000: L(Train): 0.2603704631328583; L(Test): 0.24492040276527405\n",
      "Epoch 2379/10000: L(Train): 0.2723921537399292; L(Test): 0.24485154449939728\n",
      "Epoch 2380/10000: L(Train): 0.25626397132873535; L(Test): 0.24521364271640778\n",
      "Epoch 2381/10000: L(Train): 0.27515146136283875; L(Test): 0.24483703076839447\n",
      "Epoch 2382/10000: L(Train): 0.27020883560180664; L(Test): 0.24494163691997528\n",
      "Epoch 2383/10000: L(Train): 0.2624242901802063; L(Test): 0.24459624290466309\n",
      "Epoch 2384/10000: L(Train): 0.2700044810771942; L(Test): 0.24481450021266937\n",
      "Epoch 2385/10000: L(Train): 0.2726401388645172; L(Test): 0.24470005929470062\n",
      "Epoch 2386/10000: L(Train): 0.25609028339385986; L(Test): 0.24504883587360382\n",
      "Epoch 2387/10000: L(Train): 0.25737884640693665; L(Test): 0.24405808746814728\n",
      "Epoch 2388/10000: L(Train): 0.25897178053855896; L(Test): 0.24525633454322815\n",
      "Epoch 2389/10000: L(Train): 0.2643531262874603; L(Test): 0.24450775980949402\n",
      "Epoch 2390/10000: L(Train): 0.25817543268203735; L(Test): 0.24492037296295166\n",
      "Epoch 2391/10000: L(Train): 0.26705026626586914; L(Test): 0.244510218501091\n",
      "Epoch 2392/10000: L(Train): 0.26267755031585693; L(Test): 0.24416887760162354\n",
      "Epoch 2393/10000: L(Train): 0.27423912286758423; L(Test): 0.2441827356815338\n",
      "Epoch 2394/10000: L(Train): 0.2626452147960663; L(Test): 0.24452129006385803\n",
      "Epoch 2395/10000: L(Train): 0.2565917372703552; L(Test): 0.24541661143302917\n",
      "Epoch 2396/10000: L(Train): 0.2626081705093384; L(Test): 0.24574832618236542\n",
      "Epoch 2397/10000: L(Train): 0.2787741720676422; L(Test): 0.2483666092157364\n",
      "Epoch 2398/10000: L(Train): 0.2555983364582062; L(Test): 0.2524997889995575\n",
      "Epoch 2399/10000: L(Train): 0.2787325978279114; L(Test): 0.25184687972068787\n",
      "Epoch 2400/10000: L(Train): 0.2747553884983063; L(Test): 0.2526337504386902\n",
      "Epoch 2401/10000: L(Train): 0.28247344493865967; L(Test): 0.25268465280532837\n",
      "Epoch 2402/10000: L(Train): 0.27077701687812805; L(Test): 0.25100278854370117\n",
      "Epoch 2403/10000: L(Train): 0.27909547090530396; L(Test): 0.251330703496933\n",
      "Epoch 2404/10000: L(Train): 0.2788979411125183; L(Test): 0.24984276294708252\n",
      "Epoch 2405/10000: L(Train): 0.274053156375885; L(Test): 0.24983935058116913\n",
      "Epoch 2406/10000: L(Train): 0.2673775255680084; L(Test): 0.25118687748908997\n",
      "Epoch 2407/10000: L(Train): 0.2526790499687195; L(Test): 0.2521939277648926\n",
      "Epoch 2408/10000: L(Train): 0.26408571004867554; L(Test): 0.2522469460964203\n",
      "Epoch 2409/10000: L(Train): 0.27838313579559326; L(Test): 0.2503673732280731\n",
      "Epoch 2410/10000: L(Train): 0.277252733707428; L(Test): 0.25101038813591003\n",
      "Epoch 2411/10000: L(Train): 0.2663058936595917; L(Test): 0.2521952986717224\n",
      "Epoch 2412/10000: L(Train): 0.28449907898902893; L(Test): 0.25071483850479126\n",
      "Epoch 2413/10000: L(Train): 0.269786536693573; L(Test): 0.252332866191864\n",
      "Epoch 2414/10000: L(Train): 0.26020944118499756; L(Test): 0.2540969252586365\n",
      "Epoch 2415/10000: L(Train): 0.2780754864215851; L(Test): 0.2517165541648865\n",
      "Epoch 2416/10000: L(Train): 0.2790552079677582; L(Test): 0.25133204460144043\n",
      "Epoch 2417/10000: L(Train): 0.2664872705936432; L(Test): 0.252364844083786\n",
      "Epoch 2418/10000: L(Train): 0.28362324833869934; L(Test): 0.24923071265220642\n",
      "Epoch 2419/10000: L(Train): 0.2718559205532074; L(Test): 0.2503027021884918\n",
      "Epoch 2420/10000: L(Train): 0.26984724402427673; L(Test): 0.25059041380882263\n",
      "Epoch 2421/10000: L(Train): 0.2680107355117798; L(Test): 0.2494962215423584\n",
      "Epoch 2422/10000: L(Train): 0.26588571071624756; L(Test): 0.24875251948833466\n",
      "Epoch 2423/10000: L(Train): 0.2769305408000946; L(Test): 0.24778738617897034\n",
      "Epoch 2424/10000: L(Train): 0.2674106955528259; L(Test): 0.24746643006801605\n",
      "Epoch 2425/10000: L(Train): 0.26644474267959595; L(Test): 0.24808251857757568\n",
      "Epoch 2426/10000: L(Train): 0.2638837397098541; L(Test): 0.24763306975364685\n",
      "Epoch 2427/10000: L(Train): 0.2756550908088684; L(Test): 0.24651624262332916\n",
      "Epoch 2428/10000: L(Train): 0.26886293292045593; L(Test): 0.24658574163913727\n",
      "Epoch 2429/10000: L(Train): 0.28380101919174194; L(Test): 0.24627383053302765\n",
      "Epoch 2430/10000: L(Train): 0.2669800817966461; L(Test): 0.24650390446186066\n",
      "Epoch 2431/10000: L(Train): 0.2668013274669647; L(Test): 0.2465609908103943\n",
      "Epoch 2432/10000: L(Train): 0.25637415051460266; L(Test): 0.24619509279727936\n",
      "Epoch 2433/10000: L(Train): 0.2592531442642212; L(Test): 0.24583005905151367\n",
      "Epoch 2434/10000: L(Train): 0.25564372539520264; L(Test): 0.24544773995876312\n",
      "Epoch 2435/10000: L(Train): 0.26312747597694397; L(Test): 0.2457718551158905\n",
      "Epoch 2436/10000: L(Train): 0.2732204794883728; L(Test): 0.24559108912944794\n",
      "Epoch 2437/10000: L(Train): 0.27139896154403687; L(Test): 0.24538207054138184\n",
      "Epoch 2438/10000: L(Train): 0.26993438601493835; L(Test): 0.24493169784545898\n",
      "Epoch 2439/10000: L(Train): 0.28026002645492554; L(Test): 0.24455377459526062\n",
      "Epoch 2440/10000: L(Train): 0.2655428349971771; L(Test): 0.2452244609594345\n",
      "Epoch 2441/10000: L(Train): 0.27307236194610596; L(Test): 0.24530164897441864\n",
      "Epoch 2442/10000: L(Train): 0.2638394236564636; L(Test): 0.24463973939418793\n",
      "Epoch 2443/10000: L(Train): 0.27712318301200867; L(Test): 0.24425554275512695\n",
      "Epoch 2444/10000: L(Train): 0.25512152910232544; L(Test): 0.24489940702915192\n",
      "Epoch 2445/10000: L(Train): 0.26261529326438904; L(Test): 0.24511118233203888\n",
      "Epoch 2446/10000: L(Train): 0.26676586270332336; L(Test): 0.24563682079315186\n",
      "Epoch 2447/10000: L(Train): 0.26892659068107605; L(Test): 0.24503545463085175\n",
      "Epoch 2448/10000: L(Train): 0.25501808524131775; L(Test): 0.24528858065605164\n",
      "Epoch 2449/10000: L(Train): 0.27246642112731934; L(Test): 0.24538247287273407\n",
      "Epoch 2450/10000: L(Train): 0.2641167640686035; L(Test): 0.2449989914894104\n",
      "Epoch 2451/10000: L(Train): 0.26714056730270386; L(Test): 0.2460182011127472\n",
      "Epoch 2452/10000: L(Train): 0.27634960412979126; L(Test): 0.24662594497203827\n",
      "Epoch 2453/10000: L(Train): 0.27709734439849854; L(Test): 0.24611662328243256\n",
      "Epoch 2454/10000: L(Train): 0.2522348463535309; L(Test): 0.24700526893138885\n",
      "Epoch 2455/10000: L(Train): 0.25871822237968445; L(Test): 0.2456149309873581\n",
      "Epoch 2456/10000: L(Train): 0.2573542594909668; L(Test): 0.24604931473731995\n",
      "Epoch 2457/10000: L(Train): 0.26375821232795715; L(Test): 0.24668888747692108\n",
      "Epoch 2458/10000: L(Train): 0.2689594328403473; L(Test): 0.24735379219055176\n",
      "Epoch 2459/10000: L(Train): 0.26276567578315735; L(Test): 0.2451118379831314\n",
      "Epoch 2460/10000: L(Train): 0.27183327078819275; L(Test): 0.24707281589508057\n",
      "Epoch 2461/10000: L(Train): 0.2636449635028839; L(Test): 0.24498802423477173\n",
      "Epoch 2462/10000: L(Train): 0.2668432593345642; L(Test): 0.24565592408180237\n",
      "Epoch 2463/10000: L(Train): 0.261628657579422; L(Test): 0.24616090953350067\n",
      "Epoch 2464/10000: L(Train): 0.2636941969394684; L(Test): 0.24480292201042175\n",
      "Epoch 2465/10000: L(Train): 0.25627008080482483; L(Test): 0.24542932212352753\n",
      "Epoch 2466/10000: L(Train): 0.24877870082855225; L(Test): 0.24627715349197388\n",
      "Epoch 2467/10000: L(Train): 0.28032320737838745; L(Test): 0.2445637285709381\n",
      "Epoch 2468/10000: L(Train): 0.2597058415412903; L(Test): 0.24453453719615936\n",
      "Epoch 2469/10000: L(Train): 0.2678096890449524; L(Test): 0.24510188400745392\n",
      "Epoch 2470/10000: L(Train): 0.28719255328178406; L(Test): 0.24481850862503052\n",
      "Epoch 2471/10000: L(Train): 0.26778221130371094; L(Test): 0.24634285271167755\n",
      "Epoch 2472/10000: L(Train): 0.2575768828392029; L(Test): 0.24745607376098633\n",
      "Epoch 2473/10000: L(Train): 0.2620014250278473; L(Test): 0.24686481058597565\n",
      "Epoch 2474/10000: L(Train): 0.26615554094314575; L(Test): 0.2456403225660324\n",
      "Epoch 2475/10000: L(Train): 0.2532636225223541; L(Test): 0.2493533045053482\n",
      "Epoch 2476/10000: L(Train): 0.2736048698425293; L(Test): 0.2520407736301422\n",
      "Epoch 2477/10000: L(Train): 0.27745819091796875; L(Test): 0.25097891688346863\n",
      "Epoch 2478/10000: L(Train): 0.275566041469574; L(Test): 0.25097817182540894\n",
      "Epoch 2479/10000: L(Train): 0.26261016726493835; L(Test): 0.25239428877830505\n",
      "Epoch 2480/10000: L(Train): 0.2730485200881958; L(Test): 0.2504394054412842\n",
      "Epoch 2481/10000: L(Train): 0.2754409909248352; L(Test): 0.2507949471473694\n",
      "Epoch 2482/10000: L(Train): 0.26826211810112; L(Test): 0.2508237361907959\n",
      "Epoch 2483/10000: L(Train): 0.2629607319831848; L(Test): 0.2508620321750641\n",
      "Epoch 2484/10000: L(Train): 0.2589111328125; L(Test): 0.2502981722354889\n",
      "Epoch 2485/10000: L(Train): 0.2759157419204712; L(Test): 0.24919964373111725\n",
      "Epoch 2486/10000: L(Train): 0.2653563618659973; L(Test): 0.24975614249706268\n",
      "Epoch 2487/10000: L(Train): 0.2683578431606293; L(Test): 0.2491578757762909\n",
      "Epoch 2488/10000: L(Train): 0.27859145402908325; L(Test): 0.24867045879364014\n",
      "Epoch 2489/10000: L(Train): 0.2556074261665344; L(Test): 0.24829693138599396\n",
      "Epoch 2490/10000: L(Train): 0.2575543224811554; L(Test): 0.2485484629869461\n",
      "Epoch 2491/10000: L(Train): 0.276737779378891; L(Test): 0.24838154017925262\n",
      "Epoch 2492/10000: L(Train): 0.27985715866088867; L(Test): 0.24811363220214844\n",
      "Epoch 2493/10000: L(Train): 0.26947253942489624; L(Test): 0.24683994054794312\n",
      "Epoch 2494/10000: L(Train): 0.2696162462234497; L(Test): 0.25078773498535156\n",
      "Epoch 2495/10000: L(Train): 0.2642776668071747; L(Test): 0.2488321214914322\n",
      "Epoch 2496/10000: L(Train): 0.25486791133880615; L(Test): 0.250004380941391\n",
      "Epoch 2497/10000: L(Train): 0.26550543308258057; L(Test): 0.2511863112449646\n",
      "Epoch 2498/10000: L(Train): 0.2739142179489136; L(Test): 0.2513291537761688\n",
      "Epoch 2499/10000: L(Train): 0.27825382351875305; L(Test): 0.24906422197818756\n",
      "Epoch 2500/10000: L(Train): 0.26866698265075684; L(Test): 0.2486073225736618\n",
      "Epoch 2501/10000: L(Train): 0.2606354355812073; L(Test): 0.25024670362472534\n",
      "Epoch 2502/10000: L(Train): 0.2843998670578003; L(Test): 0.24992632865905762\n",
      "Epoch 2503/10000: L(Train): 0.25066283345222473; L(Test): 0.24880856275558472\n",
      "Epoch 2504/10000: L(Train): 0.2669313848018646; L(Test): 0.24939635396003723\n",
      "Epoch 2505/10000: L(Train): 0.27870479226112366; L(Test): 0.248960480093956\n",
      "Epoch 2506/10000: L(Train): 0.26620280742645264; L(Test): 0.2486666887998581\n",
      "Epoch 2507/10000: L(Train): 0.2677389681339264; L(Test): 0.24822813272476196\n",
      "Epoch 2508/10000: L(Train): 0.2589242458343506; L(Test): 0.24825720489025116\n",
      "Epoch 2509/10000: L(Train): 0.2805511951446533; L(Test): 0.24656876921653748\n",
      "Epoch 2510/10000: L(Train): 0.27230867743492126; L(Test): 0.24648581445217133\n",
      "Epoch 2511/10000: L(Train): 0.26936423778533936; L(Test): 0.2466142475605011\n",
      "Epoch 2512/10000: L(Train): 0.26249587535858154; L(Test): 0.24622775614261627\n",
      "Epoch 2513/10000: L(Train): 0.28137052059173584; L(Test): 0.2469179481267929\n",
      "Epoch 2514/10000: L(Train): 0.26620107889175415; L(Test): 0.24791809916496277\n",
      "Epoch 2515/10000: L(Train): 0.27498480677604675; L(Test): 0.24621589481830597\n",
      "Epoch 2516/10000: L(Train): 0.2695542573928833; L(Test): 0.2464812844991684\n",
      "Epoch 2517/10000: L(Train): 0.26864680647850037; L(Test): 0.2464158684015274\n",
      "Epoch 2518/10000: L(Train): 0.2684784531593323; L(Test): 0.2457311898469925\n",
      "Epoch 2519/10000: L(Train): 0.27396160364151; L(Test): 0.24637550115585327\n",
      "Epoch 2520/10000: L(Train): 0.2538253962993622; L(Test): 0.24676819145679474\n",
      "Epoch 2521/10000: L(Train): 0.2664795517921448; L(Test): 0.24554599821567535\n",
      "Epoch 2522/10000: L(Train): 0.2656690776348114; L(Test): 0.24515677988529205\n",
      "Epoch 2523/10000: L(Train): 0.2591312527656555; L(Test): 0.2450651228427887\n",
      "Epoch 2524/10000: L(Train): 0.27663612365722656; L(Test): 0.24505174160003662\n",
      "Epoch 2525/10000: L(Train): 0.2750532031059265; L(Test): 0.24479438364505768\n",
      "Epoch 2526/10000: L(Train): 0.2670622766017914; L(Test): 0.24679724872112274\n",
      "Epoch 2527/10000: L(Train): 0.273965984582901; L(Test): 0.24658161401748657\n",
      "Epoch 2528/10000: L(Train): 0.2712688446044922; L(Test): 0.24501895904541016\n",
      "Epoch 2529/10000: L(Train): 0.2773790657520294; L(Test): 0.24684442579746246\n",
      "Epoch 2530/10000: L(Train): 0.26637741923332214; L(Test): 0.24820049107074738\n",
      "Epoch 2531/10000: L(Train): 0.24854619801044464; L(Test): 0.2522412836551666\n",
      "Epoch 2532/10000: L(Train): 0.2717699408531189; L(Test): 0.24904444813728333\n",
      "Epoch 2533/10000: L(Train): 0.25634559988975525; L(Test): 0.2508934736251831\n",
      "Epoch 2534/10000: L(Train): 0.256073534488678; L(Test): 0.24851948022842407\n",
      "Epoch 2535/10000: L(Train): 0.2733711004257202; L(Test): 0.2516326308250427\n",
      "Epoch 2536/10000: L(Train): 0.2714907228946686; L(Test): 0.248827263712883\n",
      "Epoch 2537/10000: L(Train): 0.2596839368343353; L(Test): 0.24948731064796448\n",
      "Epoch 2538/10000: L(Train): 0.2669990360736847; L(Test): 0.25010934472084045\n",
      "Epoch 2539/10000: L(Train): 0.27121660113334656; L(Test): 0.24868594110012054\n",
      "Epoch 2540/10000: L(Train): 0.260747492313385; L(Test): 0.2512058615684509\n",
      "Epoch 2541/10000: L(Train): 0.2678495943546295; L(Test): 0.25021663308143616\n",
      "Epoch 2542/10000: L(Train): 0.2752971351146698; L(Test): 0.24905705451965332\n",
      "Epoch 2543/10000: L(Train): 0.2650497257709503; L(Test): 0.24858358502388\n",
      "Epoch 2544/10000: L(Train): 0.2682570815086365; L(Test): 0.24874155223369598\n",
      "Epoch 2545/10000: L(Train): 0.2711355686187744; L(Test): 0.24964162707328796\n",
      "Epoch 2546/10000: L(Train): 0.27591997385025024; L(Test): 0.24766317009925842\n",
      "Epoch 2547/10000: L(Train): 0.2714118957519531; L(Test): 0.24654094874858856\n",
      "Epoch 2548/10000: L(Train): 0.26102742552757263; L(Test): 0.24636948108673096\n",
      "Epoch 2549/10000: L(Train): 0.27125459909439087; L(Test): 0.24682073295116425\n",
      "Epoch 2550/10000: L(Train): 0.27100908756256104; L(Test): 0.2475367933511734\n",
      "Epoch 2551/10000: L(Train): 0.2692466080188751; L(Test): 0.2464563101530075\n",
      "Epoch 2552/10000: L(Train): 0.26800456643104553; L(Test): 0.24630320072174072\n",
      "Epoch 2553/10000: L(Train): 0.27250388264656067; L(Test): 0.24709904193878174\n",
      "Epoch 2554/10000: L(Train): 0.26418793201446533; L(Test): 0.24763749539852142\n",
      "Epoch 2555/10000: L(Train): 0.2580638825893402; L(Test): 0.24638082087039948\n",
      "Epoch 2556/10000: L(Train): 0.2700158953666687; L(Test): 0.2460898756980896\n",
      "Epoch 2557/10000: L(Train): 0.25832486152648926; L(Test): 0.24620628356933594\n",
      "Epoch 2558/10000: L(Train): 0.2617775797843933; L(Test): 0.24539169669151306\n",
      "Epoch 2559/10000: L(Train): 0.2732709050178528; L(Test): 0.2450590431690216\n",
      "Epoch 2560/10000: L(Train): 0.2563951313495636; L(Test): 0.24565273523330688\n",
      "Epoch 2561/10000: L(Train): 0.24723362922668457; L(Test): 0.24708865582942963\n",
      "Epoch 2562/10000: L(Train): 0.2757035493850708; L(Test): 0.24912011623382568\n",
      "Epoch 2563/10000: L(Train): 0.2599843144416809; L(Test): 0.24839305877685547\n",
      "Epoch 2564/10000: L(Train): 0.2596770226955414; L(Test): 0.24814166128635406\n",
      "Epoch 2565/10000: L(Train): 0.2714764177799225; L(Test): 0.24681049585342407\n",
      "Epoch 2566/10000: L(Train): 0.26659658551216125; L(Test): 0.24637828767299652\n",
      "Epoch 2567/10000: L(Train): 0.27544501423835754; L(Test): 0.2478187531232834\n",
      "Epoch 2568/10000: L(Train): 0.26307886838912964; L(Test): 0.24660350382328033\n",
      "Epoch 2569/10000: L(Train): 0.26012879610061646; L(Test): 0.24570152163505554\n",
      "Epoch 2570/10000: L(Train): 0.28135836124420166; L(Test): 0.246196910738945\n",
      "Epoch 2571/10000: L(Train): 0.27922797203063965; L(Test): 0.2479267120361328\n",
      "Epoch 2572/10000: L(Train): 0.2667210102081299; L(Test): 0.24796739220619202\n",
      "Epoch 2573/10000: L(Train): 0.2565697729587555; L(Test): 0.245841383934021\n",
      "Epoch 2574/10000: L(Train): 0.27021524310112; L(Test): 0.24544885754585266\n",
      "Epoch 2575/10000: L(Train): 0.26747551560401917; L(Test): 0.24511291086673737\n",
      "Epoch 2576/10000: L(Train): 0.2567923963069916; L(Test): 0.2446928471326828\n",
      "Epoch 2577/10000: L(Train): 0.25850996375083923; L(Test): 0.24447280168533325\n",
      "Epoch 2578/10000: L(Train): 0.2676698565483093; L(Test): 0.24383865296840668\n",
      "Epoch 2579/10000: L(Train): 0.25857269763946533; L(Test): 0.2439318299293518\n",
      "Epoch 2580/10000: L(Train): 0.2501143515110016; L(Test): 0.24509389698505402\n",
      "Epoch 2581/10000: L(Train): 0.25714311003685; L(Test): 0.2459854632616043\n",
      "Epoch 2582/10000: L(Train): 0.24709095060825348; L(Test): 0.24540340900421143\n",
      "Epoch 2583/10000: L(Train): 0.2617732286453247; L(Test): 0.24526624381542206\n",
      "Epoch 2584/10000: L(Train): 0.25901398062705994; L(Test): 0.2451336830854416\n",
      "Epoch 2585/10000: L(Train): 0.2682774066925049; L(Test): 0.24554303288459778\n",
      "Epoch 2586/10000: L(Train): 0.2615908980369568; L(Test): 0.24497148394584656\n",
      "Epoch 2587/10000: L(Train): 0.27231889963150024; L(Test): 0.2451852709054947\n",
      "Epoch 2588/10000: L(Train): 0.2705540359020233; L(Test): 0.24462628364562988\n",
      "Epoch 2589/10000: L(Train): 0.26356709003448486; L(Test): 0.24510444700717926\n",
      "Epoch 2590/10000: L(Train): 0.2613352835178375; L(Test): 0.24519407749176025\n",
      "Epoch 2591/10000: L(Train): 0.2546195089817047; L(Test): 0.2453891932964325\n",
      "Epoch 2592/10000: L(Train): 0.2663349211215973; L(Test): 0.2447926104068756\n",
      "Epoch 2593/10000: L(Train): 0.27285534143447876; L(Test): 0.24427667260169983\n",
      "Epoch 2594/10000: L(Train): 0.26564520597457886; L(Test): 0.2461351752281189\n",
      "Epoch 2595/10000: L(Train): 0.2686723470687866; L(Test): 0.24507437646389008\n",
      "Epoch 2596/10000: L(Train): 0.25140413641929626; L(Test): 0.24454382061958313\n",
      "Epoch 2597/10000: L(Train): 0.275264710187912; L(Test): 0.24450865387916565\n",
      "Epoch 2598/10000: L(Train): 0.29347100853919983; L(Test): 0.24399162828922272\n",
      "Epoch 2599/10000: L(Train): 0.26286303997039795; L(Test): 0.24498926103115082\n",
      "Epoch 2600/10000: L(Train): 0.2805682122707367; L(Test): 0.24407832324504852\n",
      "Epoch 2601/10000: L(Train): 0.263229101896286; L(Test): 0.24402275681495667\n",
      "Epoch 2602/10000: L(Train): 0.2749965786933899; L(Test): 0.2449655830860138\n",
      "Epoch 2603/10000: L(Train): 0.26584628224372864; L(Test): 0.24384944140911102\n",
      "Epoch 2604/10000: L(Train): 0.2679293751716614; L(Test): 0.24309538304805756\n",
      "Epoch 2605/10000: L(Train): 0.26530197262763977; L(Test): 0.24432221055030823\n",
      "Epoch 2606/10000: L(Train): 0.28568869829177856; L(Test): 0.24379709362983704\n",
      "Epoch 2607/10000: L(Train): 0.2552988529205322; L(Test): 0.2435605674982071\n",
      "Epoch 2608/10000: L(Train): 0.26265040040016174; L(Test): 0.24338985979557037\n",
      "Epoch 2609/10000: L(Train): 0.25518912076950073; L(Test): 0.24318945407867432\n",
      "Epoch 2610/10000: L(Train): 0.26340362429618835; L(Test): 0.24403312802314758\n",
      "Epoch 2611/10000: L(Train): 0.2933554947376251; L(Test): 0.2437959611415863\n",
      "Epoch 2612/10000: L(Train): 0.26131322979927063; L(Test): 0.24450457096099854\n",
      "Epoch 2613/10000: L(Train): 0.2641284465789795; L(Test): 0.24390411376953125\n",
      "Epoch 2614/10000: L(Train): 0.244478240609169; L(Test): 0.24374477565288544\n",
      "Epoch 2615/10000: L(Train): 0.27041518688201904; L(Test): 0.24431470036506653\n",
      "Epoch 2616/10000: L(Train): 0.2739918828010559; L(Test): 0.24400150775909424\n",
      "Epoch 2617/10000: L(Train): 0.25401023030281067; L(Test): 0.2443379908800125\n",
      "Epoch 2618/10000: L(Train): 0.25716549158096313; L(Test): 0.24441379308700562\n",
      "Epoch 2619/10000: L(Train): 0.2596035897731781; L(Test): 0.24393045902252197\n",
      "Epoch 2620/10000: L(Train): 0.28871914744377136; L(Test): 0.24441088736057281\n",
      "Epoch 2621/10000: L(Train): 0.24096423387527466; L(Test): 0.24482697248458862\n",
      "Epoch 2622/10000: L(Train): 0.26537880301475525; L(Test): 0.2447563260793686\n",
      "Epoch 2623/10000: L(Train): 0.2538967430591583; L(Test): 0.24485161900520325\n",
      "Epoch 2624/10000: L(Train): 0.2547800838947296; L(Test): 0.24430759251117706\n",
      "Epoch 2625/10000: L(Train): 0.25411170721054077; L(Test): 0.24464690685272217\n",
      "Epoch 2626/10000: L(Train): 0.27338892221450806; L(Test): 0.24327777326107025\n",
      "Epoch 2627/10000: L(Train): 0.2722223401069641; L(Test): 0.2438056915998459\n",
      "Epoch 2628/10000: L(Train): 0.26268911361694336; L(Test): 0.24434512853622437\n",
      "Epoch 2629/10000: L(Train): 0.2664664685726166; L(Test): 0.24413031339645386\n",
      "Epoch 2630/10000: L(Train): 0.2684857249259949; L(Test): 0.24345076084136963\n",
      "Epoch 2631/10000: L(Train): 0.2589007318019867; L(Test): 0.2436532974243164\n",
      "Epoch 2632/10000: L(Train): 0.26086267828941345; L(Test): 0.2441098392009735\n",
      "Epoch 2633/10000: L(Train): 0.2670789957046509; L(Test): 0.2444681078195572\n",
      "Epoch 2634/10000: L(Train): 0.2563655376434326; L(Test): 0.2448863983154297\n",
      "Epoch 2635/10000: L(Train): 0.27469122409820557; L(Test): 0.24492217600345612\n",
      "Epoch 2636/10000: L(Train): 0.2618793249130249; L(Test): 0.24374093115329742\n",
      "Epoch 2637/10000: L(Train): 0.25443992018699646; L(Test): 0.24510231614112854\n",
      "Epoch 2638/10000: L(Train): 0.2664315104484558; L(Test): 0.24497029185295105\n",
      "Epoch 2639/10000: L(Train): 0.24713075160980225; L(Test): 0.243363156914711\n",
      "Epoch 2640/10000: L(Train): 0.2748516798019409; L(Test): 0.2438066303730011\n",
      "Epoch 2641/10000: L(Train): 0.2845134735107422; L(Test): 0.24377739429473877\n",
      "Epoch 2642/10000: L(Train): 0.26448026299476624; L(Test): 0.24406152963638306\n",
      "Epoch 2643/10000: L(Train): 0.2554595470428467; L(Test): 0.24409446120262146\n",
      "Epoch 2644/10000: L(Train): 0.2647716999053955; L(Test): 0.24433372914791107\n",
      "Epoch 2645/10000: L(Train): 0.2772737443447113; L(Test): 0.24303396046161652\n",
      "Epoch 2646/10000: L(Train): 0.258558064699173; L(Test): 0.2438095360994339\n",
      "Epoch 2647/10000: L(Train): 0.2786373794078827; L(Test): 0.24340921640396118\n",
      "Epoch 2648/10000: L(Train): 0.2702050805091858; L(Test): 0.24356617033481598\n",
      "Epoch 2649/10000: L(Train): 0.2524870038032532; L(Test): 0.24359504878520966\n",
      "Epoch 2650/10000: L(Train): 0.2551112771034241; L(Test): 0.2436244636774063\n",
      "Epoch 2651/10000: L(Train): 0.2598038911819458; L(Test): 0.24403142929077148\n",
      "Epoch 2652/10000: L(Train): 0.2526777982711792; L(Test): 0.24447984993457794\n",
      "Epoch 2653/10000: L(Train): 0.26749667525291443; L(Test): 0.24457791447639465\n",
      "Epoch 2654/10000: L(Train): 0.27139052748680115; L(Test): 0.2442971169948578\n",
      "Epoch 2655/10000: L(Train): 0.26037830114364624; L(Test): 0.245655819773674\n",
      "Epoch 2656/10000: L(Train): 0.2789049446582794; L(Test): 0.2450685203075409\n",
      "Epoch 2657/10000: L(Train): 0.25761574506759644; L(Test): 0.24564523994922638\n",
      "Epoch 2658/10000: L(Train): 0.25311902165412903; L(Test): 0.2453555166721344\n",
      "Epoch 2659/10000: L(Train): 0.27624884247779846; L(Test): 0.24485136568546295\n",
      "Epoch 2660/10000: L(Train): 0.26569488644599915; L(Test): 0.24595485627651215\n",
      "Epoch 2661/10000: L(Train): 0.268558531999588; L(Test): 0.2460593432188034\n",
      "Epoch 2662/10000: L(Train): 0.2759595811367035; L(Test): 0.2455502301454544\n",
      "Epoch 2663/10000: L(Train): 0.26868003606796265; L(Test): 0.2463034838438034\n",
      "Epoch 2664/10000: L(Train): 0.25479304790496826; L(Test): 0.24595369398593903\n",
      "Epoch 2665/10000: L(Train): 0.2665309011936188; L(Test): 0.24441799521446228\n",
      "Epoch 2666/10000: L(Train): 0.27211156487464905; L(Test): 0.24493323266506195\n",
      "Epoch 2667/10000: L(Train): 0.2640995979309082; L(Test): 0.2450786530971527\n",
      "Epoch 2668/10000: L(Train): 0.26178836822509766; L(Test): 0.24387797713279724\n",
      "Epoch 2669/10000: L(Train): 0.2675120532512665; L(Test): 0.2440224140882492\n",
      "Epoch 2670/10000: L(Train): 0.26225411891937256; L(Test): 0.24441561102867126\n",
      "Epoch 2671/10000: L(Train): 0.2746013402938843; L(Test): 0.24491442739963531\n",
      "Epoch 2672/10000: L(Train): 0.28796929121017456; L(Test): 0.244338721036911\n",
      "Epoch 2673/10000: L(Train): 0.2626042366027832; L(Test): 0.24549509584903717\n",
      "Epoch 2674/10000: L(Train): 0.2794981598854065; L(Test): 0.24520598351955414\n",
      "Epoch 2675/10000: L(Train): 0.24113713204860687; L(Test): 0.24554361402988434\n",
      "Epoch 2676/10000: L(Train): 0.27458804845809937; L(Test): 0.24486008286476135\n",
      "Epoch 2677/10000: L(Train): 0.2665649652481079; L(Test): 0.24494348466396332\n",
      "Epoch 2678/10000: L(Train): 0.2587209641933441; L(Test): 0.24497847259044647\n",
      "Epoch 2679/10000: L(Train): 0.2530330717563629; L(Test): 0.2437511384487152\n",
      "Epoch 2680/10000: L(Train): 0.27170124650001526; L(Test): 0.24451883137226105\n",
      "Epoch 2681/10000: L(Train): 0.27339956164360046; L(Test): 0.24401970207691193\n",
      "Epoch 2682/10000: L(Train): 0.27606961131095886; L(Test): 0.24462060630321503\n",
      "Epoch 2683/10000: L(Train): 0.26723819971084595; L(Test): 0.24336646497249603\n",
      "Epoch 2684/10000: L(Train): 0.2618160843849182; L(Test): 0.24421186745166779\n",
      "Epoch 2685/10000: L(Train): 0.28211545944213867; L(Test): 0.2435644119977951\n",
      "Epoch 2686/10000: L(Train): 0.25097110867500305; L(Test): 0.2442793846130371\n",
      "Epoch 2687/10000: L(Train): 0.2708962857723236; L(Test): 0.24460193514823914\n",
      "Epoch 2688/10000: L(Train): 0.26135990023612976; L(Test): 0.24417094886302948\n",
      "Epoch 2689/10000: L(Train): 0.2667154371738434; L(Test): 0.243502676486969\n",
      "Epoch 2690/10000: L(Train): 0.26112377643585205; L(Test): 0.24454259872436523\n",
      "Epoch 2691/10000: L(Train): 0.2597903907299042; L(Test): 0.24350781738758087\n",
      "Epoch 2692/10000: L(Train): 0.2555270195007324; L(Test): 0.24271418154239655\n",
      "Epoch 2693/10000: L(Train): 0.25104472041130066; L(Test): 0.24367421865463257\n",
      "Epoch 2694/10000: L(Train): 0.2333810180425644; L(Test): 0.24441108107566833\n",
      "Epoch 2695/10000: L(Train): 0.2640819847583771; L(Test): 0.24479907751083374\n",
      "Epoch 2696/10000: L(Train): 0.26355651021003723; L(Test): 0.24384412169456482\n",
      "Epoch 2697/10000: L(Train): 0.2759142220020294; L(Test): 0.24422451853752136\n",
      "Epoch 2698/10000: L(Train): 0.24766194820404053; L(Test): 0.24429172277450562\n",
      "Epoch 2699/10000: L(Train): 0.27919429540634155; L(Test): 0.24488700926303864\n",
      "Epoch 2700/10000: L(Train): 0.2573235332965851; L(Test): 0.24428696930408478\n",
      "Epoch 2701/10000: L(Train): 0.2797435224056244; L(Test): 0.24454455077648163\n",
      "Epoch 2702/10000: L(Train): 0.2821827828884125; L(Test): 0.24401091039180756\n",
      "Epoch 2703/10000: L(Train): 0.2567287087440491; L(Test): 0.2439582645893097\n",
      "Epoch 2704/10000: L(Train): 0.2686612904071808; L(Test): 0.2436063289642334\n",
      "Epoch 2705/10000: L(Train): 0.2668146789073944; L(Test): 0.24422962963581085\n",
      "Epoch 2706/10000: L(Train): 0.2683860957622528; L(Test): 0.24404282867908478\n",
      "Epoch 2707/10000: L(Train): 0.2572658360004425; L(Test): 0.24319010972976685\n",
      "Epoch 2708/10000: L(Train): 0.25987574458122253; L(Test): 0.24332459270954132\n",
      "Epoch 2709/10000: L(Train): 0.2744615077972412; L(Test): 0.24279186129570007\n",
      "Epoch 2710/10000: L(Train): 0.2592163383960724; L(Test): 0.24267759919166565\n",
      "Epoch 2711/10000: L(Train): 0.27591559290885925; L(Test): 0.24376818537712097\n",
      "Epoch 2712/10000: L(Train): 0.2776002883911133; L(Test): 0.24574624001979828\n",
      "Epoch 2713/10000: L(Train): 0.2571655213832855; L(Test): 0.24564340710639954\n",
      "Epoch 2714/10000: L(Train): 0.2660859525203705; L(Test): 0.2433181256055832\n",
      "Epoch 2715/10000: L(Train): 0.27473101019859314; L(Test): 0.24317064881324768\n",
      "Epoch 2716/10000: L(Train): 0.2684648334980011; L(Test): 0.2460346668958664\n",
      "Epoch 2717/10000: L(Train): 0.262582004070282; L(Test): 0.2436683177947998\n",
      "Epoch 2718/10000: L(Train): 0.24724914133548737; L(Test): 0.2433776706457138\n",
      "Epoch 2719/10000: L(Train): 0.27965134382247925; L(Test): 0.24307921528816223\n",
      "Epoch 2720/10000: L(Train): 0.27892521023750305; L(Test): 0.24360333383083344\n",
      "Epoch 2721/10000: L(Train): 0.2418326735496521; L(Test): 0.24684317409992218\n",
      "Epoch 2722/10000: L(Train): 0.2580639123916626; L(Test): 0.24349656701087952\n",
      "Epoch 2723/10000: L(Train): 0.2641422748565674; L(Test): 0.2429676651954651\n",
      "Epoch 2724/10000: L(Train): 0.2768685221672058; L(Test): 0.24413204193115234\n",
      "Epoch 2725/10000: L(Train): 0.27232933044433594; L(Test): 0.24310435354709625\n",
      "Epoch 2726/10000: L(Train): 0.26770198345184326; L(Test): 0.24405834078788757\n",
      "Epoch 2727/10000: L(Train): 0.2592141032218933; L(Test): 0.24509811401367188\n",
      "Epoch 2728/10000: L(Train): 0.25618669390678406; L(Test): 0.2446424961090088\n",
      "Epoch 2729/10000: L(Train): 0.2604401409626007; L(Test): 0.24317951500415802\n",
      "Epoch 2730/10000: L(Train): 0.27816352248191833; L(Test): 0.24313385784626007\n",
      "Epoch 2731/10000: L(Train): 0.2561597228050232; L(Test): 0.24332833290100098\n",
      "Epoch 2732/10000: L(Train): 0.2765570282936096; L(Test): 0.2440088987350464\n",
      "Epoch 2733/10000: L(Train): 0.25608599185943604; L(Test): 0.24244622886180878\n",
      "Epoch 2734/10000: L(Train): 0.26295825839042664; L(Test): 0.24310614168643951\n",
      "Epoch 2735/10000: L(Train): 0.26749587059020996; L(Test): 0.24311374127864838\n",
      "Epoch 2736/10000: L(Train): 0.25354528427124023; L(Test): 0.24259363114833832\n",
      "Epoch 2737/10000: L(Train): 0.2675934135913849; L(Test): 0.24248920381069183\n",
      "Epoch 2738/10000: L(Train): 0.2538144290447235; L(Test): 0.24321331083774567\n",
      "Epoch 2739/10000: L(Train): 0.2635940611362457; L(Test): 0.243741974234581\n",
      "Epoch 2740/10000: L(Train): 0.26833176612854004; L(Test): 0.24193941056728363\n",
      "Epoch 2741/10000: L(Train): 0.2662960886955261; L(Test): 0.2422148883342743\n",
      "Epoch 2742/10000: L(Train): 0.2630099058151245; L(Test): 0.24225975573062897\n",
      "Epoch 2743/10000: L(Train): 0.25584250688552856; L(Test): 0.24316291511058807\n",
      "Epoch 2744/10000: L(Train): 0.25600865483283997; L(Test): 0.24308305978775024\n",
      "Epoch 2745/10000: L(Train): 0.26737335324287415; L(Test): 0.24185065925121307\n",
      "Epoch 2746/10000: L(Train): 0.2688382565975189; L(Test): 0.24198509752750397\n",
      "Epoch 2747/10000: L(Train): 0.26362505555152893; L(Test): 0.24292045831680298\n",
      "Epoch 2748/10000: L(Train): 0.2820751965045929; L(Test): 0.24372904002666473\n",
      "Epoch 2749/10000: L(Train): 0.2546423375606537; L(Test): 0.24237538874149323\n",
      "Epoch 2750/10000: L(Train): 0.2860334813594818; L(Test): 0.2438095062971115\n",
      "Epoch 2751/10000: L(Train): 0.26372891664505005; L(Test): 0.2440546154975891\n",
      "Epoch 2752/10000: L(Train): 0.2615843117237091; L(Test): 0.243832066655159\n",
      "Epoch 2753/10000: L(Train): 0.2713354825973511; L(Test): 0.24262593686580658\n",
      "Epoch 2754/10000: L(Train): 0.26412561535835266; L(Test): 0.2443377673625946\n",
      "Epoch 2755/10000: L(Train): 0.27414339780807495; L(Test): 0.24347564578056335\n",
      "Epoch 2756/10000: L(Train): 0.2503904104232788; L(Test): 0.24341022968292236\n",
      "Epoch 2757/10000: L(Train): 0.27099815011024475; L(Test): 0.24267937242984772\n",
      "Epoch 2758/10000: L(Train): 0.26027119159698486; L(Test): 0.2437843233346939\n",
      "Epoch 2759/10000: L(Train): 0.2613309621810913; L(Test): 0.24440902471542358\n",
      "Epoch 2760/10000: L(Train): 0.2608949840068817; L(Test): 0.24333256483078003\n",
      "Epoch 2761/10000: L(Train): 0.26934364438056946; L(Test): 0.2510119676589966\n",
      "Epoch 2762/10000: L(Train): 0.2741832137107849; L(Test): 0.2481805980205536\n",
      "Epoch 2763/10000: L(Train): 0.2770349085330963; L(Test): 0.24785394966602325\n",
      "Epoch 2764/10000: L(Train): 0.2643609344959259; L(Test): 0.2491975873708725\n",
      "Epoch 2765/10000: L(Train): 0.28031373023986816; L(Test): 0.24697993695735931\n",
      "Epoch 2766/10000: L(Train): 0.2605881690979004; L(Test): 0.25406530499458313\n",
      "Epoch 2767/10000: L(Train): 0.2754918932914734; L(Test): 0.24789643287658691\n",
      "Epoch 2768/10000: L(Train): 0.26777032017707825; L(Test): 0.2499624341726303\n",
      "Epoch 2769/10000: L(Train): 0.2707158923149109; L(Test): 0.24827884137630463\n",
      "Epoch 2770/10000: L(Train): 0.266574501991272; L(Test): 0.24826735258102417\n",
      "Epoch 2771/10000: L(Train): 0.2715425491333008; L(Test): 0.25237837433815\n",
      "Epoch 2772/10000: L(Train): 0.27201464772224426; L(Test): 0.24954111874103546\n",
      "Epoch 2773/10000: L(Train): 0.2696930170059204; L(Test): 0.2510305643081665\n",
      "Epoch 2774/10000: L(Train): 0.2741667926311493; L(Test): 0.2505936622619629\n",
      "Epoch 2775/10000: L(Train): 0.2659417986869812; L(Test): 0.2481958270072937\n",
      "Epoch 2776/10000: L(Train): 0.25556012988090515; L(Test): 0.25005704164505005\n",
      "Epoch 2777/10000: L(Train): 0.25998544692993164; L(Test): 0.24781090021133423\n",
      "Epoch 2778/10000: L(Train): 0.28200721740722656; L(Test): 0.246297225356102\n",
      "Epoch 2779/10000: L(Train): 0.2674846053123474; L(Test): 0.24621328711509705\n",
      "Epoch 2780/10000: L(Train): 0.2758832573890686; L(Test): 0.24601136147975922\n",
      "Epoch 2781/10000: L(Train): 0.2672649323940277; L(Test): 0.24955931305885315\n",
      "Epoch 2782/10000: L(Train): 0.2642689347267151; L(Test): 0.24782845377922058\n",
      "Epoch 2783/10000: L(Train): 0.2611970007419586; L(Test): 0.2458871603012085\n",
      "Epoch 2784/10000: L(Train): 0.27357277274131775; L(Test): 0.24651330709457397\n",
      "Epoch 2785/10000: L(Train): 0.27257686853408813; L(Test): 0.24608242511749268\n",
      "Epoch 2786/10000: L(Train): 0.2663854658603668; L(Test): 0.24652042984962463\n",
      "Epoch 2787/10000: L(Train): 0.2704114019870758; L(Test): 0.24553297460079193\n",
      "Epoch 2788/10000: L(Train): 0.25458645820617676; L(Test): 0.24652288854122162\n",
      "Epoch 2789/10000: L(Train): 0.2516472041606903; L(Test): 0.24656490981578827\n",
      "Epoch 2790/10000: L(Train): 0.2695658802986145; L(Test): 0.24410639703273773\n",
      "Epoch 2791/10000: L(Train): 0.26392242312431335; L(Test): 0.24670737981796265\n",
      "Epoch 2792/10000: L(Train): 0.26877927780151367; L(Test): 0.24628667533397675\n",
      "Epoch 2793/10000: L(Train): 0.2688167095184326; L(Test): 0.2452535629272461\n",
      "Epoch 2794/10000: L(Train): 0.26222294569015503; L(Test): 0.24837763607501984\n",
      "Epoch 2795/10000: L(Train): 0.2741447985172272; L(Test): 0.24475020170211792\n",
      "Epoch 2796/10000: L(Train): 0.26640549302101135; L(Test): 0.24691520631313324\n",
      "Epoch 2797/10000: L(Train): 0.2686860263347626; L(Test): 0.2455969750881195\n",
      "Epoch 2798/10000: L(Train): 0.26832205057144165; L(Test): 0.24619360268115997\n",
      "Epoch 2799/10000: L(Train): 0.2739715278148651; L(Test): 0.2460448294878006\n",
      "Epoch 2800/10000: L(Train): 0.2773858308792114; L(Test): 0.2455076277256012\n",
      "Epoch 2801/10000: L(Train): 0.2686659097671509; L(Test): 0.2464267611503601\n",
      "Epoch 2802/10000: L(Train): 0.2607322633266449; L(Test): 0.2445863038301468\n",
      "Epoch 2803/10000: L(Train): 0.2787688076496124; L(Test): 0.24606342613697052\n",
      "Epoch 2804/10000: L(Train): 0.26714879274368286; L(Test): 0.2452680617570877\n",
      "Epoch 2805/10000: L(Train): 0.25941476225852966; L(Test): 0.24657753109931946\n",
      "Epoch 2806/10000: L(Train): 0.2683585286140442; L(Test): 0.2492523491382599\n",
      "Epoch 2807/10000: L(Train): 0.2527684271335602; L(Test): 0.24420036375522614\n",
      "Epoch 2808/10000: L(Train): 0.26334407925605774; L(Test): 0.2451418936252594\n",
      "Epoch 2809/10000: L(Train): 0.26438772678375244; L(Test): 0.24446621537208557\n",
      "Epoch 2810/10000: L(Train): 0.2595647871494293; L(Test): 0.2455091029405594\n",
      "Epoch 2811/10000: L(Train): 0.28093019127845764; L(Test): 0.24511700868606567\n",
      "Epoch 2812/10000: L(Train): 0.26649290323257446; L(Test): 0.24536347389221191\n",
      "Epoch 2813/10000: L(Train): 0.2674652636051178; L(Test): 0.24559152126312256\n",
      "Epoch 2814/10000: L(Train): 0.25297075510025024; L(Test): 0.24564886093139648\n",
      "Epoch 2815/10000: L(Train): 0.2571166455745697; L(Test): 0.24711455404758453\n",
      "Epoch 2816/10000: L(Train): 0.27467265725135803; L(Test): 0.24500690400600433\n",
      "Epoch 2817/10000: L(Train): 0.2629174292087555; L(Test): 0.2455083727836609\n",
      "Epoch 2818/10000: L(Train): 0.26058056950569153; L(Test): 0.24474427103996277\n",
      "Epoch 2819/10000: L(Train): 0.2691808342933655; L(Test): 0.24470272660255432\n",
      "Epoch 2820/10000: L(Train): 0.2630215287208557; L(Test): 0.244453564286232\n",
      "Epoch 2821/10000: L(Train): 0.2520148754119873; L(Test): 0.243763729929924\n",
      "Epoch 2822/10000: L(Train): 0.26876717805862427; L(Test): 0.2441772073507309\n",
      "Epoch 2823/10000: L(Train): 0.27003681659698486; L(Test): 0.2434636354446411\n",
      "Epoch 2824/10000: L(Train): 0.27156779170036316; L(Test): 0.24455171823501587\n",
      "Epoch 2825/10000: L(Train): 0.26535359025001526; L(Test): 0.24328768253326416\n",
      "Epoch 2826/10000: L(Train): 0.24948909878730774; L(Test): 0.24245299398899078\n",
      "Epoch 2827/10000: L(Train): 0.261881560087204; L(Test): 0.24325045943260193\n",
      "Epoch 2828/10000: L(Train): 0.25414395332336426; L(Test): 0.24302606284618378\n",
      "Epoch 2829/10000: L(Train): 0.2757364511489868; L(Test): 0.24215804040431976\n",
      "Epoch 2830/10000: L(Train): 0.26229313015937805; L(Test): 0.2434319108724594\n",
      "Epoch 2831/10000: L(Train): 0.26540806889533997; L(Test): 0.2424917072057724\n",
      "Epoch 2832/10000: L(Train): 0.25887036323547363; L(Test): 0.24244937300682068\n",
      "Epoch 2833/10000: L(Train): 0.2488202452659607; L(Test): 0.24409696459770203\n",
      "Epoch 2834/10000: L(Train): 0.24859356880187988; L(Test): 0.24331587553024292\n",
      "Epoch 2835/10000: L(Train): 0.2561739683151245; L(Test): 0.24239687621593475\n",
      "Epoch 2836/10000: L(Train): 0.2668197453022003; L(Test): 0.24279208481311798\n",
      "Epoch 2837/10000: L(Train): 0.25766196846961975; L(Test): 0.24216553568840027\n",
      "Epoch 2838/10000: L(Train): 0.26460808515548706; L(Test): 0.2415735423564911\n",
      "Epoch 2839/10000: L(Train): 0.2677060067653656; L(Test): 0.242676243185997\n",
      "Epoch 2840/10000: L(Train): 0.25800514221191406; L(Test): 0.24314601719379425\n",
      "Epoch 2841/10000: L(Train): 0.2656248211860657; L(Test): 0.24339307844638824\n",
      "Epoch 2842/10000: L(Train): 0.2567996084690094; L(Test): 0.2435847669839859\n",
      "Epoch 2843/10000: L(Train): 0.273545503616333; L(Test): 0.241997629404068\n",
      "Epoch 2844/10000: L(Train): 0.275664359331131; L(Test): 0.24309369921684265\n",
      "Epoch 2845/10000: L(Train): 0.26253318786621094; L(Test): 0.2436535507440567\n",
      "Epoch 2846/10000: L(Train): 0.2586052715778351; L(Test): 0.2417898327112198\n",
      "Epoch 2847/10000: L(Train): 0.250576376914978; L(Test): 0.2451583296060562\n",
      "Epoch 2848/10000: L(Train): 0.25513577461242676; L(Test): 0.244251549243927\n",
      "Epoch 2849/10000: L(Train): 0.25562289357185364; L(Test): 0.24369537830352783\n",
      "Epoch 2850/10000: L(Train): 0.2608793377876282; L(Test): 0.2441011220216751\n",
      "Epoch 2851/10000: L(Train): 0.25257885456085205; L(Test): 0.24313490092754364\n",
      "Epoch 2852/10000: L(Train): 0.2841436564922333; L(Test): 0.24273031949996948\n",
      "Epoch 2853/10000: L(Train): 0.2542738616466522; L(Test): 0.2427571415901184\n",
      "Epoch 2854/10000: L(Train): 0.2575550079345703; L(Test): 0.2422499805688858\n",
      "Epoch 2855/10000: L(Train): 0.2657218277454376; L(Test): 0.24348212778568268\n",
      "Epoch 2856/10000: L(Train): 0.2704247832298279; L(Test): 0.2433670312166214\n",
      "Epoch 2857/10000: L(Train): 0.2514348030090332; L(Test): 0.2433299571275711\n",
      "Epoch 2858/10000: L(Train): 0.2662472426891327; L(Test): 0.24342645704746246\n",
      "Epoch 2859/10000: L(Train): 0.2732350826263428; L(Test): 0.2434316873550415\n",
      "Epoch 2860/10000: L(Train): 0.2550441026687622; L(Test): 0.24347178637981415\n",
      "Epoch 2861/10000: L(Train): 0.27361807227134705; L(Test): 0.24398595094680786\n",
      "Epoch 2862/10000: L(Train): 0.2692789137363434; L(Test): 0.24333424866199493\n",
      "Epoch 2863/10000: L(Train): 0.27319684624671936; L(Test): 0.24262341856956482\n",
      "Epoch 2864/10000: L(Train): 0.2642320990562439; L(Test): 0.24259456992149353\n",
      "Epoch 2865/10000: L(Train): 0.2675666809082031; L(Test): 0.24289852380752563\n",
      "Epoch 2866/10000: L(Train): 0.270036906003952; L(Test): 0.24271072447299957\n",
      "Epoch 2867/10000: L(Train): 0.26191574335098267; L(Test): 0.24340566992759705\n",
      "Epoch 2868/10000: L(Train): 0.2683194875717163; L(Test): 0.24318554997444153\n",
      "Epoch 2869/10000: L(Train): 0.2576770484447479; L(Test): 0.24316081404685974\n",
      "Epoch 2870/10000: L(Train): 0.2596816420555115; L(Test): 0.24338017404079437\n",
      "Epoch 2871/10000: L(Train): 0.26853272318840027; L(Test): 0.24341508746147156\n",
      "Epoch 2872/10000: L(Train): 0.26487046480178833; L(Test): 0.2434927225112915\n",
      "Epoch 2873/10000: L(Train): 0.26373720169067383; L(Test): 0.24454715847969055\n",
      "Epoch 2874/10000: L(Train): 0.26172035932540894; L(Test): 0.24392201006412506\n",
      "Epoch 2875/10000: L(Train): 0.2722913920879364; L(Test): 0.24316173791885376\n",
      "Epoch 2876/10000: L(Train): 0.26886290311813354; L(Test): 0.2427913248538971\n",
      "Epoch 2877/10000: L(Train): 0.2745705246925354; L(Test): 0.24270358681678772\n",
      "Epoch 2878/10000: L(Train): 0.2738718092441559; L(Test): 0.2430325746536255\n",
      "Epoch 2879/10000: L(Train): 0.2636095881462097; L(Test): 0.243652805685997\n",
      "Epoch 2880/10000: L(Train): 0.26174336671829224; L(Test): 0.24335448443889618\n",
      "Epoch 2881/10000: L(Train): 0.2610289454460144; L(Test): 0.24317723512649536\n",
      "Epoch 2882/10000: L(Train): 0.27182647585868835; L(Test): 0.24271850287914276\n",
      "Epoch 2883/10000: L(Train): 0.2586061358451843; L(Test): 0.24258390069007874\n",
      "Epoch 2884/10000: L(Train): 0.2737025022506714; L(Test): 0.24209284782409668\n",
      "Epoch 2885/10000: L(Train): 0.245570108294487; L(Test): 0.24216358363628387\n",
      "Epoch 2886/10000: L(Train): 0.2690409719944; L(Test): 0.24198663234710693\n",
      "Epoch 2887/10000: L(Train): 0.26525309681892395; L(Test): 0.2423255294561386\n",
      "Epoch 2888/10000: L(Train): 0.24989405274391174; L(Test): 0.24305610358715057\n",
      "Epoch 2889/10000: L(Train): 0.2676447629928589; L(Test): 0.24229785799980164\n",
      "Epoch 2890/10000: L(Train): 0.24937301874160767; L(Test): 0.2424180507659912\n",
      "Epoch 2891/10000: L(Train): 0.26316237449645996; L(Test): 0.24166761338710785\n",
      "Epoch 2892/10000: L(Train): 0.25780946016311646; L(Test): 0.24233566224575043\n",
      "Epoch 2893/10000: L(Train): 0.2553273141384125; L(Test): 0.24278029799461365\n",
      "Epoch 2894/10000: L(Train): 0.26343756914138794; L(Test): 0.24263212084770203\n",
      "Epoch 2895/10000: L(Train): 0.2634277045726776; L(Test): 0.24277234077453613\n",
      "Epoch 2896/10000: L(Train): 0.27043408155441284; L(Test): 0.24209292232990265\n",
      "Epoch 2897/10000: L(Train): 0.2734875977039337; L(Test): 0.24258024990558624\n",
      "Epoch 2898/10000: L(Train): 0.2553848922252655; L(Test): 0.244075208902359\n",
      "Epoch 2899/10000: L(Train): 0.2586069703102112; L(Test): 0.24330398440361023\n",
      "Epoch 2900/10000: L(Train): 0.2715205252170563; L(Test): 0.24279874563217163\n",
      "Epoch 2901/10000: L(Train): 0.2599683701992035; L(Test): 0.24356693029403687\n",
      "Epoch 2902/10000: L(Train): 0.283157616853714; L(Test): 0.24272587895393372\n",
      "Epoch 2903/10000: L(Train): 0.2610039710998535; L(Test): 0.24269334971904755\n",
      "Epoch 2904/10000: L(Train): 0.2592162787914276; L(Test): 0.2429140955209732\n",
      "Epoch 2905/10000: L(Train): 0.25525352358818054; L(Test): 0.24229925870895386\n",
      "Epoch 2906/10000: L(Train): 0.2568623721599579; L(Test): 0.2422248125076294\n",
      "Epoch 2907/10000: L(Train): 0.26077961921691895; L(Test): 0.24256743490695953\n",
      "Epoch 2908/10000: L(Train): 0.27108538150787354; L(Test): 0.2421322464942932\n",
      "Epoch 2909/10000: L(Train): 0.26364123821258545; L(Test): 0.24356481432914734\n",
      "Epoch 2910/10000: L(Train): 0.2659932076931; L(Test): 0.24321767687797546\n",
      "Epoch 2911/10000: L(Train): 0.2579919993877411; L(Test): 0.24243520200252533\n",
      "Epoch 2912/10000: L(Train): 0.24758081138134003; L(Test): 0.24337485432624817\n",
      "Epoch 2913/10000: L(Train): 0.25082042813301086; L(Test): 0.24417442083358765\n",
      "Epoch 2914/10000: L(Train): 0.2705419957637787; L(Test): 0.24258412420749664\n",
      "Epoch 2915/10000: L(Train): 0.26081639528274536; L(Test): 0.2430352121591568\n",
      "Epoch 2916/10000: L(Train): 0.2724985182285309; L(Test): 0.24186085164546967\n",
      "Epoch 2917/10000: L(Train): 0.2624114155769348; L(Test): 0.24266017973423004\n",
      "Epoch 2918/10000: L(Train): 0.25445306301116943; L(Test): 0.24227941036224365\n",
      "Epoch 2919/10000: L(Train): 0.263509601354599; L(Test): 0.24198167026042938\n",
      "Epoch 2920/10000: L(Train): 0.26412254571914673; L(Test): 0.24303974211215973\n",
      "Epoch 2921/10000: L(Train): 0.27028369903564453; L(Test): 0.2429831176996231\n",
      "Epoch 2922/10000: L(Train): 0.26581770181655884; L(Test): 0.24587388336658478\n",
      "Epoch 2923/10000: L(Train): 0.26292234659194946; L(Test): 0.24544601142406464\n",
      "Epoch 2924/10000: L(Train): 0.2648002803325653; L(Test): 0.24386872351169586\n",
      "Epoch 2925/10000: L(Train): 0.26657673716545105; L(Test): 0.2462179958820343\n",
      "Epoch 2926/10000: L(Train): 0.28383365273475647; L(Test): 0.24678447842597961\n",
      "Epoch 2927/10000: L(Train): 0.2686727046966553; L(Test): 0.24551521241664886\n",
      "Epoch 2928/10000: L(Train): 0.26096662878990173; L(Test): 0.24525032937526703\n",
      "Epoch 2929/10000: L(Train): 0.2684522867202759; L(Test): 0.24441654980182648\n",
      "Epoch 2930/10000: L(Train): 0.26451727747917175; L(Test): 0.24373304843902588\n",
      "Epoch 2931/10000: L(Train): 0.2778042256832123; L(Test): 0.24562709033489227\n",
      "Epoch 2932/10000: L(Train): 0.2726992666721344; L(Test): 0.24509592354297638\n",
      "Epoch 2933/10000: L(Train): 0.2766728699207306; L(Test): 0.24373525381088257\n",
      "Epoch 2934/10000: L(Train): 0.2628589868545532; L(Test): 0.24569101631641388\n",
      "Epoch 2935/10000: L(Train): 0.26230207085609436; L(Test): 0.24479565024375916\n",
      "Epoch 2936/10000: L(Train): 0.267408549785614; L(Test): 0.2448424994945526\n",
      "Epoch 2937/10000: L(Train): 0.2641700506210327; L(Test): 0.24591359496116638\n",
      "Epoch 2938/10000: L(Train): 0.27530235052108765; L(Test): 0.24448466300964355\n",
      "Epoch 2939/10000: L(Train): 0.2742343842983246; L(Test): 0.24498967826366425\n",
      "Epoch 2940/10000: L(Train): 0.26746222376823425; L(Test): 0.24549825489521027\n",
      "Epoch 2941/10000: L(Train): 0.26078733801841736; L(Test): 0.2445024698972702\n",
      "Epoch 2942/10000: L(Train): 0.2797885835170746; L(Test): 0.24489648640155792\n",
      "Epoch 2943/10000: L(Train): 0.2609463334083557; L(Test): 0.24469053745269775\n",
      "Epoch 2944/10000: L(Train): 0.2704671025276184; L(Test): 0.24382172524929047\n",
      "Epoch 2945/10000: L(Train): 0.25372114777565; L(Test): 0.24442045390605927\n",
      "Epoch 2946/10000: L(Train): 0.27146896719932556; L(Test): 0.2443332076072693\n",
      "Epoch 2947/10000: L(Train): 0.2613665461540222; L(Test): 0.24368688464164734\n",
      "Epoch 2948/10000: L(Train): 0.2723621129989624; L(Test): 0.24325281381607056\n",
      "Epoch 2949/10000: L(Train): 0.2815396785736084; L(Test): 0.2434624880552292\n",
      "Epoch 2950/10000: L(Train): 0.26615405082702637; L(Test): 0.24376071989536285\n",
      "Epoch 2951/10000: L(Train): 0.2690751552581787; L(Test): 0.24249808490276337\n",
      "Epoch 2952/10000: L(Train): 0.2635688781738281; L(Test): 0.2430490404367447\n",
      "Epoch 2953/10000: L(Train): 0.26586925983428955; L(Test): 0.24353629350662231\n",
      "Epoch 2954/10000: L(Train): 0.26083680987358093; L(Test): 0.24291567504405975\n",
      "Epoch 2955/10000: L(Train): 0.2595634162425995; L(Test): 0.24225583672523499\n",
      "Epoch 2956/10000: L(Train): 0.2607259750366211; L(Test): 0.242068350315094\n",
      "Epoch 2957/10000: L(Train): 0.2706468105316162; L(Test): 0.24227295815944672\n",
      "Epoch 2958/10000: L(Train): 0.26056042313575745; L(Test): 0.2433295100927353\n",
      "Epoch 2959/10000: L(Train): 0.25353342294692993; L(Test): 0.24269942939281464\n",
      "Epoch 2960/10000: L(Train): 0.2720043361186981; L(Test): 0.24216261506080627\n",
      "Epoch 2961/10000: L(Train): 0.2759082019329071; L(Test): 0.24248939752578735\n",
      "Epoch 2962/10000: L(Train): 0.25395455956459045; L(Test): 0.2436264306306839\n",
      "Epoch 2963/10000: L(Train): 0.2666541635990143; L(Test): 0.24301759898662567\n",
      "Epoch 2964/10000: L(Train): 0.27079126238822937; L(Test): 0.243299201130867\n",
      "Epoch 2965/10000: L(Train): 0.26538971066474915; L(Test): 0.24270500242710114\n",
      "Epoch 2966/10000: L(Train): 0.27314287424087524; L(Test): 0.24449202418327332\n",
      "Epoch 2967/10000: L(Train): 0.25187280774116516; L(Test): 0.24434936046600342\n",
      "Epoch 2968/10000: L(Train): 0.2711576223373413; L(Test): 0.2447749227285385\n",
      "Epoch 2969/10000: L(Train): 0.257999062538147; L(Test): 0.24495291709899902\n",
      "Epoch 2970/10000: L(Train): 0.255039781332016; L(Test): 0.24386616051197052\n",
      "Epoch 2971/10000: L(Train): 0.26244479417800903; L(Test): 0.24794289469718933\n",
      "Epoch 2972/10000: L(Train): 0.266244113445282; L(Test): 0.282299667596817\n",
      "Epoch 2973/10000: L(Train): 0.30050092935562134; L(Test): 0.2807410955429077\n",
      "Epoch 2974/10000: L(Train): 0.3163723051548004; L(Test): 0.28187844157218933\n",
      "Epoch 2975/10000: L(Train): 0.3174719214439392; L(Test): 0.2885533571243286\n",
      "Epoch 2976/10000: L(Train): 0.3048020005226135; L(Test): 0.29180362820625305\n",
      "Epoch 2977/10000: L(Train): 0.31367403268814087; L(Test): 0.2958225905895233\n",
      "Epoch 2978/10000: L(Train): 0.30657288432121277; L(Test): 0.29605865478515625\n",
      "Epoch 2979/10000: L(Train): 0.33029040694236755; L(Test): 0.2924211323261261\n",
      "Epoch 2980/10000: L(Train): 0.29978498816490173; L(Test): 0.2901277244091034\n",
      "Epoch 2981/10000: L(Train): 0.3261823356151581; L(Test): 0.28968673944473267\n",
      "Epoch 2982/10000: L(Train): 0.31820255517959595; L(Test): 0.2940133213996887\n",
      "Epoch 2983/10000: L(Train): 0.29458850622177124; L(Test): 0.29488760232925415\n",
      "Epoch 2984/10000: L(Train): 0.3028981387615204; L(Test): 0.29119858145713806\n",
      "Epoch 2985/10000: L(Train): 0.2834094762802124; L(Test): 0.28959518671035767\n",
      "Epoch 2986/10000: L(Train): 0.2901451289653778; L(Test): 0.2888389825820923\n",
      "Epoch 2987/10000: L(Train): 0.3044535517692566; L(Test): 0.28767725825309753\n",
      "Epoch 2988/10000: L(Train): 0.2929235100746155; L(Test): 0.287570059299469\n",
      "Epoch 2989/10000: L(Train): 0.3002084195613861; L(Test): 0.28816694021224976\n",
      "Epoch 2990/10000: L(Train): 0.30596673488616943; L(Test): 0.2886088788509369\n",
      "Epoch 2991/10000: L(Train): 0.29891330003738403; L(Test): 0.2866058647632599\n",
      "Epoch 2992/10000: L(Train): 0.2957026958465576; L(Test): 0.28405502438545227\n",
      "Epoch 2993/10000: L(Train): 0.3074221611022949; L(Test): 0.28234705328941345\n",
      "Epoch 2994/10000: L(Train): 0.303726464509964; L(Test): 0.28025850653648376\n",
      "Epoch 2995/10000: L(Train): 0.294969379901886; L(Test): 0.27891218662261963\n",
      "Epoch 2996/10000: L(Train): 0.29471156001091003; L(Test): 0.2799345850944519\n",
      "Epoch 2997/10000: L(Train): 0.2968156933784485; L(Test): 0.2781783938407898\n",
      "Epoch 2998/10000: L(Train): 0.30318576097488403; L(Test): 0.27471449971199036\n",
      "Epoch 2999/10000: L(Train): 0.3038129210472107; L(Test): 0.2734980583190918\n",
      "Epoch 3000/10000: L(Train): 0.27837708592414856; L(Test): 0.2726599872112274\n",
      "Epoch 3001/10000: L(Train): 0.28970867395401; L(Test): 0.27136942744255066\n",
      "Epoch 3002/10000: L(Train): 0.2913210093975067; L(Test): 0.27187681198120117\n",
      "Epoch 3003/10000: L(Train): 0.27316272258758545; L(Test): 0.2717745006084442\n",
      "Epoch 3004/10000: L(Train): 0.2878858149051666; L(Test): 0.26871252059936523\n",
      "Epoch 3005/10000: L(Train): 0.27227291464805603; L(Test): 0.2673475444316864\n",
      "Epoch 3006/10000: L(Train): 0.29109153151512146; L(Test): 0.2665899693965912\n",
      "Epoch 3007/10000: L(Train): 0.282130628824234; L(Test): 0.2653496563434601\n",
      "Epoch 3008/10000: L(Train): 0.2906237244606018; L(Test): 0.26474666595458984\n",
      "Epoch 3009/10000: L(Train): 0.27328670024871826; L(Test): 0.2648144066333771\n",
      "Epoch 3010/10000: L(Train): 0.2888852655887604; L(Test): 0.2637997567653656\n",
      "Epoch 3011/10000: L(Train): 0.2840806841850281; L(Test): 0.2620042562484741\n",
      "Epoch 3012/10000: L(Train): 0.2689601480960846; L(Test): 0.26143407821655273\n",
      "Epoch 3013/10000: L(Train): 0.2751469314098358; L(Test): 0.2610100507736206\n",
      "Epoch 3014/10000: L(Train): 0.28044435381889343; L(Test): 0.2591535449028015\n",
      "Epoch 3015/10000: L(Train): 0.26537656784057617; L(Test): 0.2598028779029846\n",
      "Epoch 3016/10000: L(Train): 0.2805134952068329; L(Test): 0.2597466707229614\n",
      "Epoch 3017/10000: L(Train): 0.290128618478775; L(Test): 0.25695282220840454\n",
      "Epoch 3018/10000: L(Train): 0.28640103340148926; L(Test): 0.2558634579181671\n",
      "Epoch 3019/10000: L(Train): 0.2799644470214844; L(Test): 0.2557394802570343\n",
      "Epoch 3020/10000: L(Train): 0.2684183716773987; L(Test): 0.25555703043937683\n",
      "Epoch 3021/10000: L(Train): 0.2704384922981262; L(Test): 0.2563265264034271\n",
      "Epoch 3022/10000: L(Train): 0.2790929973125458; L(Test): 0.2575697600841522\n",
      "Epoch 3023/10000: L(Train): 0.2703482508659363; L(Test): 0.25511693954467773\n",
      "Epoch 3024/10000: L(Train): 0.27920135855674744; L(Test): 0.25412997603416443\n",
      "Epoch 3025/10000: L(Train): 0.27158668637275696; L(Test): 0.2546308636665344\n",
      "Epoch 3026/10000: L(Train): 0.2680729925632477; L(Test): 0.2546883523464203\n",
      "Epoch 3027/10000: L(Train): 0.274889200925827; L(Test): 0.25412383675575256\n",
      "Epoch 3028/10000: L(Train): 0.2745048403739929; L(Test): 0.25523608922958374\n",
      "Epoch 3029/10000: L(Train): 0.2659061849117279; L(Test): 0.2553020119667053\n",
      "Epoch 3030/10000: L(Train): 0.26196566224098206; L(Test): 0.25287577509880066\n",
      "Epoch 3031/10000: L(Train): 0.26572197675704956; L(Test): 0.252882719039917\n",
      "Epoch 3032/10000: L(Train): 0.2749589681625366; L(Test): 0.25459975004196167\n",
      "Epoch 3033/10000: L(Train): 0.2831338047981262; L(Test): 0.25289782881736755\n",
      "Epoch 3034/10000: L(Train): 0.25537410378456116; L(Test): 0.25226861238479614\n",
      "Epoch 3035/10000: L(Train): 0.26697057485580444; L(Test): 0.2512264847755432\n",
      "Epoch 3036/10000: L(Train): 0.270652711391449; L(Test): 0.2510035037994385\n",
      "Epoch 3037/10000: L(Train): 0.26688113808631897; L(Test): 0.2520693242549896\n",
      "Epoch 3038/10000: L(Train): 0.2675800323486328; L(Test): 0.2509399652481079\n",
      "Epoch 3039/10000: L(Train): 0.2801281809806824; L(Test): 0.24977357685565948\n",
      "Epoch 3040/10000: L(Train): 0.27981510758399963; L(Test): 0.2498408704996109\n",
      "Epoch 3041/10000: L(Train): 0.2754130959510803; L(Test): 0.24992221593856812\n",
      "Epoch 3042/10000: L(Train): 0.27376803755760193; L(Test): 0.250674307346344\n",
      "Epoch 3043/10000: L(Train): 0.2722841799259186; L(Test): 0.24993064999580383\n",
      "Epoch 3044/10000: L(Train): 0.27281102538108826; L(Test): 0.24865926802158356\n",
      "Epoch 3045/10000: L(Train): 0.2659508287906647; L(Test): 0.24821482598781586\n",
      "Epoch 3046/10000: L(Train): 0.26255354285240173; L(Test): 0.24811264872550964\n",
      "Epoch 3047/10000: L(Train): 0.2670632600784302; L(Test): 0.24795840680599213\n",
      "Epoch 3048/10000: L(Train): 0.27596426010131836; L(Test): 0.24845710396766663\n",
      "Epoch 3049/10000: L(Train): 0.26024094223976135; L(Test): 0.24813060462474823\n",
      "Epoch 3050/10000: L(Train): 0.27763116359710693; L(Test): 0.24793192744255066\n",
      "Epoch 3051/10000: L(Train): 0.2635432481765747; L(Test): 0.24746540188789368\n",
      "Epoch 3052/10000: L(Train): 0.2588716745376587; L(Test): 0.24770291149616241\n",
      "Epoch 3053/10000: L(Train): 0.27158865332603455; L(Test): 0.2470553070306778\n",
      "Epoch 3054/10000: L(Train): 0.2652350068092346; L(Test): 0.24665629863739014\n",
      "Epoch 3055/10000: L(Train): 0.2671521008014679; L(Test): 0.2465645670890808\n",
      "Epoch 3056/10000: L(Train): 0.27574652433395386; L(Test): 0.24666208028793335\n",
      "Epoch 3057/10000: L(Train): 0.2607274055480957; L(Test): 0.24639058113098145\n",
      "Epoch 3058/10000: L(Train): 0.25429093837738037; L(Test): 0.24622371792793274\n",
      "Epoch 3059/10000: L(Train): 0.26249030232429504; L(Test): 0.2462565004825592\n",
      "Epoch 3060/10000: L(Train): 0.26844844222068787; L(Test): 0.24528643488883972\n",
      "Epoch 3061/10000: L(Train): 0.26410749554634094; L(Test): 0.24486413598060608\n",
      "Epoch 3062/10000: L(Train): 0.27387118339538574; L(Test): 0.24498580396175385\n",
      "Epoch 3063/10000: L(Train): 0.2755656838417053; L(Test): 0.2445332556962967\n",
      "Epoch 3064/10000: L(Train): 0.2646116614341736; L(Test): 0.24439704418182373\n",
      "Epoch 3065/10000: L(Train): 0.2766866385936737; L(Test): 0.2451498955488205\n",
      "Epoch 3066/10000: L(Train): 0.25928497314453125; L(Test): 0.24542823433876038\n",
      "Epoch 3067/10000: L(Train): 0.26211991906166077; L(Test): 0.24586854875087738\n",
      "Epoch 3068/10000: L(Train): 0.2626774311065674; L(Test): 0.2463598996400833\n",
      "Epoch 3069/10000: L(Train): 0.2688024938106537; L(Test): 0.24538706243038177\n",
      "Epoch 3070/10000: L(Train): 0.2705133259296417; L(Test): 0.24456758797168732\n",
      "Epoch 3071/10000: L(Train): 0.2674191892147064; L(Test): 0.24538736045360565\n",
      "Epoch 3072/10000: L(Train): 0.26985907554626465; L(Test): 0.24402165412902832\n",
      "Epoch 3073/10000: L(Train): 0.2517879903316498; L(Test): 0.24402379989624023\n",
      "Epoch 3074/10000: L(Train): 0.25325390696525574; L(Test): 0.24479351937770844\n",
      "Epoch 3075/10000: L(Train): 0.25995081663131714; L(Test): 0.24486425518989563\n",
      "Epoch 3076/10000: L(Train): 0.2812366783618927; L(Test): 0.2435484081506729\n",
      "Epoch 3077/10000: L(Train): 0.2779842019081116; L(Test): 0.24402225017547607\n",
      "Epoch 3078/10000: L(Train): 0.26192688941955566; L(Test): 0.24428893625736237\n",
      "Epoch 3079/10000: L(Train): 0.27389252185821533; L(Test): 0.24383558332920074\n",
      "Epoch 3080/10000: L(Train): 0.25048506259918213; L(Test): 0.2435235232114792\n",
      "Epoch 3081/10000: L(Train): 0.26063936948776245; L(Test): 0.24414683878421783\n",
      "Epoch 3082/10000: L(Train): 0.2871731221675873; L(Test): 0.24409788846969604\n",
      "Epoch 3083/10000: L(Train): 0.25737082958221436; L(Test): 0.24458131194114685\n",
      "Epoch 3084/10000: L(Train): 0.2680860161781311; L(Test): 0.24392502009868622\n",
      "Epoch 3085/10000: L(Train): 0.27492284774780273; L(Test): 0.2446233183145523\n",
      "Epoch 3086/10000: L(Train): 0.2610255777835846; L(Test): 0.2466566264629364\n",
      "Epoch 3087/10000: L(Train): 0.2641616463661194; L(Test): 0.24648234248161316\n",
      "Epoch 3088/10000: L(Train): 0.25526517629623413; L(Test): 0.2460230588912964\n",
      "Epoch 3089/10000: L(Train): 0.26896098256111145; L(Test): 0.24620746076107025\n",
      "Epoch 3090/10000: L(Train): 0.2679498493671417; L(Test): 0.24923205375671387\n",
      "Epoch 3091/10000: L(Train): 0.27926406264305115; L(Test): 0.24782609939575195\n",
      "Epoch 3092/10000: L(Train): 0.26674267649650574; L(Test): 0.24705834686756134\n",
      "Epoch 3093/10000: L(Train): 0.2674477994441986; L(Test): 0.247983917593956\n",
      "Epoch 3094/10000: L(Train): 0.25432896614074707; L(Test): 0.24711333215236664\n",
      "Epoch 3095/10000: L(Train): 0.2790946960449219; L(Test): 0.24599489569664001\n",
      "Epoch 3096/10000: L(Train): 0.2659405767917633; L(Test): 0.24562260508537292\n",
      "Epoch 3097/10000: L(Train): 0.26365795731544495; L(Test): 0.24710457026958466\n",
      "Epoch 3098/10000: L(Train): 0.26757270097732544; L(Test): 0.24670007824897766\n",
      "Epoch 3099/10000: L(Train): 0.2668565809726715; L(Test): 0.24626955389976501\n",
      "Epoch 3100/10000: L(Train): 0.26435112953186035; L(Test): 0.24646899104118347\n",
      "Epoch 3101/10000: L(Train): 0.270301878452301; L(Test): 0.24515630304813385\n",
      "Epoch 3102/10000: L(Train): 0.250083863735199; L(Test): 0.24646084010601044\n",
      "Epoch 3103/10000: L(Train): 0.26911306381225586; L(Test): 0.24480657279491425\n",
      "Epoch 3104/10000: L(Train): 0.24868252873420715; L(Test): 0.2447669506072998\n",
      "Epoch 3105/10000: L(Train): 0.2629683315753937; L(Test): 0.24467723071575165\n",
      "Epoch 3106/10000: L(Train): 0.26026564836502075; L(Test): 0.24427290260791779\n",
      "Epoch 3107/10000: L(Train): 0.26193544268608093; L(Test): 0.24468037486076355\n",
      "Epoch 3108/10000: L(Train): 0.26789745688438416; L(Test): 0.24529294669628143\n",
      "Epoch 3109/10000: L(Train): 0.24784629046916962; L(Test): 0.2454071044921875\n",
      "Epoch 3110/10000: L(Train): 0.27201080322265625; L(Test): 0.24506033957004547\n",
      "Epoch 3111/10000: L(Train): 0.28047946095466614; L(Test): 0.2453937977552414\n",
      "Epoch 3112/10000: L(Train): 0.26455408334732056; L(Test): 0.2448786199092865\n",
      "Epoch 3113/10000: L(Train): 0.2722565531730652; L(Test): 0.24361491203308105\n",
      "Epoch 3114/10000: L(Train): 0.2491169273853302; L(Test): 0.2438775897026062\n",
      "Epoch 3115/10000: L(Train): 0.2559889256954193; L(Test): 0.24470704793930054\n",
      "Epoch 3116/10000: L(Train): 0.26877620816230774; L(Test): 0.24428324401378632\n",
      "Epoch 3117/10000: L(Train): 0.26244714856147766; L(Test): 0.2431807518005371\n",
      "Epoch 3118/10000: L(Train): 0.2672424018383026; L(Test): 0.24389347434043884\n",
      "Epoch 3119/10000: L(Train): 0.24924391508102417; L(Test): 0.2437254935503006\n",
      "Epoch 3120/10000: L(Train): 0.2762158215045929; L(Test): 0.24317973852157593\n",
      "Epoch 3121/10000: L(Train): 0.2628108263015747; L(Test): 0.24516978859901428\n",
      "Epoch 3122/10000: L(Train): 0.24645574390888214; L(Test): 0.24428647756576538\n",
      "Epoch 3123/10000: L(Train): 0.26796165108680725; L(Test): 0.2431761920452118\n",
      "Epoch 3124/10000: L(Train): 0.26075175404548645; L(Test): 0.24291755259037018\n",
      "Epoch 3125/10000: L(Train): 0.255905419588089; L(Test): 0.2442510575056076\n",
      "Epoch 3126/10000: L(Train): 0.2621947228908539; L(Test): 0.2437160462141037\n",
      "Epoch 3127/10000: L(Train): 0.27958574891090393; L(Test): 0.24303457140922546\n",
      "Epoch 3128/10000: L(Train): 0.2607743442058563; L(Test): 0.24298213422298431\n",
      "Epoch 3129/10000: L(Train): 0.2718231678009033; L(Test): 0.24310335516929626\n",
      "Epoch 3130/10000: L(Train): 0.268073707818985; L(Test): 0.24259012937545776\n",
      "Epoch 3131/10000: L(Train): 0.2723744511604309; L(Test): 0.24232220649719238\n",
      "Epoch 3132/10000: L(Train): 0.2702557146549225; L(Test): 0.24261537194252014\n",
      "Epoch 3133/10000: L(Train): 0.26841965317726135; L(Test): 0.2423122525215149\n",
      "Epoch 3134/10000: L(Train): 0.2769068479537964; L(Test): 0.24248234927654266\n",
      "Epoch 3135/10000: L(Train): 0.2701447904109955; L(Test): 0.2423834502696991\n",
      "Epoch 3136/10000: L(Train): 0.2724689245223999; L(Test): 0.24245013296604156\n",
      "Epoch 3137/10000: L(Train): 0.2710411250591278; L(Test): 0.24198319017887115\n",
      "Epoch 3138/10000: L(Train): 0.2675072252750397; L(Test): 0.2433147132396698\n",
      "Epoch 3139/10000: L(Train): 0.26524364948272705; L(Test): 0.24314329028129578\n",
      "Epoch 3140/10000: L(Train): 0.27523913979530334; L(Test): 0.2424386590719223\n",
      "Epoch 3141/10000: L(Train): 0.262175589799881; L(Test): 0.24216127395629883\n",
      "Epoch 3142/10000: L(Train): 0.27499422430992126; L(Test): 0.24214617908000946\n",
      "Epoch 3143/10000: L(Train): 0.27393022179603577; L(Test): 0.24214491248130798\n",
      "Epoch 3144/10000: L(Train): 0.2806381583213806; L(Test): 0.24167528748512268\n",
      "Epoch 3145/10000: L(Train): 0.2751491069793701; L(Test): 0.24146564304828644\n",
      "Epoch 3146/10000: L(Train): 0.2580045163631439; L(Test): 0.2423301637172699\n",
      "Epoch 3147/10000: L(Train): 0.26091885566711426; L(Test): 0.24244222044944763\n",
      "Epoch 3148/10000: L(Train): 0.2624731659889221; L(Test): 0.24222251772880554\n",
      "Epoch 3149/10000: L(Train): 0.2696651816368103; L(Test): 0.24198228120803833\n",
      "Epoch 3150/10000: L(Train): 0.2580738663673401; L(Test): 0.242888405919075\n",
      "Epoch 3151/10000: L(Train): 0.2706032395362854; L(Test): 0.24235780537128448\n",
      "Epoch 3152/10000: L(Train): 0.2713004946708679; L(Test): 0.24249981343746185\n",
      "Epoch 3153/10000: L(Train): 0.2499118596315384; L(Test): 0.24271143972873688\n",
      "Epoch 3154/10000: L(Train): 0.2560069262981415; L(Test): 0.24199289083480835\n",
      "Epoch 3155/10000: L(Train): 0.2530073821544647; L(Test): 0.24141210317611694\n",
      "Epoch 3156/10000: L(Train): 0.26404011249542236; L(Test): 0.24203532934188843\n",
      "Epoch 3157/10000: L(Train): 0.27118703722953796; L(Test): 0.2416105568408966\n",
      "Epoch 3158/10000: L(Train): 0.2552834153175354; L(Test): 0.24114057421684265\n",
      "Epoch 3159/10000: L(Train): 0.2504883408546448; L(Test): 0.24200589954853058\n",
      "Epoch 3160/10000: L(Train): 0.27866196632385254; L(Test): 0.24167151749134064\n",
      "Epoch 3161/10000: L(Train): 0.2574368119239807; L(Test): 0.24124638736248016\n",
      "Epoch 3162/10000: L(Train): 0.2522274851799011; L(Test): 0.24131891131401062\n",
      "Epoch 3163/10000: L(Train): 0.26404380798339844; L(Test): 0.2413794994354248\n",
      "Epoch 3164/10000: L(Train): 0.26623761653900146; L(Test): 0.24102117121219635\n",
      "Epoch 3165/10000: L(Train): 0.27107542753219604; L(Test): 0.24165867269039154\n",
      "Epoch 3166/10000: L(Train): 0.2569408416748047; L(Test): 0.24064503610134125\n",
      "Epoch 3167/10000: L(Train): 0.25480061769485474; L(Test): 0.24092304706573486\n",
      "Epoch 3168/10000: L(Train): 0.2649804651737213; L(Test): 0.24242854118347168\n",
      "Epoch 3169/10000: L(Train): 0.26530352234840393; L(Test): 0.24082615971565247\n",
      "Epoch 3170/10000: L(Train): 0.2664441168308258; L(Test): 0.24118858575820923\n",
      "Epoch 3171/10000: L(Train): 0.2764987051486969; L(Test): 0.24191947281360626\n",
      "Epoch 3172/10000: L(Train): 0.267048180103302; L(Test): 0.24134096503257751\n",
      "Epoch 3173/10000: L(Train): 0.26211053133010864; L(Test): 0.24000270664691925\n",
      "Epoch 3174/10000: L(Train): 0.26484382152557373; L(Test): 0.24018780887126923\n",
      "Epoch 3175/10000: L(Train): 0.25290223956108093; L(Test): 0.24202653765678406\n",
      "Epoch 3176/10000: L(Train): 0.26468536257743835; L(Test): 0.24110029637813568\n",
      "Epoch 3177/10000: L(Train): 0.2548603117465973; L(Test): 0.2408200353384018\n",
      "Epoch 3178/10000: L(Train): 0.26506200432777405; L(Test): 0.2415303736925125\n",
      "Epoch 3179/10000: L(Train): 0.26792263984680176; L(Test): 0.2413558065891266\n",
      "Epoch 3180/10000: L(Train): 0.26605045795440674; L(Test): 0.2427496463060379\n",
      "Epoch 3181/10000: L(Train): 0.26482146978378296; L(Test): 0.24296920001506805\n",
      "Epoch 3182/10000: L(Train): 0.2625371515750885; L(Test): 0.24320700764656067\n",
      "Epoch 3183/10000: L(Train): 0.2605752646923065; L(Test): 0.2421995848417282\n",
      "Epoch 3184/10000: L(Train): 0.26509687304496765; L(Test): 0.24541209638118744\n",
      "Epoch 3185/10000: L(Train): 0.2718921899795532; L(Test): 0.24428614974021912\n",
      "Epoch 3186/10000: L(Train): 0.2647901475429535; L(Test): 0.24154040217399597\n",
      "Epoch 3187/10000: L(Train): 0.2653687596321106; L(Test): 0.24345187842845917\n",
      "Epoch 3188/10000: L(Train): 0.2675212621688843; L(Test): 0.24262329936027527\n",
      "Epoch 3189/10000: L(Train): 0.2644537091255188; L(Test): 0.24580159783363342\n",
      "Epoch 3190/10000: L(Train): 0.2697046101093292; L(Test): 0.24142557382583618\n",
      "Epoch 3191/10000: L(Train): 0.27156051993370056; L(Test): 0.24362421035766602\n",
      "Epoch 3192/10000: L(Train): 0.2699802815914154; L(Test): 0.24473999440670013\n",
      "Epoch 3193/10000: L(Train): 0.28269854187965393; L(Test): 0.2454264909029007\n",
      "Epoch 3194/10000: L(Train): 0.27218449115753174; L(Test): 0.24568316340446472\n",
      "Epoch 3195/10000: L(Train): 0.26752182841300964; L(Test): 0.24534589052200317\n",
      "Epoch 3196/10000: L(Train): 0.2674483060836792; L(Test): 0.24441520869731903\n",
      "Epoch 3197/10000: L(Train): 0.2750200629234314; L(Test): 0.24430201947689056\n",
      "Epoch 3198/10000: L(Train): 0.2615948021411896; L(Test): 0.24485169351100922\n",
      "Epoch 3199/10000: L(Train): 0.27422618865966797; L(Test): 0.24310411512851715\n",
      "Epoch 3200/10000: L(Train): 0.26100653409957886; L(Test): 0.24267971515655518\n",
      "Epoch 3201/10000: L(Train): 0.27274829149246216; L(Test): 0.24407947063446045\n",
      "Epoch 3202/10000: L(Train): 0.2659328281879425; L(Test): 0.24306634068489075\n",
      "Epoch 3203/10000: L(Train): 0.2657086253166199; L(Test): 0.2428755909204483\n",
      "Epoch 3204/10000: L(Train): 0.26622867584228516; L(Test): 0.24343448877334595\n",
      "Epoch 3205/10000: L(Train): 0.2754249572753906; L(Test): 0.24304957687854767\n",
      "Epoch 3206/10000: L(Train): 0.2700037658214569; L(Test): 0.2425173968076706\n",
      "Epoch 3207/10000: L(Train): 0.2662659287452698; L(Test): 0.2431316375732422\n",
      "Epoch 3208/10000: L(Train): 0.26383137702941895; L(Test): 0.24272887408733368\n",
      "Epoch 3209/10000: L(Train): 0.27066677808761597; L(Test): 0.24256330728530884\n",
      "Epoch 3210/10000: L(Train): 0.26246514916419983; L(Test): 0.24232380092144012\n",
      "Epoch 3211/10000: L(Train): 0.2753283381462097; L(Test): 0.24211296439170837\n",
      "Epoch 3212/10000: L(Train): 0.2644464671611786; L(Test): 0.24248632788658142\n",
      "Epoch 3213/10000: L(Train): 0.2713243365287781; L(Test): 0.2430683970451355\n",
      "Epoch 3214/10000: L(Train): 0.2610810101032257; L(Test): 0.24243178963661194\n",
      "Epoch 3215/10000: L(Train): 0.2746888995170593; L(Test): 0.24192261695861816\n",
      "Epoch 3216/10000: L(Train): 0.2716667950153351; L(Test): 0.24139568209648132\n",
      "Epoch 3217/10000: L(Train): 0.24856895208358765; L(Test): 0.24161478877067566\n",
      "Epoch 3218/10000: L(Train): 0.252214640378952; L(Test): 0.2415880262851715\n",
      "Epoch 3219/10000: L(Train): 0.256373792886734; L(Test): 0.24165043234825134\n",
      "Epoch 3220/10000: L(Train): 0.2747438848018646; L(Test): 0.24178050458431244\n",
      "Epoch 3221/10000: L(Train): 0.26058533787727356; L(Test): 0.24151627719402313\n",
      "Epoch 3222/10000: L(Train): 0.26149603724479675; L(Test): 0.2411927431821823\n",
      "Epoch 3223/10000: L(Train): 0.25047439336776733; L(Test): 0.24170586466789246\n",
      "Epoch 3224/10000: L(Train): 0.2667737901210785; L(Test): 0.24081113934516907\n",
      "Epoch 3225/10000: L(Train): 0.2626764178276062; L(Test): 0.24032773077487946\n",
      "Epoch 3226/10000: L(Train): 0.26752591133117676; L(Test): 0.24108603596687317\n",
      "Epoch 3227/10000: L(Train): 0.2696191370487213; L(Test): 0.24157391488552094\n",
      "Epoch 3228/10000: L(Train): 0.26287975907325745; L(Test): 0.24155867099761963\n",
      "Epoch 3229/10000: L(Train): 0.25783172249794006; L(Test): 0.24139727652072906\n",
      "Epoch 3230/10000: L(Train): 0.2590939700603485; L(Test): 0.24125702679157257\n",
      "Epoch 3231/10000: L(Train): 0.2675001621246338; L(Test): 0.24194830656051636\n",
      "Epoch 3232/10000: L(Train): 0.2790108025074005; L(Test): 0.24195872247219086\n",
      "Epoch 3233/10000: L(Train): 0.2653965950012207; L(Test): 0.24191303551197052\n",
      "Epoch 3234/10000: L(Train): 0.27020183205604553; L(Test): 0.241935133934021\n",
      "Epoch 3235/10000: L(Train): 0.25725579261779785; L(Test): 0.24265390634536743\n",
      "Epoch 3236/10000: L(Train): 0.27088144421577454; L(Test): 0.24456048011779785\n",
      "Epoch 3237/10000: L(Train): 0.28090935945510864; L(Test): 0.24335503578186035\n",
      "Epoch 3238/10000: L(Train): 0.256352037191391; L(Test): 0.2420269250869751\n",
      "Epoch 3239/10000: L(Train): 0.2716028094291687; L(Test): 0.24356892704963684\n",
      "Epoch 3240/10000: L(Train): 0.2738111913204193; L(Test): 0.24394813179969788\n",
      "Epoch 3241/10000: L(Train): 0.25995078682899475; L(Test): 0.24375052750110626\n",
      "Epoch 3242/10000: L(Train): 0.2596158981323242; L(Test): 0.24450670182704926\n",
      "Epoch 3243/10000: L(Train): 0.2671516537666321; L(Test): 0.24466748535633087\n",
      "Epoch 3244/10000: L(Train): 0.2600102722644806; L(Test): 0.24196143448352814\n",
      "Epoch 3245/10000: L(Train): 0.25773635506629944; L(Test): 0.24235248565673828\n",
      "Epoch 3246/10000: L(Train): 0.2538105249404907; L(Test): 0.24338997900485992\n",
      "Epoch 3247/10000: L(Train): 0.25828462839126587; L(Test): 0.2425222545862198\n",
      "Epoch 3248/10000: L(Train): 0.27429962158203125; L(Test): 0.2422969490289688\n",
      "Epoch 3249/10000: L(Train): 0.26957598328590393; L(Test): 0.24424496293067932\n",
      "Epoch 3250/10000: L(Train): 0.2669740617275238; L(Test): 0.24349012970924377\n",
      "Epoch 3251/10000: L(Train): 0.2695610821247101; L(Test): 0.2424512505531311\n",
      "Epoch 3252/10000: L(Train): 0.26947885751724243; L(Test): 0.24277982115745544\n",
      "Epoch 3253/10000: L(Train): 0.2702442407608032; L(Test): 0.24382461607456207\n",
      "Epoch 3254/10000: L(Train): 0.2710278332233429; L(Test): 0.24299560487270355\n",
      "Epoch 3255/10000: L(Train): 0.2692946791648865; L(Test): 0.24245893955230713\n",
      "Epoch 3256/10000: L(Train): 0.26374688744544983; L(Test): 0.24299593269824982\n",
      "Epoch 3257/10000: L(Train): 0.26802992820739746; L(Test): 0.24271537363529205\n",
      "Epoch 3258/10000: L(Train): 0.2516179084777832; L(Test): 0.24240249395370483\n",
      "Epoch 3259/10000: L(Train): 0.2677084505558014; L(Test): 0.2437225878238678\n",
      "Epoch 3260/10000: L(Train): 0.2609739899635315; L(Test): 0.24345369637012482\n",
      "Epoch 3261/10000: L(Train): 0.2698060870170593; L(Test): 0.24239271879196167\n",
      "Epoch 3262/10000: L(Train): 0.27796679735183716; L(Test): 0.24284136295318604\n",
      "Epoch 3263/10000: L(Train): 0.2655618190765381; L(Test): 0.2419949471950531\n",
      "Epoch 3264/10000: L(Train): 0.2652055025100708; L(Test): 0.2419588714838028\n",
      "Epoch 3265/10000: L(Train): 0.2600895166397095; L(Test): 0.24438339471817017\n",
      "Epoch 3266/10000: L(Train): 0.275890976190567; L(Test): 0.24176526069641113\n",
      "Epoch 3267/10000: L(Train): 0.26255476474761963; L(Test): 0.24214422702789307\n",
      "Epoch 3268/10000: L(Train): 0.24736753106117249; L(Test): 0.242840975522995\n",
      "Epoch 3269/10000: L(Train): 0.2590998411178589; L(Test): 0.24246713519096375\n",
      "Epoch 3270/10000: L(Train): 0.2519169747829437; L(Test): 0.24344056844711304\n",
      "Epoch 3271/10000: L(Train): 0.26581114530563354; L(Test): 0.24329249560832977\n",
      "Epoch 3272/10000: L(Train): 0.26419493556022644; L(Test): 0.24117425084114075\n",
      "Epoch 3273/10000: L(Train): 0.2480834722518921; L(Test): 0.24170082807540894\n",
      "Epoch 3274/10000: L(Train): 0.2586767077445984; L(Test): 0.24247686564922333\n",
      "Epoch 3275/10000: L(Train): 0.26865383982658386; L(Test): 0.24206455051898956\n",
      "Epoch 3276/10000: L(Train): 0.26693564653396606; L(Test): 0.2419758439064026\n",
      "Epoch 3277/10000: L(Train): 0.2529398202896118; L(Test): 0.24353447556495667\n",
      "Epoch 3278/10000: L(Train): 0.2728710472583771; L(Test): 0.241986483335495\n",
      "Epoch 3279/10000: L(Train): 0.254682332277298; L(Test): 0.24327492713928223\n",
      "Epoch 3280/10000: L(Train): 0.26459693908691406; L(Test): 0.24350976943969727\n",
      "Epoch 3281/10000: L(Train): 0.2632986009120941; L(Test): 0.24301694333553314\n",
      "Epoch 3282/10000: L(Train): 0.26282942295074463; L(Test): 0.24228322505950928\n",
      "Epoch 3283/10000: L(Train): 0.2588338255882263; L(Test): 0.243197500705719\n",
      "Epoch 3284/10000: L(Train): 0.25998520851135254; L(Test): 0.24423393607139587\n",
      "Epoch 3285/10000: L(Train): 0.27895334362983704; L(Test): 0.2420404702425003\n",
      "Epoch 3286/10000: L(Train): 0.2581811845302582; L(Test): 0.24329788982868195\n",
      "Epoch 3287/10000: L(Train): 0.26148471236228943; L(Test): 0.2432030290365219\n",
      "Epoch 3288/10000: L(Train): 0.27699774503707886; L(Test): 0.2416548877954483\n",
      "Epoch 3289/10000: L(Train): 0.25897032022476196; L(Test): 0.2427964210510254\n",
      "Epoch 3290/10000: L(Train): 0.2658647298812866; L(Test): 0.24409666657447815\n",
      "Epoch 3291/10000: L(Train): 0.26759612560272217; L(Test): 0.24259735643863678\n",
      "Epoch 3292/10000: L(Train): 0.27070382237434387; L(Test): 0.24252401292324066\n",
      "Epoch 3293/10000: L(Train): 0.26403555274009705; L(Test): 0.24305729568004608\n",
      "Epoch 3294/10000: L(Train): 0.2674892544746399; L(Test): 0.2427191436290741\n",
      "Epoch 3295/10000: L(Train): 0.2622263431549072; L(Test): 0.24216388165950775\n",
      "Epoch 3296/10000: L(Train): 0.2615026831626892; L(Test): 0.24197544157505035\n",
      "Epoch 3297/10000: L(Train): 0.26368942856788635; L(Test): 0.24295160174369812\n",
      "Epoch 3298/10000: L(Train): 0.2520160675048828; L(Test): 0.24276494979858398\n",
      "Epoch 3299/10000: L(Train): 0.25529974699020386; L(Test): 0.24145378172397614\n",
      "Epoch 3300/10000: L(Train): 0.2662050426006317; L(Test): 0.24114686250686646\n",
      "Epoch 3301/10000: L(Train): 0.2583652436733246; L(Test): 0.24081377685070038\n",
      "Epoch 3302/10000: L(Train): 0.2625541687011719; L(Test): 0.24094833433628082\n",
      "Epoch 3303/10000: L(Train): 0.2701076567173004; L(Test): 0.24212905764579773\n",
      "Epoch 3304/10000: L(Train): 0.2653438448905945; L(Test): 0.24170447885990143\n",
      "Epoch 3305/10000: L(Train): 0.2642412483692169; L(Test): 0.24159611761569977\n",
      "Epoch 3306/10000: L(Train): 0.25965452194213867; L(Test): 0.24167688190937042\n",
      "Epoch 3307/10000: L(Train): 0.27331143617630005; L(Test): 0.24120675027370453\n",
      "Epoch 3308/10000: L(Train): 0.27000686526298523; L(Test): 0.2417345494031906\n",
      "Epoch 3309/10000: L(Train): 0.2610146403312683; L(Test): 0.24399180710315704\n",
      "Epoch 3310/10000: L(Train): 0.2580772638320923; L(Test): 0.24343591928482056\n",
      "Epoch 3311/10000: L(Train): 0.25843486189842224; L(Test): 0.24082738161087036\n",
      "Epoch 3312/10000: L(Train): 0.26378563046455383; L(Test): 0.24193984270095825\n",
      "Epoch 3313/10000: L(Train): 0.25523126125335693; L(Test): 0.24275922775268555\n",
      "Epoch 3314/10000: L(Train): 0.27118271589279175; L(Test): 0.24119925498962402\n",
      "Epoch 3315/10000: L(Train): 0.264739453792572; L(Test): 0.24247893691062927\n",
      "Epoch 3316/10000: L(Train): 0.28005701303482056; L(Test): 0.24320054054260254\n",
      "Epoch 3317/10000: L(Train): 0.2514878511428833; L(Test): 0.24190862476825714\n",
      "Epoch 3318/10000: L(Train): 0.2688504755496979; L(Test): 0.2409883439540863\n",
      "Epoch 3319/10000: L(Train): 0.26054608821868896; L(Test): 0.2416275590658188\n",
      "Epoch 3320/10000: L(Train): 0.2580430805683136; L(Test): 0.2438882291316986\n",
      "Epoch 3321/10000: L(Train): 0.26488083600997925; L(Test): 0.24325664341449738\n",
      "Epoch 3322/10000: L(Train): 0.2686897814273834; L(Test): 0.24294419586658478\n",
      "Epoch 3323/10000: L(Train): 0.27281078696250916; L(Test): 0.24263009428977966\n",
      "Epoch 3324/10000: L(Train): 0.2596585750579834; L(Test): 0.24322441220283508\n",
      "Epoch 3325/10000: L(Train): 0.2595652937889099; L(Test): 0.24355387687683105\n",
      "Epoch 3326/10000: L(Train): 0.267995148897171; L(Test): 0.24192634224891663\n",
      "Epoch 3327/10000: L(Train): 0.26839393377304077; L(Test): 0.24182137846946716\n",
      "Epoch 3328/10000: L(Train): 0.26044321060180664; L(Test): 0.24245375394821167\n",
      "Epoch 3329/10000: L(Train): 0.2679893672466278; L(Test): 0.24286024272441864\n",
      "Epoch 3330/10000: L(Train): 0.27983400225639343; L(Test): 0.24107955396175385\n",
      "Epoch 3331/10000: L(Train): 0.24580928683280945; L(Test): 0.24155354499816895\n",
      "Epoch 3332/10000: L(Train): 0.2551625072956085; L(Test): 0.24181091785430908\n",
      "Epoch 3333/10000: L(Train): 0.2707592248916626; L(Test): 0.24374227225780487\n",
      "Epoch 3334/10000: L(Train): 0.2667379081249237; L(Test): 0.24361690878868103\n",
      "Epoch 3335/10000: L(Train): 0.26914605498313904; L(Test): 0.24134673178195953\n",
      "Epoch 3336/10000: L(Train): 0.25603264570236206; L(Test): 0.24256518483161926\n",
      "Epoch 3337/10000: L(Train): 0.2543099820613861; L(Test): 0.24183320999145508\n",
      "Epoch 3338/10000: L(Train): 0.2602580785751343; L(Test): 0.24392512440681458\n",
      "Epoch 3339/10000: L(Train): 0.27153363823890686; L(Test): 0.24373193085193634\n",
      "Epoch 3340/10000: L(Train): 0.27944085001945496; L(Test): 0.24277876317501068\n",
      "Epoch 3341/10000: L(Train): 0.2549114227294922; L(Test): 0.242327481508255\n",
      "Epoch 3342/10000: L(Train): 0.2569923400878906; L(Test): 0.2418145388364792\n",
      "Epoch 3343/10000: L(Train): 0.2614401578903198; L(Test): 0.24220505356788635\n",
      "Epoch 3344/10000: L(Train): 0.26291555166244507; L(Test): 0.2409452646970749\n",
      "Epoch 3345/10000: L(Train): 0.2551804482936859; L(Test): 0.24091920256614685\n",
      "Epoch 3346/10000: L(Train): 0.26141443848609924; L(Test): 0.24128977954387665\n",
      "Epoch 3347/10000: L(Train): 0.2638498544692993; L(Test): 0.2418118268251419\n",
      "Epoch 3348/10000: L(Train): 0.2698700428009033; L(Test): 0.24167500436306\n",
      "Epoch 3349/10000: L(Train): 0.27504634857177734; L(Test): 0.24043691158294678\n",
      "Epoch 3350/10000: L(Train): 0.2612244188785553; L(Test): 0.24203181266784668\n",
      "Epoch 3351/10000: L(Train): 0.2611986994743347; L(Test): 0.24141590297222137\n",
      "Epoch 3352/10000: L(Train): 0.262621134519577; L(Test): 0.24294635653495789\n",
      "Epoch 3353/10000: L(Train): 0.2843870520591736; L(Test): 0.24377493560314178\n",
      "Epoch 3354/10000: L(Train): 0.2779929041862488; L(Test): 0.24112018942832947\n",
      "Epoch 3355/10000: L(Train): 0.2691991627216339; L(Test): 0.2432861328125\n",
      "Epoch 3356/10000: L(Train): 0.2554166913032532; L(Test): 0.24329231679439545\n",
      "Epoch 3357/10000: L(Train): 0.27896609902381897; L(Test): 0.24331580102443695\n",
      "Epoch 3358/10000: L(Train): 0.2695402204990387; L(Test): 0.24222436547279358\n",
      "Epoch 3359/10000: L(Train): 0.25745049118995667; L(Test): 0.24230122566223145\n",
      "Epoch 3360/10000: L(Train): 0.2748057246208191; L(Test): 0.24197648465633392\n",
      "Epoch 3361/10000: L(Train): 0.25160548090934753; L(Test): 0.2456052601337433\n",
      "Epoch 3362/10000: L(Train): 0.25916051864624023; L(Test): 0.24323168396949768\n",
      "Epoch 3363/10000: L(Train): 0.2558036148548126; L(Test): 0.24681368470191956\n",
      "Epoch 3364/10000: L(Train): 0.2548687160015106; L(Test): 0.24504029750823975\n",
      "Epoch 3365/10000: L(Train): 0.26718512177467346; L(Test): 0.24241280555725098\n",
      "Epoch 3366/10000: L(Train): 0.26485028862953186; L(Test): 0.24466796219348907\n",
      "Epoch 3367/10000: L(Train): 0.26469433307647705; L(Test): 0.24443970620632172\n",
      "Epoch 3368/10000: L(Train): 0.26039689779281616; L(Test): 0.2434185892343521\n",
      "Epoch 3369/10000: L(Train): 0.26492026448249817; L(Test): 0.24371306598186493\n",
      "Epoch 3370/10000: L(Train): 0.26813942193984985; L(Test): 0.24386028945446014\n",
      "Epoch 3371/10000: L(Train): 0.2504730820655823; L(Test): 0.2440783977508545\n",
      "Epoch 3372/10000: L(Train): 0.27673977613449097; L(Test): 0.2440224587917328\n",
      "Epoch 3373/10000: L(Train): 0.2547321617603302; L(Test): 0.24434098601341248\n",
      "Epoch 3374/10000: L(Train): 0.26406967639923096; L(Test): 0.24396847188472748\n",
      "Epoch 3375/10000: L(Train): 0.282724529504776; L(Test): 0.2433270663022995\n",
      "Epoch 3376/10000: L(Train): 0.27859658002853394; L(Test): 0.2421654313802719\n",
      "Epoch 3377/10000: L(Train): 0.2752690315246582; L(Test): 0.24219270050525665\n",
      "Epoch 3378/10000: L(Train): 0.2625528573989868; L(Test): 0.24161891639232635\n",
      "Epoch 3379/10000: L(Train): 0.26966336369514465; L(Test): 0.24125069379806519\n",
      "Epoch 3380/10000: L(Train): 0.26625338196754456; L(Test): 0.24205590784549713\n",
      "Epoch 3381/10000: L(Train): 0.26779142022132874; L(Test): 0.24145099520683289\n",
      "Epoch 3382/10000: L(Train): 0.2528221011161804; L(Test): 0.24378880858421326\n",
      "Epoch 3383/10000: L(Train): 0.2618381381034851; L(Test): 0.2435595542192459\n",
      "Epoch 3384/10000: L(Train): 0.25784462690353394; L(Test): 0.24205747246742249\n",
      "Epoch 3385/10000: L(Train): 0.2698926627635956; L(Test): 0.24194103479385376\n",
      "Epoch 3386/10000: L(Train): 0.25975197553634644; L(Test): 0.24215008318424225\n",
      "Epoch 3387/10000: L(Train): 0.27112647891044617; L(Test): 0.24225464463233948\n",
      "Epoch 3388/10000: L(Train): 0.27339333295822144; L(Test): 0.24033549427986145\n",
      "Epoch 3389/10000: L(Train): 0.27225637435913086; L(Test): 0.24063251912593842\n",
      "Epoch 3390/10000: L(Train): 0.27012231945991516; L(Test): 0.2413037121295929\n",
      "Epoch 3391/10000: L(Train): 0.26335665583610535; L(Test): 0.24124689400196075\n",
      "Epoch 3392/10000: L(Train): 0.25243356823921204; L(Test): 0.24054954946041107\n",
      "Epoch 3393/10000: L(Train): 0.257256418466568; L(Test): 0.24239453673362732\n",
      "Epoch 3394/10000: L(Train): 0.2685169577598572; L(Test): 0.24147698283195496\n",
      "Epoch 3395/10000: L(Train): 0.25484076142311096; L(Test): 0.24006088078022003\n",
      "Epoch 3396/10000: L(Train): 0.2710707187652588; L(Test): 0.24075524508953094\n",
      "Epoch 3397/10000: L(Train): 0.2694753408432007; L(Test): 0.24129009246826172\n",
      "Epoch 3398/10000: L(Train): 0.2720404267311096; L(Test): 0.2408638596534729\n",
      "Epoch 3399/10000: L(Train): 0.26810333132743835; L(Test): 0.24158397316932678\n",
      "Epoch 3400/10000: L(Train): 0.27083009481430054; L(Test): 0.2417069375514984\n",
      "Epoch 3401/10000: L(Train): 0.2563447952270508; L(Test): 0.2409874051809311\n",
      "Epoch 3402/10000: L(Train): 0.2755572199821472; L(Test): 0.24017879366874695\n",
      "Epoch 3403/10000: L(Train): 0.25436902046203613; L(Test): 0.24094007909297943\n",
      "Epoch 3404/10000: L(Train): 0.2678941488265991; L(Test): 0.24208737909793854\n",
      "Epoch 3405/10000: L(Train): 0.26639437675476074; L(Test): 0.24151504039764404\n",
      "Epoch 3406/10000: L(Train): 0.25616443157196045; L(Test): 0.2413049042224884\n",
      "Epoch 3407/10000: L(Train): 0.2526719272136688; L(Test): 0.2410164624452591\n",
      "Epoch 3408/10000: L(Train): 0.2714250981807709; L(Test): 0.24174541234970093\n",
      "Epoch 3409/10000: L(Train): 0.249776229262352; L(Test): 0.2428397387266159\n",
      "Epoch 3410/10000: L(Train): 0.2600974142551422; L(Test): 0.2434036135673523\n",
      "Epoch 3411/10000: L(Train): 0.24886944890022278; L(Test): 0.2428857535123825\n",
      "Epoch 3412/10000: L(Train): 0.2656429708003998; L(Test): 0.24083486199378967\n",
      "Epoch 3413/10000: L(Train): 0.2730650305747986; L(Test): 0.24232707917690277\n",
      "Epoch 3414/10000: L(Train): 0.2820398807525635; L(Test): 0.24297082424163818\n",
      "Epoch 3415/10000: L(Train): 0.26511144638061523; L(Test): 0.2413666993379593\n",
      "Epoch 3416/10000: L(Train): 0.26320359110832214; L(Test): 0.24155722558498383\n",
      "Epoch 3417/10000: L(Train): 0.2912200689315796; L(Test): 0.24191048741340637\n",
      "Epoch 3418/10000: L(Train): 0.2683466672897339; L(Test): 0.24070855975151062\n",
      "Epoch 3419/10000: L(Train): 0.26915016770362854; L(Test): 0.24147729575634003\n",
      "Epoch 3420/10000: L(Train): 0.2652531862258911; L(Test): 0.24315303564071655\n",
      "Epoch 3421/10000: L(Train): 0.26438167691230774; L(Test): 0.2427375614643097\n",
      "Epoch 3422/10000: L(Train): 0.2701910734176636; L(Test): 0.24095307290554047\n",
      "Epoch 3423/10000: L(Train): 0.2635972201824188; L(Test): 0.24202559888362885\n",
      "Epoch 3424/10000: L(Train): 0.2613413333892822; L(Test): 0.24200615286827087\n",
      "Epoch 3425/10000: L(Train): 0.25723299384117126; L(Test): 0.24128654599189758\n",
      "Epoch 3426/10000: L(Train): 0.2685315012931824; L(Test): 0.24317516386508942\n",
      "Epoch 3427/10000: L(Train): 0.26069921255111694; L(Test): 0.2438991516828537\n",
      "Epoch 3428/10000: L(Train): 0.2604590356349945; L(Test): 0.2423897087574005\n",
      "Epoch 3429/10000: L(Train): 0.27374380826950073; L(Test): 0.24255773425102234\n",
      "Epoch 3430/10000: L(Train): 0.2539898157119751; L(Test): 0.24221602082252502\n",
      "Epoch 3431/10000: L(Train): 0.2567180097103119; L(Test): 0.24213571846485138\n",
      "Epoch 3432/10000: L(Train): 0.26640984416007996; L(Test): 0.24160632491111755\n",
      "Epoch 3433/10000: L(Train): 0.269738107919693; L(Test): 0.24142897129058838\n",
      "Epoch 3434/10000: L(Train): 0.263764888048172; L(Test): 0.24120905995368958\n",
      "Epoch 3435/10000: L(Train): 0.2510451674461365; L(Test): 0.24159102141857147\n",
      "Epoch 3436/10000: L(Train): 0.27910691499710083; L(Test): 0.2412930428981781\n",
      "Epoch 3437/10000: L(Train): 0.26322418451309204; L(Test): 0.2413979172706604\n",
      "Epoch 3438/10000: L(Train): 0.2651236653327942; L(Test): 0.24088017642498016\n",
      "Epoch 3439/10000: L(Train): 0.2745402157306671; L(Test): 0.24154314398765564\n",
      "Epoch 3440/10000: L(Train): 0.2739688754081726; L(Test): 0.24138714373111725\n",
      "Epoch 3441/10000: L(Train): 0.2719966173171997; L(Test): 0.24069730937480927\n",
      "Epoch 3442/10000: L(Train): 0.2640410363674164; L(Test): 0.24051856994628906\n",
      "Epoch 3443/10000: L(Train): 0.268171101808548; L(Test): 0.24036277830600739\n",
      "Epoch 3444/10000: L(Train): 0.2547018527984619; L(Test): 0.24060729146003723\n",
      "Epoch 3445/10000: L(Train): 0.27974969148635864; L(Test): 0.241154745221138\n",
      "Epoch 3446/10000: L(Train): 0.2683996856212616; L(Test): 0.24050404131412506\n",
      "Epoch 3447/10000: L(Train): 0.25012364983558655; L(Test): 0.24088053405284882\n",
      "Epoch 3448/10000: L(Train): 0.26703155040740967; L(Test): 0.24103103578090668\n",
      "Epoch 3449/10000: L(Train): 0.27992480993270874; L(Test): 0.24034111201763153\n",
      "Epoch 3450/10000: L(Train): 0.2646823823451996; L(Test): 0.24107412993907928\n",
      "Epoch 3451/10000: L(Train): 0.26994603872299194; L(Test): 0.2408239096403122\n",
      "Epoch 3452/10000: L(Train): 0.265206903219223; L(Test): 0.24209094047546387\n",
      "Epoch 3453/10000: L(Train): 0.2843206524848938; L(Test): 0.24170878529548645\n",
      "Epoch 3454/10000: L(Train): 0.2750163674354553; L(Test): 0.24136057496070862\n",
      "Epoch 3455/10000: L(Train): 0.25576430559158325; L(Test): 0.2416461557149887\n",
      "Epoch 3456/10000: L(Train): 0.24969761073589325; L(Test): 0.24038340151309967\n",
      "Epoch 3457/10000: L(Train): 0.2660207748413086; L(Test): 0.24016468226909637\n",
      "Epoch 3458/10000: L(Train): 0.2551939785480499; L(Test): 0.24109569191932678\n",
      "Epoch 3459/10000: L(Train): 0.26375648379325867; L(Test): 0.24111083149909973\n",
      "Epoch 3460/10000: L(Train): 0.27068549394607544; L(Test): 0.24020417034626007\n",
      "Epoch 3461/10000: L(Train): 0.2738512456417084; L(Test): 0.24057209491729736\n",
      "Epoch 3462/10000: L(Train): 0.27913138270378113; L(Test): 0.24089044332504272\n",
      "Epoch 3463/10000: L(Train): 0.2676903307437897; L(Test): 0.24042685329914093\n",
      "Epoch 3464/10000: L(Train): 0.26911357045173645; L(Test): 0.24035616219043732\n",
      "Epoch 3465/10000: L(Train): 0.25452399253845215; L(Test): 0.24171921610832214\n",
      "Epoch 3466/10000: L(Train): 0.26752907037734985; L(Test): 0.2414090633392334\n",
      "Epoch 3467/10000: L(Train): 0.26305150985717773; L(Test): 0.2412727326154709\n",
      "Epoch 3468/10000: L(Train): 0.26148849725723267; L(Test): 0.2410782277584076\n",
      "Epoch 3469/10000: L(Train): 0.2692546248435974; L(Test): 0.24086503684520721\n",
      "Epoch 3470/10000: L(Train): 0.25715044140815735; L(Test): 0.24197901785373688\n",
      "Epoch 3471/10000: L(Train): 0.25404512882232666; L(Test): 0.24162165820598602\n",
      "Epoch 3472/10000: L(Train): 0.26733100414276123; L(Test): 0.24396781623363495\n",
      "Epoch 3473/10000: L(Train): 0.27109548449516296; L(Test): 0.2449347972869873\n",
      "Epoch 3474/10000: L(Train): 0.27027443051338196; L(Test): 0.24215681850910187\n",
      "Epoch 3475/10000: L(Train): 0.2515263855457306; L(Test): 0.24432045221328735\n",
      "Epoch 3476/10000: L(Train): 0.26056066155433655; L(Test): 0.24504682421684265\n",
      "Epoch 3477/10000: L(Train): 0.2691008150577545; L(Test): 0.24244840443134308\n",
      "Epoch 3478/10000: L(Train): 0.27293020486831665; L(Test): 0.24356408417224884\n",
      "Epoch 3479/10000: L(Train): 0.26896998286247253; L(Test): 0.2445240616798401\n",
      "Epoch 3480/10000: L(Train): 0.26437562704086304; L(Test): 0.24301205575466156\n",
      "Epoch 3481/10000: L(Train): 0.2661091685295105; L(Test): 0.24218381941318512\n",
      "Epoch 3482/10000: L(Train): 0.25923529267311096; L(Test): 0.24328917264938354\n",
      "Epoch 3483/10000: L(Train): 0.2826312184333801; L(Test): 0.2441248893737793\n",
      "Epoch 3484/10000: L(Train): 0.2624332010746002; L(Test): 0.24272692203521729\n",
      "Epoch 3485/10000: L(Train): 0.2562791705131531; L(Test): 0.24315515160560608\n",
      "Epoch 3486/10000: L(Train): 0.2727697193622589; L(Test): 0.24444855749607086\n",
      "Epoch 3487/10000: L(Train): 0.2600081264972687; L(Test): 0.2447647899389267\n",
      "Epoch 3488/10000: L(Train): 0.2661462128162384; L(Test): 0.24438780546188354\n",
      "Epoch 3489/10000: L(Train): 0.2708717882633209; L(Test): 0.2435959279537201\n",
      "Epoch 3490/10000: L(Train): 0.24443413317203522; L(Test): 0.2432156205177307\n",
      "Epoch 3491/10000: L(Train): 0.2713032364845276; L(Test): 0.24378539621829987\n",
      "Epoch 3492/10000: L(Train): 0.2589053213596344; L(Test): 0.2447361946105957\n",
      "Epoch 3493/10000: L(Train): 0.25175023078918457; L(Test): 0.24416932463645935\n",
      "Epoch 3494/10000: L(Train): 0.25845709443092346; L(Test): 0.24373097717761993\n",
      "Epoch 3495/10000: L(Train): 0.27644696831703186; L(Test): 0.24370059370994568\n",
      "Epoch 3496/10000: L(Train): 0.2548135221004486; L(Test): 0.24479036033153534\n",
      "Epoch 3497/10000: L(Train): 0.25369971990585327; L(Test): 0.2439291775226593\n",
      "Epoch 3498/10000: L(Train): 0.27365437150001526; L(Test): 0.24270160496234894\n",
      "Epoch 3499/10000: L(Train): 0.2692393660545349; L(Test): 0.24284985661506653\n",
      "Epoch 3500/10000: L(Train): 0.2513503432273865; L(Test): 0.24181334674358368\n",
      "Epoch 3501/10000: L(Train): 0.25930356979370117; L(Test): 0.2429361492395401\n",
      "Epoch 3502/10000: L(Train): 0.2539537250995636; L(Test): 0.24306459724903107\n",
      "Epoch 3503/10000: L(Train): 0.26989924907684326; L(Test): 0.24342966079711914\n",
      "Epoch 3504/10000: L(Train): 0.2731204032897949; L(Test): 0.24270379543304443\n",
      "Epoch 3505/10000: L(Train): 0.25333118438720703; L(Test): 0.24248133599758148\n",
      "Epoch 3506/10000: L(Train): 0.2639066278934479; L(Test): 0.2461797446012497\n",
      "Epoch 3507/10000: L(Train): 0.25680118799209595; L(Test): 0.24485056102275848\n",
      "Epoch 3508/10000: L(Train): 0.2552933692932129; L(Test): 0.24361997842788696\n",
      "Epoch 3509/10000: L(Train): 0.2721816301345825; L(Test): 0.24427708983421326\n",
      "Epoch 3510/10000: L(Train): 0.26232752203941345; L(Test): 0.24480950832366943\n",
      "Epoch 3511/10000: L(Train): 0.2593557834625244; L(Test): 0.24403110146522522\n",
      "Epoch 3512/10000: L(Train): 0.25960952043533325; L(Test): 0.2431727796792984\n",
      "Epoch 3513/10000: L(Train): 0.2815570831298828; L(Test): 0.24355871975421906\n",
      "Epoch 3514/10000: L(Train): 0.26378583908081055; L(Test): 0.24368757009506226\n",
      "Epoch 3515/10000: L(Train): 0.2539946436882019; L(Test): 0.24535106122493744\n",
      "Epoch 3516/10000: L(Train): 0.2747596204280853; L(Test): 0.24277696013450623\n",
      "Epoch 3517/10000: L(Train): 0.26244398951530457; L(Test): 0.24331681430339813\n",
      "Epoch 3518/10000: L(Train): 0.2511548101902008; L(Test): 0.24272102117538452\n",
      "Epoch 3519/10000: L(Train): 0.27456653118133545; L(Test): 0.24118672311306\n",
      "Epoch 3520/10000: L(Train): 0.26784878969192505; L(Test): 0.24504698812961578\n",
      "Epoch 3521/10000: L(Train): 0.27458223700523376; L(Test): 0.2444353550672531\n",
      "Epoch 3522/10000: L(Train): 0.2526991069316864; L(Test): 0.24219897389411926\n",
      "Epoch 3523/10000: L(Train): 0.260699063539505; L(Test): 0.24192510545253754\n",
      "Epoch 3524/10000: L(Train): 0.2717079818248749; L(Test): 0.24225236475467682\n",
      "Epoch 3525/10000: L(Train): 0.27445903420448303; L(Test): 0.24319243431091309\n",
      "Epoch 3526/10000: L(Train): 0.2674984037876129; L(Test): 0.24226489663124084\n",
      "Epoch 3527/10000: L(Train): 0.26140081882476807; L(Test): 0.2431298792362213\n",
      "Epoch 3528/10000: L(Train): 0.24943438172340393; L(Test): 0.24301019310951233\n",
      "Epoch 3529/10000: L(Train): 0.26086002588272095; L(Test): 0.24521856009960175\n",
      "Epoch 3530/10000: L(Train): 0.26150017976760864; L(Test): 0.2424677312374115\n",
      "Epoch 3531/10000: L(Train): 0.26662853360176086; L(Test): 0.2430209368467331\n",
      "Epoch 3532/10000: L(Train): 0.2750581204891205; L(Test): 0.24326974153518677\n",
      "Epoch 3533/10000: L(Train): 0.2579694390296936; L(Test): 0.24230070412158966\n",
      "Epoch 3534/10000: L(Train): 0.2728573977947235; L(Test): 0.24525600671768188\n",
      "Epoch 3535/10000: L(Train): 0.2609979808330536; L(Test): 0.24232958257198334\n",
      "Epoch 3536/10000: L(Train): 0.2616666853427887; L(Test): 0.2438398152589798\n",
      "Epoch 3537/10000: L(Train): 0.2723652124404907; L(Test): 0.24296028912067413\n",
      "Epoch 3538/10000: L(Train): 0.26874348521232605; L(Test): 0.24415405094623566\n",
      "Epoch 3539/10000: L(Train): 0.2678268551826477; L(Test): 0.24344800412654877\n",
      "Epoch 3540/10000: L(Train): 0.2733333110809326; L(Test): 0.24150621891021729\n",
      "Epoch 3541/10000: L(Train): 0.2674843668937683; L(Test): 0.24197091162204742\n",
      "Epoch 3542/10000: L(Train): 0.2628471851348877; L(Test): 0.24170824885368347\n",
      "Epoch 3543/10000: L(Train): 0.26434677839279175; L(Test): 0.24367396533489227\n",
      "Epoch 3544/10000: L(Train): 0.25537529587745667; L(Test): 0.24298761785030365\n",
      "Epoch 3545/10000: L(Train): 0.2684224545955658; L(Test): 0.24349750578403473\n",
      "Epoch 3546/10000: L(Train): 0.2690478265285492; L(Test): 0.24362686276435852\n",
      "Epoch 3547/10000: L(Train): 0.24662117660045624; L(Test): 0.24333444237709045\n",
      "Epoch 3548/10000: L(Train): 0.26918792724609375; L(Test): 0.24560660123825073\n",
      "Epoch 3549/10000: L(Train): 0.2688206434249878; L(Test): 0.24447044730186462\n",
      "Epoch 3550/10000: L(Train): 0.2678084671497345; L(Test): 0.2418699711561203\n",
      "Epoch 3551/10000: L(Train): 0.2617034614086151; L(Test): 0.24169819056987762\n",
      "Epoch 3552/10000: L(Train): 0.26785749197006226; L(Test): 0.2427404224872589\n",
      "Epoch 3553/10000: L(Train): 0.26010453701019287; L(Test): 0.2433301955461502\n",
      "Epoch 3554/10000: L(Train): 0.2697683274745941; L(Test): 0.24146835505962372\n",
      "Epoch 3555/10000: L(Train): 0.2727254629135132; L(Test): 0.24242715537548065\n",
      "Epoch 3556/10000: L(Train): 0.2555546462535858; L(Test): 0.2419586181640625\n",
      "Epoch 3557/10000: L(Train): 0.27281132340431213; L(Test): 0.24135041236877441\n",
      "Epoch 3558/10000: L(Train): 0.27698689699172974; L(Test): 0.2410576045513153\n",
      "Epoch 3559/10000: L(Train): 0.27108290791511536; L(Test): 0.241901233792305\n",
      "Epoch 3560/10000: L(Train): 0.2617100477218628; L(Test): 0.2426447868347168\n",
      "Epoch 3561/10000: L(Train): 0.26391059160232544; L(Test): 0.24121545255184174\n",
      "Epoch 3562/10000: L(Train): 0.26319795846939087; L(Test): 0.24122945964336395\n",
      "Epoch 3563/10000: L(Train): 0.2583026587963104; L(Test): 0.24189426004886627\n",
      "Epoch 3564/10000: L(Train): 0.2700020670890808; L(Test): 0.2411760538816452\n",
      "Epoch 3565/10000: L(Train): 0.26340463757514954; L(Test): 0.24048912525177002\n",
      "Epoch 3566/10000: L(Train): 0.26819178462028503; L(Test): 0.24142611026763916\n",
      "Epoch 3567/10000: L(Train): 0.25597071647644043; L(Test): 0.24143627285957336\n",
      "Epoch 3568/10000: L(Train): 0.25687065720558167; L(Test): 0.24034640192985535\n",
      "Epoch 3569/10000: L(Train): 0.26584991812705994; L(Test): 0.24012485146522522\n",
      "Epoch 3570/10000: L(Train): 0.2575480043888092; L(Test): 0.2400982677936554\n",
      "Epoch 3571/10000: L(Train): 0.25277283787727356; L(Test): 0.23930861055850983\n",
      "Epoch 3572/10000: L(Train): 0.2687409818172455; L(Test): 0.23993019759655\n",
      "Epoch 3573/10000: L(Train): 0.2479478269815445; L(Test): 0.24228955805301666\n",
      "Epoch 3574/10000: L(Train): 0.25848647952079773; L(Test): 0.24032102525234222\n",
      "Epoch 3575/10000: L(Train): 0.2638455033302307; L(Test): 0.24062523245811462\n",
      "Epoch 3576/10000: L(Train): 0.2537027895450592; L(Test): 0.2423693835735321\n",
      "Epoch 3577/10000: L(Train): 0.2615642845630646; L(Test): 0.2414364218711853\n",
      "Epoch 3578/10000: L(Train): 0.24617187678813934; L(Test): 0.24179606139659882\n",
      "Epoch 3579/10000: L(Train): 0.26197800040245056; L(Test): 0.24132584035396576\n",
      "Epoch 3580/10000: L(Train): 0.2619472146034241; L(Test): 0.24016444385051727\n",
      "Epoch 3581/10000: L(Train): 0.27031925320625305; L(Test): 0.24100686609745026\n",
      "Epoch 3582/10000: L(Train): 0.25756973028182983; L(Test): 0.2406216561794281\n",
      "Epoch 3583/10000: L(Train): 0.26679491996765137; L(Test): 0.2399069368839264\n",
      "Epoch 3584/10000: L(Train): 0.26487284898757935; L(Test): 0.2403392195701599\n",
      "Epoch 3585/10000: L(Train): 0.2530028820037842; L(Test): 0.2400384247303009\n",
      "Epoch 3586/10000: L(Train): 0.2588663697242737; L(Test): 0.23954227566719055\n",
      "Epoch 3587/10000: L(Train): 0.25713029503822327; L(Test): 0.23979498445987701\n",
      "Epoch 3588/10000: L(Train): 0.2542058527469635; L(Test): 0.23987942934036255\n",
      "Epoch 3589/10000: L(Train): 0.26739421486854553; L(Test): 0.2399764060974121\n",
      "Epoch 3590/10000: L(Train): 0.26214689016342163; L(Test): 0.24065515398979187\n",
      "Epoch 3591/10000: L(Train): 0.27853360772132874; L(Test): 0.24021360278129578\n",
      "Epoch 3592/10000: L(Train): 0.2750454843044281; L(Test): 0.2402428388595581\n",
      "Epoch 3593/10000: L(Train): 0.2704511880874634; L(Test): 0.24044755101203918\n",
      "Epoch 3594/10000: L(Train): 0.2649455666542053; L(Test): 0.2412048876285553\n",
      "Epoch 3595/10000: L(Train): 0.2664894461631775; L(Test): 0.2409481257200241\n",
      "Epoch 3596/10000: L(Train): 0.26511234045028687; L(Test): 0.2412605732679367\n",
      "Epoch 3597/10000: L(Train): 0.26422470808029175; L(Test): 0.24143396317958832\n",
      "Epoch 3598/10000: L(Train): 0.2542079985141754; L(Test): 0.24119675159454346\n",
      "Epoch 3599/10000: L(Train): 0.2743220925331116; L(Test): 0.24105636775493622\n",
      "Epoch 3600/10000: L(Train): 0.27062341570854187; L(Test): 0.24154485762119293\n",
      "Epoch 3601/10000: L(Train): 0.2711368501186371; L(Test): 0.24154303967952728\n",
      "Epoch 3602/10000: L(Train): 0.26822444796562195; L(Test): 0.24139828979969025\n",
      "Epoch 3603/10000: L(Train): 0.25954318046569824; L(Test): 0.2402535080909729\n",
      "Epoch 3604/10000: L(Train): 0.2613932490348816; L(Test): 0.24081078171730042\n",
      "Epoch 3605/10000: L(Train): 0.2565210163593292; L(Test): 0.24037015438079834\n",
      "Epoch 3606/10000: L(Train): 0.2612645924091339; L(Test): 0.2403288036584854\n",
      "Epoch 3607/10000: L(Train): 0.2641814649105072; L(Test): 0.2404867708683014\n",
      "Epoch 3608/10000: L(Train): 0.28306320309638977; L(Test): 0.2409965693950653\n",
      "Epoch 3609/10000: L(Train): 0.2686951458454132; L(Test): 0.2409285455942154\n",
      "Epoch 3610/10000: L(Train): 0.26543137431144714; L(Test): 0.2403692901134491\n",
      "Epoch 3611/10000: L(Train): 0.2602490186691284; L(Test): 0.24039730429649353\n",
      "Epoch 3612/10000: L(Train): 0.2730596661567688; L(Test): 0.24058935046195984\n",
      "Epoch 3613/10000: L(Train): 0.26652660965919495; L(Test): 0.24091540277004242\n",
      "Epoch 3614/10000: L(Train): 0.2576296627521515; L(Test): 0.2409157007932663\n",
      "Epoch 3615/10000: L(Train): 0.24853959679603577; L(Test): 0.24104858934879303\n",
      "Epoch 3616/10000: L(Train): 0.27204257249832153; L(Test): 0.2414424568414688\n",
      "Epoch 3617/10000: L(Train): 0.2658741772174835; L(Test): 0.24152430891990662\n",
      "Epoch 3618/10000: L(Train): 0.2604719400405884; L(Test): 0.24110743403434753\n",
      "Epoch 3619/10000: L(Train): 0.25561368465423584; L(Test): 0.24152643978595734\n",
      "Epoch 3620/10000: L(Train): 0.24974089860916138; L(Test): 0.2408994883298874\n",
      "Epoch 3621/10000: L(Train): 0.27793940901756287; L(Test): 0.24176989495754242\n",
      "Epoch 3622/10000: L(Train): 0.2563643157482147; L(Test): 0.24135109782218933\n",
      "Epoch 3623/10000: L(Train): 0.2623911201953888; L(Test): 0.24172253906726837\n",
      "Epoch 3624/10000: L(Train): 0.2767418324947357; L(Test): 0.24129042029380798\n",
      "Epoch 3625/10000: L(Train): 0.26272904872894287; L(Test): 0.24114491045475006\n",
      "Epoch 3626/10000: L(Train): 0.25916826725006104; L(Test): 0.24038919806480408\n",
      "Epoch 3627/10000: L(Train): 0.256611168384552; L(Test): 0.2404872477054596\n",
      "Epoch 3628/10000: L(Train): 0.2678728997707367; L(Test): 0.24124263226985931\n",
      "Epoch 3629/10000: L(Train): 0.2762119174003601; L(Test): 0.24131256341934204\n",
      "Epoch 3630/10000: L(Train): 0.2754119634628296; L(Test): 0.24397563934326172\n",
      "Epoch 3631/10000: L(Train): 0.27642562985420227; L(Test): 0.24375323951244354\n",
      "Epoch 3632/10000: L(Train): 0.2568064033985138; L(Test): 0.24135375022888184\n",
      "Epoch 3633/10000: L(Train): 0.26338905096054077; L(Test): 0.24249695241451263\n",
      "Epoch 3634/10000: L(Train): 0.2734984755516052; L(Test): 0.24001312255859375\n",
      "Epoch 3635/10000: L(Train): 0.2512538731098175; L(Test): 0.24203644692897797\n",
      "Epoch 3636/10000: L(Train): 0.26462313532829285; L(Test): 0.24012327194213867\n",
      "Epoch 3637/10000: L(Train): 0.26190492510795593; L(Test): 0.23958469927310944\n",
      "Epoch 3638/10000: L(Train): 0.2708848714828491; L(Test): 0.23982806503772736\n",
      "Epoch 3639/10000: L(Train): 0.24768908321857452; L(Test): 0.24029715359210968\n",
      "Epoch 3640/10000: L(Train): 0.26590195298194885; L(Test): 0.24253036081790924\n",
      "Epoch 3641/10000: L(Train): 0.2652675211429596; L(Test): 0.24018922448158264\n",
      "Epoch 3642/10000: L(Train): 0.27641722559928894; L(Test): 0.24064025282859802\n",
      "Epoch 3643/10000: L(Train): 0.2612623870372772; L(Test): 0.23960092663764954\n",
      "Epoch 3644/10000: L(Train): 0.25571873784065247; L(Test): 0.24138526618480682\n",
      "Epoch 3645/10000: L(Train): 0.2672606110572815; L(Test): 0.24169044196605682\n",
      "Epoch 3646/10000: L(Train): 0.27242910861968994; L(Test): 0.23990075290203094\n",
      "Epoch 3647/10000: L(Train): 0.2578112781047821; L(Test): 0.24117660522460938\n",
      "Epoch 3648/10000: L(Train): 0.27096134424209595; L(Test): 0.23938491940498352\n",
      "Epoch 3649/10000: L(Train): 0.2662299871444702; L(Test): 0.2410612553358078\n",
      "Epoch 3650/10000: L(Train): 0.2672710120677948; L(Test): 0.240333691239357\n",
      "Epoch 3651/10000: L(Train): 0.27766355872154236; L(Test): 0.23956434428691864\n",
      "Epoch 3652/10000: L(Train): 0.27202898263931274; L(Test): 0.24076496064662933\n",
      "Epoch 3653/10000: L(Train): 0.26861485838890076; L(Test): 0.2401128113269806\n",
      "Epoch 3654/10000: L(Train): 0.27155691385269165; L(Test): 0.23964473605155945\n",
      "Epoch 3655/10000: L(Train): 0.26609158515930176; L(Test): 0.2397613823413849\n",
      "Epoch 3656/10000: L(Train): 0.2738782465457916; L(Test): 0.23982031643390656\n",
      "Epoch 3657/10000: L(Train): 0.2722638249397278; L(Test): 0.24109551310539246\n",
      "Epoch 3658/10000: L(Train): 0.25877875089645386; L(Test): 0.24016837775707245\n",
      "Epoch 3659/10000: L(Train): 0.2649073004722595; L(Test): 0.2396545112133026\n",
      "Epoch 3660/10000: L(Train): 0.25916823744773865; L(Test): 0.23967623710632324\n",
      "Epoch 3661/10000: L(Train): 0.2650565207004547; L(Test): 0.2398894876241684\n",
      "Epoch 3662/10000: L(Train): 0.26511624455451965; L(Test): 0.239332914352417\n",
      "Epoch 3663/10000: L(Train): 0.25763964653015137; L(Test): 0.23992423713207245\n",
      "Epoch 3664/10000: L(Train): 0.27215635776519775; L(Test): 0.24050845205783844\n",
      "Epoch 3665/10000: L(Train): 0.2561412453651428; L(Test): 0.2406296581029892\n",
      "Epoch 3666/10000: L(Train): 0.2581077516078949; L(Test): 0.2409345507621765\n",
      "Epoch 3667/10000: L(Train): 0.2591482400894165; L(Test): 0.24115948379039764\n",
      "Epoch 3668/10000: L(Train): 0.2626931071281433; L(Test): 0.24022898077964783\n",
      "Epoch 3669/10000: L(Train): 0.27191564440727234; L(Test): 0.23976890742778778\n",
      "Epoch 3670/10000: L(Train): 0.2682456076145172; L(Test): 0.23982368409633636\n",
      "Epoch 3671/10000: L(Train): 0.2695997953414917; L(Test): 0.24005872011184692\n",
      "Epoch 3672/10000: L(Train): 0.2626529335975647; L(Test): 0.2391941249370575\n",
      "Epoch 3673/10000: L(Train): 0.2617381811141968; L(Test): 0.23882819712162018\n",
      "Epoch 3674/10000: L(Train): 0.27830708026885986; L(Test): 0.23948930203914642\n",
      "Epoch 3675/10000: L(Train): 0.25723838806152344; L(Test): 0.23965948820114136\n",
      "Epoch 3676/10000: L(Train): 0.2630102336406708; L(Test): 0.23922979831695557\n",
      "Epoch 3677/10000: L(Train): 0.25159698724746704; L(Test): 0.2395113706588745\n",
      "Epoch 3678/10000: L(Train): 0.24559386074543; L(Test): 0.2404085248708725\n",
      "Epoch 3679/10000: L(Train): 0.2527437210083008; L(Test): 0.2399621158838272\n",
      "Epoch 3680/10000: L(Train): 0.262398898601532; L(Test): 0.24074091017246246\n",
      "Epoch 3681/10000: L(Train): 0.2651444971561432; L(Test): 0.2408747375011444\n",
      "Epoch 3682/10000: L(Train): 0.24953009188175201; L(Test): 0.24097797274589539\n",
      "Epoch 3683/10000: L(Train): 0.2575226426124573; L(Test): 0.24090169370174408\n",
      "Epoch 3684/10000: L(Train): 0.27171215415000916; L(Test): 0.24023209512233734\n",
      "Epoch 3685/10000: L(Train): 0.27589449286460876; L(Test): 0.2501848340034485\n",
      "Epoch 3686/10000: L(Train): 0.29346317052841187; L(Test): 0.2489670366048813\n",
      "Epoch 3687/10000: L(Train): 0.29769420623779297; L(Test): 0.2575831413269043\n",
      "Epoch 3688/10000: L(Train): 0.2812676429748535; L(Test): 0.25333404541015625\n",
      "Epoch 3689/10000: L(Train): 0.27804791927337646; L(Test): 0.2521633505821228\n",
      "Epoch 3690/10000: L(Train): 0.2828945815563202; L(Test): 0.2571842670440674\n",
      "Epoch 3691/10000: L(Train): 0.28632962703704834; L(Test): 0.2599535286426544\n",
      "Epoch 3692/10000: L(Train): 0.28205451369285583; L(Test): 0.2575700879096985\n",
      "Epoch 3693/10000: L(Train): 0.2697333097457886; L(Test): 0.25606027245521545\n",
      "Epoch 3694/10000: L(Train): 0.28689199686050415; L(Test): 0.2544993460178375\n",
      "Epoch 3695/10000: L(Train): 0.2782878875732422; L(Test): 0.2554279565811157\n",
      "Epoch 3696/10000: L(Train): 0.2736314833164215; L(Test): 0.25689753890037537\n",
      "Epoch 3697/10000: L(Train): 0.28382545709609985; L(Test): 0.25621384382247925\n",
      "Epoch 3698/10000: L(Train): 0.2810097336769104; L(Test): 0.2547757625579834\n",
      "Epoch 3699/10000: L(Train): 0.2783575654029846; L(Test): 0.2543143630027771\n",
      "Epoch 3700/10000: L(Train): 0.2635502219200134; L(Test): 0.2544329762458801\n",
      "Epoch 3701/10000: L(Train): 0.26255616545677185; L(Test): 0.25315389037132263\n",
      "Epoch 3702/10000: L(Train): 0.2737026810646057; L(Test): 0.25501295924186707\n",
      "Epoch 3703/10000: L(Train): 0.26711374521255493; L(Test): 0.2528415322303772\n",
      "Epoch 3704/10000: L(Train): 0.27323028445243835; L(Test): 0.2528477907180786\n",
      "Epoch 3705/10000: L(Train): 0.27426671981811523; L(Test): 0.2530639171600342\n",
      "Epoch 3706/10000: L(Train): 0.2662440538406372; L(Test): 0.25033289194107056\n",
      "Epoch 3707/10000: L(Train): 0.2893354892730713; L(Test): 0.25223425030708313\n",
      "Epoch 3708/10000: L(Train): 0.2662080228328705; L(Test): 0.2513446807861328\n",
      "Epoch 3709/10000: L(Train): 0.26758161187171936; L(Test): 0.2501053512096405\n",
      "Epoch 3710/10000: L(Train): 0.26628556847572327; L(Test): 0.25022628903388977\n",
      "Epoch 3711/10000: L(Train): 0.25391674041748047; L(Test): 0.2504037022590637\n",
      "Epoch 3712/10000: L(Train): 0.2565682530403137; L(Test): 0.25134944915771484\n",
      "Epoch 3713/10000: L(Train): 0.26921841502189636; L(Test): 0.24947357177734375\n",
      "Epoch 3714/10000: L(Train): 0.2737482786178589; L(Test): 0.2484419345855713\n",
      "Epoch 3715/10000: L(Train): 0.25760769844055176; L(Test): 0.2495773732662201\n",
      "Epoch 3716/10000: L(Train): 0.26648977398872375; L(Test): 0.24827955663204193\n",
      "Epoch 3717/10000: L(Train): 0.2635461390018463; L(Test): 0.2494860142469406\n",
      "Epoch 3718/10000: L(Train): 0.26527151465415955; L(Test): 0.24904334545135498\n",
      "Epoch 3719/10000: L(Train): 0.28055238723754883; L(Test): 0.2478044182062149\n",
      "Epoch 3720/10000: L(Train): 0.25759652256965637; L(Test): 0.2473740577697754\n",
      "Epoch 3721/10000: L(Train): 0.27137503027915955; L(Test): 0.2466052770614624\n",
      "Epoch 3722/10000: L(Train): 0.26731887459754944; L(Test): 0.24771271646022797\n",
      "Epoch 3723/10000: L(Train): 0.2511811852455139; L(Test): 0.24977687001228333\n",
      "Epoch 3724/10000: L(Train): 0.27412673830986023; L(Test): 0.2448335736989975\n",
      "Epoch 3725/10000: L(Train): 0.26097866892814636; L(Test): 0.24660839140415192\n",
      "Epoch 3726/10000: L(Train): 0.27456751465797424; L(Test): 0.24596187472343445\n",
      "Epoch 3727/10000: L(Train): 0.26554906368255615; L(Test): 0.24680525064468384\n",
      "Epoch 3728/10000: L(Train): 0.2619064748287201; L(Test): 0.24771110713481903\n",
      "Epoch 3729/10000: L(Train): 0.2593362033367157; L(Test): 0.24588614702224731\n",
      "Epoch 3730/10000: L(Train): 0.2585144340991974; L(Test): 0.24503517150878906\n",
      "Epoch 3731/10000: L(Train): 0.272924542427063; L(Test): 0.24430125951766968\n",
      "Epoch 3732/10000: L(Train): 0.25153547525405884; L(Test): 0.244900643825531\n",
      "Epoch 3733/10000: L(Train): 0.2817647159099579; L(Test): 0.24514393508434296\n",
      "Epoch 3734/10000: L(Train): 0.2542175054550171; L(Test): 0.24512410163879395\n",
      "Epoch 3735/10000: L(Train): 0.265913188457489; L(Test): 0.2459954470396042\n",
      "Epoch 3736/10000: L(Train): 0.26163455843925476; L(Test): 0.2454744130373001\n",
      "Epoch 3737/10000: L(Train): 0.26875388622283936; L(Test): 0.24841545522212982\n",
      "Epoch 3738/10000: L(Train): 0.27150267362594604; L(Test): 0.24577756226062775\n",
      "Epoch 3739/10000: L(Train): 0.2746764123439789; L(Test): 0.24493291974067688\n",
      "Epoch 3740/10000: L(Train): 0.2530418932437897; L(Test): 0.24610210955142975\n",
      "Epoch 3741/10000: L(Train): 0.26926448941230774; L(Test): 0.24395319819450378\n",
      "Epoch 3742/10000: L(Train): 0.2702316641807556; L(Test): 0.2461310476064682\n",
      "Epoch 3743/10000: L(Train): 0.2775627076625824; L(Test): 0.24611611664295197\n",
      "Epoch 3744/10000: L(Train): 0.2523992359638214; L(Test): 0.24397169053554535\n",
      "Epoch 3745/10000: L(Train): 0.2577909529209137; L(Test): 0.24430875480175018\n",
      "Epoch 3746/10000: L(Train): 0.2665928900241852; L(Test): 0.2459573745727539\n",
      "Epoch 3747/10000: L(Train): 0.2762419283390045; L(Test): 0.2463875114917755\n",
      "Epoch 3748/10000: L(Train): 0.27995237708091736; L(Test): 0.24371865391731262\n",
      "Epoch 3749/10000: L(Train): 0.2796337604522705; L(Test): 0.24534885585308075\n",
      "Epoch 3750/10000: L(Train): 0.2730952203273773; L(Test): 0.24454469978809357\n",
      "Epoch 3751/10000: L(Train): 0.26511427760124207; L(Test): 0.24408255517482758\n",
      "Epoch 3752/10000: L(Train): 0.2517660856246948; L(Test): 0.24656999111175537\n",
      "Epoch 3753/10000: L(Train): 0.26757171750068665; L(Test): 0.2448475956916809\n",
      "Epoch 3754/10000: L(Train): 0.2830018103122711; L(Test): 0.24368728697299957\n",
      "Epoch 3755/10000: L(Train): 0.2566247880458832; L(Test): 0.24540945887565613\n",
      "Epoch 3756/10000: L(Train): 0.252459317445755; L(Test): 0.2432619333267212\n",
      "Epoch 3757/10000: L(Train): 0.2720440626144409; L(Test): 0.24328678846359253\n",
      "Epoch 3758/10000: L(Train): 0.25908133387565613; L(Test): 0.24720542132854462\n",
      "Epoch 3759/10000: L(Train): 0.26913347840309143; L(Test): 0.24492789804935455\n",
      "Epoch 3760/10000: L(Train): 0.2696436643600464; L(Test): 0.24303115904331207\n",
      "Epoch 3761/10000: L(Train): 0.27163204550743103; L(Test): 0.24504385888576508\n",
      "Epoch 3762/10000: L(Train): 0.2701890468597412; L(Test): 0.24390842020511627\n",
      "Epoch 3763/10000: L(Train): 0.2621496617794037; L(Test): 0.2434956282377243\n",
      "Epoch 3764/10000: L(Train): 0.24998290836811066; L(Test): 0.2459825724363327\n",
      "Epoch 3765/10000: L(Train): 0.272494912147522; L(Test): 0.24442464113235474\n",
      "Epoch 3766/10000: L(Train): 0.2599771320819855; L(Test): 0.2419900894165039\n",
      "Epoch 3767/10000: L(Train): 0.2613716721534729; L(Test): 0.24389834702014923\n",
      "Epoch 3768/10000: L(Train): 0.26143771409988403; L(Test): 0.24521222710609436\n",
      "Epoch 3769/10000: L(Train): 0.2653173506259918; L(Test): 0.24329403042793274\n",
      "Epoch 3770/10000: L(Train): 0.2651894688606262; L(Test): 0.24202027916908264\n",
      "Epoch 3771/10000: L(Train): 0.2815527021884918; L(Test): 0.2423681616783142\n",
      "Epoch 3772/10000: L(Train): 0.2733585238456726; L(Test): 0.24140556156635284\n",
      "Epoch 3773/10000: L(Train): 0.2555429935455322; L(Test): 0.24178147315979004\n",
      "Epoch 3774/10000: L(Train): 0.2631339430809021; L(Test): 0.24193358421325684\n",
      "Epoch 3775/10000: L(Train): 0.2720322608947754; L(Test): 0.24290414154529572\n",
      "Epoch 3776/10000: L(Train): 0.27851057052612305; L(Test): 0.24288025498390198\n",
      "Epoch 3777/10000: L(Train): 0.27945271134376526; L(Test): 0.24217191338539124\n",
      "Epoch 3778/10000: L(Train): 0.23860077559947968; L(Test): 0.2424967736005783\n",
      "Epoch 3779/10000: L(Train): 0.2693178057670593; L(Test): 0.24155515432357788\n",
      "Epoch 3780/10000: L(Train): 0.25984713435173035; L(Test): 0.24076974391937256\n",
      "Epoch 3781/10000: L(Train): 0.257355272769928; L(Test): 0.24053442478179932\n",
      "Epoch 3782/10000: L(Train): 0.2655160129070282; L(Test): 0.2427263855934143\n",
      "Epoch 3783/10000: L(Train): 0.2567821443080902; L(Test): 0.2418520301580429\n",
      "Epoch 3784/10000: L(Train): 0.2586629092693329; L(Test): 0.24050526320934296\n",
      "Epoch 3785/10000: L(Train): 0.2542800009250641; L(Test): 0.2407270073890686\n",
      "Epoch 3786/10000: L(Train): 0.26823690533638; L(Test): 0.24090375006198883\n",
      "Epoch 3787/10000: L(Train): 0.247977152466774; L(Test): 0.24101190268993378\n",
      "Epoch 3788/10000: L(Train): 0.26322269439697266; L(Test): 0.2406022548675537\n",
      "Epoch 3789/10000: L(Train): 0.26368966698646545; L(Test): 0.24063749611377716\n",
      "Epoch 3790/10000: L(Train): 0.25478309392929077; L(Test): 0.23985880613327026\n",
      "Epoch 3791/10000: L(Train): 0.25969192385673523; L(Test): 0.24105484783649445\n",
      "Epoch 3792/10000: L(Train): 0.26247990131378174; L(Test): 0.24110905826091766\n",
      "Epoch 3793/10000: L(Train): 0.24123013019561768; L(Test): 0.24083885550498962\n",
      "Epoch 3794/10000: L(Train): 0.27057915925979614; L(Test): 0.24101291596889496\n",
      "Epoch 3795/10000: L(Train): 0.2653605043888092; L(Test): 0.24020178616046906\n",
      "Epoch 3796/10000: L(Train): 0.2629237174987793; L(Test): 0.23975051939487457\n",
      "Epoch 3797/10000: L(Train): 0.2650185525417328; L(Test): 0.2402951866388321\n",
      "Epoch 3798/10000: L(Train): 0.2539730668067932; L(Test): 0.2392156720161438\n",
      "Epoch 3799/10000: L(Train): 0.26619699597358704; L(Test): 0.23936976492404938\n",
      "Epoch 3800/10000: L(Train): 0.27523547410964966; L(Test): 0.2395460605621338\n",
      "Epoch 3801/10000: L(Train): 0.25048503279685974; L(Test): 0.23907506465911865\n",
      "Epoch 3802/10000: L(Train): 0.2643919587135315; L(Test): 0.23945464193820953\n",
      "Epoch 3803/10000: L(Train): 0.2611643970012665; L(Test): 0.23950468003749847\n",
      "Epoch 3804/10000: L(Train): 0.27245694398880005; L(Test): 0.23908957839012146\n",
      "Epoch 3805/10000: L(Train): 0.25200212001800537; L(Test): 0.23936404287815094\n",
      "Epoch 3806/10000: L(Train): 0.2614811062812805; L(Test): 0.2401421219110489\n",
      "Epoch 3807/10000: L(Train): 0.26545360684394836; L(Test): 0.24036888778209686\n",
      "Epoch 3808/10000: L(Train): 0.2727370262145996; L(Test): 0.23941347002983093\n",
      "Epoch 3809/10000: L(Train): 0.2552894055843353; L(Test): 0.2404271811246872\n",
      "Epoch 3810/10000: L(Train): 0.27389565110206604; L(Test): 0.23926110565662384\n",
      "Epoch 3811/10000: L(Train): 0.27008292078971863; L(Test): 0.2413189709186554\n",
      "Epoch 3812/10000: L(Train): 0.2694869041442871; L(Test): 0.241840198636055\n",
      "Epoch 3813/10000: L(Train): 0.26867741346359253; L(Test): 0.24080832302570343\n",
      "Epoch 3814/10000: L(Train): 0.26034483313560486; L(Test): 0.24151431024074554\n",
      "Epoch 3815/10000: L(Train): 0.2698867619037628; L(Test): 0.24183110892772675\n",
      "Epoch 3816/10000: L(Train): 0.25803342461586; L(Test): 0.2411353588104248\n",
      "Epoch 3817/10000: L(Train): 0.26771649718284607; L(Test): 0.23989622294902802\n",
      "Epoch 3818/10000: L(Train): 0.26124128699302673; L(Test): 0.24178513884544373\n",
      "Epoch 3819/10000: L(Train): 0.25454819202423096; L(Test): 0.24133840203285217\n",
      "Epoch 3820/10000: L(Train): 0.2628682553768158; L(Test): 0.24066290259361267\n",
      "Epoch 3821/10000: L(Train): 0.25368744134902954; L(Test): 0.24137580394744873\n",
      "Epoch 3822/10000: L(Train): 0.26486989855766296; L(Test): 0.24164384603500366\n",
      "Epoch 3823/10000: L(Train): 0.2703421413898468; L(Test): 0.24110253155231476\n",
      "Epoch 3824/10000: L(Train): 0.25687897205352783; L(Test): 0.24205797910690308\n",
      "Epoch 3825/10000: L(Train): 0.24704064428806305; L(Test): 0.24334052205085754\n",
      "Epoch 3826/10000: L(Train): 0.2568385899066925; L(Test): 0.24102883040905\n",
      "Epoch 3827/10000: L(Train): 0.26777857542037964; L(Test): 0.24068205058574677\n",
      "Epoch 3828/10000: L(Train): 0.26285040378570557; L(Test): 0.2414029836654663\n",
      "Epoch 3829/10000: L(Train): 0.26173603534698486; L(Test): 0.24252058565616608\n",
      "Epoch 3830/10000: L(Train): 0.2492934912443161; L(Test): 0.24120430648326874\n",
      "Epoch 3831/10000: L(Train): 0.2598678767681122; L(Test): 0.2413242608308792\n",
      "Epoch 3832/10000: L(Train): 0.2560816705226898; L(Test): 0.24174754321575165\n",
      "Epoch 3833/10000: L(Train): 0.25286629796028137; L(Test): 0.24080006778240204\n",
      "Epoch 3834/10000: L(Train): 0.27722880244255066; L(Test): 0.2449534386396408\n",
      "Epoch 3835/10000: L(Train): 0.25881198048591614; L(Test): 0.24063454568386078\n",
      "Epoch 3836/10000: L(Train): 0.25971946120262146; L(Test): 0.24288460612297058\n",
      "Epoch 3837/10000: L(Train): 0.2564707398414612; L(Test): 0.24149090051651\n",
      "Epoch 3838/10000: L(Train): 0.2704099416732788; L(Test): 0.24613630771636963\n",
      "Epoch 3839/10000: L(Train): 0.2772004306316376; L(Test): 0.2420148402452469\n",
      "Epoch 3840/10000: L(Train): 0.2559497356414795; L(Test): 0.2425546944141388\n",
      "Epoch 3841/10000: L(Train): 0.26425430178642273; L(Test): 0.24350102245807648\n",
      "Epoch 3842/10000: L(Train): 0.265858918428421; L(Test): 0.24253249168395996\n",
      "Epoch 3843/10000: L(Train): 0.25010034441947937; L(Test): 0.2455190122127533\n",
      "Epoch 3844/10000: L(Train): 0.27426964044570923; L(Test): 0.2430865317583084\n",
      "Epoch 3845/10000: L(Train): 0.2699594497680664; L(Test): 0.24311858415603638\n",
      "Epoch 3846/10000: L(Train): 0.2674570381641388; L(Test): 0.24216260015964508\n",
      "Epoch 3847/10000: L(Train): 0.266598641872406; L(Test): 0.2426777482032776\n",
      "Epoch 3848/10000: L(Train): 0.2610374391078949; L(Test): 0.24381797015666962\n",
      "Epoch 3849/10000: L(Train): 0.25866106152534485; L(Test): 0.24226808547973633\n",
      "Epoch 3850/10000: L(Train): 0.28014075756073; L(Test): 0.24250103533267975\n",
      "Epoch 3851/10000: L(Train): 0.2632972002029419; L(Test): 0.2438296228647232\n",
      "Epoch 3852/10000: L(Train): 0.2622797191143036; L(Test): 0.24332600831985474\n",
      "Epoch 3853/10000: L(Train): 0.2612163722515106; L(Test): 0.2421025037765503\n",
      "Epoch 3854/10000: L(Train): 0.2704821228981018; L(Test): 0.24231934547424316\n",
      "Epoch 3855/10000: L(Train): 0.24789458513259888; L(Test): 0.24326425790786743\n",
      "Epoch 3856/10000: L(Train): 0.26824092864990234; L(Test): 0.24199682474136353\n",
      "Epoch 3857/10000: L(Train): 0.2752012312412262; L(Test): 0.24148398637771606\n",
      "Epoch 3858/10000: L(Train): 0.2696923315525055; L(Test): 0.24184280633926392\n",
      "Epoch 3859/10000: L(Train): 0.2691670060157776; L(Test): 0.2428053319454193\n",
      "Epoch 3860/10000: L(Train): 0.26173603534698486; L(Test): 0.2430209219455719\n",
      "Epoch 3861/10000: L(Train): 0.26604917645454407; L(Test): 0.24269366264343262\n",
      "Epoch 3862/10000: L(Train): 0.2644328474998474; L(Test): 0.2427099496126175\n",
      "Epoch 3863/10000: L(Train): 0.2868766486644745; L(Test): 0.24278438091278076\n",
      "Epoch 3864/10000: L(Train): 0.27169954776763916; L(Test): 0.24215327203273773\n",
      "Epoch 3865/10000: L(Train): 0.2557433247566223; L(Test): 0.24184460937976837\n",
      "Epoch 3866/10000: L(Train): 0.25471416115760803; L(Test): 0.2421342134475708\n",
      "Epoch 3867/10000: L(Train): 0.2707367539405823; L(Test): 0.24234825372695923\n",
      "Epoch 3868/10000: L(Train): 0.2708451747894287; L(Test): 0.24304799735546112\n",
      "Epoch 3869/10000: L(Train): 0.27082541584968567; L(Test): 0.242081418633461\n",
      "Epoch 3870/10000: L(Train): 0.2655109763145447; L(Test): 0.24232056736946106\n",
      "Epoch 3871/10000: L(Train): 0.2739295959472656; L(Test): 0.24171116948127747\n",
      "Epoch 3872/10000: L(Train): 0.26265624165534973; L(Test): 0.2406597137451172\n",
      "Epoch 3873/10000: L(Train): 0.2596670687198639; L(Test): 0.24102966487407684\n",
      "Epoch 3874/10000: L(Train): 0.2621521055698395; L(Test): 0.2411644011735916\n",
      "Epoch 3875/10000: L(Train): 0.2604179382324219; L(Test): 0.2407011091709137\n",
      "Epoch 3876/10000: L(Train): 0.2567102313041687; L(Test): 0.24062061309814453\n",
      "Epoch 3877/10000: L(Train): 0.2613329589366913; L(Test): 0.24070321023464203\n",
      "Epoch 3878/10000: L(Train): 0.27029702067375183; L(Test): 0.2405509203672409\n",
      "Epoch 3879/10000: L(Train): 0.25928789377212524; L(Test): 0.2417866438627243\n",
      "Epoch 3880/10000: L(Train): 0.25911179184913635; L(Test): 0.243261456489563\n",
      "Epoch 3881/10000: L(Train): 0.27736878395080566; L(Test): 0.2420172244310379\n",
      "Epoch 3882/10000: L(Train): 0.272554486989975; L(Test): 0.24260997772216797\n",
      "Epoch 3883/10000: L(Train): 0.26858556270599365; L(Test): 0.2432163506746292\n",
      "Epoch 3884/10000: L(Train): 0.2604440748691559; L(Test): 0.2432791143655777\n",
      "Epoch 3885/10000: L(Train): 0.26929473876953125; L(Test): 0.241459459066391\n",
      "Epoch 3886/10000: L(Train): 0.27383920550346375; L(Test): 0.24081139266490936\n",
      "Epoch 3887/10000: L(Train): 0.2680102288722992; L(Test): 0.24036408960819244\n",
      "Epoch 3888/10000: L(Train): 0.25693053007125854; L(Test): 0.2413204312324524\n",
      "Epoch 3889/10000: L(Train): 0.2786751985549927; L(Test): 0.2422696352005005\n",
      "Epoch 3890/10000: L(Train): 0.25884827971458435; L(Test): 0.24328584969043732\n",
      "Epoch 3891/10000: L(Train): 0.2595272660255432; L(Test): 0.24051137268543243\n",
      "Epoch 3892/10000: L(Train): 0.26191186904907227; L(Test): 0.24162058532238007\n",
      "Epoch 3893/10000: L(Train): 0.2604864537715912; L(Test): 0.24143396317958832\n",
      "Epoch 3894/10000: L(Train): 0.2699034512042999; L(Test): 0.24295027554035187\n",
      "Epoch 3895/10000: L(Train): 0.2650996148586273; L(Test): 0.2434060126543045\n",
      "Epoch 3896/10000: L(Train): 0.26914939284324646; L(Test): 0.24165727198123932\n",
      "Epoch 3897/10000: L(Train): 0.27282917499542236; L(Test): 0.24280184507369995\n",
      "Epoch 3898/10000: L(Train): 0.2822093069553375; L(Test): 0.24135392904281616\n",
      "Epoch 3899/10000: L(Train): 0.25724777579307556; L(Test): 0.24248722195625305\n",
      "Epoch 3900/10000: L(Train): 0.27820876240730286; L(Test): 0.24144376814365387\n",
      "Epoch 3901/10000: L(Train): 0.2627531886100769; L(Test): 0.24244384467601776\n",
      "Epoch 3902/10000: L(Train): 0.26824867725372314; L(Test): 0.24336856603622437\n",
      "Epoch 3903/10000: L(Train): 0.2717413902282715; L(Test): 0.24223044514656067\n",
      "Epoch 3904/10000: L(Train): 0.27018940448760986; L(Test): 0.24534910917282104\n",
      "Epoch 3905/10000: L(Train): 0.26599031686782837; L(Test): 0.24365387856960297\n",
      "Epoch 3906/10000: L(Train): 0.26545578241348267; L(Test): 0.24182367324829102\n",
      "Epoch 3907/10000: L(Train): 0.27345484495162964; L(Test): 0.24306084215641022\n",
      "Epoch 3908/10000: L(Train): 0.2628302574157715; L(Test): 0.24100187420845032\n",
      "Epoch 3909/10000: L(Train): 0.27049291133880615; L(Test): 0.24382038414478302\n",
      "Epoch 3910/10000: L(Train): 0.2784205675125122; L(Test): 0.24293380975723267\n",
      "Epoch 3911/10000: L(Train): 0.271266907453537; L(Test): 0.24121318757534027\n",
      "Epoch 3912/10000: L(Train): 0.2826476991176605; L(Test): 0.24343669414520264\n",
      "Epoch 3913/10000: L(Train): 0.26630839705467224; L(Test): 0.24192692339420319\n",
      "Epoch 3914/10000: L(Train): 0.25759872794151306; L(Test): 0.2426329255104065\n",
      "Epoch 3915/10000: L(Train): 0.2542519271373749; L(Test): 0.24430742859840393\n",
      "Epoch 3916/10000: L(Train): 0.25705671310424805; L(Test): 0.24332550168037415\n",
      "Epoch 3917/10000: L(Train): 0.2567177712917328; L(Test): 0.24161812663078308\n",
      "Epoch 3918/10000: L(Train): 0.27237212657928467; L(Test): 0.2463727742433548\n",
      "Epoch 3919/10000: L(Train): 0.2741565406322479; L(Test): 0.24499881267547607\n",
      "Epoch 3920/10000: L(Train): 0.2506154179573059; L(Test): 0.24255722761154175\n",
      "Epoch 3921/10000: L(Train): 0.2629544734954834; L(Test): 0.24541571736335754\n",
      "Epoch 3922/10000: L(Train): 0.2855353355407715; L(Test): 0.24391384422779083\n",
      "Epoch 3923/10000: L(Train): 0.25893256068229675; L(Test): 0.2427610456943512\n",
      "Epoch 3924/10000: L(Train): 0.2619868814945221; L(Test): 0.2437153458595276\n",
      "Epoch 3925/10000: L(Train): 0.2720147669315338; L(Test): 0.24237662553787231\n",
      "Epoch 3926/10000: L(Train): 0.26701563596725464; L(Test): 0.2427518218755722\n",
      "Epoch 3927/10000: L(Train): 0.259057879447937; L(Test): 0.2451665848493576\n",
      "Epoch 3928/10000: L(Train): 0.2752123475074768; L(Test): 0.2435956597328186\n",
      "Epoch 3929/10000: L(Train): 0.25172191858291626; L(Test): 0.24192002415657043\n",
      "Epoch 3930/10000: L(Train): 0.26217180490493774; L(Test): 0.2422991245985031\n",
      "Epoch 3931/10000: L(Train): 0.2725442945957184; L(Test): 0.24232684075832367\n",
      "Epoch 3932/10000: L(Train): 0.27587831020355225; L(Test): 0.24351650476455688\n",
      "Epoch 3933/10000: L(Train): 0.26453766226768494; L(Test): 0.24526230990886688\n",
      "Epoch 3934/10000: L(Train): 0.27402371168136597; L(Test): 0.24479182064533234\n",
      "Epoch 3935/10000: L(Train): 0.2531324326992035; L(Test): 0.24436871707439423\n",
      "Epoch 3936/10000: L(Train): 0.26228347420692444; L(Test): 0.2455739825963974\n",
      "Epoch 3937/10000: L(Train): 0.27174025774002075; L(Test): 0.2449924647808075\n",
      "Epoch 3938/10000: L(Train): 0.26142972707748413; L(Test): 0.24336712062358856\n",
      "Epoch 3939/10000: L(Train): 0.26333877444267273; L(Test): 0.24531777203083038\n",
      "Epoch 3940/10000: L(Train): 0.2826593220233917; L(Test): 0.24421808123588562\n",
      "Epoch 3941/10000: L(Train): 0.26728928089141846; L(Test): 0.24287402629852295\n",
      "Epoch 3942/10000: L(Train): 0.2667817771434784; L(Test): 0.24553848803043365\n",
      "Epoch 3943/10000: L(Train): 0.2596261501312256; L(Test): 0.2458702176809311\n",
      "Epoch 3944/10000: L(Train): 0.26797205209732056; L(Test): 0.24320188164710999\n",
      "Epoch 3945/10000: L(Train): 0.2755314111709595; L(Test): 0.2434767782688141\n",
      "Epoch 3946/10000: L(Train): 0.2611234486103058; L(Test): 0.243637353181839\n",
      "Epoch 3947/10000: L(Train): 0.252377986907959; L(Test): 0.24325600266456604\n",
      "Epoch 3948/10000: L(Train): 0.2776966691017151; L(Test): 0.24249061942100525\n",
      "Epoch 3949/10000: L(Train): 0.2625051438808441; L(Test): 0.24260839819908142\n",
      "Epoch 3950/10000: L(Train): 0.26255688071250916; L(Test): 0.2425278276205063\n",
      "Epoch 3951/10000: L(Train): 0.26689988374710083; L(Test): 0.24218036234378815\n",
      "Epoch 3952/10000: L(Train): 0.27944082021713257; L(Test): 0.24194258451461792\n",
      "Epoch 3953/10000: L(Train): 0.25487738847732544; L(Test): 0.24222669005393982\n",
      "Epoch 3954/10000: L(Train): 0.2692592740058899; L(Test): 0.24125486612319946\n",
      "Epoch 3955/10000: L(Train): 0.23741495609283447; L(Test): 0.2406242936849594\n",
      "Epoch 3956/10000: L(Train): 0.2697782814502716; L(Test): 0.24033227562904358\n",
      "Epoch 3957/10000: L(Train): 0.25507473945617676; L(Test): 0.24108028411865234\n",
      "Epoch 3958/10000: L(Train): 0.2537914514541626; L(Test): 0.24078385531902313\n",
      "Epoch 3959/10000: L(Train): 0.2681961953639984; L(Test): 0.23991160094738007\n",
      "Epoch 3960/10000: L(Train): 0.2663356065750122; L(Test): 0.24058768153190613\n",
      "Epoch 3961/10000: L(Train): 0.27399832010269165; L(Test): 0.2402968555688858\n",
      "Epoch 3962/10000: L(Train): 0.25351905822753906; L(Test): 0.241441011428833\n",
      "Epoch 3963/10000: L(Train): 0.262028306722641; L(Test): 0.23970724642276764\n",
      "Epoch 3964/10000: L(Train): 0.24890510737895966; L(Test): 0.240581676363945\n",
      "Epoch 3965/10000: L(Train): 0.2755829393863678; L(Test): 0.240328848361969\n",
      "Epoch 3966/10000: L(Train): 0.25914204120635986; L(Test): 0.24085219204425812\n",
      "Epoch 3967/10000: L(Train): 0.27235764265060425; L(Test): 0.24257533252239227\n",
      "Epoch 3968/10000: L(Train): 0.26957398653030396; L(Test): 0.24001693725585938\n",
      "Epoch 3969/10000: L(Train): 0.2518375515937805; L(Test): 0.24088440835475922\n",
      "Epoch 3970/10000: L(Train): 0.2659614384174347; L(Test): 0.23923437297344208\n",
      "Epoch 3971/10000: L(Train): 0.2760845720767975; L(Test): 0.23927095532417297\n",
      "Epoch 3972/10000: L(Train): 0.25211670994758606; L(Test): 0.24109403789043427\n",
      "Epoch 3973/10000: L(Train): 0.261178195476532; L(Test): 0.24048899114131927\n",
      "Epoch 3974/10000: L(Train): 0.24056445062160492; L(Test): 0.24069330096244812\n",
      "Epoch 3975/10000: L(Train): 0.27061915397644043; L(Test): 0.24068917334079742\n",
      "Epoch 3976/10000: L(Train): 0.26359403133392334; L(Test): 0.24033629894256592\n",
      "Epoch 3977/10000: L(Train): 0.2534157931804657; L(Test): 0.24011464416980743\n",
      "Epoch 3978/10000: L(Train): 0.25612273812294006; L(Test): 0.23943506181240082\n",
      "Epoch 3979/10000: L(Train): 0.27234748005867004; L(Test): 0.23874686658382416\n",
      "Epoch 3980/10000: L(Train): 0.2704252302646637; L(Test): 0.23906786739826202\n",
      "Epoch 3981/10000: L(Train): 0.2613806128501892; L(Test): 0.2395503669977188\n",
      "Epoch 3982/10000: L(Train): 0.26057910919189453; L(Test): 0.23875312507152557\n",
      "Epoch 3983/10000: L(Train): 0.25448212027549744; L(Test): 0.23887968063354492\n",
      "Epoch 3984/10000: L(Train): 0.2590828835964203; L(Test): 0.2390918880701065\n",
      "Epoch 3985/10000: L(Train): 0.2712377607822418; L(Test): 0.23896591365337372\n",
      "Epoch 3986/10000: L(Train): 0.27540692687034607; L(Test): 0.2391350120306015\n",
      "Epoch 3987/10000: L(Train): 0.26651906967163086; L(Test): 0.23956303298473358\n",
      "Epoch 3988/10000: L(Train): 0.26094818115234375; L(Test): 0.23940879106521606\n",
      "Epoch 3989/10000: L(Train): 0.2557944059371948; L(Test): 0.23914220929145813\n",
      "Epoch 3990/10000: L(Train): 0.269536554813385; L(Test): 0.23880572617053986\n",
      "Epoch 3991/10000: L(Train): 0.2670491933822632; L(Test): 0.23916175961494446\n",
      "Epoch 3992/10000: L(Train): 0.2651672959327698; L(Test): 0.24059806764125824\n",
      "Epoch 3993/10000: L(Train): 0.24764451384544373; L(Test): 0.24048294126987457\n",
      "Epoch 3994/10000: L(Train): 0.2637336850166321; L(Test): 0.24030663073062897\n",
      "Epoch 3995/10000: L(Train): 0.26229244470596313; L(Test): 0.24061210453510284\n",
      "Epoch 3996/10000: L(Train): 0.25406837463378906; L(Test): 0.24138778448104858\n",
      "Epoch 3997/10000: L(Train): 0.25959548354148865; L(Test): 0.24126079678535461\n",
      "Epoch 3998/10000: L(Train): 0.26269373297691345; L(Test): 0.24165639281272888\n",
      "Epoch 3999/10000: L(Train): 0.2616012692451477; L(Test): 0.24087442457675934\n",
      "Epoch 4000/10000: L(Train): 0.2552289366722107; L(Test): 0.2411716878414154\n",
      "Epoch 4001/10000: L(Train): 0.25646817684173584; L(Test): 0.24196940660476685\n",
      "Epoch 4002/10000: L(Train): 0.2521769404411316; L(Test): 0.24185535311698914\n",
      "Epoch 4003/10000: L(Train): 0.27224278450012207; L(Test): 0.24136421084403992\n",
      "Epoch 4004/10000: L(Train): 0.2563146948814392; L(Test): 0.24177832901477814\n",
      "Epoch 4005/10000: L(Train): 0.2659987211227417; L(Test): 0.24228298664093018\n",
      "Epoch 4006/10000: L(Train): 0.2678772211074829; L(Test): 0.2422761470079422\n",
      "Epoch 4007/10000: L(Train): 0.25441935658454895; L(Test): 0.2416139841079712\n",
      "Epoch 4008/10000: L(Train): 0.2510932385921478; L(Test): 0.24296538531780243\n",
      "Epoch 4009/10000: L(Train): 0.25674283504486084; L(Test): 0.2437652200460434\n",
      "Epoch 4010/10000: L(Train): 0.2824864685535431; L(Test): 0.24215272068977356\n",
      "Epoch 4011/10000: L(Train): 0.26708248257637024; L(Test): 0.24424555897712708\n",
      "Epoch 4012/10000: L(Train): 0.2721332907676697; L(Test): 0.24384567141532898\n",
      "Epoch 4013/10000: L(Train): 0.2667999863624573; L(Test): 0.24264150857925415\n",
      "Epoch 4014/10000: L(Train): 0.2553151845932007; L(Test): 0.24365301430225372\n",
      "Epoch 4015/10000: L(Train): 0.27874013781547546; L(Test): 0.24384409189224243\n",
      "Epoch 4016/10000: L(Train): 0.2677200138568878; L(Test): 0.2426910400390625\n",
      "Epoch 4017/10000: L(Train): 0.27747416496276855; L(Test): 0.24380406737327576\n",
      "Epoch 4018/10000: L(Train): 0.2679285407066345; L(Test): 0.24277320504188538\n",
      "Epoch 4019/10000: L(Train): 0.25122496485710144; L(Test): 0.24187032878398895\n",
      "Epoch 4020/10000: L(Train): 0.2652522325515747; L(Test): 0.24200785160064697\n",
      "Epoch 4021/10000: L(Train): 0.28298380970954895; L(Test): 0.2427053600549698\n",
      "Epoch 4022/10000: L(Train): 0.263126939535141; L(Test): 0.24228020012378693\n",
      "Epoch 4023/10000: L(Train): 0.2697983980178833; L(Test): 0.2416103482246399\n",
      "Epoch 4024/10000: L(Train): 0.27145975828170776; L(Test): 0.24213504791259766\n",
      "Epoch 4025/10000: L(Train): 0.26794588565826416; L(Test): 0.24350878596305847\n",
      "Epoch 4026/10000: L(Train): 0.27259334921836853; L(Test): 0.243181511759758\n",
      "Epoch 4027/10000: L(Train): 0.27572232484817505; L(Test): 0.24192096292972565\n",
      "Epoch 4028/10000: L(Train): 0.25218313932418823; L(Test): 0.2422885149717331\n",
      "Epoch 4029/10000: L(Train): 0.2609184980392456; L(Test): 0.24211838841438293\n",
      "Epoch 4030/10000: L(Train): 0.26181507110595703; L(Test): 0.2427486777305603\n",
      "Epoch 4031/10000: L(Train): 0.27180215716362; L(Test): 0.2423708289861679\n",
      "Epoch 4032/10000: L(Train): 0.25770848989486694; L(Test): 0.2423655390739441\n",
      "Epoch 4033/10000: L(Train): 0.26078662276268005; L(Test): 0.2431170642375946\n",
      "Epoch 4034/10000: L(Train): 0.2660713195800781; L(Test): 0.2429041713476181\n",
      "Epoch 4035/10000: L(Train): 0.2706664800643921; L(Test): 0.24218453466892242\n",
      "Epoch 4036/10000: L(Train): 0.25406789779663086; L(Test): 0.24246545135974884\n",
      "Epoch 4037/10000: L(Train): 0.27508193254470825; L(Test): 0.24196864664554596\n",
      "Epoch 4038/10000: L(Train): 0.2530614733695984; L(Test): 0.2421426773071289\n",
      "Epoch 4039/10000: L(Train): 0.2710590958595276; L(Test): 0.2418394684791565\n",
      "Epoch 4040/10000: L(Train): 0.2582956552505493; L(Test): 0.24196282029151917\n",
      "Epoch 4041/10000: L(Train): 0.27420708537101746; L(Test): 0.24258719384670258\n",
      "Epoch 4042/10000: L(Train): 0.25190192461013794; L(Test): 0.24151787161827087\n",
      "Epoch 4043/10000: L(Train): 0.2607516050338745; L(Test): 0.24139590561389923\n",
      "Epoch 4044/10000: L(Train): 0.26995980739593506; L(Test): 0.24180850386619568\n",
      "Epoch 4045/10000: L(Train): 0.26388421654701233; L(Test): 0.24237973988056183\n",
      "Epoch 4046/10000: L(Train): 0.2633615732192993; L(Test): 0.24183452129364014\n",
      "Epoch 4047/10000: L(Train): 0.25978532433509827; L(Test): 0.24071840941905975\n",
      "Epoch 4048/10000: L(Train): 0.2563423216342926; L(Test): 0.23993001878261566\n",
      "Epoch 4049/10000: L(Train): 0.25938141345977783; L(Test): 0.24043017625808716\n",
      "Epoch 4050/10000: L(Train): 0.2627255320549011; L(Test): 0.24170853197574615\n",
      "Epoch 4051/10000: L(Train): 0.2634802758693695; L(Test): 0.24095040559768677\n",
      "Epoch 4052/10000: L(Train): 0.26837480068206787; L(Test): 0.24108174443244934\n",
      "Epoch 4053/10000: L(Train): 0.2658665180206299; L(Test): 0.24038980901241302\n",
      "Epoch 4054/10000: L(Train): 0.2525019943714142; L(Test): 0.2401970624923706\n",
      "Epoch 4055/10000: L(Train): 0.27532529830932617; L(Test): 0.23996120691299438\n",
      "Epoch 4056/10000: L(Train): 0.26369544863700867; L(Test): 0.2392285317182541\n",
      "Epoch 4057/10000: L(Train): 0.26275262236595154; L(Test): 0.23956415057182312\n",
      "Epoch 4058/10000: L(Train): 0.2512699067592621; L(Test): 0.2399834245443344\n",
      "Epoch 4059/10000: L(Train): 0.2669764459133148; L(Test): 0.24026358127593994\n",
      "Epoch 4060/10000: L(Train): 0.24977824091911316; L(Test): 0.24099358916282654\n",
      "Epoch 4061/10000: L(Train): 0.2766469419002533; L(Test): 0.23984187841415405\n",
      "Epoch 4062/10000: L(Train): 0.24553324282169342; L(Test): 0.23922781646251678\n",
      "Epoch 4063/10000: L(Train): 0.2604040503501892; L(Test): 0.23937352001667023\n",
      "Epoch 4064/10000: L(Train): 0.2593652904033661; L(Test): 0.23941372334957123\n",
      "Epoch 4065/10000: L(Train): 0.2722966969013214; L(Test): 0.23883214592933655\n",
      "Epoch 4066/10000: L(Train): 0.2511146664619446; L(Test): 0.23923587799072266\n",
      "Epoch 4067/10000: L(Train): 0.25672364234924316; L(Test): 0.23941269516944885\n",
      "Epoch 4068/10000: L(Train): 0.24977916479110718; L(Test): 0.2400050312280655\n",
      "Epoch 4069/10000: L(Train): 0.27127349376678467; L(Test): 0.2406209260225296\n",
      "Epoch 4070/10000: L(Train): 0.2603357136249542; L(Test): 0.24089163541793823\n",
      "Epoch 4071/10000: L(Train): 0.2648904621601105; L(Test): 0.2408100962638855\n",
      "Epoch 4072/10000: L(Train): 0.24829266965389252; L(Test): 0.239422008395195\n",
      "Epoch 4073/10000: L(Train): 0.2725779712200165; L(Test): 0.24079304933547974\n",
      "Epoch 4074/10000: L(Train): 0.2641744911670685; L(Test): 0.24145613610744476\n",
      "Epoch 4075/10000: L(Train): 0.2656453847885132; L(Test): 0.23956231772899628\n",
      "Epoch 4076/10000: L(Train): 0.25617045164108276; L(Test): 0.24001702666282654\n",
      "Epoch 4077/10000: L(Train): 0.24559132754802704; L(Test): 0.2398778796195984\n",
      "Epoch 4078/10000: L(Train): 0.2564801871776581; L(Test): 0.23934616148471832\n",
      "Epoch 4079/10000: L(Train): 0.26043421030044556; L(Test): 0.23922713100910187\n",
      "Epoch 4080/10000: L(Train): 0.2751469016075134; L(Test): 0.2402227520942688\n",
      "Epoch 4081/10000: L(Train): 0.26864078640937805; L(Test): 0.23852279782295227\n",
      "Epoch 4082/10000: L(Train): 0.25924888253211975; L(Test): 0.24137085676193237\n",
      "Epoch 4083/10000: L(Train): 0.26532965898513794; L(Test): 0.24152903258800507\n",
      "Epoch 4084/10000: L(Train): 0.25950050354003906; L(Test): 0.24029552936553955\n",
      "Epoch 4085/10000: L(Train): 0.26239633560180664; L(Test): 0.2402724027633667\n",
      "Epoch 4086/10000: L(Train): 0.27058663964271545; L(Test): 0.2410479485988617\n",
      "Epoch 4087/10000: L(Train): 0.26095321774482727; L(Test): 0.2396184206008911\n",
      "Epoch 4088/10000: L(Train): 0.26241227984428406; L(Test): 0.24045631289482117\n",
      "Epoch 4089/10000: L(Train): 0.2754034399986267; L(Test): 0.24093061685562134\n",
      "Epoch 4090/10000: L(Train): 0.2669444680213928; L(Test): 0.2403533011674881\n",
      "Epoch 4091/10000: L(Train): 0.27421489357948303; L(Test): 0.24046650528907776\n",
      "Epoch 4092/10000: L(Train): 0.2723037004470825; L(Test): 0.2420128434896469\n",
      "Epoch 4093/10000: L(Train): 0.2654170095920563; L(Test): 0.24277310073375702\n",
      "Epoch 4094/10000: L(Train): 0.2767587900161743; L(Test): 0.24221397936344147\n",
      "Epoch 4095/10000: L(Train): 0.2706088423728943; L(Test): 0.24210026860237122\n",
      "Epoch 4096/10000: L(Train): 0.25619056820869446; L(Test): 0.2416764348745346\n",
      "Epoch 4097/10000: L(Train): 0.256229043006897; L(Test): 0.24129237234592438\n",
      "Epoch 4098/10000: L(Train): 0.24873241782188416; L(Test): 0.24365803599357605\n",
      "Epoch 4099/10000: L(Train): 0.2707326114177704; L(Test): 0.24230508506298065\n",
      "Epoch 4100/10000: L(Train): 0.26907438039779663; L(Test): 0.2427855283021927\n",
      "Epoch 4101/10000: L(Train): 0.2771880030632019; L(Test): 0.24357204139232635\n",
      "Epoch 4102/10000: L(Train): 0.26858240365982056; L(Test): 0.24192501604557037\n",
      "Epoch 4103/10000: L(Train): 0.2688570022583008; L(Test): 0.2422434389591217\n",
      "Epoch 4104/10000: L(Train): 0.2508009076118469; L(Test): 0.24328425526618958\n",
      "Epoch 4105/10000: L(Train): 0.26107025146484375; L(Test): 0.24351470172405243\n",
      "Epoch 4106/10000: L(Train): 0.27570801973342896; L(Test): 0.24201248586177826\n",
      "Epoch 4107/10000: L(Train): 0.2828940153121948; L(Test): 0.244424507021904\n",
      "Epoch 4108/10000: L(Train): 0.2592410147190094; L(Test): 0.24305063486099243\n",
      "Epoch 4109/10000: L(Train): 0.2624235153198242; L(Test): 0.24098210036754608\n",
      "Epoch 4110/10000: L(Train): 0.26959484815597534; L(Test): 0.24259747564792633\n",
      "Epoch 4111/10000: L(Train): 0.26054105162620544; L(Test): 0.24283824861049652\n",
      "Epoch 4112/10000: L(Train): 0.2599679231643677; L(Test): 0.2428920567035675\n",
      "Epoch 4113/10000: L(Train): 0.25493529438972473; L(Test): 0.24288585782051086\n",
      "Epoch 4114/10000: L(Train): 0.2653280794620514; L(Test): 0.24500447511672974\n",
      "Epoch 4115/10000: L(Train): 0.27530962228775024; L(Test): 0.24231736361980438\n",
      "Epoch 4116/10000: L(Train): 0.26885223388671875; L(Test): 0.24657441675662994\n",
      "Epoch 4117/10000: L(Train): 0.26491716504096985; L(Test): 0.2435525804758072\n",
      "Epoch 4118/10000: L(Train): 0.2654085159301758; L(Test): 0.24265775084495544\n",
      "Epoch 4119/10000: L(Train): 0.2661791145801544; L(Test): 0.24379737675189972\n",
      "Epoch 4120/10000: L(Train): 0.26518332958221436; L(Test): 0.24231413006782532\n",
      "Epoch 4121/10000: L(Train): 0.25977617502212524; L(Test): 0.24570874869823456\n",
      "Epoch 4122/10000: L(Train): 0.2681346833705902; L(Test): 0.242566779255867\n",
      "Epoch 4123/10000: L(Train): 0.2484053522348404; L(Test): 0.24239984154701233\n",
      "Epoch 4124/10000: L(Train): 0.2589562237262726; L(Test): 0.24147748947143555\n",
      "Epoch 4125/10000: L(Train): 0.2759673297405243; L(Test): 0.24445785582065582\n",
      "Epoch 4126/10000: L(Train): 0.2648945152759552; L(Test): 0.2434564083814621\n",
      "Epoch 4127/10000: L(Train): 0.24849358201026917; L(Test): 0.24089834094047546\n",
      "Epoch 4128/10000: L(Train): 0.25595012307167053; L(Test): 0.24163475632667542\n",
      "Epoch 4129/10000: L(Train): 0.262077271938324; L(Test): 0.24148598313331604\n",
      "Epoch 4130/10000: L(Train): 0.27823978662490845; L(Test): 0.24338921904563904\n",
      "Epoch 4131/10000: L(Train): 0.25915685296058655; L(Test): 0.2422943115234375\n",
      "Epoch 4132/10000: L(Train): 0.2594803273677826; L(Test): 0.24204455316066742\n",
      "Epoch 4133/10000: L(Train): 0.2754989266395569; L(Test): 0.24103817343711853\n",
      "Epoch 4134/10000: L(Train): 0.2614894211292267; L(Test): 0.24120858311653137\n",
      "Epoch 4135/10000: L(Train): 0.259836345911026; L(Test): 0.24223648011684418\n",
      "Epoch 4136/10000: L(Train): 0.25549620389938354; L(Test): 0.2423297017812729\n",
      "Epoch 4137/10000: L(Train): 0.25397616624832153; L(Test): 0.24063576757907867\n",
      "Epoch 4138/10000: L(Train): 0.2802989184856415; L(Test): 0.2416193187236786\n",
      "Epoch 4139/10000: L(Train): 0.2514783442020416; L(Test): 0.24219882488250732\n",
      "Epoch 4140/10000: L(Train): 0.2611031234264374; L(Test): 0.24239318072795868\n",
      "Epoch 4141/10000: L(Train): 0.25670579075813293; L(Test): 0.24302028119564056\n",
      "Epoch 4142/10000: L(Train): 0.2620672583580017; L(Test): 0.24284660816192627\n",
      "Epoch 4143/10000: L(Train): 0.28305843472480774; L(Test): 0.2415795922279358\n",
      "Epoch 4144/10000: L(Train): 0.2676609754562378; L(Test): 0.24058757722377777\n",
      "Epoch 4145/10000: L(Train): 0.2711826264858246; L(Test): 0.24111013114452362\n",
      "Epoch 4146/10000: L(Train): 0.2592598497867584; L(Test): 0.24386927485466003\n",
      "Epoch 4147/10000: L(Train): 0.2763814628124237; L(Test): 0.24148617684841156\n",
      "Epoch 4148/10000: L(Train): 0.2557499408721924; L(Test): 0.2411259114742279\n",
      "Epoch 4149/10000: L(Train): 0.2614871859550476; L(Test): 0.241672545671463\n",
      "Epoch 4150/10000: L(Train): 0.2618403434753418; L(Test): 0.24150781333446503\n",
      "Epoch 4151/10000: L(Train): 0.28083962202072144; L(Test): 0.2430374026298523\n",
      "Epoch 4152/10000: L(Train): 0.26280200481414795; L(Test): 0.24107518792152405\n",
      "Epoch 4153/10000: L(Train): 0.270525723695755; L(Test): 0.24084483087062836\n",
      "Epoch 4154/10000: L(Train): 0.2673737108707428; L(Test): 0.2421463280916214\n",
      "Epoch 4155/10000: L(Train): 0.26287707686424255; L(Test): 0.24089568853378296\n",
      "Epoch 4156/10000: L(Train): 0.250265508890152; L(Test): 0.24111878871917725\n",
      "Epoch 4157/10000: L(Train): 0.26284390687942505; L(Test): 0.24456021189689636\n",
      "Epoch 4158/10000: L(Train): 0.26119762659072876; L(Test): 0.2450377345085144\n",
      "Epoch 4159/10000: L(Train): 0.2620716691017151; L(Test): 0.24178828299045563\n",
      "Epoch 4160/10000: L(Train): 0.2605411112308502; L(Test): 0.2421288788318634\n",
      "Epoch 4161/10000: L(Train): 0.2647366523742676; L(Test): 0.2424570769071579\n",
      "Epoch 4162/10000: L(Train): 0.2680552899837494; L(Test): 0.2408132255077362\n",
      "Epoch 4163/10000: L(Train): 0.2614935636520386; L(Test): 0.24061264097690582\n",
      "Epoch 4164/10000: L(Train): 0.25458404421806335; L(Test): 0.24181658029556274\n",
      "Epoch 4165/10000: L(Train): 0.2706035077571869; L(Test): 0.24120911955833435\n",
      "Epoch 4166/10000: L(Train): 0.276693195104599; L(Test): 0.23973076045513153\n",
      "Epoch 4167/10000: L(Train): 0.25823771953582764; L(Test): 0.2406242936849594\n",
      "Epoch 4168/10000: L(Train): 0.2639763653278351; L(Test): 0.24010010063648224\n",
      "Epoch 4169/10000: L(Train): 0.24900616705417633; L(Test): 0.23986074328422546\n",
      "Epoch 4170/10000: L(Train): 0.2595911920070648; L(Test): 0.24070164561271667\n",
      "Epoch 4171/10000: L(Train): 0.262926310300827; L(Test): 0.2403119057416916\n",
      "Epoch 4172/10000: L(Train): 0.2761637568473816; L(Test): 0.2394225001335144\n",
      "Epoch 4173/10000: L(Train): 0.2612694501876831; L(Test): 0.2401188462972641\n",
      "Epoch 4174/10000: L(Train): 0.26328954100608826; L(Test): 0.24019160866737366\n",
      "Epoch 4175/10000: L(Train): 0.26847410202026367; L(Test): 0.23975175619125366\n",
      "Epoch 4176/10000: L(Train): 0.26372265815734863; L(Test): 0.2395026832818985\n",
      "Epoch 4177/10000: L(Train): 0.2562514841556549; L(Test): 0.23914772272109985\n",
      "Epoch 4178/10000: L(Train): 0.25084730982780457; L(Test): 0.23986868560314178\n",
      "Epoch 4179/10000: L(Train): 0.2706717252731323; L(Test): 0.240581214427948\n",
      "Epoch 4180/10000: L(Train): 0.2733403146266937; L(Test): 0.23906221985816956\n",
      "Epoch 4181/10000: L(Train): 0.26744499802589417; L(Test): 0.2405242919921875\n",
      "Epoch 4182/10000: L(Train): 0.2589646279811859; L(Test): 0.23984572291374207\n",
      "Epoch 4183/10000: L(Train): 0.2625623047351837; L(Test): 0.2391463816165924\n",
      "Epoch 4184/10000: L(Train): 0.2771429419517517; L(Test): 0.24062784016132355\n",
      "Epoch 4185/10000: L(Train): 0.25807851552963257; L(Test): 0.24163125455379486\n",
      "Epoch 4186/10000: L(Train): 0.2555161416530609; L(Test): 0.24072687327861786\n",
      "Epoch 4187/10000: L(Train): 0.2753187119960785; L(Test): 0.24164225161075592\n",
      "Epoch 4188/10000: L(Train): 0.2709229588508606; L(Test): 0.24438835680484772\n",
      "Epoch 4189/10000: L(Train): 0.2638765275478363; L(Test): 0.24458488821983337\n",
      "Epoch 4190/10000: L(Train): 0.27228617668151855; L(Test): 0.24123047292232513\n",
      "Epoch 4191/10000: L(Train): 0.2527843415737152; L(Test): 0.24415172636508942\n",
      "Epoch 4192/10000: L(Train): 0.26290395855903625; L(Test): 0.2435346245765686\n",
      "Epoch 4193/10000: L(Train): 0.2688112258911133; L(Test): 0.24176178872585297\n",
      "Epoch 4194/10000: L(Train): 0.2646466791629791; L(Test): 0.24377037584781647\n",
      "Epoch 4195/10000: L(Train): 0.2641220688819885; L(Test): 0.24183878302574158\n",
      "Epoch 4196/10000: L(Train): 0.2893548607826233; L(Test): 0.24212490022182465\n",
      "Epoch 4197/10000: L(Train): 0.26331156492233276; L(Test): 0.24225881695747375\n",
      "Epoch 4198/10000: L(Train): 0.26866602897644043; L(Test): 0.24189281463623047\n",
      "Epoch 4199/10000: L(Train): 0.2581292688846588; L(Test): 0.2448507845401764\n",
      "Epoch 4200/10000: L(Train): 0.2853584885597229; L(Test): 0.24134105443954468\n",
      "Epoch 4201/10000: L(Train): 0.2629941999912262; L(Test): 0.24263454973697662\n",
      "Epoch 4202/10000: L(Train): 0.2692471444606781; L(Test): 0.2418074905872345\n",
      "Epoch 4203/10000: L(Train): 0.2554160952568054; L(Test): 0.2415730059146881\n",
      "Epoch 4204/10000: L(Train): 0.25501716136932373; L(Test): 0.2425323724746704\n",
      "Epoch 4205/10000: L(Train): 0.2783622145652771; L(Test): 0.24156580865383148\n",
      "Epoch 4206/10000: L(Train): 0.272087961435318; L(Test): 0.24060893058776855\n",
      "Epoch 4207/10000: L(Train): 0.2674860656261444; L(Test): 0.24058203399181366\n",
      "Epoch 4208/10000: L(Train): 0.2730482220649719; L(Test): 0.24028387665748596\n",
      "Epoch 4209/10000: L(Train): 0.2644045054912567; L(Test): 0.2404354363679886\n",
      "Epoch 4210/10000: L(Train): 0.2656589448451996; L(Test): 0.24040652811527252\n",
      "Epoch 4211/10000: L(Train): 0.26833921670913696; L(Test): 0.24012228846549988\n",
      "Epoch 4212/10000: L(Train): 0.2579772174358368; L(Test): 0.23995740711688995\n",
      "Epoch 4213/10000: L(Train): 0.25017470121383667; L(Test): 0.24030804634094238\n",
      "Epoch 4214/10000: L(Train): 0.26690810918807983; L(Test): 0.24048231542110443\n",
      "Epoch 4215/10000: L(Train): 0.26634088158607483; L(Test): 0.24035236239433289\n",
      "Epoch 4216/10000: L(Train): 0.281647652387619; L(Test): 0.2407303899526596\n",
      "Epoch 4217/10000: L(Train): 0.26067477464675903; L(Test): 0.2400088608264923\n",
      "Epoch 4218/10000: L(Train): 0.2663782238960266; L(Test): 0.2393500655889511\n",
      "Epoch 4219/10000: L(Train): 0.25726839900016785; L(Test): 0.23958583176136017\n",
      "Epoch 4220/10000: L(Train): 0.2630314230918884; L(Test): 0.24069145321846008\n",
      "Epoch 4221/10000: L(Train): 0.2723558247089386; L(Test): 0.23963959515094757\n",
      "Epoch 4222/10000: L(Train): 0.2689822018146515; L(Test): 0.24007119238376617\n",
      "Epoch 4223/10000: L(Train): 0.2637205123901367; L(Test): 0.2400488406419754\n",
      "Epoch 4224/10000: L(Train): 0.26471811532974243; L(Test): 0.23954395949840546\n",
      "Epoch 4225/10000: L(Train): 0.2597571611404419; L(Test): 0.2403772622346878\n",
      "Epoch 4226/10000: L(Train): 0.25941017270088196; L(Test): 0.2397603988647461\n",
      "Epoch 4227/10000: L(Train): 0.252472460269928; L(Test): 0.23917156457901\n",
      "Epoch 4228/10000: L(Train): 0.2632881700992584; L(Test): 0.23898547887802124\n",
      "Epoch 4229/10000: L(Train): 0.265760213136673; L(Test): 0.2386956363916397\n",
      "Epoch 4230/10000: L(Train): 0.260994553565979; L(Test): 0.23979614675045013\n",
      "Epoch 4231/10000: L(Train): 0.27780964970588684; L(Test): 0.23978562653064728\n",
      "Epoch 4232/10000: L(Train): 0.2720731198787689; L(Test): 0.24009796977043152\n",
      "Epoch 4233/10000: L(Train): 0.2554931044578552; L(Test): 0.23977653682231903\n",
      "Epoch 4234/10000: L(Train): 0.25961026549339294; L(Test): 0.24035097658634186\n",
      "Epoch 4235/10000: L(Train): 0.26497161388397217; L(Test): 0.24045005440711975\n",
      "Epoch 4236/10000: L(Train): 0.2492734044790268; L(Test): 0.23965738713741302\n",
      "Epoch 4237/10000: L(Train): 0.25498947501182556; L(Test): 0.24226900935173035\n",
      "Epoch 4238/10000: L(Train): 0.2669011950492859; L(Test): 0.2392309606075287\n",
      "Epoch 4239/10000: L(Train): 0.2804130017757416; L(Test): 0.24086442589759827\n",
      "Epoch 4240/10000: L(Train): 0.25729286670684814; L(Test): 0.24148279428482056\n",
      "Epoch 4241/10000: L(Train): 0.26068115234375; L(Test): 0.24083609879016876\n",
      "Epoch 4242/10000: L(Train): 0.2613108456134796; L(Test): 0.24090343713760376\n",
      "Epoch 4243/10000: L(Train): 0.267945259809494; L(Test): 0.2401546686887741\n",
      "Epoch 4244/10000: L(Train): 0.27126577496528625; L(Test): 0.2402559369802475\n",
      "Epoch 4245/10000: L(Train): 0.2430761307477951; L(Test): 0.2409561425447464\n",
      "Epoch 4246/10000: L(Train): 0.2708412706851959; L(Test): 0.23942062258720398\n",
      "Epoch 4247/10000: L(Train): 0.2730907201766968; L(Test): 0.23961463570594788\n",
      "Epoch 4248/10000: L(Train): 0.26033705472946167; L(Test): 0.23918704688549042\n",
      "Epoch 4249/10000: L(Train): 0.261502742767334; L(Test): 0.24077458679676056\n",
      "Epoch 4250/10000: L(Train): 0.2848544418811798; L(Test): 0.24084912240505219\n",
      "Epoch 4251/10000: L(Train): 0.2587537169456482; L(Test): 0.239526629447937\n",
      "Epoch 4252/10000: L(Train): 0.25986090302467346; L(Test): 0.24180111289024353\n",
      "Epoch 4253/10000: L(Train): 0.2554667592048645; L(Test): 0.24041926860809326\n",
      "Epoch 4254/10000: L(Train): 0.25574320554733276; L(Test): 0.24367067217826843\n",
      "Epoch 4255/10000: L(Train): 0.27154093980789185; L(Test): 0.24074560403823853\n",
      "Epoch 4256/10000: L(Train): 0.2507466673851013; L(Test): 0.24171718955039978\n",
      "Epoch 4257/10000: L(Train): 0.25237026810646057; L(Test): 0.24191361665725708\n",
      "Epoch 4258/10000: L(Train): 0.27644628286361694; L(Test): 0.24135033786296844\n",
      "Epoch 4259/10000: L(Train): 0.2633460760116577; L(Test): 0.24324098229408264\n",
      "Epoch 4260/10000: L(Train): 0.25783488154411316; L(Test): 0.24142740666866302\n",
      "Epoch 4261/10000: L(Train): 0.280656635761261; L(Test): 0.24125008285045624\n",
      "Epoch 4262/10000: L(Train): 0.27645376324653625; L(Test): 0.2408340722322464\n",
      "Epoch 4263/10000: L(Train): 0.2572247087955475; L(Test): 0.24352651834487915\n",
      "Epoch 4264/10000: L(Train): 0.26131588220596313; L(Test): 0.24258412420749664\n",
      "Epoch 4265/10000: L(Train): 0.263924777507782; L(Test): 0.24078063666820526\n",
      "Epoch 4266/10000: L(Train): 0.25895485281944275; L(Test): 0.24107225239276886\n",
      "Epoch 4267/10000: L(Train): 0.25103959441185; L(Test): 0.24015578627586365\n",
      "Epoch 4268/10000: L(Train): 0.25101548433303833; L(Test): 0.24023929238319397\n",
      "Epoch 4269/10000: L(Train): 0.2665725648403168; L(Test): 0.24108785390853882\n",
      "Epoch 4270/10000: L(Train): 0.2373250275850296; L(Test): 0.24114038050174713\n",
      "Epoch 4271/10000: L(Train): 0.2737572491168976; L(Test): 0.24062685668468475\n",
      "Epoch 4272/10000: L(Train): 0.2651386559009552; L(Test): 0.23932674527168274\n",
      "Epoch 4273/10000: L(Train): 0.253958523273468; L(Test): 0.2414170205593109\n",
      "Epoch 4274/10000: L(Train): 0.2733374536037445; L(Test): 0.2397823929786682\n",
      "Epoch 4275/10000: L(Train): 0.25297868251800537; L(Test): 0.23970896005630493\n",
      "Epoch 4276/10000: L(Train): 0.25312432646751404; L(Test): 0.24002763628959656\n",
      "Epoch 4277/10000: L(Train): 0.26043206453323364; L(Test): 0.23968902230262756\n",
      "Epoch 4278/10000: L(Train): 0.2617599368095398; L(Test): 0.24151314795017242\n",
      "Epoch 4279/10000: L(Train): 0.2633778750896454; L(Test): 0.240564227104187\n",
      "Epoch 4280/10000: L(Train): 0.2686804234981537; L(Test): 0.23951081931591034\n",
      "Epoch 4281/10000: L(Train): 0.27570846676826477; L(Test): 0.24036090075969696\n",
      "Epoch 4282/10000: L(Train): 0.25853025913238525; L(Test): 0.2396782785654068\n",
      "Epoch 4283/10000: L(Train): 0.25711414217948914; L(Test): 0.23939265310764313\n",
      "Epoch 4284/10000: L(Train): 0.2871132493019104; L(Test): 0.2391107678413391\n",
      "Epoch 4285/10000: L(Train): 0.24431529641151428; L(Test): 0.23855160176753998\n",
      "Epoch 4286/10000: L(Train): 0.2825545072555542; L(Test): 0.23858335614204407\n",
      "Epoch 4287/10000: L(Train): 0.26122793555259705; L(Test): 0.23978789150714874\n",
      "Epoch 4288/10000: L(Train): 0.2630293369293213; L(Test): 0.23916156589984894\n",
      "Epoch 4289/10000: L(Train): 0.26103389263153076; L(Test): 0.23996244370937347\n",
      "Epoch 4290/10000: L(Train): 0.27426785230636597; L(Test): 0.2395683228969574\n",
      "Epoch 4291/10000: L(Train): 0.27278003096580505; L(Test): 0.23957641422748566\n",
      "Epoch 4292/10000: L(Train): 0.26992493867874146; L(Test): 0.2391219139099121\n",
      "Epoch 4293/10000: L(Train): 0.26068973541259766; L(Test): 0.23958410322666168\n",
      "Epoch 4294/10000: L(Train): 0.26565179228782654; L(Test): 0.23968996107578278\n",
      "Epoch 4295/10000: L(Train): 0.27134618163108826; L(Test): 0.24026994407176971\n",
      "Epoch 4296/10000: L(Train): 0.25959232449531555; L(Test): 0.24048899114131927\n",
      "Epoch 4297/10000: L(Train): 0.28055691719055176; L(Test): 0.24048177897930145\n",
      "Epoch 4298/10000: L(Train): 0.2643718421459198; L(Test): 0.24004583060741425\n",
      "Epoch 4299/10000: L(Train): 0.26765286922454834; L(Test): 0.23862145841121674\n",
      "Epoch 4300/10000: L(Train): 0.25876420736312866; L(Test): 0.23851342499256134\n",
      "Epoch 4301/10000: L(Train): 0.251960813999176; L(Test): 0.23910661041736603\n",
      "Epoch 4302/10000: L(Train): 0.2691250145435333; L(Test): 0.2384013682603836\n",
      "Epoch 4303/10000: L(Train): 0.2635822296142578; L(Test): 0.23848606646060944\n",
      "Epoch 4304/10000: L(Train): 0.25945764780044556; L(Test): 0.23872071504592896\n",
      "Epoch 4305/10000: L(Train): 0.25735756754875183; L(Test): 0.2391074150800705\n",
      "Epoch 4306/10000: L(Train): 0.2589610517024994; L(Test): 0.23840098083019257\n",
      "Epoch 4307/10000: L(Train): 0.25169679522514343; L(Test): 0.23844663798809052\n",
      "Epoch 4308/10000: L(Train): 0.2658257782459259; L(Test): 0.23829883337020874\n",
      "Epoch 4309/10000: L(Train): 0.26412031054496765; L(Test): 0.239413782954216\n",
      "Epoch 4310/10000: L(Train): 0.26290273666381836; L(Test): 0.2390766441822052\n",
      "Epoch 4311/10000: L(Train): 0.2697362005710602; L(Test): 0.23852412402629852\n",
      "Epoch 4312/10000: L(Train): 0.25315186381340027; L(Test): 0.23876997828483582\n",
      "Epoch 4313/10000: L(Train): 0.2670193016529083; L(Test): 0.2395908236503601\n",
      "Epoch 4314/10000: L(Train): 0.26806768774986267; L(Test): 0.23937749862670898\n",
      "Epoch 4315/10000: L(Train): 0.24131174385547638; L(Test): 0.23970790207386017\n",
      "Epoch 4316/10000: L(Train): 0.2496868520975113; L(Test): 0.23885877430438995\n",
      "Epoch 4317/10000: L(Train): 0.2620958983898163; L(Test): 0.2382693737745285\n",
      "Epoch 4318/10000: L(Train): 0.2807587683200836; L(Test): 0.2380903661251068\n",
      "Epoch 4319/10000: L(Train): 0.2560426592826843; L(Test): 0.24049913883209229\n",
      "Epoch 4320/10000: L(Train): 0.27462485432624817; L(Test): 0.2398463785648346\n",
      "Epoch 4321/10000: L(Train): 0.26608094573020935; L(Test): 0.2388063371181488\n",
      "Epoch 4322/10000: L(Train): 0.2667226195335388; L(Test): 0.23973695933818817\n",
      "Epoch 4323/10000: L(Train): 0.2660534083843231; L(Test): 0.23858925700187683\n",
      "Epoch 4324/10000: L(Train): 0.27395379543304443; L(Test): 0.2398453652858734\n",
      "Epoch 4325/10000: L(Train): 0.25233709812164307; L(Test): 0.23922424018383026\n",
      "Epoch 4326/10000: L(Train): 0.27242928743362427; L(Test): 0.23799262940883636\n",
      "Epoch 4327/10000: L(Train): 0.2579481601715088; L(Test): 0.23885037004947662\n",
      "Epoch 4328/10000: L(Train): 0.26935675740242004; L(Test): 0.2387416809797287\n",
      "Epoch 4329/10000: L(Train): 0.2698063254356384; L(Test): 0.23927061259746552\n",
      "Epoch 4330/10000: L(Train): 0.259660929441452; L(Test): 0.23997773230075836\n",
      "Epoch 4331/10000: L(Train): 0.2704319655895233; L(Test): 0.2402944713830948\n",
      "Epoch 4332/10000: L(Train): 0.25541356205940247; L(Test): 0.24055816233158112\n",
      "Epoch 4333/10000: L(Train): 0.2657630443572998; L(Test): 0.24138113856315613\n",
      "Epoch 4334/10000: L(Train): 0.2619101107120514; L(Test): 0.24133870005607605\n",
      "Epoch 4335/10000: L(Train): 0.25759539008140564; L(Test): 0.24145907163619995\n",
      "Epoch 4336/10000: L(Train): 0.2712435722351074; L(Test): 0.2417636662721634\n",
      "Epoch 4337/10000: L(Train): 0.27101048827171326; L(Test): 0.24170523881912231\n",
      "Epoch 4338/10000: L(Train): 0.26669439673423767; L(Test): 0.24010683596134186\n",
      "Epoch 4339/10000: L(Train): 0.2687421441078186; L(Test): 0.24071337282657623\n",
      "Epoch 4340/10000: L(Train): 0.2500746250152588; L(Test): 0.24078777432441711\n",
      "Epoch 4341/10000: L(Train): 0.2693137228488922; L(Test): 0.24072419106960297\n",
      "Epoch 4342/10000: L(Train): 0.2515062987804413; L(Test): 0.24108152091503143\n",
      "Epoch 4343/10000: L(Train): 0.2598588466644287; L(Test): 0.24097992479801178\n",
      "Epoch 4344/10000: L(Train): 0.2598477005958557; L(Test): 0.24076016247272491\n",
      "Epoch 4345/10000: L(Train): 0.2756701111793518; L(Test): 0.24165038764476776\n",
      "Epoch 4346/10000: L(Train): 0.2723531723022461; L(Test): 0.2406722754240036\n",
      "Epoch 4347/10000: L(Train): 0.2739614248275757; L(Test): 0.24268324673175812\n",
      "Epoch 4348/10000: L(Train): 0.265109121799469; L(Test): 0.2433358132839203\n",
      "Epoch 4349/10000: L(Train): 0.26902058720588684; L(Test): 0.24168625473976135\n",
      "Epoch 4350/10000: L(Train): 0.27543962001800537; L(Test): 0.24277082085609436\n",
      "Epoch 4351/10000: L(Train): 0.26852279901504517; L(Test): 0.2431536465883255\n",
      "Epoch 4352/10000: L(Train): 0.2670954465866089; L(Test): 0.24253860116004944\n",
      "Epoch 4353/10000: L(Train): 0.25505077838897705; L(Test): 0.24073943495750427\n",
      "Epoch 4354/10000: L(Train): 0.2623167634010315; L(Test): 0.2408042997121811\n",
      "Epoch 4355/10000: L(Train): 0.25100967288017273; L(Test): 0.24053128063678741\n",
      "Epoch 4356/10000: L(Train): 0.25453317165374756; L(Test): 0.24165919423103333\n",
      "Epoch 4357/10000: L(Train): 0.2778175473213196; L(Test): 0.2410202920436859\n",
      "Epoch 4358/10000: L(Train): 0.2573966383934021; L(Test): 0.24048848450183868\n",
      "Epoch 4359/10000: L(Train): 0.2516445219516754; L(Test): 0.23984742164611816\n",
      "Epoch 4360/10000: L(Train): 0.26484405994415283; L(Test): 0.23962360620498657\n",
      "Epoch 4361/10000: L(Train): 0.2499677538871765; L(Test): 0.24019798636436462\n",
      "Epoch 4362/10000: L(Train): 0.26522010564804077; L(Test): 0.24004121124744415\n",
      "Epoch 4363/10000: L(Train): 0.26342684030532837; L(Test): 0.23964329063892365\n",
      "Epoch 4364/10000: L(Train): 0.24156376719474792; L(Test): 0.2399582415819168\n",
      "Epoch 4365/10000: L(Train): 0.2755798399448395; L(Test): 0.24084602296352386\n",
      "Epoch 4366/10000: L(Train): 0.25723135471343994; L(Test): 0.24008101224899292\n",
      "Epoch 4367/10000: L(Train): 0.25710099935531616; L(Test): 0.24029125273227692\n",
      "Epoch 4368/10000: L(Train): 0.24424238502979279; L(Test): 0.2411549687385559\n",
      "Epoch 4369/10000: L(Train): 0.26062795519828796; L(Test): 0.24065826833248138\n",
      "Epoch 4370/10000: L(Train): 0.2625667154788971; L(Test): 0.240290567278862\n",
      "Epoch 4371/10000: L(Train): 0.2567340135574341; L(Test): 0.24070151150226593\n",
      "Epoch 4372/10000: L(Train): 0.27203336358070374; L(Test): 0.24109657108783722\n",
      "Epoch 4373/10000: L(Train): 0.26674216985702515; L(Test): 0.24373318254947662\n",
      "Epoch 4374/10000: L(Train): 0.25553226470947266; L(Test): 0.24146902561187744\n",
      "Epoch 4375/10000: L(Train): 0.24891772866249084; L(Test): 0.24139408767223358\n",
      "Epoch 4376/10000: L(Train): 0.2618989646434784; L(Test): 0.24146844446659088\n",
      "Epoch 4377/10000: L(Train): 0.2442111372947693; L(Test): 0.24205778539180756\n",
      "Epoch 4378/10000: L(Train): 0.27347293496131897; L(Test): 0.24181370437145233\n",
      "Epoch 4379/10000: L(Train): 0.2665346562862396; L(Test): 0.24067936837673187\n",
      "Epoch 4380/10000: L(Train): 0.26167190074920654; L(Test): 0.24205434322357178\n",
      "Epoch 4381/10000: L(Train): 0.2640116214752197; L(Test): 0.24020738899707794\n",
      "Epoch 4382/10000: L(Train): 0.24652019143104553; L(Test): 0.24137097597122192\n",
      "Epoch 4383/10000: L(Train): 0.25718602538108826; L(Test): 0.2431521862745285\n",
      "Epoch 4384/10000: L(Train): 0.28061631321907043; L(Test): 0.24014410376548767\n",
      "Epoch 4385/10000: L(Train): 0.2641685903072357; L(Test): 0.2413654327392578\n",
      "Epoch 4386/10000: L(Train): 0.25699833035469055; L(Test): 0.2410878837108612\n",
      "Epoch 4387/10000: L(Train): 0.26095443964004517; L(Test): 0.24073214828968048\n",
      "Epoch 4388/10000: L(Train): 0.2523709535598755; L(Test): 0.24135686457157135\n",
      "Epoch 4389/10000: L(Train): 0.2664950489997864; L(Test): 0.24145972728729248\n",
      "Epoch 4390/10000: L(Train): 0.2564084827899933; L(Test): 0.24130378663539886\n",
      "Epoch 4391/10000: L(Train): 0.2606826424598694; L(Test): 0.23977690935134888\n",
      "Epoch 4392/10000: L(Train): 0.2523883581161499; L(Test): 0.24064774811267853\n",
      "Epoch 4393/10000: L(Train): 0.26315978169441223; L(Test): 0.24034243822097778\n",
      "Epoch 4394/10000: L(Train): 0.2589433789253235; L(Test): 0.2401471883058548\n",
      "Epoch 4395/10000: L(Train): 0.257627010345459; L(Test): 0.24094398319721222\n",
      "Epoch 4396/10000: L(Train): 0.25907379388809204; L(Test): 0.24002185463905334\n",
      "Epoch 4397/10000: L(Train): 0.25072869658470154; L(Test): 0.23928813636302948\n",
      "Epoch 4398/10000: L(Train): 0.2605884373188019; L(Test): 0.2396368831396103\n",
      "Epoch 4399/10000: L(Train): 0.26778939366340637; L(Test): 0.23966601490974426\n",
      "Epoch 4400/10000: L(Train): 0.26210030913352966; L(Test): 0.23945996165275574\n",
      "Epoch 4401/10000: L(Train): 0.26655110716819763; L(Test): 0.24006080627441406\n",
      "Epoch 4402/10000: L(Train): 0.2496647983789444; L(Test): 0.24237915873527527\n",
      "Epoch 4403/10000: L(Train): 0.277823805809021; L(Test): 0.24144554138183594\n",
      "Epoch 4404/10000: L(Train): 0.2705100178718567; L(Test): 0.23948116600513458\n",
      "Epoch 4405/10000: L(Train): 0.26707154512405396; L(Test): 0.24043455719947815\n",
      "Epoch 4406/10000: L(Train): 0.26870548725128174; L(Test): 0.23967161774635315\n",
      "Epoch 4407/10000: L(Train): 0.26178672909736633; L(Test): 0.24098816514015198\n",
      "Epoch 4408/10000: L(Train): 0.25688737630844116; L(Test): 0.24143221974372864\n",
      "Epoch 4409/10000: L(Train): 0.2558786869049072; L(Test): 0.2406652569770813\n",
      "Epoch 4410/10000: L(Train): 0.2676040232181549; L(Test): 0.24075950682163239\n",
      "Epoch 4411/10000: L(Train): 0.25265005230903625; L(Test): 0.2409040480852127\n",
      "Epoch 4412/10000: L(Train): 0.2757522165775299; L(Test): 0.23994681239128113\n",
      "Epoch 4413/10000: L(Train): 0.25437915325164795; L(Test): 0.24046173691749573\n",
      "Epoch 4414/10000: L(Train): 0.2728930115699768; L(Test): 0.24160708487033844\n",
      "Epoch 4415/10000: L(Train): 0.2534145712852478; L(Test): 0.24004492163658142\n",
      "Epoch 4416/10000: L(Train): 0.26565203070640564; L(Test): 0.23995010554790497\n",
      "Epoch 4417/10000: L(Train): 0.2476348578929901; L(Test): 0.24013222754001617\n",
      "Epoch 4418/10000: L(Train): 0.25809457898139954; L(Test): 0.24259240925312042\n",
      "Epoch 4419/10000: L(Train): 0.2834443747997284; L(Test): 0.23912657797336578\n",
      "Epoch 4420/10000: L(Train): 0.24841882288455963; L(Test): 0.24274609982967377\n",
      "Epoch 4421/10000: L(Train): 0.26876696944236755; L(Test): 0.24126575887203217\n",
      "Epoch 4422/10000: L(Train): 0.2529234290122986; L(Test): 0.24086084961891174\n",
      "Epoch 4423/10000: L(Train): 0.2565873861312866; L(Test): 0.24067747592926025\n",
      "Epoch 4424/10000: L(Train): 0.26272639632225037; L(Test): 0.2389262467622757\n",
      "Epoch 4425/10000: L(Train): 0.24034088850021362; L(Test): 0.23945124447345734\n",
      "Epoch 4426/10000: L(Train): 0.2538467347621918; L(Test): 0.24008552730083466\n",
      "Epoch 4427/10000: L(Train): 0.24912504851818085; L(Test): 0.24449068307876587\n",
      "Epoch 4428/10000: L(Train): 0.26385873556137085; L(Test): 0.24322056770324707\n",
      "Epoch 4429/10000: L(Train): 0.26660463213920593; L(Test): 0.24254564940929413\n",
      "Epoch 4430/10000: L(Train): 0.26232802867889404; L(Test): 0.24368073046207428\n",
      "Epoch 4431/10000: L(Train): 0.28134453296661377; L(Test): 0.24332760274410248\n",
      "Epoch 4432/10000: L(Train): 0.2535403072834015; L(Test): 0.24428267776966095\n",
      "Epoch 4433/10000: L(Train): 0.269940048456192; L(Test): 0.24218790233135223\n",
      "Epoch 4434/10000: L(Train): 0.2521206736564636; L(Test): 0.24333900213241577\n",
      "Epoch 4435/10000: L(Train): 0.26468345522880554; L(Test): 0.2423723191022873\n",
      "Epoch 4436/10000: L(Train): 0.2637171447277069; L(Test): 0.24223467707633972\n",
      "Epoch 4437/10000: L(Train): 0.25546109676361084; L(Test): 0.24309514462947845\n",
      "Epoch 4438/10000: L(Train): 0.2526784837245941; L(Test): 0.24207302927970886\n",
      "Epoch 4439/10000: L(Train): 0.27501657605171204; L(Test): 0.24192754924297333\n",
      "Epoch 4440/10000: L(Train): 0.2465990036725998; L(Test): 0.2419130653142929\n",
      "Epoch 4441/10000: L(Train): 0.2662990987300873; L(Test): 0.24125012755393982\n",
      "Epoch 4442/10000: L(Train): 0.27037909626960754; L(Test): 0.24269428849220276\n",
      "Epoch 4443/10000: L(Train): 0.2583143711090088; L(Test): 0.24153950810432434\n",
      "Epoch 4444/10000: L(Train): 0.2609277367591858; L(Test): 0.24097058176994324\n",
      "Epoch 4445/10000: L(Train): 0.26140502095222473; L(Test): 0.24226893484592438\n",
      "Epoch 4446/10000: L(Train): 0.2632142901420593; L(Test): 0.24102097749710083\n",
      "Epoch 4447/10000: L(Train): 0.25223156809806824; L(Test): 0.24175818264484406\n",
      "Epoch 4448/10000: L(Train): 0.26430240273475647; L(Test): 0.24316562712192535\n",
      "Epoch 4449/10000: L(Train): 0.26151007413864136; L(Test): 0.240766704082489\n",
      "Epoch 4450/10000: L(Train): 0.25725650787353516; L(Test): 0.24132753908634186\n",
      "Epoch 4451/10000: L(Train): 0.2583685517311096; L(Test): 0.2436799705028534\n",
      "Epoch 4452/10000: L(Train): 0.2708774507045746; L(Test): 0.24305102229118347\n",
      "Epoch 4453/10000: L(Train): 0.2809056043624878; L(Test): 0.241696298122406\n",
      "Epoch 4454/10000: L(Train): 0.26887795329093933; L(Test): 0.24199233949184418\n",
      "Epoch 4455/10000: L(Train): 0.2524808943271637; L(Test): 0.24250896275043488\n",
      "Epoch 4456/10000: L(Train): 0.26557934284210205; L(Test): 0.24242639541625977\n",
      "Epoch 4457/10000: L(Train): 0.25847238302230835; L(Test): 0.24253758788108826\n",
      "Epoch 4458/10000: L(Train): 0.26972243189811707; L(Test): 0.24265466630458832\n",
      "Epoch 4459/10000: L(Train): 0.2508770525455475; L(Test): 0.24220100045204163\n",
      "Epoch 4460/10000: L(Train): 0.2731618583202362; L(Test): 0.24330812692642212\n",
      "Epoch 4461/10000: L(Train): 0.2563125193119049; L(Test): 0.24081769585609436\n",
      "Epoch 4462/10000: L(Train): 0.2639738917350769; L(Test): 0.24202221632003784\n",
      "Epoch 4463/10000: L(Train): 0.27238568663597107; L(Test): 0.24090948700904846\n",
      "Epoch 4464/10000: L(Train): 0.26800552010536194; L(Test): 0.24097619950771332\n",
      "Epoch 4465/10000: L(Train): 0.2690158188343048; L(Test): 0.24132823944091797\n",
      "Epoch 4466/10000: L(Train): 0.2769569158554077; L(Test): 0.24124997854232788\n",
      "Epoch 4467/10000: L(Train): 0.25929853320121765; L(Test): 0.24145600199699402\n",
      "Epoch 4468/10000: L(Train): 0.25707876682281494; L(Test): 0.24102900922298431\n",
      "Epoch 4469/10000: L(Train): 0.25336766242980957; L(Test): 0.24131256341934204\n",
      "Epoch 4470/10000: L(Train): 0.2628433406352997; L(Test): 0.24132385849952698\n",
      "Epoch 4471/10000: L(Train): 0.26550883054733276; L(Test): 0.24096812307834625\n",
      "Epoch 4472/10000: L(Train): 0.26611149311065674; L(Test): 0.24337369203567505\n",
      "Epoch 4473/10000: L(Train): 0.27076566219329834; L(Test): 0.24187582731246948\n",
      "Epoch 4474/10000: L(Train): 0.27746573090553284; L(Test): 0.24110156297683716\n",
      "Epoch 4475/10000: L(Train): 0.26094216108322144; L(Test): 0.2417011857032776\n",
      "Epoch 4476/10000: L(Train): 0.24931833148002625; L(Test): 0.24138475954532623\n",
      "Epoch 4477/10000: L(Train): 0.27281653881073; L(Test): 0.24264515936374664\n",
      "Epoch 4478/10000: L(Train): 0.2515918016433716; L(Test): 0.24188770353794098\n",
      "Epoch 4479/10000: L(Train): 0.26165834069252014; L(Test): 0.2405901402235031\n",
      "Epoch 4480/10000: L(Train): 0.26611217856407166; L(Test): 0.24016161262989044\n",
      "Epoch 4481/10000: L(Train): 0.2519756853580475; L(Test): 0.24123166501522064\n",
      "Epoch 4482/10000: L(Train): 0.2648296356201172; L(Test): 0.24148999154567719\n",
      "Epoch 4483/10000: L(Train): 0.2601877450942993; L(Test): 0.24010460078716278\n",
      "Epoch 4484/10000: L(Train): 0.27222639322280884; L(Test): 0.24124546349048615\n",
      "Epoch 4485/10000: L(Train): 0.2532556354999542; L(Test): 0.24058906733989716\n",
      "Epoch 4486/10000: L(Train): 0.26722779870033264; L(Test): 0.24029824137687683\n",
      "Epoch 4487/10000: L(Train): 0.24727647006511688; L(Test): 0.23996160924434662\n",
      "Epoch 4488/10000: L(Train): 0.2559002935886383; L(Test): 0.24035920202732086\n",
      "Epoch 4489/10000: L(Train): 0.2493898868560791; L(Test): 0.24110116064548492\n",
      "Epoch 4490/10000: L(Train): 0.25151941180229187; L(Test): 0.24138778448104858\n",
      "Epoch 4491/10000: L(Train): 0.27233707904815674; L(Test): 0.2403975874185562\n",
      "Epoch 4492/10000: L(Train): 0.26881319284439087; L(Test): 0.2415761947631836\n",
      "Epoch 4493/10000: L(Train): 0.26467645168304443; L(Test): 0.24047251045703888\n",
      "Epoch 4494/10000: L(Train): 0.2612071633338928; L(Test): 0.24208033084869385\n",
      "Epoch 4495/10000: L(Train): 0.25386470556259155; L(Test): 0.24451890587806702\n",
      "Epoch 4496/10000: L(Train): 0.2621236741542816; L(Test): 0.24094052612781525\n",
      "Epoch 4497/10000: L(Train): 0.25386810302734375; L(Test): 0.24063175916671753\n",
      "Epoch 4498/10000: L(Train): 0.24990014731884003; L(Test): 0.24112778902053833\n",
      "Epoch 4499/10000: L(Train): 0.26635435223579407; L(Test): 0.24315927922725677\n",
      "Epoch 4500/10000: L(Train): 0.2637895345687866; L(Test): 0.24275203049182892\n",
      "Epoch 4501/10000: L(Train): 0.25257882475852966; L(Test): 0.24185575544834137\n",
      "Epoch 4502/10000: L(Train): 0.2678162455558777; L(Test): 0.24496322870254517\n",
      "Epoch 4503/10000: L(Train): 0.25704053044319153; L(Test): 0.24247227609157562\n",
      "Epoch 4504/10000: L(Train): 0.26496464014053345; L(Test): 0.24292664229869843\n",
      "Epoch 4505/10000: L(Train): 0.2708812952041626; L(Test): 0.24198004603385925\n",
      "Epoch 4506/10000: L(Train): 0.2659895718097687; L(Test): 0.24137216806411743\n",
      "Epoch 4507/10000: L(Train): 0.2712700664997101; L(Test): 0.24088932573795319\n",
      "Epoch 4508/10000: L(Train): 0.26822102069854736; L(Test): 0.24119187891483307\n",
      "Epoch 4509/10000: L(Train): 0.27234160900115967; L(Test): 0.24091696739196777\n",
      "Epoch 4510/10000: L(Train): 0.2707561254501343; L(Test): 0.24011436104774475\n",
      "Epoch 4511/10000: L(Train): 0.27561378479003906; L(Test): 0.242050439119339\n",
      "Epoch 4512/10000: L(Train): 0.25133755803108215; L(Test): 0.24049508571624756\n",
      "Epoch 4513/10000: L(Train): 0.24483157694339752; L(Test): 0.24408932030200958\n",
      "Epoch 4514/10000: L(Train): 0.2615693211555481; L(Test): 0.24215863645076752\n",
      "Epoch 4515/10000: L(Train): 0.25568196177482605; L(Test): 0.23929283022880554\n",
      "Epoch 4516/10000: L(Train): 0.2714487910270691; L(Test): 0.24064697325229645\n",
      "Epoch 4517/10000: L(Train): 0.26795125007629395; L(Test): 0.24142155051231384\n",
      "Epoch 4518/10000: L(Train): 0.2696734666824341; L(Test): 0.24128438532352448\n",
      "Epoch 4519/10000: L(Train): 0.26088598370552063; L(Test): 0.2413940578699112\n",
      "Epoch 4520/10000: L(Train): 0.2526235282421112; L(Test): 0.24120113253593445\n",
      "Epoch 4521/10000: L(Train): 0.2637123763561249; L(Test): 0.24079196155071259\n",
      "Epoch 4522/10000: L(Train): 0.26605796813964844; L(Test): 0.24269631505012512\n",
      "Epoch 4523/10000: L(Train): 0.2629316449165344; L(Test): 0.2432021200656891\n",
      "Epoch 4524/10000: L(Train): 0.2661922872066498; L(Test): 0.24053573608398438\n",
      "Epoch 4525/10000: L(Train): 0.2681094706058502; L(Test): 0.24022594094276428\n",
      "Epoch 4526/10000: L(Train): 0.28218144178390503; L(Test): 0.2405034452676773\n",
      "Epoch 4527/10000: L(Train): 0.2543632686138153; L(Test): 0.24158747494220734\n",
      "Epoch 4528/10000: L(Train): 0.2549114227294922; L(Test): 0.2429640144109726\n",
      "Epoch 4529/10000: L(Train): 0.26153555512428284; L(Test): 0.23967306315898895\n",
      "Epoch 4530/10000: L(Train): 0.25956496596336365; L(Test): 0.24136999249458313\n",
      "Epoch 4531/10000: L(Train): 0.26671287417411804; L(Test): 0.24100035429000854\n",
      "Epoch 4532/10000: L(Train): 0.255818247795105; L(Test): 0.24107341468334198\n",
      "Epoch 4533/10000: L(Train): 0.25291675329208374; L(Test): 0.24115319550037384\n",
      "Epoch 4534/10000: L(Train): 0.269894003868103; L(Test): 0.23992665112018585\n",
      "Epoch 4535/10000: L(Train): 0.2559266686439514; L(Test): 0.23974137008190155\n",
      "Epoch 4536/10000: L(Train): 0.2731590270996094; L(Test): 0.2393687516450882\n",
      "Epoch 4537/10000: L(Train): 0.25771191716194153; L(Test): 0.2404528260231018\n",
      "Epoch 4538/10000: L(Train): 0.2677232623100281; L(Test): 0.24032801389694214\n",
      "Epoch 4539/10000: L(Train): 0.2658322751522064; L(Test): 0.23930172622203827\n",
      "Epoch 4540/10000: L(Train): 0.25098761916160583; L(Test): 0.23874549567699432\n",
      "Epoch 4541/10000: L(Train): 0.25426214933395386; L(Test): 0.23975493013858795\n",
      "Epoch 4542/10000: L(Train): 0.2617412209510803; L(Test): 0.2400982528924942\n",
      "Epoch 4543/10000: L(Train): 0.2751144468784332; L(Test): 0.2397235780954361\n",
      "Epoch 4544/10000: L(Train): 0.27323445677757263; L(Test): 0.24071666598320007\n",
      "Epoch 4545/10000: L(Train): 0.25358352065086365; L(Test): 0.2405056655406952\n",
      "Epoch 4546/10000: L(Train): 0.2693147659301758; L(Test): 0.24087516963481903\n",
      "Epoch 4547/10000: L(Train): 0.2670336067676544; L(Test): 0.24166232347488403\n",
      "Epoch 4548/10000: L(Train): 0.2553376853466034; L(Test): 0.24223670363426208\n",
      "Epoch 4549/10000: L(Train): 0.2537788450717926; L(Test): 0.24247701466083527\n",
      "Epoch 4550/10000: L(Train): 0.2618348002433777; L(Test): 0.24264100193977356\n",
      "Epoch 4551/10000: L(Train): 0.25467780232429504; L(Test): 0.24252000451087952\n",
      "Epoch 4552/10000: L(Train): 0.26916685700416565; L(Test): 0.24025927484035492\n",
      "Epoch 4553/10000: L(Train): 0.25913548469543457; L(Test): 0.2398788183927536\n",
      "Epoch 4554/10000: L(Train): 0.2611755132675171; L(Test): 0.24049361050128937\n",
      "Epoch 4555/10000: L(Train): 0.26255035400390625; L(Test): 0.24161134660243988\n",
      "Epoch 4556/10000: L(Train): 0.2751930356025696; L(Test): 0.24063724279403687\n",
      "Epoch 4557/10000: L(Train): 0.2631599009037018; L(Test): 0.24017706513404846\n",
      "Epoch 4558/10000: L(Train): 0.2526390850543976; L(Test): 0.2407996654510498\n",
      "Epoch 4559/10000: L(Train): 0.25819289684295654; L(Test): 0.240139439702034\n",
      "Epoch 4560/10000: L(Train): 0.2627381682395935; L(Test): 0.24018998444080353\n",
      "Epoch 4561/10000: L(Train): 0.26892220973968506; L(Test): 0.23982205986976624\n",
      "Epoch 4562/10000: L(Train): 0.26679620146751404; L(Test): 0.24005557596683502\n",
      "Epoch 4563/10000: L(Train): 0.2595764994621277; L(Test): 0.24046708643436432\n",
      "Epoch 4564/10000: L(Train): 0.26023128628730774; L(Test): 0.24027103185653687\n",
      "Epoch 4565/10000: L(Train): 0.26144498586654663; L(Test): 0.24104711413383484\n",
      "Epoch 4566/10000: L(Train): 0.26373299956321716; L(Test): 0.24082216620445251\n",
      "Epoch 4567/10000: L(Train): 0.2579770088195801; L(Test): 0.2401581108570099\n",
      "Epoch 4568/10000: L(Train): 0.25632280111312866; L(Test): 0.24019092321395874\n",
      "Epoch 4569/10000: L(Train): 0.25282618403434753; L(Test): 0.23983989655971527\n",
      "Epoch 4570/10000: L(Train): 0.2637743651866913; L(Test): 0.23880062997341156\n",
      "Epoch 4571/10000: L(Train): 0.2638149857521057; L(Test): 0.23839008808135986\n",
      "Epoch 4572/10000: L(Train): 0.27820348739624023; L(Test): 0.23871491849422455\n",
      "Epoch 4573/10000: L(Train): 0.2502094805240631; L(Test): 0.23927174508571625\n",
      "Epoch 4574/10000: L(Train): 0.25716063380241394; L(Test): 0.2390630543231964\n",
      "Epoch 4575/10000: L(Train): 0.27815112471580505; L(Test): 0.2395656406879425\n",
      "Epoch 4576/10000: L(Train): 0.260372132062912; L(Test): 0.2389761060476303\n",
      "Epoch 4577/10000: L(Train): 0.2734507918357849; L(Test): 0.23952798545360565\n",
      "Epoch 4578/10000: L(Train): 0.2609584927558899; L(Test): 0.23885992169380188\n",
      "Epoch 4579/10000: L(Train): 0.2713366150856018; L(Test): 0.23906756937503815\n",
      "Epoch 4580/10000: L(Train): 0.2689322829246521; L(Test): 0.23937584459781647\n",
      "Epoch 4581/10000: L(Train): 0.2651042640209198; L(Test): 0.23907694220542908\n",
      "Epoch 4582/10000: L(Train): 0.25207972526550293; L(Test): 0.23918484151363373\n",
      "Epoch 4583/10000: L(Train): 0.2530212104320526; L(Test): 0.2382863163948059\n",
      "Epoch 4584/10000: L(Train): 0.27080094814300537; L(Test): 0.2393610030412674\n",
      "Epoch 4585/10000: L(Train): 0.2741239368915558; L(Test): 0.23894630372524261\n",
      "Epoch 4586/10000: L(Train): 0.2518013119697571; L(Test): 0.23730450868606567\n",
      "Epoch 4587/10000: L(Train): 0.26516595482826233; L(Test): 0.23808553814888\n",
      "Epoch 4588/10000: L(Train): 0.26714345812797546; L(Test): 0.23761728405952454\n",
      "Epoch 4589/10000: L(Train): 0.26466745138168335; L(Test): 0.23798918724060059\n",
      "Epoch 4590/10000: L(Train): 0.2748146057128906; L(Test): 0.23850420117378235\n",
      "Epoch 4591/10000: L(Train): 0.27113577723503113; L(Test): 0.23848548531532288\n",
      "Epoch 4592/10000: L(Train): 0.2613986134529114; L(Test): 0.2386496365070343\n",
      "Epoch 4593/10000: L(Train): 0.26590803265571594; L(Test): 0.2384214848279953\n",
      "Epoch 4594/10000: L(Train): 0.2617502212524414; L(Test): 0.2380479872226715\n",
      "Epoch 4595/10000: L(Train): 0.2542760968208313; L(Test): 0.23922546207904816\n",
      "Epoch 4596/10000: L(Train): 0.2588145434856415; L(Test): 0.2385202944278717\n",
      "Epoch 4597/10000: L(Train): 0.26584258675575256; L(Test): 0.23795735836029053\n",
      "Epoch 4598/10000: L(Train): 0.24229103326797485; L(Test): 0.23886321485042572\n",
      "Epoch 4599/10000: L(Train): 0.26179271936416626; L(Test): 0.23931770026683807\n",
      "Epoch 4600/10000: L(Train): 0.26295706629753113; L(Test): 0.23890529572963715\n",
      "Epoch 4601/10000: L(Train): 0.2513234317302704; L(Test): 0.23833511769771576\n",
      "Epoch 4602/10000: L(Train): 0.25631147623062134; L(Test): 0.2388823926448822\n",
      "Epoch 4603/10000: L(Train): 0.2783994674682617; L(Test): 0.2388409674167633\n",
      "Epoch 4604/10000: L(Train): 0.26551032066345215; L(Test): 0.23863865435123444\n",
      "Epoch 4605/10000: L(Train): 0.2549925148487091; L(Test): 0.23886987566947937\n",
      "Epoch 4606/10000: L(Train): 0.269064337015152; L(Test): 0.2403557300567627\n",
      "Epoch 4607/10000: L(Train): 0.26075735688209534; L(Test): 0.2391505390405655\n",
      "Epoch 4608/10000: L(Train): 0.26229432225227356; L(Test): 0.23983602225780487\n",
      "Epoch 4609/10000: L(Train): 0.2618572413921356; L(Test): 0.23899634182453156\n",
      "Epoch 4610/10000: L(Train): 0.25229451060295105; L(Test): 0.23929335176944733\n",
      "Epoch 4611/10000: L(Train): 0.2641419768333435; L(Test): 0.2392866462469101\n",
      "Epoch 4612/10000: L(Train): 0.27175918221473694; L(Test): 0.2387027144432068\n",
      "Epoch 4613/10000: L(Train): 0.2705335319042206; L(Test): 0.23910513520240784\n",
      "Epoch 4614/10000: L(Train): 0.25798240303993225; L(Test): 0.24281227588653564\n",
      "Epoch 4615/10000: L(Train): 0.2628498375415802; L(Test): 0.2412770390510559\n",
      "Epoch 4616/10000: L(Train): 0.2513136863708496; L(Test): 0.24038149416446686\n",
      "Epoch 4617/10000: L(Train): 0.2622116208076477; L(Test): 0.2407730370759964\n",
      "Epoch 4618/10000: L(Train): 0.2567000985145569; L(Test): 0.23930831253528595\n",
      "Epoch 4619/10000: L(Train): 0.2582852244377136; L(Test): 0.2385806441307068\n",
      "Epoch 4620/10000: L(Train): 0.24791420996189117; L(Test): 0.2403930276632309\n",
      "Epoch 4621/10000: L(Train): 0.25153085589408875; L(Test): 0.24166558682918549\n",
      "Epoch 4622/10000: L(Train): 0.2601679563522339; L(Test): 0.23914434015750885\n",
      "Epoch 4623/10000: L(Train): 0.27680978178977966; L(Test): 0.23938007652759552\n",
      "Epoch 4624/10000: L(Train): 0.2515207529067993; L(Test): 0.24065560102462769\n",
      "Epoch 4625/10000: L(Train): 0.2646116018295288; L(Test): 0.23891308903694153\n",
      "Epoch 4626/10000: L(Train): 0.27083897590637207; L(Test): 0.239461287856102\n",
      "Epoch 4627/10000: L(Train): 0.2644549608230591; L(Test): 0.23927341401576996\n",
      "Epoch 4628/10000: L(Train): 0.2698681652545929; L(Test): 0.2391400784254074\n",
      "Epoch 4629/10000: L(Train): 0.26528531312942505; L(Test): 0.23842105269432068\n",
      "Epoch 4630/10000: L(Train): 0.2527463734149933; L(Test): 0.24066518247127533\n",
      "Epoch 4631/10000: L(Train): 0.26004862785339355; L(Test): 0.24008327722549438\n",
      "Epoch 4632/10000: L(Train): 0.27124255895614624; L(Test): 0.24147376418113708\n",
      "Epoch 4633/10000: L(Train): 0.27458199858665466; L(Test): 0.23904727399349213\n",
      "Epoch 4634/10000: L(Train): 0.25417646765708923; L(Test): 0.24151217937469482\n",
      "Epoch 4635/10000: L(Train): 0.260964572429657; L(Test): 0.2402265965938568\n",
      "Epoch 4636/10000: L(Train): 0.2634983956813812; L(Test): 0.23929761350154877\n",
      "Epoch 4637/10000: L(Train): 0.2595647871494293; L(Test): 0.24022206664085388\n",
      "Epoch 4638/10000: L(Train): 0.2673182487487793; L(Test): 0.24118365347385406\n",
      "Epoch 4639/10000: L(Train): 0.2575056850910187; L(Test): 0.24116502702236176\n",
      "Epoch 4640/10000: L(Train): 0.24150113761425018; L(Test): 0.23966720700263977\n",
      "Epoch 4641/10000: L(Train): 0.26477089524269104; L(Test): 0.23909804224967957\n",
      "Epoch 4642/10000: L(Train): 0.2637106776237488; L(Test): 0.23865532875061035\n",
      "Epoch 4643/10000: L(Train): 0.26028990745544434; L(Test): 0.23985213041305542\n",
      "Epoch 4644/10000: L(Train): 0.2662140727043152; L(Test): 0.2417784035205841\n",
      "Epoch 4645/10000: L(Train): 0.26046741008758545; L(Test): 0.24033036828041077\n",
      "Epoch 4646/10000: L(Train): 0.26304441690444946; L(Test): 0.2409108430147171\n",
      "Epoch 4647/10000: L(Train): 0.2677014172077179; L(Test): 0.23908421397209167\n",
      "Epoch 4648/10000: L(Train): 0.2551400363445282; L(Test): 0.24050207436084747\n",
      "Epoch 4649/10000: L(Train): 0.2629139721393585; L(Test): 0.23963655531406403\n",
      "Epoch 4650/10000: L(Train): 0.2646903395652771; L(Test): 0.238734170794487\n",
      "Epoch 4651/10000: L(Train): 0.25222665071487427; L(Test): 0.23934081196784973\n",
      "Epoch 4652/10000: L(Train): 0.27236539125442505; L(Test): 0.2392696887254715\n",
      "Epoch 4653/10000: L(Train): 0.2645782232284546; L(Test): 0.24057133495807648\n",
      "Epoch 4654/10000: L(Train): 0.26366621255874634; L(Test): 0.24000422656536102\n",
      "Epoch 4655/10000: L(Train): 0.2599419951438904; L(Test): 0.2391042858362198\n",
      "Epoch 4656/10000: L(Train): 0.2716754376888275; L(Test): 0.23959773778915405\n",
      "Epoch 4657/10000: L(Train): 0.2569662630558014; L(Test): 0.23999108374118805\n",
      "Epoch 4658/10000: L(Train): 0.269571453332901; L(Test): 0.241012841463089\n",
      "Epoch 4659/10000: L(Train): 0.26026082038879395; L(Test): 0.2417156994342804\n",
      "Epoch 4660/10000: L(Train): 0.25871363282203674; L(Test): 0.24035243690013885\n",
      "Epoch 4661/10000: L(Train): 0.2604405879974365; L(Test): 0.24049338698387146\n",
      "Epoch 4662/10000: L(Train): 0.2536848783493042; L(Test): 0.24002426862716675\n",
      "Epoch 4663/10000: L(Train): 0.25343647599220276; L(Test): 0.23988565802574158\n",
      "Epoch 4664/10000: L(Train): 0.26461726427078247; L(Test): 0.24034184217453003\n",
      "Epoch 4665/10000: L(Train): 0.2559368908405304; L(Test): 0.23921465873718262\n",
      "Epoch 4666/10000: L(Train): 0.26397469639778137; L(Test): 0.23946812748908997\n",
      "Epoch 4667/10000: L(Train): 0.2730749547481537; L(Test): 0.23969201743602753\n",
      "Epoch 4668/10000: L(Train): 0.25331512093544006; L(Test): 0.23927146196365356\n",
      "Epoch 4669/10000: L(Train): 0.2516047954559326; L(Test): 0.23984265327453613\n",
      "Epoch 4670/10000: L(Train): 0.2505849599838257; L(Test): 0.24057653546333313\n",
      "Epoch 4671/10000: L(Train): 0.27326685190200806; L(Test): 0.2391129732131958\n",
      "Epoch 4672/10000: L(Train): 0.24981169402599335; L(Test): 0.2409091591835022\n",
      "Epoch 4673/10000: L(Train): 0.2702872157096863; L(Test): 0.24377095699310303\n",
      "Epoch 4674/10000: L(Train): 0.26087793707847595; L(Test): 0.24108462035655975\n",
      "Epoch 4675/10000: L(Train): 0.25827690958976746; L(Test): 0.2395099252462387\n",
      "Epoch 4676/10000: L(Train): 0.2559008002281189; L(Test): 0.24016359448432922\n",
      "Epoch 4677/10000: L(Train): 0.25152596831321716; L(Test): 0.23926161229610443\n",
      "Epoch 4678/10000: L(Train): 0.26659905910491943; L(Test): 0.23884575068950653\n",
      "Epoch 4679/10000: L(Train): 0.2538706362247467; L(Test): 0.2393452227115631\n",
      "Epoch 4680/10000: L(Train): 0.2626447081565857; L(Test): 0.2401413470506668\n",
      "Epoch 4681/10000: L(Train): 0.25413888692855835; L(Test): 0.23953095078468323\n",
      "Epoch 4682/10000: L(Train): 0.24741223454475403; L(Test): 0.23916040360927582\n",
      "Epoch 4683/10000: L(Train): 0.2619646489620209; L(Test): 0.24000860750675201\n",
      "Epoch 4684/10000: L(Train): 0.2763088047504425; L(Test): 0.23875471949577332\n",
      "Epoch 4685/10000: L(Train): 0.26980671286582947; L(Test): 0.23908492922782898\n",
      "Epoch 4686/10000: L(Train): 0.25121426582336426; L(Test): 0.23955927789211273\n",
      "Epoch 4687/10000: L(Train): 0.2752184271812439; L(Test): 0.23960258066654205\n",
      "Epoch 4688/10000: L(Train): 0.2594144940376282; L(Test): 0.23901793360710144\n",
      "Epoch 4689/10000: L(Train): 0.23899002373218536; L(Test): 0.23971426486968994\n",
      "Epoch 4690/10000: L(Train): 0.2685815095901489; L(Test): 0.24020445346832275\n",
      "Epoch 4691/10000: L(Train): 0.2739512622356415; L(Test): 0.2388259619474411\n",
      "Epoch 4692/10000: L(Train): 0.2548936903476715; L(Test): 0.23956398665905\n",
      "Epoch 4693/10000: L(Train): 0.266875684261322; L(Test): 0.2406429648399353\n",
      "Epoch 4694/10000: L(Train): 0.2681683599948883; L(Test): 0.2386939376592636\n",
      "Epoch 4695/10000: L(Train): 0.2452085167169571; L(Test): 0.23885290324687958\n",
      "Epoch 4696/10000: L(Train): 0.26939764618873596; L(Test): 0.24151739478111267\n",
      "Epoch 4697/10000: L(Train): 0.25125014781951904; L(Test): 0.24101606011390686\n",
      "Epoch 4698/10000: L(Train): 0.2704078257083893; L(Test): 0.23966394364833832\n",
      "Epoch 4699/10000: L(Train): 0.26110532879829407; L(Test): 0.23987767100334167\n",
      "Epoch 4700/10000: L(Train): 0.26593270897865295; L(Test): 0.24036282300949097\n",
      "Epoch 4701/10000: L(Train): 0.2495700567960739; L(Test): 0.24021752178668976\n",
      "Epoch 4702/10000: L(Train): 0.2512233257293701; L(Test): 0.24097298085689545\n",
      "Epoch 4703/10000: L(Train): 0.269697368144989; L(Test): 0.24451148509979248\n",
      "Epoch 4704/10000: L(Train): 0.2532058358192444; L(Test): 0.24401387572288513\n",
      "Epoch 4705/10000: L(Train): 0.26944541931152344; L(Test): 0.24183353781700134\n",
      "Epoch 4706/10000: L(Train): 0.24568584561347961; L(Test): 0.24358278512954712\n",
      "Epoch 4707/10000: L(Train): 0.26081612706184387; L(Test): 0.24290700256824493\n",
      "Epoch 4708/10000: L(Train): 0.26532265543937683; L(Test): 0.24174785614013672\n",
      "Epoch 4709/10000: L(Train): 0.25948721170425415; L(Test): 0.24134604632854462\n",
      "Epoch 4710/10000: L(Train): 0.26225170493125916; L(Test): 0.24322111904621124\n",
      "Epoch 4711/10000: L(Train): 0.2682350277900696; L(Test): 0.24261268973350525\n",
      "Epoch 4712/10000: L(Train): 0.2773216664791107; L(Test): 0.24064773321151733\n",
      "Epoch 4713/10000: L(Train): 0.2521114647388458; L(Test): 0.24067021906375885\n",
      "Epoch 4714/10000: L(Train): 0.25456923246383667; L(Test): 0.24101947247982025\n",
      "Epoch 4715/10000: L(Train): 0.2662765085697174; L(Test): 0.24070024490356445\n",
      "Epoch 4716/10000: L(Train): 0.26060009002685547; L(Test): 0.24063529074192047\n",
      "Epoch 4717/10000: L(Train): 0.26227885484695435; L(Test): 0.23977531492710114\n",
      "Epoch 4718/10000: L(Train): 0.24593192338943481; L(Test): 0.2409495711326599\n",
      "Epoch 4719/10000: L(Train): 0.2689160108566284; L(Test): 0.24216072261333466\n",
      "Epoch 4720/10000: L(Train): 0.25484466552734375; L(Test): 0.24063421785831451\n",
      "Epoch 4721/10000: L(Train): 0.2697305679321289; L(Test): 0.24135474860668182\n",
      "Epoch 4722/10000: L(Train): 0.2551487982273102; L(Test): 0.24123987555503845\n",
      "Epoch 4723/10000: L(Train): 0.2621830999851227; L(Test): 0.23991957306861877\n",
      "Epoch 4724/10000: L(Train): 0.26963186264038086; L(Test): 0.24022157490253448\n",
      "Epoch 4725/10000: L(Train): 0.24336621165275574; L(Test): 0.2407613843679428\n",
      "Epoch 4726/10000: L(Train): 0.2747974097728729; L(Test): 0.23974162340164185\n",
      "Epoch 4727/10000: L(Train): 0.25907406210899353; L(Test): 0.23905779421329498\n",
      "Epoch 4728/10000: L(Train): 0.26564112305641174; L(Test): 0.23987950384616852\n",
      "Epoch 4729/10000: L(Train): 0.25784066319465637; L(Test): 0.2411699742078781\n",
      "Epoch 4730/10000: L(Train): 0.25497278571128845; L(Test): 0.23962196707725525\n",
      "Epoch 4731/10000: L(Train): 0.25360649824142456; L(Test): 0.23913034796714783\n",
      "Epoch 4732/10000: L(Train): 0.2566855251789093; L(Test): 0.23897922039031982\n",
      "Epoch 4733/10000: L(Train): 0.27126193046569824; L(Test): 0.23830020427703857\n",
      "Epoch 4734/10000: L(Train): 0.2604486644268036; L(Test): 0.23832449316978455\n",
      "Epoch 4735/10000: L(Train): 0.27097049355506897; L(Test): 0.23863749206066132\n",
      "Epoch 4736/10000: L(Train): 0.2680654227733612; L(Test): 0.23936393857002258\n",
      "Epoch 4737/10000: L(Train): 0.26983726024627686; L(Test): 0.23942790925502777\n",
      "Epoch 4738/10000: L(Train): 0.27253642678260803; L(Test): 0.23889052867889404\n",
      "Epoch 4739/10000: L(Train): 0.2772938311100006; L(Test): 0.2388816475868225\n",
      "Epoch 4740/10000: L(Train): 0.2637581527233124; L(Test): 0.2397371083498001\n",
      "Epoch 4741/10000: L(Train): 0.25736361742019653; L(Test): 0.2384936660528183\n",
      "Epoch 4742/10000: L(Train): 0.2626391649246216; L(Test): 0.2397943139076233\n",
      "Epoch 4743/10000: L(Train): 0.2503483295440674; L(Test): 0.23951025307178497\n",
      "Epoch 4744/10000: L(Train): 0.25547128915786743; L(Test): 0.23724646866321564\n",
      "Epoch 4745/10000: L(Train): 0.2603805363178253; L(Test): 0.23800316452980042\n",
      "Epoch 4746/10000: L(Train): 0.2574020028114319; L(Test): 0.23908750712871552\n",
      "Epoch 4747/10000: L(Train): 0.2624059021472931; L(Test): 0.23827004432678223\n",
      "Epoch 4748/10000: L(Train): 0.2578253746032715; L(Test): 0.23863926529884338\n",
      "Epoch 4749/10000: L(Train): 0.25964558124542236; L(Test): 0.2383408099412918\n",
      "Epoch 4750/10000: L(Train): 0.2535254955291748; L(Test): 0.2374046891927719\n",
      "Epoch 4751/10000: L(Train): 0.24905015528202057; L(Test): 0.2386319488286972\n",
      "Epoch 4752/10000: L(Train): 0.26102784276008606; L(Test): 0.23873673379421234\n",
      "Epoch 4753/10000: L(Train): 0.2584640681743622; L(Test): 0.2375844120979309\n",
      "Epoch 4754/10000: L(Train): 0.2579953670501709; L(Test): 0.23855362832546234\n",
      "Epoch 4755/10000: L(Train): 0.24481289088726044; L(Test): 0.23853719234466553\n",
      "Epoch 4756/10000: L(Train): 0.2596081495285034; L(Test): 0.23776976764202118\n",
      "Epoch 4757/10000: L(Train): 0.26249566674232483; L(Test): 0.23718687891960144\n",
      "Epoch 4758/10000: L(Train): 0.25691884756088257; L(Test): 0.23799629509449005\n",
      "Epoch 4759/10000: L(Train): 0.2502143979072571; L(Test): 0.23673461377620697\n",
      "Epoch 4760/10000: L(Train): 0.26321887969970703; L(Test): 0.2386378049850464\n",
      "Epoch 4761/10000: L(Train): 0.25838711857795715; L(Test): 0.24110962450504303\n",
      "Epoch 4762/10000: L(Train): 0.26652634143829346; L(Test): 0.2382710725069046\n",
      "Epoch 4763/10000: L(Train): 0.27032241225242615; L(Test): 0.2381131947040558\n",
      "Epoch 4764/10000: L(Train): 0.267973929643631; L(Test): 0.23942150175571442\n",
      "Epoch 4765/10000: L(Train): 0.26299893856048584; L(Test): 0.23827046155929565\n",
      "Epoch 4766/10000: L(Train): 0.27055826783180237; L(Test): 0.2374906986951828\n",
      "Epoch 4767/10000: L(Train): 0.2599041759967804; L(Test): 0.239435613155365\n",
      "Epoch 4768/10000: L(Train): 0.26398152112960815; L(Test): 0.23918519914150238\n",
      "Epoch 4769/10000: L(Train): 0.25403082370758057; L(Test): 0.23968742787837982\n",
      "Epoch 4770/10000: L(Train): 0.2712481617927551; L(Test): 0.24292849004268646\n",
      "Epoch 4771/10000: L(Train): 0.25032877922058105; L(Test): 0.2402101755142212\n",
      "Epoch 4772/10000: L(Train): 0.27176007628440857; L(Test): 0.2410014122724533\n",
      "Epoch 4773/10000: L(Train): 0.2704126834869385; L(Test): 0.24222266674041748\n",
      "Epoch 4774/10000: L(Train): 0.24860110878944397; L(Test): 0.2410023808479309\n",
      "Epoch 4775/10000: L(Train): 0.2657563090324402; L(Test): 0.2385687530040741\n",
      "Epoch 4776/10000: L(Train): 0.2640751004219055; L(Test): 0.23984220623970032\n",
      "Epoch 4777/10000: L(Train): 0.258110910654068; L(Test): 0.2411811649799347\n",
      "Epoch 4778/10000: L(Train): 0.2714633345603943; L(Test): 0.2403382509946823\n",
      "Epoch 4779/10000: L(Train): 0.2527469992637634; L(Test): 0.24193520843982697\n",
      "Epoch 4780/10000: L(Train): 0.27826040983200073; L(Test): 0.24085433781147003\n",
      "Epoch 4781/10000: L(Train): 0.2590872049331665; L(Test): 0.23906971514225006\n",
      "Epoch 4782/10000: L(Train): 0.2706860303878784; L(Test): 0.24242869019508362\n",
      "Epoch 4783/10000: L(Train): 0.25765326619148254; L(Test): 0.242090106010437\n",
      "Epoch 4784/10000: L(Train): 0.26292237639427185; L(Test): 0.2398270219564438\n",
      "Epoch 4785/10000: L(Train): 0.25309187173843384; L(Test): 0.24236641824245453\n",
      "Epoch 4786/10000: L(Train): 0.26653745770454407; L(Test): 0.24269750714302063\n",
      "Epoch 4787/10000: L(Train): 0.27206096053123474; L(Test): 0.24102672934532166\n",
      "Epoch 4788/10000: L(Train): 0.25237444043159485; L(Test): 0.2406206727027893\n",
      "Epoch 4789/10000: L(Train): 0.2698168456554413; L(Test): 0.24042074382305145\n",
      "Epoch 4790/10000: L(Train): 0.25409966707229614; L(Test): 0.23990046977996826\n",
      "Epoch 4791/10000: L(Train): 0.2638646066188812; L(Test): 0.2411126047372818\n",
      "Epoch 4792/10000: L(Train): 0.2554308772087097; L(Test): 0.24412181973457336\n",
      "Epoch 4793/10000: L(Train): 0.2730325162410736; L(Test): 0.24391058087348938\n",
      "Epoch 4794/10000: L(Train): 0.2640884220600128; L(Test): 0.24330133199691772\n",
      "Epoch 4795/10000: L(Train): 0.2637474536895752; L(Test): 0.24468952417373657\n",
      "Epoch 4796/10000: L(Train): 0.27283650636672974; L(Test): 0.242056205868721\n",
      "Epoch 4797/10000: L(Train): 0.2673008441925049; L(Test): 0.2432302087545395\n",
      "Epoch 4798/10000: L(Train): 0.2586052119731903; L(Test): 0.24471832811832428\n",
      "Epoch 4799/10000: L(Train): 0.2642960846424103; L(Test): 0.24290156364440918\n",
      "Epoch 4800/10000: L(Train): 0.2732272446155548; L(Test): 0.2417205572128296\n",
      "Epoch 4801/10000: L(Train): 0.25655829906463623; L(Test): 0.24255666136741638\n",
      "Epoch 4802/10000: L(Train): 0.2562040388584137; L(Test): 0.24233587086200714\n",
      "Epoch 4803/10000: L(Train): 0.2693871557712555; L(Test): 0.24141329526901245\n",
      "Epoch 4804/10000: L(Train): 0.2569126486778259; L(Test): 0.2435443252325058\n",
      "Epoch 4805/10000: L(Train): 0.2686906158924103; L(Test): 0.24468858540058136\n",
      "Epoch 4806/10000: L(Train): 0.2801908552646637; L(Test): 0.24208565056324005\n",
      "Epoch 4807/10000: L(Train): 0.26403942704200745; L(Test): 0.24261222779750824\n",
      "Epoch 4808/10000: L(Train): 0.2671862542629242; L(Test): 0.24147136509418488\n",
      "Epoch 4809/10000: L(Train): 0.2639371454715729; L(Test): 0.24072937667369843\n",
      "Epoch 4810/10000: L(Train): 0.27410492300987244; L(Test): 0.2412528693675995\n",
      "Epoch 4811/10000: L(Train): 0.24922116100788116; L(Test): 0.2432500571012497\n",
      "Epoch 4812/10000: L(Train): 0.255400687456131; L(Test): 0.24376963078975677\n",
      "Epoch 4813/10000: L(Train): 0.24567292630672455; L(Test): 0.24100272357463837\n",
      "Epoch 4814/10000: L(Train): 0.25449150800704956; L(Test): 0.23984983563423157\n",
      "Epoch 4815/10000: L(Train): 0.2776445746421814; L(Test): 0.24130257964134216\n",
      "Epoch 4816/10000: L(Train): 0.25827693939208984; L(Test): 0.24248816072940826\n",
      "Epoch 4817/10000: L(Train): 0.2706588804721832; L(Test): 0.24156391620635986\n",
      "Epoch 4818/10000: L(Train): 0.24517443776130676; L(Test): 0.2403341680765152\n",
      "Epoch 4819/10000: L(Train): 0.2513543367385864; L(Test): 0.2410552054643631\n",
      "Epoch 4820/10000: L(Train): 0.2628454864025116; L(Test): 0.24046006798744202\n",
      "Epoch 4821/10000: L(Train): 0.2773253619670868; L(Test): 0.24067874252796173\n",
      "Epoch 4822/10000: L(Train): 0.2683357000350952; L(Test): 0.2403937578201294\n",
      "Epoch 4823/10000: L(Train): 0.27050796151161194; L(Test): 0.23974314332008362\n",
      "Epoch 4824/10000: L(Train): 0.2554772198200226; L(Test): 0.24130015075206757\n",
      "Epoch 4825/10000: L(Train): 0.284411758184433; L(Test): 0.23965315520763397\n",
      "Epoch 4826/10000: L(Train): 0.2620665431022644; L(Test): 0.24019989371299744\n",
      "Epoch 4827/10000: L(Train): 0.2613033652305603; L(Test): 0.24018625915050507\n",
      "Epoch 4828/10000: L(Train): 0.25173377990722656; L(Test): 0.24049559235572815\n",
      "Epoch 4829/10000: L(Train): 0.2551134526729584; L(Test): 0.24060820043087006\n",
      "Epoch 4830/10000: L(Train): 0.25515875220298767; L(Test): 0.23954907059669495\n",
      "Epoch 4831/10000: L(Train): 0.2794714868068695; L(Test): 0.23964378237724304\n",
      "Epoch 4832/10000: L(Train): 0.2433154284954071; L(Test): 0.23964379727840424\n",
      "Epoch 4833/10000: L(Train): 0.2570475935935974; L(Test): 0.24026913940906525\n",
      "Epoch 4834/10000: L(Train): 0.2620079815387726; L(Test): 0.23965203762054443\n",
      "Epoch 4835/10000: L(Train): 0.2746415436267853; L(Test): 0.23850376904010773\n",
      "Epoch 4836/10000: L(Train): 0.2667328715324402; L(Test): 0.23909756541252136\n",
      "Epoch 4837/10000: L(Train): 0.2727046310901642; L(Test): 0.2398749589920044\n",
      "Epoch 4838/10000: L(Train): 0.24881359934806824; L(Test): 0.2399267554283142\n",
      "Epoch 4839/10000: L(Train): 0.26706087589263916; L(Test): 0.24010886251926422\n",
      "Epoch 4840/10000: L(Train): 0.2746199071407318; L(Test): 0.24016961455345154\n",
      "Epoch 4841/10000: L(Train): 0.293509304523468; L(Test): 0.23969469964504242\n",
      "Epoch 4842/10000: L(Train): 0.2614702880382538; L(Test): 0.2401338666677475\n",
      "Epoch 4843/10000: L(Train): 0.25220391154289246; L(Test): 0.24042613804340363\n",
      "Epoch 4844/10000: L(Train): 0.2551809549331665; L(Test): 0.241968035697937\n",
      "Epoch 4845/10000: L(Train): 0.2683969736099243; L(Test): 0.24081288278102875\n",
      "Epoch 4846/10000: L(Train): 0.2550128996372223; L(Test): 0.2410813271999359\n",
      "Epoch 4847/10000: L(Train): 0.2575742304325104; L(Test): 0.2414858490228653\n",
      "Epoch 4848/10000: L(Train): 0.2548232078552246; L(Test): 0.24081015586853027\n",
      "Epoch 4849/10000: L(Train): 0.26430031657218933; L(Test): 0.23985497653484344\n",
      "Epoch 4850/10000: L(Train): 0.24912527203559875; L(Test): 0.24003498256206512\n",
      "Epoch 4851/10000: L(Train): 0.26606929302215576; L(Test): 0.24055816233158112\n",
      "Epoch 4852/10000: L(Train): 0.24673844873905182; L(Test): 0.2418825328350067\n",
      "Epoch 4853/10000: L(Train): 0.2537454068660736; L(Test): 0.24023745954036713\n",
      "Epoch 4854/10000: L(Train): 0.26947081089019775; L(Test): 0.24047675728797913\n",
      "Epoch 4855/10000: L(Train): 0.2569933235645294; L(Test): 0.24157483875751495\n",
      "Epoch 4856/10000: L(Train): 0.2673772871494293; L(Test): 0.24052700400352478\n",
      "Epoch 4857/10000: L(Train): 0.25661566853523254; L(Test): 0.24097435176372528\n",
      "Epoch 4858/10000: L(Train): 0.25761353969573975; L(Test): 0.24124182760715485\n",
      "Epoch 4859/10000: L(Train): 0.26238030195236206; L(Test): 0.24386849999427795\n",
      "Epoch 4860/10000: L(Train): 0.264303058385849; L(Test): 0.24375653266906738\n",
      "Epoch 4861/10000: L(Train): 0.2563164234161377; L(Test): 0.2436726987361908\n",
      "Epoch 4862/10000: L(Train): 0.2727665603160858; L(Test): 0.24310153722763062\n",
      "Epoch 4863/10000: L(Train): 0.27087661623954773; L(Test): 0.2460654228925705\n",
      "Epoch 4864/10000: L(Train): 0.2841259241104126; L(Test): 0.24406780302524567\n",
      "Epoch 4865/10000: L(Train): 0.2689027488231659; L(Test): 0.24553942680358887\n",
      "Epoch 4866/10000: L(Train): 0.26695516705513; L(Test): 0.24633464217185974\n",
      "Epoch 4867/10000: L(Train): 0.27174240350723267; L(Test): 0.24455033242702484\n",
      "Epoch 4868/10000: L(Train): 0.26085448265075684; L(Test): 0.24613435566425323\n",
      "Epoch 4869/10000: L(Train): 0.2666022777557373; L(Test): 0.2457575649023056\n",
      "Epoch 4870/10000: L(Train): 0.2683921158313751; L(Test): 0.2449188530445099\n",
      "Epoch 4871/10000: L(Train): 0.2533814013004303; L(Test): 0.2447175234556198\n",
      "Epoch 4872/10000: L(Train): 0.27960404753685; L(Test): 0.2450944036245346\n",
      "Epoch 4873/10000: L(Train): 0.2610851228237152; L(Test): 0.24627266824245453\n",
      "Epoch 4874/10000: L(Train): 0.2775392532348633; L(Test): 0.24485096335411072\n",
      "Epoch 4875/10000: L(Train): 0.26659566164016724; L(Test): 0.24634766578674316\n",
      "Epoch 4876/10000: L(Train): 0.27464064955711365; L(Test): 0.24367830157279968\n",
      "Epoch 4877/10000: L(Train): 0.262064665555954; L(Test): 0.2441689521074295\n",
      "Epoch 4878/10000: L(Train): 0.2728593051433563; L(Test): 0.24516074359416962\n",
      "Epoch 4879/10000: L(Train): 0.2504047453403473; L(Test): 0.2443038821220398\n",
      "Epoch 4880/10000: L(Train): 0.2749638855457306; L(Test): 0.24362486600875854\n",
      "Epoch 4881/10000: L(Train): 0.25660496950149536; L(Test): 0.2455272227525711\n",
      "Epoch 4882/10000: L(Train): 0.26592546701431274; L(Test): 0.24435625970363617\n",
      "Epoch 4883/10000: L(Train): 0.2622216045856476; L(Test): 0.2433590441942215\n",
      "Epoch 4884/10000: L(Train): 0.2443356066942215; L(Test): 0.242489293217659\n",
      "Epoch 4885/10000: L(Train): 0.25734081864356995; L(Test): 0.2417585700750351\n",
      "Epoch 4886/10000: L(Train): 0.28793415427207947; L(Test): 0.2453644573688507\n",
      "Epoch 4887/10000: L(Train): 0.26477697491645813; L(Test): 0.2435387820005417\n",
      "Epoch 4888/10000: L(Train): 0.26464182138442993; L(Test): 0.24277308583259583\n",
      "Epoch 4889/10000: L(Train): 0.25499725341796875; L(Test): 0.24734358489513397\n",
      "Epoch 4890/10000: L(Train): 0.25845369696617126; L(Test): 0.24842168390750885\n",
      "Epoch 4891/10000: L(Train): 0.27132686972618103; L(Test): 0.2506171464920044\n",
      "Epoch 4892/10000: L(Train): 0.274810791015625; L(Test): 0.2545708119869232\n",
      "Epoch 4893/10000: L(Train): 0.29102370142936707; L(Test): 0.2501535713672638\n",
      "Epoch 4894/10000: L(Train): 0.2731764316558838; L(Test): 0.24852217733860016\n",
      "Epoch 4895/10000: L(Train): 0.2791776657104492; L(Test): 0.24866195023059845\n",
      "Epoch 4896/10000: L(Train): 0.269512414932251; L(Test): 0.24991045892238617\n",
      "Epoch 4897/10000: L(Train): 0.2677361071109772; L(Test): 0.2480752021074295\n",
      "Epoch 4898/10000: L(Train): 0.2752942144870758; L(Test): 0.2471543699502945\n",
      "Epoch 4899/10000: L(Train): 0.27480101585388184; L(Test): 0.24671892821788788\n",
      "Epoch 4900/10000: L(Train): 0.2503139078617096; L(Test): 0.24581989645957947\n",
      "Epoch 4901/10000: L(Train): 0.2519018054008484; L(Test): 0.24636025726795197\n",
      "Epoch 4902/10000: L(Train): 0.26824241876602173; L(Test): 0.24486297369003296\n",
      "Epoch 4903/10000: L(Train): 0.2520788311958313; L(Test): 0.2454616278409958\n",
      "Epoch 4904/10000: L(Train): 0.2643393278121948; L(Test): 0.2461715042591095\n",
      "Epoch 4905/10000: L(Train): 0.2701928913593292; L(Test): 0.24589475989341736\n",
      "Epoch 4906/10000: L(Train): 0.27283957600593567; L(Test): 0.24548865854740143\n",
      "Epoch 4907/10000: L(Train): 0.27354350686073303; L(Test): 0.24522410333156586\n",
      "Epoch 4908/10000: L(Train): 0.2590544521808624; L(Test): 0.24536441266536713\n",
      "Epoch 4909/10000: L(Train): 0.25560760498046875; L(Test): 0.24462801218032837\n",
      "Epoch 4910/10000: L(Train): 0.266445130109787; L(Test): 0.2425294816493988\n",
      "Epoch 4911/10000: L(Train): 0.2659658193588257; L(Test): 0.24303634464740753\n",
      "Epoch 4912/10000: L(Train): 0.25333067774772644; L(Test): 0.24625346064567566\n",
      "Epoch 4913/10000: L(Train): 0.2678306996822357; L(Test): 0.24325349926948547\n",
      "Epoch 4914/10000: L(Train): 0.2727946937084198; L(Test): 0.24209186434745789\n",
      "Epoch 4915/10000: L(Train): 0.27087295055389404; L(Test): 0.24234113097190857\n",
      "Epoch 4916/10000: L(Train): 0.2613416016101837; L(Test): 0.24168354272842407\n",
      "Epoch 4917/10000: L(Train): 0.2722398042678833; L(Test): 0.24421212077140808\n",
      "Epoch 4918/10000: L(Train): 0.25452691316604614; L(Test): 0.2439563274383545\n",
      "Epoch 4919/10000: L(Train): 0.28166550397872925; L(Test): 0.24152466654777527\n",
      "Epoch 4920/10000: L(Train): 0.26492705941200256; L(Test): 0.24145981669425964\n",
      "Epoch 4921/10000: L(Train): 0.25316959619522095; L(Test): 0.24199770390987396\n",
      "Epoch 4922/10000: L(Train): 0.26431241631507874; L(Test): 0.24146908521652222\n",
      "Epoch 4923/10000: L(Train): 0.2531215250492096; L(Test): 0.24079720675945282\n",
      "Epoch 4924/10000: L(Train): 0.2766581177711487; L(Test): 0.24038778245449066\n",
      "Epoch 4925/10000: L(Train): 0.2582142651081085; L(Test): 0.24093779921531677\n",
      "Epoch 4926/10000: L(Train): 0.25687575340270996; L(Test): 0.2415570169687271\n",
      "Epoch 4927/10000: L(Train): 0.2731269299983978; L(Test): 0.24127209186553955\n",
      "Epoch 4928/10000: L(Train): 0.2518029510974884; L(Test): 0.24054519832134247\n",
      "Epoch 4929/10000: L(Train): 0.2718425691127777; L(Test): 0.23967598378658295\n",
      "Epoch 4930/10000: L(Train): 0.2661919891834259; L(Test): 0.23982761800289154\n",
      "Epoch 4931/10000: L(Train): 0.2709173858165741; L(Test): 0.2405264973640442\n",
      "Epoch 4932/10000: L(Train): 0.24636240303516388; L(Test): 0.24001356959342957\n",
      "Epoch 4933/10000: L(Train): 0.24944989383220673; L(Test): 0.23967744410037994\n",
      "Epoch 4934/10000: L(Train): 0.2623222768306732; L(Test): 0.23940934240818024\n",
      "Epoch 4935/10000: L(Train): 0.2633202075958252; L(Test): 0.23932746052742004\n",
      "Epoch 4936/10000: L(Train): 0.26001301407814026; L(Test): 0.23923280835151672\n",
      "Epoch 4937/10000: L(Train): 0.2548424005508423; L(Test): 0.23872120678424835\n",
      "Epoch 4938/10000: L(Train): 0.2617781460285187; L(Test): 0.2380848526954651\n",
      "Epoch 4939/10000: L(Train): 0.265851765871048; L(Test): 0.23773184418678284\n",
      "Epoch 4940/10000: L(Train): 0.26750612258911133; L(Test): 0.23792016506195068\n",
      "Epoch 4941/10000: L(Train): 0.27017274498939514; L(Test): 0.23844388127326965\n",
      "Epoch 4942/10000: L(Train): 0.25401777029037476; L(Test): 0.23906376957893372\n",
      "Epoch 4943/10000: L(Train): 0.255416601896286; L(Test): 0.238599494099617\n",
      "Epoch 4944/10000: L(Train): 0.2621993124485016; L(Test): 0.23903630673885345\n",
      "Epoch 4945/10000: L(Train): 0.2692629098892212; L(Test): 0.23836387693881989\n",
      "Epoch 4946/10000: L(Train): 0.2766532897949219; L(Test): 0.23866888880729675\n",
      "Epoch 4947/10000: L(Train): 0.27049899101257324; L(Test): 0.23887787759304047\n",
      "Epoch 4948/10000: L(Train): 0.26385238766670227; L(Test): 0.2393750101327896\n",
      "Epoch 4949/10000: L(Train): 0.2625196576118469; L(Test): 0.23925599455833435\n",
      "Epoch 4950/10000: L(Train): 0.25714725255966187; L(Test): 0.23800496757030487\n",
      "Epoch 4951/10000: L(Train): 0.25390851497650146; L(Test): 0.23849435150623322\n",
      "Epoch 4952/10000: L(Train): 0.2544904947280884; L(Test): 0.23920711874961853\n",
      "Epoch 4953/10000: L(Train): 0.2704490125179291; L(Test): 0.23983268439769745\n",
      "Epoch 4954/10000: L(Train): 0.26345914602279663; L(Test): 0.23885659873485565\n",
      "Epoch 4955/10000: L(Train): 0.25939202308654785; L(Test): 0.23897570371627808\n",
      "Epoch 4956/10000: L(Train): 0.25861242413520813; L(Test): 0.2385702282190323\n",
      "Epoch 4957/10000: L(Train): 0.25511544942855835; L(Test): 0.23915740847587585\n",
      "Epoch 4958/10000: L(Train): 0.25857678055763245; L(Test): 0.24021686613559723\n",
      "Epoch 4959/10000: L(Train): 0.25638577342033386; L(Test): 0.23898398876190186\n",
      "Epoch 4960/10000: L(Train): 0.2653869390487671; L(Test): 0.2384715974330902\n",
      "Epoch 4961/10000: L(Train): 0.26047655940055847; L(Test): 0.23876827955245972\n",
      "Epoch 4962/10000: L(Train): 0.269429475069046; L(Test): 0.23854753375053406\n",
      "Epoch 4963/10000: L(Train): 0.24461135268211365; L(Test): 0.23862315714359283\n",
      "Epoch 4964/10000: L(Train): 0.2665500342845917; L(Test): 0.23905466496944427\n",
      "Epoch 4965/10000: L(Train): 0.26614680886268616; L(Test): 0.2389608472585678\n",
      "Epoch 4966/10000: L(Train): 0.27037039399147034; L(Test): 0.23838570713996887\n",
      "Epoch 4967/10000: L(Train): 0.26569247245788574; L(Test): 0.24183224141597748\n",
      "Epoch 4968/10000: L(Train): 0.2643260657787323; L(Test): 0.24569542706012726\n",
      "Epoch 4969/10000: L(Train): 0.2742641866207123; L(Test): 0.24516671895980835\n",
      "Epoch 4970/10000: L(Train): 0.27401989698410034; L(Test): 0.24294984340667725\n",
      "Epoch 4971/10000: L(Train): 0.2635610103607178; L(Test): 0.2442229986190796\n",
      "Epoch 4972/10000: L(Train): 0.2620253562927246; L(Test): 0.2451656311750412\n",
      "Epoch 4973/10000: L(Train): 0.2563062906265259; L(Test): 0.24492184817790985\n",
      "Epoch 4974/10000: L(Train): 0.27269527316093445; L(Test): 0.24375851452350616\n",
      "Epoch 4975/10000: L(Train): 0.26452967524528503; L(Test): 0.24457824230194092\n",
      "Epoch 4976/10000: L(Train): 0.27345702052116394; L(Test): 0.25522947311401367\n",
      "Epoch 4977/10000: L(Train): 0.26988378167152405; L(Test): 0.2621881663799286\n",
      "Epoch 4978/10000: L(Train): 0.2595955729484558; L(Test): 0.26382943987846375\n",
      "Epoch 4979/10000: L(Train): 0.27248895168304443; L(Test): 0.2603475749492645\n",
      "Epoch 4980/10000: L(Train): 0.2798556387424469; L(Test): 0.259850412607193\n",
      "Epoch 4981/10000: L(Train): 0.2771618366241455; L(Test): 0.26034924387931824\n",
      "Epoch 4982/10000: L(Train): 0.26981857419013977; L(Test): 0.2621522545814514\n",
      "Epoch 4983/10000: L(Train): 0.28714272379875183; L(Test): 0.2614904046058655\n",
      "Epoch 4984/10000: L(Train): 0.27146127820014954; L(Test): 0.2599911391735077\n",
      "Epoch 4985/10000: L(Train): 0.2915056049823761; L(Test): 0.26017817854881287\n",
      "Epoch 4986/10000: L(Train): 0.2834087610244751; L(Test): 0.2584376931190491\n",
      "Epoch 4987/10000: L(Train): 0.2794606387615204; L(Test): 0.25626203417778015\n",
      "Epoch 4988/10000: L(Train): 0.2786121070384979; L(Test): 0.25766420364379883\n",
      "Epoch 4989/10000: L(Train): 0.2730327844619751; L(Test): 0.26100364327430725\n",
      "Epoch 4990/10000: L(Train): 0.2690623700618744; L(Test): 0.25861480832099915\n",
      "Epoch 4991/10000: L(Train): 0.2802990674972534; L(Test): 0.2554723918437958\n",
      "Epoch 4992/10000: L(Train): 0.2660495936870575; L(Test): 0.2596970796585083\n",
      "Epoch 4993/10000: L(Train): 0.2860870063304901; L(Test): 0.2610417604446411\n",
      "Epoch 4994/10000: L(Train): 0.2687195837497711; L(Test): 0.25591275095939636\n",
      "Epoch 4995/10000: L(Train): 0.27958908677101135; L(Test): 0.25856223702430725\n",
      "Epoch 4996/10000: L(Train): 0.2734370827674866; L(Test): 0.25818535685539246\n",
      "Epoch 4997/10000: L(Train): 0.26669082045555115; L(Test): 0.25461477041244507\n",
      "Epoch 4998/10000: L(Train): 0.2635206878185272; L(Test): 0.2541137933731079\n",
      "Epoch 4999/10000: L(Train): 0.272128164768219; L(Test): 0.2523989677429199\n",
      "Epoch 5000/10000: L(Train): 0.2771700918674469; L(Test): 0.2518453896045685\n",
      "Epoch 5001/10000: L(Train): 0.26299652457237244; L(Test): 0.25335532426834106\n",
      "Epoch 5002/10000: L(Train): 0.2595232129096985; L(Test): 0.25628507137298584\n",
      "Epoch 5003/10000: L(Train): 0.30119067430496216; L(Test): 0.25115489959716797\n",
      "Epoch 5004/10000: L(Train): 0.26057398319244385; L(Test): 0.2501406967639923\n",
      "Epoch 5005/10000: L(Train): 0.26586541533470154; L(Test): 0.2521476447582245\n",
      "Epoch 5006/10000: L(Train): 0.28004851937294006; L(Test): 0.25000402331352234\n",
      "Epoch 5007/10000: L(Train): 0.2756192982196808; L(Test): 0.24732394516468048\n",
      "Epoch 5008/10000: L(Train): 0.28277266025543213; L(Test): 0.24907803535461426\n",
      "Epoch 5009/10000: L(Train): 0.27489250898361206; L(Test): 0.2497018426656723\n",
      "Epoch 5010/10000: L(Train): 0.26610812544822693; L(Test): 0.24617816507816315\n",
      "Epoch 5011/10000: L(Train): 0.26592817902565; L(Test): 0.24640193581581116\n",
      "Epoch 5012/10000: L(Train): 0.27243316173553467; L(Test): 0.24624872207641602\n",
      "Epoch 5013/10000: L(Train): 0.2679738998413086; L(Test): 0.24587249755859375\n",
      "Epoch 5014/10000: L(Train): 0.26207149028778076; L(Test): 0.24605026841163635\n",
      "Epoch 5015/10000: L(Train): 0.2708851099014282; L(Test): 0.2457481026649475\n",
      "Epoch 5016/10000: L(Train): 0.2752336859703064; L(Test): 0.24537475407123566\n",
      "Epoch 5017/10000: L(Train): 0.2638481557369232; L(Test): 0.2449575513601303\n",
      "Epoch 5018/10000: L(Train): 0.28387731313705444; L(Test): 0.2445746511220932\n",
      "Epoch 5019/10000: L(Train): 0.2535526752471924; L(Test): 0.24303826689720154\n",
      "Epoch 5020/10000: L(Train): 0.25780630111694336; L(Test): 0.24438712000846863\n",
      "Epoch 5021/10000: L(Train): 0.27509090304374695; L(Test): 0.24314536154270172\n",
      "Epoch 5022/10000: L(Train): 0.2651608884334564; L(Test): 0.24223583936691284\n",
      "Epoch 5023/10000: L(Train): 0.2870277166366577; L(Test): 0.24212078750133514\n",
      "Epoch 5024/10000: L(Train): 0.273039311170578; L(Test): 0.2415672093629837\n",
      "Epoch 5025/10000: L(Train): 0.26076367497444153; L(Test): 0.24101370573043823\n",
      "Epoch 5026/10000: L(Train): 0.24989499151706696; L(Test): 0.24051930010318756\n",
      "Epoch 5027/10000: L(Train): 0.2641294300556183; L(Test): 0.24129287898540497\n",
      "Epoch 5028/10000: L(Train): 0.25606149435043335; L(Test): 0.24173976480960846\n",
      "Epoch 5029/10000: L(Train): 0.2582738399505615; L(Test): 0.24086244404315948\n",
      "Epoch 5030/10000: L(Train): 0.26154887676239014; L(Test): 0.24084103107452393\n",
      "Epoch 5031/10000: L(Train): 0.24420644342899323; L(Test): 0.24082601070404053\n",
      "Epoch 5032/10000: L(Train): 0.2756764590740204; L(Test): 0.24182341992855072\n",
      "Epoch 5033/10000: L(Train): 0.25728821754455566; L(Test): 0.24091431498527527\n",
      "Epoch 5034/10000: L(Train): 0.2571265995502472; L(Test): 0.2411317080259323\n",
      "Epoch 5035/10000: L(Train): 0.26787737011909485; L(Test): 0.23968611657619476\n",
      "Epoch 5036/10000: L(Train): 0.267292320728302; L(Test): 0.23936964571475983\n",
      "Epoch 5037/10000: L(Train): 0.25390148162841797; L(Test): 0.24008043110370636\n",
      "Epoch 5038/10000: L(Train): 0.2790611982345581; L(Test): 0.23966220021247864\n",
      "Epoch 5039/10000: L(Train): 0.25344106554985046; L(Test): 0.24005448818206787\n",
      "Epoch 5040/10000: L(Train): 0.25004181265830994; L(Test): 0.24012477695941925\n",
      "Epoch 5041/10000: L(Train): 0.26688599586486816; L(Test): 0.23942479491233826\n",
      "Epoch 5042/10000: L(Train): 0.267891526222229; L(Test): 0.2398127168416977\n",
      "Epoch 5043/10000: L(Train): 0.25750988721847534; L(Test): 0.2401542067527771\n",
      "Epoch 5044/10000: L(Train): 0.2535630464553833; L(Test): 0.2402515560388565\n",
      "Epoch 5045/10000: L(Train): 0.27559393644332886; L(Test): 0.23951998353004456\n",
      "Epoch 5046/10000: L(Train): 0.2540603578090668; L(Test): 0.24033288657665253\n",
      "Epoch 5047/10000: L(Train): 0.258690744638443; L(Test): 0.24000324308872223\n",
      "Epoch 5048/10000: L(Train): 0.2611820101737976; L(Test): 0.23976543545722961\n",
      "Epoch 5049/10000: L(Train): 0.260006844997406; L(Test): 0.240106001496315\n",
      "Epoch 5050/10000: L(Train): 0.28370925784111023; L(Test): 0.23959824442863464\n",
      "Epoch 5051/10000: L(Train): 0.26441285014152527; L(Test): 0.23933248221874237\n",
      "Epoch 5052/10000: L(Train): 0.262102335691452; L(Test): 0.2391969859600067\n",
      "Epoch 5053/10000: L(Train): 0.2528865933418274; L(Test): 0.23920561373233795\n",
      "Epoch 5054/10000: L(Train): 0.2513055205345154; L(Test): 0.23889365792274475\n",
      "Epoch 5055/10000: L(Train): 0.2685577869415283; L(Test): 0.23858998715877533\n",
      "Epoch 5056/10000: L(Train): 0.2536122798919678; L(Test): 0.23817546665668488\n",
      "Epoch 5057/10000: L(Train): 0.2615524232387543; L(Test): 0.23864281177520752\n",
      "Epoch 5058/10000: L(Train): 0.27252739667892456; L(Test): 0.2380441278219223\n",
      "Epoch 5059/10000: L(Train): 0.26606887578964233; L(Test): 0.23817165195941925\n",
      "Epoch 5060/10000: L(Train): 0.2588709592819214; L(Test): 0.23923638463020325\n",
      "Epoch 5061/10000: L(Train): 0.2607480585575104; L(Test): 0.2391849011182785\n",
      "Epoch 5062/10000: L(Train): 0.2710917890071869; L(Test): 0.238168865442276\n",
      "Epoch 5063/10000: L(Train): 0.25789862871170044; L(Test): 0.23787474632263184\n",
      "Epoch 5064/10000: L(Train): 0.2519364655017853; L(Test): 0.2384832203388214\n",
      "Epoch 5065/10000: L(Train): 0.2663436233997345; L(Test): 0.2383623719215393\n",
      "Epoch 5066/10000: L(Train): 0.26276037096977234; L(Test): 0.2380441278219223\n",
      "Epoch 5067/10000: L(Train): 0.27252522110939026; L(Test): 0.2392439991235733\n",
      "Epoch 5068/10000: L(Train): 0.2599201798439026; L(Test): 0.2383960783481598\n",
      "Epoch 5069/10000: L(Train): 0.2333923578262329; L(Test): 0.2392897605895996\n",
      "Epoch 5070/10000: L(Train): 0.2618691623210907; L(Test): 0.23971647024154663\n",
      "Epoch 5071/10000: L(Train): 0.2787000238895416; L(Test): 0.24127505719661713\n",
      "Epoch 5072/10000: L(Train): 0.2807755768299103; L(Test): 0.23991753160953522\n",
      "Epoch 5073/10000: L(Train): 0.2615306079387665; L(Test): 0.23942789435386658\n",
      "Epoch 5074/10000: L(Train): 0.25775495171546936; L(Test): 0.23974570631980896\n",
      "Epoch 5075/10000: L(Train): 0.2639581561088562; L(Test): 0.23949576914310455\n",
      "Epoch 5076/10000: L(Train): 0.26436251401901245; L(Test): 0.24002905189990997\n",
      "Epoch 5077/10000: L(Train): 0.26291173696517944; L(Test): 0.23874108493328094\n",
      "Epoch 5078/10000: L(Train): 0.25588253140449524; L(Test): 0.23870094120502472\n",
      "Epoch 5079/10000: L(Train): 0.2651975154876709; L(Test): 0.23926465213298798\n",
      "Epoch 5080/10000: L(Train): 0.26221513748168945; L(Test): 0.2398897409439087\n",
      "Epoch 5081/10000: L(Train): 0.2590489387512207; L(Test): 0.23900407552719116\n",
      "Epoch 5082/10000: L(Train): 0.2558363378047943; L(Test): 0.23937228322029114\n",
      "Epoch 5083/10000: L(Train): 0.26794564723968506; L(Test): 0.23951709270477295\n",
      "Epoch 5084/10000: L(Train): 0.2492019534111023; L(Test): 0.23999279737472534\n",
      "Epoch 5085/10000: L(Train): 0.2601737678050995; L(Test): 0.24018166959285736\n",
      "Epoch 5086/10000: L(Train): 0.2703358829021454; L(Test): 0.2396726906299591\n",
      "Epoch 5087/10000: L(Train): 0.2631292939186096; L(Test): 0.2409086525440216\n",
      "Epoch 5088/10000: L(Train): 0.24695633351802826; L(Test): 0.24020422995090485\n",
      "Epoch 5089/10000: L(Train): 0.25880786776542664; L(Test): 0.23959028720855713\n",
      "Epoch 5090/10000: L(Train): 0.23510487377643585; L(Test): 0.2406361997127533\n",
      "Epoch 5091/10000: L(Train): 0.25684043765068054; L(Test): 0.24073326587677002\n",
      "Epoch 5092/10000: L(Train): 0.2731653153896332; L(Test): 0.23938068747520447\n",
      "Epoch 5093/10000: L(Train): 0.25894322991371155; L(Test): 0.23963315784931183\n",
      "Epoch 5094/10000: L(Train): 0.26778459548950195; L(Test): 0.24054405093193054\n",
      "Epoch 5095/10000: L(Train): 0.25469639897346497; L(Test): 0.2399633377790451\n",
      "Epoch 5096/10000: L(Train): 0.2568472623825073; L(Test): 0.24027471244335175\n",
      "Epoch 5097/10000: L(Train): 0.2676199674606323; L(Test): 0.24195504188537598\n",
      "Epoch 5098/10000: L(Train): 0.27219435572624207; L(Test): 0.2405255138874054\n",
      "Epoch 5099/10000: L(Train): 0.2584958076477051; L(Test): 0.2397271990776062\n",
      "Epoch 5100/10000: L(Train): 0.2573358416557312; L(Test): 0.2403036653995514\n",
      "Epoch 5101/10000: L(Train): 0.253487765789032; L(Test): 0.24029295146465302\n",
      "Epoch 5102/10000: L(Train): 0.25866827368736267; L(Test): 0.23987458646297455\n",
      "Epoch 5103/10000: L(Train): 0.2575485110282898; L(Test): 0.24040181934833527\n",
      "Epoch 5104/10000: L(Train): 0.26116907596588135; L(Test): 0.24053442478179932\n",
      "Epoch 5105/10000: L(Train): 0.26832887530326843; L(Test): 0.2390357255935669\n",
      "Epoch 5106/10000: L(Train): 0.2554536759853363; L(Test): 0.24034258723258972\n",
      "Epoch 5107/10000: L(Train): 0.25215771794319153; L(Test): 0.24120807647705078\n",
      "Epoch 5108/10000: L(Train): 0.26845312118530273; L(Test): 0.24144159257411957\n",
      "Epoch 5109/10000: L(Train): 0.2523711919784546; L(Test): 0.24099689722061157\n",
      "Epoch 5110/10000: L(Train): 0.26398900151252747; L(Test): 0.24084170162677765\n",
      "Epoch 5111/10000: L(Train): 0.27116426825523376; L(Test): 0.24178622663021088\n",
      "Epoch 5112/10000: L(Train): 0.24857757985591888; L(Test): 0.2423868626356125\n",
      "Epoch 5113/10000: L(Train): 0.2719062864780426; L(Test): 0.24136723577976227\n",
      "Epoch 5114/10000: L(Train): 0.26685404777526855; L(Test): 0.24159575998783112\n",
      "Epoch 5115/10000: L(Train): 0.2593382000923157; L(Test): 0.24393081665039062\n",
      "Epoch 5116/10000: L(Train): 0.26732760667800903; L(Test): 0.24842026829719543\n",
      "Epoch 5117/10000: L(Train): 0.26991501450538635; L(Test): 0.2467861920595169\n",
      "Epoch 5118/10000: L(Train): 0.27143141627311707; L(Test): 0.2436598539352417\n",
      "Epoch 5119/10000: L(Train): 0.2677861452102661; L(Test): 0.24983429908752441\n",
      "Epoch 5120/10000: L(Train): 0.2750016450881958; L(Test): 0.24805143475532532\n",
      "Epoch 5121/10000: L(Train): 0.2846764028072357; L(Test): 0.24624864757061005\n",
      "Epoch 5122/10000: L(Train): 0.2663864195346832; L(Test): 0.24583694338798523\n",
      "Epoch 5123/10000: L(Train): 0.2626648545265198; L(Test): 0.2480076551437378\n",
      "Epoch 5124/10000: L(Train): 0.2657976448535919; L(Test): 0.24804115295410156\n",
      "Epoch 5125/10000: L(Train): 0.2727712392807007; L(Test): 0.24591849744319916\n",
      "Epoch 5126/10000: L(Train): 0.2772647440433502; L(Test): 0.24773915112018585\n",
      "Epoch 5127/10000: L(Train): 0.2655070126056671; L(Test): 0.2507087290287018\n",
      "Epoch 5128/10000: L(Train): 0.27122119069099426; L(Test): 0.24612757563591003\n",
      "Epoch 5129/10000: L(Train): 0.26672181487083435; L(Test): 0.24606823921203613\n",
      "Epoch 5130/10000: L(Train): 0.26113438606262207; L(Test): 0.24560439586639404\n",
      "Epoch 5131/10000: L(Train): 0.256283164024353; L(Test): 0.24465294182300568\n",
      "Epoch 5132/10000: L(Train): 0.2696531414985657; L(Test): 0.24357396364212036\n",
      "Epoch 5133/10000: L(Train): 0.28025710582733154; L(Test): 0.24354954063892365\n",
      "Epoch 5134/10000: L(Train): 0.26848304271698; L(Test): 0.2431166023015976\n",
      "Epoch 5135/10000: L(Train): 0.25658249855041504; L(Test): 0.24224036931991577\n",
      "Epoch 5136/10000: L(Train): 0.2557346224784851; L(Test): 0.24400809407234192\n",
      "Epoch 5137/10000: L(Train): 0.2768307328224182; L(Test): 0.24385160207748413\n",
      "Epoch 5138/10000: L(Train): 0.2817811369895935; L(Test): 0.24159297347068787\n",
      "Epoch 5139/10000: L(Train): 0.2621392011642456; L(Test): 0.24259358644485474\n",
      "Epoch 5140/10000: L(Train): 0.2561216950416565; L(Test): 0.24180462956428528\n",
      "Epoch 5141/10000: L(Train): 0.2600194811820984; L(Test): 0.24149104952812195\n",
      "Epoch 5142/10000: L(Train): 0.2616594433784485; L(Test): 0.24156926572322845\n",
      "Epoch 5143/10000: L(Train): 0.24822872877120972; L(Test): 0.24076612293720245\n",
      "Epoch 5144/10000: L(Train): 0.24773606657981873; L(Test): 0.24055026471614838\n",
      "Epoch 5145/10000: L(Train): 0.2501428425312042; L(Test): 0.24047070741653442\n",
      "Epoch 5146/10000: L(Train): 0.2630552053451538; L(Test): 0.24029208719730377\n",
      "Epoch 5147/10000: L(Train): 0.2701885998249054; L(Test): 0.23995010554790497\n",
      "Epoch 5148/10000: L(Train): 0.24356606602668762; L(Test): 0.24005568027496338\n",
      "Epoch 5149/10000: L(Train): 0.26379460096359253; L(Test): 0.24012021720409393\n",
      "Epoch 5150/10000: L(Train): 0.2553613483905792; L(Test): 0.24007093906402588\n",
      "Epoch 5151/10000: L(Train): 0.269405722618103; L(Test): 0.23912885785102844\n",
      "Epoch 5152/10000: L(Train): 0.25653213262557983; L(Test): 0.23885110020637512\n",
      "Epoch 5153/10000: L(Train): 0.2640528976917267; L(Test): 0.23919810354709625\n",
      "Epoch 5154/10000: L(Train): 0.24933797121047974; L(Test): 0.23895226418972015\n",
      "Epoch 5155/10000: L(Train): 0.2518245279788971; L(Test): 0.23922890424728394\n",
      "Epoch 5156/10000: L(Train): 0.2746862471103668; L(Test): 0.23874139785766602\n",
      "Epoch 5157/10000: L(Train): 0.26961612701416016; L(Test): 0.23755000531673431\n",
      "Epoch 5158/10000: L(Train): 0.26613423228263855; L(Test): 0.23847658932209015\n",
      "Epoch 5159/10000: L(Train): 0.27106723189353943; L(Test): 0.23829565942287445\n",
      "Epoch 5160/10000: L(Train): 0.25046199560165405; L(Test): 0.23852287232875824\n",
      "Epoch 5161/10000: L(Train): 0.2571471929550171; L(Test): 0.24016442894935608\n",
      "Epoch 5162/10000: L(Train): 0.25394707918167114; L(Test): 0.23893077671527863\n",
      "Epoch 5163/10000: L(Train): 0.25959429144859314; L(Test): 0.23823121190071106\n",
      "Epoch 5164/10000: L(Train): 0.2565995454788208; L(Test): 0.23762328922748566\n",
      "Epoch 5165/10000: L(Train): 0.2691068947315216; L(Test): 0.2381005585193634\n",
      "Epoch 5166/10000: L(Train): 0.27650904655456543; L(Test): 0.23900139331817627\n",
      "Epoch 5167/10000: L(Train): 0.2669509947299957; L(Test): 0.2371673434972763\n",
      "Epoch 5168/10000: L(Train): 0.2533714175224304; L(Test): 0.2385832816362381\n",
      "Epoch 5169/10000: L(Train): 0.249969020485878; L(Test): 0.23849518597126007\n",
      "Epoch 5170/10000: L(Train): 0.2666471302509308; L(Test): 0.2387792468070984\n",
      "Epoch 5171/10000: L(Train): 0.2549756169319153; L(Test): 0.24025698006153107\n",
      "Epoch 5172/10000: L(Train): 0.2685767114162445; L(Test): 0.23852680623531342\n",
      "Epoch 5173/10000: L(Train): 0.27473676204681396; L(Test): 0.23792439699172974\n",
      "Epoch 5174/10000: L(Train): 0.2756918966770172; L(Test): 0.23779131472110748\n",
      "Epoch 5175/10000: L(Train): 0.2586947977542877; L(Test): 0.23796036839485168\n",
      "Epoch 5176/10000: L(Train): 0.2624877691268921; L(Test): 0.23796769976615906\n",
      "Epoch 5177/10000: L(Train): 0.2437129020690918; L(Test): 0.23791618645191193\n",
      "Epoch 5178/10000: L(Train): 0.27258437871932983; L(Test): 0.23683924973011017\n",
      "Epoch 5179/10000: L(Train): 0.24380475282669067; L(Test): 0.23756606876850128\n",
      "Epoch 5180/10000: L(Train): 0.27829644083976746; L(Test): 0.23879285156726837\n",
      "Epoch 5181/10000: L(Train): 0.2582862377166748; L(Test): 0.23793622851371765\n",
      "Epoch 5182/10000: L(Train): 0.2786315679550171; L(Test): 0.23851144313812256\n",
      "Epoch 5183/10000: L(Train): 0.24127839505672455; L(Test): 0.23809458315372467\n",
      "Epoch 5184/10000: L(Train): 0.2581891119480133; L(Test): 0.23837509751319885\n",
      "Epoch 5185/10000: L(Train): 0.2625496983528137; L(Test): 0.23857919871807098\n",
      "Epoch 5186/10000: L(Train): 0.25206273794174194; L(Test): 0.23831135034561157\n",
      "Epoch 5187/10000: L(Train): 0.258681982755661; L(Test): 0.23829108476638794\n",
      "Epoch 5188/10000: L(Train): 0.2589774429798126; L(Test): 0.238455131649971\n",
      "Epoch 5189/10000: L(Train): 0.25465235114097595; L(Test): 0.2379976361989975\n",
      "Epoch 5190/10000: L(Train): 0.25670138001441956; L(Test): 0.23755419254302979\n",
      "Epoch 5191/10000: L(Train): 0.25912928581237793; L(Test): 0.2387978434562683\n",
      "Epoch 5192/10000: L(Train): 0.2752583622932434; L(Test): 0.238502636551857\n",
      "Epoch 5193/10000: L(Train): 0.25250911712646484; L(Test): 0.23867298662662506\n",
      "Epoch 5194/10000: L(Train): 0.2377203106880188; L(Test): 0.23767413198947906\n",
      "Epoch 5195/10000: L(Train): 0.2668824791908264; L(Test): 0.23756906390190125\n",
      "Epoch 5196/10000: L(Train): 0.2658146023750305; L(Test): 0.23774829506874084\n",
      "Epoch 5197/10000: L(Train): 0.2639414668083191; L(Test): 0.23762723803520203\n",
      "Epoch 5198/10000: L(Train): 0.2638929486274719; L(Test): 0.23810993134975433\n",
      "Epoch 5199/10000: L(Train): 0.2589570879936218; L(Test): 0.23845930397510529\n",
      "Epoch 5200/10000: L(Train): 0.2526114284992218; L(Test): 0.23845911026000977\n",
      "Epoch 5201/10000: L(Train): 0.26360949873924255; L(Test): 0.2377346307039261\n",
      "Epoch 5202/10000: L(Train): 0.2607678472995758; L(Test): 0.23740623891353607\n",
      "Epoch 5203/10000: L(Train): 0.26047003269195557; L(Test): 0.23763039708137512\n",
      "Epoch 5204/10000: L(Train): 0.2606196701526642; L(Test): 0.2374793291091919\n",
      "Epoch 5205/10000: L(Train): 0.267738401889801; L(Test): 0.23732921481132507\n",
      "Epoch 5206/10000: L(Train): 0.2674700915813446; L(Test): 0.23731264472007751\n",
      "Epoch 5207/10000: L(Train): 0.2637302279472351; L(Test): 0.2374120056629181\n",
      "Epoch 5208/10000: L(Train): 0.2634144127368927; L(Test): 0.23757243156433105\n",
      "Epoch 5209/10000: L(Train): 0.25844573974609375; L(Test): 0.23745408654212952\n",
      "Epoch 5210/10000: L(Train): 0.2617505192756653; L(Test): 0.23823823034763336\n",
      "Epoch 5211/10000: L(Train): 0.27646875381469727; L(Test): 0.2385055273771286\n",
      "Epoch 5212/10000: L(Train): 0.2692522704601288; L(Test): 0.23914901912212372\n",
      "Epoch 5213/10000: L(Train): 0.25940176844596863; L(Test): 0.23902839422225952\n",
      "Epoch 5214/10000: L(Train): 0.25151121616363525; L(Test): 0.23811005055904388\n",
      "Epoch 5215/10000: L(Train): 0.25415855646133423; L(Test): 0.2379092276096344\n",
      "Epoch 5216/10000: L(Train): 0.26328012347221375; L(Test): 0.23769941926002502\n",
      "Epoch 5217/10000: L(Train): 0.2611108422279358; L(Test): 0.23834417760372162\n",
      "Epoch 5218/10000: L(Train): 0.26142618060112; L(Test): 0.23766715824604034\n",
      "Epoch 5219/10000: L(Train): 0.2605336308479309; L(Test): 0.23854494094848633\n",
      "Epoch 5220/10000: L(Train): 0.2768268287181854; L(Test): 0.23937757313251495\n",
      "Epoch 5221/10000: L(Train): 0.26821550726890564; L(Test): 0.23748712241649628\n",
      "Epoch 5222/10000: L(Train): 0.2644416391849518; L(Test): 0.2392698973417282\n",
      "Epoch 5223/10000: L(Train): 0.2634962499141693; L(Test): 0.23950731754302979\n",
      "Epoch 5224/10000: L(Train): 0.25134336948394775; L(Test): 0.24064354598522186\n",
      "Epoch 5225/10000: L(Train): 0.26493582129478455; L(Test): 0.2389068901538849\n",
      "Epoch 5226/10000: L(Train): 0.27300015091896057; L(Test): 0.2407168447971344\n",
      "Epoch 5227/10000: L(Train): 0.2578078508377075; L(Test): 0.24068786203861237\n",
      "Epoch 5228/10000: L(Train): 0.28183186054229736; L(Test): 0.23933498561382294\n",
      "Epoch 5229/10000: L(Train): 0.26774299144744873; L(Test): 0.24090911448001862\n",
      "Epoch 5230/10000: L(Train): 0.2680484354496002; L(Test): 0.24074605107307434\n",
      "Epoch 5231/10000: L(Train): 0.2592397630214691; L(Test): 0.23933014273643494\n",
      "Epoch 5232/10000: L(Train): 0.2510939836502075; L(Test): 0.24063128232955933\n",
      "Epoch 5233/10000: L(Train): 0.27767881751060486; L(Test): 0.240324467420578\n",
      "Epoch 5234/10000: L(Train): 0.25286540389060974; L(Test): 0.23910555243492126\n",
      "Epoch 5235/10000: L(Train): 0.2663848400115967; L(Test): 0.2395191788673401\n",
      "Epoch 5236/10000: L(Train): 0.2562766969203949; L(Test): 0.2390480786561966\n",
      "Epoch 5237/10000: L(Train): 0.25942543148994446; L(Test): 0.23764033615589142\n",
      "Epoch 5238/10000: L(Train): 0.2593226730823517; L(Test): 0.23961365222930908\n",
      "Epoch 5239/10000: L(Train): 0.26661935448646545; L(Test): 0.2392275184392929\n",
      "Epoch 5240/10000: L(Train): 0.25766804814338684; L(Test): 0.23740306496620178\n",
      "Epoch 5241/10000: L(Train): 0.25518476963043213; L(Test): 0.23799853026866913\n",
      "Epoch 5242/10000: L(Train): 0.27256911993026733; L(Test): 0.23855438828468323\n",
      "Epoch 5243/10000: L(Train): 0.2660669982433319; L(Test): 0.2385772168636322\n",
      "Epoch 5244/10000: L(Train): 0.26175376772880554; L(Test): 0.2384011596441269\n",
      "Epoch 5245/10000: L(Train): 0.2596495449542999; L(Test): 0.23838411271572113\n",
      "Epoch 5246/10000: L(Train): 0.26208752393722534; L(Test): 0.23857858777046204\n",
      "Epoch 5247/10000: L(Train): 0.2758067548274994; L(Test): 0.23686613142490387\n",
      "Epoch 5248/10000: L(Train): 0.25515344738960266; L(Test): 0.23776161670684814\n",
      "Epoch 5249/10000: L(Train): 0.2466183602809906; L(Test): 0.23810498416423798\n",
      "Epoch 5250/10000: L(Train): 0.26904794573783875; L(Test): 0.23818451166152954\n",
      "Epoch 5251/10000: L(Train): 0.2705013155937195; L(Test): 0.23796199262142181\n",
      "Epoch 5252/10000: L(Train): 0.2744211256504059; L(Test): 0.23768725991249084\n",
      "Epoch 5253/10000: L(Train): 0.2665729820728302; L(Test): 0.23906077444553375\n",
      "Epoch 5254/10000: L(Train): 0.2675025761127472; L(Test): 0.23836055397987366\n",
      "Epoch 5255/10000: L(Train): 0.25268781185150146; L(Test): 0.23763911426067352\n",
      "Epoch 5256/10000: L(Train): 0.26425525546073914; L(Test): 0.23809105157852173\n",
      "Epoch 5257/10000: L(Train): 0.2602556645870209; L(Test): 0.23779183626174927\n",
      "Epoch 5258/10000: L(Train): 0.27231565117836; L(Test): 0.23759868741035461\n",
      "Epoch 5259/10000: L(Train): 0.2607439160346985; L(Test): 0.23749855160713196\n",
      "Epoch 5260/10000: L(Train): 0.2628629803657532; L(Test): 0.2373226284980774\n",
      "Epoch 5261/10000: L(Train): 0.27556198835372925; L(Test): 0.2369256466627121\n",
      "Epoch 5262/10000: L(Train): 0.27225226163864136; L(Test): 0.23694545030593872\n",
      "Epoch 5263/10000: L(Train): 0.25065961480140686; L(Test): 0.2369459569454193\n",
      "Epoch 5264/10000: L(Train): 0.2640076279640198; L(Test): 0.23719146847724915\n",
      "Epoch 5265/10000: L(Train): 0.2466166615486145; L(Test): 0.23846442997455597\n",
      "Epoch 5266/10000: L(Train): 0.24765430390834808; L(Test): 0.23775802552700043\n",
      "Epoch 5267/10000: L(Train): 0.2653346061706543; L(Test): 0.23745986819267273\n",
      "Epoch 5268/10000: L(Train): 0.2691517472267151; L(Test): 0.23854736983776093\n",
      "Epoch 5269/10000: L(Train): 0.28467729687690735; L(Test): 0.23731043934822083\n",
      "Epoch 5270/10000: L(Train): 0.2607264518737793; L(Test): 0.23830118775367737\n",
      "Epoch 5271/10000: L(Train): 0.2577088475227356; L(Test): 0.23927395045757294\n",
      "Epoch 5272/10000: L(Train): 0.2561397850513458; L(Test): 0.23785069584846497\n",
      "Epoch 5273/10000: L(Train): 0.26684334874153137; L(Test): 0.2373991161584854\n",
      "Epoch 5274/10000: L(Train): 0.26966559886932373; L(Test): 0.2395690679550171\n",
      "Epoch 5275/10000: L(Train): 0.26852333545684814; L(Test): 0.2406015396118164\n",
      "Epoch 5276/10000: L(Train): 0.25212743878364563; L(Test): 0.23888760805130005\n",
      "Epoch 5277/10000: L(Train): 0.26440945267677307; L(Test): 0.23914511501789093\n",
      "Epoch 5278/10000: L(Train): 0.25415483117103577; L(Test): 0.23949003219604492\n",
      "Epoch 5279/10000: L(Train): 0.25451913475990295; L(Test): 0.24033969640731812\n",
      "Epoch 5280/10000: L(Train): 0.2673935890197754; L(Test): 0.24082249402999878\n",
      "Epoch 5281/10000: L(Train): 0.25444450974464417; L(Test): 0.24071070551872253\n",
      "Epoch 5282/10000: L(Train): 0.26090529561042786; L(Test): 0.2407860904932022\n",
      "Epoch 5283/10000: L(Train): 0.2586854100227356; L(Test): 0.24019798636436462\n",
      "Epoch 5284/10000: L(Train): 0.256889671087265; L(Test): 0.23955869674682617\n",
      "Epoch 5285/10000: L(Train): 0.26594942808151245; L(Test): 0.23939862847328186\n",
      "Epoch 5286/10000: L(Train): 0.27524858713150024; L(Test): 0.23921121656894684\n",
      "Epoch 5287/10000: L(Train): 0.25413671135902405; L(Test): 0.2406838834285736\n",
      "Epoch 5288/10000: L(Train): 0.2512570917606354; L(Test): 0.23960590362548828\n",
      "Epoch 5289/10000: L(Train): 0.26711347699165344; L(Test): 0.24047598242759705\n",
      "Epoch 5290/10000: L(Train): 0.2712978422641754; L(Test): 0.24220409989356995\n",
      "Epoch 5291/10000: L(Train): 0.27701452374458313; L(Test): 0.23950542509555817\n",
      "Epoch 5292/10000: L(Train): 0.2599010169506073; L(Test): 0.2396562695503235\n",
      "Epoch 5293/10000: L(Train): 0.26468074321746826; L(Test): 0.24201823770999908\n",
      "Epoch 5294/10000: L(Train): 0.2745194435119629; L(Test): 0.2420453429222107\n",
      "Epoch 5295/10000: L(Train): 0.24756573140621185; L(Test): 0.2407904863357544\n",
      "Epoch 5296/10000: L(Train): 0.2644774913787842; L(Test): 0.24079877138137817\n",
      "Epoch 5297/10000: L(Train): 0.27433332800865173; L(Test): 0.2404048889875412\n",
      "Epoch 5298/10000: L(Train): 0.2552115321159363; L(Test): 0.24068288505077362\n",
      "Epoch 5299/10000: L(Train): 0.2646808326244354; L(Test): 0.24093039333820343\n",
      "Epoch 5300/10000: L(Train): 0.26987963914871216; L(Test): 0.24061846733093262\n",
      "Epoch 5301/10000: L(Train): 0.2778899073600769; L(Test): 0.24044039845466614\n",
      "Epoch 5302/10000: L(Train): 0.2682901918888092; L(Test): 0.24014602601528168\n",
      "Epoch 5303/10000: L(Train): 0.2645474374294281; L(Test): 0.24047164618968964\n",
      "Epoch 5304/10000: L(Train): 0.2543362081050873; L(Test): 0.24047215282917023\n",
      "Epoch 5305/10000: L(Train): 0.256138414144516; L(Test): 0.23959574103355408\n",
      "Epoch 5306/10000: L(Train): 0.25440284609794617; L(Test): 0.23963101208209991\n",
      "Epoch 5307/10000: L(Train): 0.25601455569267273; L(Test): 0.2402467131614685\n",
      "Epoch 5308/10000: L(Train): 0.2555326819419861; L(Test): 0.24026517570018768\n",
      "Epoch 5309/10000: L(Train): 0.27414631843566895; L(Test): 0.24135443568229675\n",
      "Epoch 5310/10000: L(Train): 0.2513467073440552; L(Test): 0.24130402505397797\n",
      "Epoch 5311/10000: L(Train): 0.2735767364501953; L(Test): 0.23891672492027283\n",
      "Epoch 5312/10000: L(Train): 0.2623765170574188; L(Test): 0.24202768504619598\n",
      "Epoch 5313/10000: L(Train): 0.2582346498966217; L(Test): 0.23918169736862183\n",
      "Epoch 5314/10000: L(Train): 0.254843533039093; L(Test): 0.24502156674861908\n",
      "Epoch 5315/10000: L(Train): 0.2752261459827423; L(Test): 0.23889024555683136\n",
      "Epoch 5316/10000: L(Train): 0.26583054661750793; L(Test): 0.24085158109664917\n",
      "Epoch 5317/10000: L(Train): 0.2560764253139496; L(Test): 0.23959171772003174\n",
      "Epoch 5318/10000: L(Train): 0.257107675075531; L(Test): 0.23959819972515106\n",
      "Epoch 5319/10000: L(Train): 0.2590120732784271; L(Test): 0.241794615983963\n",
      "Epoch 5320/10000: L(Train): 0.2593183219432831; L(Test): 0.24031327664852142\n",
      "Epoch 5321/10000: L(Train): 0.27052974700927734; L(Test): 0.24032801389694214\n",
      "Epoch 5322/10000: L(Train): 0.27433744072914124; L(Test): 0.24073798954486847\n",
      "Epoch 5323/10000: L(Train): 0.25916025042533875; L(Test): 0.24140816926956177\n",
      "Epoch 5324/10000: L(Train): 0.2623804807662964; L(Test): 0.23916982114315033\n",
      "Epoch 5325/10000: L(Train): 0.25885775685310364; L(Test): 0.23816239833831787\n",
      "Epoch 5326/10000: L(Train): 0.25004440546035767; L(Test): 0.23907004296779633\n",
      "Epoch 5327/10000: L(Train): 0.2688400149345398; L(Test): 0.23924489319324493\n",
      "Epoch 5328/10000: L(Train): 0.26471778750419617; L(Test): 0.2390335649251938\n",
      "Epoch 5329/10000: L(Train): 0.25818049907684326; L(Test): 0.23988135159015656\n",
      "Epoch 5330/10000: L(Train): 0.2692951261997223; L(Test): 0.23962454497814178\n",
      "Epoch 5331/10000: L(Train): 0.257097452878952; L(Test): 0.24001646041870117\n",
      "Epoch 5332/10000: L(Train): 0.2532068192958832; L(Test): 0.240327388048172\n",
      "Epoch 5333/10000: L(Train): 0.26325660943984985; L(Test): 0.2390373945236206\n",
      "Epoch 5334/10000: L(Train): 0.2657340168952942; L(Test): 0.2383827418088913\n",
      "Epoch 5335/10000: L(Train): 0.26927635073661804; L(Test): 0.23888225853443146\n",
      "Epoch 5336/10000: L(Train): 0.27071961760520935; L(Test): 0.23905816674232483\n",
      "Epoch 5337/10000: L(Train): 0.26765164732933044; L(Test): 0.23909249901771545\n",
      "Epoch 5338/10000: L(Train): 0.25080248713493347; L(Test): 0.2385338991880417\n",
      "Epoch 5339/10000: L(Train): 0.25086936354637146; L(Test): 0.23854471743106842\n",
      "Epoch 5340/10000: L(Train): 0.2560800015926361; L(Test): 0.2390333116054535\n",
      "Epoch 5341/10000: L(Train): 0.2692399024963379; L(Test): 0.2393564134836197\n",
      "Epoch 5342/10000: L(Train): 0.27680665254592896; L(Test): 0.2391943782567978\n",
      "Epoch 5343/10000: L(Train): 0.25734105706214905; L(Test): 0.24003006517887115\n",
      "Epoch 5344/10000: L(Train): 0.2586039900779724; L(Test): 0.23877392709255219\n",
      "Epoch 5345/10000: L(Train): 0.2687447965145111; L(Test): 0.2402241975069046\n",
      "Epoch 5346/10000: L(Train): 0.2543635070323944; L(Test): 0.2409738004207611\n",
      "Epoch 5347/10000: L(Train): 0.2747591435909271; L(Test): 0.23820769786834717\n",
      "Epoch 5348/10000: L(Train): 0.250031054019928; L(Test): 0.2386295646429062\n",
      "Epoch 5349/10000: L(Train): 0.25819772481918335; L(Test): 0.23997557163238525\n",
      "Epoch 5350/10000: L(Train): 0.2715262174606323; L(Test): 0.23890210688114166\n",
      "Epoch 5351/10000: L(Train): 0.27241408824920654; L(Test): 0.2398524433374405\n",
      "Epoch 5352/10000: L(Train): 0.27408596873283386; L(Test): 0.24025842547416687\n",
      "Epoch 5353/10000: L(Train): 0.2580050826072693; L(Test): 0.23924782872200012\n",
      "Epoch 5354/10000: L(Train): 0.2616201639175415; L(Test): 0.23978474736213684\n",
      "Epoch 5355/10000: L(Train): 0.26414161920547485; L(Test): 0.24003806710243225\n",
      "Epoch 5356/10000: L(Train): 0.2722906470298767; L(Test): 0.2391301989555359\n",
      "Epoch 5357/10000: L(Train): 0.24769628047943115; L(Test): 0.24024473130702972\n",
      "Epoch 5358/10000: L(Train): 0.28254061937332153; L(Test): 0.23888131976127625\n",
      "Epoch 5359/10000: L(Train): 0.26305028796195984; L(Test): 0.2383231371641159\n",
      "Epoch 5360/10000: L(Train): 0.25774914026260376; L(Test): 0.23971612751483917\n",
      "Epoch 5361/10000: L(Train): 0.264011949300766; L(Test): 0.23889143764972687\n",
      "Epoch 5362/10000: L(Train): 0.27123260498046875; L(Test): 0.23909546434879303\n",
      "Epoch 5363/10000: L(Train): 0.25937026739120483; L(Test): 0.2401197999715805\n",
      "Epoch 5364/10000: L(Train): 0.2587553560733795; L(Test): 0.23846878111362457\n",
      "Epoch 5365/10000: L(Train): 0.2764028012752533; L(Test): 0.24176765978336334\n",
      "Epoch 5366/10000: L(Train): 0.2506104111671448; L(Test): 0.2397150695323944\n",
      "Epoch 5367/10000: L(Train): 0.25452569127082825; L(Test): 0.2388221174478531\n",
      "Epoch 5368/10000: L(Train): 0.2537982761859894; L(Test): 0.23971763253211975\n",
      "Epoch 5369/10000: L(Train): 0.2628045380115509; L(Test): 0.23988710343837738\n",
      "Epoch 5370/10000: L(Train): 0.2670639157295227; L(Test): 0.23944447934627533\n",
      "Epoch 5371/10000: L(Train): 0.25631722807884216; L(Test): 0.23947420716285706\n",
      "Epoch 5372/10000: L(Train): 0.25372380018234253; L(Test): 0.2402408868074417\n",
      "Epoch 5373/10000: L(Train): 0.25571900606155396; L(Test): 0.24006088078022003\n",
      "Epoch 5374/10000: L(Train): 0.2563486099243164; L(Test): 0.23958241939544678\n",
      "Epoch 5375/10000: L(Train): 0.25377747416496277; L(Test): 0.241985023021698\n",
      "Epoch 5376/10000: L(Train): 0.27463003993034363; L(Test): 0.23970167338848114\n",
      "Epoch 5377/10000: L(Train): 0.24692963063716888; L(Test): 0.23836135864257812\n",
      "Epoch 5378/10000: L(Train): 0.2630912959575653; L(Test): 0.2398347109556198\n",
      "Epoch 5379/10000: L(Train): 0.27979540824890137; L(Test): 0.2398846596479416\n",
      "Epoch 5380/10000: L(Train): 0.26008141040802; L(Test): 0.23868513107299805\n",
      "Epoch 5381/10000: L(Train): 0.2610514760017395; L(Test): 0.23845963180065155\n",
      "Epoch 5382/10000: L(Train): 0.27067244052886963; L(Test): 0.23885612189769745\n",
      "Epoch 5383/10000: L(Train): 0.26077619194984436; L(Test): 0.23947389423847198\n",
      "Epoch 5384/10000: L(Train): 0.2631204128265381; L(Test): 0.24053964018821716\n",
      "Epoch 5385/10000: L(Train): 0.2570790648460388; L(Test): 0.23883938789367676\n",
      "Epoch 5386/10000: L(Train): 0.2708887755870819; L(Test): 0.23964636027812958\n",
      "Epoch 5387/10000: L(Train): 0.24683046340942383; L(Test): 0.23912908136844635\n",
      "Epoch 5388/10000: L(Train): 0.2664884328842163; L(Test): 0.23827427625656128\n",
      "Epoch 5389/10000: L(Train): 0.26273369789123535; L(Test): 0.24050523340702057\n",
      "Epoch 5390/10000: L(Train): 0.2562344968318939; L(Test): 0.23931674659252167\n",
      "Epoch 5391/10000: L(Train): 0.25865426659584045; L(Test): 0.23861993849277496\n",
      "Epoch 5392/10000: L(Train): 0.26911070942878723; L(Test): 0.23915216326713562\n",
      "Epoch 5393/10000: L(Train): 0.27000507712364197; L(Test): 0.2409118264913559\n",
      "Epoch 5394/10000: L(Train): 0.2596008777618408; L(Test): 0.23959317803382874\n",
      "Epoch 5395/10000: L(Train): 0.26737186312675476; L(Test): 0.23787258565425873\n",
      "Epoch 5396/10000: L(Train): 0.2656673491001129; L(Test): 0.23992028832435608\n",
      "Epoch 5397/10000: L(Train): 0.2542727291584015; L(Test): 0.24110384285449982\n",
      "Epoch 5398/10000: L(Train): 0.24187566339969635; L(Test): 0.23969857394695282\n",
      "Epoch 5399/10000: L(Train): 0.2795471251010895; L(Test): 0.23926453292369843\n",
      "Epoch 5400/10000: L(Train): 0.26369670033454895; L(Test): 0.24056607484817505\n",
      "Epoch 5401/10000: L(Train): 0.25697019696235657; L(Test): 0.24107778072357178\n",
      "Epoch 5402/10000: L(Train): 0.2519865334033966; L(Test): 0.23991858959197998\n",
      "Epoch 5403/10000: L(Train): 0.26495781540870667; L(Test): 0.2390953153371811\n",
      "Epoch 5404/10000: L(Train): 0.2631336748600006; L(Test): 0.23796382546424866\n",
      "Epoch 5405/10000: L(Train): 0.2675846517086029; L(Test): 0.23753230273723602\n",
      "Epoch 5406/10000: L(Train): 0.2768745422363281; L(Test): 0.238107368350029\n",
      "Epoch 5407/10000: L(Train): 0.2597145140171051; L(Test): 0.23812678456306458\n",
      "Epoch 5408/10000: L(Train): 0.25210297107696533; L(Test): 0.2382514625787735\n",
      "Epoch 5409/10000: L(Train): 0.2802421450614929; L(Test): 0.23892906308174133\n",
      "Epoch 5410/10000: L(Train): 0.2628122568130493; L(Test): 0.2393452674150467\n",
      "Epoch 5411/10000: L(Train): 0.26482897996902466; L(Test): 0.23809799551963806\n",
      "Epoch 5412/10000: L(Train): 0.25209343433380127; L(Test): 0.23904861509799957\n",
      "Epoch 5413/10000: L(Train): 0.256661593914032; L(Test): 0.23928755521774292\n",
      "Epoch 5414/10000: L(Train): 0.2609676718711853; L(Test): 0.24026769399642944\n",
      "Epoch 5415/10000: L(Train): 0.26129278540611267; L(Test): 0.2409103512763977\n",
      "Epoch 5416/10000: L(Train): 0.26409029960632324; L(Test): 0.2401852309703827\n",
      "Epoch 5417/10000: L(Train): 0.2533424198627472; L(Test): 0.2385776787996292\n",
      "Epoch 5418/10000: L(Train): 0.2627852261066437; L(Test): 0.2382364571094513\n",
      "Epoch 5419/10000: L(Train): 0.25808829069137573; L(Test): 0.23798920214176178\n",
      "Epoch 5420/10000: L(Train): 0.2741698920726776; L(Test): 0.2385920137166977\n",
      "Epoch 5421/10000: L(Train): 0.257643461227417; L(Test): 0.2387787401676178\n",
      "Epoch 5422/10000: L(Train): 0.2649585008621216; L(Test): 0.2379380315542221\n",
      "Epoch 5423/10000: L(Train): 0.2519283890724182; L(Test): 0.23810772597789764\n",
      "Epoch 5424/10000: L(Train): 0.26765698194503784; L(Test): 0.23858705163002014\n",
      "Epoch 5425/10000: L(Train): 0.26062512397766113; L(Test): 0.23833149671554565\n",
      "Epoch 5426/10000: L(Train): 0.2483639121055603; L(Test): 0.23867595195770264\n",
      "Epoch 5427/10000: L(Train): 0.24448271095752716; L(Test): 0.23864775896072388\n",
      "Epoch 5428/10000: L(Train): 0.26802030205726624; L(Test): 0.23885037004947662\n",
      "Epoch 5429/10000: L(Train): 0.26353034377098083; L(Test): 0.23897580802440643\n",
      "Epoch 5430/10000: L(Train): 0.25840818881988525; L(Test): 0.23925143480300903\n",
      "Epoch 5431/10000: L(Train): 0.25916337966918945; L(Test): 0.23967939615249634\n",
      "Epoch 5432/10000: L(Train): 0.25847136974334717; L(Test): 0.2383529245853424\n",
      "Epoch 5433/10000: L(Train): 0.268846720457077; L(Test): 0.23730914294719696\n",
      "Epoch 5434/10000: L(Train): 0.25337156653404236; L(Test): 0.23760010302066803\n",
      "Epoch 5435/10000: L(Train): 0.25787436962127686; L(Test): 0.2376292645931244\n",
      "Epoch 5436/10000: L(Train): 0.24128130078315735; L(Test): 0.2375938892364502\n",
      "Epoch 5437/10000: L(Train): 0.26389771699905396; L(Test): 0.236991286277771\n",
      "Epoch 5438/10000: L(Train): 0.2634471654891968; L(Test): 0.23688346147537231\n",
      "Epoch 5439/10000: L(Train): 0.27031540870666504; L(Test): 0.2383553832769394\n",
      "Epoch 5440/10000: L(Train): 0.2538449764251709; L(Test): 0.23872573673725128\n",
      "Epoch 5441/10000: L(Train): 0.24882584810256958; L(Test): 0.23698672652244568\n",
      "Epoch 5442/10000: L(Train): 0.2654874622821808; L(Test): 0.23736055195331573\n",
      "Epoch 5443/10000: L(Train): 0.2530231177806854; L(Test): 0.2386028915643692\n",
      "Epoch 5444/10000: L(Train): 0.26772791147232056; L(Test): 0.237837553024292\n",
      "Epoch 5445/10000: L(Train): 0.2723759710788727; L(Test): 0.23777298629283905\n",
      "Epoch 5446/10000: L(Train): 0.25055137276649475; L(Test): 0.23900476098060608\n",
      "Epoch 5447/10000: L(Train): 0.25834378600120544; L(Test): 0.23716412484645844\n",
      "Epoch 5448/10000: L(Train): 0.26040616631507874; L(Test): 0.2378259152173996\n",
      "Epoch 5449/10000: L(Train): 0.2780373692512512; L(Test): 0.23784413933753967\n",
      "Epoch 5450/10000: L(Train): 0.2533327043056488; L(Test): 0.23708680272102356\n",
      "Epoch 5451/10000: L(Train): 0.26530492305755615; L(Test): 0.23823896050453186\n",
      "Epoch 5452/10000: L(Train): 0.2610851526260376; L(Test): 0.2390063852071762\n",
      "Epoch 5453/10000: L(Train): 0.28291213512420654; L(Test): 0.23780420422554016\n",
      "Epoch 5454/10000: L(Train): 0.25648245215415955; L(Test): 0.23810210824012756\n",
      "Epoch 5455/10000: L(Train): 0.26152172684669495; L(Test): 0.2385234385728836\n",
      "Epoch 5456/10000: L(Train): 0.2664518654346466; L(Test): 0.23781061172485352\n",
      "Epoch 5457/10000: L(Train): 0.26302769780158997; L(Test): 0.237643301486969\n",
      "Epoch 5458/10000: L(Train): 0.26473531126976013; L(Test): 0.23748038709163666\n",
      "Epoch 5459/10000: L(Train): 0.27785375714302063; L(Test): 0.2368026077747345\n",
      "Epoch 5460/10000: L(Train): 0.2731393873691559; L(Test): 0.23634320497512817\n",
      "Epoch 5461/10000: L(Train): 0.25568491220474243; L(Test): 0.2367745339870453\n",
      "Epoch 5462/10000: L(Train): 0.2639688551425934; L(Test): 0.236494779586792\n",
      "Epoch 5463/10000: L(Train): 0.2507113516330719; L(Test): 0.2383139580488205\n",
      "Epoch 5464/10000: L(Train): 0.25666114687919617; L(Test): 0.23838071525096893\n",
      "Epoch 5465/10000: L(Train): 0.2589099705219269; L(Test): 0.2389184981584549\n",
      "Epoch 5466/10000: L(Train): 0.255562424659729; L(Test): 0.2393077164888382\n",
      "Epoch 5467/10000: L(Train): 0.2648142874240875; L(Test): 0.24063916504383087\n",
      "Epoch 5468/10000: L(Train): 0.27258244156837463; L(Test): 0.23919622600078583\n",
      "Epoch 5469/10000: L(Train): 0.2603432834148407; L(Test): 0.2380867451429367\n",
      "Epoch 5470/10000: L(Train): 0.2558477222919464; L(Test): 0.2391943484544754\n",
      "Epoch 5471/10000: L(Train): 0.2661100924015045; L(Test): 0.2401610016822815\n",
      "Epoch 5472/10000: L(Train): 0.25858452916145325; L(Test): 0.23887819051742554\n",
      "Epoch 5473/10000: L(Train): 0.26459452509880066; L(Test): 0.2388138324022293\n",
      "Epoch 5474/10000: L(Train): 0.2629852592945099; L(Test): 0.2376878410577774\n",
      "Epoch 5475/10000: L(Train): 0.260274201631546; L(Test): 0.23888613283634186\n",
      "Epoch 5476/10000: L(Train): 0.24705758690834045; L(Test): 0.23808427155017853\n",
      "Epoch 5477/10000: L(Train): 0.2534162998199463; L(Test): 0.23720595240592957\n",
      "Epoch 5478/10000: L(Train): 0.2695314884185791; L(Test): 0.23744800686836243\n",
      "Epoch 5479/10000: L(Train): 0.2565830945968628; L(Test): 0.23875145614147186\n",
      "Epoch 5480/10000: L(Train): 0.2636409401893616; L(Test): 0.23809517920017242\n",
      "Epoch 5481/10000: L(Train): 0.26325130462646484; L(Test): 0.23738974332809448\n",
      "Epoch 5482/10000: L(Train): 0.2708700895309448; L(Test): 0.23861168324947357\n",
      "Epoch 5483/10000: L(Train): 0.2656737267971039; L(Test): 0.23833589255809784\n",
      "Epoch 5484/10000: L(Train): 0.271195650100708; L(Test): 0.24120818078517914\n",
      "Epoch 5485/10000: L(Train): 0.26401954889297485; L(Test): 0.23761910200119019\n",
      "Epoch 5486/10000: L(Train): 0.26465609669685364; L(Test): 0.23703235387802124\n",
      "Epoch 5487/10000: L(Train): 0.26211610436439514; L(Test): 0.23682156205177307\n",
      "Epoch 5488/10000: L(Train): 0.2692582309246063; L(Test): 0.2419489324092865\n",
      "Epoch 5489/10000: L(Train): 0.26396048069000244; L(Test): 0.23828624188899994\n",
      "Epoch 5490/10000: L(Train): 0.26760920882225037; L(Test): 0.23846708238124847\n",
      "Epoch 5491/10000: L(Train): 0.2606182098388672; L(Test): 0.23715369403362274\n",
      "Epoch 5492/10000: L(Train): 0.257124662399292; L(Test): 0.23877565562725067\n",
      "Epoch 5493/10000: L(Train): 0.26826053857803345; L(Test): 0.24201013147830963\n",
      "Epoch 5494/10000: L(Train): 0.26788705587387085; L(Test): 0.2397342473268509\n",
      "Epoch 5495/10000: L(Train): 0.2571602761745453; L(Test): 0.2401447594165802\n",
      "Epoch 5496/10000: L(Train): 0.26021823287010193; L(Test): 0.24123746156692505\n",
      "Epoch 5497/10000: L(Train): 0.2657968997955322; L(Test): 0.24227038025856018\n",
      "Epoch 5498/10000: L(Train): 0.25868165493011475; L(Test): 0.2400478571653366\n",
      "Epoch 5499/10000: L(Train): 0.25676465034484863; L(Test): 0.2403140515089035\n",
      "Epoch 5500/10000: L(Train): 0.25911179184913635; L(Test): 0.2400520145893097\n",
      "Epoch 5501/10000: L(Train): 0.2552618980407715; L(Test): 0.24064227938652039\n",
      "Epoch 5502/10000: L(Train): 0.26307836174964905; L(Test): 0.24061688780784607\n",
      "Epoch 5503/10000: L(Train): 0.2604968249797821; L(Test): 0.24047909677028656\n",
      "Epoch 5504/10000: L(Train): 0.2603786885738373; L(Test): 0.2412233203649521\n",
      "Epoch 5505/10000: L(Train): 0.25303661823272705; L(Test): 0.2406357228755951\n",
      "Epoch 5506/10000: L(Train): 0.2529892921447754; L(Test): 0.24050667881965637\n",
      "Epoch 5507/10000: L(Train): 0.26450008153915405; L(Test): 0.2417447865009308\n",
      "Epoch 5508/10000: L(Train): 0.2501066327095032; L(Test): 0.2393367886543274\n",
      "Epoch 5509/10000: L(Train): 0.2555929720401764; L(Test): 0.23886939883232117\n",
      "Epoch 5510/10000: L(Train): 0.27059465646743774; L(Test): 0.23991557955741882\n",
      "Epoch 5511/10000: L(Train): 0.2553439140319824; L(Test): 0.24096325039863586\n",
      "Epoch 5512/10000: L(Train): 0.2612200081348419; L(Test): 0.2410205900669098\n",
      "Epoch 5513/10000: L(Train): 0.257783442735672; L(Test): 0.24086377024650574\n",
      "Epoch 5514/10000: L(Train): 0.2699437737464905; L(Test): 0.240624338388443\n",
      "Epoch 5515/10000: L(Train): 0.2737385630607605; L(Test): 0.23919229209423065\n",
      "Epoch 5516/10000: L(Train): 0.26898279786109924; L(Test): 0.2421884834766388\n",
      "Epoch 5517/10000: L(Train): 0.25847166776657104; L(Test): 0.2409176081418991\n",
      "Epoch 5518/10000: L(Train): 0.2662622928619385; L(Test): 0.24009031057357788\n",
      "Epoch 5519/10000: L(Train): 0.2524637281894684; L(Test): 0.24512645602226257\n",
      "Epoch 5520/10000: L(Train): 0.25647544860839844; L(Test): 0.2440231442451477\n",
      "Epoch 5521/10000: L(Train): 0.2613241374492645; L(Test): 0.24185489118099213\n",
      "Epoch 5522/10000: L(Train): 0.25260141491889954; L(Test): 0.24764005839824677\n",
      "Epoch 5523/10000: L(Train): 0.26949626207351685; L(Test): 0.24521726369857788\n",
      "Epoch 5524/10000: L(Train): 0.2610665261745453; L(Test): 0.2454504817724228\n",
      "Epoch 5525/10000: L(Train): 0.26505112648010254; L(Test): 0.24756701290607452\n",
      "Epoch 5526/10000: L(Train): 0.2829459011554718; L(Test): 0.2480171024799347\n",
      "Epoch 5527/10000: L(Train): 0.27879050374031067; L(Test): 0.24515275657176971\n",
      "Epoch 5528/10000: L(Train): 0.2492048591375351; L(Test): 0.24287351965904236\n",
      "Epoch 5529/10000: L(Train): 0.2637484669685364; L(Test): 0.24538500607013702\n",
      "Epoch 5530/10000: L(Train): 0.2684759497642517; L(Test): 0.24473869800567627\n",
      "Epoch 5531/10000: L(Train): 0.27603384852409363; L(Test): 0.2431764006614685\n",
      "Epoch 5532/10000: L(Train): 0.27642616629600525; L(Test): 0.24470114707946777\n",
      "Epoch 5533/10000: L(Train): 0.25168681144714355; L(Test): 0.24551044404506683\n",
      "Epoch 5534/10000: L(Train): 0.25189119577407837; L(Test): 0.24506187438964844\n",
      "Epoch 5535/10000: L(Train): 0.26683509349823; L(Test): 0.24319101870059967\n",
      "Epoch 5536/10000: L(Train): 0.2477511465549469; L(Test): 0.24340581893920898\n",
      "Epoch 5537/10000: L(Train): 0.2625342607498169; L(Test): 0.2437913715839386\n",
      "Epoch 5538/10000: L(Train): 0.24497517943382263; L(Test): 0.2436826527118683\n",
      "Epoch 5539/10000: L(Train): 0.27998897433280945; L(Test): 0.24488382041454315\n",
      "Epoch 5540/10000: L(Train): 0.2601807713508606; L(Test): 0.245713010430336\n",
      "Epoch 5541/10000: L(Train): 0.2607440650463104; L(Test): 0.2441401183605194\n",
      "Epoch 5542/10000: L(Train): 0.2628883421421051; L(Test): 0.24375294148921967\n",
      "Epoch 5543/10000: L(Train): 0.2698993682861328; L(Test): 0.24465934932231903\n",
      "Epoch 5544/10000: L(Train): 0.2593892216682434; L(Test): 0.24461399018764496\n",
      "Epoch 5545/10000: L(Train): 0.26398056745529175; L(Test): 0.24318808317184448\n",
      "Epoch 5546/10000: L(Train): 0.2692216634750366; L(Test): 0.24272114038467407\n",
      "Epoch 5547/10000: L(Train): 0.2664751410484314; L(Test): 0.24173736572265625\n",
      "Epoch 5548/10000: L(Train): 0.2593369483947754; L(Test): 0.24114346504211426\n",
      "Epoch 5549/10000: L(Train): 0.26631152629852295; L(Test): 0.24285225570201874\n",
      "Epoch 5550/10000: L(Train): 0.2625854015350342; L(Test): 0.2442169338464737\n",
      "Epoch 5551/10000: L(Train): 0.25049567222595215; L(Test): 0.24074915051460266\n",
      "Epoch 5552/10000: L(Train): 0.27665039896965027; L(Test): 0.2410230040550232\n",
      "Epoch 5553/10000: L(Train): 0.25985974073410034; L(Test): 0.23981468379497528\n",
      "Epoch 5554/10000: L(Train): 0.2654813230037689; L(Test): 0.2408445030450821\n",
      "Epoch 5555/10000: L(Train): 0.25256234407424927; L(Test): 0.24174904823303223\n",
      "Epoch 5556/10000: L(Train): 0.2604094445705414; L(Test): 0.23958253860473633\n",
      "Epoch 5557/10000: L(Train): 0.26066696643829346; L(Test): 0.2408960610628128\n",
      "Epoch 5558/10000: L(Train): 0.25118106603622437; L(Test): 0.2392520308494568\n",
      "Epoch 5559/10000: L(Train): 0.25687727332115173; L(Test): 0.24136210978031158\n",
      "Epoch 5560/10000: L(Train): 0.2685903012752533; L(Test): 0.24185192584991455\n",
      "Epoch 5561/10000: L(Train): 0.2564733624458313; L(Test): 0.23763486742973328\n",
      "Epoch 5562/10000: L(Train): 0.25691282749176025; L(Test): 0.24074815213680267\n",
      "Epoch 5563/10000: L(Train): 0.2631423771381378; L(Test): 0.23988783359527588\n",
      "Epoch 5564/10000: L(Train): 0.25608283281326294; L(Test): 0.24197439849376678\n",
      "Epoch 5565/10000: L(Train): 0.26228097081184387; L(Test): 0.2424730360507965\n",
      "Epoch 5566/10000: L(Train): 0.26798638701438904; L(Test): 0.2403508722782135\n",
      "Epoch 5567/10000: L(Train): 0.2629585862159729; L(Test): 0.24050432443618774\n",
      "Epoch 5568/10000: L(Train): 0.2775594890117645; L(Test): 0.2392289787530899\n",
      "Epoch 5569/10000: L(Train): 0.26494717597961426; L(Test): 0.2410994917154312\n",
      "Epoch 5570/10000: L(Train): 0.25802621245384216; L(Test): 0.2408517748117447\n",
      "Epoch 5571/10000: L(Train): 0.26309850811958313; L(Test): 0.2395445555448532\n",
      "Epoch 5572/10000: L(Train): 0.251527339220047; L(Test): 0.23984214663505554\n",
      "Epoch 5573/10000: L(Train): 0.25796055793762207; L(Test): 0.2394091635942459\n",
      "Epoch 5574/10000: L(Train): 0.2543873190879822; L(Test): 0.23929829895496368\n",
      "Epoch 5575/10000: L(Train): 0.24308539927005768; L(Test): 0.2405872493982315\n",
      "Epoch 5576/10000: L(Train): 0.26330772042274475; L(Test): 0.2380835860967636\n",
      "Epoch 5577/10000: L(Train): 0.2559964060783386; L(Test): 0.238615483045578\n",
      "Epoch 5578/10000: L(Train): 0.26830172538757324; L(Test): 0.23753994703292847\n",
      "Epoch 5579/10000: L(Train): 0.2632526755332947; L(Test): 0.2381364107131958\n",
      "Epoch 5580/10000: L(Train): 0.25943684577941895; L(Test): 0.2382698506116867\n",
      "Epoch 5581/10000: L(Train): 0.2650711238384247; L(Test): 0.23762257397174835\n",
      "Epoch 5582/10000: L(Train): 0.2710922658443451; L(Test): 0.2379700243473053\n",
      "Epoch 5583/10000: L(Train): 0.26638907194137573; L(Test): 0.23741193115711212\n",
      "Epoch 5584/10000: L(Train): 0.2588454782962799; L(Test): 0.23967842757701874\n",
      "Epoch 5585/10000: L(Train): 0.2565760612487793; L(Test): 0.23700974881649017\n",
      "Epoch 5586/10000: L(Train): 0.2517901659011841; L(Test): 0.23746609687805176\n",
      "Epoch 5587/10000: L(Train): 0.2577107548713684; L(Test): 0.23819786310195923\n",
      "Epoch 5588/10000: L(Train): 0.25673162937164307; L(Test): 0.23763085901737213\n",
      "Epoch 5589/10000: L(Train): 0.25910815596580505; L(Test): 0.2375614196062088\n",
      "Epoch 5590/10000: L(Train): 0.25683706998825073; L(Test): 0.23759222030639648\n",
      "Epoch 5591/10000: L(Train): 0.2641736567020416; L(Test): 0.23661254346370697\n",
      "Epoch 5592/10000: L(Train): 0.2668081223964691; L(Test): 0.23620054125785828\n",
      "Epoch 5593/10000: L(Train): 0.25534728169441223; L(Test): 0.23661446571350098\n",
      "Epoch 5594/10000: L(Train): 0.262976735830307; L(Test): 0.23644015192985535\n",
      "Epoch 5595/10000: L(Train): 0.261207640171051; L(Test): 0.23551413416862488\n",
      "Epoch 5596/10000: L(Train): 0.26048916578292847; L(Test): 0.23624558746814728\n",
      "Epoch 5597/10000: L(Train): 0.25676286220550537; L(Test): 0.2374679446220398\n",
      "Epoch 5598/10000: L(Train): 0.2620578706264496; L(Test): 0.23593328893184662\n",
      "Epoch 5599/10000: L(Train): 0.25718867778778076; L(Test): 0.23550254106521606\n",
      "Epoch 5600/10000: L(Train): 0.26226115226745605; L(Test): 0.23608581721782684\n",
      "Epoch 5601/10000: L(Train): 0.26141512393951416; L(Test): 0.23623405396938324\n",
      "Epoch 5602/10000: L(Train): 0.2865903675556183; L(Test): 0.23680509626865387\n",
      "Epoch 5603/10000: L(Train): 0.2672524154186249; L(Test): 0.23741570115089417\n",
      "Epoch 5604/10000: L(Train): 0.26172739267349243; L(Test): 0.23740816116333008\n",
      "Epoch 5605/10000: L(Train): 0.2601447105407715; L(Test): 0.23729220032691956\n",
      "Epoch 5606/10000: L(Train): 0.26292407512664795; L(Test): 0.23703372478485107\n",
      "Epoch 5607/10000: L(Train): 0.26146742701530457; L(Test): 0.23854298889636993\n",
      "Epoch 5608/10000: L(Train): 0.2709728479385376; L(Test): 0.23851414024829865\n",
      "Epoch 5609/10000: L(Train): 0.26104187965393066; L(Test): 0.23822280764579773\n",
      "Epoch 5610/10000: L(Train): 0.25593575835227966; L(Test): 0.23986609280109406\n",
      "Epoch 5611/10000: L(Train): 0.24718087911605835; L(Test): 0.24129009246826172\n",
      "Epoch 5612/10000: L(Train): 0.25840210914611816; L(Test): 0.23903128504753113\n",
      "Epoch 5613/10000: L(Train): 0.2512509226799011; L(Test): 0.24024660885334015\n",
      "Epoch 5614/10000: L(Train): 0.2671676576137543; L(Test): 0.2407248467206955\n",
      "Epoch 5615/10000: L(Train): 0.25889766216278076; L(Test): 0.23885232210159302\n",
      "Epoch 5616/10000: L(Train): 0.2742640972137451; L(Test): 0.24009062349796295\n",
      "Epoch 5617/10000: L(Train): 0.2635684013366699; L(Test): 0.23927611112594604\n",
      "Epoch 5618/10000: L(Train): 0.2560276389122009; L(Test): 0.239458367228508\n",
      "Epoch 5619/10000: L(Train): 0.24277596175670624; L(Test): 0.23934562504291534\n",
      "Epoch 5620/10000: L(Train): 0.25005897879600525; L(Test): 0.23864346742630005\n",
      "Epoch 5621/10000: L(Train): 0.264096736907959; L(Test): 0.23899318277835846\n",
      "Epoch 5622/10000: L(Train): 0.25713086128234863; L(Test): 0.23924660682678223\n",
      "Epoch 5623/10000: L(Train): 0.2632962763309479; L(Test): 0.2396017462015152\n",
      "Epoch 5624/10000: L(Train): 0.2573908567428589; L(Test): 0.23968510329723358\n",
      "Epoch 5625/10000: L(Train): 0.2802521586418152; L(Test): 0.23870012164115906\n",
      "Epoch 5626/10000: L(Train): 0.26853999495506287; L(Test): 0.23759260773658752\n",
      "Epoch 5627/10000: L(Train): 0.2587887942790985; L(Test): 0.24012137949466705\n",
      "Epoch 5628/10000: L(Train): 0.25300195813179016; L(Test): 0.2403775155544281\n",
      "Epoch 5629/10000: L(Train): 0.24888087809085846; L(Test): 0.23894977569580078\n",
      "Epoch 5630/10000: L(Train): 0.2544344365596771; L(Test): 0.24075256288051605\n",
      "Epoch 5631/10000: L(Train): 0.2628162205219269; L(Test): 0.24117743968963623\n",
      "Epoch 5632/10000: L(Train): 0.26359179615974426; L(Test): 0.23956462740898132\n",
      "Epoch 5633/10000: L(Train): 0.26453837752342224; L(Test): 0.240059033036232\n",
      "Epoch 5634/10000: L(Train): 0.27494075894355774; L(Test): 0.24017333984375\n",
      "Epoch 5635/10000: L(Train): 0.2668510377407074; L(Test): 0.23889796435832977\n",
      "Epoch 5636/10000: L(Train): 0.2642360329627991; L(Test): 0.2401205599308014\n",
      "Epoch 5637/10000: L(Train): 0.2718336880207062; L(Test): 0.24084311723709106\n",
      "Epoch 5638/10000: L(Train): 0.2753651738166809; L(Test): 0.23910783231258392\n",
      "Epoch 5639/10000: L(Train): 0.2662406861782074; L(Test): 0.23924019932746887\n",
      "Epoch 5640/10000: L(Train): 0.27003058791160583; L(Test): 0.23953934013843536\n",
      "Epoch 5641/10000: L(Train): 0.2716119885444641; L(Test): 0.23876658082008362\n",
      "Epoch 5642/10000: L(Train): 0.26238271594047546; L(Test): 0.2387959212064743\n",
      "Epoch 5643/10000: L(Train): 0.2674504816532135; L(Test): 0.23864078521728516\n",
      "Epoch 5644/10000: L(Train): 0.27698424458503723; L(Test): 0.2386183887720108\n",
      "Epoch 5645/10000: L(Train): 0.25176164507865906; L(Test): 0.23879100382328033\n",
      "Epoch 5646/10000: L(Train): 0.2558835446834564; L(Test): 0.24000206589698792\n",
      "Epoch 5647/10000: L(Train): 0.2560518980026245; L(Test): 0.2383107841014862\n",
      "Epoch 5648/10000: L(Train): 0.2519261837005615; L(Test): 0.23897932469844818\n",
      "Epoch 5649/10000: L(Train): 0.26703208684921265; L(Test): 0.23927640914916992\n",
      "Epoch 5650/10000: L(Train): 0.2590591013431549; L(Test): 0.2386177033185959\n",
      "Epoch 5651/10000: L(Train): 0.2549019455909729; L(Test): 0.23992133140563965\n",
      "Epoch 5652/10000: L(Train): 0.2714380919933319; L(Test): 0.23953959345817566\n",
      "Epoch 5653/10000: L(Train): 0.2586422264575958; L(Test): 0.2377946823835373\n",
      "Epoch 5654/10000: L(Train): 0.2672525644302368; L(Test): 0.23709359765052795\n",
      "Epoch 5655/10000: L(Train): 0.25427931547164917; L(Test): 0.23783192038536072\n",
      "Epoch 5656/10000: L(Train): 0.264242559671402; L(Test): 0.23734238743782043\n",
      "Epoch 5657/10000: L(Train): 0.2595796287059784; L(Test): 0.23905061185359955\n",
      "Epoch 5658/10000: L(Train): 0.26171010732650757; L(Test): 0.23870952427387238\n",
      "Epoch 5659/10000: L(Train): 0.28763705492019653; L(Test): 0.23803211748600006\n",
      "Epoch 5660/10000: L(Train): 0.2527333199977875; L(Test): 0.2405325025320053\n",
      "Epoch 5661/10000: L(Train): 0.2710193693637848; L(Test): 0.2391989380121231\n",
      "Epoch 5662/10000: L(Train): 0.25316891074180603; L(Test): 0.2393054962158203\n",
      "Epoch 5663/10000: L(Train): 0.26748621463775635; L(Test): 0.24023321270942688\n",
      "Epoch 5664/10000: L(Train): 0.26720669865608215; L(Test): 0.23998086154460907\n",
      "Epoch 5665/10000: L(Train): 0.25986248254776; L(Test): 0.23906145989894867\n",
      "Epoch 5666/10000: L(Train): 0.2561586797237396; L(Test): 0.23896819353103638\n",
      "Epoch 5667/10000: L(Train): 0.25120893120765686; L(Test): 0.23770524561405182\n",
      "Epoch 5668/10000: L(Train): 0.2576149106025696; L(Test): 0.23725634813308716\n",
      "Epoch 5669/10000: L(Train): 0.2499161660671234; L(Test): 0.23915989696979523\n",
      "Epoch 5670/10000: L(Train): 0.2742885649204254; L(Test): 0.23822908103466034\n",
      "Epoch 5671/10000: L(Train): 0.2658568024635315; L(Test): 0.23761425912380219\n",
      "Epoch 5672/10000: L(Train): 0.27509158849716187; L(Test): 0.23942700028419495\n",
      "Epoch 5673/10000: L(Train): 0.252238005399704; L(Test): 0.23945149779319763\n",
      "Epoch 5674/10000: L(Train): 0.26359206438064575; L(Test): 0.24022723734378815\n",
      "Epoch 5675/10000: L(Train): 0.2650070786476135; L(Test): 0.23918487131595612\n",
      "Epoch 5676/10000: L(Train): 0.25450631976127625; L(Test): 0.2393067330121994\n",
      "Epoch 5677/10000: L(Train): 0.27016982436180115; L(Test): 0.2381734400987625\n",
      "Epoch 5678/10000: L(Train): 0.2654717266559601; L(Test): 0.23892389237880707\n",
      "Epoch 5679/10000: L(Train): 0.24935881793498993; L(Test): 0.24073272943496704\n",
      "Epoch 5680/10000: L(Train): 0.2578405439853668; L(Test): 0.23941455781459808\n",
      "Epoch 5681/10000: L(Train): 0.2540299594402313; L(Test): 0.23806095123291016\n",
      "Epoch 5682/10000: L(Train): 0.2564316987991333; L(Test): 0.23793886601924896\n",
      "Epoch 5683/10000: L(Train): 0.24442681670188904; L(Test): 0.23783311247825623\n",
      "Epoch 5684/10000: L(Train): 0.26014092564582825; L(Test): 0.23805008828639984\n",
      "Epoch 5685/10000: L(Train): 0.2644072473049164; L(Test): 0.23761403560638428\n",
      "Epoch 5686/10000: L(Train): 0.25043392181396484; L(Test): 0.23691576719284058\n",
      "Epoch 5687/10000: L(Train): 0.2623603343963623; L(Test): 0.2370487004518509\n",
      "Epoch 5688/10000: L(Train): 0.2532956004142761; L(Test): 0.2384016215801239\n",
      "Epoch 5689/10000: L(Train): 0.2661326825618744; L(Test): 0.23728226125240326\n",
      "Epoch 5690/10000: L(Train): 0.26637253165245056; L(Test): 0.2369479089975357\n",
      "Epoch 5691/10000: L(Train): 0.2503518760204315; L(Test): 0.2368123084306717\n",
      "Epoch 5692/10000: L(Train): 0.2608179748058319; L(Test): 0.23675483465194702\n",
      "Epoch 5693/10000: L(Train): 0.2565271854400635; L(Test): 0.2382284253835678\n",
      "Epoch 5694/10000: L(Train): 0.25309890508651733; L(Test): 0.23729011416435242\n",
      "Epoch 5695/10000: L(Train): 0.25897476077079773; L(Test): 0.2379176765680313\n",
      "Epoch 5696/10000: L(Train): 0.26998084783554077; L(Test): 0.2381976693868637\n",
      "Epoch 5697/10000: L(Train): 0.27005791664123535; L(Test): 0.23701010644435883\n",
      "Epoch 5698/10000: L(Train): 0.28166869282722473; L(Test): 0.2373097836971283\n",
      "Epoch 5699/10000: L(Train): 0.26562634110450745; L(Test): 0.24104931950569153\n",
      "Epoch 5700/10000: L(Train): 0.25227034091949463; L(Test): 0.23815518617630005\n",
      "Epoch 5701/10000: L(Train): 0.2622668445110321; L(Test): 0.23851968348026276\n",
      "Epoch 5702/10000: L(Train): 0.27568939328193665; L(Test): 0.239388570189476\n",
      "Epoch 5703/10000: L(Train): 0.28041863441467285; L(Test): 0.2387610524892807\n",
      "Epoch 5704/10000: L(Train): 0.2518022358417511; L(Test): 0.23940499126911163\n",
      "Epoch 5705/10000: L(Train): 0.2635098993778229; L(Test): 0.23910672962665558\n",
      "Epoch 5706/10000: L(Train): 0.26027244329452515; L(Test): 0.2414904087781906\n",
      "Epoch 5707/10000: L(Train): 0.26044315099716187; L(Test): 0.23908084630966187\n",
      "Epoch 5708/10000: L(Train): 0.2659437656402588; L(Test): 0.23941385746002197\n",
      "Epoch 5709/10000: L(Train): 0.25892946124076843; L(Test): 0.23997962474822998\n",
      "Epoch 5710/10000: L(Train): 0.26354309916496277; L(Test): 0.23960062861442566\n",
      "Epoch 5711/10000: L(Train): 0.27343034744262695; L(Test): 0.23843473196029663\n",
      "Epoch 5712/10000: L(Train): 0.27178436517715454; L(Test): 0.2400447577238083\n",
      "Epoch 5713/10000: L(Train): 0.2581866383552551; L(Test): 0.24163663387298584\n",
      "Epoch 5714/10000: L(Train): 0.28073328733444214; L(Test): 0.23837456107139587\n",
      "Epoch 5715/10000: L(Train): 0.24763281643390656; L(Test): 0.2379428744316101\n",
      "Epoch 5716/10000: L(Train): 0.2653730809688568; L(Test): 0.23990017175674438\n",
      "Epoch 5717/10000: L(Train): 0.26047956943511963; L(Test): 0.23817585408687592\n",
      "Epoch 5718/10000: L(Train): 0.25873294472694397; L(Test): 0.2375773787498474\n",
      "Epoch 5719/10000: L(Train): 0.2631630599498749; L(Test): 0.24168750643730164\n",
      "Epoch 5720/10000: L(Train): 0.25488969683647156; L(Test): 0.24160338938236237\n",
      "Epoch 5721/10000: L(Train): 0.26889893412590027; L(Test): 0.2382340431213379\n",
      "Epoch 5722/10000: L(Train): 0.24887873232364655; L(Test): 0.23947744071483612\n",
      "Epoch 5723/10000: L(Train): 0.27072346210479736; L(Test): 0.2424951046705246\n",
      "Epoch 5724/10000: L(Train): 0.2518001198768616; L(Test): 0.24102583527565002\n",
      "Epoch 5725/10000: L(Train): 0.2622307538986206; L(Test): 0.24094638228416443\n",
      "Epoch 5726/10000: L(Train): 0.2445535808801651; L(Test): 0.2451162040233612\n",
      "Epoch 5727/10000: L(Train): 0.2618601620197296; L(Test): 0.24277599155902863\n",
      "Epoch 5728/10000: L(Train): 0.2702661156654358; L(Test): 0.24829640984535217\n",
      "Epoch 5729/10000: L(Train): 0.26550865173339844; L(Test): 0.2525761127471924\n",
      "Epoch 5730/10000: L(Train): 0.2729284167289734; L(Test): 0.24933141469955444\n",
      "Epoch 5731/10000: L(Train): 0.2770553529262543; L(Test): 0.24611711502075195\n",
      "Epoch 5732/10000: L(Train): 0.27057498693466187; L(Test): 0.24860471487045288\n",
      "Epoch 5733/10000: L(Train): 0.26885318756103516; L(Test): 0.24917511641979218\n",
      "Epoch 5734/10000: L(Train): 0.28968408703804016; L(Test): 0.24624568223953247\n",
      "Epoch 5735/10000: L(Train): 0.26485753059387207; L(Test): 0.24607214331626892\n",
      "Epoch 5736/10000: L(Train): 0.26294583082199097; L(Test): 0.24605463445186615\n",
      "Epoch 5737/10000: L(Train): 0.25815266370773315; L(Test): 0.24715985357761383\n",
      "Epoch 5738/10000: L(Train): 0.2606036961078644; L(Test): 0.24645255506038666\n",
      "Epoch 5739/10000: L(Train): 0.26498886942863464; L(Test): 0.24563121795654297\n",
      "Epoch 5740/10000: L(Train): 0.264232337474823; L(Test): 0.24665163457393646\n",
      "Epoch 5741/10000: L(Train): 0.2827646732330322; L(Test): 0.2460816353559494\n",
      "Epoch 5742/10000: L(Train): 0.27073782682418823; L(Test): 0.24326656758785248\n",
      "Epoch 5743/10000: L(Train): 0.26063448190689087; L(Test): 0.24372798204421997\n",
      "Epoch 5744/10000: L(Train): 0.2730354368686676; L(Test): 0.24446332454681396\n",
      "Epoch 5745/10000: L(Train): 0.25947901606559753; L(Test): 0.24377992749214172\n",
      "Epoch 5746/10000: L(Train): 0.2732258141040802; L(Test): 0.24198977649211884\n",
      "Epoch 5747/10000: L(Train): 0.2710999548435211; L(Test): 0.24240586161613464\n",
      "Epoch 5748/10000: L(Train): 0.24625274538993835; L(Test): 0.24175821244716644\n",
      "Epoch 5749/10000: L(Train): 0.27053970098495483; L(Test): 0.24059748649597168\n",
      "Epoch 5750/10000: L(Train): 0.2501065135002136; L(Test): 0.24017001688480377\n",
      "Epoch 5751/10000: L(Train): 0.2637445032596588; L(Test): 0.23977512121200562\n",
      "Epoch 5752/10000: L(Train): 0.2679213583469391; L(Test): 0.23964960873126984\n",
      "Epoch 5753/10000: L(Train): 0.2503799498081207; L(Test): 0.23972077667713165\n",
      "Epoch 5754/10000: L(Train): 0.24837638437747955; L(Test): 0.24037042260169983\n",
      "Epoch 5755/10000: L(Train): 0.2718551456928253; L(Test): 0.24101197719573975\n",
      "Epoch 5756/10000: L(Train): 0.25090697407722473; L(Test): 0.24070946872234344\n",
      "Epoch 5757/10000: L(Train): 0.25238823890686035; L(Test): 0.23952561616897583\n",
      "Epoch 5758/10000: L(Train): 0.2631152272224426; L(Test): 0.23970471322536469\n",
      "Epoch 5759/10000: L(Train): 0.2615373432636261; L(Test): 0.24102535843849182\n",
      "Epoch 5760/10000: L(Train): 0.2546617388725281; L(Test): 0.24047835171222687\n",
      "Epoch 5761/10000: L(Train): 0.25952595472335815; L(Test): 0.23903201520442963\n",
      "Epoch 5762/10000: L(Train): 0.26568764448165894; L(Test): 0.24030974507331848\n",
      "Epoch 5763/10000: L(Train): 0.26051828265190125; L(Test): 0.23953959345817566\n",
      "Epoch 5764/10000: L(Train): 0.2522397041320801; L(Test): 0.23860003054141998\n",
      "Epoch 5765/10000: L(Train): 0.2802426218986511; L(Test): 0.24063941836357117\n",
      "Epoch 5766/10000: L(Train): 0.25289809703826904; L(Test): 0.2387831211090088\n",
      "Epoch 5767/10000: L(Train): 0.25228235125541687; L(Test): 0.24016812443733215\n",
      "Epoch 5768/10000: L(Train): 0.25036874413490295; L(Test): 0.2394922971725464\n",
      "Epoch 5769/10000: L(Train): 0.2774723172187805; L(Test): 0.23947076499462128\n",
      "Epoch 5770/10000: L(Train): 0.2530754804611206; L(Test): 0.24075251817703247\n",
      "Epoch 5771/10000: L(Train): 0.26350516080856323; L(Test): 0.2416064739227295\n",
      "Epoch 5772/10000: L(Train): 0.2627914547920227; L(Test): 0.2397288978099823\n",
      "Epoch 5773/10000: L(Train): 0.28213170170783997; L(Test): 0.2385130524635315\n",
      "Epoch 5774/10000: L(Train): 0.24562668800354004; L(Test): 0.23789824545383453\n",
      "Epoch 5775/10000: L(Train): 0.26407063007354736; L(Test): 0.23895788192749023\n",
      "Epoch 5776/10000: L(Train): 0.26752206683158875; L(Test): 0.23878811299800873\n",
      "Epoch 5777/10000: L(Train): 0.2680743634700775; L(Test): 0.23862208425998688\n",
      "Epoch 5778/10000: L(Train): 0.2626016139984131; L(Test): 0.23783324658870697\n",
      "Epoch 5779/10000: L(Train): 0.24929921329021454; L(Test): 0.238044872879982\n",
      "Epoch 5780/10000: L(Train): 0.2628461420536041; L(Test): 0.23845824599266052\n",
      "Epoch 5781/10000: L(Train): 0.260795533657074; L(Test): 0.2386694997549057\n",
      "Epoch 5782/10000: L(Train): 0.2806493937969208; L(Test): 0.2382766604423523\n",
      "Epoch 5783/10000: L(Train): 0.25115036964416504; L(Test): 0.2385590374469757\n",
      "Epoch 5784/10000: L(Train): 0.2633739113807678; L(Test): 0.2379324585199356\n",
      "Epoch 5785/10000: L(Train): 0.27492794394493103; L(Test): 0.23799508810043335\n",
      "Epoch 5786/10000: L(Train): 0.25954464077949524; L(Test): 0.23779776692390442\n",
      "Epoch 5787/10000: L(Train): 0.26003116369247437; L(Test): 0.2373736947774887\n",
      "Epoch 5788/10000: L(Train): 0.2780036926269531; L(Test): 0.23781487345695496\n",
      "Epoch 5789/10000: L(Train): 0.27902230620384216; L(Test): 0.23790517449378967\n",
      "Epoch 5790/10000: L(Train): 0.2728902995586395; L(Test): 0.23724235594272614\n",
      "Epoch 5791/10000: L(Train): 0.25575339794158936; L(Test): 0.23766230046749115\n",
      "Epoch 5792/10000: L(Train): 0.26816239953041077; L(Test): 0.2369125634431839\n",
      "Epoch 5793/10000: L(Train): 0.26247087121009827; L(Test): 0.23818707466125488\n",
      "Epoch 5794/10000: L(Train): 0.25198182463645935; L(Test): 0.23739886283874512\n",
      "Epoch 5795/10000: L(Train): 0.25638866424560547; L(Test): 0.2378738820552826\n",
      "Epoch 5796/10000: L(Train): 0.2660563290119171; L(Test): 0.23791834712028503\n",
      "Epoch 5797/10000: L(Train): 0.2531396746635437; L(Test): 0.23655882477760315\n",
      "Epoch 5798/10000: L(Train): 0.2543758153915405; L(Test): 0.2365226447582245\n",
      "Epoch 5799/10000: L(Train): 0.24464403092861176; L(Test): 0.23703022301197052\n",
      "Epoch 5800/10000: L(Train): 0.24541988968849182; L(Test): 0.23730458319187164\n",
      "Epoch 5801/10000: L(Train): 0.27145105600357056; L(Test): 0.23616166412830353\n",
      "Epoch 5802/10000: L(Train): 0.2626122534275055; L(Test): 0.23644158244132996\n",
      "Epoch 5803/10000: L(Train): 0.2627641260623932; L(Test): 0.23584865033626556\n",
      "Epoch 5804/10000: L(Train): 0.2529606521129608; L(Test): 0.2367965579032898\n",
      "Epoch 5805/10000: L(Train): 0.26595085859298706; L(Test): 0.23651297390460968\n",
      "Epoch 5806/10000: L(Train): 0.25829941034317017; L(Test): 0.23600216209888458\n",
      "Epoch 5807/10000: L(Train): 0.2623998522758484; L(Test): 0.23621152341365814\n",
      "Epoch 5808/10000: L(Train): 0.24371899664402008; L(Test): 0.23672586679458618\n",
      "Epoch 5809/10000: L(Train): 0.27410566806793213; L(Test): 0.23705488443374634\n",
      "Epoch 5810/10000: L(Train): 0.26590049266815186; L(Test): 0.23704664409160614\n",
      "Epoch 5811/10000: L(Train): 0.2644639015197754; L(Test): 0.23621904850006104\n",
      "Epoch 5812/10000: L(Train): 0.26898640394210815; L(Test): 0.23594819009304047\n",
      "Epoch 5813/10000: L(Train): 0.2587863802909851; L(Test): 0.23931805789470673\n",
      "Epoch 5814/10000: L(Train): 0.25431889295578003; L(Test): 0.23766063153743744\n",
      "Epoch 5815/10000: L(Train): 0.25315287709236145; L(Test): 0.2375001460313797\n",
      "Epoch 5816/10000: L(Train): 0.27180296182632446; L(Test): 0.24074983596801758\n",
      "Epoch 5817/10000: L(Train): 0.2574700713157654; L(Test): 0.2406344711780548\n",
      "Epoch 5818/10000: L(Train): 0.26639142632484436; L(Test): 0.23926138877868652\n",
      "Epoch 5819/10000: L(Train): 0.2553122043609619; L(Test): 0.2398885190486908\n",
      "Epoch 5820/10000: L(Train): 0.25464174151420593; L(Test): 0.23866719007492065\n",
      "Epoch 5821/10000: L(Train): 0.2544574439525604; L(Test): 0.24104852974414825\n",
      "Epoch 5822/10000: L(Train): 0.2616429328918457; L(Test): 0.24231098592281342\n",
      "Epoch 5823/10000: L(Train): 0.24708236753940582; L(Test): 0.23859001696109772\n",
      "Epoch 5824/10000: L(Train): 0.25893768668174744; L(Test): 0.23855379223823547\n",
      "Epoch 5825/10000: L(Train): 0.25858592987060547; L(Test): 0.2392827719449997\n",
      "Epoch 5826/10000: L(Train): 0.271018922328949; L(Test): 0.23956680297851562\n",
      "Epoch 5827/10000: L(Train): 0.2708011865615845; L(Test): 0.23973873257637024\n",
      "Epoch 5828/10000: L(Train): 0.2510387599468231; L(Test): 0.2409457266330719\n",
      "Epoch 5829/10000: L(Train): 0.25862473249435425; L(Test): 0.2390781044960022\n",
      "Epoch 5830/10000: L(Train): 0.27846473455429077; L(Test): 0.23920422792434692\n",
      "Epoch 5831/10000: L(Train): 0.25897467136383057; L(Test): 0.2389322966337204\n",
      "Epoch 5832/10000: L(Train): 0.24932748079299927; L(Test): 0.23808525502681732\n",
      "Epoch 5833/10000: L(Train): 0.25592440366744995; L(Test): 0.23933592438697815\n",
      "Epoch 5834/10000: L(Train): 0.2771123945713043; L(Test): 0.239127516746521\n",
      "Epoch 5835/10000: L(Train): 0.26103469729423523; L(Test): 0.2379136085510254\n",
      "Epoch 5836/10000: L(Train): 0.2477615773677826; L(Test): 0.23795047402381897\n",
      "Epoch 5837/10000: L(Train): 0.26522305607795715; L(Test): 0.2389684021472931\n",
      "Epoch 5838/10000: L(Train): 0.2556546628475189; L(Test): 0.23982788622379303\n",
      "Epoch 5839/10000: L(Train): 0.25965967774391174; L(Test): 0.24244482815265656\n",
      "Epoch 5840/10000: L(Train): 0.25819310545921326; L(Test): 0.24243417382240295\n",
      "Epoch 5841/10000: L(Train): 0.27934837341308594; L(Test): 0.2412385791540146\n",
      "Epoch 5842/10000: L(Train): 0.2477129101753235; L(Test): 0.2399533987045288\n",
      "Epoch 5843/10000: L(Train): 0.2672416865825653; L(Test): 0.24050623178482056\n",
      "Epoch 5844/10000: L(Train): 0.27056601643562317; L(Test): 0.2412000149488449\n",
      "Epoch 5845/10000: L(Train): 0.2796528935432434; L(Test): 0.24173907935619354\n",
      "Epoch 5846/10000: L(Train): 0.25608375668525696; L(Test): 0.24170322716236115\n",
      "Epoch 5847/10000: L(Train): 0.2586595416069031; L(Test): 0.24180004000663757\n",
      "Epoch 5848/10000: L(Train): 0.2612614035606384; L(Test): 0.2401522397994995\n",
      "Epoch 5849/10000: L(Train): 0.25885245203971863; L(Test): 0.24131835997104645\n",
      "Epoch 5850/10000: L(Train): 0.2531677186489105; L(Test): 0.2416324019432068\n",
      "Epoch 5851/10000: L(Train): 0.2596123516559601; L(Test): 0.24212110042572021\n",
      "Epoch 5852/10000: L(Train): 0.2624587118625641; L(Test): 0.24084992706775665\n",
      "Epoch 5853/10000: L(Train): 0.28225797414779663; L(Test): 0.24122703075408936\n",
      "Epoch 5854/10000: L(Train): 0.26558440923690796; L(Test): 0.24247293174266815\n",
      "Epoch 5855/10000: L(Train): 0.26222309470176697; L(Test): 0.2412913739681244\n",
      "Epoch 5856/10000: L(Train): 0.2548188269138336; L(Test): 0.24013933539390564\n",
      "Epoch 5857/10000: L(Train): 0.2678319811820984; L(Test): 0.23990166187286377\n",
      "Epoch 5858/10000: L(Train): 0.252356618642807; L(Test): 0.24103042483329773\n",
      "Epoch 5859/10000: L(Train): 0.2562310993671417; L(Test): 0.2396511435508728\n",
      "Epoch 5860/10000: L(Train): 0.25292471051216125; L(Test): 0.23878712952136993\n",
      "Epoch 5861/10000: L(Train): 0.2667798697948456; L(Test): 0.238881453871727\n",
      "Epoch 5862/10000: L(Train): 0.2482328712940216; L(Test): 0.23942206799983978\n",
      "Epoch 5863/10000: L(Train): 0.26368409395217896; L(Test): 0.23860369622707367\n",
      "Epoch 5864/10000: L(Train): 0.2731722295284271; L(Test): 0.23949994146823883\n",
      "Epoch 5865/10000: L(Train): 0.26011618971824646; L(Test): 0.2382611632347107\n",
      "Epoch 5866/10000: L(Train): 0.25364696979522705; L(Test): 0.2387065291404724\n",
      "Epoch 5867/10000: L(Train): 0.2657942473888397; L(Test): 0.23961958289146423\n",
      "Epoch 5868/10000: L(Train): 0.263336718082428; L(Test): 0.2382185459136963\n",
      "Epoch 5869/10000: L(Train): 0.2585192918777466; L(Test): 0.2389470636844635\n",
      "Epoch 5870/10000: L(Train): 0.27677077054977417; L(Test): 0.2387426346540451\n",
      "Epoch 5871/10000: L(Train): 0.2545101046562195; L(Test): 0.24020123481750488\n",
      "Epoch 5872/10000: L(Train): 0.25330445170402527; L(Test): 0.23991785943508148\n",
      "Epoch 5873/10000: L(Train): 0.27598682045936584; L(Test): 0.23812247812747955\n",
      "Epoch 5874/10000: L(Train): 0.2640184164047241; L(Test): 0.23884046077728271\n",
      "Epoch 5875/10000: L(Train): 0.27555397152900696; L(Test): 0.2381216138601303\n",
      "Epoch 5876/10000: L(Train): 0.26462388038635254; L(Test): 0.24007610976696014\n",
      "Epoch 5877/10000: L(Train): 0.2619970738887787; L(Test): 0.2393578141927719\n",
      "Epoch 5878/10000: L(Train): 0.25646287202835083; L(Test): 0.23955854773521423\n",
      "Epoch 5879/10000: L(Train): 0.26659855246543884; L(Test): 0.23880895972251892\n",
      "Epoch 5880/10000: L(Train): 0.27711835503578186; L(Test): 0.23914755880832672\n",
      "Epoch 5881/10000: L(Train): 0.26495638489723206; L(Test): 0.2396402508020401\n",
      "Epoch 5882/10000: L(Train): 0.2519046664237976; L(Test): 0.23840369284152985\n",
      "Epoch 5883/10000: L(Train): 0.269022673368454; L(Test): 0.23920542001724243\n",
      "Epoch 5884/10000: L(Train): 0.27904096245765686; L(Test): 0.23996186256408691\n",
      "Epoch 5885/10000: L(Train): 0.25646457076072693; L(Test): 0.23917438089847565\n",
      "Epoch 5886/10000: L(Train): 0.2539924085140228; L(Test): 0.23853711783885956\n",
      "Epoch 5887/10000: L(Train): 0.2496636062860489; L(Test): 0.23980344831943512\n",
      "Epoch 5888/10000: L(Train): 0.27215462923049927; L(Test): 0.24006660282611847\n",
      "Epoch 5889/10000: L(Train): 0.2570512890815735; L(Test): 0.23847942054271698\n",
      "Epoch 5890/10000: L(Train): 0.24963688850402832; L(Test): 0.23751479387283325\n",
      "Epoch 5891/10000: L(Train): 0.26143312454223633; L(Test): 0.23916859924793243\n",
      "Epoch 5892/10000: L(Train): 0.25343385338783264; L(Test): 0.23829343914985657\n",
      "Epoch 5893/10000: L(Train): 0.269721120595932; L(Test): 0.23793120682239532\n",
      "Epoch 5894/10000: L(Train): 0.2567983865737915; L(Test): 0.2387804388999939\n",
      "Epoch 5895/10000: L(Train): 0.2525314390659332; L(Test): 0.2392740547657013\n",
      "Epoch 5896/10000: L(Train): 0.2535736560821533; L(Test): 0.2395464926958084\n",
      "Epoch 5897/10000: L(Train): 0.2646799385547638; L(Test): 0.23816543817520142\n",
      "Epoch 5898/10000: L(Train): 0.26179805397987366; L(Test): 0.23828484117984772\n",
      "Epoch 5899/10000: L(Train): 0.27927926182746887; L(Test): 0.2379685789346695\n",
      "Epoch 5900/10000: L(Train): 0.27228179574012756; L(Test): 0.24003097414970398\n",
      "Epoch 5901/10000: L(Train): 0.26529553532600403; L(Test): 0.24020785093307495\n",
      "Epoch 5902/10000: L(Train): 0.2681282162666321; L(Test): 0.23669768869876862\n",
      "Epoch 5903/10000: L(Train): 0.25556135177612305; L(Test): 0.23759521543979645\n",
      "Epoch 5904/10000: L(Train): 0.2408100962638855; L(Test): 0.2376287877559662\n",
      "Epoch 5905/10000: L(Train): 0.2633986175060272; L(Test): 0.23876462876796722\n",
      "Epoch 5906/10000: L(Train): 0.24467836320400238; L(Test): 0.2389250546693802\n",
      "Epoch 5907/10000: L(Train): 0.23511159420013428; L(Test): 0.23702485859394073\n",
      "Epoch 5908/10000: L(Train): 0.2654240131378174; L(Test): 0.23708944022655487\n",
      "Epoch 5909/10000: L(Train): 0.25593820214271545; L(Test): 0.23692819476127625\n",
      "Epoch 5910/10000: L(Train): 0.26592203974723816; L(Test): 0.238236203789711\n",
      "Epoch 5911/10000: L(Train): 0.25144296884536743; L(Test): 0.2379661202430725\n",
      "Epoch 5912/10000: L(Train): 0.2575078308582306; L(Test): 0.23751695454120636\n",
      "Epoch 5913/10000: L(Train): 0.2582400143146515; L(Test): 0.23663833737373352\n",
      "Epoch 5914/10000: L(Train): 0.25669240951538086; L(Test): 0.23633383214473724\n",
      "Epoch 5915/10000: L(Train): 0.2528265714645386; L(Test): 0.237677201628685\n",
      "Epoch 5916/10000: L(Train): 0.2562214732170105; L(Test): 0.23665282130241394\n",
      "Epoch 5917/10000: L(Train): 0.25019022822380066; L(Test): 0.2390434294939041\n",
      "Epoch 5918/10000: L(Train): 0.2781313359737396; L(Test): 0.2381613403558731\n",
      "Epoch 5919/10000: L(Train): 0.26759201288223267; L(Test): 0.2365114837884903\n",
      "Epoch 5920/10000: L(Train): 0.2816332280635834; L(Test): 0.23852691054344177\n",
      "Epoch 5921/10000: L(Train): 0.24741914868354797; L(Test): 0.237326979637146\n",
      "Epoch 5922/10000: L(Train): 0.2626053988933563; L(Test): 0.23758664727210999\n",
      "Epoch 5923/10000: L(Train): 0.2675926983356476; L(Test): 0.240229994058609\n",
      "Epoch 5924/10000: L(Train): 0.2614597678184509; L(Test): 0.23952747881412506\n",
      "Epoch 5925/10000: L(Train): 0.2684151530265808; L(Test): 0.23910711705684662\n",
      "Epoch 5926/10000: L(Train): 0.27243226766586304; L(Test): 0.23942580819129944\n",
      "Epoch 5927/10000: L(Train): 0.24565841257572174; L(Test): 0.23974141478538513\n",
      "Epoch 5928/10000: L(Train): 0.2640915811061859; L(Test): 0.24074293673038483\n",
      "Epoch 5929/10000: L(Train): 0.26319316029548645; L(Test): 0.24197319149971008\n",
      "Epoch 5930/10000: L(Train): 0.2706964910030365; L(Test): 0.2386452704668045\n",
      "Epoch 5931/10000: L(Train): 0.26287195086479187; L(Test): 0.24013112485408783\n",
      "Epoch 5932/10000: L(Train): 0.27023079991340637; L(Test): 0.24120298027992249\n",
      "Epoch 5933/10000: L(Train): 0.24987894296646118; L(Test): 0.24066272377967834\n",
      "Epoch 5934/10000: L(Train): 0.2562903165817261; L(Test): 0.2407911717891693\n",
      "Epoch 5935/10000: L(Train): 0.27411842346191406; L(Test): 0.24241970479488373\n",
      "Epoch 5936/10000: L(Train): 0.27412351965904236; L(Test): 0.24056844413280487\n",
      "Epoch 5937/10000: L(Train): 0.26528075337409973; L(Test): 0.24078017473220825\n",
      "Epoch 5938/10000: L(Train): 0.25601306557655334; L(Test): 0.2399556040763855\n",
      "Epoch 5939/10000: L(Train): 0.2564706802368164; L(Test): 0.24066196382045746\n",
      "Epoch 5940/10000: L(Train): 0.26128682494163513; L(Test): 0.241579070687294\n",
      "Epoch 5941/10000: L(Train): 0.26594439148902893; L(Test): 0.24133886396884918\n",
      "Epoch 5942/10000: L(Train): 0.2581433951854706; L(Test): 0.24054782092571259\n",
      "Epoch 5943/10000: L(Train): 0.24778081476688385; L(Test): 0.2403186410665512\n",
      "Epoch 5944/10000: L(Train): 0.26992547512054443; L(Test): 0.24280047416687012\n",
      "Epoch 5945/10000: L(Train): 0.28160566091537476; L(Test): 0.24292026460170746\n",
      "Epoch 5946/10000: L(Train): 0.26041433215141296; L(Test): 0.24224404990673065\n",
      "Epoch 5947/10000: L(Train): 0.25652989745140076; L(Test): 0.24239318072795868\n",
      "Epoch 5948/10000: L(Train): 0.27273380756378174; L(Test): 0.24354352056980133\n",
      "Epoch 5949/10000: L(Train): 0.2662045955657959; L(Test): 0.24380986392498016\n",
      "Epoch 5950/10000: L(Train): 0.27801036834716797; L(Test): 0.24316149950027466\n",
      "Epoch 5951/10000: L(Train): 0.2764414846897125; L(Test): 0.24209527671337128\n",
      "Epoch 5952/10000: L(Train): 0.23588979244232178; L(Test): 0.24367888271808624\n",
      "Epoch 5953/10000: L(Train): 0.2621283233165741; L(Test): 0.2408488690853119\n",
      "Epoch 5954/10000: L(Train): 0.27792805433273315; L(Test): 0.24273672699928284\n",
      "Epoch 5955/10000: L(Train): 0.26787444949150085; L(Test): 0.24302776157855988\n",
      "Epoch 5956/10000: L(Train): 0.2676122486591339; L(Test): 0.24331244826316833\n",
      "Epoch 5957/10000: L(Train): 0.2677091062068939; L(Test): 0.24334174394607544\n",
      "Epoch 5958/10000: L(Train): 0.26284798979759216; L(Test): 0.24304422736167908\n",
      "Epoch 5959/10000: L(Train): 0.2577325105667114; L(Test): 0.24315078556537628\n",
      "Epoch 5960/10000: L(Train): 0.2656329274177551; L(Test): 0.24173754453659058\n",
      "Epoch 5961/10000: L(Train): 0.2724013924598694; L(Test): 0.2414240539073944\n",
      "Epoch 5962/10000: L(Train): 0.26456740498542786; L(Test): 0.24211911857128143\n",
      "Epoch 5963/10000: L(Train): 0.25938111543655396; L(Test): 0.24105902016162872\n",
      "Epoch 5964/10000: L(Train): 0.2769676148891449; L(Test): 0.2399018406867981\n",
      "Epoch 5965/10000: L(Train): 0.2530593276023865; L(Test): 0.24164727330207825\n",
      "Epoch 5966/10000: L(Train): 0.26272159814834595; L(Test): 0.24210594594478607\n",
      "Epoch 5967/10000: L(Train): 0.2692495286464691; L(Test): 0.2408999651670456\n",
      "Epoch 5968/10000: L(Train): 0.24956545233726501; L(Test): 0.23986539244651794\n",
      "Epoch 5969/10000: L(Train): 0.26129838824272156; L(Test): 0.24031390249729156\n",
      "Epoch 5970/10000: L(Train): 0.2537384033203125; L(Test): 0.2397102266550064\n",
      "Epoch 5971/10000: L(Train): 0.2541053295135498; L(Test): 0.24000582098960876\n",
      "Epoch 5972/10000: L(Train): 0.27390292286872864; L(Test): 0.24137528240680695\n",
      "Epoch 5973/10000: L(Train): 0.2672606110572815; L(Test): 0.24022261798381805\n",
      "Epoch 5974/10000: L(Train): 0.25256258249282837; L(Test): 0.24004493653774261\n",
      "Epoch 5975/10000: L(Train): 0.2605160176753998; L(Test): 0.24038532376289368\n",
      "Epoch 5976/10000: L(Train): 0.2571464776992798; L(Test): 0.2402305006980896\n",
      "Epoch 5977/10000: L(Train): 0.26225975155830383; L(Test): 0.23928667604923248\n",
      "Epoch 5978/10000: L(Train): 0.268219530582428; L(Test): 0.2387138307094574\n",
      "Epoch 5979/10000: L(Train): 0.25864100456237793; L(Test): 0.23816467821598053\n",
      "Epoch 5980/10000: L(Train): 0.2541004419326782; L(Test): 0.23967613279819489\n",
      "Epoch 5981/10000: L(Train): 0.2681836187839508; L(Test): 0.2395249456167221\n",
      "Epoch 5982/10000: L(Train): 0.26269325613975525; L(Test): 0.2389308512210846\n",
      "Epoch 5983/10000: L(Train): 0.25890272855758667; L(Test): 0.23844872415065765\n",
      "Epoch 5984/10000: L(Train): 0.2690977454185486; L(Test): 0.23803868889808655\n",
      "Epoch 5985/10000: L(Train): 0.2639942467212677; L(Test): 0.2381860613822937\n",
      "Epoch 5986/10000: L(Train): 0.26327893137931824; L(Test): 0.23878014087677002\n",
      "Epoch 5987/10000: L(Train): 0.24707193672657013; L(Test): 0.23853950202465057\n",
      "Epoch 5988/10000: L(Train): 0.2625790536403656; L(Test): 0.239199697971344\n",
      "Epoch 5989/10000: L(Train): 0.2723853588104248; L(Test): 0.2394571751356125\n",
      "Epoch 5990/10000: L(Train): 0.26751384139060974; L(Test): 0.2383670061826706\n",
      "Epoch 5991/10000: L(Train): 0.2651965022087097; L(Test): 0.23912300169467926\n",
      "Epoch 5992/10000: L(Train): 0.2756817936897278; L(Test): 0.23946569859981537\n",
      "Epoch 5993/10000: L(Train): 0.25882184505462646; L(Test): 0.23815537989139557\n",
      "Epoch 5994/10000: L(Train): 0.2466862052679062; L(Test): 0.23896275460720062\n",
      "Epoch 5995/10000: L(Train): 0.268959105014801; L(Test): 0.23949450254440308\n",
      "Epoch 5996/10000: L(Train): 0.2747815251350403; L(Test): 0.23776696622371674\n",
      "Epoch 5997/10000: L(Train): 0.27196475863456726; L(Test): 0.23908433318138123\n",
      "Epoch 5998/10000: L(Train): 0.2527749836444855; L(Test): 0.2404603660106659\n",
      "Epoch 5999/10000: L(Train): 0.27094271779060364; L(Test): 0.23791228234767914\n",
      "Epoch 6000/10000: L(Train): 0.2595975399017334; L(Test): 0.23930232226848602\n",
      "Epoch 6001/10000: L(Train): 0.26297786831855774; L(Test): 0.2398035228252411\n",
      "Epoch 6002/10000: L(Train): 0.2669014632701874; L(Test): 0.23902679979801178\n",
      "Epoch 6003/10000: L(Train): 0.2653575539588928; L(Test): 0.24034425616264343\n",
      "Epoch 6004/10000: L(Train): 0.2638699412345886; L(Test): 0.2404264509677887\n",
      "Epoch 6005/10000: L(Train): 0.258615642786026; L(Test): 0.23931577801704407\n",
      "Epoch 6006/10000: L(Train): 0.2757154405117035; L(Test): 0.23851826786994934\n",
      "Epoch 6007/10000: L(Train): 0.26696571707725525; L(Test): 0.23935307562351227\n",
      "Epoch 6008/10000: L(Train): 0.2615302801132202; L(Test): 0.23845474421977997\n",
      "Epoch 6009/10000: L(Train): 0.2738175690174103; L(Test): 0.23836199939250946\n",
      "Epoch 6010/10000: L(Train): 0.26583683490753174; L(Test): 0.23987595736980438\n",
      "Epoch 6011/10000: L(Train): 0.26726648211479187; L(Test): 0.23959389328956604\n",
      "Epoch 6012/10000: L(Train): 0.2760675549507141; L(Test): 0.23847539722919464\n",
      "Epoch 6013/10000: L(Train): 0.2620878517627716; L(Test): 0.23796382546424866\n",
      "Epoch 6014/10000: L(Train): 0.2617117464542389; L(Test): 0.2386225461959839\n",
      "Epoch 6015/10000: L(Train): 0.25935420393943787; L(Test): 0.23791725933551788\n",
      "Epoch 6016/10000: L(Train): 0.2645077705383301; L(Test): 0.23768629133701324\n",
      "Epoch 6017/10000: L(Train): 0.2733694911003113; L(Test): 0.23835618793964386\n",
      "Epoch 6018/10000: L(Train): 0.25513529777526855; L(Test): 0.23728492856025696\n",
      "Epoch 6019/10000: L(Train): 0.26764175295829773; L(Test): 0.23817141354084015\n",
      "Epoch 6020/10000: L(Train): 0.26416513323783875; L(Test): 0.23872247338294983\n",
      "Epoch 6021/10000: L(Train): 0.27056723833084106; L(Test): 0.236686572432518\n",
      "Epoch 6022/10000: L(Train): 0.26638421416282654; L(Test): 0.23779399693012238\n",
      "Epoch 6023/10000: L(Train): 0.2727622985839844; L(Test): 0.238486647605896\n",
      "Epoch 6024/10000: L(Train): 0.26605650782585144; L(Test): 0.23971137404441833\n",
      "Epoch 6025/10000: L(Train): 0.26384463906288147; L(Test): 0.2374590039253235\n",
      "Epoch 6026/10000: L(Train): 0.2583758533000946; L(Test): 0.23711340129375458\n",
      "Epoch 6027/10000: L(Train): 0.24896399676799774; L(Test): 0.23653222620487213\n",
      "Epoch 6028/10000: L(Train): 0.24629031121730804; L(Test): 0.2380191832780838\n",
      "Epoch 6029/10000: L(Train): 0.2661217153072357; L(Test): 0.23827192187309265\n",
      "Epoch 6030/10000: L(Train): 0.25861674547195435; L(Test): 0.2379492223262787\n",
      "Epoch 6031/10000: L(Train): 0.2427067905664444; L(Test): 0.23989702761173248\n",
      "Epoch 6032/10000: L(Train): 0.25601717829704285; L(Test): 0.2381543219089508\n",
      "Epoch 6033/10000: L(Train): 0.27240806818008423; L(Test): 0.2390805333852768\n",
      "Epoch 6034/10000: L(Train): 0.2590928375720978; L(Test): 0.23825950920581818\n",
      "Epoch 6035/10000: L(Train): 0.27153727412223816; L(Test): 0.23853792250156403\n",
      "Epoch 6036/10000: L(Train): 0.2505815029144287; L(Test): 0.2378057986497879\n",
      "Epoch 6037/10000: L(Train): 0.2698602080345154; L(Test): 0.23774221539497375\n",
      "Epoch 6038/10000: L(Train): 0.27139395475387573; L(Test): 0.24084138870239258\n",
      "Epoch 6039/10000: L(Train): 0.26753509044647217; L(Test): 0.2385779321193695\n",
      "Epoch 6040/10000: L(Train): 0.2781134843826294; L(Test): 0.2386423647403717\n",
      "Epoch 6041/10000: L(Train): 0.26963260769844055; L(Test): 0.23856288194656372\n",
      "Epoch 6042/10000: L(Train): 0.26503056287765503; L(Test): 0.2386641949415207\n",
      "Epoch 6043/10000: L(Train): 0.2668696343898773; L(Test): 0.2376708686351776\n",
      "Epoch 6044/10000: L(Train): 0.2760518491268158; L(Test): 0.2391415536403656\n",
      "Epoch 6045/10000: L(Train): 0.2699338495731354; L(Test): 0.23884622752666473\n",
      "Epoch 6046/10000: L(Train): 0.25796520709991455; L(Test): 0.23942634463310242\n",
      "Epoch 6047/10000: L(Train): 0.2731247842311859; L(Test): 0.2387849986553192\n",
      "Epoch 6048/10000: L(Train): 0.25907108187675476; L(Test): 0.23816964030265808\n",
      "Epoch 6049/10000: L(Train): 0.25479012727737427; L(Test): 0.23787471652030945\n",
      "Epoch 6050/10000: L(Train): 0.2573162317276001; L(Test): 0.23741775751113892\n",
      "Epoch 6051/10000: L(Train): 0.25440022349357605; L(Test): 0.23861664533615112\n",
      "Epoch 6052/10000: L(Train): 0.2606242597103119; L(Test): 0.23792009055614471\n",
      "Epoch 6053/10000: L(Train): 0.2538139820098877; L(Test): 0.23700717091560364\n",
      "Epoch 6054/10000: L(Train): 0.24589750170707703; L(Test): 0.2374667376279831\n",
      "Epoch 6055/10000: L(Train): 0.2735808193683624; L(Test): 0.2370968610048294\n",
      "Epoch 6056/10000: L(Train): 0.26808488368988037; L(Test): 0.2374737709760666\n",
      "Epoch 6057/10000: L(Train): 0.2596116364002228; L(Test): 0.23940321803092957\n",
      "Epoch 6058/10000: L(Train): 0.2744428217411041; L(Test): 0.23796221613883972\n",
      "Epoch 6059/10000: L(Train): 0.25159206986427307; L(Test): 0.23801086843013763\n",
      "Epoch 6060/10000: L(Train): 0.25736501812934875; L(Test): 0.24164076149463654\n",
      "Epoch 6061/10000: L(Train): 0.28582775592803955; L(Test): 0.2416037619113922\n",
      "Epoch 6062/10000: L(Train): 0.26056426763534546; L(Test): 0.24000133574008942\n",
      "Epoch 6063/10000: L(Train): 0.2514082193374634; L(Test): 0.24232704937458038\n",
      "Epoch 6064/10000: L(Train): 0.28575465083122253; L(Test): 0.24194012582302094\n",
      "Epoch 6065/10000: L(Train): 0.25670868158340454; L(Test): 0.24488826096057892\n",
      "Epoch 6066/10000: L(Train): 0.27309706807136536; L(Test): 0.24315378069877625\n",
      "Epoch 6067/10000: L(Train): 0.26292335987091064; L(Test): 0.24171902239322662\n",
      "Epoch 6068/10000: L(Train): 0.26670023798942566; L(Test): 0.24095267057418823\n",
      "Epoch 6069/10000: L(Train): 0.26364558935165405; L(Test): 0.24251142144203186\n",
      "Epoch 6070/10000: L(Train): 0.27011293172836304; L(Test): 0.2419515699148178\n",
      "Epoch 6071/10000: L(Train): 0.26987287402153015; L(Test): 0.2396983951330185\n",
      "Epoch 6072/10000: L(Train): 0.2633051574230194; L(Test): 0.2409456968307495\n",
      "Epoch 6073/10000: L(Train): 0.28420910239219666; L(Test): 0.2428511381149292\n",
      "Epoch 6074/10000: L(Train): 0.27688726782798767; L(Test): 0.24149861931800842\n",
      "Epoch 6075/10000: L(Train): 0.24833232164382935; L(Test): 0.24285727739334106\n",
      "Epoch 6076/10000: L(Train): 0.27100491523742676; L(Test): 0.24677768349647522\n",
      "Epoch 6077/10000: L(Train): 0.25139278173446655; L(Test): 0.24587611854076385\n",
      "Epoch 6078/10000: L(Train): 0.26178592443466187; L(Test): 0.24156105518341064\n",
      "Epoch 6079/10000: L(Train): 0.26907312870025635; L(Test): 0.24416907131671906\n",
      "Epoch 6080/10000: L(Train): 0.26633256673812866; L(Test): 0.2500822842121124\n",
      "Epoch 6081/10000: L(Train): 0.26002997159957886; L(Test): 0.24436061084270477\n",
      "Epoch 6082/10000: L(Train): 0.26574307680130005; L(Test): 0.2411363273859024\n",
      "Epoch 6083/10000: L(Train): 0.2674541771411896; L(Test): 0.24447710812091827\n",
      "Epoch 6084/10000: L(Train): 0.259196937084198; L(Test): 0.24692432582378387\n",
      "Epoch 6085/10000: L(Train): 0.26975777745246887; L(Test): 0.24347105622291565\n",
      "Epoch 6086/10000: L(Train): 0.26819002628326416; L(Test): 0.24156740307807922\n",
      "Epoch 6087/10000: L(Train): 0.2585706412792206; L(Test): 0.24445296823978424\n",
      "Epoch 6088/10000: L(Train): 0.25779294967651367; L(Test): 0.2423286736011505\n",
      "Epoch 6089/10000: L(Train): 0.2638111412525177; L(Test): 0.24416424334049225\n",
      "Epoch 6090/10000: L(Train): 0.27343955636024475; L(Test): 0.2443162202835083\n",
      "Epoch 6091/10000: L(Train): 0.25837263464927673; L(Test): 0.2428843080997467\n",
      "Epoch 6092/10000: L(Train): 0.2667565643787384; L(Test): 0.24540908634662628\n",
      "Epoch 6093/10000: L(Train): 0.27558228373527527; L(Test): 0.24355724453926086\n",
      "Epoch 6094/10000: L(Train): 0.2662002742290497; L(Test): 0.2443447858095169\n",
      "Epoch 6095/10000: L(Train): 0.2459924966096878; L(Test): 0.24295341968536377\n",
      "Epoch 6096/10000: L(Train): 0.2632529139518738; L(Test): 0.241576686501503\n",
      "Epoch 6097/10000: L(Train): 0.26548999547958374; L(Test): 0.24236586689949036\n",
      "Epoch 6098/10000: L(Train): 0.27258843183517456; L(Test): 0.2408129721879959\n",
      "Epoch 6099/10000: L(Train): 0.2566971778869629; L(Test): 0.24386325478553772\n",
      "Epoch 6100/10000: L(Train): 0.26745617389678955; L(Test): 0.24380208551883698\n",
      "Epoch 6101/10000: L(Train): 0.2681159973144531; L(Test): 0.2408047765493393\n",
      "Epoch 6102/10000: L(Train): 0.27096229791641235; L(Test): 0.2416805624961853\n",
      "Epoch 6103/10000: L(Train): 0.26442474126815796; L(Test): 0.24040430784225464\n",
      "Epoch 6104/10000: L(Train): 0.26959362626075745; L(Test): 0.24301394820213318\n",
      "Epoch 6105/10000: L(Train): 0.24315576255321503; L(Test): 0.24153874814510345\n",
      "Epoch 6106/10000: L(Train): 0.26830318570137024; L(Test): 0.24083472788333893\n",
      "Epoch 6107/10000: L(Train): 0.2642805874347687; L(Test): 0.24176011979579926\n",
      "Epoch 6108/10000: L(Train): 0.25556081533432007; L(Test): 0.23900628089904785\n",
      "Epoch 6109/10000: L(Train): 0.2603079378604889; L(Test): 0.24012267589569092\n",
      "Epoch 6110/10000: L(Train): 0.2661546468734741; L(Test): 0.2405695617198944\n",
      "Epoch 6111/10000: L(Train): 0.26056385040283203; L(Test): 0.23857367038726807\n",
      "Epoch 6112/10000: L(Train): 0.2681107521057129; L(Test): 0.2390061765909195\n",
      "Epoch 6113/10000: L(Train): 0.26003408432006836; L(Test): 0.2378154844045639\n",
      "Epoch 6114/10000: L(Train): 0.26432186365127563; L(Test): 0.2380448430776596\n",
      "Epoch 6115/10000: L(Train): 0.26515546441078186; L(Test): 0.23854964971542358\n",
      "Epoch 6116/10000: L(Train): 0.2831747829914093; L(Test): 0.2373400777578354\n",
      "Epoch 6117/10000: L(Train): 0.261986643075943; L(Test): 0.23841440677642822\n",
      "Epoch 6118/10000: L(Train): 0.2734868824481964; L(Test): 0.23735204339027405\n",
      "Epoch 6119/10000: L(Train): 0.2582320272922516; L(Test): 0.2393907755613327\n",
      "Epoch 6120/10000: L(Train): 0.26142093539237976; L(Test): 0.23939146101474762\n",
      "Epoch 6121/10000: L(Train): 0.25910627841949463; L(Test): 0.23803222179412842\n",
      "Epoch 6122/10000: L(Train): 0.2685527205467224; L(Test): 0.23838889598846436\n",
      "Epoch 6123/10000: L(Train): 0.2692149579524994; L(Test): 0.2379598468542099\n",
      "Epoch 6124/10000: L(Train): 0.2534175515174866; L(Test): 0.23887509107589722\n",
      "Epoch 6125/10000: L(Train): 0.2589753568172455; L(Test): 0.23859688639640808\n",
      "Epoch 6126/10000: L(Train): 0.26844149827957153; L(Test): 0.23698680102825165\n",
      "Epoch 6127/10000: L(Train): 0.2578601837158203; L(Test): 0.23756186664104462\n",
      "Epoch 6128/10000: L(Train): 0.25555914640426636; L(Test): 0.23832771182060242\n",
      "Epoch 6129/10000: L(Train): 0.2744797170162201; L(Test): 0.23750251531600952\n",
      "Epoch 6130/10000: L(Train): 0.25592079758644104; L(Test): 0.23683182895183563\n",
      "Epoch 6131/10000: L(Train): 0.25936347246170044; L(Test): 0.23757502436637878\n",
      "Epoch 6132/10000: L(Train): 0.2583385109901428; L(Test): 0.23778827488422394\n",
      "Epoch 6133/10000: L(Train): 0.24121499061584473; L(Test): 0.23860369622707367\n",
      "Epoch 6134/10000: L(Train): 0.27468612790107727; L(Test): 0.23697124421596527\n",
      "Epoch 6135/10000: L(Train): 0.24713249504566193; L(Test): 0.23810623586177826\n",
      "Epoch 6136/10000: L(Train): 0.2496758997440338; L(Test): 0.2378929853439331\n",
      "Epoch 6137/10000: L(Train): 0.26896417140960693; L(Test): 0.23813258111476898\n",
      "Epoch 6138/10000: L(Train): 0.2729431390762329; L(Test): 0.2378333956003189\n",
      "Epoch 6139/10000: L(Train): 0.27762725949287415; L(Test): 0.23734867572784424\n",
      "Epoch 6140/10000: L(Train): 0.2534494698047638; L(Test): 0.23863762617111206\n",
      "Epoch 6141/10000: L(Train): 0.26452478766441345; L(Test): 0.23849695920944214\n",
      "Epoch 6142/10000: L(Train): 0.2580253481864929; L(Test): 0.23966272175312042\n",
      "Epoch 6143/10000: L(Train): 0.2688398063182831; L(Test): 0.23749181628227234\n",
      "Epoch 6144/10000: L(Train): 0.2664848864078522; L(Test): 0.2378048151731491\n",
      "Epoch 6145/10000: L(Train): 0.2673853635787964; L(Test): 0.23789824545383453\n",
      "Epoch 6146/10000: L(Train): 0.259239137172699; L(Test): 0.23733583092689514\n",
      "Epoch 6147/10000: L(Train): 0.27178052067756653; L(Test): 0.23746146261692047\n",
      "Epoch 6148/10000: L(Train): 0.2559491991996765; L(Test): 0.23728829622268677\n",
      "Epoch 6149/10000: L(Train): 0.2649540603160858; L(Test): 0.23661544919013977\n",
      "Epoch 6150/10000: L(Train): 0.2545947730541229; L(Test): 0.23757706582546234\n",
      "Epoch 6151/10000: L(Train): 0.2641092538833618; L(Test): 0.23774796724319458\n",
      "Epoch 6152/10000: L(Train): 0.26902711391448975; L(Test): 0.23894402384757996\n",
      "Epoch 6153/10000: L(Train): 0.2550571858882904; L(Test): 0.23804596066474915\n",
      "Epoch 6154/10000: L(Train): 0.26770567893981934; L(Test): 0.23705951869487762\n",
      "Epoch 6155/10000: L(Train): 0.26316994428634644; L(Test): 0.23688198626041412\n",
      "Epoch 6156/10000: L(Train): 0.24990539252758026; L(Test): 0.23805226385593414\n",
      "Epoch 6157/10000: L(Train): 0.26403117179870605; L(Test): 0.2377232015132904\n",
      "Epoch 6158/10000: L(Train): 0.271220326423645; L(Test): 0.23696795105934143\n",
      "Epoch 6159/10000: L(Train): 0.26412585377693176; L(Test): 0.23742295801639557\n",
      "Epoch 6160/10000: L(Train): 0.26074695587158203; L(Test): 0.23811456561088562\n",
      "Epoch 6161/10000: L(Train): 0.26911017298698425; L(Test): 0.23802320659160614\n",
      "Epoch 6162/10000: L(Train): 0.2708563506603241; L(Test): 0.2378377765417099\n",
      "Epoch 6163/10000: L(Train): 0.2658604085445404; L(Test): 0.23793341219425201\n",
      "Epoch 6164/10000: L(Train): 0.26032546162605286; L(Test): 0.23849941790103912\n",
      "Epoch 6165/10000: L(Train): 0.26013076305389404; L(Test): 0.23849967122077942\n",
      "Epoch 6166/10000: L(Train): 0.25176700949668884; L(Test): 0.23794624209403992\n",
      "Epoch 6167/10000: L(Train): 0.2568211257457733; L(Test): 0.23811137676239014\n",
      "Epoch 6168/10000: L(Train): 0.26791834831237793; L(Test): 0.23772269487380981\n",
      "Epoch 6169/10000: L(Train): 0.26297205686569214; L(Test): 0.23863163590431213\n",
      "Epoch 6170/10000: L(Train): 0.2574962079524994; L(Test): 0.23787304759025574\n",
      "Epoch 6171/10000: L(Train): 0.2708587646484375; L(Test): 0.23743562400341034\n",
      "Epoch 6172/10000: L(Train): 0.26968812942504883; L(Test): 0.2378118336200714\n",
      "Epoch 6173/10000: L(Train): 0.24972409009933472; L(Test): 0.2388264685869217\n",
      "Epoch 6174/10000: L(Train): 0.26211032271385193; L(Test): 0.2385740578174591\n",
      "Epoch 6175/10000: L(Train): 0.25923603773117065; L(Test): 0.2385077327489853\n",
      "Epoch 6176/10000: L(Train): 0.25122055411338806; L(Test): 0.2386208176612854\n",
      "Epoch 6177/10000: L(Train): 0.2689816355705261; L(Test): 0.23780246078968048\n",
      "Epoch 6178/10000: L(Train): 0.25217869877815247; L(Test): 0.2369169443845749\n",
      "Epoch 6179/10000: L(Train): 0.26095741987228394; L(Test): 0.23885858058929443\n",
      "Epoch 6180/10000: L(Train): 0.25853151082992554; L(Test): 0.23781271278858185\n",
      "Epoch 6181/10000: L(Train): 0.2617481052875519; L(Test): 0.23750557005405426\n",
      "Epoch 6182/10000: L(Train): 0.2577207684516907; L(Test): 0.2386177033185959\n",
      "Epoch 6183/10000: L(Train): 0.2633759081363678; L(Test): 0.23692359030246735\n",
      "Epoch 6184/10000: L(Train): 0.26629358530044556; L(Test): 0.23778700828552246\n",
      "Epoch 6185/10000: L(Train): 0.26046809554100037; L(Test): 0.23892994225025177\n",
      "Epoch 6186/10000: L(Train): 0.2536812424659729; L(Test): 0.23776884377002716\n",
      "Epoch 6187/10000: L(Train): 0.273439884185791; L(Test): 0.23700644075870514\n",
      "Epoch 6188/10000: L(Train): 0.24593091011047363; L(Test): 0.24336272478103638\n",
      "Epoch 6189/10000: L(Train): 0.26206672191619873; L(Test): 0.24193556606769562\n",
      "Epoch 6190/10000: L(Train): 0.2808625102043152; L(Test): 0.24273279309272766\n",
      "Epoch 6191/10000: L(Train): 0.27828076481819153; L(Test): 0.24652419984340668\n",
      "Epoch 6192/10000: L(Train): 0.2770393490791321; L(Test): 0.2459164261817932\n",
      "Epoch 6193/10000: L(Train): 0.28675252199172974; L(Test): 0.24418364465236664\n",
      "Epoch 6194/10000: L(Train): 0.26651811599731445; L(Test): 0.24525301158428192\n",
      "Epoch 6195/10000: L(Train): 0.2597092092037201; L(Test): 0.24424859881401062\n",
      "Epoch 6196/10000: L(Train): 0.26904553174972534; L(Test): 0.24289661645889282\n",
      "Epoch 6197/10000: L(Train): 0.2662655711174011; L(Test): 0.24403391778469086\n",
      "Epoch 6198/10000: L(Train): 0.26452186703681946; L(Test): 0.24313439428806305\n",
      "Epoch 6199/10000: L(Train): 0.2825913727283478; L(Test): 0.2438374012708664\n",
      "Epoch 6200/10000: L(Train): 0.27488476037979126; L(Test): 0.2449987232685089\n",
      "Epoch 6201/10000: L(Train): 0.2783181667327881; L(Test): 0.24292048811912537\n",
      "Epoch 6202/10000: L(Train): 0.2664223909378052; L(Test): 0.24299480020999908\n",
      "Epoch 6203/10000: L(Train): 0.2702154815196991; L(Test): 0.24471354484558105\n",
      "Epoch 6204/10000: L(Train): 0.2506994605064392; L(Test): 0.24268856644630432\n",
      "Epoch 6205/10000: L(Train): 0.25673097372055054; L(Test): 0.24376438558101654\n",
      "Epoch 6206/10000: L(Train): 0.2685995101928711; L(Test): 0.24297133088111877\n",
      "Epoch 6207/10000: L(Train): 0.26371729373931885; L(Test): 0.2415459007024765\n",
      "Epoch 6208/10000: L(Train): 0.26033538579940796; L(Test): 0.24209657311439514\n",
      "Epoch 6209/10000: L(Train): 0.2547573447227478; L(Test): 0.24370507895946503\n",
      "Epoch 6210/10000: L(Train): 0.26599350571632385; L(Test): 0.24116143584251404\n",
      "Epoch 6211/10000: L(Train): 0.2746872901916504; L(Test): 0.24045398831367493\n",
      "Epoch 6212/10000: L(Train): 0.26029449701309204; L(Test): 0.24019214510917664\n",
      "Epoch 6213/10000: L(Train): 0.2691310942173004; L(Test): 0.24034187197685242\n",
      "Epoch 6214/10000: L(Train): 0.265595942735672; L(Test): 0.2407517284154892\n",
      "Epoch 6215/10000: L(Train): 0.25541427731513977; L(Test): 0.24027052521705627\n",
      "Epoch 6216/10000: L(Train): 0.25144559144973755; L(Test): 0.23949874937534332\n",
      "Epoch 6217/10000: L(Train): 0.2620824873447418; L(Test): 0.2390250861644745\n",
      "Epoch 6218/10000: L(Train): 0.26320210099220276; L(Test): 0.23947037756443024\n",
      "Epoch 6219/10000: L(Train): 0.2666110694408417; L(Test): 0.24069350957870483\n",
      "Epoch 6220/10000: L(Train): 0.2658420205116272; L(Test): 0.24323241412639618\n",
      "Epoch 6221/10000: L(Train): 0.2742837965488434; L(Test): 0.24377059936523438\n",
      "Epoch 6222/10000: L(Train): 0.2567061483860016; L(Test): 0.24232017993927002\n",
      "Epoch 6223/10000: L(Train): 0.2839873433113098; L(Test): 0.24191901087760925\n",
      "Epoch 6224/10000: L(Train): 0.2675931453704834; L(Test): 0.24246373772621155\n",
      "Epoch 6225/10000: L(Train): 0.26241984963417053; L(Test): 0.24270229041576385\n",
      "Epoch 6226/10000: L(Train): 0.25910326838493347; L(Test): 0.2428026795387268\n",
      "Epoch 6227/10000: L(Train): 0.27384859323501587; L(Test): 0.24264594912528992\n",
      "Epoch 6228/10000: L(Train): 0.267086386680603; L(Test): 0.2427336573600769\n",
      "Epoch 6229/10000: L(Train): 0.26700374484062195; L(Test): 0.24068497121334076\n",
      "Epoch 6230/10000: L(Train): 0.2540953457355499; L(Test): 0.2417946457862854\n",
      "Epoch 6231/10000: L(Train): 0.2655714750289917; L(Test): 0.24454747140407562\n",
      "Epoch 6232/10000: L(Train): 0.28481805324554443; L(Test): 0.24530135095119476\n",
      "Epoch 6233/10000: L(Train): 0.2691749334335327; L(Test): 0.24255387485027313\n",
      "Epoch 6234/10000: L(Train): 0.274515300989151; L(Test): 0.24212157726287842\n",
      "Epoch 6235/10000: L(Train): 0.2687280476093292; L(Test): 0.2405768185853958\n",
      "Epoch 6236/10000: L(Train): 0.25872886180877686; L(Test): 0.24052907526493073\n",
      "Epoch 6237/10000: L(Train): 0.26545318961143494; L(Test): 0.2416454255580902\n",
      "Epoch 6238/10000: L(Train): 0.26391085982322693; L(Test): 0.24065440893173218\n",
      "Epoch 6239/10000: L(Train): 0.27312982082366943; L(Test): 0.24032512307167053\n",
      "Epoch 6240/10000: L(Train): 0.27391770482063293; L(Test): 0.23903250694274902\n",
      "Epoch 6241/10000: L(Train): 0.25591105222702026; L(Test): 0.24093756079673767\n",
      "Epoch 6242/10000: L(Train): 0.26034706830978394; L(Test): 0.2425006479024887\n",
      "Epoch 6243/10000: L(Train): 0.2684110999107361; L(Test): 0.24162636697292328\n",
      "Epoch 6244/10000: L(Train): 0.2674580216407776; L(Test): 0.24027268588542938\n",
      "Epoch 6245/10000: L(Train): 0.2667536437511444; L(Test): 0.24234206974506378\n",
      "Epoch 6246/10000: L(Train): 0.2659287452697754; L(Test): 0.24087080359458923\n",
      "Epoch 6247/10000: L(Train): 0.2590365409851074; L(Test): 0.2408158779144287\n",
      "Epoch 6248/10000: L(Train): 0.26370707154273987; L(Test): 0.24060411751270294\n",
      "Epoch 6249/10000: L(Train): 0.26440703868865967; L(Test): 0.24248972535133362\n",
      "Epoch 6250/10000: L(Train): 0.2562069892883301; L(Test): 0.2411029040813446\n",
      "Epoch 6251/10000: L(Train): 0.2490369975566864; L(Test): 0.24140197038650513\n",
      "Epoch 6252/10000: L(Train): 0.24975097179412842; L(Test): 0.2434411644935608\n",
      "Epoch 6253/10000: L(Train): 0.2685337960720062; L(Test): 0.2404366284608841\n",
      "Epoch 6254/10000: L(Train): 0.27007588744163513; L(Test): 0.2387935370206833\n",
      "Epoch 6255/10000: L(Train): 0.2624642848968506; L(Test): 0.2394992560148239\n",
      "Epoch 6256/10000: L(Train): 0.26508769392967224; L(Test): 0.23899951577186584\n",
      "Epoch 6257/10000: L(Train): 0.2556842565536499; L(Test): 0.2401324212551117\n",
      "Epoch 6258/10000: L(Train): 0.2623758316040039; L(Test): 0.24076403677463531\n",
      "Epoch 6259/10000: L(Train): 0.2571336328983307; L(Test): 0.23996630311012268\n",
      "Epoch 6260/10000: L(Train): 0.25728073716163635; L(Test): 0.23769511282444\n",
      "Epoch 6261/10000: L(Train): 0.2707814872264862; L(Test): 0.2385166436433792\n",
      "Epoch 6262/10000: L(Train): 0.2657315135002136; L(Test): 0.23845165967941284\n",
      "Epoch 6263/10000: L(Train): 0.2520594596862793; L(Test): 0.23761433362960815\n",
      "Epoch 6264/10000: L(Train): 0.24948081374168396; L(Test): 0.23793017864227295\n",
      "Epoch 6265/10000: L(Train): 0.26379337906837463; L(Test): 0.23976260423660278\n",
      "Epoch 6266/10000: L(Train): 0.2649981677532196; L(Test): 0.23928186297416687\n",
      "Epoch 6267/10000: L(Train): 0.25892794132232666; L(Test): 0.23873937129974365\n",
      "Epoch 6268/10000: L(Train): 0.28302764892578125; L(Test): 0.2373173087835312\n",
      "Epoch 6269/10000: L(Train): 0.25313565135002136; L(Test): 0.23765596747398376\n",
      "Epoch 6270/10000: L(Train): 0.25617772340774536; L(Test): 0.23834656178951263\n",
      "Epoch 6271/10000: L(Train): 0.2724975645542145; L(Test): 0.23770704865455627\n",
      "Epoch 6272/10000: L(Train): 0.2611716687679291; L(Test): 0.23795580863952637\n",
      "Epoch 6273/10000: L(Train): 0.269030898809433; L(Test): 0.2373240441083908\n",
      "Epoch 6274/10000: L(Train): 0.2643192708492279; L(Test): 0.23698467016220093\n",
      "Epoch 6275/10000: L(Train): 0.25468870997428894; L(Test): 0.2373376488685608\n",
      "Epoch 6276/10000: L(Train): 0.2614070475101471; L(Test): 0.23626425862312317\n",
      "Epoch 6277/10000: L(Train): 0.26382696628570557; L(Test): 0.2362825721502304\n",
      "Epoch 6278/10000: L(Train): 0.26716747879981995; L(Test): 0.2381432205438614\n",
      "Epoch 6279/10000: L(Train): 0.2613169848918915; L(Test): 0.23796850442886353\n",
      "Epoch 6280/10000: L(Train): 0.27074041962623596; L(Test): 0.23690035939216614\n",
      "Epoch 6281/10000: L(Train): 0.26264312863349915; L(Test): 0.23731061816215515\n",
      "Epoch 6282/10000: L(Train): 0.2674807012081146; L(Test): 0.2372051626443863\n",
      "Epoch 6283/10000: L(Train): 0.24936899542808533; L(Test): 0.23799477517604828\n",
      "Epoch 6284/10000: L(Train): 0.25603151321411133; L(Test): 0.2383560687303543\n",
      "Epoch 6285/10000: L(Train): 0.26101550459861755; L(Test): 0.2379288524389267\n",
      "Epoch 6286/10000: L(Train): 0.26670411229133606; L(Test): 0.23887845873832703\n",
      "Epoch 6287/10000: L(Train): 0.25617921352386475; L(Test): 0.2380363494157791\n",
      "Epoch 6288/10000: L(Train): 0.248172789812088; L(Test): 0.23994271457195282\n",
      "Epoch 6289/10000: L(Train): 0.2660021185874939; L(Test): 0.23740927875041962\n",
      "Epoch 6290/10000: L(Train): 0.25995805859565735; L(Test): 0.23680098354816437\n",
      "Epoch 6291/10000: L(Train): 0.27823352813720703; L(Test): 0.2374660223722458\n",
      "Epoch 6292/10000: L(Train): 0.2652376890182495; L(Test): 0.23783470690250397\n",
      "Epoch 6293/10000: L(Train): 0.25919926166534424; L(Test): 0.23838262259960175\n",
      "Epoch 6294/10000: L(Train): 0.25513434410095215; L(Test): 0.23882941901683807\n",
      "Epoch 6295/10000: L(Train): 0.26392340660095215; L(Test): 0.2384924292564392\n",
      "Epoch 6296/10000: L(Train): 0.27179592847824097; L(Test): 0.23810595273971558\n",
      "Epoch 6297/10000: L(Train): 0.26050880551338196; L(Test): 0.23850803077220917\n",
      "Epoch 6298/10000: L(Train): 0.27225956320762634; L(Test): 0.23922836780548096\n",
      "Epoch 6299/10000: L(Train): 0.26909875869750977; L(Test): 0.23850777745246887\n",
      "Epoch 6300/10000: L(Train): 0.26188409328460693; L(Test): 0.24202755093574524\n",
      "Epoch 6301/10000: L(Train): 0.26839664578437805; L(Test): 0.24083444476127625\n",
      "Epoch 6302/10000: L(Train): 0.2757650315761566; L(Test): 0.24106574058532715\n",
      "Epoch 6303/10000: L(Train): 0.2510489821434021; L(Test): 0.24163085222244263\n",
      "Epoch 6304/10000: L(Train): 0.28275150060653687; L(Test): 0.24333885312080383\n",
      "Epoch 6305/10000: L(Train): 0.2597130537033081; L(Test): 0.24265547096729279\n",
      "Epoch 6306/10000: L(Train): 0.25590601563453674; L(Test): 0.2422586977481842\n",
      "Epoch 6307/10000: L(Train): 0.26145097613334656; L(Test): 0.2426120489835739\n",
      "Epoch 6308/10000: L(Train): 0.2551741898059845; L(Test): 0.2411184161901474\n",
      "Epoch 6309/10000: L(Train): 0.2703397274017334; L(Test): 0.24137747287750244\n",
      "Epoch 6310/10000: L(Train): 0.27977049350738525; L(Test): 0.24234044551849365\n",
      "Epoch 6311/10000: L(Train): 0.26495271921157837; L(Test): 0.2414071410894394\n",
      "Epoch 6312/10000: L(Train): 0.25879186391830444; L(Test): 0.240541011095047\n",
      "Epoch 6313/10000: L(Train): 0.25549837946891785; L(Test): 0.24055971205234528\n",
      "Epoch 6314/10000: L(Train): 0.259567528963089; L(Test): 0.2401750385761261\n",
      "Epoch 6315/10000: L(Train): 0.2557665705680847; L(Test): 0.24059394001960754\n",
      "Epoch 6316/10000: L(Train): 0.2679479718208313; L(Test): 0.23887336254119873\n",
      "Epoch 6317/10000: L(Train): 0.25662121176719666; L(Test): 0.23890945315361023\n",
      "Epoch 6318/10000: L(Train): 0.2612258493900299; L(Test): 0.23955337703227997\n",
      "Epoch 6319/10000: L(Train): 0.26420557498931885; L(Test): 0.24070367217063904\n",
      "Epoch 6320/10000: L(Train): 0.26834043860435486; L(Test): 0.2386646568775177\n",
      "Epoch 6321/10000: L(Train): 0.2646210491657257; L(Test): 0.2394341230392456\n",
      "Epoch 6322/10000: L(Train): 0.2627515196800232; L(Test): 0.23950691521167755\n",
      "Epoch 6323/10000: L(Train): 0.27912506461143494; L(Test): 0.23890681564807892\n",
      "Epoch 6324/10000: L(Train): 0.2586611211299896; L(Test): 0.24016809463500977\n",
      "Epoch 6325/10000: L(Train): 0.26565036177635193; L(Test): 0.24026454985141754\n",
      "Epoch 6326/10000: L(Train): 0.2578164041042328; L(Test): 0.23983584344387054\n",
      "Epoch 6327/10000: L(Train): 0.2720395028591156; L(Test): 0.23951470851898193\n",
      "Epoch 6328/10000: L(Train): 0.2610500454902649; L(Test): 0.2383006513118744\n",
      "Epoch 6329/10000: L(Train): 0.2703634202480316; L(Test): 0.24039678275585175\n",
      "Epoch 6330/10000: L(Train): 0.2630258798599243; L(Test): 0.2401379495859146\n",
      "Epoch 6331/10000: L(Train): 0.25043728947639465; L(Test): 0.2389695644378662\n",
      "Epoch 6332/10000: L(Train): 0.25619009137153625; L(Test): 0.23815563321113586\n",
      "Epoch 6333/10000: L(Train): 0.25693127512931824; L(Test): 0.23824676871299744\n",
      "Epoch 6334/10000: L(Train): 0.26234233379364014; L(Test): 0.2381981760263443\n",
      "Epoch 6335/10000: L(Train): 0.26201900839805603; L(Test): 0.2375403344631195\n",
      "Epoch 6336/10000: L(Train): 0.2603680491447449; L(Test): 0.23686780035495758\n",
      "Epoch 6337/10000: L(Train): 0.2569945156574249; L(Test): 0.2365514039993286\n",
      "Epoch 6338/10000: L(Train): 0.25162413716316223; L(Test): 0.2369411736726761\n",
      "Epoch 6339/10000: L(Train): 0.2604190409183502; L(Test): 0.23791781067848206\n",
      "Epoch 6340/10000: L(Train): 0.24368901550769806; L(Test): 0.23788097500801086\n",
      "Epoch 6341/10000: L(Train): 0.2665456533432007; L(Test): 0.23673143982887268\n",
      "Epoch 6342/10000: L(Train): 0.2686846852302551; L(Test): 0.23671087622642517\n",
      "Epoch 6343/10000: L(Train): 0.24782375991344452; L(Test): 0.23614634573459625\n",
      "Epoch 6344/10000: L(Train): 0.25748273730278015; L(Test): 0.2364504188299179\n",
      "Epoch 6345/10000: L(Train): 0.2498033493757248; L(Test): 0.2366684526205063\n",
      "Epoch 6346/10000: L(Train): 0.2643149495124817; L(Test): 0.23564039170742035\n",
      "Epoch 6347/10000: L(Train): 0.2694377601146698; L(Test): 0.2363876849412918\n",
      "Epoch 6348/10000: L(Train): 0.27398455142974854; L(Test): 0.23599351942539215\n",
      "Epoch 6349/10000: L(Train): 0.26112866401672363; L(Test): 0.23748649656772614\n",
      "Epoch 6350/10000: L(Train): 0.25537005066871643; L(Test): 0.23914846777915955\n",
      "Epoch 6351/10000: L(Train): 0.27462393045425415; L(Test): 0.2367236167192459\n",
      "Epoch 6352/10000: L(Train): 0.27156001329421997; L(Test): 0.23708178102970123\n",
      "Epoch 6353/10000: L(Train): 0.2594333589076996; L(Test): 0.23672467470169067\n",
      "Epoch 6354/10000: L(Train): 0.2609991431236267; L(Test): 0.23748327791690826\n",
      "Epoch 6355/10000: L(Train): 0.2560775876045227; L(Test): 0.23746126890182495\n",
      "Epoch 6356/10000: L(Train): 0.2568344473838806; L(Test): 0.2365434318780899\n",
      "Epoch 6357/10000: L(Train): 0.2453627735376358; L(Test): 0.23627522587776184\n",
      "Epoch 6358/10000: L(Train): 0.24915076792240143; L(Test): 0.23670288920402527\n",
      "Epoch 6359/10000: L(Train): 0.25510746240615845; L(Test): 0.2372187227010727\n",
      "Epoch 6360/10000: L(Train): 0.23613528907299042; L(Test): 0.2373819649219513\n",
      "Epoch 6361/10000: L(Train): 0.2694641351699829; L(Test): 0.23645809292793274\n",
      "Epoch 6362/10000: L(Train): 0.26278015971183777; L(Test): 0.23725757002830505\n",
      "Epoch 6363/10000: L(Train): 0.2686636447906494; L(Test): 0.23772470653057098\n",
      "Epoch 6364/10000: L(Train): 0.26937052607536316; L(Test): 0.23789678514003754\n",
      "Epoch 6365/10000: L(Train): 0.2606867253780365; L(Test): 0.23649516701698303\n",
      "Epoch 6366/10000: L(Train): 0.2662156820297241; L(Test): 0.23716022074222565\n",
      "Epoch 6367/10000: L(Train): 0.26072993874549866; L(Test): 0.23628446459770203\n",
      "Epoch 6368/10000: L(Train): 0.24871139228343964; L(Test): 0.23772604763507843\n",
      "Epoch 6369/10000: L(Train): 0.25899115204811096; L(Test): 0.23799194395542145\n",
      "Epoch 6370/10000: L(Train): 0.2554195821285248; L(Test): 0.23724398016929626\n",
      "Epoch 6371/10000: L(Train): 0.26076003909111023; L(Test): 0.23722216486930847\n",
      "Epoch 6372/10000: L(Train): 0.2564818561077118; L(Test): 0.23736430704593658\n",
      "Epoch 6373/10000: L(Train): 0.25829970836639404; L(Test): 0.23719723522663116\n",
      "Epoch 6374/10000: L(Train): 0.26200950145721436; L(Test): 0.23710747063159943\n",
      "Epoch 6375/10000: L(Train): 0.26418811082839966; L(Test): 0.23720084130764008\n",
      "Epoch 6376/10000: L(Train): 0.2728894352912903; L(Test): 0.2362687885761261\n",
      "Epoch 6377/10000: L(Train): 0.24728882312774658; L(Test): 0.23677510023117065\n",
      "Epoch 6378/10000: L(Train): 0.2643956243991852; L(Test): 0.23885786533355713\n",
      "Epoch 6379/10000: L(Train): 0.2585357129573822; L(Test): 0.23719148337841034\n",
      "Epoch 6380/10000: L(Train): 0.26766178011894226; L(Test): 0.2366502434015274\n",
      "Epoch 6381/10000: L(Train): 0.2667733430862427; L(Test): 0.23683679103851318\n",
      "Epoch 6382/10000: L(Train): 0.25238364934921265; L(Test): 0.23638226091861725\n",
      "Epoch 6383/10000: L(Train): 0.2637403607368469; L(Test): 0.23736698925495148\n",
      "Epoch 6384/10000: L(Train): 0.2510150372982025; L(Test): 0.23715996742248535\n",
      "Epoch 6385/10000: L(Train): 0.26940733194351196; L(Test): 0.23630695044994354\n",
      "Epoch 6386/10000: L(Train): 0.25759467482566833; L(Test): 0.23642730712890625\n",
      "Epoch 6387/10000: L(Train): 0.2545119524002075; L(Test): 0.23627078533172607\n",
      "Epoch 6388/10000: L(Train): 0.2704450190067291; L(Test): 0.2367725670337677\n",
      "Epoch 6389/10000: L(Train): 0.25589829683303833; L(Test): 0.2364920973777771\n",
      "Epoch 6390/10000: L(Train): 0.2638950049877167; L(Test): 0.2361401617527008\n",
      "Epoch 6391/10000: L(Train): 0.25289538502693176; L(Test): 0.23671312630176544\n",
      "Epoch 6392/10000: L(Train): 0.25578734278678894; L(Test): 0.23752234876155853\n",
      "Epoch 6393/10000: L(Train): 0.2548588216304779; L(Test): 0.23635901510715485\n",
      "Epoch 6394/10000: L(Train): 0.2447766661643982; L(Test): 0.23644770681858063\n",
      "Epoch 6395/10000: L(Train): 0.26429659128189087; L(Test): 0.23744970560073853\n",
      "Epoch 6396/10000: L(Train): 0.27815040946006775; L(Test): 0.2367139309644699\n",
      "Epoch 6397/10000: L(Train): 0.2547626793384552; L(Test): 0.23577608168125153\n",
      "Epoch 6398/10000: L(Train): 0.2605147659778595; L(Test): 0.23693136870861053\n",
      "Epoch 6399/10000: L(Train): 0.2670850455760956; L(Test): 0.23649318516254425\n",
      "Epoch 6400/10000: L(Train): 0.26891466975212097; L(Test): 0.23634783923625946\n",
      "Epoch 6401/10000: L(Train): 0.26215705275535583; L(Test): 0.23704957962036133\n",
      "Epoch 6402/10000: L(Train): 0.2537927031517029; L(Test): 0.23792877793312073\n",
      "Epoch 6403/10000: L(Train): 0.2578723728656769; L(Test): 0.23779526352882385\n",
      "Epoch 6404/10000: L(Train): 0.261750727891922; L(Test): 0.23760780692100525\n",
      "Epoch 6405/10000: L(Train): 0.25595158338546753; L(Test): 0.23715706169605255\n",
      "Epoch 6406/10000: L(Train): 0.2567098140716553; L(Test): 0.23736898601055145\n",
      "Epoch 6407/10000: L(Train): 0.27301937341690063; L(Test): 0.23736146092414856\n",
      "Epoch 6408/10000: L(Train): 0.2676880955696106; L(Test): 0.23735332489013672\n",
      "Epoch 6409/10000: L(Train): 0.25500789284706116; L(Test): 0.23720262944698334\n",
      "Epoch 6410/10000: L(Train): 0.2704882025718689; L(Test): 0.23798543214797974\n",
      "Epoch 6411/10000: L(Train): 0.2603216767311096; L(Test): 0.2379993200302124\n",
      "Epoch 6412/10000: L(Train): 0.26069116592407227; L(Test): 0.23892997205257416\n",
      "Epoch 6413/10000: L(Train): 0.2645649313926697; L(Test): 0.23646405339241028\n",
      "Epoch 6414/10000: L(Train): 0.26792046427726746; L(Test): 0.23614566028118134\n",
      "Epoch 6415/10000: L(Train): 0.24913062155246735; L(Test): 0.23597203195095062\n",
      "Epoch 6416/10000: L(Train): 0.2760332524776459; L(Test): 0.2372274398803711\n",
      "Epoch 6417/10000: L(Train): 0.24500273168087006; L(Test): 0.2384353131055832\n",
      "Epoch 6418/10000: L(Train): 0.25794070959091187; L(Test): 0.236253559589386\n",
      "Epoch 6419/10000: L(Train): 0.2679293155670166; L(Test): 0.23699815571308136\n",
      "Epoch 6420/10000: L(Train): 0.26550236344337463; L(Test): 0.2365255355834961\n",
      "Epoch 6421/10000: L(Train): 0.2498476356267929; L(Test): 0.23766356706619263\n",
      "Epoch 6422/10000: L(Train): 0.2693575620651245; L(Test): 0.23677395284175873\n",
      "Epoch 6423/10000: L(Train): 0.26720279455184937; L(Test): 0.2373822182416916\n",
      "Epoch 6424/10000: L(Train): 0.2630578279495239; L(Test): 0.237047016620636\n",
      "Epoch 6425/10000: L(Train): 0.274527907371521; L(Test): 0.23773245513439178\n",
      "Epoch 6426/10000: L(Train): 0.25902631878852844; L(Test): 0.23797592520713806\n",
      "Epoch 6427/10000: L(Train): 0.26557108759880066; L(Test): 0.23596251010894775\n",
      "Epoch 6428/10000: L(Train): 0.2626233696937561; L(Test): 0.2373930811882019\n",
      "Epoch 6429/10000: L(Train): 0.2635147273540497; L(Test): 0.23659184575080872\n",
      "Epoch 6430/10000: L(Train): 0.2634114623069763; L(Test): 0.23954978585243225\n",
      "Epoch 6431/10000: L(Train): 0.2605648934841156; L(Test): 0.23634251952171326\n",
      "Epoch 6432/10000: L(Train): 0.2476230412721634; L(Test): 0.2373906970024109\n",
      "Epoch 6433/10000: L(Train): 0.27217668294906616; L(Test): 0.2360052764415741\n",
      "Epoch 6434/10000: L(Train): 0.2738971412181854; L(Test): 0.23625363409519196\n",
      "Epoch 6435/10000: L(Train): 0.2521679401397705; L(Test): 0.24327769875526428\n",
      "Epoch 6436/10000: L(Train): 0.2664967477321625; L(Test): 0.24186168611049652\n",
      "Epoch 6437/10000: L(Train): 0.26140260696411133; L(Test): 0.24103690683841705\n",
      "Epoch 6438/10000: L(Train): 0.26166394352912903; L(Test): 0.2399885207414627\n",
      "Epoch 6439/10000: L(Train): 0.2608620822429657; L(Test): 0.24508288502693176\n",
      "Epoch 6440/10000: L(Train): 0.27708035707473755; L(Test): 0.24453453719615936\n",
      "Epoch 6441/10000: L(Train): 0.2620188295841217; L(Test): 0.2412102073431015\n",
      "Epoch 6442/10000: L(Train): 0.267704039812088; L(Test): 0.24278362095355988\n",
      "Epoch 6443/10000: L(Train): 0.27695563435554504; L(Test): 0.24116016924381256\n",
      "Epoch 6444/10000: L(Train): 0.25551292300224304; L(Test): 0.24400585889816284\n",
      "Epoch 6445/10000: L(Train): 0.26538941264152527; L(Test): 0.24296125769615173\n",
      "Epoch 6446/10000: L(Train): 0.25946852564811707; L(Test): 0.24023331701755524\n",
      "Epoch 6447/10000: L(Train): 0.27465692162513733; L(Test): 0.241249680519104\n",
      "Epoch 6448/10000: L(Train): 0.26075536012649536; L(Test): 0.24149101972579956\n",
      "Epoch 6449/10000: L(Train): 0.2534199059009552; L(Test): 0.24265629053115845\n",
      "Epoch 6450/10000: L(Train): 0.269084095954895; L(Test): 0.24068468809127808\n",
      "Epoch 6451/10000: L(Train): 0.2757822573184967; L(Test): 0.24136368930339813\n",
      "Epoch 6452/10000: L(Train): 0.25508901476860046; L(Test): 0.24176935851573944\n",
      "Epoch 6453/10000: L(Train): 0.27837592363357544; L(Test): 0.23986633121967316\n",
      "Epoch 6454/10000: L(Train): 0.26343175768852234; L(Test): 0.23946885764598846\n",
      "Epoch 6455/10000: L(Train): 0.2564733028411865; L(Test): 0.24047969281673431\n",
      "Epoch 6456/10000: L(Train): 0.2618136405944824; L(Test): 0.23933932185173035\n",
      "Epoch 6457/10000: L(Train): 0.2630155384540558; L(Test): 0.23917582631111145\n",
      "Epoch 6458/10000: L(Train): 0.2591567933559418; L(Test): 0.23939478397369385\n",
      "Epoch 6459/10000: L(Train): 0.2672989070415497; L(Test): 0.24094881117343903\n",
      "Epoch 6460/10000: L(Train): 0.2509048283100128; L(Test): 0.24025858938694\n",
      "Epoch 6461/10000: L(Train): 0.27238336205482483; L(Test): 0.23838433623313904\n",
      "Epoch 6462/10000: L(Train): 0.2503017783164978; L(Test): 0.2390371412038803\n",
      "Epoch 6463/10000: L(Train): 0.2671442925930023; L(Test): 0.23771563172340393\n",
      "Epoch 6464/10000: L(Train): 0.25699272751808167; L(Test): 0.2392897605895996\n",
      "Epoch 6465/10000: L(Train): 0.26420384645462036; L(Test): 0.2393655627965927\n",
      "Epoch 6466/10000: L(Train): 0.26115334033966064; L(Test): 0.23737987875938416\n",
      "Epoch 6467/10000: L(Train): 0.2603810727596283; L(Test): 0.23781190812587738\n",
      "Epoch 6468/10000: L(Train): 0.26306915283203125; L(Test): 0.2373836785554886\n",
      "Epoch 6469/10000: L(Train): 0.26736193895339966; L(Test): 0.2383478283882141\n",
      "Epoch 6470/10000: L(Train): 0.25808390974998474; L(Test): 0.23758317530155182\n",
      "Epoch 6471/10000: L(Train): 0.2641462981700897; L(Test): 0.2388981282711029\n",
      "Epoch 6472/10000: L(Train): 0.2547127902507782; L(Test): 0.23736467957496643\n",
      "Epoch 6473/10000: L(Train): 0.25991666316986084; L(Test): 0.23893210291862488\n",
      "Epoch 6474/10000: L(Train): 0.26112857460975647; L(Test): 0.23840749263763428\n",
      "Epoch 6475/10000: L(Train): 0.26992321014404297; L(Test): 0.23677022755146027\n",
      "Epoch 6476/10000: L(Train): 0.24850322306156158; L(Test): 0.23887595534324646\n",
      "Epoch 6477/10000: L(Train): 0.26113104820251465; L(Test): 0.23900392651557922\n",
      "Epoch 6478/10000: L(Train): 0.24693140387535095; L(Test): 0.23839052021503448\n",
      "Epoch 6479/10000: L(Train): 0.25650525093078613; L(Test): 0.23771458864212036\n",
      "Epoch 6480/10000: L(Train): 0.26462095975875854; L(Test): 0.23927199840545654\n",
      "Epoch 6481/10000: L(Train): 0.2503334581851959; L(Test): 0.23726670444011688\n",
      "Epoch 6482/10000: L(Train): 0.25545504689216614; L(Test): 0.2401133030653\n",
      "Epoch 6483/10000: L(Train): 0.2735847532749176; L(Test): 0.24196618795394897\n",
      "Epoch 6484/10000: L(Train): 0.26450109481811523; L(Test): 0.23922507464885712\n",
      "Epoch 6485/10000: L(Train): 0.25427934527397156; L(Test): 0.23911182582378387\n",
      "Epoch 6486/10000: L(Train): 0.2609463036060333; L(Test): 0.23851674795150757\n",
      "Epoch 6487/10000: L(Train): 0.2759556472301483; L(Test): 0.23830538988113403\n",
      "Epoch 6488/10000: L(Train): 0.2538524270057678; L(Test): 0.23861616849899292\n",
      "Epoch 6489/10000: L(Train): 0.2565760314464569; L(Test): 0.23865634202957153\n",
      "Epoch 6490/10000: L(Train): 0.2603602707386017; L(Test): 0.23761765658855438\n",
      "Epoch 6491/10000: L(Train): 0.2745707631111145; L(Test): 0.23853343725204468\n",
      "Epoch 6492/10000: L(Train): 0.25391900539398193; L(Test): 0.2399325966835022\n",
      "Epoch 6493/10000: L(Train): 0.2712329030036926; L(Test): 0.23768922686576843\n",
      "Epoch 6494/10000: L(Train): 0.2590303421020508; L(Test): 0.23841750621795654\n",
      "Epoch 6495/10000: L(Train): 0.26030707359313965; L(Test): 0.23850950598716736\n",
      "Epoch 6496/10000: L(Train): 0.268096387386322; L(Test): 0.2381669282913208\n",
      "Epoch 6497/10000: L(Train): 0.2543495297431946; L(Test): 0.23699186742305756\n",
      "Epoch 6498/10000: L(Train): 0.2547784447669983; L(Test): 0.23711897432804108\n",
      "Epoch 6499/10000: L(Train): 0.2609173357486725; L(Test): 0.239780992269516\n",
      "Epoch 6500/10000: L(Train): 0.2503889203071594; L(Test): 0.2401892989873886\n",
      "Epoch 6501/10000: L(Train): 0.2753395736217499; L(Test): 0.2365923970937729\n",
      "Epoch 6502/10000: L(Train): 0.24965530633926392; L(Test): 0.23738645017147064\n",
      "Epoch 6503/10000: L(Train): 0.2576315104961395; L(Test): 0.2373974472284317\n",
      "Epoch 6504/10000: L(Train): 0.27319273352622986; L(Test): 0.23706181347370148\n",
      "Epoch 6505/10000: L(Train): 0.2516140341758728; L(Test): 0.23663684725761414\n",
      "Epoch 6506/10000: L(Train): 0.25040990114212036; L(Test): 0.23723942041397095\n",
      "Epoch 6507/10000: L(Train): 0.2604444622993469; L(Test): 0.23712953925132751\n",
      "Epoch 6508/10000: L(Train): 0.26687154173851013; L(Test): 0.23730440437793732\n",
      "Epoch 6509/10000: L(Train): 0.2706187665462494; L(Test): 0.2372315376996994\n",
      "Epoch 6510/10000: L(Train): 0.26619619131088257; L(Test): 0.23700721561908722\n",
      "Epoch 6511/10000: L(Train): 0.2646818459033966; L(Test): 0.23775571584701538\n",
      "Epoch 6512/10000: L(Train): 0.26263901591300964; L(Test): 0.23692069947719574\n",
      "Epoch 6513/10000: L(Train): 0.253775030374527; L(Test): 0.23702479898929596\n",
      "Epoch 6514/10000: L(Train): 0.26779529452323914; L(Test): 0.23701971769332886\n",
      "Epoch 6515/10000: L(Train): 0.24502518773078918; L(Test): 0.23740296065807343\n",
      "Epoch 6516/10000: L(Train): 0.26819878816604614; L(Test): 0.23707610368728638\n",
      "Epoch 6517/10000: L(Train): 0.26763319969177246; L(Test): 0.23774826526641846\n",
      "Epoch 6518/10000: L(Train): 0.2609051465988159; L(Test): 0.2378782331943512\n",
      "Epoch 6519/10000: L(Train): 0.26220911741256714; L(Test): 0.23700468242168427\n",
      "Epoch 6520/10000: L(Train): 0.25044316053390503; L(Test): 0.2374068945646286\n",
      "Epoch 6521/10000: L(Train): 0.25393396615982056; L(Test): 0.23773103952407837\n",
      "Epoch 6522/10000: L(Train): 0.2632407546043396; L(Test): 0.23687373101711273\n",
      "Epoch 6523/10000: L(Train): 0.2671346068382263; L(Test): 0.24055299162864685\n",
      "Epoch 6524/10000: L(Train): 0.2513817250728607; L(Test): 0.24137791991233826\n",
      "Epoch 6525/10000: L(Train): 0.24813547730445862; L(Test): 0.2390402853488922\n",
      "Epoch 6526/10000: L(Train): 0.260320246219635; L(Test): 0.24030490219593048\n",
      "Epoch 6527/10000: L(Train): 0.25513938069343567; L(Test): 0.24017685651779175\n",
      "Epoch 6528/10000: L(Train): 0.2510521113872528; L(Test): 0.24020518362522125\n",
      "Epoch 6529/10000: L(Train): 0.24874810874462128; L(Test): 0.23997756838798523\n",
      "Epoch 6530/10000: L(Train): 0.26211926341056824; L(Test): 0.24192461371421814\n",
      "Epoch 6531/10000: L(Train): 0.2683534622192383; L(Test): 0.240960955619812\n",
      "Epoch 6532/10000: L(Train): 0.2664138376712799; L(Test): 0.24288569390773773\n",
      "Epoch 6533/10000: L(Train): 0.2471919059753418; L(Test): 0.2409762591123581\n",
      "Epoch 6534/10000: L(Train): 0.259278267621994; L(Test): 0.24100004136562347\n",
      "Epoch 6535/10000: L(Train): 0.26593369245529175; L(Test): 0.24165089428424835\n",
      "Epoch 6536/10000: L(Train): 0.26827579736709595; L(Test): 0.2388305962085724\n",
      "Epoch 6537/10000: L(Train): 0.25408583879470825; L(Test): 0.24036158621311188\n",
      "Epoch 6538/10000: L(Train): 0.26127544045448303; L(Test): 0.24035261571407318\n",
      "Epoch 6539/10000: L(Train): 0.2500188946723938; L(Test): 0.24020268023014069\n",
      "Epoch 6540/10000: L(Train): 0.2711160182952881; L(Test): 0.24145321547985077\n",
      "Epoch 6541/10000: L(Train): 0.25905245542526245; L(Test): 0.24205319583415985\n",
      "Epoch 6542/10000: L(Train): 0.2672266662120819; L(Test): 0.238414004445076\n",
      "Epoch 6543/10000: L(Train): 0.262128621339798; L(Test): 0.23893199861049652\n",
      "Epoch 6544/10000: L(Train): 0.27089643478393555; L(Test): 0.24377179145812988\n",
      "Epoch 6545/10000: L(Train): 0.276897668838501; L(Test): 0.24442456662654877\n",
      "Epoch 6546/10000: L(Train): 0.2549002468585968; L(Test): 0.24610261619091034\n",
      "Epoch 6547/10000: L(Train): 0.25844836235046387; L(Test): 0.2484884262084961\n",
      "Epoch 6548/10000: L(Train): 0.27268287539482117; L(Test): 0.24560298025608063\n",
      "Epoch 6549/10000: L(Train): 0.2478596419095993; L(Test): 0.24383105337619781\n",
      "Epoch 6550/10000: L(Train): 0.25185367465019226; L(Test): 0.24609375\n",
      "Epoch 6551/10000: L(Train): 0.2620018422603607; L(Test): 0.2475266307592392\n",
      "Epoch 6552/10000: L(Train): 0.2745010256767273; L(Test): 0.24487708508968353\n",
      "Epoch 6553/10000: L(Train): 0.2705075144767761; L(Test): 0.24244311451911926\n",
      "Epoch 6554/10000: L(Train): 0.26671066880226135; L(Test): 0.2445492148399353\n",
      "Epoch 6555/10000: L(Train): 0.2673202157020569; L(Test): 0.24482914805412292\n",
      "Epoch 6556/10000: L(Train): 0.2770439088344574; L(Test): 0.2441486120223999\n",
      "Epoch 6557/10000: L(Train): 0.27028021216392517; L(Test): 0.24428042769432068\n",
      "Epoch 6558/10000: L(Train): 0.26034072041511536; L(Test): 0.24439562857151031\n",
      "Epoch 6559/10000: L(Train): 0.2569485008716583; L(Test): 0.24391290545463562\n",
      "Epoch 6560/10000: L(Train): 0.2636682689189911; L(Test): 0.24321526288986206\n",
      "Epoch 6561/10000: L(Train): 0.27189797163009644; L(Test): 0.24252080917358398\n",
      "Epoch 6562/10000: L(Train): 0.2506529688835144; L(Test): 0.24239520728588104\n",
      "Epoch 6563/10000: L(Train): 0.2588989734649658; L(Test): 0.24027703702449799\n",
      "Epoch 6564/10000: L(Train): 0.259883314371109; L(Test): 0.24010643362998962\n",
      "Epoch 6565/10000: L(Train): 0.2627773582935333; L(Test): 0.24113069474697113\n",
      "Epoch 6566/10000: L(Train): 0.24887043237686157; L(Test): 0.24050873517990112\n",
      "Epoch 6567/10000: L(Train): 0.26431336998939514; L(Test): 0.23967421054840088\n",
      "Epoch 6568/10000: L(Train): 0.26386702060699463; L(Test): 0.23963989317417145\n",
      "Epoch 6569/10000: L(Train): 0.26277199387550354; L(Test): 0.23963163793087006\n",
      "Epoch 6570/10000: L(Train): 0.25900980830192566; L(Test): 0.24039003252983093\n",
      "Epoch 6571/10000: L(Train): 0.24703460931777954; L(Test): 0.240464985370636\n",
      "Epoch 6572/10000: L(Train): 0.26012203097343445; L(Test): 0.23933622241020203\n",
      "Epoch 6573/10000: L(Train): 0.2710813581943512; L(Test): 0.23899658024311066\n",
      "Epoch 6574/10000: L(Train): 0.25956279039382935; L(Test): 0.23886212706565857\n",
      "Epoch 6575/10000: L(Train): 0.23746812343597412; L(Test): 0.2384883463382721\n",
      "Epoch 6576/10000: L(Train): 0.2732667028903961; L(Test): 0.23826341331005096\n",
      "Epoch 6577/10000: L(Train): 0.26593896746635437; L(Test): 0.23714010417461395\n",
      "Epoch 6578/10000: L(Train): 0.24669626355171204; L(Test): 0.2372140884399414\n",
      "Epoch 6579/10000: L(Train): 0.2419360727071762; L(Test): 0.23709997534751892\n",
      "Epoch 6580/10000: L(Train): 0.2710764706134796; L(Test): 0.23897205293178558\n",
      "Epoch 6581/10000: L(Train): 0.2615378797054291; L(Test): 0.2369699776172638\n",
      "Epoch 6582/10000: L(Train): 0.26353514194488525; L(Test): 0.23683734238147736\n",
      "Epoch 6583/10000: L(Train): 0.26963672041893005; L(Test): 0.23768556118011475\n",
      "Epoch 6584/10000: L(Train): 0.2736765146255493; L(Test): 0.23715467751026154\n",
      "Epoch 6585/10000: L(Train): 0.26343441009521484; L(Test): 0.23786544799804688\n",
      "Epoch 6586/10000: L(Train): 0.2623053193092346; L(Test): 0.2370840162038803\n",
      "Epoch 6587/10000: L(Train): 0.25416967272758484; L(Test): 0.23690536618232727\n",
      "Epoch 6588/10000: L(Train): 0.25851184129714966; L(Test): 0.23698373138904572\n",
      "Epoch 6589/10000: L(Train): 0.2578654885292053; L(Test): 0.23647639155387878\n",
      "Epoch 6590/10000: L(Train): 0.261526882648468; L(Test): 0.2365419566631317\n",
      "Epoch 6591/10000: L(Train): 0.2554935812950134; L(Test): 0.23644709587097168\n",
      "Epoch 6592/10000: L(Train): 0.2675226926803589; L(Test): 0.23625171184539795\n",
      "Epoch 6593/10000: L(Train): 0.25592365860939026; L(Test): 0.2362401783466339\n",
      "Epoch 6594/10000: L(Train): 0.25348758697509766; L(Test): 0.2372857928276062\n",
      "Epoch 6595/10000: L(Train): 0.25396111607551575; L(Test): 0.23625700175762177\n",
      "Epoch 6596/10000: L(Train): 0.25811976194381714; L(Test): 0.23717288672924042\n",
      "Epoch 6597/10000: L(Train): 0.25739115476608276; L(Test): 0.23558855056762695\n",
      "Epoch 6598/10000: L(Train): 0.25737228989601135; L(Test): 0.23613972961902618\n",
      "Epoch 6599/10000: L(Train): 0.242855504155159; L(Test): 0.23627661168575287\n",
      "Epoch 6600/10000: L(Train): 0.255779892206192; L(Test): 0.23873163759708405\n",
      "Epoch 6601/10000: L(Train): 0.25730621814727783; L(Test): 0.23722916841506958\n",
      "Epoch 6602/10000: L(Train): 0.26389116048812866; L(Test): 0.23745320737361908\n",
      "Epoch 6603/10000: L(Train): 0.26055237650871277; L(Test): 0.23673179745674133\n",
      "Epoch 6604/10000: L(Train): 0.27088433504104614; L(Test): 0.23701271414756775\n",
      "Epoch 6605/10000: L(Train): 0.2528180181980133; L(Test): 0.23884980380535126\n",
      "Epoch 6606/10000: L(Train): 0.2673826813697815; L(Test): 0.2375945746898651\n",
      "Epoch 6607/10000: L(Train): 0.25411954522132874; L(Test): 0.2384462058544159\n",
      "Epoch 6608/10000: L(Train): 0.25347286462783813; L(Test): 0.2371094524860382\n",
      "Epoch 6609/10000: L(Train): 0.2575990855693817; L(Test): 0.23857203125953674\n",
      "Epoch 6610/10000: L(Train): 0.25353744626045227; L(Test): 0.24067328870296478\n",
      "Epoch 6611/10000: L(Train): 0.27508974075317383; L(Test): 0.23763848841190338\n",
      "Epoch 6612/10000: L(Train): 0.25744128227233887; L(Test): 0.23819011449813843\n",
      "Epoch 6613/10000: L(Train): 0.25633352994918823; L(Test): 0.2390851527452469\n",
      "Epoch 6614/10000: L(Train): 0.25893574953079224; L(Test): 0.2396315187215805\n",
      "Epoch 6615/10000: L(Train): 0.25873613357543945; L(Test): 0.24079707264900208\n",
      "Epoch 6616/10000: L(Train): 0.27334216237068176; L(Test): 0.23985758423805237\n",
      "Epoch 6617/10000: L(Train): 0.24903157353401184; L(Test): 0.23896430432796478\n",
      "Epoch 6618/10000: L(Train): 0.253600537776947; L(Test): 0.23807907104492188\n",
      "Epoch 6619/10000: L(Train): 0.2612186372280121; L(Test): 0.23937420547008514\n",
      "Epoch 6620/10000: L(Train): 0.25533628463745117; L(Test): 0.2381838858127594\n",
      "Epoch 6621/10000: L(Train): 0.2640767991542816; L(Test): 0.23709283769130707\n",
      "Epoch 6622/10000: L(Train): 0.25999894738197327; L(Test): 0.23724843561649323\n",
      "Epoch 6623/10000: L(Train): 0.26394549012184143; L(Test): 0.23781158030033112\n",
      "Epoch 6624/10000: L(Train): 0.2693224251270294; L(Test): 0.2368181198835373\n",
      "Epoch 6625/10000: L(Train): 0.26719143986701965; L(Test): 0.236840158700943\n",
      "Epoch 6626/10000: L(Train): 0.25771766901016235; L(Test): 0.23704347014427185\n",
      "Epoch 6627/10000: L(Train): 0.2609401345252991; L(Test): 0.23694197833538055\n",
      "Epoch 6628/10000: L(Train): 0.2520352602005005; L(Test): 0.23655693233013153\n",
      "Epoch 6629/10000: L(Train): 0.2548508644104004; L(Test): 0.23731188476085663\n",
      "Epoch 6630/10000: L(Train): 0.25418075919151306; L(Test): 0.2368476837873459\n",
      "Epoch 6631/10000: L(Train): 0.25207334756851196; L(Test): 0.23631438612937927\n",
      "Epoch 6632/10000: L(Train): 0.26612886786460876; L(Test): 0.23576727509498596\n",
      "Epoch 6633/10000: L(Train): 0.2634224593639374; L(Test): 0.23678264021873474\n",
      "Epoch 6634/10000: L(Train): 0.2699199914932251; L(Test): 0.23770886659622192\n",
      "Epoch 6635/10000: L(Train): 0.26391029357910156; L(Test): 0.2363424450159073\n",
      "Epoch 6636/10000: L(Train): 0.2791983485221863; L(Test): 0.23813042044639587\n",
      "Epoch 6637/10000: L(Train): 0.2579144835472107; L(Test): 0.23725588619709015\n",
      "Epoch 6638/10000: L(Train): 0.24777063727378845; L(Test): 0.2383676916360855\n",
      "Epoch 6639/10000: L(Train): 0.25503721833229065; L(Test): 0.23710526525974274\n",
      "Epoch 6640/10000: L(Train): 0.26312747597694397; L(Test): 0.23792026937007904\n",
      "Epoch 6641/10000: L(Train): 0.2578839957714081; L(Test): 0.2371874302625656\n",
      "Epoch 6642/10000: L(Train): 0.25995147228240967; L(Test): 0.23973830044269562\n",
      "Epoch 6643/10000: L(Train): 0.24913357198238373; L(Test): 0.2428741753101349\n",
      "Epoch 6644/10000: L(Train): 0.26291391253471375; L(Test): 0.23908621072769165\n",
      "Epoch 6645/10000: L(Train): 0.2643700838088989; L(Test): 0.24052274227142334\n",
      "Epoch 6646/10000: L(Train): 0.26281192898750305; L(Test): 0.23781722784042358\n",
      "Epoch 6647/10000: L(Train): 0.25566425919532776; L(Test): 0.24056677520275116\n",
      "Epoch 6648/10000: L(Train): 0.2564074993133545; L(Test): 0.239706888794899\n",
      "Epoch 6649/10000: L(Train): 0.2480316013097763; L(Test): 0.23748034238815308\n",
      "Epoch 6650/10000: L(Train): 0.2633134722709656; L(Test): 0.23855766654014587\n",
      "Epoch 6651/10000: L(Train): 0.27555781602859497; L(Test): 0.23826022446155548\n",
      "Epoch 6652/10000: L(Train): 0.2529132068157196; L(Test): 0.23830729722976685\n",
      "Epoch 6653/10000: L(Train): 0.26235848665237427; L(Test): 0.2384694218635559\n",
      "Epoch 6654/10000: L(Train): 0.269666463136673; L(Test): 0.2381362020969391\n",
      "Epoch 6655/10000: L(Train): 0.26508018374443054; L(Test): 0.23744279146194458\n",
      "Epoch 6656/10000: L(Train): 0.2548878788948059; L(Test): 0.23707357048988342\n",
      "Epoch 6657/10000: L(Train): 0.2691520154476166; L(Test): 0.23866581916809082\n",
      "Epoch 6658/10000: L(Train): 0.2572226822376251; L(Test): 0.23814578354358673\n",
      "Epoch 6659/10000: L(Train): 0.26185721158981323; L(Test): 0.23771429061889648\n",
      "Epoch 6660/10000: L(Train): 0.26091280579566956; L(Test): 0.23792992532253265\n",
      "Epoch 6661/10000: L(Train): 0.2594052255153656; L(Test): 0.23854200541973114\n",
      "Epoch 6662/10000: L(Train): 0.2560775578022003; L(Test): 0.23755480349063873\n",
      "Epoch 6663/10000: L(Train): 0.24558021128177643; L(Test): 0.2377818524837494\n",
      "Epoch 6664/10000: L(Train): 0.2594151198863983; L(Test): 0.23832380771636963\n",
      "Epoch 6665/10000: L(Train): 0.2578936815261841; L(Test): 0.2387966811656952\n",
      "Epoch 6666/10000: L(Train): 0.26765957474708557; L(Test): 0.2372792810201645\n",
      "Epoch 6667/10000: L(Train): 0.26089683175086975; L(Test): 0.23723186552524567\n",
      "Epoch 6668/10000: L(Train): 0.24421867728233337; L(Test): 0.23798087239265442\n",
      "Epoch 6669/10000: L(Train): 0.24966268241405487; L(Test): 0.23793557286262512\n",
      "Epoch 6670/10000: L(Train): 0.26226407289505005; L(Test): 0.2371813803911209\n",
      "Epoch 6671/10000: L(Train): 0.2590792179107666; L(Test): 0.23699863255023956\n",
      "Epoch 6672/10000: L(Train): 0.25286194682121277; L(Test): 0.23900657892227173\n",
      "Epoch 6673/10000: L(Train): 0.26350030303001404; L(Test): 0.23923909664154053\n",
      "Epoch 6674/10000: L(Train): 0.2712850570678711; L(Test): 0.2367829829454422\n",
      "Epoch 6675/10000: L(Train): 0.26053690910339355; L(Test): 0.2384193241596222\n",
      "Epoch 6676/10000: L(Train): 0.2556041181087494; L(Test): 0.2388172447681427\n",
      "Epoch 6677/10000: L(Train): 0.2496708333492279; L(Test): 0.23668107390403748\n",
      "Epoch 6678/10000: L(Train): 0.26028767228126526; L(Test): 0.2366291582584381\n",
      "Epoch 6679/10000: L(Train): 0.25783148407936096; L(Test): 0.23754478991031647\n",
      "Epoch 6680/10000: L(Train): 0.2691323459148407; L(Test): 0.2378827929496765\n",
      "Epoch 6681/10000: L(Train): 0.253648042678833; L(Test): 0.23853470385074615\n",
      "Epoch 6682/10000: L(Train): 0.2528163492679596; L(Test): 0.23765061795711517\n",
      "Epoch 6683/10000: L(Train): 0.2581547498703003; L(Test): 0.23728586733341217\n",
      "Epoch 6684/10000: L(Train): 0.2678970992565155; L(Test): 0.23717212677001953\n",
      "Epoch 6685/10000: L(Train): 0.2629377245903015; L(Test): 0.23898738622665405\n",
      "Epoch 6686/10000: L(Train): 0.2581963539123535; L(Test): 0.2375338226556778\n",
      "Epoch 6687/10000: L(Train): 0.2591443657875061; L(Test): 0.2366154044866562\n",
      "Epoch 6688/10000: L(Train): 0.2494772970676422; L(Test): 0.23705141246318817\n",
      "Epoch 6689/10000: L(Train): 0.2750561833381653; L(Test): 0.23753364384174347\n",
      "Epoch 6690/10000: L(Train): 0.2574559450149536; L(Test): 0.23961514234542847\n",
      "Epoch 6691/10000: L(Train): 0.2649233341217041; L(Test): 0.23719216883182526\n",
      "Epoch 6692/10000: L(Train): 0.26721349358558655; L(Test): 0.2363351732492447\n",
      "Epoch 6693/10000: L(Train): 0.2609163522720337; L(Test): 0.23758885264396667\n",
      "Epoch 6694/10000: L(Train): 0.2543506622314453; L(Test): 0.23876939713954926\n",
      "Epoch 6695/10000: L(Train): 0.2576025128364563; L(Test): 0.23763245344161987\n",
      "Epoch 6696/10000: L(Train): 0.2530187964439392; L(Test): 0.23745958507061005\n",
      "Epoch 6697/10000: L(Train): 0.27287164330482483; L(Test): 0.23738670349121094\n",
      "Epoch 6698/10000: L(Train): 0.25894010066986084; L(Test): 0.2378767728805542\n",
      "Epoch 6699/10000: L(Train): 0.26122042536735535; L(Test): 0.2387542724609375\n",
      "Epoch 6700/10000: L(Train): 0.2568798065185547; L(Test): 0.23767264187335968\n",
      "Epoch 6701/10000: L(Train): 0.2541596293449402; L(Test): 0.23751424252986908\n",
      "Epoch 6702/10000: L(Train): 0.27182522416114807; L(Test): 0.2364874929189682\n",
      "Epoch 6703/10000: L(Train): 0.25702598690986633; L(Test): 0.2362537831068039\n",
      "Epoch 6704/10000: L(Train): 0.25561103224754333; L(Test): 0.23726245760917664\n",
      "Epoch 6705/10000: L(Train): 0.27188676595687866; L(Test): 0.241389200091362\n",
      "Epoch 6706/10000: L(Train): 0.2517445385456085; L(Test): 0.24001196026802063\n",
      "Epoch 6707/10000: L(Train): 0.26556074619293213; L(Test): 0.23848958313465118\n",
      "Epoch 6708/10000: L(Train): 0.2637498676776886; L(Test): 0.24243129789829254\n",
      "Epoch 6709/10000: L(Train): 0.2622007131576538; L(Test): 0.24081800878047943\n",
      "Epoch 6710/10000: L(Train): 0.2711050510406494; L(Test): 0.23924076557159424\n",
      "Epoch 6711/10000: L(Train): 0.272348552942276; L(Test): 0.24104511737823486\n",
      "Epoch 6712/10000: L(Train): 0.25104284286499023; L(Test): 0.2397991120815277\n",
      "Epoch 6713/10000: L(Train): 0.2578258812427521; L(Test): 0.239305779337883\n",
      "Epoch 6714/10000: L(Train): 0.2602071762084961; L(Test): 0.2408372312784195\n",
      "Epoch 6715/10000: L(Train): 0.26774412393569946; L(Test): 0.23927858471870422\n",
      "Epoch 6716/10000: L(Train): 0.2642391622066498; L(Test): 0.24019967019557953\n",
      "Epoch 6717/10000: L(Train): 0.27112340927124023; L(Test): 0.23968695104122162\n",
      "Epoch 6718/10000: L(Train): 0.28087860345840454; L(Test): 0.2392234355211258\n",
      "Epoch 6719/10000: L(Train): 0.26230067014694214; L(Test): 0.23922887444496155\n",
      "Epoch 6720/10000: L(Train): 0.2627752721309662; L(Test): 0.24051712453365326\n",
      "Epoch 6721/10000: L(Train): 0.2551787793636322; L(Test): 0.2384510040283203\n",
      "Epoch 6722/10000: L(Train): 0.25796252489089966; L(Test): 0.23971927165985107\n",
      "Epoch 6723/10000: L(Train): 0.2645430266857147; L(Test): 0.23980262875556946\n",
      "Epoch 6724/10000: L(Train): 0.26510876417160034; L(Test): 0.23930959403514862\n",
      "Epoch 6725/10000: L(Train): 0.2696913778781891; L(Test): 0.24127867817878723\n",
      "Epoch 6726/10000: L(Train): 0.26286226511001587; L(Test): 0.24068692326545715\n",
      "Epoch 6727/10000: L(Train): 0.25188761949539185; L(Test): 0.23978890478610992\n",
      "Epoch 6728/10000: L(Train): 0.2581068277359009; L(Test): 0.24236074090003967\n",
      "Epoch 6729/10000: L(Train): 0.2638891339302063; L(Test): 0.24166840314865112\n",
      "Epoch 6730/10000: L(Train): 0.257612943649292; L(Test): 0.24231138825416565\n",
      "Epoch 6731/10000: L(Train): 0.26910439133644104; L(Test): 0.24350814521312714\n",
      "Epoch 6732/10000: L(Train): 0.28661996126174927; L(Test): 0.2406121790409088\n",
      "Epoch 6733/10000: L(Train): 0.250973105430603; L(Test): 0.24139954149723053\n",
      "Epoch 6734/10000: L(Train): 0.25152432918548584; L(Test): 0.24084500968456268\n",
      "Epoch 6735/10000: L(Train): 0.2680915296077728; L(Test): 0.2405124306678772\n",
      "Epoch 6736/10000: L(Train): 0.2613808810710907; L(Test): 0.24136799573898315\n",
      "Epoch 6737/10000: L(Train): 0.2746385335922241; L(Test): 0.23951271176338196\n",
      "Epoch 6738/10000: L(Train): 0.27256467938423157; L(Test): 0.23921725153923035\n",
      "Epoch 6739/10000: L(Train): 0.2520855963230133; L(Test): 0.2392943650484085\n",
      "Epoch 6740/10000: L(Train): 0.24672092497348785; L(Test): 0.23933376371860504\n",
      "Epoch 6741/10000: L(Train): 0.26157087087631226; L(Test): 0.23959694802761078\n",
      "Epoch 6742/10000: L(Train): 0.2621319591999054; L(Test): 0.23879222571849823\n",
      "Epoch 6743/10000: L(Train): 0.2456461489200592; L(Test): 0.2379399836063385\n",
      "Epoch 6744/10000: L(Train): 0.25368526577949524; L(Test): 0.2374761402606964\n",
      "Epoch 6745/10000: L(Train): 0.2544398605823517; L(Test): 0.2372131198644638\n",
      "Epoch 6746/10000: L(Train): 0.26220694184303284; L(Test): 0.23813305795192719\n",
      "Epoch 6747/10000: L(Train): 0.2661040127277374; L(Test): 0.23874324560165405\n",
      "Epoch 6748/10000: L(Train): 0.2674234211444855; L(Test): 0.2379492074251175\n",
      "Epoch 6749/10000: L(Train): 0.2591550052165985; L(Test): 0.23797710239887238\n",
      "Epoch 6750/10000: L(Train): 0.24393488466739655; L(Test): 0.237209752202034\n",
      "Epoch 6751/10000: L(Train): 0.26756566762924194; L(Test): 0.23582711815834045\n",
      "Epoch 6752/10000: L(Train): 0.27304530143737793; L(Test): 0.2373695969581604\n",
      "Epoch 6753/10000: L(Train): 0.2697955071926117; L(Test): 0.23661841452121735\n",
      "Epoch 6754/10000: L(Train): 0.25711163878440857; L(Test): 0.23776187002658844\n",
      "Epoch 6755/10000: L(Train): 0.26856547594070435; L(Test): 0.23766876757144928\n",
      "Epoch 6756/10000: L(Train): 0.2621327340602875; L(Test): 0.23645424842834473\n",
      "Epoch 6757/10000: L(Train): 0.2563011348247528; L(Test): 0.23635949194431305\n",
      "Epoch 6758/10000: L(Train): 0.269733190536499; L(Test): 0.23770076036453247\n",
      "Epoch 6759/10000: L(Train): 0.26088380813598633; L(Test): 0.2376556098461151\n",
      "Epoch 6760/10000: L(Train): 0.259542852640152; L(Test): 0.23650473356246948\n",
      "Epoch 6761/10000: L(Train): 0.260044127702713; L(Test): 0.23704920709133148\n",
      "Epoch 6762/10000: L(Train): 0.25408023595809937; L(Test): 0.23821578919887543\n",
      "Epoch 6763/10000: L(Train): 0.2617320418357849; L(Test): 0.23597900569438934\n",
      "Epoch 6764/10000: L(Train): 0.26062870025634766; L(Test): 0.23578478395938873\n",
      "Epoch 6765/10000: L(Train): 0.25728774070739746; L(Test): 0.23723793029785156\n",
      "Epoch 6766/10000: L(Train): 0.26098641753196716; L(Test): 0.2382226288318634\n",
      "Epoch 6767/10000: L(Train): 0.25196224451065063; L(Test): 0.23837094008922577\n",
      "Epoch 6768/10000: L(Train): 0.2545594573020935; L(Test): 0.23834384977817535\n",
      "Epoch 6769/10000: L(Train): 0.2557028532028198; L(Test): 0.23829232156276703\n",
      "Epoch 6770/10000: L(Train): 0.2674776315689087; L(Test): 0.24033549427986145\n",
      "Epoch 6771/10000: L(Train): 0.2639654874801636; L(Test): 0.23934048414230347\n",
      "Epoch 6772/10000: L(Train): 0.2736043334007263; L(Test): 0.2388053685426712\n",
      "Epoch 6773/10000: L(Train): 0.25912848114967346; L(Test): 0.2422853261232376\n",
      "Epoch 6774/10000: L(Train): 0.2685931622982025; L(Test): 0.239093616604805\n",
      "Epoch 6775/10000: L(Train): 0.2511139214038849; L(Test): 0.2381858378648758\n",
      "Epoch 6776/10000: L(Train): 0.25661876797676086; L(Test): 0.23943936824798584\n",
      "Epoch 6777/10000: L(Train): 0.26526862382888794; L(Test): 0.23934820294380188\n",
      "Epoch 6778/10000: L(Train): 0.25729504227638245; L(Test): 0.23806922137737274\n",
      "Epoch 6779/10000: L(Train): 0.2530936896800995; L(Test): 0.23993802070617676\n",
      "Epoch 6780/10000: L(Train): 0.24304574728012085; L(Test): 0.23872819542884827\n",
      "Epoch 6781/10000: L(Train): 0.26359081268310547; L(Test): 0.23918968439102173\n",
      "Epoch 6782/10000: L(Train): 0.2691502571105957; L(Test): 0.2387630045413971\n",
      "Epoch 6783/10000: L(Train): 0.26030656695365906; L(Test): 0.23896199464797974\n",
      "Epoch 6784/10000: L(Train): 0.2626149654388428; L(Test): 0.23876668512821198\n",
      "Epoch 6785/10000: L(Train): 0.26060038805007935; L(Test): 0.23731665313243866\n",
      "Epoch 6786/10000: L(Train): 0.2620009779930115; L(Test): 0.23694512248039246\n",
      "Epoch 6787/10000: L(Train): 0.25366926193237305; L(Test): 0.23833411931991577\n",
      "Epoch 6788/10000: L(Train): 0.26855820417404175; L(Test): 0.2367689162492752\n",
      "Epoch 6789/10000: L(Train): 0.2515021562576294; L(Test): 0.2373204529285431\n",
      "Epoch 6790/10000: L(Train): 0.25068917870521545; L(Test): 0.23870059847831726\n",
      "Epoch 6791/10000: L(Train): 0.25945332646369934; L(Test): 0.23827259242534637\n",
      "Epoch 6792/10000: L(Train): 0.2529662251472473; L(Test): 0.23723182082176208\n",
      "Epoch 6793/10000: L(Train): 0.26172614097595215; L(Test): 0.2364712655544281\n",
      "Epoch 6794/10000: L(Train): 0.2674318850040436; L(Test): 0.23672904074192047\n",
      "Epoch 6795/10000: L(Train): 0.2489640861749649; L(Test): 0.23628151416778564\n",
      "Epoch 6796/10000: L(Train): 0.2613734006881714; L(Test): 0.23922936618328094\n",
      "Epoch 6797/10000: L(Train): 0.26720842719078064; L(Test): 0.23860858380794525\n",
      "Epoch 6798/10000: L(Train): 0.26472556591033936; L(Test): 0.23761583864688873\n",
      "Epoch 6799/10000: L(Train): 0.2681056559085846; L(Test): 0.23622995615005493\n",
      "Epoch 6800/10000: L(Train): 0.2653886079788208; L(Test): 0.23768462240695953\n",
      "Epoch 6801/10000: L(Train): 0.25405776500701904; L(Test): 0.2376820296049118\n",
      "Epoch 6802/10000: L(Train): 0.27984386682510376; L(Test): 0.23604460060596466\n",
      "Epoch 6803/10000: L(Train): 0.26395508646965027; L(Test): 0.23706063628196716\n",
      "Epoch 6804/10000: L(Train): 0.2595241367816925; L(Test): 0.23718206584453583\n",
      "Epoch 6805/10000: L(Train): 0.26468631625175476; L(Test): 0.23656409978866577\n",
      "Epoch 6806/10000: L(Train): 0.26037201285362244; L(Test): 0.2375798523426056\n",
      "Epoch 6807/10000: L(Train): 0.2559291422367096; L(Test): 0.23565424978733063\n",
      "Epoch 6808/10000: L(Train): 0.25304675102233887; L(Test): 0.23639024794101715\n",
      "Epoch 6809/10000: L(Train): 0.24670207500457764; L(Test): 0.23616325855255127\n",
      "Epoch 6810/10000: L(Train): 0.24960899353027344; L(Test): 0.23753410577774048\n",
      "Epoch 6811/10000: L(Train): 0.2574096620082855; L(Test): 0.23638185858726501\n",
      "Epoch 6812/10000: L(Train): 0.25988245010375977; L(Test): 0.23657362163066864\n",
      "Epoch 6813/10000: L(Train): 0.2622014880180359; L(Test): 0.23631854355335236\n",
      "Epoch 6814/10000: L(Train): 0.2574603259563446; L(Test): 0.23721474409103394\n",
      "Epoch 6815/10000: L(Train): 0.25797179341316223; L(Test): 0.23647987842559814\n",
      "Epoch 6816/10000: L(Train): 0.2569037973880768; L(Test): 0.2352658212184906\n",
      "Epoch 6817/10000: L(Train): 0.2533484995365143; L(Test): 0.23519450426101685\n",
      "Epoch 6818/10000: L(Train): 0.2754802107810974; L(Test): 0.2351677566766739\n",
      "Epoch 6819/10000: L(Train): 0.2682303190231323; L(Test): 0.23494082689285278\n",
      "Epoch 6820/10000: L(Train): 0.2612782418727875; L(Test): 0.23488149046897888\n",
      "Epoch 6821/10000: L(Train): 0.2571462392807007; L(Test): 0.2347421944141388\n",
      "Epoch 6822/10000: L(Train): 0.25105300545692444; L(Test): 0.23487502336502075\n",
      "Epoch 6823/10000: L(Train): 0.2515023350715637; L(Test): 0.23651959002017975\n",
      "Epoch 6824/10000: L(Train): 0.27352067828178406; L(Test): 0.2352597415447235\n",
      "Epoch 6825/10000: L(Train): 0.2466973513364792; L(Test): 0.23496098816394806\n",
      "Epoch 6826/10000: L(Train): 0.24601826071739197; L(Test): 0.2360740303993225\n",
      "Epoch 6827/10000: L(Train): 0.26667752861976624; L(Test): 0.23686085641384125\n",
      "Epoch 6828/10000: L(Train): 0.26137682795524597; L(Test): 0.2351105511188507\n",
      "Epoch 6829/10000: L(Train): 0.26552629470825195; L(Test): 0.235114187002182\n",
      "Epoch 6830/10000: L(Train): 0.269612193107605; L(Test): 0.23604092001914978\n",
      "Epoch 6831/10000: L(Train): 0.2656386196613312; L(Test): 0.23701722919940948\n",
      "Epoch 6832/10000: L(Train): 0.2517712116241455; L(Test): 0.23618827760219574\n",
      "Epoch 6833/10000: L(Train): 0.26476219296455383; L(Test): 0.23662690818309784\n",
      "Epoch 6834/10000: L(Train): 0.26608073711395264; L(Test): 0.23670367896556854\n",
      "Epoch 6835/10000: L(Train): 0.2566254436969757; L(Test): 0.2371620535850525\n",
      "Epoch 6836/10000: L(Train): 0.2642069160938263; L(Test): 0.23676590621471405\n",
      "Epoch 6837/10000: L(Train): 0.24751690030097961; L(Test): 0.2374972105026245\n",
      "Epoch 6838/10000: L(Train): 0.26953864097595215; L(Test): 0.2370924949645996\n",
      "Epoch 6839/10000: L(Train): 0.25199151039123535; L(Test): 0.2363593876361847\n",
      "Epoch 6840/10000: L(Train): 0.2708737552165985; L(Test): 0.23637515306472778\n",
      "Epoch 6841/10000: L(Train): 0.26824167370796204; L(Test): 0.23626570403575897\n",
      "Epoch 6842/10000: L(Train): 0.2541425824165344; L(Test): 0.23676584661006927\n",
      "Epoch 6843/10000: L(Train): 0.2555563449859619; L(Test): 0.23658786714076996\n",
      "Epoch 6844/10000: L(Train): 0.25553953647613525; L(Test): 0.23663389682769775\n",
      "Epoch 6845/10000: L(Train): 0.2710646688938141; L(Test): 0.2360963225364685\n",
      "Epoch 6846/10000: L(Train): 0.26937562227249146; L(Test): 0.23686207830905914\n",
      "Epoch 6847/10000: L(Train): 0.268787682056427; L(Test): 0.23995676636695862\n",
      "Epoch 6848/10000: L(Train): 0.2836875021457672; L(Test): 0.23987022042274475\n",
      "Epoch 6849/10000: L(Train): 0.2706534266471863; L(Test): 0.2386254072189331\n",
      "Epoch 6850/10000: L(Train): 0.2712157964706421; L(Test): 0.2397524118423462\n",
      "Epoch 6851/10000: L(Train): 0.25785839557647705; L(Test): 0.2403562366962433\n",
      "Epoch 6852/10000: L(Train): 0.2799051105976105; L(Test): 0.2379157394170761\n",
      "Epoch 6853/10000: L(Train): 0.2459724247455597; L(Test): 0.23992908000946045\n",
      "Epoch 6854/10000: L(Train): 0.26834315061569214; L(Test): 0.24129769206047058\n",
      "Epoch 6855/10000: L(Train): 0.2619404196739197; L(Test): 0.23989365994930267\n",
      "Epoch 6856/10000: L(Train): 0.2576119303703308; L(Test): 0.2398594617843628\n",
      "Epoch 6857/10000: L(Train): 0.24861350655555725; L(Test): 0.23976054787635803\n",
      "Epoch 6858/10000: L(Train): 0.2727805972099304; L(Test): 0.23860760033130646\n",
      "Epoch 6859/10000: L(Train): 0.2659849226474762; L(Test): 0.23833341896533966\n",
      "Epoch 6860/10000: L(Train): 0.26284465193748474; L(Test): 0.23927713930606842\n",
      "Epoch 6861/10000: L(Train): 0.25969889760017395; L(Test): 0.2388535588979721\n",
      "Epoch 6862/10000: L(Train): 0.2552095055580139; L(Test): 0.23796072602272034\n",
      "Epoch 6863/10000: L(Train): 0.25728413462638855; L(Test): 0.23807382583618164\n",
      "Epoch 6864/10000: L(Train): 0.2516101598739624; L(Test): 0.23825867474079132\n",
      "Epoch 6865/10000: L(Train): 0.2839552164077759; L(Test): 0.23695285618305206\n",
      "Epoch 6866/10000: L(Train): 0.2599211037158966; L(Test): 0.23689259588718414\n",
      "Epoch 6867/10000: L(Train): 0.26674672961235046; L(Test): 0.2388448715209961\n",
      "Epoch 6868/10000: L(Train): 0.2521941363811493; L(Test): 0.23838862776756287\n",
      "Epoch 6869/10000: L(Train): 0.280566543340683; L(Test): 0.2384587973356247\n",
      "Epoch 6870/10000: L(Train): 0.24771186709403992; L(Test): 0.23831862211227417\n",
      "Epoch 6871/10000: L(Train): 0.2615642249584198; L(Test): 0.23858387768268585\n",
      "Epoch 6872/10000: L(Train): 0.26331627368927; L(Test): 0.2378452718257904\n",
      "Epoch 6873/10000: L(Train): 0.2541391849517822; L(Test): 0.23773068189620972\n",
      "Epoch 6874/10000: L(Train): 0.27200940251350403; L(Test): 0.2370034009218216\n",
      "Epoch 6875/10000: L(Train): 0.267031192779541; L(Test): 0.23657894134521484\n",
      "Epoch 6876/10000: L(Train): 0.25343576073646545; L(Test): 0.23685956001281738\n",
      "Epoch 6877/10000: L(Train): 0.2628389596939087; L(Test): 0.2362023890018463\n",
      "Epoch 6878/10000: L(Train): 0.24963048100471497; L(Test): 0.23754040896892548\n",
      "Epoch 6879/10000: L(Train): 0.2579493224620819; L(Test): 0.2405346781015396\n",
      "Epoch 6880/10000: L(Train): 0.2646666467189789; L(Test): 0.23894791305065155\n",
      "Epoch 6881/10000: L(Train): 0.2605867385864258; L(Test): 0.23792193830013275\n",
      "Epoch 6882/10000: L(Train): 0.2546654939651489; L(Test): 0.23906438052654266\n",
      "Epoch 6883/10000: L(Train): 0.2556615173816681; L(Test): 0.23892593383789062\n",
      "Epoch 6884/10000: L(Train): 0.2639782726764679; L(Test): 0.23762895166873932\n",
      "Epoch 6885/10000: L(Train): 0.26356250047683716; L(Test): 0.23765988647937775\n",
      "Epoch 6886/10000: L(Train): 0.25958213210105896; L(Test): 0.23753876984119415\n",
      "Epoch 6887/10000: L(Train): 0.24925626814365387; L(Test): 0.23764587938785553\n",
      "Epoch 6888/10000: L(Train): 0.25890424847602844; L(Test): 0.2370537370443344\n",
      "Epoch 6889/10000: L(Train): 0.2735765278339386; L(Test): 0.2368098348379135\n",
      "Epoch 6890/10000: L(Train): 0.2576102912425995; L(Test): 0.23716726899147034\n",
      "Epoch 6891/10000: L(Train): 0.2562795877456665; L(Test): 0.23668527603149414\n",
      "Epoch 6892/10000: L(Train): 0.25295576453208923; L(Test): 0.2364078015089035\n",
      "Epoch 6893/10000: L(Train): 0.2687941789627075; L(Test): 0.23737603425979614\n",
      "Epoch 6894/10000: L(Train): 0.2498953491449356; L(Test): 0.23707696795463562\n",
      "Epoch 6895/10000: L(Train): 0.25613221526145935; L(Test): 0.2360607534646988\n",
      "Epoch 6896/10000: L(Train): 0.2574383318424225; L(Test): 0.23611588776111603\n",
      "Epoch 6897/10000: L(Train): 0.2706226408481598; L(Test): 0.23612619936466217\n",
      "Epoch 6898/10000: L(Train): 0.24706783890724182; L(Test): 0.23565906286239624\n",
      "Epoch 6899/10000: L(Train): 0.2573612928390503; L(Test): 0.23608778417110443\n",
      "Epoch 6900/10000: L(Train): 0.24778012931346893; L(Test): 0.23575003445148468\n",
      "Epoch 6901/10000: L(Train): 0.25822845101356506; L(Test): 0.23566384613513947\n",
      "Epoch 6902/10000: L(Train): 0.25121939182281494; L(Test): 0.2358373999595642\n",
      "Epoch 6903/10000: L(Train): 0.2589883506298065; L(Test): 0.2368326336145401\n",
      "Epoch 6904/10000: L(Train): 0.26481732726097107; L(Test): 0.23752188682556152\n",
      "Epoch 6905/10000: L(Train): 0.25174644589424133; L(Test): 0.23730483651161194\n",
      "Epoch 6906/10000: L(Train): 0.25687605142593384; L(Test): 0.2366795837879181\n",
      "Epoch 6907/10000: L(Train): 0.27553194761276245; L(Test): 0.236493319272995\n",
      "Epoch 6908/10000: L(Train): 0.2632489502429962; L(Test): 0.23599134385585785\n",
      "Epoch 6909/10000: L(Train): 0.2527066469192505; L(Test): 0.23598378896713257\n",
      "Epoch 6910/10000: L(Train): 0.2598072290420532; L(Test): 0.23597656190395355\n",
      "Epoch 6911/10000: L(Train): 0.2599959969520569; L(Test): 0.23659807443618774\n",
      "Epoch 6912/10000: L(Train): 0.2577613592147827; L(Test): 0.23796437680721283\n",
      "Epoch 6913/10000: L(Train): 0.25784730911254883; L(Test): 0.2368621677160263\n",
      "Epoch 6914/10000: L(Train): 0.25829243659973145; L(Test): 0.23761841654777527\n",
      "Epoch 6915/10000: L(Train): 0.26681259274482727; L(Test): 0.23880308866500854\n",
      "Epoch 6916/10000: L(Train): 0.24886274337768555; L(Test): 0.23747006058692932\n",
      "Epoch 6917/10000: L(Train): 0.25524091720581055; L(Test): 0.23642081022262573\n",
      "Epoch 6918/10000: L(Train): 0.25270894169807434; L(Test): 0.23628923296928406\n",
      "Epoch 6919/10000: L(Train): 0.25452685356140137; L(Test): 0.23687124252319336\n",
      "Epoch 6920/10000: L(Train): 0.2531748116016388; L(Test): 0.2374781370162964\n",
      "Epoch 6921/10000: L(Train): 0.25852230191230774; L(Test): 0.23630507290363312\n",
      "Epoch 6922/10000: L(Train): 0.26370203495025635; L(Test): 0.2360847443342209\n",
      "Epoch 6923/10000: L(Train): 0.25777122378349304; L(Test): 0.23668986558914185\n",
      "Epoch 6924/10000: L(Train): 0.26512110233306885; L(Test): 0.23671424388885498\n",
      "Epoch 6925/10000: L(Train): 0.25195905566215515; L(Test): 0.2362765371799469\n",
      "Epoch 6926/10000: L(Train): 0.2559495270252228; L(Test): 0.2370622456073761\n",
      "Epoch 6927/10000: L(Train): 0.257948100566864; L(Test): 0.237218976020813\n",
      "Epoch 6928/10000: L(Train): 0.2675572633743286; L(Test): 0.23749229311943054\n",
      "Epoch 6929/10000: L(Train): 0.26061469316482544; L(Test): 0.23730744421482086\n",
      "Epoch 6930/10000: L(Train): 0.2584814429283142; L(Test): 0.23971669375896454\n",
      "Epoch 6931/10000: L(Train): 0.2697852849960327; L(Test): 0.24037134647369385\n",
      "Epoch 6932/10000: L(Train): 0.2513965964317322; L(Test): 0.23848244547843933\n",
      "Epoch 6933/10000: L(Train): 0.2565893828868866; L(Test): 0.23856191337108612\n",
      "Epoch 6934/10000: L(Train): 0.2574637234210968; L(Test): 0.23922817409038544\n",
      "Epoch 6935/10000: L(Train): 0.2612625062465668; L(Test): 0.23775076866149902\n",
      "Epoch 6936/10000: L(Train): 0.25791746377944946; L(Test): 0.23783078789710999\n",
      "Epoch 6937/10000: L(Train): 0.25693589448928833; L(Test): 0.2375486195087433\n",
      "Epoch 6938/10000: L(Train): 0.2416944056749344; L(Test): 0.23709946870803833\n",
      "Epoch 6939/10000: L(Train): 0.2625470459461212; L(Test): 0.23668693006038666\n",
      "Epoch 6940/10000: L(Train): 0.25930333137512207; L(Test): 0.23744405806064606\n",
      "Epoch 6941/10000: L(Train): 0.2698972225189209; L(Test): 0.2378125637769699\n",
      "Epoch 6942/10000: L(Train): 0.2536270320415497; L(Test): 0.2363765984773636\n",
      "Epoch 6943/10000: L(Train): 0.2505963146686554; L(Test): 0.23653775453567505\n",
      "Epoch 6944/10000: L(Train): 0.2701428532600403; L(Test): 0.2380005121231079\n",
      "Epoch 6945/10000: L(Train): 0.27414774894714355; L(Test): 0.23756201565265656\n",
      "Epoch 6946/10000: L(Train): 0.2587979733943939; L(Test): 0.23668551445007324\n",
      "Epoch 6947/10000: L(Train): 0.2634124755859375; L(Test): 0.23733045160770416\n",
      "Epoch 6948/10000: L(Train): 0.26785820722579956; L(Test): 0.24002467095851898\n",
      "Epoch 6949/10000: L(Train): 0.2681857645511627; L(Test): 0.24017442762851715\n",
      "Epoch 6950/10000: L(Train): 0.26528772711753845; L(Test): 0.23811893165111542\n",
      "Epoch 6951/10000: L(Train): 0.27026909589767456; L(Test): 0.24063318967819214\n",
      "Epoch 6952/10000: L(Train): 0.26191526651382446; L(Test): 0.23735302686691284\n",
      "Epoch 6953/10000: L(Train): 0.2748784124851227; L(Test): 0.2397952526807785\n",
      "Epoch 6954/10000: L(Train): 0.26899832487106323; L(Test): 0.23784618079662323\n",
      "Epoch 6955/10000: L(Train): 0.2704841196537018; L(Test): 0.23947615921497345\n",
      "Epoch 6956/10000: L(Train): 0.258998304605484; L(Test): 0.24009637534618378\n",
      "Epoch 6957/10000: L(Train): 0.2607967257499695; L(Test): 0.23744165897369385\n",
      "Epoch 6958/10000: L(Train): 0.2661208510398865; L(Test): 0.24061383306980133\n",
      "Epoch 6959/10000: L(Train): 0.2634674608707428; L(Test): 0.23772774636745453\n",
      "Epoch 6960/10000: L(Train): 0.26530739665031433; L(Test): 0.2385743260383606\n",
      "Epoch 6961/10000: L(Train): 0.24988314509391785; L(Test): 0.23913708329200745\n",
      "Epoch 6962/10000: L(Train): 0.27406492829322815; L(Test): 0.23819485306739807\n",
      "Epoch 6963/10000: L(Train): 0.25205960869789124; L(Test): 0.24133934080600739\n",
      "Epoch 6964/10000: L(Train): 0.2552450895309448; L(Test): 0.23767225444316864\n",
      "Epoch 6965/10000: L(Train): 0.2644908130168915; L(Test): 0.23902596533298492\n",
      "Epoch 6966/10000: L(Train): 0.25243568420410156; L(Test): 0.23685893416404724\n",
      "Epoch 6967/10000: L(Train): 0.26505908370018005; L(Test): 0.2380428910255432\n",
      "Epoch 6968/10000: L(Train): 0.26639842987060547; L(Test): 0.23923224210739136\n",
      "Epoch 6969/10000: L(Train): 0.27430567145347595; L(Test): 0.23698778450489044\n",
      "Epoch 6970/10000: L(Train): 0.27395105361938477; L(Test): 0.23811618983745575\n",
      "Epoch 6971/10000: L(Train): 0.26867353916168213; L(Test): 0.2361314743757248\n",
      "Epoch 6972/10000: L(Train): 0.27136313915252686; L(Test): 0.23944389820098877\n",
      "Epoch 6973/10000: L(Train): 0.27384406328201294; L(Test): 0.23761869966983795\n",
      "Epoch 6974/10000: L(Train): 0.26133421063423157; L(Test): 0.23626242578029633\n",
      "Epoch 6975/10000: L(Train): 0.2513236403465271; L(Test): 0.2370549738407135\n",
      "Epoch 6976/10000: L(Train): 0.26992058753967285; L(Test): 0.23623409867286682\n",
      "Epoch 6977/10000: L(Train): 0.2563230097293854; L(Test): 0.23753765225410461\n",
      "Epoch 6978/10000: L(Train): 0.2526122033596039; L(Test): 0.23810075223445892\n",
      "Epoch 6979/10000: L(Train): 0.25897926092147827; L(Test): 0.23669575154781342\n",
      "Epoch 6980/10000: L(Train): 0.27225252985954285; L(Test): 0.23737987875938416\n",
      "Epoch 6981/10000: L(Train): 0.2563636302947998; L(Test): 0.23626765608787537\n",
      "Epoch 6982/10000: L(Train): 0.26555490493774414; L(Test): 0.23725862801074982\n",
      "Epoch 6983/10000: L(Train): 0.2706684172153473; L(Test): 0.23674866557121277\n",
      "Epoch 6984/10000: L(Train): 0.26506003737449646; L(Test): 0.23734205961227417\n",
      "Epoch 6985/10000: L(Train): 0.25908687710762024; L(Test): 0.23799903690814972\n",
      "Epoch 6986/10000: L(Train): 0.2601957321166992; L(Test): 0.23678621649742126\n",
      "Epoch 6987/10000: L(Train): 0.25916406512260437; L(Test): 0.23781684041023254\n",
      "Epoch 6988/10000: L(Train): 0.2423211932182312; L(Test): 0.23933227360248566\n",
      "Epoch 6989/10000: L(Train): 0.25506356358528137; L(Test): 0.2377365380525589\n",
      "Epoch 6990/10000: L(Train): 0.2450992912054062; L(Test): 0.2365221232175827\n",
      "Epoch 6991/10000: L(Train): 0.2769201397895813; L(Test): 0.23703651130199432\n",
      "Epoch 6992/10000: L(Train): 0.27009251713752747; L(Test): 0.23772186040878296\n",
      "Epoch 6993/10000: L(Train): 0.26077407598495483; L(Test): 0.2387794703245163\n",
      "Epoch 6994/10000: L(Train): 0.2750711143016815; L(Test): 0.23749084770679474\n",
      "Epoch 6995/10000: L(Train): 0.26678165793418884; L(Test): 0.23772285878658295\n",
      "Epoch 6996/10000: L(Train): 0.26825475692749023; L(Test): 0.23758839070796967\n",
      "Epoch 6997/10000: L(Train): 0.2640502154827118; L(Test): 0.2369724065065384\n",
      "Epoch 6998/10000: L(Train): 0.2616090476512909; L(Test): 0.23671504855155945\n",
      "Epoch 6999/10000: L(Train): 0.2655234932899475; L(Test): 0.23813442885875702\n",
      "Epoch 7000/10000: L(Train): 0.26013487577438354; L(Test): 0.2369619458913803\n",
      "Epoch 7001/10000: L(Train): 0.25611093640327454; L(Test): 0.23738707602024078\n",
      "Epoch 7002/10000: L(Train): 0.26865243911743164; L(Test): 0.23737484216690063\n",
      "Epoch 7003/10000: L(Train): 0.25734201073646545; L(Test): 0.23704023659229279\n",
      "Epoch 7004/10000: L(Train): 0.25277891755104065; L(Test): 0.23704107105731964\n",
      "Epoch 7005/10000: L(Train): 0.2553049325942993; L(Test): 0.23721091449260712\n",
      "Epoch 7006/10000: L(Train): 0.24813330173492432; L(Test): 0.2376815527677536\n",
      "Epoch 7007/10000: L(Train): 0.25639796257019043; L(Test): 0.23763950169086456\n",
      "Epoch 7008/10000: L(Train): 0.26126670837402344; L(Test): 0.23794353008270264\n",
      "Epoch 7009/10000: L(Train): 0.2549614906311035; L(Test): 0.23692819476127625\n",
      "Epoch 7010/10000: L(Train): 0.24381382763385773; L(Test): 0.23735074698925018\n",
      "Epoch 7011/10000: L(Train): 0.2663033902645111; L(Test): 0.23630522191524506\n",
      "Epoch 7012/10000: L(Train): 0.2544262707233429; L(Test): 0.2364022135734558\n",
      "Epoch 7013/10000: L(Train): 0.2733488082885742; L(Test): 0.23711861670017242\n",
      "Epoch 7014/10000: L(Train): 0.2580505907535553; L(Test): 0.2373904287815094\n",
      "Epoch 7015/10000: L(Train): 0.2633669674396515; L(Test): 0.23624740540981293\n",
      "Epoch 7016/10000: L(Train): 0.2565840184688568; L(Test): 0.23735342919826508\n",
      "Epoch 7017/10000: L(Train): 0.25553423166275024; L(Test): 0.23654697835445404\n",
      "Epoch 7018/10000: L(Train): 0.27028894424438477; L(Test): 0.23647302389144897\n",
      "Epoch 7019/10000: L(Train): 0.2595352530479431; L(Test): 0.23571912944316864\n",
      "Epoch 7020/10000: L(Train): 0.2651515603065491; L(Test): 0.23592305183410645\n",
      "Epoch 7021/10000: L(Train): 0.25523728132247925; L(Test): 0.23644176125526428\n",
      "Epoch 7022/10000: L(Train): 0.2498682588338852; L(Test): 0.23670241236686707\n",
      "Epoch 7023/10000: L(Train): 0.2546346187591553; L(Test): 0.23653464019298553\n",
      "Epoch 7024/10000: L(Train): 0.25615766644477844; L(Test): 0.23642317950725555\n",
      "Epoch 7025/10000: L(Train): 0.26524657011032104; L(Test): 0.23718789219856262\n",
      "Epoch 7026/10000: L(Train): 0.26175928115844727; L(Test): 0.23663489520549774\n",
      "Epoch 7027/10000: L(Train): 0.2659178376197815; L(Test): 0.2355363816022873\n",
      "Epoch 7028/10000: L(Train): 0.25710591673851013; L(Test): 0.23679541051387787\n",
      "Epoch 7029/10000: L(Train): 0.2602505385875702; L(Test): 0.23655013740062714\n",
      "Epoch 7030/10000: L(Train): 0.26882249116897583; L(Test): 0.2364642322063446\n",
      "Epoch 7031/10000: L(Train): 0.267537385225296; L(Test): 0.2358352392911911\n",
      "Epoch 7032/10000: L(Train): 0.2571502923965454; L(Test): 0.23592282831668854\n",
      "Epoch 7033/10000: L(Train): 0.26996293663978577; L(Test): 0.2354319542646408\n",
      "Epoch 7034/10000: L(Train): 0.26486170291900635; L(Test): 0.23596324026584625\n",
      "Epoch 7035/10000: L(Train): 0.25857600569725037; L(Test): 0.23649980127811432\n",
      "Epoch 7036/10000: L(Train): 0.2688572406768799; L(Test): 0.23518924415111542\n",
      "Epoch 7037/10000: L(Train): 0.2492254227399826; L(Test): 0.23553915321826935\n",
      "Epoch 7038/10000: L(Train): 0.25615382194519043; L(Test): 0.23560146987438202\n",
      "Epoch 7039/10000: L(Train): 0.263611763715744; L(Test): 0.23495042324066162\n",
      "Epoch 7040/10000: L(Train): 0.2527431845664978; L(Test): 0.23635688424110413\n",
      "Epoch 7041/10000: L(Train): 0.24972352385520935; L(Test): 0.2365526705980301\n",
      "Epoch 7042/10000: L(Train): 0.2551639974117279; L(Test): 0.2356453835964203\n",
      "Epoch 7043/10000: L(Train): 0.2786894738674164; L(Test): 0.23595118522644043\n",
      "Epoch 7044/10000: L(Train): 0.2579791247844696; L(Test): 0.23569683730602264\n",
      "Epoch 7045/10000: L(Train): 0.2698623538017273; L(Test): 0.23594745993614197\n",
      "Epoch 7046/10000: L(Train): 0.24989545345306396; L(Test): 0.23584334552288055\n",
      "Epoch 7047/10000: L(Train): 0.25819069147109985; L(Test): 0.23605424165725708\n",
      "Epoch 7048/10000: L(Train): 0.2555887699127197; L(Test): 0.23661866784095764\n",
      "Epoch 7049/10000: L(Train): 0.2520499527454376; L(Test): 0.2362164705991745\n",
      "Epoch 7050/10000: L(Train): 0.24852636456489563; L(Test): 0.23704180121421814\n",
      "Epoch 7051/10000: L(Train): 0.26631179451942444; L(Test): 0.2377290576696396\n",
      "Epoch 7052/10000: L(Train): 0.26485469937324524; L(Test): 0.2402373105287552\n",
      "Epoch 7053/10000: L(Train): 0.24412189424037933; L(Test): 0.23861491680145264\n",
      "Epoch 7054/10000: L(Train): 0.2622624337673187; L(Test): 0.23965251445770264\n",
      "Epoch 7055/10000: L(Train): 0.267476350069046; L(Test): 0.23979084193706512\n",
      "Epoch 7056/10000: L(Train): 0.25652042031288147; L(Test): 0.23803402483463287\n",
      "Epoch 7057/10000: L(Train): 0.2628110647201538; L(Test): 0.24002166092395782\n",
      "Epoch 7058/10000: L(Train): 0.2621252238750458; L(Test): 0.2387963980436325\n",
      "Epoch 7059/10000: L(Train): 0.27032211422920227; L(Test): 0.23778456449508667\n",
      "Epoch 7060/10000: L(Train): 0.2648053467273712; L(Test): 0.2377212792634964\n",
      "Epoch 7061/10000: L(Train): 0.2584037482738495; L(Test): 0.23999305069446564\n",
      "Epoch 7062/10000: L(Train): 0.27128756046295166; L(Test): 0.23691023886203766\n",
      "Epoch 7063/10000: L(Train): 0.2561472952365875; L(Test): 0.23725371062755585\n",
      "Epoch 7064/10000: L(Train): 0.26516059041023254; L(Test): 0.2380123883485794\n",
      "Epoch 7065/10000: L(Train): 0.25117260217666626; L(Test): 0.23827393352985382\n",
      "Epoch 7066/10000: L(Train): 0.2680680751800537; L(Test): 0.23761127889156342\n",
      "Epoch 7067/10000: L(Train): 0.2699117064476013; L(Test): 0.236665740609169\n",
      "Epoch 7068/10000: L(Train): 0.2526857554912567; L(Test): 0.23736214637756348\n",
      "Epoch 7069/10000: L(Train): 0.27599987387657166; L(Test): 0.2383916676044464\n",
      "Epoch 7070/10000: L(Train): 0.27220940589904785; L(Test): 0.23723258078098297\n",
      "Epoch 7071/10000: L(Train): 0.2576020359992981; L(Test): 0.23705032467842102\n",
      "Epoch 7072/10000: L(Train): 0.26582902669906616; L(Test): 0.23754790425300598\n",
      "Epoch 7073/10000: L(Train): 0.25791338086128235; L(Test): 0.23655740916728973\n",
      "Epoch 7074/10000: L(Train): 0.24181130528450012; L(Test): 0.23672647774219513\n",
      "Epoch 7075/10000: L(Train): 0.25977492332458496; L(Test): 0.23735781013965607\n",
      "Epoch 7076/10000: L(Train): 0.2538903057575226; L(Test): 0.2381121665239334\n",
      "Epoch 7077/10000: L(Train): 0.2549828588962555; L(Test): 0.23746374249458313\n",
      "Epoch 7078/10000: L(Train): 0.26007598638534546; L(Test): 0.2364572286605835\n",
      "Epoch 7079/10000: L(Train): 0.2610248923301697; L(Test): 0.23709110915660858\n",
      "Epoch 7080/10000: L(Train): 0.26995694637298584; L(Test): 0.2369077354669571\n",
      "Epoch 7081/10000: L(Train): 0.23859182000160217; L(Test): 0.23673924803733826\n",
      "Epoch 7082/10000: L(Train): 0.2582109868526459; L(Test): 0.2367776483297348\n",
      "Epoch 7083/10000: L(Train): 0.2539937496185303; L(Test): 0.2364189326763153\n",
      "Epoch 7084/10000: L(Train): 0.2540465295314789; L(Test): 0.23590187728405\n",
      "Epoch 7085/10000: L(Train): 0.24682243168354034; L(Test): 0.2357913702726364\n",
      "Epoch 7086/10000: L(Train): 0.2579118311405182; L(Test): 0.23670567572116852\n",
      "Epoch 7087/10000: L(Train): 0.26916423439979553; L(Test): 0.23561304807662964\n",
      "Epoch 7088/10000: L(Train): 0.2531094551086426; L(Test): 0.23696202039718628\n",
      "Epoch 7089/10000: L(Train): 0.26359322667121887; L(Test): 0.2357778549194336\n",
      "Epoch 7090/10000: L(Train): 0.24766004085540771; L(Test): 0.23677140474319458\n",
      "Epoch 7091/10000: L(Train): 0.26221707463264465; L(Test): 0.23578637838363647\n",
      "Epoch 7092/10000: L(Train): 0.2606806457042694; L(Test): 0.23585382103919983\n",
      "Epoch 7093/10000: L(Train): 0.2615143358707428; L(Test): 0.23574531078338623\n",
      "Epoch 7094/10000: L(Train): 0.24916604161262512; L(Test): 0.2368423193693161\n",
      "Epoch 7095/10000: L(Train): 0.26004335284233093; L(Test): 0.23727193474769592\n",
      "Epoch 7096/10000: L(Train): 0.26344960927963257; L(Test): 0.23712754249572754\n",
      "Epoch 7097/10000: L(Train): 0.26715150475502014; L(Test): 0.2364509254693985\n",
      "Epoch 7098/10000: L(Train): 0.2601845860481262; L(Test): 0.23529455065727234\n",
      "Epoch 7099/10000: L(Train): 0.2614727318286896; L(Test): 0.23556622862815857\n",
      "Epoch 7100/10000: L(Train): 0.26546511054039; L(Test): 0.23662643134593964\n",
      "Epoch 7101/10000: L(Train): 0.26261383295059204; L(Test): 0.23542851209640503\n",
      "Epoch 7102/10000: L(Train): 0.24776048958301544; L(Test): 0.23589785397052765\n",
      "Epoch 7103/10000: L(Train): 0.2678819000720978; L(Test): 0.2361573874950409\n",
      "Epoch 7104/10000: L(Train): 0.2610852122306824; L(Test): 0.23584207892417908\n",
      "Epoch 7105/10000: L(Train): 0.2527252733707428; L(Test): 0.23583024740219116\n",
      "Epoch 7106/10000: L(Train): 0.24951979517936707; L(Test): 0.23603618144989014\n",
      "Epoch 7107/10000: L(Train): 0.25444599986076355; L(Test): 0.2356850802898407\n",
      "Epoch 7108/10000: L(Train): 0.25966310501098633; L(Test): 0.23499949276447296\n",
      "Epoch 7109/10000: L(Train): 0.2743421196937561; L(Test): 0.23494510352611542\n",
      "Epoch 7110/10000: L(Train): 0.2717207670211792; L(Test): 0.23529645800590515\n",
      "Epoch 7111/10000: L(Train): 0.26153820753097534; L(Test): 0.23623694479465485\n",
      "Epoch 7112/10000: L(Train): 0.2639647126197815; L(Test): 0.23675090074539185\n",
      "Epoch 7113/10000: L(Train): 0.24666790664196014; L(Test): 0.23556625843048096\n",
      "Epoch 7114/10000: L(Train): 0.25519222021102905; L(Test): 0.23627009987831116\n",
      "Epoch 7115/10000: L(Train): 0.266286700963974; L(Test): 0.2361287772655487\n",
      "Epoch 7116/10000: L(Train): 0.27125611901283264; L(Test): 0.23662921786308289\n",
      "Epoch 7117/10000: L(Train): 0.26790761947631836; L(Test): 0.2369096279144287\n",
      "Epoch 7118/10000: L(Train): 0.2662048637866974; L(Test): 0.23534324765205383\n",
      "Epoch 7119/10000: L(Train): 0.2663734257221222; L(Test): 0.23618261516094208\n",
      "Epoch 7120/10000: L(Train): 0.2737204134464264; L(Test): 0.23582999408245087\n",
      "Epoch 7121/10000: L(Train): 0.25194135308265686; L(Test): 0.2363845407962799\n",
      "Epoch 7122/10000: L(Train): 0.28200215101242065; L(Test): 0.23591016232967377\n",
      "Epoch 7123/10000: L(Train): 0.25916534662246704; L(Test): 0.23652932047843933\n",
      "Epoch 7124/10000: L(Train): 0.23712478578090668; L(Test): 0.2358551025390625\n",
      "Epoch 7125/10000: L(Train): 0.2713256776332855; L(Test): 0.2357041835784912\n",
      "Epoch 7126/10000: L(Train): 0.2653149962425232; L(Test): 0.23602022230625153\n",
      "Epoch 7127/10000: L(Train): 0.25485318899154663; L(Test): 0.23674385249614716\n",
      "Epoch 7128/10000: L(Train): 0.24550266563892365; L(Test): 0.23759080469608307\n",
      "Epoch 7129/10000: L(Train): 0.26115596294403076; L(Test): 0.23713025450706482\n",
      "Epoch 7130/10000: L(Train): 0.26389241218566895; L(Test): 0.23636466264724731\n",
      "Epoch 7131/10000: L(Train): 0.25761404633522034; L(Test): 0.23663370311260223\n",
      "Epoch 7132/10000: L(Train): 0.25312182307243347; L(Test): 0.23666912317276\n",
      "Epoch 7133/10000: L(Train): 0.2525506913661957; L(Test): 0.23682211339473724\n",
      "Epoch 7134/10000: L(Train): 0.25973477959632874; L(Test): 0.23629184067249298\n",
      "Epoch 7135/10000: L(Train): 0.26619547605514526; L(Test): 0.23597536981105804\n",
      "Epoch 7136/10000: L(Train): 0.24806411564350128; L(Test): 0.23659278452396393\n",
      "Epoch 7137/10000: L(Train): 0.2657887041568756; L(Test): 0.235854372382164\n",
      "Epoch 7138/10000: L(Train): 0.2523624300956726; L(Test): 0.2360023558139801\n",
      "Epoch 7139/10000: L(Train): 0.2545974850654602; L(Test): 0.23652184009552002\n",
      "Epoch 7140/10000: L(Train): 0.26493316888809204; L(Test): 0.23618701100349426\n",
      "Epoch 7141/10000: L(Train): 0.2550022602081299; L(Test): 0.23627737164497375\n",
      "Epoch 7142/10000: L(Train): 0.2712964117527008; L(Test): 0.2372952103614807\n",
      "Epoch 7143/10000: L(Train): 0.2526599168777466; L(Test): 0.23673833906650543\n",
      "Epoch 7144/10000: L(Train): 0.2625546455383301; L(Test): 0.2359643280506134\n",
      "Epoch 7145/10000: L(Train): 0.2708622217178345; L(Test): 0.23654893040657043\n",
      "Epoch 7146/10000: L(Train): 0.2552943527698517; L(Test): 0.23554487526416779\n",
      "Epoch 7147/10000: L(Train): 0.263550728559494; L(Test): 0.23553231358528137\n",
      "Epoch 7148/10000: L(Train): 0.2567446529865265; L(Test): 0.2358185201883316\n",
      "Epoch 7149/10000: L(Train): 0.2470470666885376; L(Test): 0.236228346824646\n",
      "Epoch 7150/10000: L(Train): 0.2645963430404663; L(Test): 0.23561261594295502\n",
      "Epoch 7151/10000: L(Train): 0.24595752358436584; L(Test): 0.23532280325889587\n",
      "Epoch 7152/10000: L(Train): 0.249899223446846; L(Test): 0.23530343174934387\n",
      "Epoch 7153/10000: L(Train): 0.26359814405441284; L(Test): 0.23634043335914612\n",
      "Epoch 7154/10000: L(Train): 0.26225578784942627; L(Test): 0.2366575449705124\n",
      "Epoch 7155/10000: L(Train): 0.2553330957889557; L(Test): 0.2356574833393097\n",
      "Epoch 7156/10000: L(Train): 0.23496176302433014; L(Test): 0.2355622798204422\n",
      "Epoch 7157/10000: L(Train): 0.26039451360702515; L(Test): 0.23644691705703735\n",
      "Epoch 7158/10000: L(Train): 0.27299174666404724; L(Test): 0.23539483547210693\n",
      "Epoch 7159/10000: L(Train): 0.26362165808677673; L(Test): 0.2372351884841919\n",
      "Epoch 7160/10000: L(Train): 0.25811246037483215; L(Test): 0.23749496042728424\n",
      "Epoch 7161/10000: L(Train): 0.2570306360721588; L(Test): 0.23602835834026337\n",
      "Epoch 7162/10000: L(Train): 0.2727713882923126; L(Test): 0.23670744895935059\n",
      "Epoch 7163/10000: L(Train): 0.2742542326450348; L(Test): 0.23703187704086304\n",
      "Epoch 7164/10000: L(Train): 0.24424844980239868; L(Test): 0.23933903872966766\n",
      "Epoch 7165/10000: L(Train): 0.2583038806915283; L(Test): 0.2360922247171402\n",
      "Epoch 7166/10000: L(Train): 0.27377212047576904; L(Test): 0.2395499348640442\n",
      "Epoch 7167/10000: L(Train): 0.2516908347606659; L(Test): 0.2370263934135437\n",
      "Epoch 7168/10000: L(Train): 0.25840362906455994; L(Test): 0.24037446081638336\n",
      "Epoch 7169/10000: L(Train): 0.2565326392650604; L(Test): 0.23640914261341095\n",
      "Epoch 7170/10000: L(Train): 0.2731233239173889; L(Test): 0.23941244184970856\n",
      "Epoch 7171/10000: L(Train): 0.27357184886932373; L(Test): 0.2373574674129486\n",
      "Epoch 7172/10000: L(Train): 0.25875920057296753; L(Test): 0.23821350932121277\n",
      "Epoch 7173/10000: L(Train): 0.27383551001548767; L(Test): 0.23888063430786133\n",
      "Epoch 7174/10000: L(Train): 0.270809531211853; L(Test): 0.23733942210674286\n",
      "Epoch 7175/10000: L(Train): 0.25766608119010925; L(Test): 0.23777154088020325\n",
      "Epoch 7176/10000: L(Train): 0.254516065120697; L(Test): 0.23713956773281097\n",
      "Epoch 7177/10000: L(Train): 0.25976333022117615; L(Test): 0.23934972286224365\n",
      "Epoch 7178/10000: L(Train): 0.2762758433818817; L(Test): 0.23679868876934052\n",
      "Epoch 7179/10000: L(Train): 0.2732211947441101; L(Test): 0.23780567944049835\n",
      "Epoch 7180/10000: L(Train): 0.2621820867061615; L(Test): 0.23853187263011932\n",
      "Epoch 7181/10000: L(Train): 0.24944743514060974; L(Test): 0.23858532309532166\n",
      "Epoch 7182/10000: L(Train): 0.26127728819847107; L(Test): 0.237870454788208\n",
      "Epoch 7183/10000: L(Train): 0.2815310060977936; L(Test): 0.23625117540359497\n",
      "Epoch 7184/10000: L(Train): 0.2600460648536682; L(Test): 0.23718327283859253\n",
      "Epoch 7185/10000: L(Train): 0.25165581703186035; L(Test): 0.23632006347179413\n",
      "Epoch 7186/10000: L(Train): 0.25740912556648254; L(Test): 0.23690654337406158\n",
      "Epoch 7187/10000: L(Train): 0.2551715075969696; L(Test): 0.2361183911561966\n",
      "Epoch 7188/10000: L(Train): 0.24777692556381226; L(Test): 0.23621100187301636\n",
      "Epoch 7189/10000: L(Train): 0.25094273686408997; L(Test): 0.23635642230510712\n",
      "Epoch 7190/10000: L(Train): 0.27508416771888733; L(Test): 0.23570846021175385\n",
      "Epoch 7191/10000: L(Train): 0.2586895227432251; L(Test): 0.23623086512088776\n",
      "Epoch 7192/10000: L(Train): 0.25910788774490356; L(Test): 0.23653154075145721\n",
      "Epoch 7193/10000: L(Train): 0.267841637134552; L(Test): 0.23593218624591827\n",
      "Epoch 7194/10000: L(Train): 0.25222328305244446; L(Test): 0.23692193627357483\n",
      "Epoch 7195/10000: L(Train): 0.2719193696975708; L(Test): 0.23697279393672943\n",
      "Epoch 7196/10000: L(Train): 0.2590180039405823; L(Test): 0.23715059459209442\n",
      "Epoch 7197/10000: L(Train): 0.26920413970947266; L(Test): 0.23602817952632904\n",
      "Epoch 7198/10000: L(Train): 0.2614361643791199; L(Test): 0.23651446402072906\n",
      "Epoch 7199/10000: L(Train): 0.26745885610580444; L(Test): 0.2367892563343048\n",
      "Epoch 7200/10000: L(Train): 0.2625485956668854; L(Test): 0.23733432590961456\n",
      "Epoch 7201/10000: L(Train): 0.25353506207466125; L(Test): 0.23828940093517303\n",
      "Epoch 7202/10000: L(Train): 0.2603600323200226; L(Test): 0.24360710382461548\n",
      "Epoch 7203/10000: L(Train): 0.2714270353317261; L(Test): 0.24375608563423157\n",
      "Epoch 7204/10000: L(Train): 0.26451873779296875; L(Test): 0.24513082206249237\n",
      "Epoch 7205/10000: L(Train): 0.2697862982749939; L(Test): 0.2438649982213974\n",
      "Epoch 7206/10000: L(Train): 0.25722265243530273; L(Test): 0.247514009475708\n",
      "Epoch 7207/10000: L(Train): 0.2744940221309662; L(Test): 0.24657995998859406\n",
      "Epoch 7208/10000: L(Train): 0.26712334156036377; L(Test): 0.24477888643741608\n",
      "Epoch 7209/10000: L(Train): 0.2704157829284668; L(Test): 0.24529726803302765\n",
      "Epoch 7210/10000: L(Train): 0.26798006892204285; L(Test): 0.24688105285167694\n",
      "Epoch 7211/10000: L(Train): 0.2628398835659027; L(Test): 0.24820993840694427\n",
      "Epoch 7212/10000: L(Train): 0.2700823247432709; L(Test): 0.24576783180236816\n",
      "Epoch 7213/10000: L(Train): 0.26772165298461914; L(Test): 0.2465328425168991\n",
      "Epoch 7214/10000: L(Train): 0.26637744903564453; L(Test): 0.2465038299560547\n",
      "Epoch 7215/10000: L(Train): 0.27017298340797424; L(Test): 0.2441619634628296\n",
      "Epoch 7216/10000: L(Train): 0.25078439712524414; L(Test): 0.2441754937171936\n",
      "Epoch 7217/10000: L(Train): 0.26771003007888794; L(Test): 0.2443283349275589\n",
      "Epoch 7218/10000: L(Train): 0.2548620104789734; L(Test): 0.24387657642364502\n",
      "Epoch 7219/10000: L(Train): 0.2686634063720703; L(Test): 0.2443961799144745\n",
      "Epoch 7220/10000: L(Train): 0.27109605073928833; L(Test): 0.24271143972873688\n",
      "Epoch 7221/10000: L(Train): 0.26758816838264465; L(Test): 0.24247145652770996\n",
      "Epoch 7222/10000: L(Train): 0.2578328847885132; L(Test): 0.24262221157550812\n",
      "Epoch 7223/10000: L(Train): 0.252581924200058; L(Test): 0.24393953382968903\n",
      "Epoch 7224/10000: L(Train): 0.24981188774108887; L(Test): 0.24271823465824127\n",
      "Epoch 7225/10000: L(Train): 0.26844462752342224; L(Test): 0.24275973439216614\n",
      "Epoch 7226/10000: L(Train): 0.25311279296875; L(Test): 0.24399301409721375\n",
      "Epoch 7227/10000: L(Train): 0.2645535171031952; L(Test): 0.24119707942008972\n",
      "Epoch 7228/10000: L(Train): 0.24792149662971497; L(Test): 0.24191567301750183\n",
      "Epoch 7229/10000: L(Train): 0.2565616965293884; L(Test): 0.2450200319290161\n",
      "Epoch 7230/10000: L(Train): 0.25698480010032654; L(Test): 0.2410183548927307\n",
      "Epoch 7231/10000: L(Train): 0.26075151562690735; L(Test): 0.23997434973716736\n",
      "Epoch 7232/10000: L(Train): 0.2631247639656067; L(Test): 0.24122920632362366\n",
      "Epoch 7233/10000: L(Train): 0.26613372564315796; L(Test): 0.23973391950130463\n",
      "Epoch 7234/10000: L(Train): 0.26899853348731995; L(Test): 0.24008607864379883\n",
      "Epoch 7235/10000: L(Train): 0.2604723870754242; L(Test): 0.24172383546829224\n",
      "Epoch 7236/10000: L(Train): 0.256436824798584; L(Test): 0.2410738468170166\n",
      "Epoch 7237/10000: L(Train): 0.2649243175983429; L(Test): 0.24059130251407623\n",
      "Epoch 7238/10000: L(Train): 0.24885854125022888; L(Test): 0.2424626499414444\n",
      "Epoch 7239/10000: L(Train): 0.2619868218898773; L(Test): 0.23982614278793335\n",
      "Epoch 7240/10000: L(Train): 0.2792215645313263; L(Test): 0.2409326732158661\n",
      "Epoch 7241/10000: L(Train): 0.2630871832370758; L(Test): 0.2436704784631729\n",
      "Epoch 7242/10000: L(Train): 0.26373860239982605; L(Test): 0.24229441583156586\n",
      "Epoch 7243/10000: L(Train): 0.27265608310699463; L(Test): 0.24143698811531067\n",
      "Epoch 7244/10000: L(Train): 0.25614356994628906; L(Test): 0.24446585774421692\n",
      "Epoch 7245/10000: L(Train): 0.26247796416282654; L(Test): 0.24180440604686737\n",
      "Epoch 7246/10000: L(Train): 0.25974345207214355; L(Test): 0.2427348494529724\n",
      "Epoch 7247/10000: L(Train): 0.2643326222896576; L(Test): 0.24480122327804565\n",
      "Epoch 7248/10000: L(Train): 0.26053786277770996; L(Test): 0.24264931678771973\n",
      "Epoch 7249/10000: L(Train): 0.27740681171417236; L(Test): 0.24087044596672058\n",
      "Epoch 7250/10000: L(Train): 0.26048728823661804; L(Test): 0.2411929965019226\n",
      "Epoch 7251/10000: L(Train): 0.27021002769470215; L(Test): 0.24106644093990326\n",
      "Epoch 7252/10000: L(Train): 0.27436235547065735; L(Test): 0.2436090111732483\n",
      "Epoch 7253/10000: L(Train): 0.26391977071762085; L(Test): 0.24312223494052887\n",
      "Epoch 7254/10000: L(Train): 0.26942360401153564; L(Test): 0.24106523394584656\n",
      "Epoch 7255/10000: L(Train): 0.27339795231819153; L(Test): 0.24336127936840057\n",
      "Epoch 7256/10000: L(Train): 0.26642003655433655; L(Test): 0.24007782340049744\n",
      "Epoch 7257/10000: L(Train): 0.25491857528686523; L(Test): 0.24434804916381836\n",
      "Epoch 7258/10000: L(Train): 0.2690688371658325; L(Test): 0.24230290949344635\n",
      "Epoch 7259/10000: L(Train): 0.258308470249176; L(Test): 0.2406953126192093\n",
      "Epoch 7260/10000: L(Train): 0.267648309469223; L(Test): 0.24283252656459808\n",
      "Epoch 7261/10000: L(Train): 0.26911017298698425; L(Test): 0.24042892456054688\n",
      "Epoch 7262/10000: L(Train): 0.267184317111969; L(Test): 0.24548521637916565\n",
      "Epoch 7263/10000: L(Train): 0.2735530734062195; L(Test): 0.24227599799633026\n",
      "Epoch 7264/10000: L(Train): 0.2423306405544281; L(Test): 0.24142122268676758\n",
      "Epoch 7265/10000: L(Train): 0.2477729320526123; L(Test): 0.24119049310684204\n",
      "Epoch 7266/10000: L(Train): 0.26238593459129333; L(Test): 0.2422972023487091\n",
      "Epoch 7267/10000: L(Train): 0.2636522054672241; L(Test): 0.241998091340065\n",
      "Epoch 7268/10000: L(Train): 0.2702435255050659; L(Test): 0.23947949707508087\n",
      "Epoch 7269/10000: L(Train): 0.2569342851638794; L(Test): 0.24115782976150513\n",
      "Epoch 7270/10000: L(Train): 0.26555830240249634; L(Test): 0.239449605345726\n",
      "Epoch 7271/10000: L(Train): 0.2647894322872162; L(Test): 0.24088317155838013\n",
      "Epoch 7272/10000: L(Train): 0.26195791363716125; L(Test): 0.24213767051696777\n",
      "Epoch 7273/10000: L(Train): 0.2669742703437805; L(Test): 0.23995277285575867\n",
      "Epoch 7274/10000: L(Train): 0.2580224573612213; L(Test): 0.2404148429632187\n",
      "Epoch 7275/10000: L(Train): 0.271494597196579; L(Test): 0.2382287234067917\n",
      "Epoch 7276/10000: L(Train): 0.2769394516944885; L(Test): 0.23991137742996216\n",
      "Epoch 7277/10000: L(Train): 0.25563234090805054; L(Test): 0.2406979650259018\n",
      "Epoch 7278/10000: L(Train): 0.25233736634254456; L(Test): 0.23779822885990143\n",
      "Epoch 7279/10000: L(Train): 0.25990957021713257; L(Test): 0.23798640072345734\n",
      "Epoch 7280/10000: L(Train): 0.24107113480567932; L(Test): 0.23845328390598297\n",
      "Epoch 7281/10000: L(Train): 0.2557307481765747; L(Test): 0.23774659633636475\n",
      "Epoch 7282/10000: L(Train): 0.25813400745391846; L(Test): 0.23943130671977997\n",
      "Epoch 7283/10000: L(Train): 0.24646736681461334; L(Test): 0.23953703045845032\n",
      "Epoch 7284/10000: L(Train): 0.268524169921875; L(Test): 0.2388308048248291\n",
      "Epoch 7285/10000: L(Train): 0.2612423598766327; L(Test): 0.23984260857105255\n",
      "Epoch 7286/10000: L(Train): 0.26406505703926086; L(Test): 0.2383006066083908\n",
      "Epoch 7287/10000: L(Train): 0.24955978989601135; L(Test): 0.2420678436756134\n",
      "Epoch 7288/10000: L(Train): 0.25713661313056946; L(Test): 0.2399989813566208\n",
      "Epoch 7289/10000: L(Train): 0.24574634432792664; L(Test): 0.2385711669921875\n",
      "Epoch 7290/10000: L(Train): 0.26992523670196533; L(Test): 0.2400071620941162\n",
      "Epoch 7291/10000: L(Train): 0.27097252011299133; L(Test): 0.2379683256149292\n",
      "Epoch 7292/10000: L(Train): 0.25895455479621887; L(Test): 0.24163924157619476\n",
      "Epoch 7293/10000: L(Train): 0.2673172056674957; L(Test): 0.23890362679958344\n",
      "Epoch 7294/10000: L(Train): 0.2670022249221802; L(Test): 0.23743820190429688\n",
      "Epoch 7295/10000: L(Train): 0.2453637421131134; L(Test): 0.23824463784694672\n",
      "Epoch 7296/10000: L(Train): 0.26718541979789734; L(Test): 0.23741266131401062\n",
      "Epoch 7297/10000: L(Train): 0.26998406648635864; L(Test): 0.2393186241388321\n",
      "Epoch 7298/10000: L(Train): 0.2659945785999298; L(Test): 0.23734477162361145\n",
      "Epoch 7299/10000: L(Train): 0.26486343145370483; L(Test): 0.23688748478889465\n",
      "Epoch 7300/10000: L(Train): 0.2563599646091461; L(Test): 0.2373838871717453\n",
      "Epoch 7301/10000: L(Train): 0.25507456064224243; L(Test): 0.23672513663768768\n",
      "Epoch 7302/10000: L(Train): 0.2614772915840149; L(Test): 0.23783080279827118\n",
      "Epoch 7303/10000: L(Train): 0.24289202690124512; L(Test): 0.23820428550243378\n",
      "Epoch 7304/10000: L(Train): 0.2601991891860962; L(Test): 0.23747579753398895\n",
      "Epoch 7305/10000: L(Train): 0.26165464520454407; L(Test): 0.2374764084815979\n",
      "Epoch 7306/10000: L(Train): 0.25419384241104126; L(Test): 0.23675034940242767\n",
      "Epoch 7307/10000: L(Train): 0.25953084230422974; L(Test): 0.23709477484226227\n",
      "Epoch 7308/10000: L(Train): 0.25627878308296204; L(Test): 0.237453430891037\n",
      "Epoch 7309/10000: L(Train): 0.26831942796707153; L(Test): 0.23600192368030548\n",
      "Epoch 7310/10000: L(Train): 0.2560190260410309; L(Test): 0.23741388320922852\n",
      "Epoch 7311/10000: L(Train): 0.253827840089798; L(Test): 0.2374478578567505\n",
      "Epoch 7312/10000: L(Train): 0.25175103545188904; L(Test): 0.23875218629837036\n",
      "Epoch 7313/10000: L(Train): 0.27487239241600037; L(Test): 0.23968949913978577\n",
      "Epoch 7314/10000: L(Train): 0.26250872015953064; L(Test): 0.23671114444732666\n",
      "Epoch 7315/10000: L(Train): 0.26887989044189453; L(Test): 0.236905038356781\n",
      "Epoch 7316/10000: L(Train): 0.2514239549636841; L(Test): 0.23650197684764862\n",
      "Epoch 7317/10000: L(Train): 0.26564282178878784; L(Test): 0.2374897450208664\n",
      "Epoch 7318/10000: L(Train): 0.2506880760192871; L(Test): 0.23714031279087067\n",
      "Epoch 7319/10000: L(Train): 0.26068371534347534; L(Test): 0.23643076419830322\n",
      "Epoch 7320/10000: L(Train): 0.2444775104522705; L(Test): 0.2364833801984787\n",
      "Epoch 7321/10000: L(Train): 0.2500482201576233; L(Test): 0.236700177192688\n",
      "Epoch 7322/10000: L(Train): 0.25024306774139404; L(Test): 0.23692865669727325\n",
      "Epoch 7323/10000: L(Train): 0.250826358795166; L(Test): 0.23638048768043518\n",
      "Epoch 7324/10000: L(Train): 0.25486794114112854; L(Test): 0.2367965579032898\n",
      "Epoch 7325/10000: L(Train): 0.26123037934303284; L(Test): 0.23667919635772705\n",
      "Epoch 7326/10000: L(Train): 0.2789538502693176; L(Test): 0.2363819181919098\n",
      "Epoch 7327/10000: L(Train): 0.24719782173633575; L(Test): 0.23777471482753754\n",
      "Epoch 7328/10000: L(Train): 0.25936201214790344; L(Test): 0.23592713475227356\n",
      "Epoch 7329/10000: L(Train): 0.26437869668006897; L(Test): 0.2369547188282013\n",
      "Epoch 7330/10000: L(Train): 0.27197033166885376; L(Test): 0.23584717512130737\n",
      "Epoch 7331/10000: L(Train): 0.2521320879459381; L(Test): 0.2375578135251999\n",
      "Epoch 7332/10000: L(Train): 0.2678552269935608; L(Test): 0.23580661416053772\n",
      "Epoch 7333/10000: L(Train): 0.27076372504234314; L(Test): 0.23652389645576477\n",
      "Epoch 7334/10000: L(Train): 0.2573244273662567; L(Test): 0.23719458281993866\n",
      "Epoch 7335/10000: L(Train): 0.2675909996032715; L(Test): 0.24382320046424866\n",
      "Epoch 7336/10000: L(Train): 0.2558848261833191; L(Test): 0.2397172451019287\n",
      "Epoch 7337/10000: L(Train): 0.25304126739501953; L(Test): 0.23862554132938385\n",
      "Epoch 7338/10000: L(Train): 0.2542273998260498; L(Test): 0.24142570793628693\n",
      "Epoch 7339/10000: L(Train): 0.27186518907546997; L(Test): 0.23826594650745392\n",
      "Epoch 7340/10000: L(Train): 0.25403785705566406; L(Test): 0.24024149775505066\n",
      "Epoch 7341/10000: L(Train): 0.25406137108802795; L(Test): 0.24172869324684143\n",
      "Epoch 7342/10000: L(Train): 0.2615920603275299; L(Test): 0.23883670568466187\n",
      "Epoch 7343/10000: L(Train): 0.269821435213089; L(Test): 0.23876875638961792\n",
      "Epoch 7344/10000: L(Train): 0.26815712451934814; L(Test): 0.2396285980939865\n",
      "Epoch 7345/10000: L(Train): 0.2667654752731323; L(Test): 0.23940019309520721\n",
      "Epoch 7346/10000: L(Train): 0.2653277814388275; L(Test): 0.23843121528625488\n",
      "Epoch 7347/10000: L(Train): 0.26190778613090515; L(Test): 0.23792149126529694\n",
      "Epoch 7348/10000: L(Train): 0.24976378679275513; L(Test): 0.2382999211549759\n",
      "Epoch 7349/10000: L(Train): 0.259620726108551; L(Test): 0.23717162013053894\n",
      "Epoch 7350/10000: L(Train): 0.27127185463905334; L(Test): 0.23699826002120972\n",
      "Epoch 7351/10000: L(Train): 0.26521530747413635; L(Test): 0.23760806024074554\n",
      "Epoch 7352/10000: L(Train): 0.26843076944351196; L(Test): 0.2375655472278595\n",
      "Epoch 7353/10000: L(Train): 0.2614156901836395; L(Test): 0.23837126791477203\n",
      "Epoch 7354/10000: L(Train): 0.27376627922058105; L(Test): 0.23667314648628235\n",
      "Epoch 7355/10000: L(Train): 0.2582435607910156; L(Test): 0.23959758877754211\n",
      "Epoch 7356/10000: L(Train): 0.2582649290561676; L(Test): 0.24017050862312317\n",
      "Epoch 7357/10000: L(Train): 0.26028677821159363; L(Test): 0.23666134476661682\n",
      "Epoch 7358/10000: L(Train): 0.25773483514785767; L(Test): 0.23934514820575714\n",
      "Epoch 7359/10000: L(Train): 0.26109597086906433; L(Test): 0.23862217366695404\n",
      "Epoch 7360/10000: L(Train): 0.25458672642707825; L(Test): 0.23954200744628906\n",
      "Epoch 7361/10000: L(Train): 0.24904891848564148; L(Test): 0.23912329971790314\n",
      "Epoch 7362/10000: L(Train): 0.2814890742301941; L(Test): 0.2389087826013565\n",
      "Epoch 7363/10000: L(Train): 0.27028027176856995; L(Test): 0.23855945467948914\n",
      "Epoch 7364/10000: L(Train): 0.25615230202674866; L(Test): 0.23975558578968048\n",
      "Epoch 7365/10000: L(Train): 0.25085046887397766; L(Test): 0.2391858547925949\n",
      "Epoch 7366/10000: L(Train): 0.25888070464134216; L(Test): 0.23710177838802338\n",
      "Epoch 7367/10000: L(Train): 0.26435601711273193; L(Test): 0.23681487143039703\n",
      "Epoch 7368/10000: L(Train): 0.2656136155128479; L(Test): 0.2377556562423706\n",
      "Epoch 7369/10000: L(Train): 0.27816423773765564; L(Test): 0.23763158917427063\n",
      "Epoch 7370/10000: L(Train): 0.26177388429641724; L(Test): 0.23758170008659363\n",
      "Epoch 7371/10000: L(Train): 0.2643432021141052; L(Test): 0.23699690401554108\n",
      "Epoch 7372/10000: L(Train): 0.2740953266620636; L(Test): 0.23666732013225555\n",
      "Epoch 7373/10000: L(Train): 0.2625106871128082; L(Test): 0.2366901934146881\n",
      "Epoch 7374/10000: L(Train): 0.2751292288303375; L(Test): 0.23672911524772644\n",
      "Epoch 7375/10000: L(Train): 0.25598955154418945; L(Test): 0.2364501953125\n",
      "Epoch 7376/10000: L(Train): 0.26325052976608276; L(Test): 0.23630398511886597\n",
      "Epoch 7377/10000: L(Train): 0.25471678376197815; L(Test): 0.2363586574792862\n",
      "Epoch 7378/10000: L(Train): 0.2637365460395813; L(Test): 0.2369898408651352\n",
      "Epoch 7379/10000: L(Train): 0.2682589292526245; L(Test): 0.2374437004327774\n",
      "Epoch 7380/10000: L(Train): 0.2544286847114563; L(Test): 0.23644015192985535\n",
      "Epoch 7381/10000: L(Train): 0.25719714164733887; L(Test): 0.23625370860099792\n",
      "Epoch 7382/10000: L(Train): 0.25579383969306946; L(Test): 0.2364926040172577\n",
      "Epoch 7383/10000: L(Train): 0.2624140679836273; L(Test): 0.23593772947788239\n",
      "Epoch 7384/10000: L(Train): 0.2544277012348175; L(Test): 0.23591302335262299\n",
      "Epoch 7385/10000: L(Train): 0.2494805008172989; L(Test): 0.23786433041095734\n",
      "Epoch 7386/10000: L(Train): 0.25674986839294434; L(Test): 0.23671363294124603\n",
      "Epoch 7387/10000: L(Train): 0.25487080216407776; L(Test): 0.23499926924705505\n",
      "Epoch 7388/10000: L(Train): 0.26697131991386414; L(Test): 0.23684145510196686\n",
      "Epoch 7389/10000: L(Train): 0.2535802125930786; L(Test): 0.23611436784267426\n",
      "Epoch 7390/10000: L(Train): 0.25231367349624634; L(Test): 0.23588143289089203\n",
      "Epoch 7391/10000: L(Train): 0.26371315121650696; L(Test): 0.23800630867481232\n",
      "Epoch 7392/10000: L(Train): 0.2607566714286804; L(Test): 0.23659521341323853\n",
      "Epoch 7393/10000: L(Train): 0.26120755076408386; L(Test): 0.23576727509498596\n",
      "Epoch 7394/10000: L(Train): 0.25710535049438477; L(Test): 0.23737238347530365\n",
      "Epoch 7395/10000: L(Train): 0.2567295730113983; L(Test): 0.23863744735717773\n",
      "Epoch 7396/10000: L(Train): 0.25046396255493164; L(Test): 0.23788072168827057\n",
      "Epoch 7397/10000: L(Train): 0.26237496733665466; L(Test): 0.23769521713256836\n",
      "Epoch 7398/10000: L(Train): 0.27360910177230835; L(Test): 0.23829160630702972\n",
      "Epoch 7399/10000: L(Train): 0.2521325945854187; L(Test): 0.2379380464553833\n",
      "Epoch 7400/10000: L(Train): 0.24919980764389038; L(Test): 0.23885586857795715\n",
      "Epoch 7401/10000: L(Train): 0.2565724849700928; L(Test): 0.2389705777168274\n",
      "Epoch 7402/10000: L(Train): 0.26599475741386414; L(Test): 0.23760908842086792\n",
      "Epoch 7403/10000: L(Train): 0.25231432914733887; L(Test): 0.23691295087337494\n",
      "Epoch 7404/10000: L(Train): 0.2676379680633545; L(Test): 0.23768533766269684\n",
      "Epoch 7405/10000: L(Train): 0.27073338627815247; L(Test): 0.2381875365972519\n",
      "Epoch 7406/10000: L(Train): 0.2622993290424347; L(Test): 0.23855994641780853\n",
      "Epoch 7407/10000: L(Train): 0.2485027015209198; L(Test): 0.23877671360969543\n",
      "Epoch 7408/10000: L(Train): 0.250576913356781; L(Test): 0.238303542137146\n",
      "Epoch 7409/10000: L(Train): 0.25128859281539917; L(Test): 0.23841190338134766\n",
      "Epoch 7410/10000: L(Train): 0.2369702011346817; L(Test): 0.23955076932907104\n",
      "Epoch 7411/10000: L(Train): 0.2747637629508972; L(Test): 0.24005264043807983\n",
      "Epoch 7412/10000: L(Train): 0.26180168986320496; L(Test): 0.23963981866836548\n",
      "Epoch 7413/10000: L(Train): 0.25626683235168457; L(Test): 0.23774942755699158\n",
      "Epoch 7414/10000: L(Train): 0.2642253041267395; L(Test): 0.23754137754440308\n",
      "Epoch 7415/10000: L(Train): 0.25447848439216614; L(Test): 0.23929999768733978\n",
      "Epoch 7416/10000: L(Train): 0.26582393050193787; L(Test): 0.23837773501873016\n",
      "Epoch 7417/10000: L(Train): 0.25650230050086975; L(Test): 0.23785340785980225\n",
      "Epoch 7418/10000: L(Train): 0.25647515058517456; L(Test): 0.23890985548496246\n",
      "Epoch 7419/10000: L(Train): 0.26768699288368225; L(Test): 0.23883473873138428\n",
      "Epoch 7420/10000: L(Train): 0.2567179799079895; L(Test): 0.23714657127857208\n",
      "Epoch 7421/10000: L(Train): 0.2441960573196411; L(Test): 0.23711296916007996\n",
      "Epoch 7422/10000: L(Train): 0.28197240829467773; L(Test): 0.23727324604988098\n",
      "Epoch 7423/10000: L(Train): 0.2583274841308594; L(Test): 0.23753193020820618\n",
      "Epoch 7424/10000: L(Train): 0.25307467579841614; L(Test): 0.24186892807483673\n",
      "Epoch 7425/10000: L(Train): 0.2671971917152405; L(Test): 0.23876863718032837\n",
      "Epoch 7426/10000: L(Train): 0.2635253965854645; L(Test): 0.23947980999946594\n",
      "Epoch 7427/10000: L(Train): 0.2451983392238617; L(Test): 0.24081040918827057\n",
      "Epoch 7428/10000: L(Train): 0.26908937096595764; L(Test): 0.24202045798301697\n",
      "Epoch 7429/10000: L(Train): 0.2571108937263489; L(Test): 0.24223265051841736\n",
      "Epoch 7430/10000: L(Train): 0.26941853761672974; L(Test): 0.23933982849121094\n",
      "Epoch 7431/10000: L(Train): 0.25272423028945923; L(Test): 0.24195043742656708\n",
      "Epoch 7432/10000: L(Train): 0.2682143449783325; L(Test): 0.23934508860111237\n",
      "Epoch 7433/10000: L(Train): 0.2686275541782379; L(Test): 0.24114342033863068\n",
      "Epoch 7434/10000: L(Train): 0.2584850490093231; L(Test): 0.24123482406139374\n",
      "Epoch 7435/10000: L(Train): 0.26899129152297974; L(Test): 0.23989781737327576\n",
      "Epoch 7436/10000: L(Train): 0.26658323407173157; L(Test): 0.2391013652086258\n",
      "Epoch 7437/10000: L(Train): 0.26491034030914307; L(Test): 0.23870792984962463\n",
      "Epoch 7438/10000: L(Train): 0.25487273931503296; L(Test): 0.2401878535747528\n",
      "Epoch 7439/10000: L(Train): 0.257122665643692; L(Test): 0.23961086571216583\n",
      "Epoch 7440/10000: L(Train): 0.24496860802173615; L(Test): 0.23779353499412537\n",
      "Epoch 7441/10000: L(Train): 0.2507854700088501; L(Test): 0.23803085088729858\n",
      "Epoch 7442/10000: L(Train): 0.2692899703979492; L(Test): 0.24065907299518585\n",
      "Epoch 7443/10000: L(Train): 0.2640322744846344; L(Test): 0.240385964512825\n",
      "Epoch 7444/10000: L(Train): 0.26529383659362793; L(Test): 0.23888081312179565\n",
      "Epoch 7445/10000: L(Train): 0.25535571575164795; L(Test): 0.23980233073234558\n",
      "Epoch 7446/10000: L(Train): 0.25357043743133545; L(Test): 0.23975425958633423\n",
      "Epoch 7447/10000: L(Train): 0.2615456283092499; L(Test): 0.24045757949352264\n",
      "Epoch 7448/10000: L(Train): 0.2807122766971588; L(Test): 0.24068990349769592\n",
      "Epoch 7449/10000: L(Train): 0.2628640830516815; L(Test): 0.23931685090065002\n",
      "Epoch 7450/10000: L(Train): 0.2655905783176422; L(Test): 0.23869270086288452\n",
      "Epoch 7451/10000: L(Train): 0.24346080422401428; L(Test): 0.23865652084350586\n",
      "Epoch 7452/10000: L(Train): 0.2511168122291565; L(Test): 0.23903989791870117\n",
      "Epoch 7453/10000: L(Train): 0.2685752809047699; L(Test): 0.23798814415931702\n",
      "Epoch 7454/10000: L(Train): 0.26068562269210815; L(Test): 0.2375166267156601\n",
      "Epoch 7455/10000: L(Train): 0.2567061185836792; L(Test): 0.23695875704288483\n",
      "Epoch 7456/10000: L(Train): 0.2581096589565277; L(Test): 0.2376743108034134\n",
      "Epoch 7457/10000: L(Train): 0.25888118147850037; L(Test): 0.2392328381538391\n",
      "Epoch 7458/10000: L(Train): 0.2609832286834717; L(Test): 0.23896493017673492\n",
      "Epoch 7459/10000: L(Train): 0.2570973336696625; L(Test): 0.23788191378116608\n",
      "Epoch 7460/10000: L(Train): 0.2618797719478607; L(Test): 0.23734766244888306\n",
      "Epoch 7461/10000: L(Train): 0.25595974922180176; L(Test): 0.23862095177173615\n",
      "Epoch 7462/10000: L(Train): 0.26509684324264526; L(Test): 0.2369459867477417\n",
      "Epoch 7463/10000: L(Train): 0.24924439191818237; L(Test): 0.2372894585132599\n",
      "Epoch 7464/10000: L(Train): 0.2590336203575134; L(Test): 0.23697078227996826\n",
      "Epoch 7465/10000: L(Train): 0.2602410316467285; L(Test): 0.23629426956176758\n",
      "Epoch 7466/10000: L(Train): 0.2615197002887726; L(Test): 0.23674790561199188\n",
      "Epoch 7467/10000: L(Train): 0.2560140788555145; L(Test): 0.23652946949005127\n",
      "Epoch 7468/10000: L(Train): 0.2608954906463623; L(Test): 0.23710229992866516\n",
      "Epoch 7469/10000: L(Train): 0.25469180941581726; L(Test): 0.2375473827123642\n",
      "Epoch 7470/10000: L(Train): 0.24867354333400726; L(Test): 0.23736515641212463\n",
      "Epoch 7471/10000: L(Train): 0.2614794373512268; L(Test): 0.2364603579044342\n",
      "Epoch 7472/10000: L(Train): 0.2567247152328491; L(Test): 0.23599278926849365\n",
      "Epoch 7473/10000: L(Train): 0.2599051296710968; L(Test): 0.23647606372833252\n",
      "Epoch 7474/10000: L(Train): 0.2454875111579895; L(Test): 0.23820458352565765\n",
      "Epoch 7475/10000: L(Train): 0.2681221663951874; L(Test): 0.23768743872642517\n",
      "Epoch 7476/10000: L(Train): 0.2686654329299927; L(Test): 0.236729234457016\n",
      "Epoch 7477/10000: L(Train): 0.2562759220600128; L(Test): 0.23659390211105347\n",
      "Epoch 7478/10000: L(Train): 0.2641097605228424; L(Test): 0.23665298521518707\n",
      "Epoch 7479/10000: L(Train): 0.2457733303308487; L(Test): 0.23726792633533478\n",
      "Epoch 7480/10000: L(Train): 0.2632414400577545; L(Test): 0.2376086711883545\n",
      "Epoch 7481/10000: L(Train): 0.26666125655174255; L(Test): 0.2372768223285675\n",
      "Epoch 7482/10000: L(Train): 0.25354066491127014; L(Test): 0.23688432574272156\n",
      "Epoch 7483/10000: L(Train): 0.24606618285179138; L(Test): 0.23691906034946442\n",
      "Epoch 7484/10000: L(Train): 0.2486160546541214; L(Test): 0.23846708238124847\n",
      "Epoch 7485/10000: L(Train): 0.24017661809921265; L(Test): 0.23739564418792725\n",
      "Epoch 7486/10000: L(Train): 0.2640206813812256; L(Test): 0.23678813874721527\n",
      "Epoch 7487/10000: L(Train): 0.2584986388683319; L(Test): 0.23674899339675903\n",
      "Epoch 7488/10000: L(Train): 0.25409644842147827; L(Test): 0.23774924874305725\n",
      "Epoch 7489/10000: L(Train): 0.27037686109542847; L(Test): 0.23720912635326385\n",
      "Epoch 7490/10000: L(Train): 0.2546093761920929; L(Test): 0.23661887645721436\n",
      "Epoch 7491/10000: L(Train): 0.25844892859458923; L(Test): 0.23594613373279572\n",
      "Epoch 7492/10000: L(Train): 0.2549063265323639; L(Test): 0.23657849431037903\n",
      "Epoch 7493/10000: L(Train): 0.2500245273113251; L(Test): 0.23680317401885986\n",
      "Epoch 7494/10000: L(Train): 0.260016530752182; L(Test): 0.23620200157165527\n",
      "Epoch 7495/10000: L(Train): 0.2591104209423065; L(Test): 0.2358468472957611\n",
      "Epoch 7496/10000: L(Train): 0.25006675720214844; L(Test): 0.23542366921901703\n",
      "Epoch 7497/10000: L(Train): 0.2681385278701782; L(Test): 0.2361396998167038\n",
      "Epoch 7498/10000: L(Train): 0.26200002431869507; L(Test): 0.23599503934383392\n",
      "Epoch 7499/10000: L(Train): 0.2642841935157776; L(Test): 0.2357592135667801\n",
      "Epoch 7500/10000: L(Train): 0.2673223912715912; L(Test): 0.23582936823368073\n",
      "Epoch 7501/10000: L(Train): 0.2604440748691559; L(Test): 0.23688358068466187\n",
      "Epoch 7502/10000: L(Train): 0.26006853580474854; L(Test): 0.23632262647151947\n",
      "Epoch 7503/10000: L(Train): 0.2588993310928345; L(Test): 0.23539187014102936\n",
      "Epoch 7504/10000: L(Train): 0.24526715278625488; L(Test): 0.23592402040958405\n",
      "Epoch 7505/10000: L(Train): 0.2534583806991577; L(Test): 0.2363450527191162\n",
      "Epoch 7506/10000: L(Train): 0.26784414052963257; L(Test): 0.23632845282554626\n",
      "Epoch 7507/10000: L(Train): 0.26652029156684875; L(Test): 0.2365097999572754\n",
      "Epoch 7508/10000: L(Train): 0.258666068315506; L(Test): 0.23676779866218567\n",
      "Epoch 7509/10000: L(Train): 0.2548154592514038; L(Test): 0.2363852560520172\n",
      "Epoch 7510/10000: L(Train): 0.2554817199707031; L(Test): 0.2368750423192978\n",
      "Epoch 7511/10000: L(Train): 0.2666071355342865; L(Test): 0.23577524721622467\n",
      "Epoch 7512/10000: L(Train): 0.25895261764526367; L(Test): 0.23694443702697754\n",
      "Epoch 7513/10000: L(Train): 0.2576838731765747; L(Test): 0.2371223419904709\n",
      "Epoch 7514/10000: L(Train): 0.2563837170600891; L(Test): 0.2357640564441681\n",
      "Epoch 7515/10000: L(Train): 0.24697178602218628; L(Test): 0.23701535165309906\n",
      "Epoch 7516/10000: L(Train): 0.26485174894332886; L(Test): 0.23662959039211273\n",
      "Epoch 7517/10000: L(Train): 0.24676838517189026; L(Test): 0.23516052961349487\n",
      "Epoch 7518/10000: L(Train): 0.26777198910713196; L(Test): 0.2353561520576477\n",
      "Epoch 7519/10000: L(Train): 0.253400981426239; L(Test): 0.23560863733291626\n",
      "Epoch 7520/10000: L(Train): 0.25774848461151123; L(Test): 0.23559780418872833\n",
      "Epoch 7521/10000: L(Train): 0.2484017312526703; L(Test): 0.23555254936218262\n",
      "Epoch 7522/10000: L(Train): 0.2564674913883209; L(Test): 0.2355804741382599\n",
      "Epoch 7523/10000: L(Train): 0.2581486403942108; L(Test): 0.23483651876449585\n",
      "Epoch 7524/10000: L(Train): 0.25366735458374023; L(Test): 0.2350153774023056\n",
      "Epoch 7525/10000: L(Train): 0.2544535994529724; L(Test): 0.23576772212982178\n",
      "Epoch 7526/10000: L(Train): 0.24752981960773468; L(Test): 0.2358042150735855\n",
      "Epoch 7527/10000: L(Train): 0.27075281739234924; L(Test): 0.23546123504638672\n",
      "Epoch 7528/10000: L(Train): 0.2721478343009949; L(Test): 0.2347259223461151\n",
      "Epoch 7529/10000: L(Train): 0.2699306607246399; L(Test): 0.23441262543201447\n",
      "Epoch 7530/10000: L(Train): 0.2584606409072876; L(Test): 0.23505766689777374\n",
      "Epoch 7531/10000: L(Train): 0.2611027657985687; L(Test): 0.23477338254451752\n",
      "Epoch 7532/10000: L(Train): 0.2533230483531952; L(Test): 0.23462852835655212\n",
      "Epoch 7533/10000: L(Train): 0.25260329246520996; L(Test): 0.23487530648708344\n",
      "Epoch 7534/10000: L(Train): 0.2549583315849304; L(Test): 0.23565077781677246\n",
      "Epoch 7535/10000: L(Train): 0.2607291638851166; L(Test): 0.23487690091133118\n",
      "Epoch 7536/10000: L(Train): 0.26069676876068115; L(Test): 0.23422224819660187\n",
      "Epoch 7537/10000: L(Train): 0.2755725383758545; L(Test): 0.23426739871501923\n",
      "Epoch 7538/10000: L(Train): 0.23677222430706024; L(Test): 0.23416978120803833\n",
      "Epoch 7539/10000: L(Train): 0.2645357847213745; L(Test): 0.23508794605731964\n",
      "Epoch 7540/10000: L(Train): 0.2653708755970001; L(Test): 0.23640474677085876\n",
      "Epoch 7541/10000: L(Train): 0.2647533118724823; L(Test): 0.23444677889347076\n",
      "Epoch 7542/10000: L(Train): 0.24888111650943756; L(Test): 0.23525629937648773\n",
      "Epoch 7543/10000: L(Train): 0.2623252868652344; L(Test): 0.2354581207036972\n",
      "Epoch 7544/10000: L(Train): 0.2740793228149414; L(Test): 0.23613213002681732\n",
      "Epoch 7545/10000: L(Train): 0.25087541341781616; L(Test): 0.23705504834651947\n",
      "Epoch 7546/10000: L(Train): 0.25383350253105164; L(Test): 0.23581457138061523\n",
      "Epoch 7547/10000: L(Train): 0.25372394919395447; L(Test): 0.2349616438150406\n",
      "Epoch 7548/10000: L(Train): 0.24683363735675812; L(Test): 0.23573869466781616\n",
      "Epoch 7549/10000: L(Train): 0.2629016041755676; L(Test): 0.2374299168586731\n",
      "Epoch 7550/10000: L(Train): 0.2676360607147217; L(Test): 0.23594702780246735\n",
      "Epoch 7551/10000: L(Train): 0.260386198759079; L(Test): 0.23574720323085785\n",
      "Epoch 7552/10000: L(Train): 0.27201345562934875; L(Test): 0.23756396770477295\n",
      "Epoch 7553/10000: L(Train): 0.2621200382709503; L(Test): 0.23729635775089264\n",
      "Epoch 7554/10000: L(Train): 0.2620386481285095; L(Test): 0.23681989312171936\n",
      "Epoch 7555/10000: L(Train): 0.24003981053829193; L(Test): 0.2374887466430664\n",
      "Epoch 7556/10000: L(Train): 0.2659609019756317; L(Test): 0.2371167242527008\n",
      "Epoch 7557/10000: L(Train): 0.26765450835227966; L(Test): 0.2363358587026596\n",
      "Epoch 7558/10000: L(Train): 0.255998820066452; L(Test): 0.2366679310798645\n",
      "Epoch 7559/10000: L(Train): 0.2549915909767151; L(Test): 0.23644611239433289\n",
      "Epoch 7560/10000: L(Train): 0.25736892223358154; L(Test): 0.23574213683605194\n",
      "Epoch 7561/10000: L(Train): 0.27483516931533813; L(Test): 0.23722708225250244\n",
      "Epoch 7562/10000: L(Train): 0.2634039521217346; L(Test): 0.2368512749671936\n",
      "Epoch 7563/10000: L(Train): 0.2268914133310318; L(Test): 0.23625457286834717\n",
      "Epoch 7564/10000: L(Train): 0.2502678632736206; L(Test): 0.23611287772655487\n",
      "Epoch 7565/10000: L(Train): 0.2520909011363983; L(Test): 0.23568926751613617\n",
      "Epoch 7566/10000: L(Train): 0.26978182792663574; L(Test): 0.23715750873088837\n",
      "Epoch 7567/10000: L(Train): 0.26069679856300354; L(Test): 0.23648905754089355\n",
      "Epoch 7568/10000: L(Train): 0.24316748976707458; L(Test): 0.23554009199142456\n",
      "Epoch 7569/10000: L(Train): 0.24761846661567688; L(Test): 0.23590165376663208\n",
      "Epoch 7570/10000: L(Train): 0.2568219006061554; L(Test): 0.23630978167057037\n",
      "Epoch 7571/10000: L(Train): 0.24666950106620789; L(Test): 0.236661896109581\n",
      "Epoch 7572/10000: L(Train): 0.26012367010116577; L(Test): 0.2382780760526657\n",
      "Epoch 7573/10000: L(Train): 0.26905012130737305; L(Test): 0.2362109273672104\n",
      "Epoch 7574/10000: L(Train): 0.26318949460983276; L(Test): 0.23559676110744476\n",
      "Epoch 7575/10000: L(Train): 0.2710146903991699; L(Test): 0.2359997034072876\n",
      "Epoch 7576/10000: L(Train): 0.26703888177871704; L(Test): 0.2357250601053238\n",
      "Epoch 7577/10000: L(Train): 0.26918160915374756; L(Test): 0.23650355637073517\n",
      "Epoch 7578/10000: L(Train): 0.264886736869812; L(Test): 0.23663592338562012\n",
      "Epoch 7579/10000: L(Train): 0.2682814598083496; L(Test): 0.2368890792131424\n",
      "Epoch 7580/10000: L(Train): 0.2625141739845276; L(Test): 0.23622699081897736\n",
      "Epoch 7581/10000: L(Train): 0.26096174120903015; L(Test): 0.23591949045658112\n",
      "Epoch 7582/10000: L(Train): 0.25733682513237; L(Test): 0.23584109544754028\n",
      "Epoch 7583/10000: L(Train): 0.2365475445985794; L(Test): 0.23668332397937775\n",
      "Epoch 7584/10000: L(Train): 0.2619141638278961; L(Test): 0.2366139143705368\n",
      "Epoch 7585/10000: L(Train): 0.2627248167991638; L(Test): 0.23711998760700226\n",
      "Epoch 7586/10000: L(Train): 0.2585821747779846; L(Test): 0.23741284012794495\n",
      "Epoch 7587/10000: L(Train): 0.2560276389122009; L(Test): 0.23730909824371338\n",
      "Epoch 7588/10000: L(Train): 0.2507596015930176; L(Test): 0.238899827003479\n",
      "Epoch 7589/10000: L(Train): 0.26455700397491455; L(Test): 0.2386903166770935\n",
      "Epoch 7590/10000: L(Train): 0.26057082414627075; L(Test): 0.23729391396045685\n",
      "Epoch 7591/10000: L(Train): 0.2555861175060272; L(Test): 0.23823505640029907\n",
      "Epoch 7592/10000: L(Train): 0.24629420042037964; L(Test): 0.23834869265556335\n",
      "Epoch 7593/10000: L(Train): 0.2572229206562042; L(Test): 0.23631878197193146\n",
      "Epoch 7594/10000: L(Train): 0.2454555779695511; L(Test): 0.23650889098644257\n",
      "Epoch 7595/10000: L(Train): 0.2722935676574707; L(Test): 0.23731249570846558\n",
      "Epoch 7596/10000: L(Train): 0.2728261649608612; L(Test): 0.2362132966518402\n",
      "Epoch 7597/10000: L(Train): 0.27168405055999756; L(Test): 0.2364160120487213\n",
      "Epoch 7598/10000: L(Train): 0.26453834772109985; L(Test): 0.23650161921977997\n",
      "Epoch 7599/10000: L(Train): 0.24376638233661652; L(Test): 0.2383045107126236\n",
      "Epoch 7600/10000: L(Train): 0.27525776624679565; L(Test): 0.2379397451877594\n",
      "Epoch 7601/10000: L(Train): 0.25617411732673645; L(Test): 0.23691099882125854\n",
      "Epoch 7602/10000: L(Train): 0.25138428807258606; L(Test): 0.23685987293720245\n",
      "Epoch 7603/10000: L(Train): 0.2663637399673462; L(Test): 0.23717230558395386\n",
      "Epoch 7604/10000: L(Train): 0.24866411089897156; L(Test): 0.23716194927692413\n",
      "Epoch 7605/10000: L(Train): 0.2585572302341461; L(Test): 0.23567251861095428\n",
      "Epoch 7606/10000: L(Train): 0.25408339500427246; L(Test): 0.2374432235956192\n",
      "Epoch 7607/10000: L(Train): 0.2661772668361664; L(Test): 0.2356073558330536\n",
      "Epoch 7608/10000: L(Train): 0.2687341272830963; L(Test): 0.23793068528175354\n",
      "Epoch 7609/10000: L(Train): 0.26352691650390625; L(Test): 0.23669229447841644\n",
      "Epoch 7610/10000: L(Train): 0.27398616075515747; L(Test): 0.2363700270652771\n",
      "Epoch 7611/10000: L(Train): 0.25952646136283875; L(Test): 0.23811191320419312\n",
      "Epoch 7612/10000: L(Train): 0.2619993984699249; L(Test): 0.2376217395067215\n",
      "Epoch 7613/10000: L(Train): 0.26969224214553833; L(Test): 0.23894289135932922\n",
      "Epoch 7614/10000: L(Train): 0.26995572447776794; L(Test): 0.2377517819404602\n",
      "Epoch 7615/10000: L(Train): 0.26149508357048035; L(Test): 0.23707084357738495\n",
      "Epoch 7616/10000: L(Train): 0.27012231945991516; L(Test): 0.23828819394111633\n",
      "Epoch 7617/10000: L(Train): 0.25324705243110657; L(Test): 0.23690661787986755\n",
      "Epoch 7618/10000: L(Train): 0.2711862623691559; L(Test): 0.23753681778907776\n",
      "Epoch 7619/10000: L(Train): 0.26320087909698486; L(Test): 0.23726427555084229\n",
      "Epoch 7620/10000: L(Train): 0.26291725039482117; L(Test): 0.23646126687526703\n",
      "Epoch 7621/10000: L(Train): 0.2698916494846344; L(Test): 0.23618409037590027\n",
      "Epoch 7622/10000: L(Train): 0.26300814747810364; L(Test): 0.23742951452732086\n",
      "Epoch 7623/10000: L(Train): 0.25713396072387695; L(Test): 0.2378213107585907\n",
      "Epoch 7624/10000: L(Train): 0.26040565967559814; L(Test): 0.23711958527565002\n",
      "Epoch 7625/10000: L(Train): 0.26317375898361206; L(Test): 0.23746539652347565\n",
      "Epoch 7626/10000: L(Train): 0.25625863671302795; L(Test): 0.2372799813747406\n",
      "Epoch 7627/10000: L(Train): 0.26524436473846436; L(Test): 0.2375534325838089\n",
      "Epoch 7628/10000: L(Train): 0.26244881749153137; L(Test): 0.23605386912822723\n",
      "Epoch 7629/10000: L(Train): 0.2601875960826874; L(Test): 0.23630033433437347\n",
      "Epoch 7630/10000: L(Train): 0.2669764459133148; L(Test): 0.23717494308948517\n",
      "Epoch 7631/10000: L(Train): 0.25178587436676025; L(Test): 0.23724707961082458\n",
      "Epoch 7632/10000: L(Train): 0.2582615911960602; L(Test): 0.23747020959854126\n",
      "Epoch 7633/10000: L(Train): 0.2551117241382599; L(Test): 0.23729433119297028\n",
      "Epoch 7634/10000: L(Train): 0.26388266682624817; L(Test): 0.23724158108234406\n",
      "Epoch 7635/10000: L(Train): 0.2689381241798401; L(Test): 0.23790442943572998\n",
      "Epoch 7636/10000: L(Train): 0.2803126275539398; L(Test): 0.23828400671482086\n",
      "Epoch 7637/10000: L(Train): 0.26745328307151794; L(Test): 0.23813050985336304\n",
      "Epoch 7638/10000: L(Train): 0.2664332389831543; L(Test): 0.2371806502342224\n",
      "Epoch 7639/10000: L(Train): 0.2528707981109619; L(Test): 0.2374563217163086\n",
      "Epoch 7640/10000: L(Train): 0.25341489911079407; L(Test): 0.23845365643501282\n",
      "Epoch 7641/10000: L(Train): 0.2687491178512573; L(Test): 0.23800921440124512\n",
      "Epoch 7642/10000: L(Train): 0.26322701573371887; L(Test): 0.23709625005722046\n",
      "Epoch 7643/10000: L(Train): 0.2669745981693268; L(Test): 0.2376997023820877\n",
      "Epoch 7644/10000: L(Train): 0.2663268446922302; L(Test): 0.23640458285808563\n",
      "Epoch 7645/10000: L(Train): 0.25783470273017883; L(Test): 0.23775134980678558\n",
      "Epoch 7646/10000: L(Train): 0.2456999123096466; L(Test): 0.2399250715970993\n",
      "Epoch 7647/10000: L(Train): 0.25914883613586426; L(Test): 0.2363732010126114\n",
      "Epoch 7648/10000: L(Train): 0.25172603130340576; L(Test): 0.23645900189876556\n",
      "Epoch 7649/10000: L(Train): 0.2694315016269684; L(Test): 0.23690810799598694\n",
      "Epoch 7650/10000: L(Train): 0.25949758291244507; L(Test): 0.23732128739356995\n",
      "Epoch 7651/10000: L(Train): 0.2631802558898926; L(Test): 0.23728814721107483\n",
      "Epoch 7652/10000: L(Train): 0.254648357629776; L(Test): 0.23598282039165497\n",
      "Epoch 7653/10000: L(Train): 0.2484501600265503; L(Test): 0.23660197854042053\n",
      "Epoch 7654/10000: L(Train): 0.2673337459564209; L(Test): 0.2367652952671051\n",
      "Epoch 7655/10000: L(Train): 0.264045387506485; L(Test): 0.23695439100265503\n",
      "Epoch 7656/10000: L(Train): 0.24704280495643616; L(Test): 0.23589617013931274\n",
      "Epoch 7657/10000: L(Train): 0.26574304699897766; L(Test): 0.23550431430339813\n",
      "Epoch 7658/10000: L(Train): 0.27296993136405945; L(Test): 0.23558269441127777\n",
      "Epoch 7659/10000: L(Train): 0.26151642203330994; L(Test): 0.23580288887023926\n",
      "Epoch 7660/10000: L(Train): 0.24301907420158386; L(Test): 0.2359175831079483\n",
      "Epoch 7661/10000: L(Train): 0.25451138615608215; L(Test): 0.23519301414489746\n",
      "Epoch 7662/10000: L(Train): 0.27609315514564514; L(Test): 0.2354588806629181\n",
      "Epoch 7663/10000: L(Train): 0.2562867999076843; L(Test): 0.2356257140636444\n",
      "Epoch 7664/10000: L(Train): 0.24640719592571259; L(Test): 0.23506489396095276\n",
      "Epoch 7665/10000: L(Train): 0.2657192349433899; L(Test): 0.23510517179965973\n",
      "Epoch 7666/10000: L(Train): 0.26055628061294556; L(Test): 0.23431739211082458\n",
      "Epoch 7667/10000: L(Train): 0.2498619258403778; L(Test): 0.23471462726593018\n",
      "Epoch 7668/10000: L(Train): 0.257938414812088; L(Test): 0.235090434551239\n",
      "Epoch 7669/10000: L(Train): 0.26960289478302; L(Test): 0.23546969890594482\n",
      "Epoch 7670/10000: L(Train): 0.2533729076385498; L(Test): 0.2348659485578537\n",
      "Epoch 7671/10000: L(Train): 0.2536868751049042; L(Test): 0.23426714539527893\n",
      "Epoch 7672/10000: L(Train): 0.2607797384262085; L(Test): 0.23444728553295135\n",
      "Epoch 7673/10000: L(Train): 0.2636435329914093; L(Test): 0.23604877293109894\n",
      "Epoch 7674/10000: L(Train): 0.24956557154655457; L(Test): 0.23624233901500702\n",
      "Epoch 7675/10000: L(Train): 0.2604278326034546; L(Test): 0.23447684943675995\n",
      "Epoch 7676/10000: L(Train): 0.2457236796617508; L(Test): 0.23433078825473785\n",
      "Epoch 7677/10000: L(Train): 0.26574286818504333; L(Test): 0.23449921607971191\n",
      "Epoch 7678/10000: L(Train): 0.25885236263275146; L(Test): 0.24016031622886658\n",
      "Epoch 7679/10000: L(Train): 0.2658770978450775; L(Test): 0.2350272387266159\n",
      "Epoch 7680/10000: L(Train): 0.26678940653800964; L(Test): 0.23925726115703583\n",
      "Epoch 7681/10000: L(Train): 0.2748109996318817; L(Test): 0.23865532875061035\n",
      "Epoch 7682/10000: L(Train): 0.2724703252315521; L(Test): 0.23754380643367767\n",
      "Epoch 7683/10000: L(Train): 0.27421316504478455; L(Test): 0.23663873970508575\n",
      "Epoch 7684/10000: L(Train): 0.25400641560554504; L(Test): 0.23655451834201813\n",
      "Epoch 7685/10000: L(Train): 0.25374674797058105; L(Test): 0.2354622334241867\n",
      "Epoch 7686/10000: L(Train): 0.2533056437969208; L(Test): 0.2396833449602127\n",
      "Epoch 7687/10000: L(Train): 0.26190727949142456; L(Test): 0.2373858392238617\n",
      "Epoch 7688/10000: L(Train): 0.2500514090061188; L(Test): 0.2363007664680481\n",
      "Epoch 7689/10000: L(Train): 0.2584492266178131; L(Test): 0.23728525638580322\n",
      "Epoch 7690/10000: L(Train): 0.25413617491722107; L(Test): 0.23729366064071655\n",
      "Epoch 7691/10000: L(Train): 0.2532126307487488; L(Test): 0.23715850710868835\n",
      "Epoch 7692/10000: L(Train): 0.2724655568599701; L(Test): 0.23800453543663025\n",
      "Epoch 7693/10000: L(Train): 0.26151731610298157; L(Test): 0.23801401257514954\n",
      "Epoch 7694/10000: L(Train): 0.2687717080116272; L(Test): 0.23722513020038605\n",
      "Epoch 7695/10000: L(Train): 0.25910502672195435; L(Test): 0.23802103102207184\n",
      "Epoch 7696/10000: L(Train): 0.24637801945209503; L(Test): 0.23875826597213745\n",
      "Epoch 7697/10000: L(Train): 0.25797492265701294; L(Test): 0.23781003057956696\n",
      "Epoch 7698/10000: L(Train): 0.2522885501384735; L(Test): 0.23717331886291504\n",
      "Epoch 7699/10000: L(Train): 0.2643086016178131; L(Test): 0.2387130707502365\n",
      "Epoch 7700/10000: L(Train): 0.2572188973426819; L(Test): 0.2380393147468567\n",
      "Epoch 7701/10000: L(Train): 0.24898916482925415; L(Test): 0.2363199144601822\n",
      "Epoch 7702/10000: L(Train): 0.2563032805919647; L(Test): 0.24465523660182953\n",
      "Epoch 7703/10000: L(Train): 0.26629188656806946; L(Test): 0.24727195501327515\n",
      "Epoch 7704/10000: L(Train): 0.26580941677093506; L(Test): 0.2532596290111542\n",
      "Epoch 7705/10000: L(Train): 0.2906145453453064; L(Test): 0.2508045434951782\n",
      "Epoch 7706/10000: L(Train): 0.2642558813095093; L(Test): 0.24971763789653778\n",
      "Epoch 7707/10000: L(Train): 0.2813994288444519; L(Test): 0.24666433036327362\n",
      "Epoch 7708/10000: L(Train): 0.2769603133201599; L(Test): 0.2503891587257385\n",
      "Epoch 7709/10000: L(Train): 0.27432313561439514; L(Test): 0.24719040095806122\n",
      "Epoch 7710/10000: L(Train): 0.2624783515930176; L(Test): 0.24746397137641907\n",
      "Epoch 7711/10000: L(Train): 0.2728746831417084; L(Test): 0.24822184443473816\n",
      "Epoch 7712/10000: L(Train): 0.26288944482803345; L(Test): 0.2513037919998169\n",
      "Epoch 7713/10000: L(Train): 0.2561890482902527; L(Test): 0.2519741952419281\n",
      "Epoch 7714/10000: L(Train): 0.26748567819595337; L(Test): 0.24827925860881805\n",
      "Epoch 7715/10000: L(Train): 0.27554839849472046; L(Test): 0.2498888522386551\n",
      "Epoch 7716/10000: L(Train): 0.2646694779396057; L(Test): 0.24831697344779968\n",
      "Epoch 7717/10000: L(Train): 0.2741216719150543; L(Test): 0.2485465705394745\n",
      "Epoch 7718/10000: L(Train): 0.2830184996128082; L(Test): 0.24794520437717438\n",
      "Epoch 7719/10000: L(Train): 0.2749251425266266; L(Test): 0.24654445052146912\n",
      "Epoch 7720/10000: L(Train): 0.2650843858718872; L(Test): 0.24839656054973602\n",
      "Epoch 7721/10000: L(Train): 0.2628171145915985; L(Test): 0.24602442979812622\n",
      "Epoch 7722/10000: L(Train): 0.2595158815383911; L(Test): 0.24892795085906982\n",
      "Epoch 7723/10000: L(Train): 0.274881511926651; L(Test): 0.2543250024318695\n",
      "Epoch 7724/10000: L(Train): 0.27297332882881165; L(Test): 0.2494514137506485\n",
      "Epoch 7725/10000: L(Train): 0.2647971510887146; L(Test): 0.24719585478305817\n",
      "Epoch 7726/10000: L(Train): 0.2714909613132477; L(Test): 0.24694466590881348\n",
      "Epoch 7727/10000: L(Train): 0.2651500105857849; L(Test): 0.24368397891521454\n",
      "Epoch 7728/10000: L(Train): 0.26164403557777405; L(Test): 0.245210200548172\n",
      "Epoch 7729/10000: L(Train): 0.25810980796813965; L(Test): 0.24587059020996094\n",
      "Epoch 7730/10000: L(Train): 0.266748309135437; L(Test): 0.24196700751781464\n",
      "Epoch 7731/10000: L(Train): 0.26540714502334595; L(Test): 0.243831068277359\n",
      "Epoch 7732/10000: L(Train): 0.28361523151397705; L(Test): 0.24155603349208832\n",
      "Epoch 7733/10000: L(Train): 0.2586667239665985; L(Test): 0.2431686669588089\n",
      "Epoch 7734/10000: L(Train): 0.2596527934074402; L(Test): 0.24453872442245483\n",
      "Epoch 7735/10000: L(Train): 0.2675003111362457; L(Test): 0.24275170266628265\n",
      "Epoch 7736/10000: L(Train): 0.26854440569877625; L(Test): 0.24136470258235931\n",
      "Epoch 7737/10000: L(Train): 0.26738622784614563; L(Test): 0.24014826118946075\n",
      "Epoch 7738/10000: L(Train): 0.24756960570812225; L(Test): 0.23991648852825165\n",
      "Epoch 7739/10000: L(Train): 0.25902897119522095; L(Test): 0.24040237069129944\n",
      "Epoch 7740/10000: L(Train): 0.261868953704834; L(Test): 0.23894177377223969\n",
      "Epoch 7741/10000: L(Train): 0.2615748941898346; L(Test): 0.2377350628376007\n",
      "Epoch 7742/10000: L(Train): 0.25321584939956665; L(Test): 0.23837824165821075\n",
      "Epoch 7743/10000: L(Train): 0.26768824458122253; L(Test): 0.23877473175525665\n",
      "Epoch 7744/10000: L(Train): 0.26612627506256104; L(Test): 0.23819752037525177\n",
      "Epoch 7745/10000: L(Train): 0.257363885641098; L(Test): 0.2381601482629776\n",
      "Epoch 7746/10000: L(Train): 0.25695520639419556; L(Test): 0.2378179132938385\n",
      "Epoch 7747/10000: L(Train): 0.26103830337524414; L(Test): 0.2378213107585907\n",
      "Epoch 7748/10000: L(Train): 0.2571367025375366; L(Test): 0.23752228915691376\n",
      "Epoch 7749/10000: L(Train): 0.2562696039676666; L(Test): 0.23750589787960052\n",
      "Epoch 7750/10000: L(Train): 0.27706220746040344; L(Test): 0.23796036839485168\n",
      "Epoch 7751/10000: L(Train): 0.2493230551481247; L(Test): 0.23859244585037231\n",
      "Epoch 7752/10000: L(Train): 0.26151609420776367; L(Test): 0.2377254068851471\n",
      "Epoch 7753/10000: L(Train): 0.2506560981273651; L(Test): 0.23679789900779724\n",
      "Epoch 7754/10000: L(Train): 0.260886013507843; L(Test): 0.23726221919059753\n",
      "Epoch 7755/10000: L(Train): 0.2569103538990021; L(Test): 0.23718702793121338\n",
      "Epoch 7756/10000: L(Train): 0.2604151666164398; L(Test): 0.23766422271728516\n",
      "Epoch 7757/10000: L(Train): 0.25253352522850037; L(Test): 0.23722627758979797\n",
      "Epoch 7758/10000: L(Train): 0.2595900893211365; L(Test): 0.23656460642814636\n",
      "Epoch 7759/10000: L(Train): 0.2637302577495575; L(Test): 0.23691385984420776\n",
      "Epoch 7760/10000: L(Train): 0.2470265030860901; L(Test): 0.23784922063350677\n",
      "Epoch 7761/10000: L(Train): 0.26362529397010803; L(Test): 0.23701165616512299\n",
      "Epoch 7762/10000: L(Train): 0.2598167657852173; L(Test): 0.23757438361644745\n",
      "Epoch 7763/10000: L(Train): 0.2558424770832062; L(Test): 0.23790058493614197\n",
      "Epoch 7764/10000: L(Train): 0.2521599233150482; L(Test): 0.23627696931362152\n",
      "Epoch 7765/10000: L(Train): 0.2569246292114258; L(Test): 0.2371874898672104\n",
      "Epoch 7766/10000: L(Train): 0.26139289140701294; L(Test): 0.23680777847766876\n",
      "Epoch 7767/10000: L(Train): 0.25413045287132263; L(Test): 0.23760972917079926\n",
      "Epoch 7768/10000: L(Train): 0.26659807562828064; L(Test): 0.23845472931861877\n",
      "Epoch 7769/10000: L(Train): 0.2543424665927887; L(Test): 0.23826268315315247\n",
      "Epoch 7770/10000: L(Train): 0.2635701298713684; L(Test): 0.23774844408035278\n",
      "Epoch 7771/10000: L(Train): 0.2608898878097534; L(Test): 0.23759329319000244\n",
      "Epoch 7772/10000: L(Train): 0.25788256525993347; L(Test): 0.23781177401542664\n",
      "Epoch 7773/10000: L(Train): 0.2787702977657318; L(Test): 0.2375716269016266\n",
      "Epoch 7774/10000: L(Train): 0.26119670271873474; L(Test): 0.23852984607219696\n",
      "Epoch 7775/10000: L(Train): 0.2605575621128082; L(Test): 0.23754960298538208\n",
      "Epoch 7776/10000: L(Train): 0.2583450376987457; L(Test): 0.23667387664318085\n",
      "Epoch 7777/10000: L(Train): 0.2632935643196106; L(Test): 0.2370898723602295\n",
      "Epoch 7778/10000: L(Train): 0.26719632744789124; L(Test): 0.23789186775684357\n",
      "Epoch 7779/10000: L(Train): 0.26333317160606384; L(Test): 0.23694512248039246\n",
      "Epoch 7780/10000: L(Train): 0.2465600073337555; L(Test): 0.23755966126918793\n",
      "Epoch 7781/10000: L(Train): 0.26004016399383545; L(Test): 0.23937676846981049\n",
      "Epoch 7782/10000: L(Train): 0.26555922627449036; L(Test): 0.2361983060836792\n",
      "Epoch 7783/10000: L(Train): 0.25601550936698914; L(Test): 0.2363235205411911\n",
      "Epoch 7784/10000: L(Train): 0.27610138058662415; L(Test): 0.23727498948574066\n",
      "Epoch 7785/10000: L(Train): 0.2479073852300644; L(Test): 0.23722046613693237\n",
      "Epoch 7786/10000: L(Train): 0.2677113711833954; L(Test): 0.23775459825992584\n",
      "Epoch 7787/10000: L(Train): 0.2629561424255371; L(Test): 0.23725201189517975\n",
      "Epoch 7788/10000: L(Train): 0.25582507252693176; L(Test): 0.23811249434947968\n",
      "Epoch 7789/10000: L(Train): 0.24902459979057312; L(Test): 0.23868438601493835\n",
      "Epoch 7790/10000: L(Train): 0.26216524839401245; L(Test): 0.23889075219631195\n",
      "Epoch 7791/10000: L(Train): 0.2582111060619354; L(Test): 0.2375245988368988\n",
      "Epoch 7792/10000: L(Train): 0.26112768054008484; L(Test): 0.23694702982902527\n",
      "Epoch 7793/10000: L(Train): 0.2490822821855545; L(Test): 0.24044382572174072\n",
      "Epoch 7794/10000: L(Train): 0.26015520095825195; L(Test): 0.23742492496967316\n",
      "Epoch 7795/10000: L(Train): 0.2624821066856384; L(Test): 0.2385353147983551\n",
      "Epoch 7796/10000: L(Train): 0.25319698452949524; L(Test): 0.23983754217624664\n",
      "Epoch 7797/10000: L(Train): 0.25315243005752563; L(Test): 0.23803329467773438\n",
      "Epoch 7798/10000: L(Train): 0.2431679666042328; L(Test): 0.24053336679935455\n",
      "Epoch 7799/10000: L(Train): 0.2692630887031555; L(Test): 0.24053405225276947\n",
      "Epoch 7800/10000: L(Train): 0.27245602011680603; L(Test): 0.23995038866996765\n",
      "Epoch 7801/10000: L(Train): 0.27479487657546997; L(Test): 0.23902733623981476\n",
      "Epoch 7802/10000: L(Train): 0.25936394929885864; L(Test): 0.24274374544620514\n",
      "Epoch 7803/10000: L(Train): 0.27123335003852844; L(Test): 0.24091722071170807\n",
      "Epoch 7804/10000: L(Train): 0.2504000961780548; L(Test): 0.23805193603038788\n",
      "Epoch 7805/10000: L(Train): 0.2733011841773987; L(Test): 0.24054144322872162\n",
      "Epoch 7806/10000: L(Train): 0.2758501172065735; L(Test): 0.241866797208786\n",
      "Epoch 7807/10000: L(Train): 0.2735231816768646; L(Test): 0.2391955852508545\n",
      "Epoch 7808/10000: L(Train): 0.26487377285957336; L(Test): 0.23782040178775787\n",
      "Epoch 7809/10000: L(Train): 0.2613043487071991; L(Test): 0.2388678938150406\n",
      "Epoch 7810/10000: L(Train): 0.2649141550064087; L(Test): 0.23844240605831146\n",
      "Epoch 7811/10000: L(Train): 0.2669943869113922; L(Test): 0.23735594749450684\n",
      "Epoch 7812/10000: L(Train): 0.25181034207344055; L(Test): 0.23790112137794495\n",
      "Epoch 7813/10000: L(Train): 0.2603408694267273; L(Test): 0.24022434651851654\n",
      "Epoch 7814/10000: L(Train): 0.24963046610355377; L(Test): 0.23963655531406403\n",
      "Epoch 7815/10000: L(Train): 0.2679598331451416; L(Test): 0.2383280247449875\n",
      "Epoch 7816/10000: L(Train): 0.2708178758621216; L(Test): 0.23852521181106567\n",
      "Epoch 7817/10000: L(Train): 0.2512984275817871; L(Test): 0.23725728690624237\n",
      "Epoch 7818/10000: L(Train): 0.2550419569015503; L(Test): 0.2366073727607727\n",
      "Epoch 7819/10000: L(Train): 0.24988479912281036; L(Test): 0.23678146302700043\n",
      "Epoch 7820/10000: L(Train): 0.2470921277999878; L(Test): 0.23645740747451782\n",
      "Epoch 7821/10000: L(Train): 0.24878618121147156; L(Test): 0.23705022037029266\n",
      "Epoch 7822/10000: L(Train): 0.24762152135372162; L(Test): 0.23786328732967377\n",
      "Epoch 7823/10000: L(Train): 0.2536514401435852; L(Test): 0.23810328543186188\n",
      "Epoch 7824/10000: L(Train): 0.25575169920921326; L(Test): 0.2369529753923416\n",
      "Epoch 7825/10000: L(Train): 0.2622532844543457; L(Test): 0.23622757196426392\n",
      "Epoch 7826/10000: L(Train): 0.25386112928390503; L(Test): 0.23785822093486786\n",
      "Epoch 7827/10000: L(Train): 0.26513415575027466; L(Test): 0.23635374009609222\n",
      "Epoch 7828/10000: L(Train): 0.27127423882484436; L(Test): 0.23562422394752502\n",
      "Epoch 7829/10000: L(Train): 0.26999378204345703; L(Test): 0.23643340170383453\n",
      "Epoch 7830/10000: L(Train): 0.2636010944843292; L(Test): 0.23703326284885406\n",
      "Epoch 7831/10000: L(Train): 0.2662101984024048; L(Test): 0.23700782656669617\n",
      "Epoch 7832/10000: L(Train): 0.2588275074958801; L(Test): 0.23756946623325348\n",
      "Epoch 7833/10000: L(Train): 0.24620430171489716; L(Test): 0.23727650940418243\n",
      "Epoch 7834/10000: L(Train): 0.25477951765060425; L(Test): 0.23737329244613647\n",
      "Epoch 7835/10000: L(Train): 0.2537655234336853; L(Test): 0.23696520924568176\n",
      "Epoch 7836/10000: L(Train): 0.265572726726532; L(Test): 0.2371664047241211\n",
      "Epoch 7837/10000: L(Train): 0.26877328753471375; L(Test): 0.23734742403030396\n",
      "Epoch 7838/10000: L(Train): 0.26638659834861755; L(Test): 0.23683661222457886\n",
      "Epoch 7839/10000: L(Train): 0.26037439703941345; L(Test): 0.2364673763513565\n",
      "Epoch 7840/10000: L(Train): 0.2540624439716339; L(Test): 0.2372390180826187\n",
      "Epoch 7841/10000: L(Train): 0.2646615207195282; L(Test): 0.23726119101047516\n",
      "Epoch 7842/10000: L(Train): 0.26639002561569214; L(Test): 0.23705358803272247\n",
      "Epoch 7843/10000: L(Train): 0.2586376667022705; L(Test): 0.23728540539741516\n",
      "Epoch 7844/10000: L(Train): 0.25024938583374023; L(Test): 0.23754730820655823\n",
      "Epoch 7845/10000: L(Train): 0.2607787847518921; L(Test): 0.23722566664218903\n",
      "Epoch 7846/10000: L(Train): 0.26685619354248047; L(Test): 0.23649759590625763\n",
      "Epoch 7847/10000: L(Train): 0.25339531898498535; L(Test): 0.2375292330980301\n",
      "Epoch 7848/10000: L(Train): 0.25362107157707214; L(Test): 0.23743095993995667\n",
      "Epoch 7849/10000: L(Train): 0.2672693431377411; L(Test): 0.23641809821128845\n",
      "Epoch 7850/10000: L(Train): 0.26350897550582886; L(Test): 0.2364974468946457\n",
      "Epoch 7851/10000: L(Train): 0.2774590253829956; L(Test): 0.2362663596868515\n",
      "Epoch 7852/10000: L(Train): 0.264313668012619; L(Test): 0.23650236427783966\n",
      "Epoch 7853/10000: L(Train): 0.27740710973739624; L(Test): 0.23595957458019257\n",
      "Epoch 7854/10000: L(Train): 0.25439125299453735; L(Test): 0.23606820404529572\n",
      "Epoch 7855/10000: L(Train): 0.2552868723869324; L(Test): 0.23641084134578705\n",
      "Epoch 7856/10000: L(Train): 0.2482949048280716; L(Test): 0.2362060844898224\n",
      "Epoch 7857/10000: L(Train): 0.27293235063552856; L(Test): 0.23791299760341644\n",
      "Epoch 7858/10000: L(Train): 0.2520032823085785; L(Test): 0.23713666200637817\n",
      "Epoch 7859/10000: L(Train): 0.26088449358940125; L(Test): 0.2363772690296173\n",
      "Epoch 7860/10000: L(Train): 0.25442540645599365; L(Test): 0.23688440024852753\n",
      "Epoch 7861/10000: L(Train): 0.26237815618515015; L(Test): 0.23780615627765656\n",
      "Epoch 7862/10000: L(Train): 0.2689703404903412; L(Test): 0.23670195043087006\n",
      "Epoch 7863/10000: L(Train): 0.2700183391571045; L(Test): 0.23628543317317963\n",
      "Epoch 7864/10000: L(Train): 0.27410632371902466; L(Test): 0.23729383945465088\n",
      "Epoch 7865/10000: L(Train): 0.26158565282821655; L(Test): 0.23538170754909515\n",
      "Epoch 7866/10000: L(Train): 0.2664753198623657; L(Test): 0.23883508145809174\n",
      "Epoch 7867/10000: L(Train): 0.2474263310432434; L(Test): 0.23885388672351837\n",
      "Epoch 7868/10000: L(Train): 0.2723444700241089; L(Test): 0.23704540729522705\n",
      "Epoch 7869/10000: L(Train): 0.262162446975708; L(Test): 0.2367950826883316\n",
      "Epoch 7870/10000: L(Train): 0.2452467679977417; L(Test): 0.2394188493490219\n",
      "Epoch 7871/10000: L(Train): 0.25440409779548645; L(Test): 0.2381076216697693\n",
      "Epoch 7872/10000: L(Train): 0.26752153038978577; L(Test): 0.23618748784065247\n",
      "Epoch 7873/10000: L(Train): 0.2672654390335083; L(Test): 0.23779627680778503\n",
      "Epoch 7874/10000: L(Train): 0.26576611399650574; L(Test): 0.23829878866672516\n",
      "Epoch 7875/10000: L(Train): 0.2637570798397064; L(Test): 0.23678892850875854\n",
      "Epoch 7876/10000: L(Train): 0.2567383646965027; L(Test): 0.23588404059410095\n",
      "Epoch 7877/10000: L(Train): 0.254299134016037; L(Test): 0.236424520611763\n",
      "Epoch 7878/10000: L(Train): 0.2545280456542969; L(Test): 0.23581984639167786\n",
      "Epoch 7879/10000: L(Train): 0.2552962899208069; L(Test): 0.23503407835960388\n",
      "Epoch 7880/10000: L(Train): 0.25700679421424866; L(Test): 0.2357627898454666\n",
      "Epoch 7881/10000: L(Train): 0.271681547164917; L(Test): 0.23601780831813812\n",
      "Epoch 7882/10000: L(Train): 0.2632980942726135; L(Test): 0.2359914928674698\n",
      "Epoch 7883/10000: L(Train): 0.2585493326187134; L(Test): 0.23757266998291016\n",
      "Epoch 7884/10000: L(Train): 0.24443016946315765; L(Test): 0.2371690422296524\n",
      "Epoch 7885/10000: L(Train): 0.2540428638458252; L(Test): 0.23545926809310913\n",
      "Epoch 7886/10000: L(Train): 0.2702192962169647; L(Test): 0.23515741527080536\n",
      "Epoch 7887/10000: L(Train): 0.27887678146362305; L(Test): 0.23528626561164856\n",
      "Epoch 7888/10000: L(Train): 0.2564765512943268; L(Test): 0.23587383329868317\n",
      "Epoch 7889/10000: L(Train): 0.2675786316394806; L(Test): 0.2347131073474884\n",
      "Epoch 7890/10000: L(Train): 0.26627373695373535; L(Test): 0.23497134447097778\n",
      "Epoch 7891/10000: L(Train): 0.255567729473114; L(Test): 0.23545435070991516\n",
      "Epoch 7892/10000: L(Train): 0.27418309450149536; L(Test): 0.23709410429000854\n",
      "Epoch 7893/10000: L(Train): 0.2649986445903778; L(Test): 0.2367340326309204\n",
      "Epoch 7894/10000: L(Train): 0.2769966423511505; L(Test): 0.2384219616651535\n",
      "Epoch 7895/10000: L(Train): 0.26763489842414856; L(Test): 0.23715409636497498\n",
      "Epoch 7896/10000: L(Train): 0.2706136405467987; L(Test): 0.2375015765428543\n",
      "Epoch 7897/10000: L(Train): 0.2676599323749542; L(Test): 0.23819470405578613\n",
      "Epoch 7898/10000: L(Train): 0.25833383202552795; L(Test): 0.23742195963859558\n",
      "Epoch 7899/10000: L(Train): 0.2658134400844574; L(Test): 0.23828822374343872\n",
      "Epoch 7900/10000: L(Train): 0.25621873140335083; L(Test): 0.23684410750865936\n",
      "Epoch 7901/10000: L(Train): 0.27093902230262756; L(Test): 0.23724666237831116\n",
      "Epoch 7902/10000: L(Train): 0.26771900057792664; L(Test): 0.23835228383541107\n",
      "Epoch 7903/10000: L(Train): 0.2558354437351227; L(Test): 0.23739705979824066\n",
      "Epoch 7904/10000: L(Train): 0.2763664126396179; L(Test): 0.23681078851222992\n",
      "Epoch 7905/10000: L(Train): 0.25522077083587646; L(Test): 0.23643732070922852\n",
      "Epoch 7906/10000: L(Train): 0.25272631645202637; L(Test): 0.23654043674468994\n",
      "Epoch 7907/10000: L(Train): 0.2521643340587616; L(Test): 0.2368650585412979\n",
      "Epoch 7908/10000: L(Train): 0.2600819766521454; L(Test): 0.2379433959722519\n",
      "Epoch 7909/10000: L(Train): 0.26222020387649536; L(Test): 0.24070802330970764\n",
      "Epoch 7910/10000: L(Train): 0.25166964530944824; L(Test): 0.24288484454154968\n",
      "Epoch 7911/10000: L(Train): 0.277057409286499; L(Test): 0.2512455880641937\n",
      "Epoch 7912/10000: L(Train): 0.27107957005500793; L(Test): 0.2534371018409729\n",
      "Epoch 7913/10000: L(Train): 0.2863427400588989; L(Test): 0.2507864832878113\n",
      "Epoch 7914/10000: L(Train): 0.26336470246315; L(Test): 0.2529771327972412\n",
      "Epoch 7915/10000: L(Train): 0.2785733640193939; L(Test): 0.2541545331478119\n",
      "Epoch 7916/10000: L(Train): 0.2773241400718689; L(Test): 0.25242406129837036\n",
      "Epoch 7917/10000: L(Train): 0.2596496045589447; L(Test): 0.25352713465690613\n",
      "Epoch 7918/10000: L(Train): 0.2781846523284912; L(Test): 0.25293388962745667\n",
      "Epoch 7919/10000: L(Train): 0.27653491497039795; L(Test): 0.251956582069397\n",
      "Epoch 7920/10000: L(Train): 0.28165411949157715; L(Test): 0.2503121793270111\n",
      "Epoch 7921/10000: L(Train): 0.266500324010849; L(Test): 0.2519555985927582\n",
      "Epoch 7922/10000: L(Train): 0.2646309733390808; L(Test): 0.2505607306957245\n",
      "Epoch 7923/10000: L(Train): 0.27322855591773987; L(Test): 0.24878843128681183\n",
      "Epoch 7924/10000: L(Train): 0.2742190659046173; L(Test): 0.2502272427082062\n",
      "Epoch 7925/10000: L(Train): 0.26159167289733887; L(Test): 0.24868318438529968\n",
      "Epoch 7926/10000: L(Train): 0.2771766483783722; L(Test): 0.24800588190555573\n",
      "Epoch 7927/10000: L(Train): 0.2698907256126404; L(Test): 0.24854114651679993\n",
      "Epoch 7928/10000: L(Train): 0.26451024413108826; L(Test): 0.248676136136055\n",
      "Epoch 7929/10000: L(Train): 0.25740846991539; L(Test): 0.2467212826013565\n",
      "Epoch 7930/10000: L(Train): 0.27278006076812744; L(Test): 0.24576020240783691\n",
      "Epoch 7931/10000: L(Train): 0.2665850520133972; L(Test): 0.24546220898628235\n",
      "Epoch 7932/10000: L(Train): 0.27024388313293457; L(Test): 0.2435910403728485\n",
      "Epoch 7933/10000: L(Train): 0.25773516297340393; L(Test): 0.24426230788230896\n",
      "Epoch 7934/10000: L(Train): 0.2727269232273102; L(Test): 0.24457834661006927\n",
      "Epoch 7935/10000: L(Train): 0.2672435939311981; L(Test): 0.2447938770055771\n",
      "Epoch 7936/10000: L(Train): 0.2670862674713135; L(Test): 0.2440294325351715\n",
      "Epoch 7937/10000: L(Train): 0.2672414779663086; L(Test): 0.24246789515018463\n",
      "Epoch 7938/10000: L(Train): 0.275558739900589; L(Test): 0.24217751622200012\n",
      "Epoch 7939/10000: L(Train): 0.2680445611476898; L(Test): 0.24146033823490143\n",
      "Epoch 7940/10000: L(Train): 0.2548409402370453; L(Test): 0.24220359325408936\n",
      "Epoch 7941/10000: L(Train): 0.24713772535324097; L(Test): 0.24171552062034607\n",
      "Epoch 7942/10000: L(Train): 0.2609022259712219; L(Test): 0.2406865954399109\n",
      "Epoch 7943/10000: L(Train): 0.26177433133125305; L(Test): 0.24097470939159393\n",
      "Epoch 7944/10000: L(Train): 0.26877936720848083; L(Test): 0.24065053462982178\n",
      "Epoch 7945/10000: L(Train): 0.2564195990562439; L(Test): 0.2434907704591751\n",
      "Epoch 7946/10000: L(Train): 0.28213754296302795; L(Test): 0.24100424349308014\n",
      "Epoch 7947/10000: L(Train): 0.2704818546772003; L(Test): 0.24061134457588196\n",
      "Epoch 7948/10000: L(Train): 0.2654600143432617; L(Test): 0.24029408395290375\n",
      "Epoch 7949/10000: L(Train): 0.2699352204799652; L(Test): 0.23994745314121246\n",
      "Epoch 7950/10000: L(Train): 0.25582635402679443; L(Test): 0.24061940610408783\n",
      "Epoch 7951/10000: L(Train): 0.25473225116729736; L(Test): 0.239839568734169\n",
      "Epoch 7952/10000: L(Train): 0.26679542660713196; L(Test): 0.2382422536611557\n",
      "Epoch 7953/10000: L(Train): 0.2566033899784088; L(Test): 0.238493412733078\n",
      "Epoch 7954/10000: L(Train): 0.25637269020080566; L(Test): 0.23982009291648865\n",
      "Epoch 7955/10000: L(Train): 0.27851709723472595; L(Test): 0.23874549567699432\n",
      "Epoch 7956/10000: L(Train): 0.2599565386772156; L(Test): 0.23841020464897156\n",
      "Epoch 7957/10000: L(Train): 0.27166813611984253; L(Test): 0.24022139608860016\n",
      "Epoch 7958/10000: L(Train): 0.2810710072517395; L(Test): 0.23820139467716217\n",
      "Epoch 7959/10000: L(Train): 0.26868972182273865; L(Test): 0.23939573764801025\n",
      "Epoch 7960/10000: L(Train): 0.2766582667827606; L(Test): 0.23955489695072174\n",
      "Epoch 7961/10000: L(Train): 0.2636358439922333; L(Test): 0.23935814201831818\n",
      "Epoch 7962/10000: L(Train): 0.26920291781425476; L(Test): 0.24060450494289398\n",
      "Epoch 7963/10000: L(Train): 0.2600697875022888; L(Test): 0.23975743353366852\n",
      "Epoch 7964/10000: L(Train): 0.2536379396915436; L(Test): 0.238205224275589\n",
      "Epoch 7965/10000: L(Train): 0.2618585526943207; L(Test): 0.23879244923591614\n",
      "Epoch 7966/10000: L(Train): 0.25092658400535583; L(Test): 0.23919716477394104\n",
      "Epoch 7967/10000: L(Train): 0.25684741139411926; L(Test): 0.2371939718723297\n",
      "Epoch 7968/10000: L(Train): 0.26394739747047424; L(Test): 0.23770087957382202\n",
      "Epoch 7969/10000: L(Train): 0.25113174319267273; L(Test): 0.2371564507484436\n",
      "Epoch 7970/10000: L(Train): 0.25492626428604126; L(Test): 0.23764540255069733\n",
      "Epoch 7971/10000: L(Train): 0.26016154885292053; L(Test): 0.24046079814434052\n",
      "Epoch 7972/10000: L(Train): 0.25826144218444824; L(Test): 0.23802635073661804\n",
      "Epoch 7973/10000: L(Train): 0.24651645123958588; L(Test): 0.2375802844762802\n",
      "Epoch 7974/10000: L(Train): 0.24425849318504333; L(Test): 0.23831214010715485\n",
      "Epoch 7975/10000: L(Train): 0.2682109773159027; L(Test): 0.23800534009933472\n",
      "Epoch 7976/10000: L(Train): 0.2596942186355591; L(Test): 0.23880615830421448\n",
      "Epoch 7977/10000: L(Train): 0.2516568899154663; L(Test): 0.23883764445781708\n",
      "Epoch 7978/10000: L(Train): 0.2641465663909912; L(Test): 0.23838403820991516\n",
      "Epoch 7979/10000: L(Train): 0.263349711894989; L(Test): 0.23909097909927368\n",
      "Epoch 7980/10000: L(Train): 0.27295106649398804; L(Test): 0.23890523612499237\n",
      "Epoch 7981/10000: L(Train): 0.2535751760005951; L(Test): 0.2369507998228073\n",
      "Epoch 7982/10000: L(Train): 0.25052154064178467; L(Test): 0.23891720175743103\n",
      "Epoch 7983/10000: L(Train): 0.2557216286659241; L(Test): 0.24005691707134247\n",
      "Epoch 7984/10000: L(Train): 0.2506852447986603; L(Test): 0.2373104691505432\n",
      "Epoch 7985/10000: L(Train): 0.2568678855895996; L(Test): 0.23643478751182556\n",
      "Epoch 7986/10000: L(Train): 0.2561994194984436; L(Test): 0.23774218559265137\n",
      "Epoch 7987/10000: L(Train): 0.2701720595359802; L(Test): 0.23743736743927002\n",
      "Epoch 7988/10000: L(Train): 0.2614762485027313; L(Test): 0.23731008172035217\n",
      "Epoch 7989/10000: L(Train): 0.2688654065132141; L(Test): 0.2377096265554428\n",
      "Epoch 7990/10000: L(Train): 0.2623523771762848; L(Test): 0.23671816289424896\n",
      "Epoch 7991/10000: L(Train): 0.2562134563922882; L(Test): 0.23592108488082886\n",
      "Epoch 7992/10000: L(Train): 0.27518582344055176; L(Test): 0.23609982430934906\n",
      "Epoch 7993/10000: L(Train): 0.24279755353927612; L(Test): 0.2360154092311859\n",
      "Epoch 7994/10000: L(Train): 0.24569487571716309; L(Test): 0.23666515946388245\n",
      "Epoch 7995/10000: L(Train): 0.26988980174064636; L(Test): 0.23647372424602509\n",
      "Epoch 7996/10000: L(Train): 0.25601863861083984; L(Test): 0.23891565203666687\n",
      "Epoch 7997/10000: L(Train): 0.2577058672904968; L(Test): 0.23839391767978668\n",
      "Epoch 7998/10000: L(Train): 0.2613656520843506; L(Test): 0.23733417689800262\n",
      "Epoch 7999/10000: L(Train): 0.27386701107025146; L(Test): 0.23668023943901062\n",
      "Epoch 8000/10000: L(Train): 0.26043352484703064; L(Test): 0.23631708323955536\n",
      "Epoch 8001/10000: L(Train): 0.2711751163005829; L(Test): 0.2366594672203064\n",
      "Epoch 8002/10000: L(Train): 0.25927019119262695; L(Test): 0.23621264100074768\n",
      "Epoch 8003/10000: L(Train): 0.2470858097076416; L(Test): 0.2360992431640625\n",
      "Epoch 8004/10000: L(Train): 0.2522793114185333; L(Test): 0.23684872686862946\n",
      "Epoch 8005/10000: L(Train): 0.26045671105384827; L(Test): 0.2373906821012497\n",
      "Epoch 8006/10000: L(Train): 0.256165474653244; L(Test): 0.23668859899044037\n",
      "Epoch 8007/10000: L(Train): 0.2776424288749695; L(Test): 0.23601393401622772\n",
      "Epoch 8008/10000: L(Train): 0.24900081753730774; L(Test): 0.23543967306613922\n",
      "Epoch 8009/10000: L(Train): 0.2623398005962372; L(Test): 0.23612280189990997\n",
      "Epoch 8010/10000: L(Train): 0.25855085253715515; L(Test): 0.23497875034809113\n",
      "Epoch 8011/10000: L(Train): 0.25693008303642273; L(Test): 0.23682253062725067\n",
      "Epoch 8012/10000: L(Train): 0.2731301188468933; L(Test): 0.23585939407348633\n",
      "Epoch 8013/10000: L(Train): 0.24451981484889984; L(Test): 0.23559336364269257\n",
      "Epoch 8014/10000: L(Train): 0.26506105065345764; L(Test): 0.23530839383602142\n",
      "Epoch 8015/10000: L(Train): 0.27045348286628723; L(Test): 0.23550157248973846\n",
      "Epoch 8016/10000: L(Train): 0.25913703441619873; L(Test): 0.23662568628787994\n",
      "Epoch 8017/10000: L(Train): 0.25243088603019714; L(Test): 0.23604454100131989\n",
      "Epoch 8018/10000: L(Train): 0.2650545537471771; L(Test): 0.23453952372074127\n",
      "Epoch 8019/10000: L(Train): 0.25388064980506897; L(Test): 0.23471133410930634\n",
      "Epoch 8020/10000: L(Train): 0.2679527699947357; L(Test): 0.2354350984096527\n",
      "Epoch 8021/10000: L(Train): 0.2557360827922821; L(Test): 0.23690669238567352\n",
      "Epoch 8022/10000: L(Train): 0.2597951889038086; L(Test): 0.23523162305355072\n",
      "Epoch 8023/10000: L(Train): 0.2692294120788574; L(Test): 0.2348223775625229\n",
      "Epoch 8024/10000: L(Train): 0.25686806440353394; L(Test): 0.2349366694688797\n",
      "Epoch 8025/10000: L(Train): 0.27304914593696594; L(Test): 0.23538297414779663\n",
      "Epoch 8026/10000: L(Train): 0.2661777138710022; L(Test): 0.2351071983575821\n",
      "Epoch 8027/10000: L(Train): 0.25229838490486145; L(Test): 0.23574477434158325\n",
      "Epoch 8028/10000: L(Train): 0.2634151875972748; L(Test): 0.23633818328380585\n",
      "Epoch 8029/10000: L(Train): 0.2615531086921692; L(Test): 0.2351578027009964\n",
      "Epoch 8030/10000: L(Train): 0.2553461492061615; L(Test): 0.2355702668428421\n",
      "Epoch 8031/10000: L(Train): 0.2653561532497406; L(Test): 0.2351493537425995\n",
      "Epoch 8032/10000: L(Train): 0.26358163356781006; L(Test): 0.2347162514925003\n",
      "Epoch 8033/10000: L(Train): 0.2537713348865509; L(Test): 0.23629458248615265\n",
      "Epoch 8034/10000: L(Train): 0.24964316189289093; L(Test): 0.23587191104888916\n",
      "Epoch 8035/10000: L(Train): 0.2719018757343292; L(Test): 0.23546257615089417\n",
      "Epoch 8036/10000: L(Train): 0.25609034299850464; L(Test): 0.23557646572589874\n",
      "Epoch 8037/10000: L(Train): 0.2574504613876343; L(Test): 0.23481325805187225\n",
      "Epoch 8038/10000: L(Train): 0.26340776681900024; L(Test): 0.23564419150352478\n",
      "Epoch 8039/10000: L(Train): 0.2603912651538849; L(Test): 0.23497064411640167\n",
      "Epoch 8040/10000: L(Train): 0.2465929239988327; L(Test): 0.2346406728029251\n",
      "Epoch 8041/10000: L(Train): 0.26121145486831665; L(Test): 0.2347637265920639\n",
      "Epoch 8042/10000: L(Train): 0.2630898654460907; L(Test): 0.2344558984041214\n",
      "Epoch 8043/10000: L(Train): 0.254509836435318; L(Test): 0.2350843995809555\n",
      "Epoch 8044/10000: L(Train): 0.24515941739082336; L(Test): 0.23439395427703857\n",
      "Epoch 8045/10000: L(Train): 0.24750885367393494; L(Test): 0.23425617814064026\n",
      "Epoch 8046/10000: L(Train): 0.2510579228401184; L(Test): 0.23464563488960266\n",
      "Epoch 8047/10000: L(Train): 0.2670762538909912; L(Test): 0.23433303833007812\n",
      "Epoch 8048/10000: L(Train): 0.25779616832733154; L(Test): 0.23465225100517273\n",
      "Epoch 8049/10000: L(Train): 0.25494933128356934; L(Test): 0.23442496359348297\n",
      "Epoch 8050/10000: L(Train): 0.2640499770641327; L(Test): 0.2334693819284439\n",
      "Epoch 8051/10000: L(Train): 0.2507109045982361; L(Test): 0.23356562852859497\n",
      "Epoch 8052/10000: L(Train): 0.2510538101196289; L(Test): 0.23369769752025604\n",
      "Epoch 8053/10000: L(Train): 0.2561337649822235; L(Test): 0.23502974212169647\n",
      "Epoch 8054/10000: L(Train): 0.27124395966529846; L(Test): 0.23387938737869263\n",
      "Epoch 8055/10000: L(Train): 0.2630443572998047; L(Test): 0.23459835350513458\n",
      "Epoch 8056/10000: L(Train): 0.2683956027030945; L(Test): 0.23366577923297882\n",
      "Epoch 8057/10000: L(Train): 0.26190638542175293; L(Test): 0.23594436049461365\n",
      "Epoch 8058/10000: L(Train): 0.2723616361618042; L(Test): 0.23609919846057892\n",
      "Epoch 8059/10000: L(Train): 0.25471240282058716; L(Test): 0.23419319093227386\n",
      "Epoch 8060/10000: L(Train): 0.25871217250823975; L(Test): 0.23515397310256958\n",
      "Epoch 8061/10000: L(Train): 0.26451629400253296; L(Test): 0.23601961135864258\n",
      "Epoch 8062/10000: L(Train): 0.2574883997440338; L(Test): 0.236202210187912\n",
      "Epoch 8063/10000: L(Train): 0.26032382249832153; L(Test): 0.23633095622062683\n",
      "Epoch 8064/10000: L(Train): 0.2683190405368805; L(Test): 0.23762597143650055\n",
      "Epoch 8065/10000: L(Train): 0.2630295753479004; L(Test): 0.23885449767112732\n",
      "Epoch 8066/10000: L(Train): 0.27225688099861145; L(Test): 0.23906667530536652\n",
      "Epoch 8067/10000: L(Train): 0.28152719140052795; L(Test): 0.2399979680776596\n",
      "Epoch 8068/10000: L(Train): 0.26355549693107605; L(Test): 0.23776400089263916\n",
      "Epoch 8069/10000: L(Train): 0.2706942856311798; L(Test): 0.23920680582523346\n",
      "Epoch 8070/10000: L(Train): 0.2596282362937927; L(Test): 0.23843419551849365\n",
      "Epoch 8071/10000: L(Train): 0.26110145449638367; L(Test): 0.23889373242855072\n",
      "Epoch 8072/10000: L(Train): 0.2595093846321106; L(Test): 0.23983804881572723\n",
      "Epoch 8073/10000: L(Train): 0.2611832618713379; L(Test): 0.23819655179977417\n",
      "Epoch 8074/10000: L(Train): 0.26044830679893494; L(Test): 0.23832930624485016\n",
      "Epoch 8075/10000: L(Train): 0.2708735466003418; L(Test): 0.23804335296154022\n",
      "Epoch 8076/10000: L(Train): 0.2589503526687622; L(Test): 0.23917874693870544\n",
      "Epoch 8077/10000: L(Train): 0.23840433359146118; L(Test): 0.23686975240707397\n",
      "Epoch 8078/10000: L(Train): 0.25637075304985046; L(Test): 0.23648692667484283\n",
      "Epoch 8079/10000: L(Train): 0.2560900151729584; L(Test): 0.237313374876976\n",
      "Epoch 8080/10000: L(Train): 0.2645778954029083; L(Test): 0.23552942276000977\n",
      "Epoch 8081/10000: L(Train): 0.25407853722572327; L(Test): 0.2381407618522644\n",
      "Epoch 8082/10000: L(Train): 0.27110177278518677; L(Test): 0.23712505400180817\n",
      "Epoch 8083/10000: L(Train): 0.26650282740592957; L(Test): 0.23572230339050293\n",
      "Epoch 8084/10000: L(Train): 0.26555135846138; L(Test): 0.23694317042827606\n",
      "Epoch 8085/10000: L(Train): 0.24543403089046478; L(Test): 0.23616892099380493\n",
      "Epoch 8086/10000: L(Train): 0.2704225182533264; L(Test): 0.23696936666965485\n",
      "Epoch 8087/10000: L(Train): 0.24970626831054688; L(Test): 0.23573248088359833\n",
      "Epoch 8088/10000: L(Train): 0.26183271408081055; L(Test): 0.23552513122558594\n",
      "Epoch 8089/10000: L(Train): 0.2534922659397125; L(Test): 0.2347237467765808\n",
      "Epoch 8090/10000: L(Train): 0.24624545872211456; L(Test): 0.23537302017211914\n",
      "Epoch 8091/10000: L(Train): 0.25725245475769043; L(Test): 0.23663921654224396\n",
      "Epoch 8092/10000: L(Train): 0.2694416642189026; L(Test): 0.23460005223751068\n",
      "Epoch 8093/10000: L(Train): 0.24233703315258026; L(Test): 0.23836404085159302\n",
      "Epoch 8094/10000: L(Train): 0.2598539888858795; L(Test): 0.23629173636436462\n",
      "Epoch 8095/10000: L(Train): 0.26228201389312744; L(Test): 0.23532253503799438\n",
      "Epoch 8096/10000: L(Train): 0.25807079672813416; L(Test): 0.23941515386104584\n",
      "Epoch 8097/10000: L(Train): 0.26714569330215454; L(Test): 0.23724350333213806\n",
      "Epoch 8098/10000: L(Train): 0.25987762212753296; L(Test): 0.2365856170654297\n",
      "Epoch 8099/10000: L(Train): 0.2587672770023346; L(Test): 0.2366943508386612\n",
      "Epoch 8100/10000: L(Train): 0.2581358850002289; L(Test): 0.2361524999141693\n",
      "Epoch 8101/10000: L(Train): 0.2531988322734833; L(Test): 0.2382662445306778\n",
      "Epoch 8102/10000: L(Train): 0.2508874535560608; L(Test): 0.23625124990940094\n",
      "Epoch 8103/10000: L(Train): 0.26428189873695374; L(Test): 0.2355668842792511\n",
      "Epoch 8104/10000: L(Train): 0.26736006140708923; L(Test): 0.23495309054851532\n",
      "Epoch 8105/10000: L(Train): 0.25518599152565; L(Test): 0.23513823747634888\n",
      "Epoch 8106/10000: L(Train): 0.252879798412323; L(Test): 0.23687197268009186\n",
      "Epoch 8107/10000: L(Train): 0.29133090376853943; L(Test): 0.2353639453649521\n",
      "Epoch 8108/10000: L(Train): 0.272310733795166; L(Test): 0.2367333173751831\n",
      "Epoch 8109/10000: L(Train): 0.2604437470436096; L(Test): 0.2349163442850113\n",
      "Epoch 8110/10000: L(Train): 0.2530396580696106; L(Test): 0.23773889243602753\n",
      "Epoch 8111/10000: L(Train): 0.27734190225601196; L(Test): 0.23621803522109985\n",
      "Epoch 8112/10000: L(Train): 0.25572332739830017; L(Test): 0.23618127405643463\n",
      "Epoch 8113/10000: L(Train): 0.24934473633766174; L(Test): 0.23652690649032593\n",
      "Epoch 8114/10000: L(Train): 0.26199984550476074; L(Test): 0.23637555539608002\n",
      "Epoch 8115/10000: L(Train): 0.26461854577064514; L(Test): 0.23558811843395233\n",
      "Epoch 8116/10000: L(Train): 0.2680836319923401; L(Test): 0.23590947687625885\n",
      "Epoch 8117/10000: L(Train): 0.27316126227378845; L(Test): 0.23589590191841125\n",
      "Epoch 8118/10000: L(Train): 0.26163098216056824; L(Test): 0.235315203666687\n",
      "Epoch 8119/10000: L(Train): 0.2537150979042053; L(Test): 0.23671789467334747\n",
      "Epoch 8120/10000: L(Train): 0.2718576490879059; L(Test): 0.23649075627326965\n",
      "Epoch 8121/10000: L(Train): 0.2572576105594635; L(Test): 0.23595589399337769\n",
      "Epoch 8122/10000: L(Train): 0.2713627219200134; L(Test): 0.23668906092643738\n",
      "Epoch 8123/10000: L(Train): 0.2549639046192169; L(Test): 0.2359708696603775\n",
      "Epoch 8124/10000: L(Train): 0.25368696451187134; L(Test): 0.2361447513103485\n",
      "Epoch 8125/10000: L(Train): 0.264455109834671; L(Test): 0.23646891117095947\n",
      "Epoch 8126/10000: L(Train): 0.2637369632720947; L(Test): 0.2360745668411255\n",
      "Epoch 8127/10000: L(Train): 0.2645849585533142; L(Test): 0.23551376163959503\n",
      "Epoch 8128/10000: L(Train): 0.2640268802642822; L(Test): 0.2361195683479309\n",
      "Epoch 8129/10000: L(Train): 0.25277283787727356; L(Test): 0.23640677332878113\n",
      "Epoch 8130/10000: L(Train): 0.25490304827690125; L(Test): 0.2357628345489502\n",
      "Epoch 8131/10000: L(Train): 0.25513195991516113; L(Test): 0.2366604208946228\n",
      "Epoch 8132/10000: L(Train): 0.26816800236701965; L(Test): 0.2367292195558548\n",
      "Epoch 8133/10000: L(Train): 0.24871477484703064; L(Test): 0.2363259494304657\n",
      "Epoch 8134/10000: L(Train): 0.27651575207710266; L(Test): 0.23618105053901672\n",
      "Epoch 8135/10000: L(Train): 0.2616707682609558; L(Test): 0.23657187819480896\n",
      "Epoch 8136/10000: L(Train): 0.2681906521320343; L(Test): 0.23633362352848053\n",
      "Epoch 8137/10000: L(Train): 0.25328177213668823; L(Test): 0.23576590418815613\n",
      "Epoch 8138/10000: L(Train): 0.2554593086242676; L(Test): 0.23587611317634583\n",
      "Epoch 8139/10000: L(Train): 0.2593461275100708; L(Test): 0.23673664033412933\n",
      "Epoch 8140/10000: L(Train): 0.2725105285644531; L(Test): 0.23514986038208008\n",
      "Epoch 8141/10000: L(Train): 0.24809274077415466; L(Test): 0.23627398908138275\n",
      "Epoch 8142/10000: L(Train): 0.24537603557109833; L(Test): 0.23566357791423798\n",
      "Epoch 8143/10000: L(Train): 0.23061291873455048; L(Test): 0.23678256571292877\n",
      "Epoch 8144/10000: L(Train): 0.2384365200996399; L(Test): 0.23651297390460968\n",
      "Epoch 8145/10000: L(Train): 0.26968613266944885; L(Test): 0.2368801087141037\n",
      "Epoch 8146/10000: L(Train): 0.26696547865867615; L(Test): 0.23655490577220917\n",
      "Epoch 8147/10000: L(Train): 0.24779853224754333; L(Test): 0.2357146441936493\n",
      "Epoch 8148/10000: L(Train): 0.26657143235206604; L(Test): 0.23566944897174835\n",
      "Epoch 8149/10000: L(Train): 0.2569183111190796; L(Test): 0.23605333268642426\n",
      "Epoch 8150/10000: L(Train): 0.2626561224460602; L(Test): 0.2361358255147934\n",
      "Epoch 8151/10000: L(Train): 0.2742595374584198; L(Test): 0.2349180430173874\n",
      "Epoch 8152/10000: L(Train): 0.27839136123657227; L(Test): 0.2351396083831787\n",
      "Epoch 8153/10000: L(Train): 0.2687949240207672; L(Test): 0.23586337268352509\n",
      "Epoch 8154/10000: L(Train): 0.2626245617866516; L(Test): 0.23635229468345642\n",
      "Epoch 8155/10000: L(Train): 0.2505943477153778; L(Test): 0.23750200867652893\n",
      "Epoch 8156/10000: L(Train): 0.26474282145500183; L(Test): 0.23795294761657715\n",
      "Epoch 8157/10000: L(Train): 0.25889191031455994; L(Test): 0.23908312618732452\n",
      "Epoch 8158/10000: L(Train): 0.27788904309272766; L(Test): 0.23752832412719727\n",
      "Epoch 8159/10000: L(Train): 0.2685154974460602; L(Test): 0.23883964121341705\n",
      "Epoch 8160/10000: L(Train): 0.2676125764846802; L(Test): 0.23826199769973755\n",
      "Epoch 8161/10000: L(Train): 0.2624123692512512; L(Test): 0.2389654964208603\n",
      "Epoch 8162/10000: L(Train): 0.25368532538414; L(Test): 0.23952417075634003\n",
      "Epoch 8163/10000: L(Train): 0.2795546352863312; L(Test): 0.23897291719913483\n",
      "Epoch 8164/10000: L(Train): 0.2647456228733063; L(Test): 0.23792283236980438\n",
      "Epoch 8165/10000: L(Train): 0.26414594054222107; L(Test): 0.23719976842403412\n",
      "Epoch 8166/10000: L(Train): 0.2723426818847656; L(Test): 0.2366439551115036\n",
      "Epoch 8167/10000: L(Train): 0.26779705286026; L(Test): 0.2364855855703354\n",
      "Epoch 8168/10000: L(Train): 0.26301223039627075; L(Test): 0.2367737740278244\n",
      "Epoch 8169/10000: L(Train): 0.25460317730903625; L(Test): 0.23702827095985413\n",
      "Epoch 8170/10000: L(Train): 0.26034894585609436; L(Test): 0.23639394342899323\n",
      "Epoch 8171/10000: L(Train): 0.26005303859710693; L(Test): 0.2374948263168335\n",
      "Epoch 8172/10000: L(Train): 0.2605692446231842; L(Test): 0.23677970468997955\n",
      "Epoch 8173/10000: L(Train): 0.2577962577342987; L(Test): 0.23988990485668182\n",
      "Epoch 8174/10000: L(Train): 0.25918975472450256; L(Test): 0.23702353239059448\n",
      "Epoch 8175/10000: L(Train): 0.25946128368377686; L(Test): 0.23727041482925415\n",
      "Epoch 8176/10000: L(Train): 0.2592993676662445; L(Test): 0.2360047698020935\n",
      "Epoch 8177/10000: L(Train): 0.2569959759712219; L(Test): 0.2381381094455719\n",
      "Epoch 8178/10000: L(Train): 0.26350247859954834; L(Test): 0.23842713236808777\n",
      "Epoch 8179/10000: L(Train): 0.27483147382736206; L(Test): 0.23622052371501923\n",
      "Epoch 8180/10000: L(Train): 0.24952732026576996; L(Test): 0.235786572098732\n",
      "Epoch 8181/10000: L(Train): 0.26919567584991455; L(Test): 0.23916693031787872\n",
      "Epoch 8182/10000: L(Train): 0.26178181171417236; L(Test): 0.23977726697921753\n",
      "Epoch 8183/10000: L(Train): 0.2528364360332489; L(Test): 0.23548710346221924\n",
      "Epoch 8184/10000: L(Train): 0.2651720345020294; L(Test): 0.23643532395362854\n",
      "Epoch 8185/10000: L(Train): 0.2565390467643738; L(Test): 0.23497910797595978\n",
      "Epoch 8186/10000: L(Train): 0.25127336382865906; L(Test): 0.23719161748886108\n",
      "Epoch 8187/10000: L(Train): 0.23938977718353271; L(Test): 0.23560628294944763\n",
      "Epoch 8188/10000: L(Train): 0.2321072220802307; L(Test): 0.2360510230064392\n",
      "Epoch 8189/10000: L(Train): 0.26678967475891113; L(Test): 0.23555997014045715\n",
      "Epoch 8190/10000: L(Train): 0.24653296172618866; L(Test): 0.23566333949565887\n",
      "Epoch 8191/10000: L(Train): 0.2500542998313904; L(Test): 0.23692014813423157\n",
      "Epoch 8192/10000: L(Train): 0.2649941146373749; L(Test): 0.23572982847690582\n",
      "Epoch 8193/10000: L(Train): 0.2730850577354431; L(Test): 0.2351202666759491\n",
      "Epoch 8194/10000: L(Train): 0.2585132420063019; L(Test): 0.23549701273441315\n",
      "Epoch 8195/10000: L(Train): 0.2526930272579193; L(Test): 0.23549392819404602\n",
      "Epoch 8196/10000: L(Train): 0.2599959373474121; L(Test): 0.23529425263404846\n",
      "Epoch 8197/10000: L(Train): 0.25253012776374817; L(Test): 0.23520058393478394\n",
      "Epoch 8198/10000: L(Train): 0.2574964463710785; L(Test): 0.23557139933109283\n",
      "Epoch 8199/10000: L(Train): 0.265213280916214; L(Test): 0.23597612977027893\n",
      "Epoch 8200/10000: L(Train): 0.2626563608646393; L(Test): 0.2359849512577057\n",
      "Epoch 8201/10000: L(Train): 0.2578039765357971; L(Test): 0.23539823293685913\n",
      "Epoch 8202/10000: L(Train): 0.25791776180267334; L(Test): 0.23558218777179718\n",
      "Epoch 8203/10000: L(Train): 0.2647612988948822; L(Test): 0.23522420227527618\n",
      "Epoch 8204/10000: L(Train): 0.25504106283187866; L(Test): 0.23566967248916626\n",
      "Epoch 8205/10000: L(Train): 0.2649462819099426; L(Test): 0.23610596358776093\n",
      "Epoch 8206/10000: L(Train): 0.2732926905155182; L(Test): 0.23711459338665009\n",
      "Epoch 8207/10000: L(Train): 0.25144341588020325; L(Test): 0.2365373969078064\n",
      "Epoch 8208/10000: L(Train): 0.25867852568626404; L(Test): 0.23699787259101868\n",
      "Epoch 8209/10000: L(Train): 0.24949251115322113; L(Test): 0.2384432703256607\n",
      "Epoch 8210/10000: L(Train): 0.2698511481285095; L(Test): 0.2372695505619049\n",
      "Epoch 8211/10000: L(Train): 0.26102280616760254; L(Test): 0.23600360751152039\n",
      "Epoch 8212/10000: L(Train): 0.25269272923469543; L(Test): 0.23651261627674103\n",
      "Epoch 8213/10000: L(Train): 0.2648366689682007; L(Test): 0.2368803471326828\n",
      "Epoch 8214/10000: L(Train): 0.26470747590065; L(Test): 0.23584198951721191\n",
      "Epoch 8215/10000: L(Train): 0.28415948152542114; L(Test): 0.2366376519203186\n",
      "Epoch 8216/10000: L(Train): 0.26658937335014343; L(Test): 0.241064190864563\n",
      "Epoch 8217/10000: L(Train): 0.2589622735977173; L(Test): 0.237850621342659\n",
      "Epoch 8218/10000: L(Train): 0.26726293563842773; L(Test): 0.2413419932126999\n",
      "Epoch 8219/10000: L(Train): 0.25435149669647217; L(Test): 0.24103060364723206\n",
      "Epoch 8220/10000: L(Train): 0.2639063000679016; L(Test): 0.2391691654920578\n",
      "Epoch 8221/10000: L(Train): 0.27797451615333557; L(Test): 0.24227429926395416\n",
      "Epoch 8222/10000: L(Train): 0.2560887634754181; L(Test): 0.2407941371202469\n",
      "Epoch 8223/10000: L(Train): 0.2788569927215576; L(Test): 0.23870372772216797\n",
      "Epoch 8224/10000: L(Train): 0.24760359525680542; L(Test): 0.2414853721857071\n",
      "Epoch 8225/10000: L(Train): 0.2573859691619873; L(Test): 0.24007724225521088\n",
      "Epoch 8226/10000: L(Train): 0.270172119140625; L(Test): 0.23926949501037598\n",
      "Epoch 8227/10000: L(Train): 0.2617320418357849; L(Test): 0.2392723560333252\n",
      "Epoch 8228/10000: L(Train): 0.28923237323760986; L(Test): 0.23757293820381165\n",
      "Epoch 8229/10000: L(Train): 0.2591707408428192; L(Test): 0.23717689514160156\n",
      "Epoch 8230/10000: L(Train): 0.2665339708328247; L(Test): 0.23721684515476227\n",
      "Epoch 8231/10000: L(Train): 0.2702556848526001; L(Test): 0.23798124492168427\n",
      "Epoch 8232/10000: L(Train): 0.2689818739891052; L(Test): 0.23707811534404755\n",
      "Epoch 8233/10000: L(Train): 0.26916420459747314; L(Test): 0.23797638714313507\n",
      "Epoch 8234/10000: L(Train): 0.256902277469635; L(Test): 0.2387268841266632\n",
      "Epoch 8235/10000: L(Train): 0.2676772475242615; L(Test): 0.23747441172599792\n",
      "Epoch 8236/10000: L(Train): 0.26872649788856506; L(Test): 0.23692819476127625\n",
      "Epoch 8237/10000: L(Train): 0.2466864138841629; L(Test): 0.23736152052879333\n",
      "Epoch 8238/10000: L(Train): 0.24561235308647156; L(Test): 0.23819778859615326\n",
      "Epoch 8239/10000: L(Train): 0.253337562084198; L(Test): 0.23904527723789215\n",
      "Epoch 8240/10000: L(Train): 0.25890377163887024; L(Test): 0.2372046560049057\n",
      "Epoch 8241/10000: L(Train): 0.2661323547363281; L(Test): 0.23762394487857819\n",
      "Epoch 8242/10000: L(Train): 0.24416692554950714; L(Test): 0.23888058960437775\n",
      "Epoch 8243/10000: L(Train): 0.25789475440979004; L(Test): 0.23649998009204865\n",
      "Epoch 8244/10000: L(Train): 0.2583214044570923; L(Test): 0.23605887591838837\n",
      "Epoch 8245/10000: L(Train): 0.24414612352848053; L(Test): 0.23589052259922028\n",
      "Epoch 8246/10000: L(Train): 0.26296985149383545; L(Test): 0.23721590638160706\n",
      "Epoch 8247/10000: L(Train): 0.2768224775791168; L(Test): 0.23562853038311005\n",
      "Epoch 8248/10000: L(Train): 0.2526552677154541; L(Test): 0.23568138480186462\n",
      "Epoch 8249/10000: L(Train): 0.2575002610683441; L(Test): 0.2352544069290161\n",
      "Epoch 8250/10000: L(Train): 0.2620108723640442; L(Test): 0.23534145951271057\n",
      "Epoch 8251/10000: L(Train): 0.2582072615623474; L(Test): 0.23551340401172638\n",
      "Epoch 8252/10000: L(Train): 0.27150389552116394; L(Test): 0.23514442145824432\n",
      "Epoch 8253/10000: L(Train): 0.2765743136405945; L(Test): 0.23467935621738434\n",
      "Epoch 8254/10000: L(Train): 0.2624046206474304; L(Test): 0.23394621908664703\n",
      "Epoch 8255/10000: L(Train): 0.2631637752056122; L(Test): 0.23393367230892181\n",
      "Epoch 8256/10000: L(Train): 0.2648181617259979; L(Test): 0.23452168703079224\n",
      "Epoch 8257/10000: L(Train): 0.24797780811786652; L(Test): 0.23473188281059265\n",
      "Epoch 8258/10000: L(Train): 0.25232893228530884; L(Test): 0.2347690761089325\n",
      "Epoch 8259/10000: L(Train): 0.2452719658613205; L(Test): 0.23467598855495453\n",
      "Epoch 8260/10000: L(Train): 0.2640056908130646; L(Test): 0.23480449616909027\n",
      "Epoch 8261/10000: L(Train): 0.24720801413059235; L(Test): 0.2343348115682602\n",
      "Epoch 8262/10000: L(Train): 0.2552335858345032; L(Test): 0.23572546243667603\n",
      "Epoch 8263/10000: L(Train): 0.2574019730091095; L(Test): 0.23419612646102905\n",
      "Epoch 8264/10000: L(Train): 0.25067394971847534; L(Test): 0.2334103137254715\n",
      "Epoch 8265/10000: L(Train): 0.24979041516780853; L(Test): 0.23312877118587494\n",
      "Epoch 8266/10000: L(Train): 0.2552393972873688; L(Test): 0.2334887534379959\n",
      "Epoch 8267/10000: L(Train): 0.2756957411766052; L(Test): 0.23398526012897491\n",
      "Epoch 8268/10000: L(Train): 0.2448243647813797; L(Test): 0.2337314784526825\n",
      "Epoch 8269/10000: L(Train): 0.25692424178123474; L(Test): 0.23361483216285706\n",
      "Epoch 8270/10000: L(Train): 0.24209894239902496; L(Test): 0.23350107669830322\n",
      "Epoch 8271/10000: L(Train): 0.25279122591018677; L(Test): 0.23407430946826935\n",
      "Epoch 8272/10000: L(Train): 0.2502821981906891; L(Test): 0.23454508185386658\n",
      "Epoch 8273/10000: L(Train): 0.2568703591823578; L(Test): 0.2348146289587021\n",
      "Epoch 8274/10000: L(Train): 0.26865991950035095; L(Test): 0.2344047725200653\n",
      "Epoch 8275/10000: L(Train): 0.2577325105667114; L(Test): 0.23508234322071075\n",
      "Epoch 8276/10000: L(Train): 0.24980750679969788; L(Test): 0.23502042889595032\n",
      "Epoch 8277/10000: L(Train): 0.2580028176307678; L(Test): 0.2343459129333496\n",
      "Epoch 8278/10000: L(Train): 0.25017452239990234; L(Test): 0.23430165648460388\n",
      "Epoch 8279/10000: L(Train): 0.26205235719680786; L(Test): 0.2347942590713501\n",
      "Epoch 8280/10000: L(Train): 0.2531333863735199; L(Test): 0.23625344038009644\n",
      "Epoch 8281/10000: L(Train): 0.2596931457519531; L(Test): 0.234141007065773\n",
      "Epoch 8282/10000: L(Train): 0.25911635160446167; L(Test): 0.2344006896018982\n",
      "Epoch 8283/10000: L(Train): 0.24273844063282013; L(Test): 0.23553301393985748\n",
      "Epoch 8284/10000: L(Train): 0.2561388909816742; L(Test): 0.23758459091186523\n",
      "Epoch 8285/10000: L(Train): 0.2505294978618622; L(Test): 0.23575173318386078\n",
      "Epoch 8286/10000: L(Train): 0.26638561487197876; L(Test): 0.23606657981872559\n",
      "Epoch 8287/10000: L(Train): 0.26232466101646423; L(Test): 0.234310120344162\n",
      "Epoch 8288/10000: L(Train): 0.24752865731716156; L(Test): 0.23525896668434143\n",
      "Epoch 8289/10000: L(Train): 0.2575288712978363; L(Test): 0.23528730869293213\n",
      "Epoch 8290/10000: L(Train): 0.24052059650421143; L(Test): 0.23498404026031494\n",
      "Epoch 8291/10000: L(Train): 0.264369398355484; L(Test): 0.23569589853286743\n",
      "Epoch 8292/10000: L(Train): 0.25593388080596924; L(Test): 0.23417238891124725\n",
      "Epoch 8293/10000: L(Train): 0.24816769361495972; L(Test): 0.23623861372470856\n",
      "Epoch 8294/10000: L(Train): 0.2543677091598511; L(Test): 0.23431605100631714\n",
      "Epoch 8295/10000: L(Train): 0.25430580973625183; L(Test): 0.23430600762367249\n",
      "Epoch 8296/10000: L(Train): 0.2561435103416443; L(Test): 0.23490187525749207\n",
      "Epoch 8297/10000: L(Train): 0.26157164573669434; L(Test): 0.23476198315620422\n",
      "Epoch 8298/10000: L(Train): 0.2692957818508148; L(Test): 0.2353074997663498\n",
      "Epoch 8299/10000: L(Train): 0.2661758363246918; L(Test): 0.23583243787288666\n",
      "Epoch 8300/10000: L(Train): 0.25810471177101135; L(Test): 0.23537999391555786\n",
      "Epoch 8301/10000: L(Train): 0.2715206444263458; L(Test): 0.2366102635860443\n",
      "Epoch 8302/10000: L(Train): 0.259994238615036; L(Test): 0.23747025430202484\n",
      "Epoch 8303/10000: L(Train): 0.2573683261871338; L(Test): 0.23630213737487793\n",
      "Epoch 8304/10000: L(Train): 0.2646179497241974; L(Test): 0.2361159324645996\n",
      "Epoch 8305/10000: L(Train): 0.2675298750400543; L(Test): 0.23619815707206726\n",
      "Epoch 8306/10000: L(Train): 0.2640846371650696; L(Test): 0.236310213804245\n",
      "Epoch 8307/10000: L(Train): 0.2541535496711731; L(Test): 0.23681603372097015\n",
      "Epoch 8308/10000: L(Train): 0.2738156318664551; L(Test): 0.23672346770763397\n",
      "Epoch 8309/10000: L(Train): 0.249589741230011; L(Test): 0.23723283410072327\n",
      "Epoch 8310/10000: L(Train): 0.27226975560188293; L(Test): 0.23845897614955902\n",
      "Epoch 8311/10000: L(Train): 0.2582944929599762; L(Test): 0.2367819845676422\n",
      "Epoch 8312/10000: L(Train): 0.25719860196113586; L(Test): 0.23754706978797913\n",
      "Epoch 8313/10000: L(Train): 0.258831650018692; L(Test): 0.2379911094903946\n",
      "Epoch 8314/10000: L(Train): 0.26421910524368286; L(Test): 0.23602145910263062\n",
      "Epoch 8315/10000: L(Train): 0.2672737240791321; L(Test): 0.23481778800487518\n",
      "Epoch 8316/10000: L(Train): 0.26291653513908386; L(Test): 0.23556950688362122\n",
      "Epoch 8317/10000: L(Train): 0.26434528827667236; L(Test): 0.2355157434940338\n",
      "Epoch 8318/10000: L(Train): 0.2582654058933258; L(Test): 0.23833096027374268\n",
      "Epoch 8319/10000: L(Train): 0.2568795084953308; L(Test): 0.23675695061683655\n",
      "Epoch 8320/10000: L(Train): 0.26652097702026367; L(Test): 0.2357608824968338\n",
      "Epoch 8321/10000: L(Train): 0.26335567235946655; L(Test): 0.23540180921554565\n",
      "Epoch 8322/10000: L(Train): 0.2670227885246277; L(Test): 0.2356141209602356\n",
      "Epoch 8323/10000: L(Train): 0.2683912217617035; L(Test): 0.23517663776874542\n",
      "Epoch 8324/10000: L(Train): 0.2548096776008606; L(Test): 0.2357456386089325\n",
      "Epoch 8325/10000: L(Train): 0.2712785005569458; L(Test): 0.235407754778862\n",
      "Epoch 8326/10000: L(Train): 0.2556000351905823; L(Test): 0.23477888107299805\n",
      "Epoch 8327/10000: L(Train): 0.24724248051643372; L(Test): 0.23493023216724396\n",
      "Epoch 8328/10000: L(Train): 0.26988330483436584; L(Test): 0.2346731722354889\n",
      "Epoch 8329/10000: L(Train): 0.2471492737531662; L(Test): 0.23439663648605347\n",
      "Epoch 8330/10000: L(Train): 0.26040804386138916; L(Test): 0.2352585345506668\n",
      "Epoch 8331/10000: L(Train): 0.2541724443435669; L(Test): 0.23552903532981873\n",
      "Epoch 8332/10000: L(Train): 0.26554951071739197; L(Test): 0.235096275806427\n",
      "Epoch 8333/10000: L(Train): 0.2636434733867645; L(Test): 0.23595230281352997\n",
      "Epoch 8334/10000: L(Train): 0.2521477937698364; L(Test): 0.23583701252937317\n",
      "Epoch 8335/10000: L(Train): 0.26283201575279236; L(Test): 0.23558753728866577\n",
      "Epoch 8336/10000: L(Train): 0.26470646262168884; L(Test): 0.23550337553024292\n",
      "Epoch 8337/10000: L(Train): 0.24355724453926086; L(Test): 0.23618905246257782\n",
      "Epoch 8338/10000: L(Train): 0.25901392102241516; L(Test): 0.2351682037115097\n",
      "Epoch 8339/10000: L(Train): 0.25150102376937866; L(Test): 0.23585574328899384\n",
      "Epoch 8340/10000: L(Train): 0.24828286468982697; L(Test): 0.23665723204612732\n",
      "Epoch 8341/10000: L(Train): 0.2737301290035248; L(Test): 0.23544791340827942\n",
      "Epoch 8342/10000: L(Train): 0.2745257318019867; L(Test): 0.23501309752464294\n",
      "Epoch 8343/10000: L(Train): 0.24513383209705353; L(Test): 0.2348524034023285\n",
      "Epoch 8344/10000: L(Train): 0.2577930688858032; L(Test): 0.23543061316013336\n",
      "Epoch 8345/10000: L(Train): 0.26251712441444397; L(Test): 0.23577094078063965\n",
      "Epoch 8346/10000: L(Train): 0.2524629533290863; L(Test): 0.23472929000854492\n",
      "Epoch 8347/10000: L(Train): 0.2637355327606201; L(Test): 0.2348935753107071\n",
      "Epoch 8348/10000: L(Train): 0.27724888920783997; L(Test): 0.2352493852376938\n",
      "Epoch 8349/10000: L(Train): 0.2527504563331604; L(Test): 0.23541444540023804\n",
      "Epoch 8350/10000: L(Train): 0.23603539168834686; L(Test): 0.23487350344657898\n",
      "Epoch 8351/10000: L(Train): 0.26364293694496155; L(Test): 0.23384042084217072\n",
      "Epoch 8352/10000: L(Train): 0.2529378831386566; L(Test): 0.2334757149219513\n",
      "Epoch 8353/10000: L(Train): 0.2664680480957031; L(Test): 0.23316198587417603\n",
      "Epoch 8354/10000: L(Train): 0.25613418221473694; L(Test): 0.23329170048236847\n",
      "Epoch 8355/10000: L(Train): 0.25728413462638855; L(Test): 0.23407885432243347\n",
      "Epoch 8356/10000: L(Train): 0.2601679563522339; L(Test): 0.23401594161987305\n",
      "Epoch 8357/10000: L(Train): 0.26353719830513; L(Test): 0.23542878031730652\n",
      "Epoch 8358/10000: L(Train): 0.25417855381965637; L(Test): 0.2356935441493988\n",
      "Epoch 8359/10000: L(Train): 0.25883257389068604; L(Test): 0.23665711283683777\n",
      "Epoch 8360/10000: L(Train): 0.2598159909248352; L(Test): 0.2371387630701065\n",
      "Epoch 8361/10000: L(Train): 0.2539523243904114; L(Test): 0.23608003556728363\n",
      "Epoch 8362/10000: L(Train): 0.2466113567352295; L(Test): 0.23587144911289215\n",
      "Epoch 8363/10000: L(Train): 0.26502448320388794; L(Test): 0.23724322021007538\n",
      "Epoch 8364/10000: L(Train): 0.2517448365688324; L(Test): 0.23648867011070251\n",
      "Epoch 8365/10000: L(Train): 0.24410472810268402; L(Test): 0.2358664870262146\n",
      "Epoch 8366/10000: L(Train): 0.27053302526474; L(Test): 0.23701636493206024\n",
      "Epoch 8367/10000: L(Train): 0.2564542591571808; L(Test): 0.2355220764875412\n",
      "Epoch 8368/10000: L(Train): 0.2558209002017975; L(Test): 0.23576366901397705\n",
      "Epoch 8369/10000: L(Train): 0.25140833854675293; L(Test): 0.23593372106552124\n",
      "Epoch 8370/10000: L(Train): 0.2556730806827545; L(Test): 0.23587742447853088\n",
      "Epoch 8371/10000: L(Train): 0.2676672339439392; L(Test): 0.23642274737358093\n",
      "Epoch 8372/10000: L(Train): 0.2600748538970947; L(Test): 0.23586250841617584\n",
      "Epoch 8373/10000: L(Train): 0.2623835802078247; L(Test): 0.23544712364673615\n",
      "Epoch 8374/10000: L(Train): 0.24663273990154266; L(Test): 0.23610611259937286\n",
      "Epoch 8375/10000: L(Train): 0.24725812673568726; L(Test): 0.23595809936523438\n",
      "Epoch 8376/10000: L(Train): 0.24920164048671722; L(Test): 0.23540367186069489\n",
      "Epoch 8377/10000: L(Train): 0.25050899386405945; L(Test): 0.2352408915758133\n",
      "Epoch 8378/10000: L(Train): 0.2612605392932892; L(Test): 0.23494477570056915\n",
      "Epoch 8379/10000: L(Train): 0.25527384877204895; L(Test): 0.23481029272079468\n",
      "Epoch 8380/10000: L(Train): 0.2441062331199646; L(Test): 0.23467302322387695\n",
      "Epoch 8381/10000: L(Train): 0.256292462348938; L(Test): 0.23422738909721375\n",
      "Epoch 8382/10000: L(Train): 0.2619997262954712; L(Test): 0.2355705350637436\n",
      "Epoch 8383/10000: L(Train): 0.2585374116897583; L(Test): 0.23584960401058197\n",
      "Epoch 8384/10000: L(Train): 0.2608702778816223; L(Test): 0.23598472774028778\n",
      "Epoch 8385/10000: L(Train): 0.26638224720954895; L(Test): 0.2356807440519333\n",
      "Epoch 8386/10000: L(Train): 0.26256489753723145; L(Test): 0.23484650254249573\n",
      "Epoch 8387/10000: L(Train): 0.25832828879356384; L(Test): 0.2347470223903656\n",
      "Epoch 8388/10000: L(Train): 0.28180915117263794; L(Test): 0.2358555942773819\n",
      "Epoch 8389/10000: L(Train): 0.2529031038284302; L(Test): 0.23566608130931854\n",
      "Epoch 8390/10000: L(Train): 0.2824940085411072; L(Test): 0.2350480705499649\n",
      "Epoch 8391/10000: L(Train): 0.26471614837646484; L(Test): 0.23556944727897644\n",
      "Epoch 8392/10000: L(Train): 0.2758234143257141; L(Test): 0.23770400881767273\n",
      "Epoch 8393/10000: L(Train): 0.2576855719089508; L(Test): 0.23679739236831665\n",
      "Epoch 8394/10000: L(Train): 0.27308106422424316; L(Test): 0.2364383339881897\n",
      "Epoch 8395/10000: L(Train): 0.26663777232170105; L(Test): 0.23755872249603271\n",
      "Epoch 8396/10000: L(Train): 0.26337936520576477; L(Test): 0.2368997484445572\n",
      "Epoch 8397/10000: L(Train): 0.2738075852394104; L(Test): 0.23785948753356934\n",
      "Epoch 8398/10000: L(Train): 0.2508988380432129; L(Test): 0.236495241522789\n",
      "Epoch 8399/10000: L(Train): 0.2551334798336029; L(Test): 0.2376023828983307\n",
      "Epoch 8400/10000: L(Train): 0.26614347100257874; L(Test): 0.23504091799259186\n",
      "Epoch 8401/10000: L(Train): 0.26239660382270813; L(Test): 0.23809991776943207\n",
      "Epoch 8402/10000: L(Train): 0.24365286529064178; L(Test): 0.23821434378623962\n",
      "Epoch 8403/10000: L(Train): 0.2659304738044739; L(Test): 0.23546959459781647\n",
      "Epoch 8404/10000: L(Train): 0.2642696499824524; L(Test): 0.23745965957641602\n",
      "Epoch 8405/10000: L(Train): 0.25037890672683716; L(Test): 0.23712769150733948\n",
      "Epoch 8406/10000: L(Train): 0.276481956243515; L(Test): 0.23476916551589966\n",
      "Epoch 8407/10000: L(Train): 0.258258193731308; L(Test): 0.23502019047737122\n",
      "Epoch 8408/10000: L(Train): 0.24559828639030457; L(Test): 0.23635247349739075\n",
      "Epoch 8409/10000: L(Train): 0.2651095688343048; L(Test): 0.23438647389411926\n",
      "Epoch 8410/10000: L(Train): 0.2596246898174286; L(Test): 0.2362319976091385\n",
      "Epoch 8411/10000: L(Train): 0.2578088045120239; L(Test): 0.2367762178182602\n",
      "Epoch 8412/10000: L(Train): 0.2620621919631958; L(Test): 0.23510676622390747\n",
      "Epoch 8413/10000: L(Train): 0.25145429372787476; L(Test): 0.23589569330215454\n",
      "Epoch 8414/10000: L(Train): 0.24953097105026245; L(Test): 0.23715369403362274\n",
      "Epoch 8415/10000: L(Train): 0.2548847198486328; L(Test): 0.2360040247440338\n",
      "Epoch 8416/10000: L(Train): 0.2764110565185547; L(Test): 0.2366257607936859\n",
      "Epoch 8417/10000: L(Train): 0.26048901677131653; L(Test): 0.2370454967021942\n",
      "Epoch 8418/10000: L(Train): 0.24351967871189117; L(Test): 0.23570439219474792\n",
      "Epoch 8419/10000: L(Train): 0.25636276602745056; L(Test): 0.2357148975133896\n",
      "Epoch 8420/10000: L(Train): 0.25192832946777344; L(Test): 0.23640254139900208\n",
      "Epoch 8421/10000: L(Train): 0.2604182958602905; L(Test): 0.23650400340557098\n",
      "Epoch 8422/10000: L(Train): 0.26481568813323975; L(Test): 0.23515655100345612\n",
      "Epoch 8423/10000: L(Train): 0.25375840067863464; L(Test): 0.23456494510173798\n",
      "Epoch 8424/10000: L(Train): 0.2508493959903717; L(Test): 0.23591016232967377\n",
      "Epoch 8425/10000: L(Train): 0.25130367279052734; L(Test): 0.23593877255916595\n",
      "Epoch 8426/10000: L(Train): 0.2680452764034271; L(Test): 0.23493963479995728\n",
      "Epoch 8427/10000: L(Train): 0.2581920325756073; L(Test): 0.23526346683502197\n",
      "Epoch 8428/10000: L(Train): 0.2610456347465515; L(Test): 0.23503164947032928\n",
      "Epoch 8429/10000: L(Train): 0.26319023966789246; L(Test): 0.23405711352825165\n",
      "Epoch 8430/10000: L(Train): 0.24873855710029602; L(Test): 0.23447851836681366\n",
      "Epoch 8431/10000: L(Train): 0.260752409696579; L(Test): 0.23411446809768677\n",
      "Epoch 8432/10000: L(Train): 0.26285290718078613; L(Test): 0.23605477809906006\n",
      "Epoch 8433/10000: L(Train): 0.25152385234832764; L(Test): 0.23439186811447144\n",
      "Epoch 8434/10000: L(Train): 0.25255703926086426; L(Test): 0.23496179282665253\n",
      "Epoch 8435/10000: L(Train): 0.2653399705886841; L(Test): 0.23538127541542053\n",
      "Epoch 8436/10000: L(Train): 0.26355665922164917; L(Test): 0.23488910496234894\n",
      "Epoch 8437/10000: L(Train): 0.25491684675216675; L(Test): 0.23548637330532074\n",
      "Epoch 8438/10000: L(Train): 0.25972655415534973; L(Test): 0.2352944016456604\n",
      "Epoch 8439/10000: L(Train): 0.26346728205680847; L(Test): 0.23457105457782745\n",
      "Epoch 8440/10000: L(Train): 0.24826115369796753; L(Test): 0.23451277613639832\n",
      "Epoch 8441/10000: L(Train): 0.2618243396282196; L(Test): 0.2344062626361847\n",
      "Epoch 8442/10000: L(Train): 0.24378757178783417; L(Test): 0.23609349131584167\n",
      "Epoch 8443/10000: L(Train): 0.26805129647254944; L(Test): 0.2360907793045044\n",
      "Epoch 8444/10000: L(Train): 0.2708839476108551; L(Test): 0.2352333515882492\n",
      "Epoch 8445/10000: L(Train): 0.2722219228744507; L(Test): 0.2367812544107437\n",
      "Epoch 8446/10000: L(Train): 0.26841431856155396; L(Test): 0.23565161228179932\n",
      "Epoch 8447/10000: L(Train): 0.2593224048614502; L(Test): 0.23466841876506805\n",
      "Epoch 8448/10000: L(Train): 0.24606932699680328; L(Test): 0.23613542318344116\n",
      "Epoch 8449/10000: L(Train): 0.25558459758758545; L(Test): 0.23636223375797272\n",
      "Epoch 8450/10000: L(Train): 0.2563237249851227; L(Test): 0.2368043065071106\n",
      "Epoch 8451/10000: L(Train): 0.2737504243850708; L(Test): 0.2359933853149414\n",
      "Epoch 8452/10000: L(Train): 0.267046183347702; L(Test): 0.23521657288074493\n",
      "Epoch 8453/10000: L(Train): 0.2710106372833252; L(Test): 0.23684103786945343\n",
      "Epoch 8454/10000: L(Train): 0.2622552216053009; L(Test): 0.23710550367832184\n",
      "Epoch 8455/10000: L(Train): 0.24955423176288605; L(Test): 0.2351837158203125\n",
      "Epoch 8456/10000: L(Train): 0.2507506310939789; L(Test): 0.23709075152873993\n",
      "Epoch 8457/10000: L(Train): 0.2601378262042999; L(Test): 0.23625406622886658\n",
      "Epoch 8458/10000: L(Train): 0.2555968761444092; L(Test): 0.23515748977661133\n",
      "Epoch 8459/10000: L(Train): 0.25893017649650574; L(Test): 0.23504826426506042\n",
      "Epoch 8460/10000: L(Train): 0.2447027564048767; L(Test): 0.2352563440799713\n",
      "Epoch 8461/10000: L(Train): 0.25254544615745544; L(Test): 0.23570388555526733\n",
      "Epoch 8462/10000: L(Train): 0.2549836337566376; L(Test): 0.23726437985897064\n",
      "Epoch 8463/10000: L(Train): 0.2830151617527008; L(Test): 0.23647430539131165\n",
      "Epoch 8464/10000: L(Train): 0.2658596932888031; L(Test): 0.2364860624074936\n",
      "Epoch 8465/10000: L(Train): 0.2651396691799164; L(Test): 0.23555026948451996\n",
      "Epoch 8466/10000: L(Train): 0.26153168082237244; L(Test): 0.2380792796611786\n",
      "Epoch 8467/10000: L(Train): 0.256620854139328; L(Test): 0.23806601762771606\n",
      "Epoch 8468/10000: L(Train): 0.2552141845226288; L(Test): 0.23609139025211334\n",
      "Epoch 8469/10000: L(Train): 0.26841822266578674; L(Test): 0.23599685728549957\n",
      "Epoch 8470/10000: L(Train): 0.2559834122657776; L(Test): 0.23522500693798065\n",
      "Epoch 8471/10000: L(Train): 0.25731971859931946; L(Test): 0.23807193338871002\n",
      "Epoch 8472/10000: L(Train): 0.24808591604232788; L(Test): 0.23527421057224274\n",
      "Epoch 8473/10000: L(Train): 0.27323660254478455; L(Test): 0.23917466402053833\n",
      "Epoch 8474/10000: L(Train): 0.25985559821128845; L(Test): 0.24107138812541962\n",
      "Epoch 8475/10000: L(Train): 0.279535174369812; L(Test): 0.24288050830364227\n",
      "Epoch 8476/10000: L(Train): 0.26221734285354614; L(Test): 0.24283680319786072\n",
      "Epoch 8477/10000: L(Train): 0.27646753191947937; L(Test): 0.24135583639144897\n",
      "Epoch 8478/10000: L(Train): 0.25485101342201233; L(Test): 0.24414034187793732\n",
      "Epoch 8479/10000: L(Train): 0.2684362828731537; L(Test): 0.2397058755159378\n",
      "Epoch 8480/10000: L(Train): 0.25855839252471924; L(Test): 0.2420518845319748\n",
      "Epoch 8481/10000: L(Train): 0.24810323119163513; L(Test): 0.2457447499036789\n",
      "Epoch 8482/10000: L(Train): 0.26551124453544617; L(Test): 0.24171359837055206\n",
      "Epoch 8483/10000: L(Train): 0.25688329339027405; L(Test): 0.24009431898593903\n",
      "Epoch 8484/10000: L(Train): 0.2600301504135132; L(Test): 0.24164807796478271\n",
      "Epoch 8485/10000: L(Train): 0.2617884576320648; L(Test): 0.24264997243881226\n",
      "Epoch 8486/10000: L(Train): 0.2683066129684448; L(Test): 0.2415267676115036\n",
      "Epoch 8487/10000: L(Train): 0.25902920961380005; L(Test): 0.23862206935882568\n",
      "Epoch 8488/10000: L(Train): 0.25593045353889465; L(Test): 0.2414790391921997\n",
      "Epoch 8489/10000: L(Train): 0.2620769441127777; L(Test): 0.24220411479473114\n",
      "Epoch 8490/10000: L(Train): 0.2670268714427948; L(Test): 0.24128268659114838\n",
      "Epoch 8491/10000: L(Train): 0.27285200357437134; L(Test): 0.24033521115779877\n",
      "Epoch 8492/10000: L(Train): 0.2607434391975403; L(Test): 0.2400314062833786\n",
      "Epoch 8493/10000: L(Train): 0.26333922147750854; L(Test): 0.23885449767112732\n",
      "Epoch 8494/10000: L(Train): 0.2486715316772461; L(Test): 0.23783452808856964\n",
      "Epoch 8495/10000: L(Train): 0.2754788100719452; L(Test): 0.2411309778690338\n",
      "Epoch 8496/10000: L(Train): 0.26240846514701843; L(Test): 0.24268503487110138\n",
      "Epoch 8497/10000: L(Train): 0.2779580056667328; L(Test): 0.23757536709308624\n",
      "Epoch 8498/10000: L(Train): 0.24871139228343964; L(Test): 0.2379974126815796\n",
      "Epoch 8499/10000: L(Train): 0.25239500403404236; L(Test): 0.23881900310516357\n",
      "Epoch 8500/10000: L(Train): 0.26372480392456055; L(Test): 0.24175000190734863\n",
      "Epoch 8501/10000: L(Train): 0.26814645528793335; L(Test): 0.23910404741764069\n",
      "Epoch 8502/10000: L(Train): 0.25163668394088745; L(Test): 0.23947025835514069\n",
      "Epoch 8503/10000: L(Train): 0.2518150508403778; L(Test): 0.24052155017852783\n",
      "Epoch 8504/10000: L(Train): 0.27440109848976135; L(Test): 0.23795472085475922\n",
      "Epoch 8505/10000: L(Train): 0.2555685341358185; L(Test): 0.23996436595916748\n",
      "Epoch 8506/10000: L(Train): 0.25911033153533936; L(Test): 0.2382563203573227\n",
      "Epoch 8507/10000: L(Train): 0.2705855369567871; L(Test): 0.23699244856834412\n",
      "Epoch 8508/10000: L(Train): 0.2527454197406769; L(Test): 0.23743298649787903\n",
      "Epoch 8509/10000: L(Train): 0.2595263719558716; L(Test): 0.23630638420581818\n",
      "Epoch 8510/10000: L(Train): 0.2694958448410034; L(Test): 0.23823809623718262\n",
      "Epoch 8511/10000: L(Train): 0.26592615246772766; L(Test): 0.23683276772499084\n",
      "Epoch 8512/10000: L(Train): 0.25141894817352295; L(Test): 0.2372450977563858\n",
      "Epoch 8513/10000: L(Train): 0.2551371157169342; L(Test): 0.23675104975700378\n",
      "Epoch 8514/10000: L(Train): 0.2566375732421875; L(Test): 0.23621773719787598\n",
      "Epoch 8515/10000: L(Train): 0.26042047142982483; L(Test): 0.23667965829372406\n",
      "Epoch 8516/10000: L(Train): 0.2567380964756012; L(Test): 0.23709248006343842\n",
      "Epoch 8517/10000: L(Train): 0.2646947503089905; L(Test): 0.23619124293327332\n",
      "Epoch 8518/10000: L(Train): 0.2524576783180237; L(Test): 0.23567086458206177\n",
      "Epoch 8519/10000: L(Train): 0.26477089524269104; L(Test): 0.2379627376794815\n",
      "Epoch 8520/10000: L(Train): 0.25808775424957275; L(Test): 0.2383015751838684\n",
      "Epoch 8521/10000: L(Train): 0.27760741114616394; L(Test): 0.23701028525829315\n",
      "Epoch 8522/10000: L(Train): 0.24964502453804016; L(Test): 0.2360921949148178\n",
      "Epoch 8523/10000: L(Train): 0.2693338394165039; L(Test): 0.23688064515590668\n",
      "Epoch 8524/10000: L(Train): 0.25581416487693787; L(Test): 0.23612868785858154\n",
      "Epoch 8525/10000: L(Train): 0.26637494564056396; L(Test): 0.2350676953792572\n",
      "Epoch 8526/10000: L(Train): 0.251372754573822; L(Test): 0.23690329492092133\n",
      "Epoch 8527/10000: L(Train): 0.2641391456127167; L(Test): 0.23763686418533325\n",
      "Epoch 8528/10000: L(Train): 0.2597044110298157; L(Test): 0.23716633021831512\n",
      "Epoch 8529/10000: L(Train): 0.2707297205924988; L(Test): 0.23519526422023773\n",
      "Epoch 8530/10000: L(Train): 0.2764883041381836; L(Test): 0.2384338676929474\n",
      "Epoch 8531/10000: L(Train): 0.2581021189689636; L(Test): 0.23981213569641113\n",
      "Epoch 8532/10000: L(Train): 0.2565624415874481; L(Test): 0.23743273317813873\n",
      "Epoch 8533/10000: L(Train): 0.26489588618278503; L(Test): 0.23732249438762665\n",
      "Epoch 8534/10000: L(Train): 0.2684418261051178; L(Test): 0.23698028922080994\n",
      "Epoch 8535/10000: L(Train): 0.2769591212272644; L(Test): 0.23923197388648987\n",
      "Epoch 8536/10000: L(Train): 0.24837370216846466; L(Test): 0.2360987812280655\n",
      "Epoch 8537/10000: L(Train): 0.2537893056869507; L(Test): 0.23800337314605713\n",
      "Epoch 8538/10000: L(Train): 0.27053940296173096; L(Test): 0.2364310622215271\n",
      "Epoch 8539/10000: L(Train): 0.2552204430103302; L(Test): 0.2367197424173355\n",
      "Epoch 8540/10000: L(Train): 0.26022768020629883; L(Test): 0.237493634223938\n",
      "Epoch 8541/10000: L(Train): 0.2624417245388031; L(Test): 0.23671779036521912\n",
      "Epoch 8542/10000: L(Train): 0.2675970494747162; L(Test): 0.23713521659374237\n",
      "Epoch 8543/10000: L(Train): 0.25465306639671326; L(Test): 0.23685447871685028\n",
      "Epoch 8544/10000: L(Train): 0.25752803683280945; L(Test): 0.23698565363883972\n",
      "Epoch 8545/10000: L(Train): 0.2525274455547333; L(Test): 0.23697222769260406\n",
      "Epoch 8546/10000: L(Train): 0.2631339430809021; L(Test): 0.2373412400484085\n",
      "Epoch 8547/10000: L(Train): 0.26676416397094727; L(Test): 0.23566162586212158\n",
      "Epoch 8548/10000: L(Train): 0.25889554619789124; L(Test): 0.23600296676158905\n",
      "Epoch 8549/10000: L(Train): 0.2549501061439514; L(Test): 0.23771753907203674\n",
      "Epoch 8550/10000: L(Train): 0.2664409577846527; L(Test): 0.23663385212421417\n",
      "Epoch 8551/10000: L(Train): 0.24250218272209167; L(Test): 0.23601502180099487\n",
      "Epoch 8552/10000: L(Train): 0.2550656795501709; L(Test): 0.2357294112443924\n",
      "Epoch 8553/10000: L(Train): 0.2658502459526062; L(Test): 0.2354431301355362\n",
      "Epoch 8554/10000: L(Train): 0.25934550166130066; L(Test): 0.23520047962665558\n",
      "Epoch 8555/10000: L(Train): 0.24977964162826538; L(Test): 0.23490415513515472\n",
      "Epoch 8556/10000: L(Train): 0.26260653138160706; L(Test): 0.23414987325668335\n",
      "Epoch 8557/10000: L(Train): 0.2554355263710022; L(Test): 0.2340206801891327\n",
      "Epoch 8558/10000: L(Train): 0.26923978328704834; L(Test): 0.2356443852186203\n",
      "Epoch 8559/10000: L(Train): 0.24911285936832428; L(Test): 0.23605431616306305\n",
      "Epoch 8560/10000: L(Train): 0.23851507902145386; L(Test): 0.235301673412323\n",
      "Epoch 8561/10000: L(Train): 0.26125943660736084; L(Test): 0.23656392097473145\n",
      "Epoch 8562/10000: L(Train): 0.2579343020915985; L(Test): 0.23725832998752594\n",
      "Epoch 8563/10000: L(Train): 0.25577595829963684; L(Test): 0.23652498424053192\n",
      "Epoch 8564/10000: L(Train): 0.2611798346042633; L(Test): 0.23564666509628296\n",
      "Epoch 8565/10000: L(Train): 0.25276249647140503; L(Test): 0.23536647856235504\n",
      "Epoch 8566/10000: L(Train): 0.2514304518699646; L(Test): 0.23538564145565033\n",
      "Epoch 8567/10000: L(Train): 0.2506829798221588; L(Test): 0.23521378636360168\n",
      "Epoch 8568/10000: L(Train): 0.2623285949230194; L(Test): 0.23504716157913208\n",
      "Epoch 8569/10000: L(Train): 0.2541448175907135; L(Test): 0.23549577593803406\n",
      "Epoch 8570/10000: L(Train): 0.2579054832458496; L(Test): 0.2353840172290802\n",
      "Epoch 8571/10000: L(Train): 0.2518821358680725; L(Test): 0.2361786961555481\n",
      "Epoch 8572/10000: L(Train): 0.2573891282081604; L(Test): 0.23777970671653748\n",
      "Epoch 8573/10000: L(Train): 0.25823256373405457; L(Test): 0.23604924976825714\n",
      "Epoch 8574/10000: L(Train): 0.2611972391605377; L(Test): 0.23563674092292786\n",
      "Epoch 8575/10000: L(Train): 0.2556975185871124; L(Test): 0.2370038479566574\n",
      "Epoch 8576/10000: L(Train): 0.2735828459262848; L(Test): 0.23586486279964447\n",
      "Epoch 8577/10000: L(Train): 0.2699284851551056; L(Test): 0.23796267807483673\n",
      "Epoch 8578/10000: L(Train): 0.2548520565032959; L(Test): 0.23827970027923584\n",
      "Epoch 8579/10000: L(Train): 0.2736968398094177; L(Test): 0.2364727109670639\n",
      "Epoch 8580/10000: L(Train): 0.2414095103740692; L(Test): 0.23583795130252838\n",
      "Epoch 8581/10000: L(Train): 0.24380365014076233; L(Test): 0.23666805028915405\n",
      "Epoch 8582/10000: L(Train): 0.2628023624420166; L(Test): 0.23662219941616058\n",
      "Epoch 8583/10000: L(Train): 0.2644039988517761; L(Test): 0.23558036983013153\n",
      "Epoch 8584/10000: L(Train): 0.25201258063316345; L(Test): 0.2362327128648758\n",
      "Epoch 8585/10000: L(Train): 0.25001654028892517; L(Test): 0.235988050699234\n",
      "Epoch 8586/10000: L(Train): 0.24266354739665985; L(Test): 0.23545345664024353\n",
      "Epoch 8587/10000: L(Train): 0.25352948904037476; L(Test): 0.23615680634975433\n",
      "Epoch 8588/10000: L(Train): 0.2607378661632538; L(Test): 0.23579514026641846\n",
      "Epoch 8589/10000: L(Train): 0.261970579624176; L(Test): 0.23661395907402039\n",
      "Epoch 8590/10000: L(Train): 0.2504537105560303; L(Test): 0.2363167256116867\n",
      "Epoch 8591/10000: L(Train): 0.25806504487991333; L(Test): 0.23768629133701324\n",
      "Epoch 8592/10000: L(Train): 0.24784882366657257; L(Test): 0.23694226145744324\n",
      "Epoch 8593/10000: L(Train): 0.2560984790325165; L(Test): 0.23562870919704437\n",
      "Epoch 8594/10000: L(Train): 0.26913395524024963; L(Test): 0.2349122166633606\n",
      "Epoch 8595/10000: L(Train): 0.260426789522171; L(Test): 0.23559346795082092\n",
      "Epoch 8596/10000: L(Train): 0.2526959776878357; L(Test): 0.2364688366651535\n",
      "Epoch 8597/10000: L(Train): 0.2491239458322525; L(Test): 0.23503972589969635\n",
      "Epoch 8598/10000: L(Train): 0.25306436419487; L(Test): 0.23518450558185577\n",
      "Epoch 8599/10000: L(Train): 0.24897132813930511; L(Test): 0.234976664185524\n",
      "Epoch 8600/10000: L(Train): 0.25121667981147766; L(Test): 0.23545753955841064\n",
      "Epoch 8601/10000: L(Train): 0.2525924742221832; L(Test): 0.23617319762706757\n",
      "Epoch 8602/10000: L(Train): 0.2744106650352478; L(Test): 0.23529388010501862\n",
      "Epoch 8603/10000: L(Train): 0.25981783866882324; L(Test): 0.2348712682723999\n",
      "Epoch 8604/10000: L(Train): 0.2757088541984558; L(Test): 0.2348281592130661\n",
      "Epoch 8605/10000: L(Train): 0.2578568458557129; L(Test): 0.23443740606307983\n",
      "Epoch 8606/10000: L(Train): 0.2525661885738373; L(Test): 0.23462313413619995\n",
      "Epoch 8607/10000: L(Train): 0.25747156143188477; L(Test): 0.2337353527545929\n",
      "Epoch 8608/10000: L(Train): 0.2472621649503708; L(Test): 0.23426906764507294\n",
      "Epoch 8609/10000: L(Train): 0.26854732632637024; L(Test): 0.2341325879096985\n",
      "Epoch 8610/10000: L(Train): 0.24196994304656982; L(Test): 0.23395936191082\n",
      "Epoch 8611/10000: L(Train): 0.2586040496826172; L(Test): 0.2340533435344696\n",
      "Epoch 8612/10000: L(Train): 0.27307015657424927; L(Test): 0.23410186171531677\n",
      "Epoch 8613/10000: L(Train): 0.2487954944372177; L(Test): 0.23581743240356445\n",
      "Epoch 8614/10000: L(Train): 0.24464038014411926; L(Test): 0.23548059165477753\n",
      "Epoch 8615/10000: L(Train): 0.241522878408432; L(Test): 0.2371390163898468\n",
      "Epoch 8616/10000: L(Train): 0.2514927387237549; L(Test): 0.2376917153596878\n",
      "Epoch 8617/10000: L(Train): 0.25027358531951904; L(Test): 0.23521366715431213\n",
      "Epoch 8618/10000: L(Train): 0.261210560798645; L(Test): 0.23547230660915375\n",
      "Epoch 8619/10000: L(Train): 0.25710874795913696; L(Test): 0.23722881078720093\n",
      "Epoch 8620/10000: L(Train): 0.2465524673461914; L(Test): 0.23539724946022034\n",
      "Epoch 8621/10000: L(Train): 0.267282634973526; L(Test): 0.23626329004764557\n",
      "Epoch 8622/10000: L(Train): 0.2479298859834671; L(Test): 0.2377212792634964\n",
      "Epoch 8623/10000: L(Train): 0.25462090969085693; L(Test): 0.2373839169740677\n",
      "Epoch 8624/10000: L(Train): 0.2576177716255188; L(Test): 0.2359781414270401\n",
      "Epoch 8625/10000: L(Train): 0.2581596374511719; L(Test): 0.23615211248397827\n",
      "Epoch 8626/10000: L(Train): 0.26256102323532104; L(Test): 0.23531578481197357\n",
      "Epoch 8627/10000: L(Train): 0.2603244185447693; L(Test): 0.23616917431354523\n",
      "Epoch 8628/10000: L(Train): 0.2714061141014099; L(Test): 0.2348647564649582\n",
      "Epoch 8629/10000: L(Train): 0.26032617688179016; L(Test): 0.2361818552017212\n",
      "Epoch 8630/10000: L(Train): 0.2568962275981903; L(Test): 0.2373218834400177\n",
      "Epoch 8631/10000: L(Train): 0.2719930410385132; L(Test): 0.23557306826114655\n",
      "Epoch 8632/10000: L(Train): 0.2613368630409241; L(Test): 0.23517945408821106\n",
      "Epoch 8633/10000: L(Train): 0.26808100938796997; L(Test): 0.23492053151130676\n",
      "Epoch 8634/10000: L(Train): 0.2581441402435303; L(Test): 0.23498816788196564\n",
      "Epoch 8635/10000: L(Train): 0.27030351758003235; L(Test): 0.23486416041851044\n",
      "Epoch 8636/10000: L(Train): 0.2623651325702667; L(Test): 0.2351725846529007\n",
      "Epoch 8637/10000: L(Train): 0.26808300614356995; L(Test): 0.23625695705413818\n",
      "Epoch 8638/10000: L(Train): 0.2465370148420334; L(Test): 0.23403149843215942\n",
      "Epoch 8639/10000: L(Train): 0.26021286845207214; L(Test): 0.2345951646566391\n",
      "Epoch 8640/10000: L(Train): 0.2619451582431793; L(Test): 0.23605389893054962\n",
      "Epoch 8641/10000: L(Train): 0.2598429024219513; L(Test): 0.2346252202987671\n",
      "Epoch 8642/10000: L(Train): 0.2503579556941986; L(Test): 0.23598414659500122\n",
      "Epoch 8643/10000: L(Train): 0.2689271867275238; L(Test): 0.23813486099243164\n",
      "Epoch 8644/10000: L(Train): 0.25451311469078064; L(Test): 0.23536022007465363\n",
      "Epoch 8645/10000: L(Train): 0.2723037004470825; L(Test): 0.23528459668159485\n",
      "Epoch 8646/10000: L(Train): 0.260540634393692; L(Test): 0.23604664206504822\n",
      "Epoch 8647/10000: L(Train): 0.2577730417251587; L(Test): 0.2354068160057068\n",
      "Epoch 8648/10000: L(Train): 0.24813862144947052; L(Test): 0.2346991002559662\n",
      "Epoch 8649/10000: L(Train): 0.25472888350486755; L(Test): 0.23627382516860962\n",
      "Epoch 8650/10000: L(Train): 0.27322036027908325; L(Test): 0.2351538985967636\n",
      "Epoch 8651/10000: L(Train): 0.255047470331192; L(Test): 0.23523621261119843\n",
      "Epoch 8652/10000: L(Train): 0.2592330276966095; L(Test): 0.23436541855335236\n",
      "Epoch 8653/10000: L(Train): 0.2392216920852661; L(Test): 0.23523317277431488\n",
      "Epoch 8654/10000: L(Train): 0.2503903806209564; L(Test): 0.2347750961780548\n",
      "Epoch 8655/10000: L(Train): 0.25351694226264954; L(Test): 0.23716619610786438\n",
      "Epoch 8656/10000: L(Train): 0.25539955496788025; L(Test): 0.23704367876052856\n",
      "Epoch 8657/10000: L(Train): 0.270052969455719; L(Test): 0.23490752279758453\n",
      "Epoch 8658/10000: L(Train): 0.24966008961200714; L(Test): 0.23703061044216156\n",
      "Epoch 8659/10000: L(Train): 0.2575143277645111; L(Test): 0.23800937831401825\n",
      "Epoch 8660/10000: L(Train): 0.25968265533447266; L(Test): 0.2365484982728958\n",
      "Epoch 8661/10000: L(Train): 0.24397923052310944; L(Test): 0.23660562932491302\n",
      "Epoch 8662/10000: L(Train): 0.2506440281867981; L(Test): 0.23690471053123474\n",
      "Epoch 8663/10000: L(Train): 0.2576915919780731; L(Test): 0.23682904243469238\n",
      "Epoch 8664/10000: L(Train): 0.26648133993148804; L(Test): 0.23808778822422028\n",
      "Epoch 8665/10000: L(Train): 0.2610924541950226; L(Test): 0.23747719824314117\n",
      "Epoch 8666/10000: L(Train): 0.2572947144508362; L(Test): 0.2357414811849594\n",
      "Epoch 8667/10000: L(Train): 0.25413045287132263; L(Test): 0.23604409396648407\n",
      "Epoch 8668/10000: L(Train): 0.25927749276161194; L(Test): 0.2362060397863388\n",
      "Epoch 8669/10000: L(Train): 0.2614530920982361; L(Test): 0.23627160489559174\n",
      "Epoch 8670/10000: L(Train): 0.26271262764930725; L(Test): 0.23790492117404938\n",
      "Epoch 8671/10000: L(Train): 0.24855606257915497; L(Test): 0.23711922764778137\n",
      "Epoch 8672/10000: L(Train): 0.2378840297460556; L(Test): 0.23791712522506714\n",
      "Epoch 8673/10000: L(Train): 0.2754448354244232; L(Test): 0.23687796294689178\n",
      "Epoch 8674/10000: L(Train): 0.25235825777053833; L(Test): 0.23676328361034393\n",
      "Epoch 8675/10000: L(Train): 0.26145854592323303; L(Test): 0.23610343039035797\n",
      "Epoch 8676/10000: L(Train): 0.2487931251525879; L(Test): 0.2384769171476364\n",
      "Epoch 8677/10000: L(Train): 0.24894022941589355; L(Test): 0.23683810234069824\n",
      "Epoch 8678/10000: L(Train): 0.2668958306312561; L(Test): 0.23733431100845337\n",
      "Epoch 8679/10000: L(Train): 0.25323620438575745; L(Test): 0.23686519265174866\n",
      "Epoch 8680/10000: L(Train): 0.2519603371620178; L(Test): 0.23631489276885986\n",
      "Epoch 8681/10000: L(Train): 0.259991317987442; L(Test): 0.23669642210006714\n",
      "Epoch 8682/10000: L(Train): 0.2546824514865875; L(Test): 0.23512998223304749\n",
      "Epoch 8683/10000: L(Train): 0.25201788544654846; L(Test): 0.23488052189350128\n",
      "Epoch 8684/10000: L(Train): 0.2526480555534363; L(Test): 0.2349216192960739\n",
      "Epoch 8685/10000: L(Train): 0.25237739086151123; L(Test): 0.234956756234169\n",
      "Epoch 8686/10000: L(Train): 0.25978344678878784; L(Test): 0.23537898063659668\n",
      "Epoch 8687/10000: L(Train): 0.25534313917160034; L(Test): 0.2348574697971344\n",
      "Epoch 8688/10000: L(Train): 0.25758662819862366; L(Test): 0.2346135377883911\n",
      "Epoch 8689/10000: L(Train): 0.2588556110858917; L(Test): 0.23515485227108002\n",
      "Epoch 8690/10000: L(Train): 0.2556004822254181; L(Test): 0.23568487167358398\n",
      "Epoch 8691/10000: L(Train): 0.2571532130241394; L(Test): 0.23538997769355774\n",
      "Epoch 8692/10000: L(Train): 0.25565996766090393; L(Test): 0.23580896854400635\n",
      "Epoch 8693/10000: L(Train): 0.23865003883838654; L(Test): 0.2365085333585739\n",
      "Epoch 8694/10000: L(Train): 0.2566877007484436; L(Test): 0.2345835119485855\n",
      "Epoch 8695/10000: L(Train): 0.26578137278556824; L(Test): 0.23433083295822144\n",
      "Epoch 8696/10000: L(Train): 0.2600827217102051; L(Test): 0.2352440059185028\n",
      "Epoch 8697/10000: L(Train): 0.24178995192050934; L(Test): 0.23455898463726044\n",
      "Epoch 8698/10000: L(Train): 0.25463706254959106; L(Test): 0.23489384353160858\n",
      "Epoch 8699/10000: L(Train): 0.25892841815948486; L(Test): 0.23482604324817657\n",
      "Epoch 8700/10000: L(Train): 0.23911884427070618; L(Test): 0.2364262491464615\n",
      "Epoch 8701/10000: L(Train): 0.26341670751571655; L(Test): 0.23804733157157898\n",
      "Epoch 8702/10000: L(Train): 0.2606734037399292; L(Test): 0.23557718098163605\n",
      "Epoch 8703/10000: L(Train): 0.25562340021133423; L(Test): 0.23551368713378906\n",
      "Epoch 8704/10000: L(Train): 0.2621157467365265; L(Test): 0.23537439107894897\n",
      "Epoch 8705/10000: L(Train): 0.25584176182746887; L(Test): 0.23550866544246674\n",
      "Epoch 8706/10000: L(Train): 0.254056841135025; L(Test): 0.23502592742443085\n",
      "Epoch 8707/10000: L(Train): 0.253011018037796; L(Test): 0.23515257239341736\n",
      "Epoch 8708/10000: L(Train): 0.257318913936615; L(Test): 0.2352573424577713\n",
      "Epoch 8709/10000: L(Train): 0.2574827969074249; L(Test): 0.23483265936374664\n",
      "Epoch 8710/10000: L(Train): 0.24887806177139282; L(Test): 0.23584334552288055\n",
      "Epoch 8711/10000: L(Train): 0.2561561167240143; L(Test): 0.2375786453485489\n",
      "Epoch 8712/10000: L(Train): 0.24740703403949738; L(Test): 0.24453094601631165\n",
      "Epoch 8713/10000: L(Train): 0.26931750774383545; L(Test): 0.24369744956493378\n",
      "Epoch 8714/10000: L(Train): 0.26671740412712097; L(Test): 0.2423781454563141\n",
      "Epoch 8715/10000: L(Train): 0.26974815130233765; L(Test): 0.24262383580207825\n",
      "Epoch 8716/10000: L(Train): 0.2775990962982178; L(Test): 0.2432398945093155\n",
      "Epoch 8717/10000: L(Train): 0.2688373625278473; L(Test): 0.2403421252965927\n",
      "Epoch 8718/10000: L(Train): 0.2753729522228241; L(Test): 0.24066521227359772\n",
      "Epoch 8719/10000: L(Train): 0.25252488255500793; L(Test): 0.24413003027439117\n",
      "Epoch 8720/10000: L(Train): 0.2748972773551941; L(Test): 0.24327974021434784\n",
      "Epoch 8721/10000: L(Train): 0.2577317953109741; L(Test): 0.2416262924671173\n",
      "Epoch 8722/10000: L(Train): 0.253521203994751; L(Test): 0.24231970310211182\n",
      "Epoch 8723/10000: L(Train): 0.2766115367412567; L(Test): 0.24240809679031372\n",
      "Epoch 8724/10000: L(Train): 0.260331392288208; L(Test): 0.23964394629001617\n",
      "Epoch 8725/10000: L(Train): 0.25644829869270325; L(Test): 0.24005599319934845\n",
      "Epoch 8726/10000: L(Train): 0.2597121298313141; L(Test): 0.2406354397535324\n",
      "Epoch 8727/10000: L(Train): 0.2737499475479126; L(Test): 0.2397691160440445\n",
      "Epoch 8728/10000: L(Train): 0.2748371958732605; L(Test): 0.23982614278793335\n",
      "Epoch 8729/10000: L(Train): 0.28041771054267883; L(Test): 0.24131622910499573\n",
      "Epoch 8730/10000: L(Train): 0.2639073133468628; L(Test): 0.23942576348781586\n",
      "Epoch 8731/10000: L(Train): 0.2670048177242279; L(Test): 0.23931056261062622\n",
      "Epoch 8732/10000: L(Train): 0.26476627588272095; L(Test): 0.2393348067998886\n",
      "Epoch 8733/10000: L(Train): 0.2624545693397522; L(Test): 0.23936748504638672\n",
      "Epoch 8734/10000: L(Train): 0.26533982157707214; L(Test): 0.23930299282073975\n",
      "Epoch 8735/10000: L(Train): 0.2682946026325226; L(Test): 0.23833782970905304\n",
      "Epoch 8736/10000: L(Train): 0.25799232721328735; L(Test): 0.23764164745807648\n",
      "Epoch 8737/10000: L(Train): 0.26464274525642395; L(Test): 0.23840458691120148\n",
      "Epoch 8738/10000: L(Train): 0.2640553414821625; L(Test): 0.23798434436321259\n",
      "Epoch 8739/10000: L(Train): 0.26459160447120667; L(Test): 0.23755928874015808\n",
      "Epoch 8740/10000: L(Train): 0.2640908360481262; L(Test): 0.23754499852657318\n",
      "Epoch 8741/10000: L(Train): 0.2686264216899872; L(Test): 0.23748892545700073\n",
      "Epoch 8742/10000: L(Train): 0.2550567388534546; L(Test): 0.23735252022743225\n",
      "Epoch 8743/10000: L(Train): 0.26662400364875793; L(Test): 0.2373240888118744\n",
      "Epoch 8744/10000: L(Train): 0.2582118511199951; L(Test): 0.236592099070549\n",
      "Epoch 8745/10000: L(Train): 0.25110137462615967; L(Test): 0.23664072155952454\n",
      "Epoch 8746/10000: L(Train): 0.25543147325515747; L(Test): 0.23707617819309235\n",
      "Epoch 8747/10000: L(Train): 0.2576393783092499; L(Test): 0.2361481934785843\n",
      "Epoch 8748/10000: L(Train): 0.2587219476699829; L(Test): 0.2366371899843216\n",
      "Epoch 8749/10000: L(Train): 0.2669038772583008; L(Test): 0.23736868798732758\n",
      "Epoch 8750/10000: L(Train): 0.250444620847702; L(Test): 0.23698760569095612\n",
      "Epoch 8751/10000: L(Train): 0.2552565336227417; L(Test): 0.2364116609096527\n",
      "Epoch 8752/10000: L(Train): 0.2497604638338089; L(Test): 0.235563725233078\n",
      "Epoch 8753/10000: L(Train): 0.2551131248474121; L(Test): 0.23586532473564148\n",
      "Epoch 8754/10000: L(Train): 0.2504730224609375; L(Test): 0.236315056681633\n",
      "Epoch 8755/10000: L(Train): 0.24954141676425934; L(Test): 0.23698972165584564\n",
      "Epoch 8756/10000: L(Train): 0.25100427865982056; L(Test): 0.23532721400260925\n",
      "Epoch 8757/10000: L(Train): 0.26923149824142456; L(Test): 0.2351851612329483\n",
      "Epoch 8758/10000: L(Train): 0.23859378695487976; L(Test): 0.23510707914829254\n",
      "Epoch 8759/10000: L(Train): 0.24013853073120117; L(Test): 0.23656851053237915\n",
      "Epoch 8760/10000: L(Train): 0.2669392228126526; L(Test): 0.23532888293266296\n",
      "Epoch 8761/10000: L(Train): 0.26911771297454834; L(Test): 0.23577633500099182\n",
      "Epoch 8762/10000: L(Train): 0.26419851183891296; L(Test): 0.23603788018226624\n",
      "Epoch 8763/10000: L(Train): 0.2631848156452179; L(Test): 0.23717479407787323\n",
      "Epoch 8764/10000: L(Train): 0.2776287794113159; L(Test): 0.23546846210956573\n",
      "Epoch 8765/10000: L(Train): 0.2504376769065857; L(Test): 0.2361394315958023\n",
      "Epoch 8766/10000: L(Train): 0.25206872820854187; L(Test): 0.23482158780097961\n",
      "Epoch 8767/10000: L(Train): 0.2580457329750061; L(Test): 0.2346302568912506\n",
      "Epoch 8768/10000: L(Train): 0.24298372864723206; L(Test): 0.23489321768283844\n",
      "Epoch 8769/10000: L(Train): 0.2612917423248291; L(Test): 0.2341250330209732\n",
      "Epoch 8770/10000: L(Train): 0.24824698269367218; L(Test): 0.23599714040756226\n",
      "Epoch 8771/10000: L(Train): 0.25250548124313354; L(Test): 0.23471756279468536\n",
      "Epoch 8772/10000: L(Train): 0.258830726146698; L(Test): 0.23469921946525574\n",
      "Epoch 8773/10000: L(Train): 0.2538723051548004; L(Test): 0.23515401780605316\n",
      "Epoch 8774/10000: L(Train): 0.2667843699455261; L(Test): 0.23515553772449493\n",
      "Epoch 8775/10000: L(Train): 0.25396910309791565; L(Test): 0.2351556420326233\n",
      "Epoch 8776/10000: L(Train): 0.25204604864120483; L(Test): 0.2354598194360733\n",
      "Epoch 8777/10000: L(Train): 0.24874146282672882; L(Test): 0.23653218150138855\n",
      "Epoch 8778/10000: L(Train): 0.25355198979377747; L(Test): 0.23510122299194336\n",
      "Epoch 8779/10000: L(Train): 0.24632056057453156; L(Test): 0.23567119240760803\n",
      "Epoch 8780/10000: L(Train): 0.25586408376693726; L(Test): 0.23575150966644287\n",
      "Epoch 8781/10000: L(Train): 0.25442594289779663; L(Test): 0.23741768300533295\n",
      "Epoch 8782/10000: L(Train): 0.2557492256164551; L(Test): 0.2359974980354309\n",
      "Epoch 8783/10000: L(Train): 0.25897592306137085; L(Test): 0.23702959716320038\n",
      "Epoch 8784/10000: L(Train): 0.2664114236831665; L(Test): 0.23644353449344635\n",
      "Epoch 8785/10000: L(Train): 0.2567507028579712; L(Test): 0.2406284660100937\n",
      "Epoch 8786/10000: L(Train): 0.2589316666126251; L(Test): 0.23781241476535797\n",
      "Epoch 8787/10000: L(Train): 0.2515115439891815; L(Test): 0.23842337727546692\n",
      "Epoch 8788/10000: L(Train): 0.2527586817741394; L(Test): 0.23582060635089874\n",
      "Epoch 8789/10000: L(Train): 0.26804760098457336; L(Test): 0.2367040514945984\n",
      "Epoch 8790/10000: L(Train): 0.2458231896162033; L(Test): 0.23729969561100006\n",
      "Epoch 8791/10000: L(Train): 0.26223453879356384; L(Test): 0.23565581440925598\n",
      "Epoch 8792/10000: L(Train): 0.25799739360809326; L(Test): 0.23951303958892822\n",
      "Epoch 8793/10000: L(Train): 0.2571013271808624; L(Test): 0.23778961598873138\n",
      "Epoch 8794/10000: L(Train): 0.2677876651287079; L(Test): 0.23901033401489258\n",
      "Epoch 8795/10000: L(Train): 0.2500503361225128; L(Test): 0.24001309275627136\n",
      "Epoch 8796/10000: L(Train): 0.2592690885066986; L(Test): 0.24025963246822357\n",
      "Epoch 8797/10000: L(Train): 0.26967665553092957; L(Test): 0.23692113161087036\n",
      "Epoch 8798/10000: L(Train): 0.25157859921455383; L(Test): 0.23832976818084717\n",
      "Epoch 8799/10000: L(Train): 0.2668478190898895; L(Test): 0.23855644464492798\n",
      "Epoch 8800/10000: L(Train): 0.2642853856086731; L(Test): 0.2354169487953186\n",
      "Epoch 8801/10000: L(Train): 0.24154165387153625; L(Test): 0.23701368272304535\n",
      "Epoch 8802/10000: L(Train): 0.2548837661743164; L(Test): 0.23770344257354736\n",
      "Epoch 8803/10000: L(Train): 0.25049659609794617; L(Test): 0.23758931457996368\n",
      "Epoch 8804/10000: L(Train): 0.2808700501918793; L(Test): 0.23764008283615112\n",
      "Epoch 8805/10000: L(Train): 0.2538319528102875; L(Test): 0.23669812083244324\n",
      "Epoch 8806/10000: L(Train): 0.2554611563682556; L(Test): 0.23517069220542908\n",
      "Epoch 8807/10000: L(Train): 0.262087881565094; L(Test): 0.2392425537109375\n",
      "Epoch 8808/10000: L(Train): 0.26854652166366577; L(Test): 0.23914626240730286\n",
      "Epoch 8809/10000: L(Train): 0.26083579659461975; L(Test): 0.23831874132156372\n",
      "Epoch 8810/10000: L(Train): 0.25230127573013306; L(Test): 0.239643394947052\n",
      "Epoch 8811/10000: L(Train): 0.2571018636226654; L(Test): 0.23866237699985504\n",
      "Epoch 8812/10000: L(Train): 0.2607399821281433; L(Test): 0.23804719746112823\n",
      "Epoch 8813/10000: L(Train): 0.2579553723335266; L(Test): 0.23857197165489197\n",
      "Epoch 8814/10000: L(Train): 0.2617329955101013; L(Test): 0.2397373467683792\n",
      "Epoch 8815/10000: L(Train): 0.2781294584274292; L(Test): 0.23769305646419525\n",
      "Epoch 8816/10000: L(Train): 0.2643025517463684; L(Test): 0.23713625967502594\n",
      "Epoch 8817/10000: L(Train): 0.2605974078178406; L(Test): 0.23739346861839294\n",
      "Epoch 8818/10000: L(Train): 0.2580208480358124; L(Test): 0.23721438646316528\n",
      "Epoch 8819/10000: L(Train): 0.25787508487701416; L(Test): 0.2360442578792572\n",
      "Epoch 8820/10000: L(Train): 0.25832733511924744; L(Test): 0.23697291314601898\n",
      "Epoch 8821/10000: L(Train): 0.2538379728794098; L(Test): 0.2391936182975769\n",
      "Epoch 8822/10000: L(Train): 0.2624519467353821; L(Test): 0.23657281696796417\n",
      "Epoch 8823/10000: L(Train): 0.26677632331848145; L(Test): 0.23893645405769348\n",
      "Epoch 8824/10000: L(Train): 0.254944771528244; L(Test): 0.2389441579580307\n",
      "Epoch 8825/10000: L(Train): 0.26037272810935974; L(Test): 0.23749658465385437\n",
      "Epoch 8826/10000: L(Train): 0.25666943192481995; L(Test): 0.23764580488204956\n",
      "Epoch 8827/10000: L(Train): 0.2694285809993744; L(Test): 0.23759602010250092\n",
      "Epoch 8828/10000: L(Train): 0.25482937693595886; L(Test): 0.2362767457962036\n",
      "Epoch 8829/10000: L(Train): 0.2555166482925415; L(Test): 0.2369929850101471\n",
      "Epoch 8830/10000: L(Train): 0.2775014638900757; L(Test): 0.23660194873809814\n",
      "Epoch 8831/10000: L(Train): 0.26791390776634216; L(Test): 0.2365853637456894\n",
      "Epoch 8832/10000: L(Train): 0.25618281960487366; L(Test): 0.23637701570987701\n",
      "Epoch 8833/10000: L(Train): 0.26132646203041077; L(Test): 0.23592285811901093\n",
      "Epoch 8834/10000: L(Train): 0.2706318497657776; L(Test): 0.23571203649044037\n",
      "Epoch 8835/10000: L(Train): 0.2571715712547302; L(Test): 0.23578183352947235\n",
      "Epoch 8836/10000: L(Train): 0.2490319311618805; L(Test): 0.23606428503990173\n",
      "Epoch 8837/10000: L(Train): 0.2441955804824829; L(Test): 0.23508097231388092\n",
      "Epoch 8838/10000: L(Train): 0.23915547132492065; L(Test): 0.23555445671081543\n",
      "Epoch 8839/10000: L(Train): 0.2540343701839447; L(Test): 0.23551857471466064\n",
      "Epoch 8840/10000: L(Train): 0.25574254989624023; L(Test): 0.23583027720451355\n",
      "Epoch 8841/10000: L(Train): 0.254315048456192; L(Test): 0.23489615321159363\n",
      "Epoch 8842/10000: L(Train): 0.26544585824012756; L(Test): 0.2348732203245163\n",
      "Epoch 8843/10000: L(Train): 0.26855194568634033; L(Test): 0.23449823260307312\n",
      "Epoch 8844/10000: L(Train): 0.2625826299190521; L(Test): 0.2351403832435608\n",
      "Epoch 8845/10000: L(Train): 0.25568944215774536; L(Test): 0.23395736515522003\n",
      "Epoch 8846/10000: L(Train): 0.24715177714824677; L(Test): 0.235033318400383\n",
      "Epoch 8847/10000: L(Train): 0.27699992060661316; L(Test): 0.2347588837146759\n",
      "Epoch 8848/10000: L(Train): 0.25286394357681274; L(Test): 0.23431961238384247\n",
      "Epoch 8849/10000: L(Train): 0.2543807327747345; L(Test): 0.23482367396354675\n",
      "Epoch 8850/10000: L(Train): 0.25856783986091614; L(Test): 0.2352796047925949\n",
      "Epoch 8851/10000: L(Train): 0.2616330087184906; L(Test): 0.23447301983833313\n",
      "Epoch 8852/10000: L(Train): 0.2608969211578369; L(Test): 0.23517167568206787\n",
      "Epoch 8853/10000: L(Train): 0.2703298330307007; L(Test): 0.23625300824642181\n",
      "Epoch 8854/10000: L(Train): 0.2652372121810913; L(Test): 0.2352985143661499\n",
      "Epoch 8855/10000: L(Train): 0.24310600757598877; L(Test): 0.23595044016838074\n",
      "Epoch 8856/10000: L(Train): 0.24939051270484924; L(Test): 0.23560795187950134\n",
      "Epoch 8857/10000: L(Train): 0.25088945031166077; L(Test): 0.23589405417442322\n",
      "Epoch 8858/10000: L(Train): 0.26281023025512695; L(Test): 0.2352132499217987\n",
      "Epoch 8859/10000: L(Train): 0.2556186318397522; L(Test): 0.23449960350990295\n",
      "Epoch 8860/10000: L(Train): 0.26185423135757446; L(Test): 0.23623813688755035\n",
      "Epoch 8861/10000: L(Train): 0.2499854564666748; L(Test): 0.23655012249946594\n",
      "Epoch 8862/10000: L(Train): 0.24755431711673737; L(Test): 0.23455853760242462\n",
      "Epoch 8863/10000: L(Train): 0.2579743564128876; L(Test): 0.2356189787387848\n",
      "Epoch 8864/10000: L(Train): 0.2551329433917999; L(Test): 0.23581421375274658\n",
      "Epoch 8865/10000: L(Train): 0.24581855535507202; L(Test): 0.2343921959400177\n",
      "Epoch 8866/10000: L(Train): 0.26693102717399597; L(Test): 0.23539969325065613\n",
      "Epoch 8867/10000: L(Train): 0.2524409592151642; L(Test): 0.23577994108200073\n",
      "Epoch 8868/10000: L(Train): 0.2675359845161438; L(Test): 0.23579919338226318\n",
      "Epoch 8869/10000: L(Train): 0.2646692395210266; L(Test): 0.25726115703582764\n",
      "Epoch 8870/10000: L(Train): 0.30042052268981934; L(Test): 0.2678004801273346\n",
      "Epoch 8871/10000: L(Train): 0.2885637581348419; L(Test): 0.2612007260322571\n",
      "Epoch 8872/10000: L(Train): 0.28218933939933777; L(Test): 0.25939127802848816\n",
      "Epoch 8873/10000: L(Train): 0.2618964612483978; L(Test): 0.26601457595825195\n",
      "Epoch 8874/10000: L(Train): 0.2985242009162903; L(Test): 0.26505282521247864\n",
      "Epoch 8875/10000: L(Train): 0.28532594442367554; L(Test): 0.26393553614616394\n",
      "Epoch 8876/10000: L(Train): 0.2843567132949829; L(Test): 0.2637125253677368\n",
      "Epoch 8877/10000: L(Train): 0.270511269569397; L(Test): 0.2660786211490631\n",
      "Epoch 8878/10000: L(Train): 0.29873883724212646; L(Test): 0.2678644359111786\n",
      "Epoch 8879/10000: L(Train): 0.2673279047012329; L(Test): 0.26555392146110535\n",
      "Epoch 8880/10000: L(Train): 0.2718389332294464; L(Test): 0.2614521086215973\n",
      "Epoch 8881/10000: L(Train): 0.2823309302330017; L(Test): 0.2614225149154663\n",
      "Epoch 8882/10000: L(Train): 0.27535590529441833; L(Test): 0.2651938498020172\n",
      "Epoch 8883/10000: L(Train): 0.26782456040382385; L(Test): 0.262093722820282\n",
      "Epoch 8884/10000: L(Train): 0.2696942985057831; L(Test): 0.2596772313117981\n",
      "Epoch 8885/10000: L(Train): 0.27577486634254456; L(Test): 0.2627788484096527\n",
      "Epoch 8886/10000: L(Train): 0.27672675251960754; L(Test): 0.2611180245876312\n",
      "Epoch 8887/10000: L(Train): 0.2721325159072876; L(Test): 0.2574406564235687\n",
      "Epoch 8888/10000: L(Train): 0.26993218064308167; L(Test): 0.25761669874191284\n",
      "Epoch 8889/10000: L(Train): 0.2778618633747101; L(Test): 0.2564578652381897\n",
      "Epoch 8890/10000: L(Train): 0.2820957899093628; L(Test): 0.25432437658309937\n",
      "Epoch 8891/10000: L(Train): 0.2802254855632782; L(Test): 0.2550460994243622\n",
      "Epoch 8892/10000: L(Train): 0.27928102016448975; L(Test): 0.2542905807495117\n",
      "Epoch 8893/10000: L(Train): 0.2849411368370056; L(Test): 0.2524907886981964\n",
      "Epoch 8894/10000: L(Train): 0.2639757990837097; L(Test): 0.2526389956474304\n",
      "Epoch 8895/10000: L(Train): 0.2721635401248932; L(Test): 0.24992735683918\n",
      "Epoch 8896/10000: L(Train): 0.25920990109443665; L(Test): 0.24924230575561523\n",
      "Epoch 8897/10000: L(Train): 0.27314484119415283; L(Test): 0.2500459551811218\n",
      "Epoch 8898/10000: L(Train): 0.2613353729248047; L(Test): 0.24938926100730896\n",
      "Epoch 8899/10000: L(Train): 0.2698693871498108; L(Test): 0.2519867420196533\n",
      "Epoch 8900/10000: L(Train): 0.27459651231765747; L(Test): 0.24627915024757385\n",
      "Epoch 8901/10000: L(Train): 0.27212023735046387; L(Test): 0.24957244098186493\n",
      "Epoch 8902/10000: L(Train): 0.25838881731033325; L(Test): 0.24961723387241364\n",
      "Epoch 8903/10000: L(Train): 0.27510592341423035; L(Test): 0.2471105009317398\n",
      "Epoch 8904/10000: L(Train): 0.2598488926887512; L(Test): 0.24778872728347778\n",
      "Epoch 8905/10000: L(Train): 0.27637162804603577; L(Test): 0.2477167248725891\n",
      "Epoch 8906/10000: L(Train): 0.2606632113456726; L(Test): 0.24841323494911194\n",
      "Epoch 8907/10000: L(Train): 0.27447158098220825; L(Test): 0.246398463845253\n",
      "Epoch 8908/10000: L(Train): 0.2675810754299164; L(Test): 0.24712473154067993\n",
      "Epoch 8909/10000: L(Train): 0.2551431357860565; L(Test): 0.24675601720809937\n",
      "Epoch 8910/10000: L(Train): 0.26081523299217224; L(Test): 0.24557092785835266\n",
      "Epoch 8911/10000: L(Train): 0.25170430541038513; L(Test): 0.24581031501293182\n",
      "Epoch 8912/10000: L(Train): 0.2745066285133362; L(Test): 0.24391797184944153\n",
      "Epoch 8913/10000: L(Train): 0.25791317224502563; L(Test): 0.2456154078245163\n",
      "Epoch 8914/10000: L(Train): 0.2674352824687958; L(Test): 0.24572224915027618\n",
      "Epoch 8915/10000: L(Train): 0.27431154251098633; L(Test): 0.24408693611621857\n",
      "Epoch 8916/10000: L(Train): 0.2638428509235382; L(Test): 0.24323534965515137\n",
      "Epoch 8917/10000: L(Train): 0.25253674387931824; L(Test): 0.24471600353717804\n",
      "Epoch 8918/10000: L(Train): 0.26543453335762024; L(Test): 0.24387186765670776\n",
      "Epoch 8919/10000: L(Train): 0.26080089807510376; L(Test): 0.2430361956357956\n",
      "Epoch 8920/10000: L(Train): 0.27326884865760803; L(Test): 0.24453869462013245\n",
      "Epoch 8921/10000: L(Train): 0.25678935647010803; L(Test): 0.2464739829301834\n",
      "Epoch 8922/10000: L(Train): 0.27365782856941223; L(Test): 0.24461382627487183\n",
      "Epoch 8923/10000: L(Train): 0.26610898971557617; L(Test): 0.2435559332370758\n",
      "Epoch 8924/10000: L(Train): 0.26393866539001465; L(Test): 0.24439436197280884\n",
      "Epoch 8925/10000: L(Train): 0.2706264555454254; L(Test): 0.24397163093090057\n",
      "Epoch 8926/10000: L(Train): 0.26332566142082214; L(Test): 0.24482303857803345\n",
      "Epoch 8927/10000: L(Train): 0.2682424485683441; L(Test): 0.24613572657108307\n",
      "Epoch 8928/10000: L(Train): 0.2674407362937927; L(Test): 0.24370799958705902\n",
      "Epoch 8929/10000: L(Train): 0.2656695544719696; L(Test): 0.2497607320547104\n",
      "Epoch 8930/10000: L(Train): 0.2671428322792053; L(Test): 0.2500346601009369\n",
      "Epoch 8931/10000: L(Train): 0.24570390582084656; L(Test): 0.24704794585704803\n",
      "Epoch 8932/10000: L(Train): 0.272168904542923; L(Test): 0.24911272525787354\n",
      "Epoch 8933/10000: L(Train): 0.2659069299697876; L(Test): 0.2501242756843567\n",
      "Epoch 8934/10000: L(Train): 0.28718361258506775; L(Test): 0.24633058905601501\n",
      "Epoch 8935/10000: L(Train): 0.26378190517425537; L(Test): 0.24431683123111725\n",
      "Epoch 8936/10000: L(Train): 0.26784947514533997; L(Test): 0.24493272602558136\n",
      "Epoch 8937/10000: L(Train): 0.25020161271095276; L(Test): 0.2448330968618393\n",
      "Epoch 8938/10000: L(Train): 0.2665879428386688; L(Test): 0.24602250754833221\n",
      "Epoch 8939/10000: L(Train): 0.26025548577308655; L(Test): 0.24503591656684875\n",
      "Epoch 8940/10000: L(Train): 0.27104052901268005; L(Test): 0.24398142099380493\n",
      "Epoch 8941/10000: L(Train): 0.2748376429080963; L(Test): 0.24353599548339844\n",
      "Epoch 8942/10000: L(Train): 0.24486373364925385; L(Test): 0.2444390505552292\n",
      "Epoch 8943/10000: L(Train): 0.25994396209716797; L(Test): 0.24794404208660126\n",
      "Epoch 8944/10000: L(Train): 0.28011149168014526; L(Test): 0.24410617351531982\n",
      "Epoch 8945/10000: L(Train): 0.2669355571269989; L(Test): 0.24263854324817657\n",
      "Epoch 8946/10000: L(Train): 0.2661105990409851; L(Test): 0.24241848289966583\n",
      "Epoch 8947/10000: L(Train): 0.25188544392585754; L(Test): 0.24237282574176788\n",
      "Epoch 8948/10000: L(Train): 0.27270087599754333; L(Test): 0.24199585616588593\n",
      "Epoch 8949/10000: L(Train): 0.2617945075035095; L(Test): 0.2413637936115265\n",
      "Epoch 8950/10000: L(Train): 0.26042938232421875; L(Test): 0.24213021993637085\n",
      "Epoch 8951/10000: L(Train): 0.25960153341293335; L(Test): 0.24126626551151276\n",
      "Epoch 8952/10000: L(Train): 0.26218152046203613; L(Test): 0.24051415920257568\n",
      "Epoch 8953/10000: L(Train): 0.2672489285469055; L(Test): 0.24133692681789398\n",
      "Epoch 8954/10000: L(Train): 0.2562272250652313; L(Test): 0.2419787049293518\n",
      "Epoch 8955/10000: L(Train): 0.26070547103881836; L(Test): 0.2406013160943985\n",
      "Epoch 8956/10000: L(Train): 0.2586006820201874; L(Test): 0.24004612863063812\n",
      "Epoch 8957/10000: L(Train): 0.2659124433994293; L(Test): 0.24018658697605133\n",
      "Epoch 8958/10000: L(Train): 0.264470636844635; L(Test): 0.24009659886360168\n",
      "Epoch 8959/10000: L(Train): 0.2651333510875702; L(Test): 0.2385314404964447\n",
      "Epoch 8960/10000: L(Train): 0.2676340937614441; L(Test): 0.23973090946674347\n",
      "Epoch 8961/10000: L(Train): 0.26958709955215454; L(Test): 0.23953810334205627\n",
      "Epoch 8962/10000: L(Train): 0.2575112581253052; L(Test): 0.24233074486255646\n",
      "Epoch 8963/10000: L(Train): 0.26380839943885803; L(Test): 0.24288666248321533\n",
      "Epoch 8964/10000: L(Train): 0.26689213514328003; L(Test): 0.24115587770938873\n",
      "Epoch 8965/10000: L(Train): 0.2641875743865967; L(Test): 0.2441118210554123\n",
      "Epoch 8966/10000: L(Train): 0.2599063515663147; L(Test): 0.2416389286518097\n",
      "Epoch 8967/10000: L(Train): 0.2514088749885559; L(Test): 0.24114574491977692\n",
      "Epoch 8968/10000: L(Train): 0.2756316065788269; L(Test): 0.24055533111095428\n",
      "Epoch 8969/10000: L(Train): 0.26046228408813477; L(Test): 0.2396717518568039\n",
      "Epoch 8970/10000: L(Train): 0.2721549868583679; L(Test): 0.2392570525407791\n",
      "Epoch 8971/10000: L(Train): 0.26216769218444824; L(Test): 0.2380657196044922\n",
      "Epoch 8972/10000: L(Train): 0.25921931862831116; L(Test): 0.24035055935382843\n",
      "Epoch 8973/10000: L(Train): 0.26473623514175415; L(Test): 0.2376912385225296\n",
      "Epoch 8974/10000: L(Train): 0.2600694000720978; L(Test): 0.23812665045261383\n",
      "Epoch 8975/10000: L(Train): 0.2620263993740082; L(Test): 0.23895400762557983\n",
      "Epoch 8976/10000: L(Train): 0.27145734429359436; L(Test): 0.23795190453529358\n",
      "Epoch 8977/10000: L(Train): 0.2613286077976227; L(Test): 0.2378864735364914\n",
      "Epoch 8978/10000: L(Train): 0.25903740525245667; L(Test): 0.2369430959224701\n",
      "Epoch 8979/10000: L(Train): 0.24885447323322296; L(Test): 0.23725345730781555\n",
      "Epoch 8980/10000: L(Train): 0.25368279218673706; L(Test): 0.23727694153785706\n",
      "Epoch 8981/10000: L(Train): 0.2547473907470703; L(Test): 0.24161572754383087\n",
      "Epoch 8982/10000: L(Train): 0.26642143726348877; L(Test): 0.24625830352306366\n",
      "Epoch 8983/10000: L(Train): 0.2594849765300751; L(Test): 0.24280667304992676\n",
      "Epoch 8984/10000: L(Train): 0.258526086807251; L(Test): 0.24212121963500977\n",
      "Epoch 8985/10000: L(Train): 0.2669812738895416; L(Test): 0.2409500628709793\n",
      "Epoch 8986/10000: L(Train): 0.27502313256263733; L(Test): 0.239963099360466\n",
      "Epoch 8987/10000: L(Train): 0.26103395223617554; L(Test): 0.2435242384672165\n",
      "Epoch 8988/10000: L(Train): 0.26543939113616943; L(Test): 0.24269147217273712\n",
      "Epoch 8989/10000: L(Train): 0.2665475010871887; L(Test): 0.2398873269557953\n",
      "Epoch 8990/10000: L(Train): 0.2672339081764221; L(Test): 0.2405562400817871\n",
      "Epoch 8991/10000: L(Train): 0.2599479854106903; L(Test): 0.2423233985900879\n",
      "Epoch 8992/10000: L(Train): 0.25462111830711365; L(Test): 0.24206025898456573\n",
      "Epoch 8993/10000: L(Train): 0.2592785060405731; L(Test): 0.23996460437774658\n",
      "Epoch 8994/10000: L(Train): 0.2719016373157501; L(Test): 0.24479350447654724\n",
      "Epoch 8995/10000: L(Train): 0.2614310383796692; L(Test): 0.24164246022701263\n",
      "Epoch 8996/10000: L(Train): 0.26481521129608154; L(Test): 0.24344445765018463\n",
      "Epoch 8997/10000: L(Train): 0.25888821482658386; L(Test): 0.243554025888443\n",
      "Epoch 8998/10000: L(Train): 0.27687060832977295; L(Test): 0.24228866398334503\n",
      "Epoch 8999/10000: L(Train): 0.2608793377876282; L(Test): 0.2421797215938568\n",
      "Epoch 9000/10000: L(Train): 0.2751288115978241; L(Test): 0.24007973074913025\n",
      "Epoch 9001/10000: L(Train): 0.2709082067012787; L(Test): 0.24237807095050812\n",
      "Epoch 9002/10000: L(Train): 0.2716761827468872; L(Test): 0.2399826943874359\n",
      "Epoch 9003/10000: L(Train): 0.2651026248931885; L(Test): 0.2400515228509903\n",
      "Epoch 9004/10000: L(Train): 0.2620681822299957; L(Test): 0.24148830771446228\n",
      "Epoch 9005/10000: L(Train): 0.2710542380809784; L(Test): 0.23924076557159424\n",
      "Epoch 9006/10000: L(Train): 0.2664341628551483; L(Test): 0.24146626889705658\n",
      "Epoch 9007/10000: L(Train): 0.25100117921829224; L(Test): 0.242553249001503\n",
      "Epoch 9008/10000: L(Train): 0.2760823965072632; L(Test): 0.24498574435710907\n",
      "Epoch 9009/10000: L(Train): 0.27247506380081177; L(Test): 0.24127663671970367\n",
      "Epoch 9010/10000: L(Train): 0.265205442905426; L(Test): 0.24199479818344116\n",
      "Epoch 9011/10000: L(Train): 0.27220049500465393; L(Test): 0.24803516268730164\n",
      "Epoch 9012/10000: L(Train): 0.26517316699028015; L(Test): 0.24316444993019104\n",
      "Epoch 9013/10000: L(Train): 0.2721540331840515; L(Test): 0.24069039523601532\n",
      "Epoch 9014/10000: L(Train): 0.24688488245010376; L(Test): 0.2440900355577469\n",
      "Epoch 9015/10000: L(Train): 0.2599797248840332; L(Test): 0.24342045187950134\n",
      "Epoch 9016/10000: L(Train): 0.2615048885345459; L(Test): 0.24247556924819946\n",
      "Epoch 9017/10000: L(Train): 0.2674604058265686; L(Test): 0.24097119271755219\n",
      "Epoch 9018/10000: L(Train): 0.2725764811038971; L(Test): 0.2421240657567978\n",
      "Epoch 9019/10000: L(Train): 0.26213908195495605; L(Test): 0.24106855690479279\n",
      "Epoch 9020/10000: L(Train): 0.25917190313339233; L(Test): 0.2402268797159195\n",
      "Epoch 9021/10000: L(Train): 0.25053665041923523; L(Test): 0.24219690263271332\n",
      "Epoch 9022/10000: L(Train): 0.2711913585662842; L(Test): 0.24071644246578217\n",
      "Epoch 9023/10000: L(Train): 0.25717875361442566; L(Test): 0.24061468243598938\n",
      "Epoch 9024/10000: L(Train): 0.2578451931476593; L(Test): 0.24102210998535156\n",
      "Epoch 9025/10000: L(Train): 0.26327750086784363; L(Test): 0.2416752129793167\n",
      "Epoch 9026/10000: L(Train): 0.2732723653316498; L(Test): 0.24146124720573425\n",
      "Epoch 9027/10000: L(Train): 0.26283785700798035; L(Test): 0.24009419977664948\n",
      "Epoch 9028/10000: L(Train): 0.265292763710022; L(Test): 0.23973026871681213\n",
      "Epoch 9029/10000: L(Train): 0.2607349753379822; L(Test): 0.24191023409366608\n",
      "Epoch 9030/10000: L(Train): 0.2657504975795746; L(Test): 0.24095198512077332\n",
      "Epoch 9031/10000: L(Train): 0.276815801858902; L(Test): 0.23890827596187592\n",
      "Epoch 9032/10000: L(Train): 0.2621432840824127; L(Test): 0.24077720940113068\n",
      "Epoch 9033/10000: L(Train): 0.2473708838224411; L(Test): 0.24135881662368774\n",
      "Epoch 9034/10000: L(Train): 0.2642829418182373; L(Test): 0.2394006848335266\n",
      "Epoch 9035/10000: L(Train): 0.2514362037181854; L(Test): 0.24103695154190063\n",
      "Epoch 9036/10000: L(Train): 0.2733459770679474; L(Test): 0.24026910960674286\n",
      "Epoch 9037/10000: L(Train): 0.2628781795501709; L(Test): 0.239742249250412\n",
      "Epoch 9038/10000: L(Train): 0.251695454120636; L(Test): 0.23893602192401886\n",
      "Epoch 9039/10000: L(Train): 0.2591007351875305; L(Test): 0.23699736595153809\n",
      "Epoch 9040/10000: L(Train): 0.24881647527217865; L(Test): 0.2396015226840973\n",
      "Epoch 9041/10000: L(Train): 0.25894612073898315; L(Test): 0.23901891708374023\n",
      "Epoch 9042/10000: L(Train): 0.24646200239658356; L(Test): 0.23732806742191315\n",
      "Epoch 9043/10000: L(Train): 0.2511744201183319; L(Test): 0.23767684400081635\n",
      "Epoch 9044/10000: L(Train): 0.2440900206565857; L(Test): 0.23845495283603668\n",
      "Epoch 9045/10000: L(Train): 0.2514517605304718; L(Test): 0.23966340720653534\n",
      "Epoch 9046/10000: L(Train): 0.261531263589859; L(Test): 0.23713275790214539\n",
      "Epoch 9047/10000: L(Train): 0.24783861637115479; L(Test): 0.23684652149677277\n",
      "Epoch 9048/10000: L(Train): 0.2689671814441681; L(Test): 0.23666879534721375\n",
      "Epoch 9049/10000: L(Train): 0.26795926690101624; L(Test): 0.2365640550851822\n",
      "Epoch 9050/10000: L(Train): 0.25592344999313354; L(Test): 0.23814988136291504\n",
      "Epoch 9051/10000: L(Train): 0.25220584869384766; L(Test): 0.2369014173746109\n",
      "Epoch 9052/10000: L(Train): 0.24487590789794922; L(Test): 0.23660694062709808\n",
      "Epoch 9053/10000: L(Train): 0.2590005695819855; L(Test): 0.23733212053775787\n",
      "Epoch 9054/10000: L(Train): 0.25739750266075134; L(Test): 0.2382422536611557\n",
      "Epoch 9055/10000: L(Train): 0.24547605216503143; L(Test): 0.23853929340839386\n",
      "Epoch 9056/10000: L(Train): 0.27007776498794556; L(Test): 0.24002066254615784\n",
      "Epoch 9057/10000: L(Train): 0.24995693564414978; L(Test): 0.23903244733810425\n",
      "Epoch 9058/10000: L(Train): 0.24871553480625153; L(Test): 0.23765087127685547\n",
      "Epoch 9059/10000: L(Train): 0.25960370898246765; L(Test): 0.23784364759922028\n",
      "Epoch 9060/10000: L(Train): 0.26165369153022766; L(Test): 0.23872782289981842\n",
      "Epoch 9061/10000: L(Train): 0.26868733763694763; L(Test): 0.23879556357860565\n",
      "Epoch 9062/10000: L(Train): 0.263491153717041; L(Test): 0.23880067467689514\n",
      "Epoch 9063/10000: L(Train): 0.26140543818473816; L(Test): 0.23837871849536896\n",
      "Epoch 9064/10000: L(Train): 0.24742363393306732; L(Test): 0.23702102899551392\n",
      "Epoch 9065/10000: L(Train): 0.25438037514686584; L(Test): 0.2380955070257187\n",
      "Epoch 9066/10000: L(Train): 0.2597738206386566; L(Test): 0.23815317451953888\n",
      "Epoch 9067/10000: L(Train): 0.26207074522972107; L(Test): 0.23846852779388428\n",
      "Epoch 9068/10000: L(Train): 0.26729339361190796; L(Test): 0.23966260254383087\n",
      "Epoch 9069/10000: L(Train): 0.24680152535438538; L(Test): 0.2391684353351593\n",
      "Epoch 9070/10000: L(Train): 0.26101022958755493; L(Test): 0.23763006925582886\n",
      "Epoch 9071/10000: L(Train): 0.25473031401634216; L(Test): 0.23734521865844727\n",
      "Epoch 9072/10000: L(Train): 0.24070721864700317; L(Test): 0.23869052529335022\n",
      "Epoch 9073/10000: L(Train): 0.2503642439842224; L(Test): 0.23821485042572021\n",
      "Epoch 9074/10000: L(Train): 0.2478557676076889; L(Test): 0.2368614673614502\n",
      "Epoch 9075/10000: L(Train): 0.2564477026462555; L(Test): 0.23730088770389557\n",
      "Epoch 9076/10000: L(Train): 0.2534937262535095; L(Test): 0.23716939985752106\n",
      "Epoch 9077/10000: L(Train): 0.2538816034793854; L(Test): 0.23616524040699005\n",
      "Epoch 9078/10000: L(Train): 0.2483910173177719; L(Test): 0.23650945723056793\n",
      "Epoch 9079/10000: L(Train): 0.2605302929878235; L(Test): 0.23609653115272522\n",
      "Epoch 9080/10000: L(Train): 0.2617412805557251; L(Test): 0.23556195199489594\n",
      "Epoch 9081/10000: L(Train): 0.25581425428390503; L(Test): 0.23580504953861237\n",
      "Epoch 9082/10000: L(Train): 0.24896904826164246; L(Test): 0.2354341298341751\n",
      "Epoch 9083/10000: L(Train): 0.2693641781806946; L(Test): 0.23531830310821533\n",
      "Epoch 9084/10000: L(Train): 0.2557847499847412; L(Test): 0.23512203991413116\n",
      "Epoch 9085/10000: L(Train): 0.2567654252052307; L(Test): 0.2351379543542862\n",
      "Epoch 9086/10000: L(Train): 0.2708207964897156; L(Test): 0.23501069843769073\n",
      "Epoch 9087/10000: L(Train): 0.24074161052703857; L(Test): 0.2350948601961136\n",
      "Epoch 9088/10000: L(Train): 0.26192033290863037; L(Test): 0.2352955937385559\n",
      "Epoch 9089/10000: L(Train): 0.267750084400177; L(Test): 0.23528262972831726\n",
      "Epoch 9090/10000: L(Train): 0.25773489475250244; L(Test): 0.23512278497219086\n",
      "Epoch 9091/10000: L(Train): 0.2665562927722931; L(Test): 0.23499232530593872\n",
      "Epoch 9092/10000: L(Train): 0.2625561058521271; L(Test): 0.23475074768066406\n",
      "Epoch 9093/10000: L(Train): 0.255384236574173; L(Test): 0.23462504148483276\n",
      "Epoch 9094/10000: L(Train): 0.26745182275772095; L(Test): 0.23425807058811188\n",
      "Epoch 9095/10000: L(Train): 0.26527848839759827; L(Test): 0.23424406349658966\n",
      "Epoch 9096/10000: L(Train): 0.25286397337913513; L(Test): 0.23471057415008545\n",
      "Epoch 9097/10000: L(Train): 0.2607097625732422; L(Test): 0.23456253111362457\n",
      "Epoch 9098/10000: L(Train): 0.2561069428920746; L(Test): 0.2351347953081131\n",
      "Epoch 9099/10000: L(Train): 0.25240495800971985; L(Test): 0.23529352247714996\n",
      "Epoch 9100/10000: L(Train): 0.25690996646881104; L(Test): 0.23394712805747986\n",
      "Epoch 9101/10000: L(Train): 0.24021871387958527; L(Test): 0.23367540538311005\n",
      "Epoch 9102/10000: L(Train): 0.24440346658229828; L(Test): 0.23434993624687195\n",
      "Epoch 9103/10000: L(Train): 0.2605825662612915; L(Test): 0.23558634519577026\n",
      "Epoch 9104/10000: L(Train): 0.26164668798446655; L(Test): 0.2341892570257187\n",
      "Epoch 9105/10000: L(Train): 0.2678709030151367; L(Test): 0.23320920765399933\n",
      "Epoch 9106/10000: L(Train): 0.2531140148639679; L(Test): 0.23305293917655945\n",
      "Epoch 9107/10000: L(Train): 0.26248860359191895; L(Test): 0.23332397639751434\n",
      "Epoch 9108/10000: L(Train): 0.262844979763031; L(Test): 0.23382870852947235\n",
      "Epoch 9109/10000: L(Train): 0.2573072016239166; L(Test): 0.23407481610774994\n",
      "Epoch 9110/10000: L(Train): 0.254252165555954; L(Test): 0.23376122117042542\n",
      "Epoch 9111/10000: L(Train): 0.2576883137226105; L(Test): 0.2328178733587265\n",
      "Epoch 9112/10000: L(Train): 0.26737236976623535; L(Test): 0.23338469862937927\n",
      "Epoch 9113/10000: L(Train): 0.2684473991394043; L(Test): 0.2338104248046875\n",
      "Epoch 9114/10000: L(Train): 0.24436940252780914; L(Test): 0.23447544872760773\n",
      "Epoch 9115/10000: L(Train): 0.2686759829521179; L(Test): 0.23413324356079102\n",
      "Epoch 9116/10000: L(Train): 0.26093268394470215; L(Test): 0.23503226041793823\n",
      "Epoch 9117/10000: L(Train): 0.2637045383453369; L(Test): 0.2345556616783142\n",
      "Epoch 9118/10000: L(Train): 0.27270835638046265; L(Test): 0.23582643270492554\n",
      "Epoch 9119/10000: L(Train): 0.2644326686859131; L(Test): 0.23668330907821655\n",
      "Epoch 9120/10000: L(Train): 0.2513004541397095; L(Test): 0.23519793152809143\n",
      "Epoch 9121/10000: L(Train): 0.2369564175605774; L(Test): 0.23468145728111267\n",
      "Epoch 9122/10000: L(Train): 0.24507597088813782; L(Test): 0.2360341101884842\n",
      "Epoch 9123/10000: L(Train): 0.26401761174201965; L(Test): 0.23517537117004395\n",
      "Epoch 9124/10000: L(Train): 0.2511880397796631; L(Test): 0.23499777913093567\n",
      "Epoch 9125/10000: L(Train): 0.2450263947248459; L(Test): 0.23684942722320557\n",
      "Epoch 9126/10000: L(Train): 0.2729117274284363; L(Test): 0.23545996844768524\n",
      "Epoch 9127/10000: L(Train): 0.2715050280094147; L(Test): 0.23392346501350403\n",
      "Epoch 9128/10000: L(Train): 0.2485899180173874; L(Test): 0.23606978356838226\n",
      "Epoch 9129/10000: L(Train): 0.24971754848957062; L(Test): 0.23482516407966614\n",
      "Epoch 9130/10000: L(Train): 0.24940982460975647; L(Test): 0.23450902104377747\n",
      "Epoch 9131/10000: L(Train): 0.2540677487850189; L(Test): 0.2357633411884308\n",
      "Epoch 9132/10000: L(Train): 0.26105812191963196; L(Test): 0.23492813110351562\n",
      "Epoch 9133/10000: L(Train): 0.2459019422531128; L(Test): 0.23504409193992615\n",
      "Epoch 9134/10000: L(Train): 0.26101621985435486; L(Test): 0.23648960888385773\n",
      "Epoch 9135/10000: L(Train): 0.2631407678127289; L(Test): 0.2362324297428131\n",
      "Epoch 9136/10000: L(Train): 0.25385478138923645; L(Test): 0.2353835552930832\n",
      "Epoch 9137/10000: L(Train): 0.25022464990615845; L(Test): 0.2349386364221573\n",
      "Epoch 9138/10000: L(Train): 0.259319931268692; L(Test): 0.23607823252677917\n",
      "Epoch 9139/10000: L(Train): 0.27240046858787537; L(Test): 0.2360171228647232\n",
      "Epoch 9140/10000: L(Train): 0.25162383913993835; L(Test): 0.2359752058982849\n",
      "Epoch 9141/10000: L(Train): 0.27863067388534546; L(Test): 0.23756490647792816\n",
      "Epoch 9142/10000: L(Train): 0.2542138397693634; L(Test): 0.23664803802967072\n",
      "Epoch 9143/10000: L(Train): 0.2510834336280823; L(Test): 0.23571887612342834\n",
      "Epoch 9144/10000: L(Train): 0.2627231478691101; L(Test): 0.23651224374771118\n",
      "Epoch 9145/10000: L(Train): 0.2659793198108673; L(Test): 0.23565222322940826\n",
      "Epoch 9146/10000: L(Train): 0.24550001323223114; L(Test): 0.23608490824699402\n",
      "Epoch 9147/10000: L(Train): 0.2496894896030426; L(Test): 0.2378963828086853\n",
      "Epoch 9148/10000: L(Train): 0.26563626527786255; L(Test): 0.2387758046388626\n",
      "Epoch 9149/10000: L(Train): 0.2650717794895172; L(Test): 0.23802343010902405\n",
      "Epoch 9150/10000: L(Train): 0.25348398089408875; L(Test): 0.2369176298379898\n",
      "Epoch 9151/10000: L(Train): 0.25420480966567993; L(Test): 0.23657537996768951\n",
      "Epoch 9152/10000: L(Train): 0.2535085082054138; L(Test): 0.23701846599578857\n",
      "Epoch 9153/10000: L(Train): 0.2723798453807831; L(Test): 0.23773838579654694\n",
      "Epoch 9154/10000: L(Train): 0.258144736289978; L(Test): 0.23647871613502502\n",
      "Epoch 9155/10000: L(Train): 0.24511095881462097; L(Test): 0.23665255308151245\n",
      "Epoch 9156/10000: L(Train): 0.2553907334804535; L(Test): 0.23766222596168518\n",
      "Epoch 9157/10000: L(Train): 0.252378910779953; L(Test): 0.23602333664894104\n",
      "Epoch 9158/10000: L(Train): 0.26030227541923523; L(Test): 0.23469698429107666\n",
      "Epoch 9159/10000: L(Train): 0.27567097544670105; L(Test): 0.23566152155399323\n",
      "Epoch 9160/10000: L(Train): 0.24627237021923065; L(Test): 0.2346731275320053\n",
      "Epoch 9161/10000: L(Train): 0.26267361640930176; L(Test): 0.23486995697021484\n",
      "Epoch 9162/10000: L(Train): 0.2532682716846466; L(Test): 0.23588044941425323\n",
      "Epoch 9163/10000: L(Train): 0.2576419413089752; L(Test): 0.23569296300411224\n",
      "Epoch 9164/10000: L(Train): 0.26206862926483154; L(Test): 0.23470208048820496\n",
      "Epoch 9165/10000: L(Train): 0.24995581805706024; L(Test): 0.23561513423919678\n",
      "Epoch 9166/10000: L(Train): 0.25287312269210815; L(Test): 0.2356584519147873\n",
      "Epoch 9167/10000: L(Train): 0.23925063014030457; L(Test): 0.23486648499965668\n",
      "Epoch 9168/10000: L(Train): 0.2553389072418213; L(Test): 0.2349565029144287\n",
      "Epoch 9169/10000: L(Train): 0.2678426206111908; L(Test): 0.23487363755702972\n",
      "Epoch 9170/10000: L(Train): 0.2704210579395294; L(Test): 0.23420988023281097\n",
      "Epoch 9171/10000: L(Train): 0.2575451135635376; L(Test): 0.234970360994339\n",
      "Epoch 9172/10000: L(Train): 0.25223591923713684; L(Test): 0.23461711406707764\n",
      "Epoch 9173/10000: L(Train): 0.2713965177536011; L(Test): 0.23360741138458252\n",
      "Epoch 9174/10000: L(Train): 0.2408532053232193; L(Test): 0.2342420071363449\n",
      "Epoch 9175/10000: L(Train): 0.25956353545188904; L(Test): 0.2350093275308609\n",
      "Epoch 9176/10000: L(Train): 0.26385775208473206; L(Test): 0.2346191555261612\n",
      "Epoch 9177/10000: L(Train): 0.24691107869148254; L(Test): 0.23441490530967712\n",
      "Epoch 9178/10000: L(Train): 0.2475501447916031; L(Test): 0.23475156724452972\n",
      "Epoch 9179/10000: L(Train): 0.24925853312015533; L(Test): 0.23526421189308167\n",
      "Epoch 9180/10000: L(Train): 0.26970556378364563; L(Test): 0.2343602031469345\n",
      "Epoch 9181/10000: L(Train): 0.267729789018631; L(Test): 0.2357284277677536\n",
      "Epoch 9182/10000: L(Train): 0.27845457196235657; L(Test): 0.2355363667011261\n",
      "Epoch 9183/10000: L(Train): 0.24110572040081024; L(Test): 0.23532544076442719\n",
      "Epoch 9184/10000: L(Train): 0.2521451413631439; L(Test): 0.23568609356880188\n",
      "Epoch 9185/10000: L(Train): 0.25548872351646423; L(Test): 0.23443350195884705\n",
      "Epoch 9186/10000: L(Train): 0.2527620196342468; L(Test): 0.2345624566078186\n",
      "Epoch 9187/10000: L(Train): 0.25091642141342163; L(Test): 0.23466698825359344\n",
      "Epoch 9188/10000: L(Train): 0.2662959694862366; L(Test): 0.23427894711494446\n",
      "Epoch 9189/10000: L(Train): 0.25111818313598633; L(Test): 0.23466317355632782\n",
      "Epoch 9190/10000: L(Train): 0.2595304250717163; L(Test): 0.2349776327610016\n",
      "Epoch 9191/10000: L(Train): 0.26484501361846924; L(Test): 0.23499086499214172\n",
      "Epoch 9192/10000: L(Train): 0.2527439594268799; L(Test): 0.23565439879894257\n",
      "Epoch 9193/10000: L(Train): 0.2588213384151459; L(Test): 0.23400095105171204\n",
      "Epoch 9194/10000: L(Train): 0.26087087392807007; L(Test): 0.2336156964302063\n",
      "Epoch 9195/10000: L(Train): 0.25176894664764404; L(Test): 0.23399274051189423\n",
      "Epoch 9196/10000: L(Train): 0.25727298855781555; L(Test): 0.23348625004291534\n",
      "Epoch 9197/10000: L(Train): 0.26232993602752686; L(Test): 0.23346078395843506\n",
      "Epoch 9198/10000: L(Train): 0.2569728493690491; L(Test): 0.2334222048521042\n",
      "Epoch 9199/10000: L(Train): 0.2546065151691437; L(Test): 0.23296183347702026\n",
      "Epoch 9200/10000: L(Train): 0.26152554154396057; L(Test): 0.23298127949237823\n",
      "Epoch 9201/10000: L(Train): 0.25387680530548096; L(Test): 0.23330077528953552\n",
      "Epoch 9202/10000: L(Train): 0.25229737162590027; L(Test): 0.2334764450788498\n",
      "Epoch 9203/10000: L(Train): 0.24329468607902527; L(Test): 0.23367664217948914\n",
      "Epoch 9204/10000: L(Train): 0.25301846861839294; L(Test): 0.23446914553642273\n",
      "Epoch 9205/10000: L(Train): 0.2713128924369812; L(Test): 0.23475989699363708\n",
      "Epoch 9206/10000: L(Train): 0.27728554606437683; L(Test): 0.23352742195129395\n",
      "Epoch 9207/10000: L(Train): 0.2561630308628082; L(Test): 0.23412096500396729\n",
      "Epoch 9208/10000: L(Train): 0.2555706799030304; L(Test): 0.23433168232440948\n",
      "Epoch 9209/10000: L(Train): 0.2459520399570465; L(Test): 0.2334996461868286\n",
      "Epoch 9210/10000: L(Train): 0.2586728036403656; L(Test): 0.2342127561569214\n",
      "Epoch 9211/10000: L(Train): 0.2548274099826813; L(Test): 0.23529505729675293\n",
      "Epoch 9212/10000: L(Train): 0.26161444187164307; L(Test): 0.23439642786979675\n",
      "Epoch 9213/10000: L(Train): 0.2560308873653412; L(Test): 0.23407530784606934\n",
      "Epoch 9214/10000: L(Train): 0.26456210017204285; L(Test): 0.23487776517868042\n",
      "Epoch 9215/10000: L(Train): 0.2685101330280304; L(Test): 0.2363114356994629\n",
      "Epoch 9216/10000: L(Train): 0.24471665918827057; L(Test): 0.23445473611354828\n",
      "Epoch 9217/10000: L(Train): 0.25797444581985474; L(Test): 0.23466579616069794\n",
      "Epoch 9218/10000: L(Train): 0.24792730808258057; L(Test): 0.2360161393880844\n",
      "Epoch 9219/10000: L(Train): 0.2577892243862152; L(Test): 0.2359790802001953\n",
      "Epoch 9220/10000: L(Train): 0.24230395257472992; L(Test): 0.23440991342067719\n",
      "Epoch 9221/10000: L(Train): 0.25168123841285706; L(Test): 0.23537543416023254\n",
      "Epoch 9222/10000: L(Train): 0.25279900431632996; L(Test): 0.23580309748649597\n",
      "Epoch 9223/10000: L(Train): 0.2705674469470978; L(Test): 0.23494930565357208\n",
      "Epoch 9224/10000: L(Train): 0.26714026927948; L(Test): 0.23521558940410614\n",
      "Epoch 9225/10000: L(Train): 0.2724447548389435; L(Test): 0.23586775362491608\n",
      "Epoch 9226/10000: L(Train): 0.2588734030723572; L(Test): 0.23644134402275085\n",
      "Epoch 9227/10000: L(Train): 0.24605828523635864; L(Test): 0.23518766462802887\n",
      "Epoch 9228/10000: L(Train): 0.24435074627399445; L(Test): 0.23405581712722778\n",
      "Epoch 9229/10000: L(Train): 0.2523942291736603; L(Test): 0.23468612134456635\n",
      "Epoch 9230/10000: L(Train): 0.2767225503921509; L(Test): 0.23408156633377075\n",
      "Epoch 9231/10000: L(Train): 0.24622736871242523; L(Test): 0.23538365960121155\n",
      "Epoch 9232/10000: L(Train): 0.2540673315525055; L(Test): 0.23576237261295319\n",
      "Epoch 9233/10000: L(Train): 0.25272616744041443; L(Test): 0.23574459552764893\n",
      "Epoch 9234/10000: L(Train): 0.24736812710762024; L(Test): 0.2347836196422577\n",
      "Epoch 9235/10000: L(Train): 0.25543302297592163; L(Test): 0.23412223160266876\n",
      "Epoch 9236/10000: L(Train): 0.27688518166542053; L(Test): 0.2348059117794037\n",
      "Epoch 9237/10000: L(Train): 0.2590344250202179; L(Test): 0.23538166284561157\n",
      "Epoch 9238/10000: L(Train): 0.2645774185657501; L(Test): 0.2350025624036789\n",
      "Epoch 9239/10000: L(Train): 0.2590971291065216; L(Test): 0.2343267798423767\n",
      "Epoch 9240/10000: L(Train): 0.2512853741645813; L(Test): 0.2350376546382904\n",
      "Epoch 9241/10000: L(Train): 0.2634409964084625; L(Test): 0.23561647534370422\n",
      "Epoch 9242/10000: L(Train): 0.26987454295158386; L(Test): 0.2351781725883484\n",
      "Epoch 9243/10000: L(Train): 0.26426711678504944; L(Test): 0.2357311099767685\n",
      "Epoch 9244/10000: L(Train): 0.2685913145542145; L(Test): 0.2340162992477417\n",
      "Epoch 9245/10000: L(Train): 0.25195053219795227; L(Test): 0.23715604841709137\n",
      "Epoch 9246/10000: L(Train): 0.2490285038948059; L(Test): 0.23607544600963593\n",
      "Epoch 9247/10000: L(Train): 0.26608482003211975; L(Test): 0.23486167192459106\n",
      "Epoch 9248/10000: L(Train): 0.2515780031681061; L(Test): 0.23717831075191498\n",
      "Epoch 9249/10000: L(Train): 0.25257420539855957; L(Test): 0.23606106638908386\n",
      "Epoch 9250/10000: L(Train): 0.2553361654281616; L(Test): 0.23955877125263214\n",
      "Epoch 9251/10000: L(Train): 0.27276864647865295; L(Test): 0.2366512566804886\n",
      "Epoch 9252/10000: L(Train): 0.2684953808784485; L(Test): 0.23506729304790497\n",
      "Epoch 9253/10000: L(Train): 0.2606525421142578; L(Test): 0.23585112392902374\n",
      "Epoch 9254/10000: L(Train): 0.25854650139808655; L(Test): 0.23614682257175446\n",
      "Epoch 9255/10000: L(Train): 0.2701925039291382; L(Test): 0.23547415435314178\n",
      "Epoch 9256/10000: L(Train): 0.2661004960536957; L(Test): 0.23485834896564484\n",
      "Epoch 9257/10000: L(Train): 0.2599034309387207; L(Test): 0.23543567955493927\n",
      "Epoch 9258/10000: L(Train): 0.2679440379142761; L(Test): 0.2344146966934204\n",
      "Epoch 9259/10000: L(Train): 0.2626264989376068; L(Test): 0.23554915189743042\n",
      "Epoch 9260/10000: L(Train): 0.2693553566932678; L(Test): 0.23571905493736267\n",
      "Epoch 9261/10000: L(Train): 0.24884934723377228; L(Test): 0.23403725028038025\n",
      "Epoch 9262/10000: L(Train): 0.26526468992233276; L(Test): 0.23388202488422394\n",
      "Epoch 9263/10000: L(Train): 0.24943147599697113; L(Test): 0.23471713066101074\n",
      "Epoch 9264/10000: L(Train): 0.2567695677280426; L(Test): 0.23585358262062073\n",
      "Epoch 9265/10000: L(Train): 0.25418350100517273; L(Test): 0.2353566586971283\n",
      "Epoch 9266/10000: L(Train): 0.2568182051181793; L(Test): 0.23507912456989288\n",
      "Epoch 9267/10000: L(Train): 0.2613549828529358; L(Test): 0.2346363365650177\n",
      "Epoch 9268/10000: L(Train): 0.2521747648715973; L(Test): 0.234811931848526\n",
      "Epoch 9269/10000: L(Train): 0.26709306240081787; L(Test): 0.23547086119651794\n",
      "Epoch 9270/10000: L(Train): 0.2687670886516571; L(Test): 0.23482899367809296\n",
      "Epoch 9271/10000: L(Train): 0.2560029923915863; L(Test): 0.2344866544008255\n",
      "Epoch 9272/10000: L(Train): 0.28279945254325867; L(Test): 0.23514333367347717\n",
      "Epoch 9273/10000: L(Train): 0.26708120107650757; L(Test): 0.23846323788166046\n",
      "Epoch 9274/10000: L(Train): 0.261425256729126; L(Test): 0.2401469349861145\n",
      "Epoch 9275/10000: L(Train): 0.2622278928756714; L(Test): 0.2363964319229126\n",
      "Epoch 9276/10000: L(Train): 0.26332128047943115; L(Test): 0.23784439265727997\n",
      "Epoch 9277/10000: L(Train): 0.25431132316589355; L(Test): 0.2379557341337204\n",
      "Epoch 9278/10000: L(Train): 0.2613072395324707; L(Test): 0.23769207298755646\n",
      "Epoch 9279/10000: L(Train): 0.2510494291782379; L(Test): 0.23578928411006927\n",
      "Epoch 9280/10000: L(Train): 0.2577785849571228; L(Test): 0.23699769377708435\n",
      "Epoch 9281/10000: L(Train): 0.26001405715942383; L(Test): 0.2363869994878769\n",
      "Epoch 9282/10000: L(Train): 0.2514038681983948; L(Test): 0.23707081377506256\n",
      "Epoch 9283/10000: L(Train): 0.2526969909667969; L(Test): 0.23793011903762817\n",
      "Epoch 9284/10000: L(Train): 0.24647444486618042; L(Test): 0.23880575597286224\n",
      "Epoch 9285/10000: L(Train): 0.26033473014831543; L(Test): 0.23732171952724457\n",
      "Epoch 9286/10000: L(Train): 0.24549898505210876; L(Test): 0.2387215793132782\n",
      "Epoch 9287/10000: L(Train): 0.2619175314903259; L(Test): 0.23865996301174164\n",
      "Epoch 9288/10000: L(Train): 0.24738088250160217; L(Test): 0.23756133019924164\n",
      "Epoch 9289/10000: L(Train): 0.26372039318084717; L(Test): 0.2369050234556198\n",
      "Epoch 9290/10000: L(Train): 0.2605118751525879; L(Test): 0.23796358704566956\n",
      "Epoch 9291/10000: L(Train): 0.2548905313014984; L(Test): 0.23972269892692566\n",
      "Epoch 9292/10000: L(Train): 0.2537553906440735; L(Test): 0.23785234987735748\n",
      "Epoch 9293/10000: L(Train): 0.26576176285743713; L(Test): 0.2362896353006363\n",
      "Epoch 9294/10000: L(Train): 0.25029659271240234; L(Test): 0.236021488904953\n",
      "Epoch 9295/10000: L(Train): 0.25646117329597473; L(Test): 0.23662123084068298\n",
      "Epoch 9296/10000: L(Train): 0.27093276381492615; L(Test): 0.23581282794475555\n",
      "Epoch 9297/10000: L(Train): 0.25928452610969543; L(Test): 0.23507079482078552\n",
      "Epoch 9298/10000: L(Train): 0.2532358467578888; L(Test): 0.23576609790325165\n",
      "Epoch 9299/10000: L(Train): 0.26820915937423706; L(Test): 0.23573382198810577\n",
      "Epoch 9300/10000: L(Train): 0.26497700810432434; L(Test): 0.23448997735977173\n",
      "Epoch 9301/10000: L(Train): 0.26664528250694275; L(Test): 0.2349473088979721\n",
      "Epoch 9302/10000: L(Train): 0.2716251313686371; L(Test): 0.23528915643692017\n",
      "Epoch 9303/10000: L(Train): 0.25435909628868103; L(Test): 0.23518989980220795\n",
      "Epoch 9304/10000: L(Train): 0.2605646252632141; L(Test): 0.2345035821199417\n",
      "Epoch 9305/10000: L(Train): 0.253149151802063; L(Test): 0.2370060831308365\n",
      "Epoch 9306/10000: L(Train): 0.2605927586555481; L(Test): 0.23597730696201324\n",
      "Epoch 9307/10000: L(Train): 0.2494160234928131; L(Test): 0.23525753617286682\n",
      "Epoch 9308/10000: L(Train): 0.25829699635505676; L(Test): 0.23603278398513794\n",
      "Epoch 9309/10000: L(Train): 0.2601243555545807; L(Test): 0.2373570054769516\n",
      "Epoch 9310/10000: L(Train): 0.2695811092853546; L(Test): 0.23691682517528534\n",
      "Epoch 9311/10000: L(Train): 0.26170822978019714; L(Test): 0.2369866967201233\n",
      "Epoch 9312/10000: L(Train): 0.26406794786453247; L(Test): 0.23802193999290466\n",
      "Epoch 9313/10000: L(Train): 0.25149476528167725; L(Test): 0.23790745437145233\n",
      "Epoch 9314/10000: L(Train): 0.2579262852668762; L(Test): 0.23853904008865356\n",
      "Epoch 9315/10000: L(Train): 0.2548881471157074; L(Test): 0.23769113421440125\n",
      "Epoch 9316/10000: L(Train): 0.25148677825927734; L(Test): 0.23677068948745728\n",
      "Epoch 9317/10000: L(Train): 0.26849570870399475; L(Test): 0.2373984009027481\n",
      "Epoch 9318/10000: L(Train): 0.28052887320518494; L(Test): 0.23722442984580994\n",
      "Epoch 9319/10000: L(Train): 0.2609550654888153; L(Test): 0.23657827079296112\n",
      "Epoch 9320/10000: L(Train): 0.2518654465675354; L(Test): 0.23805935680866241\n",
      "Epoch 9321/10000: L(Train): 0.2650163173675537; L(Test): 0.2390192300081253\n",
      "Epoch 9322/10000: L(Train): 0.25825560092926025; L(Test): 0.23854775726795197\n",
      "Epoch 9323/10000: L(Train): 0.2514292001724243; L(Test): 0.23878991603851318\n",
      "Epoch 9324/10000: L(Train): 0.2674640715122223; L(Test): 0.23821616172790527\n",
      "Epoch 9325/10000: L(Train): 0.26820337772369385; L(Test): 0.23729676008224487\n",
      "Epoch 9326/10000: L(Train): 0.2618773281574249; L(Test): 0.23787608742713928\n",
      "Epoch 9327/10000: L(Train): 0.2573843002319336; L(Test): 0.23796331882476807\n",
      "Epoch 9328/10000: L(Train): 0.2557080090045929; L(Test): 0.23901890218257904\n",
      "Epoch 9329/10000: L(Train): 0.2626648545265198; L(Test): 0.2364618480205536\n",
      "Epoch 9330/10000: L(Train): 0.2566473186016083; L(Test): 0.23711705207824707\n",
      "Epoch 9331/10000: L(Train): 0.26971933245658875; L(Test): 0.23798614740371704\n",
      "Epoch 9332/10000: L(Train): 0.2584785521030426; L(Test): 0.2381676435470581\n",
      "Epoch 9333/10000: L(Train): 0.2590087354183197; L(Test): 0.2379274070262909\n",
      "Epoch 9334/10000: L(Train): 0.2681325078010559; L(Test): 0.23872913420200348\n",
      "Epoch 9335/10000: L(Train): 0.2482348084449768; L(Test): 0.23856393992900848\n",
      "Epoch 9336/10000: L(Train): 0.25869476795196533; L(Test): 0.23877359926700592\n",
      "Epoch 9337/10000: L(Train): 0.2690351903438568; L(Test): 0.23818092048168182\n",
      "Epoch 9338/10000: L(Train): 0.2579772472381592; L(Test): 0.23853984475135803\n",
      "Epoch 9339/10000: L(Train): 0.2726238965988159; L(Test): 0.2378895878791809\n",
      "Epoch 9340/10000: L(Train): 0.26050931215286255; L(Test): 0.23807759582996368\n",
      "Epoch 9341/10000: L(Train): 0.2553192973136902; L(Test): 0.23713111877441406\n",
      "Epoch 9342/10000: L(Train): 0.26847100257873535; L(Test): 0.23672178387641907\n",
      "Epoch 9343/10000: L(Train): 0.24975116550922394; L(Test): 0.23727162182331085\n",
      "Epoch 9344/10000: L(Train): 0.2638799250125885; L(Test): 0.23674046993255615\n",
      "Epoch 9345/10000: L(Train): 0.25808942317962646; L(Test): 0.23617851734161377\n",
      "Epoch 9346/10000: L(Train): 0.2719302475452423; L(Test): 0.2357027381658554\n",
      "Epoch 9347/10000: L(Train): 0.2613312005996704; L(Test): 0.23573552072048187\n",
      "Epoch 9348/10000: L(Train): 0.2572099268436432; L(Test): 0.23565280437469482\n",
      "Epoch 9349/10000: L(Train): 0.27280429005622864; L(Test): 0.23568427562713623\n",
      "Epoch 9350/10000: L(Train): 0.24904407560825348; L(Test): 0.23632870614528656\n",
      "Epoch 9351/10000: L(Train): 0.24701158702373505; L(Test): 0.23546238243579865\n",
      "Epoch 9352/10000: L(Train): 0.2582944333553314; L(Test): 0.23579095304012299\n",
      "Epoch 9353/10000: L(Train): 0.2643449306488037; L(Test): 0.23591388761997223\n",
      "Epoch 9354/10000: L(Train): 0.2586396634578705; L(Test): 0.2349562793970108\n",
      "Epoch 9355/10000: L(Train): 0.26161763072013855; L(Test): 0.2345452755689621\n",
      "Epoch 9356/10000: L(Train): 0.2556578516960144; L(Test): 0.2342309206724167\n",
      "Epoch 9357/10000: L(Train): 0.26598942279815674; L(Test): 0.23475594818592072\n",
      "Epoch 9358/10000: L(Train): 0.2783440053462982; L(Test): 0.2345091998577118\n",
      "Epoch 9359/10000: L(Train): 0.2496442347764969; L(Test): 0.23525506258010864\n",
      "Epoch 9360/10000: L(Train): 0.2601219713687897; L(Test): 0.235276460647583\n",
      "Epoch 9361/10000: L(Train): 0.2718851864337921; L(Test): 0.23505288362503052\n",
      "Epoch 9362/10000: L(Train): 0.2612163722515106; L(Test): 0.23643873631954193\n",
      "Epoch 9363/10000: L(Train): 0.25893303751945496; L(Test): 0.23579636216163635\n",
      "Epoch 9364/10000: L(Train): 0.2601364254951477; L(Test): 0.2353636920452118\n",
      "Epoch 9365/10000: L(Train): 0.2693893313407898; L(Test): 0.23627710342407227\n",
      "Epoch 9366/10000: L(Train): 0.2624284625053406; L(Test): 0.2365720570087433\n",
      "Epoch 9367/10000: L(Train): 0.2756668031215668; L(Test): 0.23500099778175354\n",
      "Epoch 9368/10000: L(Train): 0.25271862745285034; L(Test): 0.23504799604415894\n",
      "Epoch 9369/10000: L(Train): 0.26363980770111084; L(Test): 0.2357313483953476\n",
      "Epoch 9370/10000: L(Train): 0.26571378111839294; L(Test): 0.23544462025165558\n",
      "Epoch 9371/10000: L(Train): 0.2630898058414459; L(Test): 0.23501135408878326\n",
      "Epoch 9372/10000: L(Train): 0.2663412392139435; L(Test): 0.23619386553764343\n",
      "Epoch 9373/10000: L(Train): 0.2630236744880676; L(Test): 0.23603390157222748\n",
      "Epoch 9374/10000: L(Train): 0.2541404366493225; L(Test): 0.23899903893470764\n",
      "Epoch 9375/10000: L(Train): 0.25804850459098816; L(Test): 0.23778752982616425\n",
      "Epoch 9376/10000: L(Train): 0.27228978276252747; L(Test): 0.23636242747306824\n",
      "Epoch 9377/10000: L(Train): 0.2558751702308655; L(Test): 0.2355424165725708\n",
      "Epoch 9378/10000: L(Train): 0.25896477699279785; L(Test): 0.23634560406208038\n",
      "Epoch 9379/10000: L(Train): 0.25782111287117004; L(Test): 0.238044872879982\n",
      "Epoch 9380/10000: L(Train): 0.26768893003463745; L(Test): 0.238832026720047\n",
      "Epoch 9381/10000: L(Train): 0.2732139825820923; L(Test): 0.2379453033208847\n",
      "Epoch 9382/10000: L(Train): 0.267638623714447; L(Test): 0.24064861238002777\n",
      "Epoch 9383/10000: L(Train): 0.2665262520313263; L(Test): 0.23648369312286377\n",
      "Epoch 9384/10000: L(Train): 0.27078554034233093; L(Test): 0.23969119787216187\n",
      "Epoch 9385/10000: L(Train): 0.26797622442245483; L(Test): 0.23942330479621887\n",
      "Epoch 9386/10000: L(Train): 0.2598959505558014; L(Test): 0.23988395929336548\n",
      "Epoch 9387/10000: L(Train): 0.2603846490383148; L(Test): 0.240306556224823\n",
      "Epoch 9388/10000: L(Train): 0.26126718521118164; L(Test): 0.24043726921081543\n",
      "Epoch 9389/10000: L(Train): 0.2516368329524994; L(Test): 0.23858235776424408\n",
      "Epoch 9390/10000: L(Train): 0.26259690523147583; L(Test): 0.23955391347408295\n",
      "Epoch 9391/10000: L(Train): 0.24859564006328583; L(Test): 0.24142573773860931\n",
      "Epoch 9392/10000: L(Train): 0.26074695587158203; L(Test): 0.23820766806602478\n",
      "Epoch 9393/10000: L(Train): 0.25387898087501526; L(Test): 0.23797212541103363\n",
      "Epoch 9394/10000: L(Train): 0.2605477571487427; L(Test): 0.23871015012264252\n",
      "Epoch 9395/10000: L(Train): 0.2472446709871292; L(Test): 0.23920521140098572\n",
      "Epoch 9396/10000: L(Train): 0.2552104592323303; L(Test): 0.23645378649234772\n",
      "Epoch 9397/10000: L(Train): 0.2558865249156952; L(Test): 0.23778723180294037\n",
      "Epoch 9398/10000: L(Train): 0.2689448893070221; L(Test): 0.23616595566272736\n",
      "Epoch 9399/10000: L(Train): 0.2524714469909668; L(Test): 0.23651811480522156\n",
      "Epoch 9400/10000: L(Train): 0.2657284736633301; L(Test): 0.23551608622074127\n",
      "Epoch 9401/10000: L(Train): 0.25230589509010315; L(Test): 0.23562461137771606\n",
      "Epoch 9402/10000: L(Train): 0.2517576515674591; L(Test): 0.23548829555511475\n",
      "Epoch 9403/10000: L(Train): 0.2674750089645386; L(Test): 0.23541893064975739\n",
      "Epoch 9404/10000: L(Train): 0.2723090350627899; L(Test): 0.23642267286777496\n",
      "Epoch 9405/10000: L(Train): 0.25301387906074524; L(Test): 0.24270011484622955\n",
      "Epoch 9406/10000: L(Train): 0.2752269208431244; L(Test): 0.24178656935691833\n",
      "Epoch 9407/10000: L(Train): 0.2681577801704407; L(Test): 0.2401629239320755\n",
      "Epoch 9408/10000: L(Train): 0.2594906687736511; L(Test): 0.24203641712665558\n",
      "Epoch 9409/10000: L(Train): 0.25834017992019653; L(Test): 0.24633410573005676\n",
      "Epoch 9410/10000: L(Train): 0.2794487774372101; L(Test): 0.24022872745990753\n",
      "Epoch 9411/10000: L(Train): 0.2622000575065613; L(Test): 0.2400798499584198\n",
      "Epoch 9412/10000: L(Train): 0.2597828805446625; L(Test): 0.24007941782474518\n",
      "Epoch 9413/10000: L(Train): 0.26450395584106445; L(Test): 0.23968221247196198\n",
      "Epoch 9414/10000: L(Train): 0.26723265647888184; L(Test): 0.23837578296661377\n",
      "Epoch 9415/10000: L(Train): 0.2550561726093292; L(Test): 0.23947526514530182\n",
      "Epoch 9416/10000: L(Train): 0.2789916396141052; L(Test): 0.23935775458812714\n",
      "Epoch 9417/10000: L(Train): 0.26405784487724304; L(Test): 0.23880569636821747\n",
      "Epoch 9418/10000: L(Train): 0.26380616426467896; L(Test): 0.23899206519126892\n",
      "Epoch 9419/10000: L(Train): 0.2622259855270386; L(Test): 0.23989905416965485\n",
      "Epoch 9420/10000: L(Train): 0.2598079741001129; L(Test): 0.23860499262809753\n",
      "Epoch 9421/10000: L(Train): 0.24974466860294342; L(Test): 0.23868289589881897\n",
      "Epoch 9422/10000: L(Train): 0.2522103190422058; L(Test): 0.24032583832740784\n",
      "Epoch 9423/10000: L(Train): 0.2651043236255646; L(Test): 0.23929670453071594\n",
      "Epoch 9424/10000: L(Train): 0.2650145888328552; L(Test): 0.2382410615682602\n",
      "Epoch 9425/10000: L(Train): 0.2561294436454773; L(Test): 0.23853817582130432\n",
      "Epoch 9426/10000: L(Train): 0.2612379491329193; L(Test): 0.2375430017709732\n",
      "Epoch 9427/10000: L(Train): 0.264007031917572; L(Test): 0.23716366291046143\n",
      "Epoch 9428/10000: L(Train): 0.2644198536872864; L(Test): 0.23720121383666992\n",
      "Epoch 9429/10000: L(Train): 0.2640974223613739; L(Test): 0.2383149266242981\n",
      "Epoch 9430/10000: L(Train): 0.25502657890319824; L(Test): 0.23755107820034027\n",
      "Epoch 9431/10000: L(Train): 0.25206491351127625; L(Test): 0.23666685819625854\n",
      "Epoch 9432/10000: L(Train): 0.26671290397644043; L(Test): 0.2372947335243225\n",
      "Epoch 9433/10000: L(Train): 0.26583224534988403; L(Test): 0.23932768404483795\n",
      "Epoch 9434/10000: L(Train): 0.28269389271736145; L(Test): 0.23865799605846405\n",
      "Epoch 9435/10000: L(Train): 0.27202677726745605; L(Test): 0.2372208535671234\n",
      "Epoch 9436/10000: L(Train): 0.2501492202281952; L(Test): 0.23784609138965607\n",
      "Epoch 9437/10000: L(Train): 0.2507024109363556; L(Test): 0.23805218935012817\n",
      "Epoch 9438/10000: L(Train): 0.25494304299354553; L(Test): 0.2395455241203308\n",
      "Epoch 9439/10000: L(Train): 0.27253055572509766; L(Test): 0.23959606885910034\n",
      "Epoch 9440/10000: L(Train): 0.25589755177497864; L(Test): 0.23903098702430725\n",
      "Epoch 9441/10000: L(Train): 0.24447159469127655; L(Test): 0.2386242151260376\n",
      "Epoch 9442/10000: L(Train): 0.2611381411552429; L(Test): 0.23809027671813965\n",
      "Epoch 9443/10000: L(Train): 0.26956626772880554; L(Test): 0.23696845769882202\n",
      "Epoch 9444/10000: L(Train): 0.26886898279190063; L(Test): 0.23779457807540894\n",
      "Epoch 9445/10000: L(Train): 0.2633650600910187; L(Test): 0.2389259934425354\n",
      "Epoch 9446/10000: L(Train): 0.25353342294692993; L(Test): 0.24032363295555115\n",
      "Epoch 9447/10000: L(Train): 0.26246243715286255; L(Test): 0.241637721657753\n",
      "Epoch 9448/10000: L(Train): 0.2590862214565277; L(Test): 0.24185486137866974\n",
      "Epoch 9449/10000: L(Train): 0.2784789502620697; L(Test): 0.24336186051368713\n",
      "Epoch 9450/10000: L(Train): 0.27664247155189514; L(Test): 0.2431275099515915\n",
      "Epoch 9451/10000: L(Train): 0.27421286702156067; L(Test): 0.25129005312919617\n",
      "Epoch 9452/10000: L(Train): 0.27743542194366455; L(Test): 0.24618369340896606\n",
      "Epoch 9453/10000: L(Train): 0.2764134109020233; L(Test): 0.24467581510543823\n",
      "Epoch 9454/10000: L(Train): 0.27078336477279663; L(Test): 0.2490295171737671\n",
      "Epoch 9455/10000: L(Train): 0.2606394588947296; L(Test): 0.24437613785266876\n",
      "Epoch 9456/10000: L(Train): 0.2682154178619385; L(Test): 0.24628420174121857\n",
      "Epoch 9457/10000: L(Train): 0.2731117904186249; L(Test): 0.24643494188785553\n",
      "Epoch 9458/10000: L(Train): 0.26928776502609253; L(Test): 0.2445831149816513\n",
      "Epoch 9459/10000: L(Train): 0.26191964745521545; L(Test): 0.24122324585914612\n",
      "Epoch 9460/10000: L(Train): 0.2526387572288513; L(Test): 0.24519066512584686\n",
      "Epoch 9461/10000: L(Train): 0.27603110671043396; L(Test): 0.24436704814434052\n",
      "Epoch 9462/10000: L(Train): 0.27084454894065857; L(Test): 0.24246247112751007\n",
      "Epoch 9463/10000: L(Train): 0.26593562960624695; L(Test): 0.242280051112175\n",
      "Epoch 9464/10000: L(Train): 0.26214075088500977; L(Test): 0.2418937385082245\n",
      "Epoch 9465/10000: L(Train): 0.26315826177597046; L(Test): 0.24101896584033966\n",
      "Epoch 9466/10000: L(Train): 0.2595641314983368; L(Test): 0.24008911848068237\n",
      "Epoch 9467/10000: L(Train): 0.2581659257411957; L(Test): 0.24048782885074615\n",
      "Epoch 9468/10000: L(Train): 0.27097031474113464; L(Test): 0.24006414413452148\n",
      "Epoch 9469/10000: L(Train): 0.26604002714157104; L(Test): 0.2402767390012741\n",
      "Epoch 9470/10000: L(Train): 0.261375367641449; L(Test): 0.24005818367004395\n",
      "Epoch 9471/10000: L(Train): 0.2655651867389679; L(Test): 0.23847608268260956\n",
      "Epoch 9472/10000: L(Train): 0.2666192650794983; L(Test): 0.23757962882518768\n",
      "Epoch 9473/10000: L(Train): 0.24623917043209076; L(Test): 0.2397495061159134\n",
      "Epoch 9474/10000: L(Train): 0.2665441632270813; L(Test): 0.23870474100112915\n",
      "Epoch 9475/10000: L(Train): 0.25183016061782837; L(Test): 0.23696386814117432\n",
      "Epoch 9476/10000: L(Train): 0.25173020362854004; L(Test): 0.2389952540397644\n",
      "Epoch 9477/10000: L(Train): 0.26223546266555786; L(Test): 0.23903650045394897\n",
      "Epoch 9478/10000: L(Train): 0.2550375759601593; L(Test): 0.23816409707069397\n",
      "Epoch 9479/10000: L(Train): 0.2446499466896057; L(Test): 0.2374672144651413\n",
      "Epoch 9480/10000: L(Train): 0.2586058974266052; L(Test): 0.238373264670372\n",
      "Epoch 9481/10000: L(Train): 0.2613988220691681; L(Test): 0.2371789962053299\n",
      "Epoch 9482/10000: L(Train): 0.2669607698917389; L(Test): 0.23601675033569336\n",
      "Epoch 9483/10000: L(Train): 0.26748961210250854; L(Test): 0.23609724640846252\n",
      "Epoch 9484/10000: L(Train): 0.2549636662006378; L(Test): 0.2372940480709076\n",
      "Epoch 9485/10000: L(Train): 0.25628530979156494; L(Test): 0.23647667467594147\n",
      "Epoch 9486/10000: L(Train): 0.2520805299282074; L(Test): 0.23694783449172974\n",
      "Epoch 9487/10000: L(Train): 0.275310218334198; L(Test): 0.2379189282655716\n",
      "Epoch 9488/10000: L(Train): 0.2786348760128021; L(Test): 0.23662585020065308\n",
      "Epoch 9489/10000: L(Train): 0.2624596953392029; L(Test): 0.23667071759700775\n",
      "Epoch 9490/10000: L(Train): 0.25596240162849426; L(Test): 0.23647722601890564\n",
      "Epoch 9491/10000: L(Train): 0.25160303711891174; L(Test): 0.2362886518239975\n",
      "Epoch 9492/10000: L(Train): 0.27761465311050415; L(Test): 0.23544804751873016\n",
      "Epoch 9493/10000: L(Train): 0.2622387707233429; L(Test): 0.2346133142709732\n",
      "Epoch 9494/10000: L(Train): 0.24562963843345642; L(Test): 0.2358141988515854\n",
      "Epoch 9495/10000: L(Train): 0.2637377977371216; L(Test): 0.23662550747394562\n",
      "Epoch 9496/10000: L(Train): 0.2632960081100464; L(Test): 0.23514728248119354\n",
      "Epoch 9497/10000: L(Train): 0.2617344260215759; L(Test): 0.23540833592414856\n",
      "Epoch 9498/10000: L(Train): 0.2511608898639679; L(Test): 0.2364058792591095\n",
      "Epoch 9499/10000: L(Train): 0.26563000679016113; L(Test): 0.24525569379329681\n",
      "Epoch 9500/10000: L(Train): 0.2705540955066681; L(Test): 0.24608474969863892\n",
      "Epoch 9501/10000: L(Train): 0.25783103704452515; L(Test): 0.24544832110404968\n",
      "Epoch 9502/10000: L(Train): 0.2646249234676361; L(Test): 0.24946600198745728\n",
      "Epoch 9503/10000: L(Train): 0.259820818901062; L(Test): 0.2515685558319092\n",
      "Epoch 9504/10000: L(Train): 0.2746489346027374; L(Test): 0.2505913972854614\n",
      "Epoch 9505/10000: L(Train): 0.2760573625564575; L(Test): 0.24716529250144958\n",
      "Epoch 9506/10000: L(Train): 0.2540019452571869; L(Test): 0.2462027370929718\n",
      "Epoch 9507/10000: L(Train): 0.26421594619750977; L(Test): 0.249686136841774\n",
      "Epoch 9508/10000: L(Train): 0.26844915747642517; L(Test): 0.24983566999435425\n",
      "Epoch 9509/10000: L(Train): 0.2798757255077362; L(Test): 0.2463376373052597\n",
      "Epoch 9510/10000: L(Train): 0.2794341444969177; L(Test): 0.24783800542354584\n",
      "Epoch 9511/10000: L(Train): 0.2748834192752838; L(Test): 0.24888275563716888\n",
      "Epoch 9512/10000: L(Train): 0.26684507727622986; L(Test): 0.2480769157409668\n",
      "Epoch 9513/10000: L(Train): 0.2683285176753998; L(Test): 0.2471865713596344\n",
      "Epoch 9514/10000: L(Train): 0.2795635461807251; L(Test): 0.24814529716968536\n",
      "Epoch 9515/10000: L(Train): 0.28533822298049927; L(Test): 0.24732057750225067\n",
      "Epoch 9516/10000: L(Train): 0.265968382358551; L(Test): 0.2483893185853958\n",
      "Epoch 9517/10000: L(Train): 0.26977771520614624; L(Test): 0.2481459081172943\n",
      "Epoch 9518/10000: L(Train): 0.2790672779083252; L(Test): 0.24617771804332733\n",
      "Epoch 9519/10000: L(Train): 0.26547399163246155; L(Test): 0.24694938957691193\n",
      "Epoch 9520/10000: L(Train): 0.25276878476142883; L(Test): 0.24666233360767365\n",
      "Epoch 9521/10000: L(Train): 0.2766522467136383; L(Test): 0.24601595103740692\n",
      "Epoch 9522/10000: L(Train): 0.25908803939819336; L(Test): 0.24435681104660034\n",
      "Epoch 9523/10000: L(Train): 0.26923060417175293; L(Test): 0.24413034319877625\n",
      "Epoch 9524/10000: L(Train): 0.259583055973053; L(Test): 0.24367927014827728\n",
      "Epoch 9525/10000: L(Train): 0.26272347569465637; L(Test): 0.24212856590747833\n",
      "Epoch 9526/10000: L(Train): 0.2549106180667877; L(Test): 0.24123933911323547\n",
      "Epoch 9527/10000: L(Train): 0.2694737911224365; L(Test): 0.24151214957237244\n",
      "Epoch 9528/10000: L(Train): 0.2581234276294708; L(Test): 0.24087531864643097\n",
      "Epoch 9529/10000: L(Train): 0.2544195353984833; L(Test): 0.2403053641319275\n",
      "Epoch 9530/10000: L(Train): 0.25698286294937134; L(Test): 0.24003683030605316\n",
      "Epoch 9531/10000: L(Train): 0.25440075993537903; L(Test): 0.2404589056968689\n",
      "Epoch 9532/10000: L(Train): 0.24949634075164795; L(Test): 0.24023394286632538\n",
      "Epoch 9533/10000: L(Train): 0.27050158381462097; L(Test): 0.2398117184638977\n",
      "Epoch 9534/10000: L(Train): 0.27398309111595154; L(Test): 0.23903650045394897\n",
      "Epoch 9535/10000: L(Train): 0.2729531228542328; L(Test): 0.2387433499097824\n",
      "Epoch 9536/10000: L(Train): 0.24952144920825958; L(Test): 0.2375440150499344\n",
      "Epoch 9537/10000: L(Train): 0.26353806257247925; L(Test): 0.23713095486164093\n",
      "Epoch 9538/10000: L(Train): 0.2675144374370575; L(Test): 0.2366301566362381\n",
      "Epoch 9539/10000: L(Train): 0.2559899091720581; L(Test): 0.23709161579608917\n",
      "Epoch 9540/10000: L(Train): 0.26680341362953186; L(Test): 0.23740752041339874\n",
      "Epoch 9541/10000: L(Train): 0.26311835646629333; L(Test): 0.2387206256389618\n",
      "Epoch 9542/10000: L(Train): 0.2549971640110016; L(Test): 0.2393456995487213\n",
      "Epoch 9543/10000: L(Train): 0.26196858286857605; L(Test): 0.23938339948654175\n",
      "Epoch 9544/10000: L(Train): 0.25670647621154785; L(Test): 0.24020102620124817\n",
      "Epoch 9545/10000: L(Train): 0.269929438829422; L(Test): 0.23920071125030518\n",
      "Epoch 9546/10000: L(Train): 0.25453877449035645; L(Test): 0.2424149364233017\n",
      "Epoch 9547/10000: L(Train): 0.26633962988853455; L(Test): 0.2417243868112564\n",
      "Epoch 9548/10000: L(Train): 0.25883159041404724; L(Test): 0.24142085015773773\n",
      "Epoch 9549/10000: L(Train): 0.26061850786209106; L(Test): 0.24413560330867767\n",
      "Epoch 9550/10000: L(Train): 0.2735442817211151; L(Test): 0.24073556065559387\n",
      "Epoch 9551/10000: L(Train): 0.2821623384952545; L(Test): 0.2389187514781952\n",
      "Epoch 9552/10000: L(Train): 0.25788816809654236; L(Test): 0.23966090381145477\n",
      "Epoch 9553/10000: L(Train): 0.262857049703598; L(Test): 0.2431107759475708\n",
      "Epoch 9554/10000: L(Train): 0.2785964608192444; L(Test): 0.23926140367984772\n",
      "Epoch 9555/10000: L(Train): 0.2649618089199066; L(Test): 0.2388225942850113\n",
      "Epoch 9556/10000: L(Train): 0.26342469453811646; L(Test): 0.23948730528354645\n",
      "Epoch 9557/10000: L(Train): 0.2806442975997925; L(Test): 0.24138648808002472\n",
      "Epoch 9558/10000: L(Train): 0.2744876444339752; L(Test): 0.2411130666732788\n",
      "Epoch 9559/10000: L(Train): 0.26048415899276733; L(Test): 0.2387964278459549\n",
      "Epoch 9560/10000: L(Train): 0.26408651471138; L(Test): 0.2388879358768463\n",
      "Epoch 9561/10000: L(Train): 0.2617189586162567; L(Test): 0.23958028852939606\n",
      "Epoch 9562/10000: L(Train): 0.2561509311199188; L(Test): 0.23977942764759064\n",
      "Epoch 9563/10000: L(Train): 0.24407663941383362; L(Test): 0.23848401010036469\n",
      "Epoch 9564/10000: L(Train): 0.26723429560661316; L(Test): 0.2386065274477005\n",
      "Epoch 9565/10000: L(Train): 0.268519788980484; L(Test): 0.2383214831352234\n",
      "Epoch 9566/10000: L(Train): 0.25345510244369507; L(Test): 0.2377050369977951\n",
      "Epoch 9567/10000: L(Train): 0.2572210133075714; L(Test): 0.23883146047592163\n",
      "Epoch 9568/10000: L(Train): 0.25458312034606934; L(Test): 0.2368556708097458\n",
      "Epoch 9569/10000: L(Train): 0.26517611742019653; L(Test): 0.23887892067432404\n",
      "Epoch 9570/10000: L(Train): 0.25263604521751404; L(Test): 0.23765741288661957\n",
      "Epoch 9571/10000: L(Train): 0.25958681106567383; L(Test): 0.23786227405071259\n",
      "Epoch 9572/10000: L(Train): 0.26354700326919556; L(Test): 0.23921728134155273\n",
      "Epoch 9573/10000: L(Train): 0.2758987545967102; L(Test): 0.23698756098747253\n",
      "Epoch 9574/10000: L(Train): 0.252959281206131; L(Test): 0.2383040338754654\n",
      "Epoch 9575/10000: L(Train): 0.2646014392375946; L(Test): 0.23747314512729645\n",
      "Epoch 9576/10000: L(Train): 0.2569980025291443; L(Test): 0.23743616044521332\n",
      "Epoch 9577/10000: L(Train): 0.26251599192619324; L(Test): 0.23690058290958405\n",
      "Epoch 9578/10000: L(Train): 0.24901054799556732; L(Test): 0.23693962395191193\n",
      "Epoch 9579/10000: L(Train): 0.26193803548812866; L(Test): 0.23859255015850067\n",
      "Epoch 9580/10000: L(Train): 0.26159173250198364; L(Test): 0.2377232015132904\n",
      "Epoch 9581/10000: L(Train): 0.26452404260635376; L(Test): 0.23709172010421753\n",
      "Epoch 9582/10000: L(Train): 0.25750628113746643; L(Test): 0.23710648715496063\n",
      "Epoch 9583/10000: L(Train): 0.27857354283332825; L(Test): 0.23765583336353302\n",
      "Epoch 9584/10000: L(Train): 0.26204487681388855; L(Test): 0.23818852007389069\n",
      "Epoch 9585/10000: L(Train): 0.26333561539649963; L(Test): 0.2384287267923355\n",
      "Epoch 9586/10000: L(Train): 0.267665296792984; L(Test): 0.2383151799440384\n",
      "Epoch 9587/10000: L(Train): 0.26332467794418335; L(Test): 0.23804697394371033\n",
      "Epoch 9588/10000: L(Train): 0.27742722630500793; L(Test): 0.23823222517967224\n",
      "Epoch 9589/10000: L(Train): 0.26000547409057617; L(Test): 0.23657497763633728\n",
      "Epoch 9590/10000: L(Train): 0.2534043788909912; L(Test): 0.23722834885120392\n",
      "Epoch 9591/10000: L(Train): 0.24373432993888855; L(Test): 0.23725399374961853\n",
      "Epoch 9592/10000: L(Train): 0.26556625962257385; L(Test): 0.23775072395801544\n",
      "Epoch 9593/10000: L(Train): 0.2611337900161743; L(Test): 0.23766885697841644\n",
      "Epoch 9594/10000: L(Train): 0.26002711057662964; L(Test): 0.23755908012390137\n",
      "Epoch 9595/10000: L(Train): 0.2558816373348236; L(Test): 0.23654094338417053\n",
      "Epoch 9596/10000: L(Train): 0.26145434379577637; L(Test): 0.23767930269241333\n",
      "Epoch 9597/10000: L(Train): 0.25209370255470276; L(Test): 0.2402387112379074\n",
      "Epoch 9598/10000: L(Train): 0.2604220509529114; L(Test): 0.2390165627002716\n",
      "Epoch 9599/10000: L(Train): 0.2460576593875885; L(Test): 0.23773129284381866\n",
      "Epoch 9600/10000: L(Train): 0.25851649045944214; L(Test): 0.23966485261917114\n",
      "Epoch 9601/10000: L(Train): 0.2786886692047119; L(Test): 0.23656399548053741\n",
      "Epoch 9602/10000: L(Train): 0.2532796561717987; L(Test): 0.2379295974969864\n",
      "Epoch 9603/10000: L(Train): 0.24687246978282928; L(Test): 0.2382480800151825\n",
      "Epoch 9604/10000: L(Train): 0.27990150451660156; L(Test): 0.23597651720046997\n",
      "Epoch 9605/10000: L(Train): 0.2724882960319519; L(Test): 0.2364989072084427\n",
      "Epoch 9606/10000: L(Train): 0.24917015433311462; L(Test): 0.236474871635437\n",
      "Epoch 9607/10000: L(Train): 0.26445990800857544; L(Test): 0.23608951270580292\n",
      "Epoch 9608/10000: L(Train): 0.2538100779056549; L(Test): 0.2370510995388031\n",
      "Epoch 9609/10000: L(Train): 0.26326698064804077; L(Test): 0.2376999706029892\n",
      "Epoch 9610/10000: L(Train): 0.2794412672519684; L(Test): 0.23503342270851135\n",
      "Epoch 9611/10000: L(Train): 0.26002615690231323; L(Test): 0.23583808541297913\n",
      "Epoch 9612/10000: L(Train): 0.24628081917762756; L(Test): 0.23626086115837097\n",
      "Epoch 9613/10000: L(Train): 0.25318169593811035; L(Test): 0.235911026597023\n",
      "Epoch 9614/10000: L(Train): 0.2599247992038727; L(Test): 0.23489071428775787\n",
      "Epoch 9615/10000: L(Train): 0.2577868700027466; L(Test): 0.2357260286808014\n",
      "Epoch 9616/10000: L(Train): 0.2604207396507263; L(Test): 0.2355220466852188\n",
      "Epoch 9617/10000: L(Train): 0.26048406958580017; L(Test): 0.2355778068304062\n",
      "Epoch 9618/10000: L(Train): 0.262052059173584; L(Test): 0.23561029136180878\n",
      "Epoch 9619/10000: L(Train): 0.24470359086990356; L(Test): 0.23527206480503082\n",
      "Epoch 9620/10000: L(Train): 0.2614992558956146; L(Test): 0.23543687164783478\n",
      "Epoch 9621/10000: L(Train): 0.2763909101486206; L(Test): 0.23476073145866394\n",
      "Epoch 9622/10000: L(Train): 0.25054410099983215; L(Test): 0.23665502667427063\n",
      "Epoch 9623/10000: L(Train): 0.26169097423553467; L(Test): 0.2361624836921692\n",
      "Epoch 9624/10000: L(Train): 0.24657967686653137; L(Test): 0.23523429036140442\n",
      "Epoch 9625/10000: L(Train): 0.2620963752269745; L(Test): 0.2356438785791397\n",
      "Epoch 9626/10000: L(Train): 0.2646036446094513; L(Test): 0.23612438142299652\n",
      "Epoch 9627/10000: L(Train): 0.2723711431026459; L(Test): 0.23583154380321503\n",
      "Epoch 9628/10000: L(Train): 0.25641804933547974; L(Test): 0.23726235330104828\n",
      "Epoch 9629/10000: L(Train): 0.2533334791660309; L(Test): 0.23556260764598846\n",
      "Epoch 9630/10000: L(Train): 0.26412859559059143; L(Test): 0.2361050397157669\n",
      "Epoch 9631/10000: L(Train): 0.2643173933029175; L(Test): 0.23569536209106445\n",
      "Epoch 9632/10000: L(Train): 0.26752689480781555; L(Test): 0.23609641194343567\n",
      "Epoch 9633/10000: L(Train): 0.272376149892807; L(Test): 0.23555417358875275\n",
      "Epoch 9634/10000: L(Train): 0.24314755201339722; L(Test): 0.2351359874010086\n",
      "Epoch 9635/10000: L(Train): 0.27135002613067627; L(Test): 0.23633985221385956\n",
      "Epoch 9636/10000: L(Train): 0.26937755942344666; L(Test): 0.2370140105485916\n",
      "Epoch 9637/10000: L(Train): 0.259455144405365; L(Test): 0.24042272567749023\n",
      "Epoch 9638/10000: L(Train): 0.2703801393508911; L(Test): 0.23622718453407288\n",
      "Epoch 9639/10000: L(Train): 0.2728727161884308; L(Test): 0.2390500158071518\n",
      "Epoch 9640/10000: L(Train): 0.25862544775009155; L(Test): 0.2365381121635437\n",
      "Epoch 9641/10000: L(Train): 0.27410703897476196; L(Test): 0.23807041347026825\n",
      "Epoch 9642/10000: L(Train): 0.2623003423213959; L(Test): 0.24219340085983276\n",
      "Epoch 9643/10000: L(Train): 0.2688734531402588; L(Test): 0.2368595153093338\n",
      "Epoch 9644/10000: L(Train): 0.25858259201049805; L(Test): 0.23700909316539764\n",
      "Epoch 9645/10000: L(Train): 0.2547556161880493; L(Test): 0.23565442860126495\n",
      "Epoch 9646/10000: L(Train): 0.26521676778793335; L(Test): 0.23601016402244568\n",
      "Epoch 9647/10000: L(Train): 0.2598606050014496; L(Test): 0.23733747005462646\n",
      "Epoch 9648/10000: L(Train): 0.26499125361442566; L(Test): 0.23577459156513214\n",
      "Epoch 9649/10000: L(Train): 0.2558412551879883; L(Test): 0.23696169257164001\n",
      "Epoch 9650/10000: L(Train): 0.26407933235168457; L(Test): 0.2416655570268631\n",
      "Epoch 9651/10000: L(Train): 0.2622435986995697; L(Test): 0.24903222918510437\n",
      "Epoch 9652/10000: L(Train): 0.27192139625549316; L(Test): 0.24764280021190643\n",
      "Epoch 9653/10000: L(Train): 0.275790274143219; L(Test): 0.25380122661590576\n",
      "Epoch 9654/10000: L(Train): 0.2698811888694763; L(Test): 0.25971248745918274\n",
      "Epoch 9655/10000: L(Train): 0.29516997933387756; L(Test): 0.269342839717865\n",
      "Epoch 9656/10000: L(Train): 0.2849862277507782; L(Test): 0.27533432841300964\n",
      "Epoch 9657/10000: L(Train): 0.28717419505119324; L(Test): 0.2711986005306244\n",
      "Epoch 9658/10000: L(Train): 0.29847410321235657; L(Test): 0.26863500475883484\n",
      "Epoch 9659/10000: L(Train): 0.29561448097229004; L(Test): 0.2727739214897156\n",
      "Epoch 9660/10000: L(Train): 0.28674206137657166; L(Test): 0.268930047750473\n",
      "Epoch 9661/10000: L(Train): 0.2945883572101593; L(Test): 0.2659076452255249\n",
      "Epoch 9662/10000: L(Train): 0.296772837638855; L(Test): 0.26580578088760376\n",
      "Epoch 9663/10000: L(Train): 0.2739374041557312; L(Test): 0.26866644620895386\n",
      "Epoch 9664/10000: L(Train): 0.2910180985927582; L(Test): 0.2654283046722412\n",
      "Epoch 9665/10000: L(Train): 0.2688443958759308; L(Test): 0.2686539888381958\n",
      "Epoch 9666/10000: L(Train): 0.2846575677394867; L(Test): 0.26784461736679077\n",
      "Epoch 9667/10000: L(Train): 0.2788185775279999; L(Test): 0.2633153200149536\n",
      "Epoch 9668/10000: L(Train): 0.2813068926334381; L(Test): 0.26120948791503906\n",
      "Epoch 9669/10000: L(Train): 0.2592504918575287; L(Test): 0.2628406584262848\n",
      "Epoch 9670/10000: L(Train): 0.27119287848472595; L(Test): 0.26293081045150757\n",
      "Epoch 9671/10000: L(Train): 0.283346027135849; L(Test): 0.2631846070289612\n",
      "Epoch 9672/10000: L(Train): 0.27537524700164795; L(Test): 0.25940680503845215\n",
      "Epoch 9673/10000: L(Train): 0.26372966170310974; L(Test): 0.25743886828422546\n",
      "Epoch 9674/10000: L(Train): 0.2708667516708374; L(Test): 0.25847798585891724\n",
      "Epoch 9675/10000: L(Train): 0.2763743996620178; L(Test): 0.25801023840904236\n",
      "Epoch 9676/10000: L(Train): 0.2676186263561249; L(Test): 0.2575744688510895\n",
      "Epoch 9677/10000: L(Train): 0.29488375782966614; L(Test): 0.25704076886177063\n",
      "Epoch 9678/10000: L(Train): 0.2738954424858093; L(Test): 0.25531288981437683\n",
      "Epoch 9679/10000: L(Train): 0.26376086473464966; L(Test): 0.2540142238140106\n",
      "Epoch 9680/10000: L(Train): 0.27366411685943604; L(Test): 0.2537033259868622\n",
      "Epoch 9681/10000: L(Train): 0.2729615867137909; L(Test): 0.2521504759788513\n",
      "Epoch 9682/10000: L(Train): 0.28046914935112; L(Test): 0.2495124191045761\n",
      "Epoch 9683/10000: L(Train): 0.2628887891769409; L(Test): 0.248030886054039\n",
      "Epoch 9684/10000: L(Train): 0.2709503173828125; L(Test): 0.24818375706672668\n",
      "Epoch 9685/10000: L(Train): 0.2607419490814209; L(Test): 0.24756987392902374\n",
      "Epoch 9686/10000: L(Train): 0.2592211663722992; L(Test): 0.2466513067483902\n",
      "Epoch 9687/10000: L(Train): 0.2746296525001526; L(Test): 0.24781343340873718\n",
      "Epoch 9688/10000: L(Train): 0.2441646009683609; L(Test): 0.249782994389534\n",
      "Epoch 9689/10000: L(Train): 0.2639707326889038; L(Test): 0.25161805748939514\n",
      "Epoch 9690/10000: L(Train): 0.26847389340400696; L(Test): 0.25025078654289246\n",
      "Epoch 9691/10000: L(Train): 0.26007741689682007; L(Test): 0.24950352311134338\n",
      "Epoch 9692/10000: L(Train): 0.2717798352241516; L(Test): 0.24894289672374725\n",
      "Epoch 9693/10000: L(Train): 0.2661064565181732; L(Test): 0.2479182779788971\n",
      "Epoch 9694/10000: L(Train): 0.27180802822113037; L(Test): 0.24810649454593658\n",
      "Epoch 9695/10000: L(Train): 0.2666783332824707; L(Test): 0.24701792001724243\n",
      "Epoch 9696/10000: L(Train): 0.26088887453079224; L(Test): 0.24595896899700165\n",
      "Epoch 9697/10000: L(Train): 0.2644002437591553; L(Test): 0.24605026841163635\n",
      "Epoch 9698/10000: L(Train): 0.27364522218704224; L(Test): 0.24611422419548035\n",
      "Epoch 9699/10000: L(Train): 0.26327091455459595; L(Test): 0.24427734315395355\n",
      "Epoch 9700/10000: L(Train): 0.27745547890663147; L(Test): 0.2428773194551468\n",
      "Epoch 9701/10000: L(Train): 0.2504209280014038; L(Test): 0.24239522218704224\n",
      "Epoch 9702/10000: L(Train): 0.2736513614654541; L(Test): 0.2422347217798233\n",
      "Epoch 9703/10000: L(Train): 0.2686871886253357; L(Test): 0.2421063780784607\n",
      "Epoch 9704/10000: L(Train): 0.26981765031814575; L(Test): 0.24168939888477325\n",
      "Epoch 9705/10000: L(Train): 0.26078319549560547; L(Test): 0.24126119911670685\n",
      "Epoch 9706/10000: L(Train): 0.26892444491386414; L(Test): 0.24189327657222748\n",
      "Epoch 9707/10000: L(Train): 0.26170870661735535; L(Test): 0.24167904257774353\n",
      "Epoch 9708/10000: L(Train): 0.27014636993408203; L(Test): 0.24061673879623413\n",
      "Epoch 9709/10000: L(Train): 0.25041845440864563; L(Test): 0.24098274111747742\n",
      "Epoch 9710/10000: L(Train): 0.25707876682281494; L(Test): 0.2412102222442627\n",
      "Epoch 9711/10000: L(Train): 0.27418091893196106; L(Test): 0.24042999744415283\n",
      "Epoch 9712/10000: L(Train): 0.2651251554489136; L(Test): 0.23975418508052826\n",
      "Epoch 9713/10000: L(Train): 0.2866804003715515; L(Test): 0.2403709590435028\n",
      "Epoch 9714/10000: L(Train): 0.2521143853664398; L(Test): 0.24050091207027435\n",
      "Epoch 9715/10000: L(Train): 0.26410529017448425; L(Test): 0.23795673251152039\n",
      "Epoch 9716/10000: L(Train): 0.2586422264575958; L(Test): 0.23895052075386047\n",
      "Epoch 9717/10000: L(Train): 0.26407042145729065; L(Test): 0.23923848569393158\n",
      "Epoch 9718/10000: L(Train): 0.2515591084957123; L(Test): 0.2375384271144867\n",
      "Epoch 9719/10000: L(Train): 0.2432376742362976; L(Test): 0.2371140569448471\n",
      "Epoch 9720/10000: L(Train): 0.26961636543273926; L(Test): 0.2384198158979416\n",
      "Epoch 9721/10000: L(Train): 0.2559782862663269; L(Test): 0.23733952641487122\n",
      "Epoch 9722/10000: L(Train): 0.2581799030303955; L(Test): 0.23836660385131836\n",
      "Epoch 9723/10000: L(Train): 0.25895223021507263; L(Test): 0.23788082599639893\n",
      "Epoch 9724/10000: L(Train): 0.2572507858276367; L(Test): 0.2369810789823532\n",
      "Epoch 9725/10000: L(Train): 0.26077261567115784; L(Test): 0.23712722957134247\n",
      "Epoch 9726/10000: L(Train): 0.25744473934173584; L(Test): 0.2378697544336319\n",
      "Epoch 9727/10000: L(Train): 0.27439066767692566; L(Test): 0.23707719147205353\n",
      "Epoch 9728/10000: L(Train): 0.2502155303955078; L(Test): 0.23749691247940063\n",
      "Epoch 9729/10000: L(Train): 0.25389108061790466; L(Test): 0.2387559711933136\n",
      "Epoch 9730/10000: L(Train): 0.2702099680900574; L(Test): 0.23717834055423737\n",
      "Epoch 9731/10000: L(Train): 0.2734777331352234; L(Test): 0.2372005581855774\n",
      "Epoch 9732/10000: L(Train): 0.2615564167499542; L(Test): 0.23749083280563354\n",
      "Epoch 9733/10000: L(Train): 0.27057525515556335; L(Test): 0.23608151078224182\n",
      "Epoch 9734/10000: L(Train): 0.2610054016113281; L(Test): 0.23663194477558136\n",
      "Epoch 9735/10000: L(Train): 0.2482134997844696; L(Test): 0.2383786141872406\n",
      "Epoch 9736/10000: L(Train): 0.24762830138206482; L(Test): 0.23644904792308807\n",
      "Epoch 9737/10000: L(Train): 0.2671298384666443; L(Test): 0.23653370141983032\n",
      "Epoch 9738/10000: L(Train): 0.24983136355876923; L(Test): 0.23751874268054962\n",
      "Epoch 9739/10000: L(Train): 0.2673942744731903; L(Test): 0.23664847016334534\n",
      "Epoch 9740/10000: L(Train): 0.2552270293235779; L(Test): 0.23660516738891602\n",
      "Epoch 9741/10000: L(Train): 0.2597992718219757; L(Test): 0.23759987950325012\n",
      "Epoch 9742/10000: L(Train): 0.25729691982269287; L(Test): 0.2380865216255188\n",
      "Epoch 9743/10000: L(Train): 0.26453250646591187; L(Test): 0.2398448884487152\n",
      "Epoch 9744/10000: L(Train): 0.26514625549316406; L(Test): 0.23863326013088226\n",
      "Epoch 9745/10000: L(Train): 0.2794671356678009; L(Test): 0.23896151781082153\n",
      "Epoch 9746/10000: L(Train): 0.24994932115077972; L(Test): 0.2391103357076645\n",
      "Epoch 9747/10000: L(Train): 0.24283525347709656; L(Test): 0.23823562264442444\n",
      "Epoch 9748/10000: L(Train): 0.2636867165565491; L(Test): 0.237823948264122\n",
      "Epoch 9749/10000: L(Train): 0.25844860076904297; L(Test): 0.2389955371618271\n",
      "Epoch 9750/10000: L(Train): 0.2522212564945221; L(Test): 0.2394493967294693\n",
      "Epoch 9751/10000: L(Train): 0.2658427655696869; L(Test): 0.23706777393817902\n",
      "Epoch 9752/10000: L(Train): 0.27122801542282104; L(Test): 0.235771045088768\n",
      "Epoch 9753/10000: L(Train): 0.2442292422056198; L(Test): 0.2384147197008133\n",
      "Epoch 9754/10000: L(Train): 0.2552419900894165; L(Test): 0.23763403296470642\n",
      "Epoch 9755/10000: L(Train): 0.2510189712047577; L(Test): 0.23545485734939575\n",
      "Epoch 9756/10000: L(Train): 0.25263261795043945; L(Test): 0.2363818883895874\n",
      "Epoch 9757/10000: L(Train): 0.26638299226760864; L(Test): 0.23822085559368134\n",
      "Epoch 9758/10000: L(Train): 0.2569219172000885; L(Test): 0.23795102536678314\n",
      "Epoch 9759/10000: L(Train): 0.2417726218700409; L(Test): 0.23703375458717346\n",
      "Epoch 9760/10000: L(Train): 0.2547713816165924; L(Test): 0.23707956075668335\n",
      "Epoch 9761/10000: L(Train): 0.26244834065437317; L(Test): 0.2381834089756012\n",
      "Epoch 9762/10000: L(Train): 0.2482355833053589; L(Test): 0.2373971939086914\n",
      "Epoch 9763/10000: L(Train): 0.24547284841537476; L(Test): 0.2373044639825821\n",
      "Epoch 9764/10000: L(Train): 0.2554164230823517; L(Test): 0.2372046411037445\n",
      "Epoch 9765/10000: L(Train): 0.2579130232334137; L(Test): 0.23805536329746246\n",
      "Epoch 9766/10000: L(Train): 0.26736706495285034; L(Test): 0.23760448396205902\n",
      "Epoch 9767/10000: L(Train): 0.2649956941604614; L(Test): 0.23733483254909515\n",
      "Epoch 9768/10000: L(Train): 0.25245973467826843; L(Test): 0.23643311858177185\n",
      "Epoch 9769/10000: L(Train): 0.2591564655303955; L(Test): 0.23853813111782074\n",
      "Epoch 9770/10000: L(Train): 0.25557008385658264; L(Test): 0.23849141597747803\n",
      "Epoch 9771/10000: L(Train): 0.2536342144012451; L(Test): 0.23685196042060852\n",
      "Epoch 9772/10000: L(Train): 0.2653847634792328; L(Test): 0.23805071413516998\n",
      "Epoch 9773/10000: L(Train): 0.2571942210197449; L(Test): 0.23834973573684692\n",
      "Epoch 9774/10000: L(Train): 0.2616332769393921; L(Test): 0.23716379702091217\n",
      "Epoch 9775/10000: L(Train): 0.2606986165046692; L(Test): 0.23678363859653473\n",
      "Epoch 9776/10000: L(Train): 0.257931113243103; L(Test): 0.2363080531358719\n",
      "Epoch 9777/10000: L(Train): 0.27500733733177185; L(Test): 0.23578189313411713\n",
      "Epoch 9778/10000: L(Train): 0.2373887449502945; L(Test): 0.2365565448999405\n",
      "Epoch 9779/10000: L(Train): 0.25568342208862305; L(Test): 0.23824124038219452\n",
      "Epoch 9780/10000: L(Train): 0.2616014778614044; L(Test): 0.23910032212734222\n",
      "Epoch 9781/10000: L(Train): 0.2590160369873047; L(Test): 0.23738859593868256\n",
      "Epoch 9782/10000: L(Train): 0.25402796268463135; L(Test): 0.23526081442832947\n",
      "Epoch 9783/10000: L(Train): 0.25374922156333923; L(Test): 0.23569440841674805\n",
      "Epoch 9784/10000: L(Train): 0.266119122505188; L(Test): 0.23565518856048584\n",
      "Epoch 9785/10000: L(Train): 0.2519037425518036; L(Test): 0.23940539360046387\n",
      "Epoch 9786/10000: L(Train): 0.26386716961860657; L(Test): 0.24174092710018158\n",
      "Epoch 9787/10000: L(Train): 0.2556551992893219; L(Test): 0.24237698316574097\n",
      "Epoch 9788/10000: L(Train): 0.2527938187122345; L(Test): 0.24411305785179138\n",
      "Epoch 9789/10000: L(Train): 0.2703906297683716; L(Test): 0.24478478729724884\n",
      "Epoch 9790/10000: L(Train): 0.2730059325695038; L(Test): 0.2436036318540573\n",
      "Epoch 9791/10000: L(Train): 0.266541451215744; L(Test): 0.24382567405700684\n",
      "Epoch 9792/10000: L(Train): 0.281779944896698; L(Test): 0.2437366545200348\n",
      "Epoch 9793/10000: L(Train): 0.25695323944091797; L(Test): 0.2425498068332672\n",
      "Epoch 9794/10000: L(Train): 0.2493147850036621; L(Test): 0.243741974234581\n",
      "Epoch 9795/10000: L(Train): 0.2780321538448334; L(Test): 0.24240180850028992\n",
      "Epoch 9796/10000: L(Train): 0.2483028769493103; L(Test): 0.2415073961019516\n",
      "Epoch 9797/10000: L(Train): 0.2784830331802368; L(Test): 0.24378937482833862\n",
      "Epoch 9798/10000: L(Train): 0.26303964853286743; L(Test): 0.24358874559402466\n",
      "Epoch 9799/10000: L(Train): 0.2718614637851715; L(Test): 0.24082684516906738\n",
      "Epoch 9800/10000: L(Train): 0.26258203387260437; L(Test): 0.24226659536361694\n",
      "Epoch 9801/10000: L(Train): 0.2688125967979431; L(Test): 0.24188567698001862\n",
      "Epoch 9802/10000: L(Train): 0.2802758514881134; L(Test): 0.24034157395362854\n",
      "Epoch 9803/10000: L(Train): 0.2625351846218109; L(Test): 0.24080146849155426\n",
      "Epoch 9804/10000: L(Train): 0.2551593482494354; L(Test): 0.2406422346830368\n",
      "Epoch 9805/10000: L(Train): 0.2624380588531494; L(Test): 0.23998220264911652\n",
      "Epoch 9806/10000: L(Train): 0.25561755895614624; L(Test): 0.23948393762111664\n",
      "Epoch 9807/10000: L(Train): 0.251789927482605; L(Test): 0.23901236057281494\n",
      "Epoch 9808/10000: L(Train): 0.2657662630081177; L(Test): 0.2389523684978485\n",
      "Epoch 9809/10000: L(Train): 0.2714293301105499; L(Test): 0.2394372969865799\n",
      "Epoch 9810/10000: L(Train): 0.25085315108299255; L(Test): 0.238033264875412\n",
      "Epoch 9811/10000: L(Train): 0.26323390007019043; L(Test): 0.23933100700378418\n",
      "Epoch 9812/10000: L(Train): 0.2574580907821655; L(Test): 0.2407837063074112\n",
      "Epoch 9813/10000: L(Train): 0.2573872208595276; L(Test): 0.23921145498752594\n",
      "Epoch 9814/10000: L(Train): 0.2650935649871826; L(Test): 0.2378442883491516\n",
      "Epoch 9815/10000: L(Train): 0.2683836817741394; L(Test): 0.23931439220905304\n",
      "Epoch 9816/10000: L(Train): 0.2578299045562744; L(Test): 0.2414327710866928\n",
      "Epoch 9817/10000: L(Train): 0.2738170027732849; L(Test): 0.23947490751743317\n",
      "Epoch 9818/10000: L(Train): 0.2653478980064392; L(Test): 0.23743537068367004\n",
      "Epoch 9819/10000: L(Train): 0.26001569628715515; L(Test): 0.23814187943935394\n",
      "Epoch 9820/10000: L(Train): 0.2606769800186157; L(Test): 0.237979456782341\n",
      "Epoch 9821/10000: L(Train): 0.2508198320865631; L(Test): 0.2378849983215332\n",
      "Epoch 9822/10000: L(Train): 0.2538145184516907; L(Test): 0.2379596084356308\n",
      "Epoch 9823/10000: L(Train): 0.2613691985607147; L(Test): 0.23678737878799438\n",
      "Epoch 9824/10000: L(Train): 0.25414523482322693; L(Test): 0.23680263757705688\n",
      "Epoch 9825/10000: L(Train): 0.2655238211154938; L(Test): 0.2371591329574585\n",
      "Epoch 9826/10000: L(Train): 0.2530980408191681; L(Test): 0.23704111576080322\n",
      "Epoch 9827/10000: L(Train): 0.25751736760139465; L(Test): 0.23989474773406982\n",
      "Epoch 9828/10000: L(Train): 0.27059122920036316; L(Test): 0.2397976666688919\n",
      "Epoch 9829/10000: L(Train): 0.2657134532928467; L(Test): 0.23852229118347168\n",
      "Epoch 9830/10000: L(Train): 0.2652907073497772; L(Test): 0.23794600367546082\n",
      "Epoch 9831/10000: L(Train): 0.2541143596172333; L(Test): 0.2375987023115158\n",
      "Epoch 9832/10000: L(Train): 0.2694756090641022; L(Test): 0.2378282994031906\n",
      "Epoch 9833/10000: L(Train): 0.25912630558013916; L(Test): 0.23726947605609894\n",
      "Epoch 9834/10000: L(Train): 0.2466486543416977; L(Test): 0.23616303503513336\n",
      "Epoch 9835/10000: L(Train): 0.26141324639320374; L(Test): 0.23731359839439392\n",
      "Epoch 9836/10000: L(Train): 0.2618520259857178; L(Test): 0.2364383041858673\n",
      "Epoch 9837/10000: L(Train): 0.25307539105415344; L(Test): 0.23509395122528076\n",
      "Epoch 9838/10000: L(Train): 0.2680516839027405; L(Test): 0.23689500987529755\n",
      "Epoch 9839/10000: L(Train): 0.26309576630592346; L(Test): 0.2363099306821823\n",
      "Epoch 9840/10000: L(Train): 0.2605876326560974; L(Test): 0.23537664115428925\n",
      "Epoch 9841/10000: L(Train): 0.2433491200208664; L(Test): 0.23691998422145844\n",
      "Epoch 9842/10000: L(Train): 0.26280662417411804; L(Test): 0.23629088699817657\n",
      "Epoch 9843/10000: L(Train): 0.25064024329185486; L(Test): 0.23581571877002716\n",
      "Epoch 9844/10000: L(Train): 0.25504550337791443; L(Test): 0.23614363372325897\n",
      "Epoch 9845/10000: L(Train): 0.2552798390388489; L(Test): 0.23534537851810455\n",
      "Epoch 9846/10000: L(Train): 0.25930336117744446; L(Test): 0.23467081785202026\n",
      "Epoch 9847/10000: L(Train): 0.25180506706237793; L(Test): 0.23522934317588806\n",
      "Epoch 9848/10000: L(Train): 0.24740101397037506; L(Test): 0.2350465953350067\n",
      "Epoch 9849/10000: L(Train): 0.2540718615055084; L(Test): 0.23486357927322388\n",
      "Epoch 9850/10000: L(Train): 0.258832722902298; L(Test): 0.2357562780380249\n",
      "Epoch 9851/10000: L(Train): 0.26630911231040955; L(Test): 0.235421285033226\n",
      "Epoch 9852/10000: L(Train): 0.2592604458332062; L(Test): 0.2347233146429062\n",
      "Epoch 9853/10000: L(Train): 0.2524650990962982; L(Test): 0.2355949580669403\n",
      "Epoch 9854/10000: L(Train): 0.2653769552707672; L(Test): 0.23471619188785553\n",
      "Epoch 9855/10000: L(Train): 0.2473674863576889; L(Test): 0.23613108694553375\n",
      "Epoch 9856/10000: L(Train): 0.26676997542381287; L(Test): 0.23737527430057526\n",
      "Epoch 9857/10000: L(Train): 0.27298662066459656; L(Test): 0.23562034964561462\n",
      "Epoch 9858/10000: L(Train): 0.26478415727615356; L(Test): 0.236210897564888\n",
      "Epoch 9859/10000: L(Train): 0.25606241822242737; L(Test): 0.23544682562351227\n",
      "Epoch 9860/10000: L(Train): 0.26777687668800354; L(Test): 0.23533907532691956\n",
      "Epoch 9861/10000: L(Train): 0.2488257735967636; L(Test): 0.2353755235671997\n",
      "Epoch 9862/10000: L(Train): 0.2522181272506714; L(Test): 0.23524707555770874\n",
      "Epoch 9863/10000: L(Train): 0.2548504173755646; L(Test): 0.23526082932949066\n",
      "Epoch 9864/10000: L(Train): 0.25275900959968567; L(Test): 0.23467005789279938\n",
      "Epoch 9865/10000: L(Train): 0.2585415244102478; L(Test): 0.23521679639816284\n",
      "Epoch 9866/10000: L(Train): 0.28558966517448425; L(Test): 0.2346159964799881\n",
      "Epoch 9867/10000: L(Train): 0.2533387839794159; L(Test): 0.2351224273443222\n",
      "Epoch 9868/10000: L(Train): 0.2503342628479004; L(Test): 0.23505103588104248\n",
      "Epoch 9869/10000: L(Train): 0.24364259839057922; L(Test): 0.23505571484565735\n",
      "Epoch 9870/10000: L(Train): 0.26752302050590515; L(Test): 0.23558847606182098\n",
      "Epoch 9871/10000: L(Train): 0.2546637952327728; L(Test): 0.23520395159721375\n",
      "Epoch 9872/10000: L(Train): 0.2529532015323639; L(Test): 0.23728244006633759\n",
      "Epoch 9873/10000: L(Train): 0.25770339369773865; L(Test): 0.2351698875427246\n",
      "Epoch 9874/10000: L(Train): 0.24876639246940613; L(Test): 0.2345246821641922\n",
      "Epoch 9875/10000: L(Train): 0.2630051076412201; L(Test): 0.23502430319786072\n",
      "Epoch 9876/10000: L(Train): 0.2544107735157013; L(Test): 0.234476700425148\n",
      "Epoch 9877/10000: L(Train): 0.2382168471813202; L(Test): 0.23463471233844757\n",
      "Epoch 9878/10000: L(Train): 0.267469197511673; L(Test): 0.23518864810466766\n",
      "Epoch 9879/10000: L(Train): 0.2551368176937103; L(Test): 0.23506197333335876\n",
      "Epoch 9880/10000: L(Train): 0.2598557472229004; L(Test): 0.23590217530727386\n",
      "Epoch 9881/10000: L(Train): 0.26588085293769836; L(Test): 0.23582668602466583\n",
      "Epoch 9882/10000: L(Train): 0.2473130226135254; L(Test): 0.2349870800971985\n",
      "Epoch 9883/10000: L(Train): 0.26344749331474304; L(Test): 0.2346329391002655\n",
      "Epoch 9884/10000: L(Train): 0.26915454864501953; L(Test): 0.2349652498960495\n",
      "Epoch 9885/10000: L(Train): 0.253947377204895; L(Test): 0.23441551625728607\n",
      "Epoch 9886/10000: L(Train): 0.2459770143032074; L(Test): 0.2339111864566803\n",
      "Epoch 9887/10000: L(Train): 0.2539275884628296; L(Test): 0.2342253178358078\n",
      "Epoch 9888/10000: L(Train): 0.264623761177063; L(Test): 0.23468634486198425\n",
      "Epoch 9889/10000: L(Train): 0.2555640637874603; L(Test): 0.23387844860553741\n",
      "Epoch 9890/10000: L(Train): 0.25638508796691895; L(Test): 0.23401792347431183\n",
      "Epoch 9891/10000: L(Train): 0.25151968002319336; L(Test): 0.2353331744670868\n",
      "Epoch 9892/10000: L(Train): 0.2556553781032562; L(Test): 0.23552913963794708\n",
      "Epoch 9893/10000: L(Train): 0.2583194673061371; L(Test): 0.23522087931632996\n",
      "Epoch 9894/10000: L(Train): 0.25724390149116516; L(Test): 0.23509536683559418\n",
      "Epoch 9895/10000: L(Train): 0.2686765193939209; L(Test): 0.23422755300998688\n",
      "Epoch 9896/10000: L(Train): 0.25248637795448303; L(Test): 0.2341327667236328\n",
      "Epoch 9897/10000: L(Train): 0.25053972005844116; L(Test): 0.23346048593521118\n",
      "Epoch 9898/10000: L(Train): 0.2525159418582916; L(Test): 0.23397068679332733\n",
      "Epoch 9899/10000: L(Train): 0.27112266421318054; L(Test): 0.23391033709049225\n",
      "Epoch 9900/10000: L(Train): 0.2549774944782257; L(Test): 0.2329311966896057\n",
      "Epoch 9901/10000: L(Train): 0.25042611360549927; L(Test): 0.23443588614463806\n",
      "Epoch 9902/10000: L(Train): 0.24776294827461243; L(Test): 0.23338744044303894\n",
      "Epoch 9903/10000: L(Train): 0.26380807161331177; L(Test): 0.23766681551933289\n",
      "Epoch 9904/10000: L(Train): 0.27256274223327637; L(Test): 0.23691928386688232\n",
      "Epoch 9905/10000: L(Train): 0.25377893447875977; L(Test): 0.23623625934123993\n",
      "Epoch 9906/10000: L(Train): 0.27232247591018677; L(Test): 0.23731018602848053\n",
      "Epoch 9907/10000: L(Train): 0.2653508484363556; L(Test): 0.23548004031181335\n",
      "Epoch 9908/10000: L(Train): 0.2584840655326843; L(Test): 0.2388165146112442\n",
      "Epoch 9909/10000: L(Train): 0.27360621094703674; L(Test): 0.2361113280057907\n",
      "Epoch 9910/10000: L(Train): 0.26191389560699463; L(Test): 0.23592250049114227\n",
      "Epoch 9911/10000: L(Train): 0.2519295811653137; L(Test): 0.23823349177837372\n",
      "Epoch 9912/10000: L(Train): 0.24609269201755524; L(Test): 0.23520907759666443\n",
      "Epoch 9913/10000: L(Train): 0.2672312259674072; L(Test): 0.23684757947921753\n",
      "Epoch 9914/10000: L(Train): 0.26667794585227966; L(Test): 0.2373095452785492\n",
      "Epoch 9915/10000: L(Train): 0.26259756088256836; L(Test): 0.23688827455043793\n",
      "Epoch 9916/10000: L(Train): 0.25967469811439514; L(Test): 0.2356591671705246\n",
      "Epoch 9917/10000: L(Train): 0.2517613470554352; L(Test): 0.23801393806934357\n",
      "Epoch 9918/10000: L(Train): 0.2593845725059509; L(Test): 0.23720461130142212\n",
      "Epoch 9919/10000: L(Train): 0.25436341762542725; L(Test): 0.2364165484905243\n",
      "Epoch 9920/10000: L(Train): 0.26648974418640137; L(Test): 0.23610258102416992\n",
      "Epoch 9921/10000: L(Train): 0.27772918343544006; L(Test): 0.23554672300815582\n",
      "Epoch 9922/10000: L(Train): 0.25152960419654846; L(Test): 0.2356448918581009\n",
      "Epoch 9923/10000: L(Train): 0.233922079205513; L(Test): 0.23680250346660614\n",
      "Epoch 9924/10000: L(Train): 0.27284157276153564; L(Test): 0.23497647047042847\n",
      "Epoch 9925/10000: L(Train): 0.2505260705947876; L(Test): 0.23558467626571655\n",
      "Epoch 9926/10000: L(Train): 0.2593807578086853; L(Test): 0.23550264537334442\n",
      "Epoch 9927/10000: L(Train): 0.2571372389793396; L(Test): 0.23594345152378082\n",
      "Epoch 9928/10000: L(Train): 0.24785825610160828; L(Test): 0.23716062307357788\n",
      "Epoch 9929/10000: L(Train): 0.25203198194503784; L(Test): 0.23601150512695312\n",
      "Epoch 9930/10000: L(Train): 0.24920764565467834; L(Test): 0.2358851283788681\n",
      "Epoch 9931/10000: L(Train): 0.24696019291877747; L(Test): 0.23604923486709595\n",
      "Epoch 9932/10000: L(Train): 0.26011380553245544; L(Test): 0.2384081333875656\n",
      "Epoch 9933/10000: L(Train): 0.2687269151210785; L(Test): 0.23656804859638214\n",
      "Epoch 9934/10000: L(Train): 0.26327693462371826; L(Test): 0.235482320189476\n",
      "Epoch 9935/10000: L(Train): 0.2551271319389343; L(Test): 0.2375231832265854\n",
      "Epoch 9936/10000: L(Train): 0.2613237202167511; L(Test): 0.2359558492898941\n",
      "Epoch 9937/10000: L(Train): 0.24137721955776215; L(Test): 0.2378140389919281\n",
      "Epoch 9938/10000: L(Train): 0.26074615120887756; L(Test): 0.2378825694322586\n",
      "Epoch 9939/10000: L(Train): 0.2622487545013428; L(Test): 0.23617753386497498\n",
      "Epoch 9940/10000: L(Train): 0.2655368149280548; L(Test): 0.23546412587165833\n",
      "Epoch 9941/10000: L(Train): 0.2582942843437195; L(Test): 0.23711928725242615\n",
      "Epoch 9942/10000: L(Train): 0.25741612911224365; L(Test): 0.23612861335277557\n",
      "Epoch 9943/10000: L(Train): 0.26220157742500305; L(Test): 0.23741960525512695\n",
      "Epoch 9944/10000: L(Train): 0.24694569408893585; L(Test): 0.23817643523216248\n",
      "Epoch 9945/10000: L(Train): 0.26884087920188904; L(Test): 0.23633965849876404\n",
      "Epoch 9946/10000: L(Train): 0.2513309121131897; L(Test): 0.2394867241382599\n",
      "Epoch 9947/10000: L(Train): 0.251237690448761; L(Test): 0.23753131926059723\n",
      "Epoch 9948/10000: L(Train): 0.25549471378326416; L(Test): 0.2374098300933838\n",
      "Epoch 9949/10000: L(Train): 0.27213621139526367; L(Test): 0.23719632625579834\n",
      "Epoch 9950/10000: L(Train): 0.24821816384792328; L(Test): 0.24175141751766205\n",
      "Epoch 9951/10000: L(Train): 0.2663552761077881; L(Test): 0.23669597506523132\n",
      "Epoch 9952/10000: L(Train): 0.25303637981414795; L(Test): 0.23685693740844727\n",
      "Epoch 9953/10000: L(Train): 0.27570047974586487; L(Test): 0.23850911855697632\n",
      "Epoch 9954/10000: L(Train): 0.26605308055877686; L(Test): 0.235935777425766\n",
      "Epoch 9955/10000: L(Train): 0.25504279136657715; L(Test): 0.2382788211107254\n",
      "Epoch 9956/10000: L(Train): 0.25981658697128296; L(Test): 0.2400026023387909\n",
      "Epoch 9957/10000: L(Train): 0.271197110414505; L(Test): 0.23729285597801208\n",
      "Epoch 9958/10000: L(Train): 0.26215535402297974; L(Test): 0.23671725392341614\n",
      "Epoch 9959/10000: L(Train): 0.26352307200431824; L(Test): 0.23745223879814148\n",
      "Epoch 9960/10000: L(Train): 0.2714426815509796; L(Test): 0.23577632009983063\n",
      "Epoch 9961/10000: L(Train): 0.25916799902915955; L(Test): 0.23721547424793243\n",
      "Epoch 9962/10000: L(Train): 0.24714435636997223; L(Test): 0.2381669282913208\n",
      "Epoch 9963/10000: L(Train): 0.2406371831893921; L(Test): 0.23710177838802338\n",
      "Epoch 9964/10000: L(Train): 0.26296761631965637; L(Test): 0.23668783903121948\n",
      "Epoch 9965/10000: L(Train): 0.2638293504714966; L(Test): 0.23642799258232117\n",
      "Epoch 9966/10000: L(Train): 0.2449185699224472; L(Test): 0.23707854747772217\n",
      "Epoch 9967/10000: L(Train): 0.2535886764526367; L(Test): 0.2370576411485672\n",
      "Epoch 9968/10000: L(Train): 0.24416294693946838; L(Test): 0.23888938128948212\n",
      "Epoch 9969/10000: L(Train): 0.26018205285072327; L(Test): 0.235658660531044\n",
      "Epoch 9970/10000: L(Train): 0.25229719281196594; L(Test): 0.23729541897773743\n",
      "Epoch 9971/10000: L(Train): 0.26527005434036255; L(Test): 0.23645024001598358\n",
      "Epoch 9972/10000: L(Train): 0.24733449518680573; L(Test): 0.23789212107658386\n",
      "Epoch 9973/10000: L(Train): 0.2671901285648346; L(Test): 0.23864226043224335\n",
      "Epoch 9974/10000: L(Train): 0.2556500732898712; L(Test): 0.23748363554477692\n",
      "Epoch 9975/10000: L(Train): 0.26300206780433655; L(Test): 0.2390214502811432\n",
      "Epoch 9976/10000: L(Train): 0.2545143961906433; L(Test): 0.23764953017234802\n",
      "Epoch 9977/10000: L(Train): 0.27641454339027405; L(Test): 0.23789045214653015\n",
      "Epoch 9978/10000: L(Train): 0.26692959666252136; L(Test): 0.23778781294822693\n",
      "Epoch 9979/10000: L(Train): 0.27076199650764465; L(Test): 0.23808355629444122\n",
      "Epoch 9980/10000: L(Train): 0.27280884981155396; L(Test): 0.23697763681411743\n",
      "Epoch 9981/10000: L(Train): 0.2619098126888275; L(Test): 0.23586338758468628\n",
      "Epoch 9982/10000: L(Train): 0.25840476155281067; L(Test): 0.23546434938907623\n",
      "Epoch 9983/10000: L(Train): 0.24470321834087372; L(Test): 0.23665186762809753\n",
      "Epoch 9984/10000: L(Train): 0.25907957553863525; L(Test): 0.2371063530445099\n",
      "Epoch 9985/10000: L(Train): 0.2642318606376648; L(Test): 0.23652943968772888\n",
      "Epoch 9986/10000: L(Train): 0.25787097215652466; L(Test): 0.23676066100597382\n",
      "Epoch 9987/10000: L(Train): 0.2561631202697754; L(Test): 0.236041858792305\n",
      "Epoch 9988/10000: L(Train): 0.2641531825065613; L(Test): 0.2353135347366333\n",
      "Epoch 9989/10000: L(Train): 0.24393926560878754; L(Test): 0.23535847663879395\n",
      "Epoch 9990/10000: L(Train): 0.25038808584213257; L(Test): 0.2375064641237259\n",
      "Epoch 9991/10000: L(Train): 0.266216903924942; L(Test): 0.236062690615654\n",
      "Epoch 9992/10000: L(Train): 0.25240325927734375; L(Test): 0.2347862422466278\n",
      "Epoch 9993/10000: L(Train): 0.2565383315086365; L(Test): 0.2355535328388214\n",
      "Epoch 9994/10000: L(Train): 0.24656671285629272; L(Test): 0.23613689839839935\n",
      "Epoch 9995/10000: L(Train): 0.25329282879829407; L(Test): 0.23635749518871307\n",
      "Epoch 9996/10000: L(Train): 0.2596082091331482; L(Test): 0.23454028367996216\n",
      "Epoch 9997/10000: L(Train): 0.26457738876342773; L(Test): 0.2354925274848938\n",
      "Epoch 9998/10000: L(Train): 0.2418474555015564; L(Test): 0.2352105677127838\n",
      "Epoch 9999/10000: L(Train): 0.2580106258392334; L(Test): 0.2355806976556778\n",
      "Epoch 10000/10000: L(Train): 0.25135791301727295; L(Test): 0.23542015254497528\n",
      "Trained GRU parameters saved to ../../weinhardt2025/params/augustat2025/gru_augustat2025.pkl\n"
     ]
    }
   ],
   "source": [
    "gru = training(\n",
    "    gru=gru,\n",
    "    optimizer=optimizer,\n",
    "    dataset_train=dataset,\n",
    "    dataset_test=dataset,\n",
    "    epochs=epochs,\n",
    "    )\n",
    "\n",
    "torch.save(gru.state_dict(), path_gru)\n",
    "print(\"Trained GRU parameters saved to \" + path_gru)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_agent = setup_agent_gru(path_gru, gru)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot SPICE against benchmark models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spice import plot_session\n",
    "\n",
    "# plotting\n",
    "participant_id = 7\n",
    "\n",
    "# estimator.print_spice_model(participant_id)\n",
    "\n",
    "agents = {\n",
    "    # add baseline agent here\n",
    "    'rnn': estimator.rnn_agent,\n",
    "    'spice': estimator.spice_agent,\n",
    "    # 'baseline': baseline_agent,\n",
    "    'gru': gru_agent,\n",
    "}\n",
    "\n",
    "fig, axs = plot_session(agents, dataset.xs[participant_id], signals_to_plot=[])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "spice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
